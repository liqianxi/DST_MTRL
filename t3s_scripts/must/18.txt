W&B enabled.
2023-09-06 13:52:01,779 MainThread INFO: Experiment Name:testing_must_mtsac
2023-09-06 13:52:01,779 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      20,
      20
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      24,
      24
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      24,
      24
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 400,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "success_traj_update_only": 1,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 10,
    "mask_update_interval": 25,
    "update_end_epoch": 20,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
wandb: Currently logged in as: liqianxi. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: WARNING Serializing object of type str that is 934455 bytes
wandb: wandb version 0.15.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/qianxi/t3s/t3s_code/wandb/run-20230906_135313-4wwda43c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-universe-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/liqianxi/dst_mtrl
wandb: üöÄ View run at https://wandb.ai/liqianxi/dst_mtrl/runs/4wwda43c
2023-09-06 13:53:20,436 MainThread INFO: Finished Pretrain
  0%|          | 0/400 [00:00<?, ?it/s]sample: [4, 2, 9, 0, 5, 8, 3, 6, 1, 7]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.7437100410461426 0.0020339488983154297
train_time 0.7469673156738281
snapshot at best
2023-09-06 13:53:21,750 MainThread INFO: EPOCH:0
2023-09-06 13:53:21,750 MainThread INFO: Time Consumed:1.2593231201171875s
2023-09-06 13:53:21,751 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:374: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/400 [00:02<13:28,  2.03s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1190.55157
Train_Epoch_Reward                    15328.84191
Running_Training_Average_Rewards      1532.88419
Explore_Time                          0.00348
Train___Time                          0.74697
Eval____Time                          0.00258
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.50740
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48842
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.00195
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85156
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50424
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21898
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.28963
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12153.51626
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61132
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.52706
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.54870      0.46865    8.48176     6.51463
alpha_0                               0.99835      0.00086    0.99970     0.99700
alpha_1                               0.99835      0.00086    0.99970     0.99700
alpha_2                               0.99835      0.00086    0.99970     0.99700
alpha_3                               0.99835      0.00086    0.99970     0.99700
alpha_4                               0.99835      0.00086    0.99970     0.99700
alpha_5                               0.99835      0.00086    0.99970     0.99700
alpha_6                               0.99835      0.00086    0.99970     0.99700
alpha_7                               0.99835      0.00086    0.99970     0.99700
alpha_8                               0.99835      0.00086    0.99970     0.99701
alpha_9                               0.99835      0.00086    0.99970     0.99700
Alpha_loss                            -0.00903     0.00576    -0.00000    -0.01806
Training/policy_loss                  -2.68099     0.01477    -2.65542    -2.70964
Training/qf1_loss                     859.32728    107.63549  1053.13623  620.55780
Training/qf2_loss                     859.24108    107.63590  1053.05054  620.47131
Training/pf_norm                      0.43343      0.03974    0.49120     0.36073
Training/qf1_norm                     21.77963     1.02138    23.84640    19.55679
Training/qf2_norm                     22.81695     1.07161    25.04728    20.54416
log_std/mean                          -0.00336     0.00173    -0.00064    -0.00608
log_std/std                           0.00196      0.00002    0.00199     0.00194
log_std/max                           0.00040      0.00168    0.00312     -0.00220
log_std/min                           -0.00574     0.00194    -0.00287    -0.00886
log_probs/mean                        -2.68403     0.01489    -2.65813    -2.71266
log_probs/std                         0.42916      0.00896    0.44892     0.41647
log_probs/max                         -1.28316     0.10285    -1.12445    -1.41451
log_probs/min                         -4.21278     0.37790    -3.63561    -4.89773
mean/mean                             -0.00015     0.00033    0.00068     -0.00041
mean/std                              0.00120      0.00010    0.00139     0.00108
mean/max                              0.00183      0.00060    0.00326     0.00136
mean/min                              -0.00267     0.00019    -0.00222    -0.00290
------------------------------------  -----------  ---------  ----------  ---------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/18/model
sample: [3, 8, 1, 9, 5, 6, 0, 4, 7, 2]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.6094365119934082 0.0021276473999023438
train_time 0.6128125190734863
snapshot at best
2023-09-06 13:53:23,592 MainThread INFO: EPOCH:1
2023-09-06 13:53:23,593 MainThread INFO: Time Consumed:1.0843405723571777s
2023-09-06 13:53:23,593 MainThread INFO: Total Frames:3000s
  0%|          | 2/400 [00:03<10:11,  1.54s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1190.73074
Train_Epoch_Reward                    10819.82669
Running_Training_Average_Rewards      1307.43343
Explore_Time                          0.00340
Train___Time                          0.61281
Eval____Time                          0.00257
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.92394
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48842
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.00195
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85156
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50424
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21898
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.28963
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12153.51626
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61132
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.52706
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.27774      0.23552   7.62972    6.81370
alpha_0                               0.99536      0.00086   0.99671    0.99402
alpha_1                               0.99536      0.00086   0.99670    0.99402
alpha_2                               0.99536      0.00086   0.99670    0.99402
alpha_3                               0.99536      0.00086   0.99670    0.99401
alpha_4                               0.99536      0.00086   0.99670    0.99401
alpha_5                               0.99536      0.00086   0.99671    0.99402
alpha_6                               0.99536      0.00086   0.99671    0.99402
alpha_7                               0.99536      0.00086   0.99671    0.99402
alpha_8                               0.99536      0.00086   0.99671    0.99402
alpha_9                               0.99536      0.00086   0.99670    0.99401
Alpha_loss                            -0.02912     0.00578   -0.02006   -0.03813
Training/policy_loss                  -2.68788     0.01338   -2.66266   -2.70710
Training/qf1_loss                     796.78315    89.61497  919.68799  653.81165
Training/qf2_loss                     796.68285    89.61319  919.58728  653.71503
Training/pf_norm                      0.41056      0.04645   0.50765    0.35011
Training/qf1_norm                     21.30590     0.51854   22.16521   20.26421
Training/qf2_norm                     22.31479     0.53544   23.19565   21.28266
log_std/mean                          -0.00958     0.00186   -0.00670   -0.01253
log_std/std                           0.00211      0.00006   0.00220    0.00201
log_std/max                           -0.00537     0.00164   -0.00277   -0.00793
log_std/min                           -0.01291     0.00215   -0.00958   -0.01633
log_probs/mean                        -2.69168     0.01350   -2.66614   -2.71101
log_probs/std                         0.41283      0.00852   0.42606    0.40024
log_probs/max                         -1.32779     0.05916   -1.22374   -1.39996
log_probs/min                         -4.26154     0.72246   -3.59551   -6.29489
mean/mean                             -0.00017     0.00005   -0.00003   -0.00023
mean/std                              0.00141      0.00011   0.00163    0.00125
mean/max                              0.00233      0.00035   0.00307    0.00180
mean/min                              -0.00293     0.00007   -0.00284   -0.00305
------------------------------------  -----------  --------  ---------  ---------
sample: [3, 4, 0, 1, 6, 7, 2, 9, 8, 5]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.6254794597625732 0.0019502639770507812
train_time 0.6286215782165527
snapshot at best
2023-09-06 13:53:24,842 MainThread INFO: EPOCH:2
2023-09-06 13:53:24,843 MainThread INFO: Time Consumed:1.141113519668579s
2023-09-06 13:53:24,843 MainThread INFO: Total Frames:4500s
  1%|          | 3/400 [00:04<09:16,  1.40s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1191.81512
Train_Epoch_Reward                    7013.51725
Running_Training_Average_Rewards      1105.40620
Explore_Time                          0.00394
Train___Time                          0.62862
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.07934
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.49075
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.93188
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62901
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26060
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94736
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07202
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12190.25103
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57951
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.42187
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.30916      0.44710   7.79651    6.27654
alpha_0                               0.99238      0.00086   0.99372    0.99104
alpha_1                               0.99238      0.00086   0.99372    0.99104
alpha_2                               0.99238      0.00085   0.99372    0.99104
alpha_3                               0.99237      0.00086   0.99372    0.99103
alpha_4                               0.99237      0.00086   0.99372    0.99103
alpha_5                               0.99238      0.00086   0.99372    0.99104
alpha_6                               0.99238      0.00085   0.99372    0.99104
alpha_7                               0.99238      0.00086   0.99372    0.99104
alpha_8                               0.99238      0.00086   0.99372    0.99104
alpha_9                               0.99237      0.00086   0.99372    0.99103
Alpha_loss                            -0.04921     0.00577   -0.04006   -0.05818
Training/policy_loss                  -2.68885     0.01286   -2.66402   -2.70928
Training/qf1_loss                     795.41652    80.81419  869.79358  579.96863
Training/qf2_loss                     795.29667    80.80586  869.66614  579.86731
Training/pf_norm                      0.40161      0.03685   0.47557    0.34901
Training/qf1_norm                     21.67003     1.06203   22.90246   19.32187
Training/qf2_norm                     22.74111     1.11932   23.94703   20.18514
log_std/mean                          -0.01646     0.00211   -0.01321   -0.01981
log_std/std                           0.00237      0.00010   0.00254    0.00223
log_std/max                           -0.01129     0.00181   -0.00851   -0.01418
log_std/min                           -0.02103     0.00251   -0.01714   -0.02501
log_probs/mean                        -2.69290     0.01295   -2.66790   -2.71357
log_probs/std                         0.40226      0.00772   0.41325    0.38741
log_probs/max                         -1.42445     0.09118   -1.23306   -1.55122
log_probs/min                         -4.46592     0.57791   -3.83454   -5.94568
mean/mean                             0.00033      0.00021   0.00063    0.00003
mean/std                              0.00205      0.00029   0.00254    0.00168
mean/max                              0.00407      0.00060   0.00514    0.00330
mean/min                              -0.00346     0.00027   -0.00305   -0.00389
------------------------------------  -----------  --------  ---------  ---------
sample: [8, 6, 5, 2, 9, 7, 1, 0, 3, 4]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.6753358840942383 0.002033710479736328
train_time 0.6785888671875
snapshot at best
2023-09-06 13:53:26,107 MainThread INFO: EPOCH:3
2023-09-06 13:53:26,107 MainThread INFO: Time Consumed:1.1601762771606445s
2023-09-06 13:53:26,108 MainThread INFO: Total Frames:6000s
  1%|          | 4/400 [00:05<08:55,  1.35s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1197.40869
Train_Epoch_Reward                    9614.36658
Running_Training_Average_Rewards      914.92368
Explore_Time                          0.00313
Train___Time                          0.67859
Eval____Time                          0.00351
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.39507
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.39599
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.01460
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.45356
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20648
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.87358
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01985
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12326.44636
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.43769
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.32659
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.56522      0.62356    9.59997     6.98506
alpha_0                               0.98941      0.00085    0.99074     0.98807
alpha_1                               0.98940      0.00085    0.99074     0.98807
alpha_2                               0.98941      0.00085    0.99075     0.98807
alpha_3                               0.98940      0.00085    0.99074     0.98806
alpha_4                               0.98940      0.00085    0.99073     0.98806
alpha_5                               0.98941      0.00085    0.99074     0.98807
alpha_6                               0.98941      0.00085    0.99075     0.98807
alpha_7                               0.98940      0.00085    0.99074     0.98806
alpha_8                               0.98941      0.00085    0.99074     0.98807
alpha_9                               0.98940      0.00085    0.99074     0.98807
Alpha_loss                            -0.06934     0.00581    -0.06025    -0.07853
Training/policy_loss                  -2.69334     0.00837    -2.68212    -2.70669
Training/qf1_loss                     1084.51877   147.69662  1364.92920  751.09656
Training/qf2_loss                     1084.33880   147.68714  1364.74438  750.96179
Training/pf_norm                      0.38850      0.03554    0.47071     0.33816
Training/qf1_norm                     24.81183     1.42021    27.11225    21.15337
Training/qf2_norm                     26.33633     1.53073    28.67038    22.34036
log_std/mean                          -0.02429     0.00241    -0.02059    -0.02812
log_std/std                           0.00277      0.00013    0.00297     0.00257
log_std/max                           -0.01813     0.00213    -0.01486    -0.02155
log_std/min                           -0.03020     0.00281    -0.02589    -0.03465
log_probs/mean                        -2.69687     0.00831    -2.68578    -2.70986
log_probs/std                         0.38406      0.01147    0.40364     0.36399
log_probs/max                         -1.50354     0.05585    -1.38416    -1.58553
log_probs/min                         -4.26665     0.58399    -3.55498    -5.52090
mean/mean                             0.00094      0.00014    0.00110     0.00066
mean/std                              0.00274      0.00007    0.00283     0.00263
mean/max                              0.00639      0.00059    0.00724     0.00540
mean/min                              -0.00410     0.00013    -0.00391    -0.00428
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 0, 3, 9, 2, 7, 5, 8, 4, 6]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.7421386241912842 0.0020377635955810547
train_time 0.7454214096069336
2023-09-06 13:53:26,975 MainThread INFO: EPOCH:4
2023-09-06 13:53:26,975 MainThread INFO: Time Consumed:0.7579758167266846s
2023-09-06 13:53:26,976 MainThread INFO: Total Frames:7500s
  1%|‚ñè         | 5/400 [00:06<07:45,  1.18s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1202.41752
Train_Epoch_Reward                    14679.79225
Running_Training_Average_Rewards      1043.58920
Explore_Time                          0.00301
Train___Time                          0.74542
Eval____Time                          0.00545
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.95965
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.11676
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.13412
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.26315
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20046
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.85472
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98428
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12310.32480
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.06190
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.38569
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.25999      0.68498    9.96298     7.49355
alpha_0                               0.98644      0.00085    0.98778     0.98511
alpha_1                               0.98644      0.00085    0.98777     0.98510
alpha_2                               0.98644      0.00085    0.98778     0.98511
alpha_3                               0.98643      0.00085    0.98776     0.98509
alpha_4                               0.98643      0.00085    0.98777     0.98510
alpha_5                               0.98644      0.00085    0.98778     0.98511
alpha_6                               0.98644      0.00085    0.98777     0.98511
alpha_7                               0.98644      0.00085    0.98777     0.98510
alpha_8                               0.98644      0.00085    0.98777     0.98511
alpha_9                               0.98644      0.00085    0.98777     0.98511
Alpha_loss                            -0.08949     0.00579    -0.08049    -0.09864
Training/policy_loss                  -2.69891     0.00563    -2.68945    -2.70663
Training/qf1_loss                     1015.99513   171.36327  1414.51648  820.09900
Training/qf2_loss                     1015.77338   171.36269  1414.28589  819.87073
Training/pf_norm                      0.35748      0.01968    0.38884     0.32591
Training/qf1_norm                     24.56072     1.48962    28.27207    22.92958
Training/qf2_norm                     26.22128     1.55783    30.11552    24.55946
log_std/mean                          -0.03314     0.00270    -0.02900    -0.03745
log_std/std                           0.00329      0.00018    0.00356     0.00302
log_std/max                           -0.02586     0.00234    -0.02232    -0.02962
log_std/min                           -0.04057     0.00320    -0.03565    -0.04564
log_probs/mean                        -2.70063     0.00549    -2.69099    -2.70720
log_probs/std                         0.36783      0.01603    0.39026     0.34349
log_probs/max                         -1.54133     0.06621    -1.45077    -1.63747
log_probs/min                         -4.33258     0.39976    -3.82163    -5.23376
mean/mean                             0.00080      0.00008    0.00090     0.00063
mean/std                              0.00243      0.00009    0.00257     0.00226
mean/max                              0.00815      0.00032    0.00843     0.00745
mean/min                              -0.00375     0.00004    -0.00367    -0.00383
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 0, 6, 4, 7, 1, 2, 5, 3, 8]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.8528203964233398 0.001987934112548828
train_time 0.856008768081665
2023-09-06 13:53:27,959 MainThread INFO: EPOCH:5
2023-09-06 13:53:27,960 MainThread INFO: Time Consumed:0.866325855255127s
2023-09-06 13:53:27,960 MainThread INFO: Total Frames:9000s
  2%|‚ñè         | 6/400 [00:07<07:18,  1.11s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1202.36630
Train_Epoch_Reward                    21200.57572
Running_Training_Average_Rewards      1516.49115
Explore_Time                          0.00353
Train___Time                          0.85601
Eval____Time                          0.00280
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.76255
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.08911
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.09071
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.29276
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.17669
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.80422
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94297
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12182.91105
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.99727
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.45268
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.58700      0.63200    9.76776     7.70232
alpha_0                               0.98349      0.00085    0.98482     0.98216
alpha_1                               0.98348      0.00085    0.98481     0.98214
alpha_2                               0.98349      0.00085    0.98482     0.98216
alpha_3                               0.98347      0.00085    0.98480     0.98214
alpha_4                               0.98347      0.00085    0.98480     0.98215
alpha_5                               0.98348      0.00085    0.98482     0.98215
alpha_6                               0.98348      0.00085    0.98481     0.98215
alpha_7                               0.98348      0.00085    0.98481     0.98215
alpha_8                               0.98348      0.00085    0.98481     0.98215
alpha_9                               0.98348      0.00085    0.98481     0.98215
Alpha_loss                            -0.10978     0.00587    -0.10047    -0.11887
Training/policy_loss                  -2.71221     0.00931    -2.69509    -2.73131
Training/qf1_loss                     1076.23412   165.55538  1438.24133  844.87518
Training/qf2_loss                     1075.93071   165.53913  1437.89795  844.62714
Training/pf_norm                      0.32053      0.03627    0.37648     0.24068
Training/qf1_norm                     25.90663     1.49418    28.80409    23.59834
Training/qf2_norm                     27.98716     1.62448    31.17916    25.37302
log_std/mean                          -0.04312     0.00303    -0.03842    -0.04789
log_std/std                           0.00399      0.00024    0.00439     0.00364
log_std/max                           -0.03489     0.00277    -0.03052    -0.03923
log_std/min                           -0.05225     0.00355    -0.04677    -0.05785
log_probs/mean                        -2.71091     0.00882    -2.69527    -2.72941
log_probs/std                         0.35179      0.00823    0.36242     0.33431
log_probs/max                         -1.62026     0.07346    -1.49984    -1.75046
log_probs/min                         -4.72603     0.72190    -4.03452    -6.07260
mean/mean                             0.00055      0.00003    0.00060     0.00051
mean/std                              0.00222      0.00008    0.00240     0.00214
mean/max                              0.00759      0.00034    0.00804     0.00692
mean/min                              -0.00414     0.00042    -0.00367    -0.00500
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 0, 8, 4, 6, 1, 3, 9, 5, 2]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.0397686958312988 0.0022497177124023438
train_time 1.0450160503387451
2023-09-06 13:53:29,133 MainThread INFO: EPOCH:6
2023-09-06 13:53:29,134 MainThread INFO: Time Consumed:1.0548453330993652s
2023-09-06 13:53:29,134 MainThread INFO: Total Frames:10500s
  2%|‚ñè         | 7/400 [00:08<07:26,  1.14s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1192.25891
Train_Epoch_Reward                    7393.10090
Running_Training_Average_Rewards      1442.44896
Explore_Time                          0.00282
Train___Time                          1.04502
Eval____Time                          0.00282
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.10514
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.25107
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.90656
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.58239
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20680
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.79570
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97881
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12015.66018
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.20606
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.52641
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.51053      0.48581    9.27053     7.91381
alpha_0                               0.98054      0.00085    0.98187     0.97922
alpha_1                               0.98052      0.00085    0.98185     0.97919
alpha_2                               0.98054      0.00085    0.98186     0.97921
alpha_3                               0.98052      0.00085    0.98185     0.97919
alpha_4                               0.98053      0.00085    0.98185     0.97920
alpha_5                               0.98053      0.00085    0.98186     0.97921
alpha_6                               0.98053      0.00085    0.98186     0.97920
alpha_7                               0.98052      0.00085    0.98185     0.97920
alpha_8                               0.98053      0.00085    0.98186     0.97921
alpha_9                               0.98053      0.00085    0.98185     0.97920
Alpha_loss                            -0.13002     0.00585    -0.12078    -0.13897
Training/policy_loss                  -2.72077     0.00849    -2.70948    -2.73545
Training/qf1_loss                     1095.61812   122.49462  1295.17090  907.19348
Training/qf2_loss                     1095.25197   122.48193  1294.78711  906.89600
Training/pf_norm                      0.27489      0.02925    0.30430     0.19570
Training/qf1_norm                     26.44633     1.27331    28.64646    24.64313
Training/qf2_norm                     28.69795     1.35029    30.99892    26.44322
log_std/mean                          -0.05404     0.00327    -0.04898    -0.05919
log_std/std                           0.00490      0.00027    0.00532     0.00449
log_std/max                           -0.04521     0.00318    -0.04025    -0.05024
log_std/min                           -0.06528     0.00394    -0.05918    -0.07148
log_probs/mean                        -2.71470     0.00783    -2.70495    -2.72757
log_probs/std                         0.32676      0.00639    0.33806     0.31606
log_probs/max                         -1.70013     0.05687    -1.60167    -1.82432
log_probs/min                         -4.37926     0.42715    -3.72691    -5.20220
mean/mean                             0.00004      0.00026    0.00042     -0.00033
mean/std                              0.00298      0.00027    0.00337     0.00253
mean/max                              0.00654      0.00028    0.00687     0.00598
mean/min                              -0.00742     0.00115    -0.00554    -0.00901
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 1, 7, 2, 4, 5, 6, 8, 9, 3]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.9533102512359619 0.001996278762817383
train_time 0.9565463066101074
2023-09-06 13:53:30,226 MainThread INFO: EPOCH:7
2023-09-06 13:53:30,227 MainThread INFO: Time Consumed:0.9660069942474365s
2023-09-06 13:53:30,227 MainThread INFO: Total Frames:12000s
  2%|‚ñè         | 8/400 [00:09<07:17,  1.12s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1189.74463
Train_Epoch_Reward                    18943.96234
Running_Training_Average_Rewards      1584.58797
Explore_Time                          0.00274
Train___Time                          0.95655
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.74159
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.34422
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.02225
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.60941
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36956
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95008
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.10519
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12228.75851
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.31395
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.36682
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           11.15556     1.45242     12.96593    8.31902
alpha_0                               0.97760      0.00084     0.97892     0.97628
alpha_1                               0.97757      0.00085     0.97890     0.97625
alpha_2                               0.97760      0.00084     0.97892     0.97627
alpha_3                               0.97758      0.00084     0.97890     0.97625
alpha_4                               0.97758      0.00084     0.97891     0.97626
alpha_5                               0.97759      0.00085     0.97891     0.97626
alpha_6                               0.97759      0.00084     0.97891     0.97626
alpha_7                               0.97758      0.00084     0.97890     0.97626
alpha_8                               0.97759      0.00084     0.97892     0.97627
alpha_9                               0.97759      0.00084     0.97891     0.97626
Alpha_loss                            -0.15039     0.00584     -0.14094    -0.15944
Training/policy_loss                  -2.73584     0.01079     -2.71628    -2.74954
Training/qf1_loss                     2997.47269   1108.21488  4172.48828  1026.65271
Training/qf2_loss                     2996.84731   1108.11326  4171.86426  1026.23206
Training/pf_norm                      0.23796      0.05100     0.33461     0.16670
Training/qf1_norm                     33.85375     3.83046     38.37556    26.53811
Training/qf2_norm                     37.54855     4.46367     42.94075    28.99044
log_std/mean                          -0.06555     0.00330     -0.06037    -0.07077
log_std/std                           0.00577      0.00023     0.00613     0.00539
log_std/max                           -0.05602     0.00318     -0.05106    -0.06080
log_std/min                           -0.07893     0.00382     -0.07287    -0.08493
log_probs/mean                        -2.72317     0.01062     -2.70645    -2.73842
log_probs/std                         0.31264      0.01171     0.33634     0.29732
log_probs/max                         -1.78847     0.06745     -1.64235    -1.91007
log_probs/min                         -4.75048     0.75064     -4.27111    -6.90787
mean/mean                             -0.00037     0.00016     -0.00020    -0.00076
mean/std                              0.00370      0.00011     0.00383     0.00346
mean/max                              0.00539      0.00032     0.00590     0.00481
mean/min                              -0.00913     0.00018     -0.00878    -0.00933
------------------------------------  -----------  ----------  ----------  ----------
sample: [1, 4, 0, 3, 8, 6, 5, 2, 7, 9]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.0255885124206543 0.0020384788513183594
train_time 1.028878927230835
2023-09-06 13:53:31,371 MainThread INFO: EPOCH:8
2023-09-06 13:53:31,372 MainThread INFO: Time Consumed:1.039283037185669s
2023-09-06 13:53:31,372 MainThread INFO: Total Frames:13500s
  2%|‚ñè         | 9/400 [00:10<07:19,  1.12s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1186.36173
Train_Epoch_Reward                    7659.42706
Running_Training_Average_Rewards      1133.21634
Explore_Time                          0.00326
Train___Time                          1.02888
Eval____Time                          0.00316
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.63829
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.58153
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.94777
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.87528
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.55965
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.11378
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.27051
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12085.92868
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.64466
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.48214
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.29816     1.28641    13.68319    9.69452
alpha_0                               0.97466      0.00084    0.97598     0.97334
alpha_1                               0.97464      0.00084    0.97596     0.97332
alpha_2                               0.97466      0.00084    0.97598     0.97334
alpha_3                               0.97464      0.00084    0.97596     0.97332
alpha_4                               0.97464      0.00084    0.97596     0.97332
alpha_5                               0.97465      0.00084    0.97597     0.97333
alpha_6                               0.97465      0.00084    0.97597     0.97333
alpha_7                               0.97464      0.00084    0.97596     0.97332
alpha_8                               0.97466      0.00084    0.97598     0.97335
alpha_9                               0.97465      0.00084    0.97597     0.97333
Alpha_loss                            -0.17071     0.00588    -0.16144    -0.17993
Training/policy_loss                  -2.74801     0.00907    -2.73428    -2.76274
Training/qf1_loss                     3272.45569   998.89501  5092.62549  2271.45825
Training/qf2_loss                     3271.68787   998.81732  5091.70459  2270.72510
Training/pf_norm                      0.21071      0.04168    0.25466     0.13237
Training/qf1_norm                     35.37503     3.17177    41.21050    31.24587
Training/qf2_norm                     39.58606     3.66657    46.35391    35.26541
log_std/mean                          -0.07747     0.00358    -0.07192    -0.08308
log_std/std                           0.00675      0.00032    0.00726     0.00625
log_std/max                           -0.06701     0.00315    -0.06224    -0.07202
log_std/min                           -0.09306     0.00436    -0.08618    -0.09991
log_probs/mean                        -2.72680     0.00781    -2.71432    -2.73845
log_probs/std                         0.29400      0.00828    0.30877     0.28059
log_probs/max                         -1.84817     0.06258    -1.74384    -1.94531
log_probs/min                         -4.78600     0.38983    -4.00371    -5.32344
mean/mean                             -0.00128     0.00014    -0.00098    -0.00156
mean/std                              0.00335      0.00020    0.00362     0.00301
mean/max                              0.00475      0.00026    0.00501     0.00429
mean/min                              -0.00912     0.00029    -0.00859    -0.00952
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 7, 5, 8, 6, 4, 2, 1, 9, 0]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.0321695804595947 0.0019805431365966797
train_time 1.035402536392212
2023-09-06 13:53:32,522 MainThread INFO: EPOCH:9
2023-09-06 13:53:32,522 MainThread INFO: Time Consumed:1.0459530353546143s
2023-09-06 13:53:32,523 MainThread INFO: Total Frames:15000s
  2%|‚ñé         | 10/400 [00:12<07:21,  1.13s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1182.58230
Train_Epoch_Reward                    66829.37360
Running_Training_Average_Rewards      3114.42543
Explore_Time                          0.00334
Train___Time                          1.03540
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.10858
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.82631
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.76283
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.06522
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.62451
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19867
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.33568
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11907.25915
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.06080
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.55795
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.34449     1.43198    13.25658    8.67892
alpha_0                               0.97173      0.00084    0.97305     0.97042
alpha_1                               0.97171      0.00084    0.97303     0.97039
alpha_2                               0.97174      0.00084    0.97305     0.97042
alpha_3                               0.97172      0.00084    0.97303     0.97040
alpha_4                               0.97171      0.00084    0.97303     0.97040
alpha_5                               0.97172      0.00084    0.97304     0.97040
alpha_6                               0.97172      0.00084    0.97304     0.97041
alpha_7                               0.97171      0.00084    0.97303     0.97040
alpha_8                               0.97174      0.00084    0.97305     0.97043
alpha_9                               0.97172      0.00084    0.97304     0.97041
Alpha_loss                            -0.19083     0.00594    -0.18156    -0.20025
Training/policy_loss                  -2.75527     0.01094    -2.74039    -2.77218
Training/qf1_loss                     2599.22458   954.40498  4419.53516  1449.90784
Training/qf2_loss                     2598.36353   954.27890  4418.36523  1449.10303
Training/pf_norm                      0.20101      0.02495    0.23005     0.14978
Training/qf1_norm                     34.11576     3.82538    41.44114    30.09650
Training/qf2_norm                     38.51597     4.60271    47.67016    34.08137
log_std/mean                          -0.09002     0.00370    -0.08429    -0.09588
log_std/std                           0.00791      0.00036    0.00848     0.00736
log_std/max                           -0.07769     0.00296    -0.07311    -0.08237
log_std/min                           -0.10818     0.00444    -0.10135    -0.11526
log_probs/mean                        -2.72303     0.00893    -2.70892    -2.73735
log_probs/std                         0.27028      0.00473    0.27874     0.26186
log_probs/max                         -1.90743     0.04465    -1.84857    -1.98711
log_probs/min                         -4.36441     0.33956    -3.63755    -4.97156
mean/mean                             -0.00143     0.00028    -0.00089    -0.00172
mean/std                              0.00322      0.00031    0.00385     0.00294
mean/max                              0.00678      0.00130    0.00932     0.00515
mean/min                              -0.00992     0.00063    -0.00915    -0.01091
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 9, 1, 8, 2, 6, 0, 3, 7, 4]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.0318019390106201 0.002084493637084961
train_time 1.035109519958496
2023-09-06 13:53:33,674 MainThread INFO: EPOCH:10
2023-09-06 13:53:33,674 MainThread INFO: Time Consumed:1.0451014041900635s
2023-09-06 13:53:33,674 MainThread INFO: Total Frames:16500s
  3%|‚ñé         | 11/400 [00:13<07:23,  1.14s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1162.88588
Train_Epoch_Reward                    4269.32137
Running_Training_Average_Rewards      2625.27073
Explore_Time                          0.00289
Train___Time                          1.03511
Eval____Time                          0.00324
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.76424
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.74592
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.45390
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.29935
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89214
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.04202
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11637.03243
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.09033
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.65360
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.05384     0.70010    11.16817    8.63318
alpha_0                               0.96881      0.00084    0.97013     0.96750
alpha_1                               0.96879      0.00084    0.97010     0.96748
alpha_2                               0.96882      0.00084    0.97013     0.96751
alpha_3                               0.96880      0.00084    0.97011     0.96749
alpha_4                               0.96879      0.00084    0.97010     0.96748
alpha_5                               0.96880      0.00084    0.97011     0.96749
alpha_6                               0.96881      0.00084    0.97012     0.96749
alpha_7                               0.96880      0.00084    0.97011     0.96749
alpha_8                               0.96882      0.00084    0.97013     0.96751
alpha_9                               0.96880      0.00084    0.97012     0.96749
Alpha_loss                            -0.21114     0.00587    -0.20163    -0.22017
Training/policy_loss                  -2.77241     0.00924    -2.75285    -2.78781
Training/qf1_loss                     2542.27780   420.78403  3241.45068  1738.22241
Training/qf2_loss                     2541.27594   420.74442  3240.34082  1737.36584
Training/pf_norm                      0.17376      0.03724    0.23210     0.12245
Training/qf1_norm                     34.79441     2.11912    37.76357    29.89643
Training/qf2_norm                     39.60705     2.36854    42.54272    34.07410
log_std/mean                          -0.10305     0.00372    -0.09714    -0.10879
log_std/std                           0.00910      0.00033    0.00962     0.00858
log_std/max                           -0.08849     0.00311    -0.08349    -0.09320
log_std/min                           -0.12397     0.00458    -0.11676    -0.13117
log_probs/mean                        -2.72592     0.00735    -2.71246    -2.73820
log_probs/std                         0.25929      0.01034    0.27727     0.24693
log_probs/max                         -1.98880     0.04961    -1.91706    -2.07694
log_probs/min                         -4.80585     0.57995    -4.00630    -5.71015
mean/mean                             -0.00047     0.00017    -0.00026    -0.00075
mean/std                              0.00468      0.00035    0.00504     0.00406
mean/max                              0.01200      0.00099    0.01303     0.01011
mean/min                              -0.01043     0.00063    -0.00929    -0.01104
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 8, 5, 1, 9, 7, 6, 4, 0, 2]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.1515271663665771 0.0019571781158447266
train_time 1.1546990871429443
2023-09-06 13:53:34,945 MainThread INFO: EPOCH:11
2023-09-06 13:53:34,946 MainThread INFO: Time Consumed:1.1643712520599365s
2023-09-06 13:53:34,946 MainThread INFO: Total Frames:18000s
  3%|‚ñé         | 12/400 [00:14<07:37,  1.18s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1133.15284
Train_Epoch_Reward                    11771.02792
Running_Training_Average_Rewards      2762.32410
Explore_Time                          0.00306
Train___Time                          1.15470
Eval____Time                          0.00256
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.69416
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.39327
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.29472
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.08135
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.09404
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.68598
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.85216
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11188.89649
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.90072
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.07625
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.94519      0.89118    11.59044    8.91442
alpha_0                               0.96590      0.00083    0.96721     0.96460
alpha_1                               0.96588      0.00084    0.96719     0.96457
alpha_2                               0.96591      0.00083    0.96722     0.96461
alpha_3                               0.96589      0.00084    0.96720     0.96458
alpha_4                               0.96588      0.00083    0.96719     0.96458
alpha_5                               0.96589      0.00083    0.96720     0.96458
alpha_6                               0.96590      0.00083    0.96720     0.96459
alpha_7                               0.96589      0.00083    0.96720     0.96458
alpha_8                               0.96591      0.00084    0.96722     0.96461
alpha_9                               0.96590      0.00083    0.96720     0.96459
Alpha_loss                            -0.23170     0.00598    -0.22229    -0.24131
Training/policy_loss                  -2.79823     0.01171    -2.78181    -2.82051
Training/qf1_loss                     2582.04163   556.68840  3657.38989  1839.08667
Training/qf2_loss                     2580.91447   556.58630  3655.92847  1838.04822
Training/pf_norm                      0.13801      0.01968    0.16894     0.11398
Training/qf1_norm                     35.82465     2.54317    40.74184    32.49647
Training/qf2_norm                     40.96912     3.14390    46.78384    36.87088
log_std/mean                          -0.11457     0.00280    -0.10995    -0.11876
log_std/std                           0.00996      0.00017    0.01020     0.00969
log_std/max                           -0.09862     0.00271    -0.09422    -0.10269
log_std/min                           -0.13806     0.00337    -0.13240    -0.14292
log_probs/mean                        -2.73536     0.00823    -2.72558    -2.74932
log_probs/std                         0.25414      0.02103    0.30720     0.22989
log_probs/max                         -2.06667     0.03142    -2.03329    -2.14087
log_probs/min                         -4.95814     1.02273    -4.04032    -7.68837
mean/mean                             -0.00066     0.00019    -0.00043    -0.00089
mean/std                              0.00500      0.00021    0.00547     0.00482
mean/max                              0.01238      0.00033    0.01308     0.01192
mean/min                              -0.00949     0.00021    -0.00916    -0.00978
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 8, 2, 4, 9, 6, 3, 7, 5, 0]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.1544148921966553 0.0026454925537109375
train_time 1.1586403846740723
2023-09-06 13:53:36,223 MainThread INFO: EPOCH:12
2023-09-06 13:53:36,223 MainThread INFO: Time Consumed:1.170752763748169s
2023-09-06 13:53:36,224 MainThread INFO: Total Frames:19500s
  3%|‚ñé         | 13/400 [00:15<07:47,  1.21s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1107.55514
Train_Epoch_Reward                    8631.16130
Running_Training_Average_Rewards      822.38369
Explore_Time                          0.00307
Train___Time                          1.15864
Eval____Time                          0.00311
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.47059
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.94587
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.36474
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.91609
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.85726
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.40233
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.55697
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11145.05336
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57390
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.17783
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.82933      0.67751    11.13192    9.03229
alpha_0                               0.96300      0.00083    0.96431     0.96170
alpha_1                               0.96297      0.00083    0.96428     0.96167
alpha_2                               0.96301      0.00083    0.96432     0.96171
alpha_3                               0.96298      0.00083    0.96429     0.96168
alpha_4                               0.96298      0.00083    0.96428     0.96168
alpha_5                               0.96299      0.00083    0.96429     0.96169
alpha_6                               0.96299      0.00083    0.96430     0.96169
alpha_7                               0.96299      0.00083    0.96429     0.96168
alpha_8                               0.96301      0.00083    0.96432     0.96171
alpha_9                               0.96299      0.00083    0.96430     0.96169
Alpha_loss                            -0.25195     0.00596    -0.24308    -0.26184
Training/policy_loss                  -2.81890     0.01371    -2.80028    -2.84823
Training/qf1_loss                     2484.73361   470.34113  3269.11157  1731.05640
Training/qf2_loss                     2483.37610   470.26265  3267.46021  1729.88306
Training/pf_norm                      0.13120      0.02240    0.18471     0.09417
Training/qf1_norm                     37.47645     2.50083    42.68700    34.08082
Training/qf2_norm                     43.39345     2.87787    49.79334    39.29228
log_std/mean                          -0.12308     0.00208    -0.11962    -0.12604
log_std/std                           0.01037      0.00004    0.01042     0.01026
log_std/max                           -0.10677     0.00177    -0.10349    -0.10916
log_std/min                           -0.14771     0.00210    -0.14413    -0.15068
log_probs/mean                        -2.73493     0.01071    -2.71924    -2.75491
log_probs/std                         0.23957      0.01265    0.26906     0.22206
log_probs/max                         -2.08651     0.04117    -2.01696    -2.16670
log_probs/min                         -4.71308     0.51720    -4.05687    -5.71485
mean/mean                             -0.00104     0.00009    -0.00086    -0.00114
mean/std                              0.00688      0.00069    0.00794     0.00573
mean/max                              0.01532      0.00096    0.01660     0.01353
mean/min                              -0.01117     0.00128    -0.00929    -0.01319
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 8, 4, 6, 7, 9, 1, 0, 2, 5]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.1420905590057373 0.001966238021850586
train_time 1.1452593803405762
2023-09-06 13:53:37,485 MainThread INFO: EPOCH:13
2023-09-06 13:53:37,485 MainThread INFO: Time Consumed:1.1572461128234863s
2023-09-06 13:53:37,486 MainThread INFO: Total Frames:21000s
  4%|‚ñé         | 14/400 [00:17<07:57,  1.24s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1087.87098
Train_Epoch_Reward                    8337.22232
Running_Training_Average_Rewards      957.98038
Explore_Time                          0.00390
Train___Time                          1.14526
Eval____Time                          0.00313
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.72268
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.87274
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32517
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.94390
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.66185
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.13167
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.31872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11044.21980
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.52230
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.20301
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.84023      0.67538    11.19817    8.93885
alpha_0                               0.96011      0.00083    0.96141     0.95881
alpha_1                               0.96008      0.00083    0.96138     0.95878
alpha_2                               0.96012      0.00083    0.96142     0.95882
alpha_3                               0.96009      0.00083    0.96139     0.95878
alpha_4                               0.96009      0.00083    0.96139     0.95879
alpha_5                               0.96010      0.00083    0.96140     0.95880
alpha_6                               0.96010      0.00083    0.96140     0.95880
alpha_7                               0.96009      0.00083    0.96139     0.95879
alpha_8                               0.96012      0.00083    0.96142     0.95882
alpha_9                               0.96010      0.00083    0.96140     0.95880
Alpha_loss                            -0.27239     0.00575    -0.26323    -0.28124
Training/policy_loss                  -2.84793     0.00748    -2.83428    -2.86292
Training/qf1_loss                     2451.11459   453.33378  3248.37646  1739.78540
Training/qf2_loss                     2449.58191   453.25672  3246.73901  1738.29224
Training/pf_norm                      0.11853      0.01792    0.15356     0.08915
Training/qf1_norm                     39.20407     1.95755    43.50525    37.03382
Training/qf2_norm                     45.68508     2.41119    50.49467    43.34286
log_std/mean                          -0.12825     0.00105    -0.12653    -0.12977
log_std/std                           0.01018      0.00013    0.01034     0.01000
log_std/max                           -0.11089     0.00078    -0.10942    -0.11196
log_std/min                           -0.15227     0.00050    -0.15134    -0.15288
log_probs/mean                        -2.73929     0.00551    -2.72923    -2.74585
log_probs/std                         0.25309      0.01392    0.28397     0.23858
log_probs/max                         -2.09550     0.04365    -2.01080    -2.14430
log_probs/min                         -5.70646     0.65112    -4.82549    -7.07275
mean/mean                             -0.00034     0.00045    0.00028     -0.00098
mean/std                              0.00965      0.00094    0.01107     0.00822
mean/max                              0.01964      0.00170    0.02189     0.01706
mean/min                              -0.01580     0.00173    -0.01352    -0.01873
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 1, 9, 2, 5, 3, 4, 7, 8, 6]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.9624729156494141 0.0031363964080810547
train_time 0.9668121337890625
2023-09-06 13:53:38,932 MainThread INFO: EPOCH:14
2023-09-06 13:53:38,932 MainThread INFO: Time Consumed:0.97745680809021s
2023-09-06 13:53:38,933 MainThread INFO: Total Frames:22500s
  4%|‚ñç         | 15/400 [00:18<08:21,  1.30s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1068.58791
Train_Epoch_Reward                    13423.87728
Running_Training_Average_Rewards      1013.07536
Explore_Time                          0.00379
Train___Time                          0.96681
Eval____Time                          0.00295
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.86810
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.69676
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.09518
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.87875
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.18983
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.57519
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.88139
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10615.26067
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.25910
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.48467
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.69255      1.16028    11.80990    7.64629
alpha_0                               0.95723      0.00083    0.95852     0.95593
alpha_1                               0.95719      0.00083    0.95849     0.95590
alpha_2                               0.95723      0.00083    0.95853     0.95594
alpha_3                               0.95720      0.00083    0.95850     0.95590
alpha_4                               0.95720      0.00083    0.95850     0.95591
alpha_5                               0.95721      0.00083    0.95851     0.95592
alpha_6                               0.95721      0.00083    0.95851     0.95592
alpha_7                               0.95721      0.00083    0.95850     0.95591
alpha_8                               0.95723      0.00083    0.95853     0.95594
alpha_9                               0.95721      0.00083    0.95851     0.95592
Alpha_loss                            -0.29248     0.00583    -0.28341    -0.30189
Training/policy_loss                  -2.87296     0.01214    -2.85930    -2.89439
Training/qf1_loss                     2376.13411   834.30549  4081.19775  1136.10449
Training/qf2_loss                     2374.46884   834.10183  4079.19189  1134.88904
Training/pf_norm                      0.12372      0.02336    0.15700     0.07964
Training/qf1_norm                     41.11211     3.77359    47.50468    34.22817
Training/qf2_norm                     47.89539     4.80952    55.87890    39.08789
log_std/mean                          -0.13162     0.00095    -0.13011    -0.13316
log_std/std                           0.00984      0.00005    0.00994     0.00977
log_std/max                           -0.11356     0.00078    -0.11220    -0.11494
log_std/min                           -0.15337     0.00061    -0.15246    -0.15433
log_probs/mean                        -2.73463     0.00745    -2.72026    -2.74558
log_probs/std                         0.24066      0.01495    0.26576     0.22027
log_probs/max                         -2.12273     0.04954    -2.03734    -2.19120
log_probs/min                         -5.01607     0.66980    -4.24546    -6.44671
mean/mean                             0.00024      0.00017    0.00044     0.00003
mean/std                              0.01274      0.00085    0.01397     0.01133
mean/max                              0.02277      0.00041    0.02351     0.02212
mean/min                              -0.02252     0.00190    -0.01926    -0.02508
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 2, 8, 3, 1, 4, 7, 5, 0]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.9284954071044922 0.0020830631256103516
train_time 0.9318532943725586
2023-09-06 13:53:40,368 MainThread INFO: EPOCH:15
2023-09-06 13:53:40,368 MainThread INFO: Time Consumed:0.9433906078338623s
2023-09-06 13:53:40,369 MainThread INFO: Total Frames:24000s
  4%|‚ñç         | 16/400 [00:20<08:31,  1.33s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1040.19477
Train_Epoch_Reward                    10226.34557
Running_Training_Average_Rewards      1066.24817
Explore_Time                          0.00323
Train___Time                          0.93185
Eval____Time                          0.00381
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.09745
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.37526
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.96368
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57125
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.75459
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.03929
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.59150
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10278.96819
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.85092
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.73068
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.03892      1.14030    10.70141    6.87984
alpha_0                               0.95435      0.00082    0.95564     0.95306
alpha_1                               0.95432      0.00082    0.95561     0.95303
alpha_2                               0.95436      0.00082    0.95565     0.95307
alpha_3                               0.95432      0.00082    0.95561     0.95303
alpha_4                               0.95433      0.00082    0.95562     0.95304
alpha_5                               0.95434      0.00082    0.95563     0.95305
alpha_6                               0.95434      0.00082    0.95563     0.95304
alpha_7                               0.95433      0.00082    0.95562     0.95304
alpha_8                               0.95436      0.00082    0.95565     0.95307
alpha_9                               0.95434      0.00082    0.95563     0.95304
Alpha_loss                            -0.31264     0.00580    -0.30341    -0.32162
Training/policy_loss                  -2.90596     0.01211    -2.88505    -2.92134
Training/qf1_loss                     1953.40136   617.16086  2960.11768  883.83563
Training/qf2_loss                     1951.66055   616.92285  2957.90088  882.55701
Training/pf_norm                      0.12340      0.01820    0.15602     0.09004
Training/qf1_norm                     40.62511     4.34592    47.53088    32.05855
Training/qf2_norm                     47.56420     5.36614    56.32258    37.10478
log_std/mean                          -0.13475     0.00068    -0.13352    -0.13570
log_std/std                           0.00965      0.00014    0.00984     0.00942
log_std/max                           -0.11634     0.00080    -0.11494    -0.11757
log_std/min                           -0.15595     0.00063    -0.15488    -0.15672
log_probs/mean                        -2.73263     0.00611    -2.72183    -2.74227
log_probs/std                         0.23470      0.00924    0.25714     0.22352
log_probs/max                         -2.14258     0.05664    -2.03867    -2.21482
log_probs/min                         -4.87622     0.65472    -4.38485    -6.62791
mean/mean                             -0.00024     0.00029    0.00004     -0.00084
mean/std                              0.01498      0.00045    0.01557     0.01419
mean/max                              0.02376      0.00039    0.02416     0.02283
mean/min                              -0.02604     0.00029    -0.02543    -0.02646
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 1, 3, 9, 5, 2, 8, 0, 6, 7]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.221963882446289 0.001989603042602539
train_time 1.2251417636871338
2023-09-06 13:53:41,725 MainThread INFO: EPOCH:16
2023-09-06 13:53:41,726 MainThread INFO: Time Consumed:1.2359814643859863s
2023-09-06 13:53:41,726 MainThread INFO: Total Frames:25500s
  4%|‚ñç         | 17/400 [00:21<08:33,  1.34s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               991.41757
Train_Epoch_Reward                    4935.43782
Running_Training_Average_Rewards      952.85536
Explore_Time                          0.00379
Train___Time                          1.22514
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.97659
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.47090
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.38749
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.93570
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.46973
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.53918
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.32636
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9577.72854
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.22720
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.19359
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.86472     1.26970    11.30954    6.85726
alpha_0                               0.95148     0.00082    0.95277     0.95019
alpha_1                               0.95145     0.00082    0.95274     0.95017
alpha_2                               0.95149     0.00082    0.95278     0.95021
alpha_3                               0.95146     0.00082    0.95275     0.95017
alpha_4                               0.95146     0.00082    0.95275     0.95018
alpha_5                               0.95147     0.00082    0.95276     0.95019
alpha_6                               0.95147     0.00082    0.95276     0.95018
alpha_7                               0.95146     0.00082    0.95275     0.95018
alpha_8                               0.95149     0.00082    0.95278     0.95021
alpha_9                               0.95147     0.00082    0.95276     0.95019
Alpha_loss                            -0.33293    0.00575    -0.32415    -0.34211
Training/policy_loss                  -2.94704    0.01197    -2.93124    -2.96993
Training/qf1_loss                     2206.78063  970.81489  4048.61841  959.71503
Training/qf2_loss                     2204.99835  970.60871  4046.44995  958.41016
Training/pf_norm                      0.11866     0.02630    0.14714     0.08153
Training/qf1_norm                     42.72289    5.70661    53.84497    34.28643
Training/qf2_norm                     49.67621    6.52341    62.22884    39.35225
log_std/mean                          -0.13600    0.00010    -0.13582    -0.13618
log_std/std                           0.00891     0.00032    0.00937     0.00842
log_std/max                           -0.11904    0.00082    -0.11785    -0.12022
log_std/min                           -0.15591    0.00066    -0.15496    -0.15680
log_probs/mean                        -2.73343    0.00420    -2.72449    -2.74036
log_probs/std                         0.24090     0.00956    0.25795     0.22636
log_probs/max                         -2.16028    0.03514    -2.06650    -2.20118
log_probs/min                         -5.27447    0.52624    -4.30901    -6.08898
mean/mean                             -0.00203    0.00043    -0.00115    -0.00254
mean/std                              0.01562     0.00008    0.01579     0.01548
mean/max                              0.02085     0.00068    0.02228     0.02008
mean/min                              -0.02814    0.00085    -0.02666    -0.02950
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 4, 5, 6, 9, 0, 2, 3, 8, 1]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.3793647289276123 0.002047300338745117
train_time 1.3826725482940674
2023-09-06 13:53:43,238 MainThread INFO: EPOCH:17
2023-09-06 13:53:43,239 MainThread INFO: Time Consumed:1.3924314975738525s
2023-09-06 13:53:43,239 MainThread INFO: Total Frames:27000s
  4%|‚ñç         | 18/400 [00:22<08:54,  1.40s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               930.59759
Train_Epoch_Reward                    10254.70864
Running_Training_Average_Rewards      847.21640
Explore_Time                          0.00259
Train___Time                          1.38267
Eval____Time                          0.00329
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.19398
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.97707
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.68650
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.70066
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.66729
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.56123
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.49105
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8792.83271
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.08590
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.73680
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.82426      0.90756    10.10078    6.95278
alpha_0                               0.94863      0.00082    0.94991     0.94734
alpha_1                               0.94860      0.00082    0.94988     0.94731
alpha_2                               0.94864      0.00082    0.94992     0.94736
alpha_3                               0.94860      0.00082    0.94988     0.94732
alpha_4                               0.94861      0.00082    0.94989     0.94733
alpha_5                               0.94862      0.00082    0.94990     0.94734
alpha_6                               0.94861      0.00082    0.94990     0.94733
alpha_7                               0.94861      0.00082    0.94989     0.94732
alpha_8                               0.94864      0.00082    0.94992     0.94736
alpha_9                               0.94862      0.00082    0.94990     0.94733
Alpha_loss                            -0.35304     0.00584    -0.34411    -0.36213
Training/policy_loss                  -2.98999     0.01595    -2.97003    -3.01605
Training/qf1_loss                     1957.75476   577.68281  3011.46924  861.65417
Training/qf2_loss                     1955.82285   577.52277  3009.42627  860.13251
Training/pf_norm                      0.11800      0.02554    0.15012     0.07321
Training/qf1_norm                     44.92051     4.60291    51.54364    35.63662
Training/qf2_norm                     52.41581     5.30900    59.74315    41.59385
log_std/mean                          -0.13562     0.00010    -0.13550    -0.13585
log_std/std                           0.00798      0.00019    0.00835     0.00771
log_std/max                           -0.12101     0.00038    -0.12056    -0.12166
log_std/min                           -0.15467     0.00015    -0.15442    -0.15490
log_probs/mean                        -2.73089     0.00704    -2.71885    -2.74294
log_probs/std                         0.23697      0.00854    0.25477     0.22855
log_probs/max                         -2.14933     0.02903    -2.09879    -2.19942
log_probs/min                         -4.93907     0.59172    -4.24161    -6.35767
mean/mean                             -0.00287     0.00034    -0.00254    -0.00349
mean/std                              0.01611      0.00023    0.01642     0.01572
mean/max                              0.01999      0.00009    0.02012     0.01987
mean/min                              -0.03130     0.00125    -0.02951    -0.03332
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 9, 4, 1, 7, 5, 6, 3, 0, 8]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.059166431427002 0.0019524097442626953
train_time 1.0623633861541748
2023-09-06 13:53:44,804 MainThread INFO: EPOCH:18
2023-09-06 13:53:44,804 MainThread INFO: Time Consumed:1.0725374221801758s
2023-09-06 13:53:44,804 MainThread INFO: Total Frames:28500s
  5%|‚ñç         | 19/400 [00:24<09:07,  1.44s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               874.18888
Train_Epoch_Reward                    1894.85317
Running_Training_Average_Rewards      569.49999
Explore_Time                          0.00321
Train___Time                          1.06236
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.68087
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.04700
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.48163
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.55848
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.47887
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.18789
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.28481
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8593.49300
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.28821
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.75274
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.68674     0.82233    9.83549     7.53630
alpha_0                               0.94578     0.00082    0.94706     0.94450
alpha_1                               0.94575     0.00082    0.94703     0.94447
alpha_2                               0.94579     0.00082    0.94707     0.94451
alpha_3                               0.94575     0.00082    0.94703     0.94447
alpha_4                               0.94576     0.00082    0.94704     0.94448
alpha_5                               0.94577     0.00082    0.94705     0.94449
alpha_6                               0.94577     0.00082    0.94705     0.94449
alpha_7                               0.94576     0.00082    0.94704     0.94448
alpha_8                               0.94579     0.00082    0.94707     0.94451
alpha_9                               0.94577     0.00082    0.94705     0.94449
Alpha_loss                            -0.37346    0.00583    -0.36474    -0.38282
Training/policy_loss                  -3.04432    0.01677    -3.01402    -3.07408
Training/qf1_loss                     1921.75253  496.95979  2618.74219  1026.76477
Training/qf2_loss                     1919.79316  496.84057  2616.66553  1024.93384
Training/pf_norm                      0.13027     0.01435    0.14899     0.09778
Training/qf1_norm                     46.79973    3.57992    51.22077    41.40022
Training/qf2_norm                     54.36860    4.16163    59.51155    47.75903
log_std/mean                          -0.13613    0.00033    -0.13567    -0.13664
log_std/std                           0.00729     0.00022    0.00762     0.00694
log_std/max                           -0.12269    0.00068    -0.12157    -0.12362
log_std/min                           -0.15468    0.00014    -0.15451    -0.15494
log_probs/mean                        -2.73425    0.00564    -2.72398    -2.74146
log_probs/std                         0.24004     0.01145    0.26537     0.21822
log_probs/max                         -2.13589    0.03466    -2.10578    -2.22755
log_probs/min                         -5.09087    0.84719    -4.35738    -7.25582
mean/mean                             -0.00400    0.00016    -0.00367    -0.00420
mean/std                              0.01737     0.00068    0.01850     0.01650
mean/max                              0.02127     0.00131    0.02369     0.01965
mean/min                              -0.03649    0.00134    -0.03391    -0.03799
------------------------------------  ----------  ---------  ----------  ----------
sample: [6, 2, 1, 7, 4, 8, 5, 9, 3, 0]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.4125113487243652 0.0020575523376464844
train_time 1.4158384799957275
2023-09-06 13:53:46,337 MainThread INFO: EPOCH:19
2023-09-06 13:53:46,338 MainThread INFO: Time Consumed:1.4277966022491455s
2023-09-06 13:53:46,338 MainThread INFO: Total Frames:30000s
  5%|‚ñå         | 20/400 [00:25<09:18,  1.47s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               838.10828
Train_Epoch_Reward                    12304.09969
Running_Training_Average_Rewards      815.12205
Explore_Time                          0.00315
Train___Time                          1.41584
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.69372
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.95568
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.34973
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.23512
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.09853
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.68989
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.96891
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8501.71624
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.24754
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.69334
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.59231      1.05331    10.69923    7.04644
alpha_0                               0.94294      0.00081    0.94422     0.94167
alpha_1                               0.94291      0.00081    0.94419     0.94164
alpha_2                               0.94295      0.00081    0.94423     0.94168
alpha_3                               0.94291      0.00081    0.94419     0.94164
alpha_4                               0.94292      0.00081    0.94420     0.94165
alpha_5                               0.94293      0.00081    0.94421     0.94166
alpha_6                               0.94293      0.00081    0.94420     0.94166
alpha_7                               0.94292      0.00081    0.94419     0.94164
alpha_8                               0.94295      0.00081    0.94423     0.94168
alpha_9                               0.94293      0.00081    0.94421     0.94166
Alpha_loss                            -0.39364     0.00588    -0.38490    -0.40298
Training/policy_loss                  -3.10087     0.01790    -3.07705    -3.13068
Training/qf1_loss                     1772.21688   633.09202  3072.61768  901.88733
Training/qf2_loss                     1770.23285   632.86902  3070.21973  900.30127
Training/pf_norm                      0.11969      0.02395    0.16109     0.09347
Training/qf1_norm                     49.47589     4.96016    57.71529    41.46861
Training/qf2_norm                     57.09706     5.80603    67.01516    47.60500
log_std/mean                          -0.13717     0.00037    -0.13669    -0.13773
log_std/std                           0.00668      0.00012    0.00689     0.00647
log_std/max                           -0.12430     0.00057    -0.12352    -0.12513
log_std/min                           -0.15499     0.00047    -0.15441    -0.15580
log_probs/mean                        -2.73318     0.00444    -2.72464    -2.73959
log_probs/std                         0.23452      0.01207    0.25688     0.21780
log_probs/max                         -2.14354     0.03661    -2.07448    -2.19311
log_probs/min                         -5.00637     0.71781    -4.13347    -6.24118
mean/mean                             -0.00353     0.00024    -0.00303    -0.00375
mean/std                              0.01955      0.00045    0.02022     0.01874
mean/max                              0.02669      0.00115    0.02841     0.02448
mean/min                              -0.03868     0.00044    -0.03802    -0.03937
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 5, 3, 4, 7, 9, 2, 8, 0, 1]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.6814711093902588 0.0021882057189941406
train_time 1.6849365234375
2023-09-06 13:53:48,150 MainThread INFO: EPOCH:20
2023-09-06 13:53:48,150 MainThread INFO: Time Consumed:1.699401617050171s
2023-09-06 13:53:48,151 MainThread INFO: Total Frames:31500s
  5%|‚ñå         | 21/400 [00:27<09:58,  1.58s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               815.72274
Train_Epoch_Reward                    14527.07960
Running_Training_Average_Rewards      957.53442
Explore_Time                          0.00266
Train___Time                          1.68494
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.92027
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.71409
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.22530
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.18996
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.85399
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.36314
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.77394
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8111.15400
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97634
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.97094
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.60389      0.64319    9.65380     7.90250
alpha_0                               0.94011      0.00081    0.94138     0.93884
alpha_1                               0.94008      0.00081    0.94136     0.93881
alpha_2                               0.94012      0.00081    0.94139     0.93885
alpha_3                               0.94008      0.00081    0.94135     0.93881
alpha_4                               0.94009      0.00081    0.94136     0.93882
alpha_5                               0.94010      0.00081    0.94137     0.93883
alpha_6                               0.94010      0.00081    0.94137     0.93883
alpha_7                               0.94009      0.00081    0.94136     0.93882
alpha_8                               0.94012      0.00081    0.94140     0.93885
alpha_9                               0.94010      0.00081    0.94138     0.93883
Alpha_loss                            -0.41397     0.00570    -0.40565    -0.42240
Training/policy_loss                  -3.16662     0.01791    -3.13530    -3.18590
Training/qf1_loss                     1784.87908   502.67542  2691.78662  1179.42151
Training/qf2_loss                     1782.82228   502.57563  2689.89771  1177.56128
Training/pf_norm                      0.11226      0.02421    0.15779     0.07526
Training/qf1_norm                     52.55954     3.60425    58.99474    48.14203
Training/qf2_norm                     60.46340     4.08388    68.61457    56.28169
log_std/mean                          -0.13734     0.00035    -0.13671    -0.13773
log_std/std                           0.00622      0.00015    0.00648     0.00603
log_std/max                           -0.12558     0.00032    -0.12500    -0.12608
log_std/min                           -0.15463     0.00064    -0.15354    -0.15561
log_probs/mean                        -2.73473     0.00744    -2.72390    -2.74778
log_probs/std                         0.24057      0.01277    0.26267     0.22053
log_probs/max                         -2.12172     0.04547    -2.03128    -2.20626
log_probs/min                         -4.83354     0.44352    -4.19413    -5.61413
mean/mean                             -0.00183     0.00059    -0.00106    -0.00281
mean/std                              0.02080      0.00017    0.02098     0.02042
mean/max                              0.03070      0.00096    0.03184     0.02904
mean/min                              -0.03845     0.00071    -0.03736    -0.03934
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 7, 3, 9, 1, 5, 8, 0, 2, 4]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.3736402988433838 0.0019931793212890625
train_time 1.3768224716186523
2023-09-06 13:53:49,672 MainThread INFO: EPOCH:21
2023-09-06 13:53:49,672 MainThread INFO: Time Consumed:1.3877193927764893s
2023-09-06 13:53:49,673 MainThread INFO: Total Frames:33000s
  6%|‚ñå         | 22/400 [00:29<09:47,  1.56s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               788.60906
Train_Epoch_Reward                    10853.66373
Running_Training_Average_Rewards      1256.16143
Explore_Time                          0.00318
Train___Time                          1.37682
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.59655
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.58887
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.24179
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.24754
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.89788
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.36519
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.82418
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7768.14145
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.76787
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.28968
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.13701      0.97595    10.66459    7.04720
alpha_0                               0.93729      0.00081    0.93856     0.93602
alpha_1                               0.93726      0.00081    0.93853     0.93600
alpha_2                               0.93730      0.00081    0.93857     0.93603
alpha_3                               0.93726      0.00081    0.93853     0.93599
alpha_4                               0.93727      0.00081    0.93854     0.93600
alpha_5                               0.93728      0.00081    0.93855     0.93601
alpha_6                               0.93728      0.00081    0.93855     0.93602
alpha_7                               0.93727      0.00081    0.93853     0.93600
alpha_8                               0.93730      0.00081    0.93857     0.93603
alpha_9                               0.93728      0.00081    0.93855     0.93602
Alpha_loss                            -0.43410     0.00565    -0.42492    -0.44265
Training/policy_loss                  -3.23395     0.01874    -3.19875    -3.25981
Training/qf1_loss                     2124.38363   653.95404  3442.87183  795.59363
Training/qf2_loss                     2122.13192   653.66142  3440.05542  793.86145
Training/pf_norm                      0.12377      0.02065    0.16238     0.09304
Training/qf1_norm                     58.65955     6.11087    67.58180    44.56048
Training/qf2_norm                     67.32783     7.10646    78.20476    51.31459
log_std/mean                          -0.13572     0.00055    -0.13487    -0.13655
log_std/std                           0.00582      0.00011    0.00599     0.00568
log_std/max                           -0.12358     0.00080    -0.12242    -0.12487
log_std/min                           -0.15214     0.00099    -0.15080    -0.15354
log_probs/mean                        -2.73307     0.00678    -2.72439    -2.74518
log_probs/std                         0.23943      0.00988    0.25566     0.22248
log_probs/max                         -2.11915     0.04017    -2.06770    -2.19849
log_probs/min                         -5.09683     0.65702    -4.00671    -6.25710
mean/mean                             -0.00065     0.00027    -0.00021    -0.00101
mean/std                              0.02070      0.00010    0.02084     0.02057
mean/max                              0.03229      0.00047    0.03333     0.03187
mean/min                              -0.03669     0.00052    -0.03587    -0.03738
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 2, 4, 8, 0, 9, 1, 6, 7, 5]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.4938745498657227 0.0020525455474853516
train_time 1.49784517288208
2023-09-06 13:53:51,298 MainThread INFO: EPOCH:22
2023-09-06 13:53:51,299 MainThread INFO: Time Consumed:1.5120649337768555s
2023-09-06 13:53:51,300 MainThread INFO: Total Frames:34500s
  6%|‚ñå         | 23/400 [00:30<09:55,  1.58s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               765.62860
Train_Epoch_Reward                    12183.05200
Running_Training_Average_Rewards      1252.12651
Explore_Time                          0.00379
Train___Time                          1.49785
Eval____Time                          0.00369
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.70537
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.30916
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.51838
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.02712
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.96840
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.48373
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.05412
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7809.23651
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.38966
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.41041
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.30437      0.41526    8.77475     7.55331
alpha_0                               0.93448      0.00081    0.93574     0.93321
alpha_1                               0.93445      0.00081    0.93572     0.93319
alpha_2                               0.93449      0.00081    0.93575     0.93322
alpha_3                               0.93444      0.00081    0.93571     0.93318
alpha_4                               0.93446      0.00081    0.93572     0.93319
alpha_5                               0.93446      0.00081    0.93573     0.93320
alpha_6                               0.93447      0.00081    0.93573     0.93321
alpha_7                               0.93445      0.00081    0.93572     0.93319
alpha_8                               0.93449      0.00081    0.93575     0.93323
alpha_9                               0.93448      0.00081    0.93574     0.93321
Alpha_loss                            -0.45452     0.00587    -0.44549    -0.46363
Training/policy_loss                  -3.30782     0.02221    -3.27400    -3.34085
Training/qf1_loss                     1440.89090   310.85494  1789.32812  927.89435
Training/qf2_loss                     1438.95288   310.68403  1787.03931  926.32971
Training/pf_norm                      0.11237      0.00948    0.12620     0.09737
Training/qf1_norm                     57.50230     2.40002    61.52077    52.99685
Training/qf2_norm                     65.14182     2.87130    69.48183    59.50780
log_std/mean                          -0.13507     0.00020    -0.13480    -0.13535
log_std/std                           0.00553      0.00010    0.00568     0.00538
log_std/max                           -0.12238     0.00039    -0.12172    -0.12291
log_std/min                           -0.15133     0.00034    -0.15096    -0.15194
log_probs/mean                        -2.73565     0.00591    -2.72794    -2.74727
log_probs/std                         0.24613      0.01355    0.27355     0.22401
log_probs/max                         -2.11292     0.04325    -2.03380    -2.19126
log_probs/min                         -5.29365     0.72293    -4.28885    -6.63198
mean/mean                             -0.00017     0.00029    0.00016     -0.00077
mean/std                              0.02124      0.00037    0.02179     0.02065
mean/max                              0.03494      0.00061    0.03549     0.03367
mean/min                              -0.03648     0.00098    -0.03551    -0.03856
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 0, 5, 1, 7, 4, 9, 6, 8, 3]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.5063025951385498 0.002099752426147461
train_time 1.5096919536590576
2023-09-06 13:53:52,941 MainThread INFO: EPOCH:23
2023-09-06 13:53:52,942 MainThread INFO: Time Consumed:1.5191855430603027s
2023-09-06 13:53:52,942 MainThread INFO: Total Frames:36000s
  6%|‚ñå         | 24/400 [00:32<10:00,  1.60s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               759.58216
Train_Epoch_Reward                    7644.84195
Running_Training_Average_Rewards      1022.71859
Explore_Time                          0.00276
Train___Time                          1.50969
Eval____Time                          0.00282
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.07426
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.06175
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.78897
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.72242
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.02716
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.52138
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.20769
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7925.75398
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.09764
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.48000
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.13887     0.84678    9.22298     6.25520
alpha_0                               0.93168     0.00080    0.93293     0.93042
alpha_1                               0.93165     0.00080    0.93291     0.93039
alpha_2                               0.93168     0.00080    0.93294     0.93042
alpha_3                               0.93164     0.00080    0.93290     0.93038
alpha_4                               0.93165     0.00080    0.93291     0.93039
alpha_5                               0.93166     0.00080    0.93292     0.93040
alpha_6                               0.93167     0.00080    0.93293     0.93041
alpha_7                               0.93165     0.00080    0.93291     0.93039
alpha_8                               0.93169     0.00080    0.93295     0.93043
alpha_9                               0.93168     0.00080    0.93293     0.93042
Alpha_loss                            -0.47455    0.00568    -0.46551    -0.48294
Training/policy_loss                  -3.38546    0.02225    -3.34995    -3.41471
Training/qf1_loss                     1499.01558  475.65465  2216.05225  614.06757
Training/qf2_loss                     1497.08957  475.43060  2213.89062  612.65283
Training/pf_norm                      0.11624     0.00998    0.13015     0.09771
Training/qf1_norm                     59.69040    5.84009    68.35606    48.10644
Training/qf2_norm                     67.37118    6.67115    77.22472    53.94297
log_std/mean                          -0.13573    0.00019    -0.13541    -0.13606
log_std/std                           0.00515     0.00010    0.00533     0.00504
log_std/max                           -0.12403    0.00056    -0.12302    -0.12496
log_std/min                           -0.15199    0.00015    -0.15180    -0.15229
log_probs/mean                        -2.73282    0.00487    -2.72272    -2.74020
log_probs/std                         0.24213     0.01709    0.27609     0.21598
log_probs/max                         -2.10678    0.03621    -2.04468    -2.16926
log_probs/min                         -5.05222    0.70746    -4.37869    -6.67332
mean/mean                             -0.00232    0.00095    -0.00103    -0.00400
mean/std                              0.02289     0.00054    0.02383     0.02201
mean/max                              0.03480     0.00082    0.03576     0.03315
mean/min                              -0.04319    0.00275    -0.03938    -0.04792
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 9, 7, 3, 8, 2, 6, 5, 4, 0]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.6220970153808594 0.001987457275390625
train_time 1.6253166198730469
2023-09-06 13:53:54,695 MainThread INFO: EPOCH:24
2023-09-06 13:53:54,696 MainThread INFO: Time Consumed:1.6351912021636963s
2023-09-06 13:53:54,696 MainThread INFO: Total Frames:37500s
  6%|‚ñã         | 25/400 [00:34<10:18,  1.65s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               756.52417
Train_Epoch_Reward                    13749.07610
Running_Training_Average_Rewards      1119.23234
Explore_Time                          0.00331
Train___Time                          1.62532
Eval____Time                          0.00273
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.61083
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.02550
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.66068
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62866
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.72125
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.11597
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.93262
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7682.00309
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.08693
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.63841
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.16534      0.73499    9.15664     7.15705
alpha_0                               0.92888      0.00080    0.93014     0.92763
alpha_1                               0.92885      0.00080    0.93011     0.92759
alpha_2                               0.92889      0.00080    0.93014     0.92763
alpha_3                               0.92884      0.00080    0.93010     0.92759
alpha_4                               0.92886      0.00080    0.93011     0.92760
alpha_5                               0.92886      0.00080    0.93012     0.92760
alpha_6                               0.92887      0.00080    0.93013     0.92762
alpha_7                               0.92885      0.00080    0.93011     0.92759
alpha_8                               0.92889      0.00080    0.93015     0.92764
alpha_9                               0.92888      0.00080    0.93014     0.92763
Alpha_loss                            -0.49483     0.00585    -0.48571    -0.50341
Training/policy_loss                  -3.47146     0.02722    -3.42882    -3.50551
Training/qf1_loss                     1482.71620   356.65177  2048.57178  937.01721
Training/qf2_loss                     1480.96574   356.48706  2046.47168  935.49719
Training/pf_norm                      0.12185      0.01527    0.14354     0.09413
Training/qf1_norm                     62.97130     4.95063    70.86079    56.50311
Training/qf2_norm                     70.31526     5.59225    78.64851    62.99704
log_std/mean                          -0.13731     0.00079    -0.13614    -0.13845
log_std/std                           0.00529      0.00021    0.00563     0.00504
log_std/max                           -0.12600     0.00104    -0.12441    -0.12760
log_std/min                           -0.15427     0.00143    -0.15244    -0.15640
log_probs/mean                        -2.73345     0.00717    -2.72636    -2.74967
log_probs/std                         0.24670      0.01200    0.26358     0.22829
log_probs/max                         -2.10102     0.04205    -2.01089    -2.16452
log_probs/min                         -5.21973     0.44658    -4.58072    -6.10905
mean/mean                             -0.00560     0.00070    -0.00437    -0.00656
mean/std                              0.02569      0.00105    0.02737     0.02407
mean/max                              0.03330      0.00031    0.03403     0.03293
mean/min                              -0.05410     0.00318    -0.04911    -0.05884
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 7, 5, 9, 2, 3, 4, 1, 0, 8]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.5961594581604004 0.004194498062133789
train_time 1.601989984512329
2023-09-06 13:53:56,439 MainThread INFO: EPOCH:25
2023-09-06 13:53:56,440 MainThread INFO: Time Consumed:1.6124074459075928s
2023-09-06 13:53:56,440 MainThread INFO: Total Frames:39000s
  6%|‚ñã         | 26/400 [00:36<10:28,  1.68s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               739.41241
Train_Epoch_Reward                    8357.69637
Running_Training_Average_Rewards      991.72048
Explore_Time                          0.00359
Train___Time                          1.60199
Eval____Time                          0.00274
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.58869
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.46609
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.06761
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70020
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.88552
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -16.06391
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.19404
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7293.40969
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.73652
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.68972
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.56824     0.79702    10.42497    7.25208
alpha_0                               0.92609     0.00080    0.92735     0.92484
alpha_1                               0.92606     0.00080    0.92732     0.92481
alpha_2                               0.92610     0.00080    0.92735     0.92485
alpha_3                               0.92606     0.00080    0.92731     0.92481
alpha_4                               0.92607     0.00080    0.92732     0.92482
alpha_5                               0.92607     0.00080    0.92733     0.92482
alpha_6                               0.92609     0.00080    0.92734     0.92484
alpha_7                               0.92606     0.00080    0.92731     0.92481
alpha_8                               0.92611     0.00080    0.92736     0.92486
alpha_9                               0.92610     0.00080    0.92735     0.92485
Alpha_loss                            -0.51523    0.00591    -0.50594    -0.52446
Training/policy_loss                  -3.56650    0.02843    -3.52471    -3.60791
Training/qf1_loss                     1711.06835  587.20206  3233.78296  1069.70886
Training/qf2_loss                     1709.37684  587.16947  3232.19775  1068.26538
Training/pf_norm                      0.12580     0.02684    0.16899     0.09201
Training/qf1_norm                     69.69132    6.25364    84.95885    61.32441
Training/qf2_norm                     77.16588    6.59520    92.92937    67.76290
log_std/mean                          -0.13850    0.00018    -0.13805    -0.13867
log_std/std                           0.00575     0.00005    0.00582     0.00562
log_std/max                           -0.12760    0.00048    -0.12672    -0.12817
log_std/min                           -0.15639    0.00032    -0.15578    -0.15681
log_probs/mean                        -2.73558    0.00369    -2.73049    -2.74262
log_probs/std                         0.24352     0.01570    0.28036     0.21965
log_probs/max                         -2.08479    0.02716    -2.06035    -2.15857
log_probs/min                         -5.28035    0.77804    -4.14575    -6.90147
mean/mean                             -0.00779    0.00065    -0.00675    -0.00875
mean/std                              0.02956     0.00118    0.03133     0.02775
mean/max                              0.03555     0.00069    0.03671     0.03465
mean/min                              -0.06428    0.00309    -0.05912    -0.06889
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 1, 9, 5, 8, 3, 7, 4, 6, 2]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.1227500438690186 0.0020263195037841797
train_time 1.1259706020355225
2023-09-06 13:53:58,191 MainThread INFO: EPOCH:26
2023-09-06 13:53:58,191 MainThread INFO: Time Consumed:1.1381556987762451s
2023-09-06 13:53:58,192 MainThread INFO: Total Frames:40500s
  7%|‚ñã         | 27/400 [00:37<10:30,  1.69s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               693.51801
Train_Epoch_Reward                    3256.55662
Running_Training_Average_Rewards      845.44430
Explore_Time                          0.00458
Train___Time                          1.12597
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.00725
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.80381
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.60129
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.91156
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.14054
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -15.01603
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.48417
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6547.26493
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.29238
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.06734
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.21268     0.68826    9.62233     7.24311
alpha_0                               0.92331     0.00080    0.92456     0.92207
alpha_1                               0.92328     0.00080    0.92453     0.92203
alpha_2                               0.92332     0.00080    0.92457     0.92207
alpha_3                               0.92328     0.00080    0.92453     0.92203
alpha_4                               0.92329     0.00080    0.92454     0.92204
alpha_5                               0.92329     0.00080    0.92454     0.92205
alpha_6                               0.92332     0.00080    0.92456     0.92207
alpha_7                               0.92329     0.00080    0.92453     0.92204
alpha_8                               0.92333     0.00080    0.92458     0.92208
alpha_9                               0.92332     0.00080    0.92457     0.92207
Alpha_loss                            -0.53490    0.00561    -0.52593    -0.54325
Training/policy_loss                  -3.65714    0.02844    -3.60976    -3.69674
Training/qf1_loss                     1465.19517  388.96438  2075.77563  785.59241
Training/qf2_loss                     1463.72263  388.71322  2073.81958  784.36169
Training/pf_norm                      0.11780     0.03289    0.18514     0.07903
Training/qf1_norm                     71.35226    6.06709    84.17100    64.04111
Training/qf2_norm                     78.29126    6.91280    92.88347    70.04937
log_std/mean                          -0.13790    0.00022    -0.13764    -0.13830
log_std/std                           0.00567     0.00007    0.00578     0.00555
log_std/max                           -0.12654    0.00019    -0.12621    -0.12690
log_std/min                           -0.15443    0.00035    -0.15396    -0.15505
log_probs/mean                        -2.72861    0.00689    -2.71936    -2.74078
log_probs/std                         0.24230     0.01391    0.26410     0.22624
log_probs/max                         -2.06867    0.05304    -1.98502    -2.17114
log_probs/min                         -4.99860    0.68940    -4.23705    -6.22861
mean/mean                             -0.00966    0.00050    -0.00892    -0.01055
mean/std                              0.03381     0.00125    0.03548     0.03172
mean/max                              0.03980     0.00159    0.04164     0.03695
mean/min                              -0.07413    0.00267    -0.06979    -0.07798
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 9, 1, 7, 3, 4, 6, 2, 0, 8]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.7233355045318604 0.002086162567138672
train_time 1.7266898155212402
2023-09-06 13:54:00,035 MainThread INFO: EPOCH:27
2023-09-06 13:54:00,035 MainThread INFO: Time Consumed:1.7360095977783203s
2023-09-06 13:54:00,036 MainThread INFO: Total Frames:42000s
  7%|‚ñã         | 28/400 [00:39<10:45,  1.74s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               631.97933
Train_Epoch_Reward                    22376.48278
Running_Training_Average_Rewards      1133.02453
Explore_Time                          0.00265
Train___Time                          1.72669
Eval____Time                          0.00263
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.89051
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.87637
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.34634
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04681
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.37948
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.09949
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.81429
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5830.08485
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.61825
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.59138
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.10687      0.80598    9.68057     6.94266
alpha_0                               0.92054      0.00079    0.92179     0.91930
alpha_1                               0.92051      0.00079    0.92175     0.91927
alpha_2                               0.92055      0.00079    0.92180     0.91931
alpha_3                               0.92051      0.00079    0.92176     0.91927
alpha_4                               0.92052      0.00079    0.92177     0.91928
alpha_5                               0.92052      0.00079    0.92177     0.91928
alpha_6                               0.92055      0.00079    0.92179     0.91931
alpha_7                               0.92052      0.00079    0.92176     0.91928
alpha_8                               0.92056      0.00079    0.92181     0.91932
alpha_9                               0.92056      0.00079    0.92180     0.91931
Alpha_loss                            -0.55554     0.00584    -0.54628    -0.56490
Training/policy_loss                  -3.75927     0.02859    -3.71768    -3.80617
Training/qf1_loss                     1547.38326   446.32010  2448.42407  864.59503
Training/qf2_loss                     1546.15556   446.15960  2447.03345  863.67889
Training/pf_norm                      0.13909      0.02692    0.20055     0.10794
Training/qf1_norm                     73.51743     6.58557    87.91636    63.53421
Training/qf2_norm                     80.05360     7.26155    95.48841    68.82268
log_std/mean                          -0.13848     0.00009    -0.13832    -0.13859
log_std/std                           0.00530      0.00013    0.00548     0.00504
log_std/max                           -0.12673     0.00034    -0.12626    -0.12723
log_std/min                           -0.15284     0.00078    -0.15144    -0.15383
log_probs/mean                        -2.73372     0.00581    -2.72470    -2.74247
log_probs/std                         0.25109      0.00870    0.27207     0.23941
log_probs/max                         -2.05725     0.05538    -1.96328    -2.14111
log_probs/min                         -4.99997     0.39328    -4.35239    -5.71632
mean/mean                             -0.01167     0.00049    -0.01077    -0.01226
mean/std                              0.03671      0.00081    0.03808     0.03562
mean/max                              0.04223      0.00055    0.04300     0.04120
mean/min                              -0.08068     0.00164    -0.07803    -0.08330
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 7, 1, 6, 8, 5, 3, 9, 4, 0]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.66025710105896 0.0021364688873291016
train_time 1.6636600494384766
2023-09-06 13:54:01,811 MainThread INFO: EPOCH:28
2023-09-06 13:54:01,812 MainThread INFO: Time Consumed:1.6737234592437744s
2023-09-06 13:54:01,812 MainThread INFO: Total Frames:43500s
  7%|‚ñã         | 29/400 [00:41<10:49,  1.75s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               560.23768
Train_Epoch_Reward                    12366.97057
Running_Training_Average_Rewards      1266.66700
Explore_Time                          0.00293
Train___Time                          1.66366
Eval____Time                          0.00324
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.70449
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.93651
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.13172
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.32859
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.79840
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -13.52631
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.44837
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5146.89204
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.03467
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.21498
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.00816      0.69843    9.14474     6.64349
alpha_0                               0.91778      0.00079    0.91902     0.91654
alpha_1                               0.91775      0.00079    0.91899     0.91651
alpha_2                               0.91779      0.00079    0.91903     0.91655
alpha_3                               0.91775      0.00079    0.91899     0.91651
alpha_4                               0.91776      0.00079    0.91900     0.91652
alpha_5                               0.91776      0.00079    0.91900     0.91652
alpha_6                               0.91779      0.00079    0.91903     0.91655
alpha_7                               0.91776      0.00079    0.91900     0.91652
alpha_8                               0.91780      0.00079    0.91904     0.91656
alpha_9                               0.91780      0.00079    0.91904     0.91656
Alpha_loss                            -0.57532     0.00581    -0.56664    -0.58469
Training/policy_loss                  -3.85873     0.03221    -3.81592    -3.91791
Training/qf1_loss                     1532.15024   455.71642  2136.72461  705.09192
Training/qf2_loss                     1531.25796   455.63516  2135.68896  704.34509
Training/pf_norm                      0.11927      0.01935    0.14846     0.09516
Training/qf1_norm                     77.29857     6.14014    86.53033    64.37975
Training/qf2_norm                     83.23553     6.62962    93.09891    69.40648
log_std/mean                          -0.13802     0.00027    -0.13742    -0.13831
log_std/std                           0.00469      0.00022    0.00505     0.00438
log_std/max                           -0.12741     0.00037    -0.12690    -0.12809
log_std/min                           -0.15007     0.00088    -0.14845    -0.15130
log_probs/mean                        -2.72861     0.00605    -2.71728    -2.73615
log_probs/std                         0.24490      0.01468    0.27785     0.22329
log_probs/max                         -2.05067     0.02686    -2.00651    -2.10268
log_probs/min                         -4.75846     0.52547    -4.02971    -5.64155
mean/mean                             -0.01206     0.00008    -0.01196    -0.01220
mean/std                              0.04042      0.00114    0.04206     0.03851
mean/max                              0.04585      0.00128    0.04752     0.04379
mean/min                              -0.08678     0.00180    -0.08419    -0.08962
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 6, 9, 1, 4, 7, 0, 5, 8, 2]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.8150064945220947 0.0019881725311279297
train_time 1.8182008266448975
2023-09-06 13:54:03,749 MainThread INFO: EPOCH:29
2023-09-06 13:54:03,750 MainThread INFO: Time Consumed:1.8277406692504883s
2023-09-06 13:54:03,750 MainThread INFO: Total Frames:45000s
  8%|‚ñä         | 30/400 [00:43<11:08,  1.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               497.43648
Train_Epoch_Reward                    2647.48519
Running_Training_Average_Rewards      1246.36462
Explore_Time                          0.00271
Train___Time                          1.81820
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.11536
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.15839
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.78993
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.81360
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.97171
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -13.87224
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.15872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4669.92502
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.46811
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.67254
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.17169     0.87463    9.55129     6.59011
alpha_0                               0.91503     0.00079    0.91627     0.91380
alpha_1                               0.91500     0.00079    0.91624     0.91377
alpha_2                               0.91504     0.00079    0.91627     0.91380
alpha_3                               0.91500     0.00079    0.91623     0.91376
alpha_4                               0.91501     0.00079    0.91625     0.91377
alpha_5                               0.91501     0.00079    0.91625     0.91378
alpha_6                               0.91504     0.00079    0.91627     0.91380
alpha_7                               0.91501     0.00079    0.91624     0.91377
alpha_8                               0.91505     0.00079    0.91629     0.91382
alpha_9                               0.91505     0.00079    0.91628     0.91381
Alpha_loss                            -0.59528    0.00578    -0.58573    -0.60492
Training/policy_loss                  -3.96514    0.03023    -3.91173    -4.01561
Training/qf1_loss                     1417.54244  388.60960  2243.84937  762.98962
Training/qf2_loss                     1416.80357  388.51010  2242.89209  762.38898
Training/pf_norm                      0.10923     0.02718    0.16466     0.06995
Training/qf1_norm                     82.84844    8.52614    97.40448    67.55496
Training/qf2_norm                     88.70214    9.18062    104.43415   72.11784
log_std/mean                          -0.13666    0.00030    -0.13628    -0.13716
log_std/std                           0.00436     0.00006    0.00448     0.00429
log_std/max                           -0.12610    0.00061    -0.12541    -0.12752
log_std/min                           -0.14655    0.00054    -0.14604    -0.14769
log_probs/mean                        -2.72586    0.00649    -2.71394    -2.73437
log_probs/std                         0.24468     0.01261    0.26165     0.22473
log_probs/max                         -2.01292    0.06325    -1.84492    -2.09914
log_probs/min                         -4.59117    0.36177    -4.26754    -5.42568
mean/mean                             -0.01212    0.00003    -0.01207    -0.01215
mean/std                              0.04272     0.00039    0.04344     0.04219
mean/max                              0.04651     0.00032    0.04695     0.04601
mean/min                              -0.09162    0.00132    -0.08978    -0.09388
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 5, 1, 4, 6, 8, 3, 7, 9]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.791203498840332 0.002462625503540039
train_time 1.7949192523956299
2023-09-06 13:54:05,669 MainThread INFO: EPOCH:30
2023-09-06 13:54:05,669 MainThread INFO: Time Consumed:1.8051912784576416s
2023-09-06 13:54:05,669 MainThread INFO: Total Frames:46500s
  8%|‚ñä         | 31/400 [00:45<11:19,  1.84s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               446.86783
Train_Epoch_Reward                    8942.63313
Running_Training_Average_Rewards      798.56963
Explore_Time                          0.00298
Train___Time                          1.79492
Eval____Time                          0.00330
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.19960
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.09652
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.69403
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.01340
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24081
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.16099
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.94931
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4318.34800
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.53734
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.09340
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.60378     0.73831    9.64322     7.14228
alpha_0                               0.91229     0.00079    0.91352     0.91106
alpha_1                               0.91226     0.00079    0.91349     0.91103
alpha_2                               0.91229     0.00079    0.91353     0.91106
alpha_3                               0.91226     0.00079    0.91349     0.91103
alpha_4                               0.91227     0.00079    0.91350     0.91104
alpha_5                               0.91227     0.00079    0.91350     0.91104
alpha_6                               0.91229     0.00079    0.91353     0.91106
alpha_7                               0.91227     0.00079    0.91350     0.91103
alpha_8                               0.91231     0.00079    0.91354     0.91108
alpha_9                               0.91231     0.00079    0.91354     0.91107
Alpha_loss                            -0.61571    0.00620    -0.60556    -0.62534
Training/policy_loss                  -4.07693    0.03493    -4.01902    -4.13198
Training/qf1_loss                     1725.01653  384.20809  2338.82031  816.57123
Training/qf2_loss                     1724.46177  384.09889  2338.23926  816.29999
Training/pf_norm                      0.11930     0.02112    0.16045     0.09490
Training/qf1_norm                     90.30604    7.50585    98.39955    74.78751
Training/qf2_norm                     96.21219    8.10991    104.82709   79.30429
log_std/mean                          -0.13811    0.00051    -0.13724    -0.13861
log_std/std                           0.00464     0.00007    0.00471     0.00451
log_std/max                           -0.12692    0.00067    -0.12588    -0.12760
log_std/min                           -0.14838    0.00094    -0.14674    -0.14947
log_probs/mean                        -2.72856    0.00708    -2.71681    -2.73834
log_probs/std                         0.25438     0.01045    0.27185     0.23911
log_probs/max                         -2.02443    0.05607    -1.93064    -2.12895
log_probs/min                         -4.92187    0.41486    -4.21385    -5.78831
mean/mean                             -0.01193    0.00021    -0.01161    -0.01219
mean/std                              0.04461     0.00057    0.04551     0.04368
mean/max                              0.04648     0.00024    0.04702     0.04609
mean/min                              -0.09692    0.00151    -0.09441    -0.09933
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 7, 1, 3, 0, 8, 2, 5, 4, 9]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.7294251918792725 0.0019941329956054688
train_time 1.7326345443725586
2023-09-06 13:54:07,530 MainThread INFO: EPOCH:31
2023-09-06 13:54:07,530 MainThread INFO: Time Consumed:1.7448744773864746s
2023-09-06 13:54:07,531 MainThread INFO: Total Frames:48000s
  8%|‚ñä         | 32/400 [00:47<11:19,  1.85s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               416.94804
Train_Epoch_Reward                    13210.04879
Running_Training_Average_Rewards      826.67224
Explore_Time                          0.00317
Train___Time                          1.73263
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.00551
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.13939
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.37611
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.85644
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.54093
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -16.67865
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.61604
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4254.96181
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.64199
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.93246
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.46230      0.72577    9.34106     7.04367
alpha_0                               0.90956      0.00078    0.91079     0.90833
alpha_1                               0.90952      0.00078    0.91075     0.90830
alpha_2                               0.90956      0.00078    0.91079     0.90833
alpha_3                               0.90953      0.00078    0.91076     0.90830
alpha_4                               0.90954      0.00078    0.91076     0.90831
alpha_5                               0.90953      0.00078    0.91076     0.90831
alpha_6                               0.90956      0.00078    0.91079     0.90833
alpha_7                               0.90953      0.00078    0.91076     0.90830
alpha_8                               0.90958      0.00078    0.91081     0.90835
alpha_9                               0.90957      0.00078    0.91080     0.90834
Alpha_loss                            -0.63608     0.00581    -0.62741    -0.64517
Training/policy_loss                  -4.18646     0.03192    -4.14271    -4.23609
Training/qf1_loss                     1674.21832   408.28652  2294.44409  864.17108
Training/qf2_loss                     1674.04030   408.26517  2294.66479  864.31915
Training/pf_norm                      0.10931      0.01473    0.13135     0.08189
Training/qf1_norm                     93.58124     6.79112    101.47367   80.92059
Training/qf2_norm                     98.85041     7.19306    107.47006   85.49428
log_std/mean                          -0.13825     0.00022    -0.13784    -0.13855
log_std/std                           0.00450      0.00007    0.00464     0.00440
log_std/max                           -0.12800     0.00027    -0.12769    -0.12854
log_std/min                           -0.14922     0.00015    -0.14902    -0.14944
log_probs/mean                        -2.73039     0.00607    -2.72044    -2.74022
log_probs/std                         0.25793      0.02003    0.28245     0.22846
log_probs/max                         -2.00729     0.05298    -1.87924    -2.05585
log_probs/min                         -5.10608     0.74967    -4.00674    -6.50583
mean/mean                             -0.01209     0.00035    -0.01162    -0.01276
mean/std                              0.04681      0.00073    0.04792     0.04571
mean/max                              0.04758      0.00032    0.04807     0.04704
mean/min                              -0.10276     0.00188    -0.09971    -0.10580
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 0, 1, 5, 7, 6, 8, 3, 2, 4]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.8360562324523926 0.0019712448120117188
train_time 1.8392891883850098
2023-09-06 13:54:09,490 MainThread INFO: EPOCH:32
2023-09-06 13:54:09,491 MainThread INFO: Time Consumed:1.8504869937896729s
2023-09-06 13:54:09,491 MainThread INFO: Total Frames:49500s
  8%|‚ñä         | 33/400 [00:49<11:30,  1.88s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               405.20639
Train_Epoch_Reward                    16498.81029
Running_Training_Average_Rewards      1288.38307
Explore_Time                          0.00293
Train___Time                          1.83929
Eval____Time                          0.00423
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.54173
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.78474
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.61596
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.40424
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44147
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.29191
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.09245
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4314.03130
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.48636
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.71758
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.98807      0.94976    9.29914     6.51579
alpha_0                               0.90683      0.00078    0.90806     0.90561
alpha_1                               0.90680      0.00078    0.90802     0.90557
alpha_2                               0.90683      0.00078    0.90806     0.90560
alpha_3                               0.90681      0.00078    0.90803     0.90558
alpha_4                               0.90681      0.00078    0.90804     0.90559
alpha_5                               0.90681      0.00078    0.90803     0.90558
alpha_6                               0.90683      0.00078    0.90806     0.90561
alpha_7                               0.90681      0.00078    0.90803     0.90558
alpha_8                               0.90685      0.00078    0.90808     0.90562
alpha_9                               0.90684      0.00078    0.90807     0.90562
Alpha_loss                            -0.65590     0.00579    -0.64646    -0.66437
Training/policy_loss                  -4.29610     0.03079    -4.24260    -4.34294
Training/qf1_loss                     1588.23954   555.94484  2351.36450  764.29102
Training/qf2_loss                     1588.44302   555.94650  2351.41479  764.73633
Training/pf_norm                      0.11632      0.02463    0.16031     0.08103
Training/qf1_norm                     93.26614     10.62684   110.03946   78.72046
Training/qf2_norm                     97.79763     11.01602   114.71842   82.11332
log_std/mean                          -0.13743     0.00017    -0.13718    -0.13773
log_std/std                           0.00445      0.00005    0.00452     0.00436
log_std/max                           -0.12743     0.00046    -0.12677    -0.12823
log_std/min                           -0.14857     0.00022    -0.14821    -0.14900
log_probs/mean                        -2.72650     0.00533    -2.72018    -2.73549
log_probs/std                         0.25785      0.00740    0.26628     0.24241
log_probs/max                         -2.04119     0.03932    -1.95558    -2.10832
log_probs/min                         -4.80909     0.37508    -4.19957    -5.45161
mean/mean                             -0.01348     0.00036    -0.01291    -0.01407
mean/std                              0.04900      0.00052    0.04983     0.04814
mean/max                              0.04931      0.00081    0.05046     0.04788
mean/min                              -0.10863     0.00183    -0.10580    -0.11158
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 9, 0, 1, 4, 2, 7, 3, 6, 8]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.078282117843628 0.0021696090698242188
train_time 2.081756830215454
2023-09-06 13:54:11,700 MainThread INFO: EPOCH:33
2023-09-06 13:54:11,700 MainThread INFO: Time Consumed:2.094928026199341s
2023-09-06 13:54:11,701 MainThread INFO: Total Frames:51000s
  8%|‚ñä         | 34/400 [00:51<12:06,  1.98s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               401.32566
Train_Epoch_Reward                    3255.85865
Running_Training_Average_Rewards      1098.82392
Explore_Time                          0.00486
Train___Time                          2.08176
Eval____Time                          0.00419
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.92854
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.86895
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.66338
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.48592
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.83696
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -13.21443
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.63062
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4201.28594
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.85371
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.86272
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.65288     0.64379    8.49403     6.44481
alpha_0                               0.90412     0.00078    0.90534     0.90290
alpha_1                               0.90408     0.00078    0.90530     0.90286
alpha_2                               0.90411     0.00078    0.90533     0.90289
alpha_3                               0.90409     0.00078    0.90531     0.90287
alpha_4                               0.90410     0.00078    0.90532     0.90288
alpha_5                               0.90409     0.00078    0.90531     0.90287
alpha_6                               0.90411     0.00078    0.90533     0.90289
alpha_7                               0.90409     0.00078    0.90531     0.90286
alpha_8                               0.90413     0.00078    0.90535     0.90291
alpha_9                               0.90413     0.00078    0.90535     0.90291
Alpha_loss                            -0.67601    0.00572    -0.66671    -0.68463
Training/policy_loss                  -4.40950    0.03413    -4.35499    -4.46064
Training/qf1_loss                     1299.47686  380.51488  1728.40894  724.21466
Training/qf2_loss                     1300.11778  380.61228  1728.92908  724.67316
Training/pf_norm                      0.10050     0.02063    0.14757     0.07203
Training/qf1_norm                     93.35188    7.31966    103.82005   78.85831
Training/qf2_norm                     97.14647    7.42545    107.66918   82.31609
log_std/mean                          -0.13882    0.00062    -0.13779    -0.13967
log_std/std                           0.00460     0.00005    0.00465     0.00452
log_std/max                           -0.12834    0.00038    -0.12758    -0.12890
log_std/min                           -0.14971    0.00098    -0.14863    -0.15170
log_probs/mean                        -2.72571    0.00564    -2.71910    -2.73659
log_probs/std                         0.26196     0.00721    0.27296     0.24974
log_probs/max                         -1.98644    0.04382    -1.93972    -2.10196
log_probs/min                         -5.19755    0.60056    -4.43289    -6.37764
mean/mean                             -0.01491    0.00042    -0.01420    -0.01546
mean/std                              0.05119     0.00078    0.05244     0.05002
mean/max                              0.05223     0.00106    0.05378     0.05058
mean/min                              -0.11486    0.00190    -0.11189    -0.11811
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 7, 0, 3, 8, 9, 4, 6, 5, 2]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.9460573196411133 0.003016948699951172
train_time 1.9510431289672852
2023-09-06 13:54:13,792 MainThread INFO: EPOCH:34
2023-09-06 13:54:13,793 MainThread INFO: Time Consumed:1.9644103050231934s
2023-09-06 13:54:13,793 MainThread INFO: Total Frames:52500s
  9%|‚ñâ         | 35/400 [00:53<12:16,  2.02s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               395.88612
Train_Epoch_Reward                    1600.92109
Running_Training_Average_Rewards      711.85300
Explore_Time                          0.00344
Train___Time                          1.95104
Eval____Time                          0.00461
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.98798
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.84036
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.76999
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.56061
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.60214
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.49165
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.30394
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4079.55240
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.02074
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.98701
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.79465     0.59983    8.54582     6.46688
alpha_0                               0.90141     0.00078    0.90263     0.90019
alpha_1                               0.90137     0.00078    0.90259     0.90015
alpha_2                               0.90140     0.00078    0.90262     0.90018
alpha_3                               0.90138     0.00078    0.90260     0.90016
alpha_4                               0.90139     0.00078    0.90261     0.90018
alpha_5                               0.90138     0.00078    0.90260     0.90017
alpha_6                               0.90140     0.00078    0.90262     0.90019
alpha_7                               0.90138     0.00078    0.90259     0.90016
alpha_8                               0.90142     0.00078    0.90264     0.90021
alpha_9                               0.90142     0.00078    0.90263     0.90020
Alpha_loss                            -0.69641    0.00550    -0.68708    -0.70368
Training/policy_loss                  -4.52676    0.03359    -4.47264    -4.56847
Training/qf1_loss                     1301.77058  307.76199  1651.54431  702.85632
Training/qf2_loss                     1302.78115  307.74284  1652.40063  703.96057
Training/pf_norm                      0.12037     0.02028    0.15443     0.07537
Training/qf1_norm                     99.02663    7.20355    109.83360   84.62028
Training/qf2_norm                     102.38868   7.50775    113.27258   87.29864
log_std/mean                          -0.14015    0.00024    -0.13972    -0.14041
log_std/std                           0.00480     0.00010    0.00492     0.00463
log_std/max                           -0.12903    0.00042    -0.12854    -0.12974
log_std/min                           -0.15266    0.00126    -0.15029    -0.15456
log_probs/mean                        -2.72790    0.00730    -2.71056    -2.73805
log_probs/std                         0.26654     0.01362    0.29034     0.24388
log_probs/max                         -1.96207    0.03182    -1.91468    -2.02920
log_probs/min                         -5.17437    0.62289    -4.34362    -6.13408
mean/mean                             -0.01558    0.00004    -0.01552    -0.01566
mean/std                              0.05412     0.00099    0.05551     0.05265
mean/max                              0.05562     0.00106    0.05700     0.05397
mean/min                              -0.12163    0.00206    -0.11865    -0.12451
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 2, 4, 5, 7, 6, 8, 1, 9, 0]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.2235984802246094 0.002628326416015625
train_time 1.2278826236724854
2023-09-06 13:54:15,786 MainThread INFO: EPOCH:35
2023-09-06 13:54:15,786 MainThread INFO: Time Consumed:1.3080711364746094s
2023-09-06 13:54:15,787 MainThread INFO: Total Frames:54000s
  9%|‚ñâ         | 36/400 [00:55<12:11,  2.01s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               383.36527
Train_Epoch_Reward                    4768.09433
Running_Training_Average_Rewards      320.82914
Explore_Time                          0.07121
Train___Time                          1.22788
Eval____Time                          0.00454
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.86534
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.67298
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.90320
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.53580
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.48148
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.98073
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.92359
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3937.62278
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.05533
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.17497
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.10777     0.76932    9.77135     7.15850
alpha_0                               0.89871     0.00077    0.89992     0.89750
alpha_1                               0.89867     0.00078    0.89988     0.89745
alpha_2                               0.89870     0.00077    0.89991     0.89749
alpha_3                               0.89868     0.00077    0.89989     0.89746
alpha_4                               0.89869     0.00077    0.89991     0.89748
alpha_5                               0.89868     0.00077    0.89990     0.89747
alpha_6                               0.89870     0.00077    0.89992     0.89749
alpha_7                               0.89868     0.00077    0.89989     0.89746
alpha_8                               0.89872     0.00077    0.89994     0.89751
alpha_9                               0.89871     0.00078    0.89993     0.89750
Alpha_loss                            -0.71642    0.00589    -0.70664    -0.72583
Training/policy_loss                  -4.64048    0.03412    -4.58583    -4.69411
Training/qf1_loss                     1495.60936  509.48514  2530.70435  858.81409
Training/qf2_loss                     1496.92166  509.49416  2531.97803  860.03357
Training/pf_norm                      0.11549     0.02657    0.17075     0.06942
Training/qf1_norm                     107.46593   8.96366    126.30885   97.34238
Training/qf2_norm                     110.71848   9.34497    130.27007   100.25444
log_std/mean                          -0.13941    0.00041    -0.13886    -0.14008
log_std/std                           0.00496     0.00004    0.00502     0.00489
log_std/max                           -0.12859    0.00031    -0.12818    -0.12908
log_std/min                           -0.15335    0.00065    -0.15223    -0.15419
log_probs/mean                        -2.72618    0.00426    -2.71955    -2.73283
log_probs/std                         0.26141     0.00693    0.27601     0.25352
log_probs/max                         -1.98392    0.03936    -1.93534    -2.04050
log_probs/min                         -4.84402    0.44115    -4.41326    -5.67538
mean/mean                             -0.01529    0.00020    -0.01491    -0.01548
mean/std                              0.05666     0.00080    0.05796     0.05559
mean/max                              0.05767     0.00089    0.05936     0.05647
mean/min                              -0.12687    0.00158    -0.12475    -0.12944
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 2, 3, 1, 5, 0, 7, 8, 9, 4]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.3376760482788086 0.001986980438232422
train_time 1.3408875465393066
2023-09-06 13:54:17,902 MainThread INFO: EPOCH:36
2023-09-06 13:54:17,902 MainThread INFO: Time Consumed:1.47049880027771s
2023-09-06 13:54:17,902 MainThread INFO: Total Frames:55500s
  9%|‚ñâ         | 37/400 [00:57<12:19,  2.04s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               370.16664
Train_Epoch_Reward                    20427.76521
Running_Training_Average_Rewards      893.22602
Explore_Time                          0.12122
Train___Time                          1.34089
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.48635
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.47399
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.99501
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.56039
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.19390
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.50743
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.78601
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3811.40326
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.09936
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.31893
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.03564      0.62779    8.85687     6.68939
alpha_0                               0.89602      0.00077    0.89723     0.89481
alpha_1                               0.89597      0.00077    0.89718     0.89476
alpha_2                               0.89601      0.00077    0.89722     0.89480
alpha_3                               0.89598      0.00077    0.89719     0.89477
alpha_4                               0.89600      0.00077    0.89721     0.89480
alpha_5                               0.89599      0.00077    0.89720     0.89478
alpha_6                               0.89601      0.00077    0.89722     0.89480
alpha_7                               0.89598      0.00077    0.89719     0.89478
alpha_8                               0.89603      0.00077    0.89724     0.89482
alpha_9                               0.89602      0.00077    0.89723     0.89481
Alpha_loss                            -0.73634     0.00541    -0.72753    -0.74501
Training/policy_loss                  -4.75877     0.03066    -4.70580    -4.80669
Training/qf1_loss                     1396.39995   323.92078  1815.05139  768.84637
Training/qf2_loss                     1398.09031   324.10508  1817.21216  770.27020
Training/pf_norm                      0.11258      0.01965    0.14772     0.08252
Training/qf1_norm                     109.93573    9.32127    121.41507   90.42686
Training/qf2_norm                     112.75884    9.39321    123.94890   92.87495
log_std/mean                          -0.13828     0.00017    -0.13814    -0.13865
log_std/std                           0.00480      0.00008    0.00494     0.00463
log_std/max                           -0.12813     0.00035    -0.12765    -0.12878
log_std/min                           -0.15124     0.00087    -0.14945    -0.15288
log_probs/mean                        -2.72381     0.00748    -2.70584    -2.73351
log_probs/std                         0.27456      0.01757    0.31637     0.25100
log_probs/max                         -1.94659     0.05268    -1.88309    -2.06112
log_probs/min                         -4.88779     1.00643    -4.17135    -7.69421
mean/mean                             -0.01493     0.00017    -0.01468    -0.01522
mean/std                              0.05919      0.00052    0.05988     0.05826
mean/max                              0.06106      0.00058    0.06177     0.05988
mean/min                              -0.13261     0.00169    -0.12897    -0.13483
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 4, 5, 7, 9, 3, 6, 8, 0, 1]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.9460713863372803 0.0022499561309814453
train_time 1.9496269226074219
2023-09-06 13:54:19,978 MainThread INFO: EPOCH:37
2023-09-06 13:54:19,979 MainThread INFO: Time Consumed:1.9630775451660156s
2023-09-06 13:54:19,979 MainThread INFO: Total Frames:57000s
 10%|‚ñâ         | 38/400 [00:59<12:24,  2.06s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               360.25690
Train_Epoch_Reward                    14499.72684
Running_Training_Average_Rewards      1323.18621
Explore_Time                          0.00365
Train___Time                          1.94963
Eval____Time                          0.00391
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.38710
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.23518
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.20432
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.26485
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.66096
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.71776
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.61055
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3786.06200
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.97359
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.31190
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.03159      0.80949    9.36343     6.90512
alpha_0                               0.89334      0.00077    0.89454     0.89213
alpha_1                               0.89329      0.00077    0.89449     0.89208
alpha_2                               0.89332      0.00077    0.89453     0.89211
alpha_3                               0.89330      0.00077    0.89451     0.89209
alpha_4                               0.89332      0.00077    0.89453     0.89212
alpha_5                               0.89331      0.00077    0.89451     0.89210
alpha_6                               0.89332      0.00077    0.89453     0.89212
alpha_7                               0.89330      0.00077    0.89451     0.89210
alpha_8                               0.89334      0.00077    0.89455     0.89214
alpha_9                               0.89334      0.00077    0.89455     0.89214
Alpha_loss                            -0.75687     0.00609    -0.74688    -0.76558
Training/policy_loss                  -4.87583     0.03253    -4.82332    -4.92156
Training/qf1_loss                     1370.95837   555.00179  2437.52368  675.31598
Training/qf2_loss                     1373.02573   555.12039  2439.57690  677.25995
Training/pf_norm                      0.12348      0.03189    0.19738     0.08752
Training/qf1_norm                     115.16354    11.71279   135.45074   98.70369
Training/qf2_norm                     117.54972    11.95221   138.73784   101.09571
log_std/mean                          -0.13890     0.00037    -0.13843    -0.13965
log_std/std                           0.00457      0.00009    0.00475     0.00447
log_std/max                           -0.12958     0.00019    -0.12912    -0.12981
log_std/min                           -0.15129     0.00112    -0.14950    -0.15295
log_probs/mean                        -2.72697     0.00593    -2.71880    -2.74103
log_probs/std                         0.27770      0.01379    0.30767     0.25768
log_probs/max                         -1.97793     0.05634    -1.88835    -2.05703
log_probs/min                         -5.20004     0.51888    -4.52364    -6.29104
mean/mean                             -0.01533     0.00012    -0.01520    -0.01550
mean/std                              0.06039      0.00042    0.06128     0.05996
mean/max                              0.06111      0.00060    0.06195     0.06024
mean/min                              -0.13625     0.00141    -0.13387    -0.13921
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 8, 9, 1, 5, 0, 3, 7, 6, 2]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.6916313171386719 0.0023560523986816406
train_time 1.6953322887420654
2023-09-06 13:54:22,487 MainThread INFO: EPOCH:38
2023-09-06 13:54:22,488 MainThread INFO: Time Consumed:1.7101917266845703s
2023-09-06 13:54:22,488 MainThread INFO: Total Frames:58500s
 10%|‚ñâ         | 39/400 [01:02<13:11,  2.19s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               352.91594
Train_Epoch_Reward                    14382.74251
Running_Training_Average_Rewards      1643.67449
Explore_Time                          0.00543
Train___Time                          1.69533
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.80177
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.28467
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.30834
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04698
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.97726
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.35336
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.37539
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3731.26141
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.12526
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.18794
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.06179      0.72332    9.42296     6.82322
alpha_0                               0.89066      0.00077    0.89187     0.88946
alpha_1                               0.89061      0.00077    0.89181     0.88941
alpha_2                               0.89064      0.00077    0.89185     0.88944
alpha_3                               0.89062      0.00077    0.89183     0.88942
alpha_4                               0.89065      0.00077    0.89185     0.88945
alpha_5                               0.89063      0.00077    0.89183     0.88942
alpha_6                               0.89065      0.00077    0.89185     0.88945
alpha_7                               0.89063      0.00077    0.89183     0.88943
alpha_8                               0.89067      0.00077    0.89187     0.88947
alpha_9                               0.89067      0.00077    0.89187     0.88947
Alpha_loss                            -0.77695     0.00585    -0.76760    -0.78672
Training/policy_loss                  -4.99095     0.03473    -4.93415    -5.05292
Training/qf1_loss                     1323.96863   415.33327  2347.80103  690.61700
Training/qf2_loss                     1326.60054   415.47718  2350.68237  693.03632
Training/pf_norm                      0.11871      0.01687    0.14319     0.09384
Training/qf1_norm                     120.68319    10.52316   138.61714   103.74824
Training/qf2_norm                     122.45431    10.63657   140.52742   105.14134
log_std/mean                          -0.14118     0.00068    -0.13996    -0.14223
log_std/std                           0.00554      0.00041    0.00619     0.00490
log_std/max                           -0.12879     0.00070    -0.12794    -0.13018
log_std/min                           -0.15446     0.00208    -0.15122    -0.15757
log_probs/mean                        -2.72612     0.00636    -2.71105    -2.73198
log_probs/std                         0.28301      0.01441    0.31131     0.25728
log_probs/max                         -1.97871     0.03796    -1.90925    -2.04534
log_probs/min                         -5.12917     0.36034    -4.74859    -5.99062
mean/mean                             -0.01509     0.00005    -0.01500    -0.01515
mean/std                              0.06315      0.00087    0.06441     0.06167
mean/max                              0.06358      0.00027    0.06390     0.06294
mean/min                              -0.14356     0.00233    -0.14007    -0.14730
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 2, 8, 9, 3, 0, 7, 4, 1, 6]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.0370798110961914 0.0030014514923095703
train_time 2.0421924591064453
2023-09-06 13:54:24,688 MainThread INFO: EPOCH:39
2023-09-06 13:54:24,689 MainThread INFO: Time Consumed:2.0579545497894287s
2023-09-06 13:54:24,690 MainThread INFO: Total Frames:60000s
 10%|‚ñà         | 40/400 [01:04<13:06,  2.19s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               350.60222
Train_Epoch_Reward                    10408.80854
Running_Training_Average_Rewards      1309.70926
Explore_Time                          0.00310
Train___Time                          2.04219
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.06935
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.07814
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.53879
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62395
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.40404
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.63944
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.08860
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3743.99008
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.03907
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.93829
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.11332      0.55748    8.97357     7.13353
alpha_0                               0.88800      0.00076    0.88919     0.88680
alpha_1                               0.88794      0.00077    0.88914     0.88674
alpha_2                               0.88797      0.00076    0.88917     0.88678
alpha_3                               0.88795      0.00077    0.88915     0.88675
alpha_4                               0.88798      0.00076    0.88918     0.88679
alpha_5                               0.88796      0.00077    0.88916     0.88676
alpha_6                               0.88798      0.00076    0.88918     0.88678
alpha_7                               0.88796      0.00077    0.88916     0.88676
alpha_8                               0.88800      0.00076    0.88920     0.88680
alpha_9                               0.88800      0.00077    0.88920     0.88680
Alpha_loss                            -0.79641     0.00532    -0.78817    -0.80466
Training/policy_loss                  -5.10273     0.03033    -5.05829    -5.15211
Training/qf1_loss                     1399.48483   352.99441  2116.11133  811.32629
Training/qf2_loss                     1402.36424   353.23128  2119.51489  813.85956
Training/pf_norm                      0.11829      0.01623    0.15082     0.08916
Training/qf1_norm                     125.71756    9.66316    141.76442   108.79907
Training/qf2_norm                     127.42057    9.59925    143.35318   110.74654
log_std/mean                          -0.14280     0.00018    -0.14249    -0.14304
log_std/std                           0.00652      0.00009    0.00662     0.00631
log_std/max                           -0.12802     0.00017    -0.12772    -0.12826
log_std/min                           -0.15853     0.00118    -0.15590    -0.15964
log_probs/mean                        -2.72005     0.00478    -2.71318    -2.72715
log_probs/std                         0.27907      0.01482    0.30559     0.26263
log_probs/max                         -1.95764     0.05663    -1.87399    -2.04396
log_probs/min                         -4.95312     0.73821    -3.97388    -6.07082
mean/mean                             -0.01548     0.00030    -0.01508    -0.01601
mean/std                              0.06527      0.00028    0.06552     0.06467
mean/max                              0.06342      0.00049    0.06396     0.06222
mean/min                              -0.15017     0.00161    -0.14790    -0.15213
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 2, 9, 0, 3, 4, 7, 8, 1, 6]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.259706974029541 0.0028727054595947266
train_time 2.264347791671753
2023-09-06 13:54:27,075 MainThread INFO: EPOCH:40
2023-09-06 13:54:27,076 MainThread INFO: Time Consumed:2.2757372856140137s
2023-09-06 13:54:27,076 MainThread INFO: Total Frames:61500s
 10%|‚ñà         | 41/400 [01:06<13:26,  2.25s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               350.60990
Train_Epoch_Reward                    28872.45231
Running_Training_Average_Rewards      1788.80011
Explore_Time                          0.00342
Train___Time                          2.26435
Eval____Time                          0.00374
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.49450
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.89997
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.93930
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.02000
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.50956
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.04228
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.60378
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3791.14539
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.11139
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.59846
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.45631      0.99023    10.73426    7.33925
alpha_0                               0.88534      0.00076    0.88653     0.88414
alpha_1                               0.88528      0.00076    0.88647     0.88408
alpha_2                               0.88532      0.00076    0.88651     0.88412
alpha_3                               0.88529      0.00076    0.88649     0.88410
alpha_4                               0.88533      0.00076    0.88652     0.88413
alpha_5                               0.88530      0.00076    0.88649     0.88410
alpha_6                               0.88532      0.00076    0.88652     0.88413
alpha_7                               0.88530      0.00076    0.88650     0.88411
alpha_8                               0.88534      0.00076    0.88654     0.88415
alpha_9                               0.88534      0.00076    0.88653     0.88414
Alpha_loss                            -0.81770     0.00570    -0.80868    -0.82577
Training/policy_loss                  -5.22545     0.03393    -5.16899    -5.27766
Training/qf1_loss                     1633.34683   615.63162  3212.08008  826.69629
Training/qf2_loss                     1636.78051   616.02418  3216.67065  829.76208
Training/pf_norm                      0.12374      0.01813    0.16713     0.09640
Training/qf1_norm                     136.53306    15.85625   172.98332   118.01446
Training/qf2_norm                     137.85685    15.82473   173.76875   119.12956
log_std/mean                          -0.14206     0.00045    -0.14119    -0.14250
log_std/std                           0.00680      0.00008    0.00689     0.00665
log_std/max                           -0.12658     0.00073    -0.12520    -0.12738
log_std/min                           -0.15831     0.00108    -0.15679    -0.15984
log_probs/mean                        -2.72938     0.00404    -2.72111    -2.73520
log_probs/std                         0.28665      0.01342    0.31216     0.26175
log_probs/max                         -1.96297     0.06088    -1.85980    -2.08921
log_probs/min                         -5.20985     0.51790    -4.30022    -6.08991
mean/mean                             -0.01683     0.00057    -0.01609    -0.01783
mean/std                              0.06535      0.00005    0.06541     0.06526
mean/max                              0.06068      0.00112    0.06228     0.05855
mean/min                              -0.15384     0.00156    -0.15105    -0.15632
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 6, 5, 9, 3, 0, 7, 8, 2, 4]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.1621484756469727 0.0019826889038085938
train_time 2.1653876304626465
2023-09-06 13:54:29,362 MainThread INFO: EPOCH:41
2023-09-06 13:54:29,362 MainThread INFO: Time Consumed:2.1768810749053955s
2023-09-06 13:54:29,363 MainThread INFO: Total Frames:63000s
 10%|‚ñà         | 42/400 [01:09<13:29,  2.26s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               362.09716
Train_Epoch_Reward                    10545.57449
Running_Training_Average_Rewards      1660.89451
Explore_Time                          0.00327
Train___Time                          2.16539
Eval____Time                          0.00408
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.07527
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.93927
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.22032
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.58098
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.78260
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.07267
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  156.23669
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3894.18213
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.25280
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.07682
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.08031      0.57060    8.85993     6.87121
alpha_0                               0.88269      0.00076    0.88388     0.88150
alpha_1                               0.88262      0.00076    0.88382     0.88143
alpha_2                               0.88267      0.00076    0.88386     0.88148
alpha_3                               0.88264      0.00076    0.88383     0.88145
alpha_4                               0.88267      0.00076    0.88387     0.88148
alpha_5                               0.88264      0.00076    0.88384     0.88145
alpha_6                               0.88267      0.00076    0.88386     0.88147
alpha_7                               0.88265      0.00076    0.88384     0.88146
alpha_8                               0.88269      0.00076    0.88388     0.88149
alpha_9                               0.88269      0.00076    0.88388     0.88150
Alpha_loss                            -0.83690     0.00562    -0.82889    -0.84606
Training/policy_loss                  -5.33105     0.03180    -5.28493    -5.38300
Training/qf1_loss                     1225.48745   296.53515  1847.16772  704.02521
Training/qf2_loss                     1229.16722   296.77484  1851.07288  707.21326
Training/pf_norm                      0.11012      0.02138    0.14090     0.07106
Training/qf1_norm                     134.49846    9.86663    147.06470   114.27555
Training/qf2_norm                     135.45609    9.87120    148.14684   115.21010
log_std/mean                          -0.13951     0.00088    -0.13830    -0.14090
log_std/std                           0.00715      0.00011    0.00732     0.00694
log_std/max                           -0.12312     0.00100    -0.12162    -0.12484
log_std/min                           -0.15944     0.00062    -0.15825    -0.16024
log_probs/mean                        -2.72142     0.00607    -2.71254    -2.73010
log_probs/std                         0.27763      0.01163    0.29800     0.25899
log_probs/max                         -1.94613     0.03060    -1.88769    -1.99143
log_probs/min                         -4.95040     0.45933    -4.23769    -5.81749
mean/mean                             -0.01879     0.00037    -0.01805    -0.01914
mean/std                              0.06488      0.00020    0.06518     0.06465
mean/max                              0.05637      0.00083    0.05799     0.05562
mean/min                              -0.15649     0.00082    -0.15492    -0.15741
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 7, 0, 9, 8, 2, 3, 6, 4, 5]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.0574021339416504 0.0020761489868164062
train_time 2.060758590698242
2023-09-06 13:54:31,557 MainThread INFO: EPOCH:42
2023-09-06 13:54:31,558 MainThread INFO: Time Consumed:2.0712273120880127s
2023-09-06 13:54:31,558 MainThread INFO: Total Frames:64500s
 11%|‚ñà         | 43/400 [01:11<13:18,  2.24s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               382.51067
Train_Epoch_Reward                    12773.28087
Running_Training_Average_Rewards      1739.71026
Explore_Time                          0.00285
Train___Time                          2.06076
Eval____Time                          0.00289
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.40811
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.98055
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.57226
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.15423
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.48516
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.51558
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  304.95027
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4037.02044
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.39881
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.48016
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.47239      0.74253    9.33781     7.02532
alpha_0                               0.88004      0.00076    0.88123     0.87886
alpha_1                               0.87998      0.00076    0.88117     0.87879
alpha_2                               0.88003      0.00076    0.88122     0.87884
alpha_3                               0.88000      0.00076    0.88118     0.87881
alpha_4                               0.88003      0.00076    0.88122     0.87885
alpha_5                               0.88000      0.00076    0.88119     0.87882
alpha_6                               0.88002      0.00076    0.88121     0.87883
alpha_7                               0.88001      0.00076    0.88120     0.87882
alpha_8                               0.88004      0.00076    0.88123     0.87885
alpha_9                               0.88005      0.00076    0.88124     0.87886
Alpha_loss                            -0.85696     0.00563    -0.84661    -0.86480
Training/policy_loss                  -5.44585     0.03130    -5.39249    -5.49621
Training/qf1_loss                     1535.99821   408.51055  2171.91479  882.82178
Training/qf2_loss                     1540.08466   408.81033  2176.63037  886.62317
Training/pf_norm                      0.13574      0.02879    0.17685     0.08787
Training/qf1_norm                     146.79042    12.92722   165.06818   121.75155
Training/qf2_norm                     147.78121    12.83002   165.64180   123.05603
log_std/mean                          -0.13852     0.00023    -0.13824    -0.13896
log_std/std                           0.00724      0.00013    0.00739     0.00704
log_std/max                           -0.12209     0.00052    -0.12128    -0.12313
log_std/min                           -0.15890     0.00052    -0.15788    -0.15962
log_probs/mean                        -2.72070     0.00843    -2.70997    -2.73759
log_probs/std                         0.28120      0.01449    0.30923     0.25672
log_probs/max                         -1.93565     0.04017    -1.86198    -2.00182
log_probs/min                         -4.90157     0.42660    -4.23219    -5.49378
mean/mean                             -0.01840     0.00033    -0.01797    -0.01904
mean/std                              0.06511      0.00033    0.06568     0.06469
mean/max                              0.05696      0.00071    0.05772     0.05550
mean/min                              -0.15586     0.00046    -0.15489    -0.15627
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 8, 5, 9, 1, 3, 6, 2, 4, 7]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.407797336578369 0.0021004676818847656
train_time 2.411252498626709
2023-09-06 13:54:34,086 MainThread INFO: EPOCH:43
2023-09-06 13:54:34,086 MainThread INFO: Time Consumed:2.4247257709503174s
2023-09-06 13:54:34,087 MainThread INFO: Total Frames:66000s
 11%|‚ñà         | 44/400 [01:13<13:47,  2.33s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               402.18242
Train_Epoch_Reward                    9468.07819
Running_Training_Average_Rewards      1092.89778
Explore_Time                          0.00314
Train___Time                          2.41125
Eval____Time                          0.00582
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.01772
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.20275
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.54613
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.02532
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.64704
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.65722
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  318.58901
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4045.44564
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.63951
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.22021
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.89906     0.48155    8.92652     7.38248
alpha_0                               0.87741     0.00075    0.87859     0.87623
alpha_1                               0.87734     0.00076    0.87853     0.87616
alpha_2                               0.87740     0.00076    0.87858     0.87621
alpha_3                               0.87736     0.00076    0.87854     0.87617
alpha_4                               0.87740     0.00076    0.87858     0.87622
alpha_5                               0.87737     0.00076    0.87855     0.87618
alpha_6                               0.87739     0.00076    0.87857     0.87620
alpha_7                               0.87737     0.00076    0.87856     0.87619
alpha_8                               0.87740     0.00076    0.87859     0.87622
alpha_9                               0.87742     0.00076    0.87860     0.87623
Alpha_loss                            -0.87732    0.00612    -0.86750    -0.88589
Training/policy_loss                  -5.55831    0.03498    -5.50499    -5.60647
Training/qf1_loss                     1106.29435  347.55648  1807.13672  785.14160
Training/qf2_loss                     1110.50504  347.73551  1811.89917  789.32178
Training/pf_norm                      0.12055     0.02189    0.15544     0.08608
Training/qf1_norm                     141.32768   8.62347    159.04300   132.99756
Training/qf2_norm                     142.02929   8.68862    159.64554   133.62993
log_std/mean                          -0.14057    0.00090    -0.13921    -0.14174
log_std/std                           0.00699     0.00007    0.00711     0.00690
log_std/max                           -0.12462    0.00105    -0.12276    -0.12637
log_std/min                           -0.15865    0.00064    -0.15790    -0.15975
log_probs/mean                        -2.72225    0.00509    -2.71379    -2.73111
log_probs/std                         0.28668     0.01011    0.30407     0.27367
log_probs/max                         -1.92144    0.03669    -1.85098    -1.96875
log_probs/min                         -5.19273    0.51620    -4.45404    -6.04133
mean/mean                             -0.01752    0.00035    -0.01696    -0.01798
mean/std                              0.06614     0.00028    0.06651     0.06574
mean/max                              0.05691     0.00015    0.05711     0.05662
mean/min                              -0.15549    0.00093    -0.15312    -0.15638
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 1, 4, 5, 9, 2, 6, 7, 3, 8]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.1888773441314697 0.0019707679748535156
train_time 2.192054510116577
2023-09-06 13:54:36,400 MainThread INFO: EPOCH:44
2023-09-06 13:54:36,401 MainThread INFO: Time Consumed:2.2037720680236816s
2023-09-06 13:54:36,401 MainThread INFO: Total Frames:67500s
 11%|‚ñà‚ñè        | 45/400 [01:16<13:44,  2.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               417.04095
Train_Epoch_Reward                    11940.91072
Running_Training_Average_Rewards      1139.40899
Explore_Time                          0.00299
Train___Time                          2.19205
Eval____Time                          0.00353
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.80209
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.87261
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.98623
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.51442
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.02650
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.74672
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  311.81628
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4191.56200
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.36436
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.89154
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.72511      0.53786    8.35623     6.84056
alpha_0                               0.87479      0.00075    0.87597     0.87361
alpha_1                               0.87472      0.00075    0.87590     0.87354
alpha_2                               0.87477      0.00075    0.87595     0.87359
alpha_3                               0.87473      0.00075    0.87591     0.87355
alpha_4                               0.87477      0.00075    0.87595     0.87359
alpha_5                               0.87474      0.00075    0.87592     0.87356
alpha_6                               0.87476      0.00075    0.87594     0.87358
alpha_7                               0.87474      0.00075    0.87592     0.87356
alpha_8                               0.87478      0.00075    0.87596     0.87360
alpha_9                               0.87479      0.00075    0.87597     0.87361
Alpha_loss                            -0.89714     0.00532    -0.88858    -0.90543
Training/policy_loss                  -5.67035     0.03289    -5.61539    -5.71672
Training/qf1_loss                     1180.79262   311.07097  1697.75037  720.14709
Training/qf2_loss                     1185.18527   311.19816  1702.16870  724.26172
Training/pf_norm                      0.11621      0.01889    0.16220     0.09380
Training/qf1_norm                     141.97905    9.92057    153.72130   124.50111
Training/qf2_norm                     142.64424    9.88506    154.82896   125.16355
log_std/mean                          -0.14266     0.00048    -0.14188    -0.14333
log_std/std                           0.00731      0.00014    0.00757     0.00709
log_std/max                           -0.12635     0.00042    -0.12593    -0.12750
log_std/min                           -0.16012     0.00057    -0.15892    -0.16103
log_probs/mean                        -2.71976     0.00505    -2.71001    -2.72858
log_probs/std                         0.27687      0.01127    0.29599     0.25765
log_probs/max                         -1.96460     0.04539    -1.89501    -2.04870
log_probs/min                         -4.92388     0.62340    -4.34243    -6.33438
mean/mean                             -0.01691     0.00003    -0.01687    -0.01695
mean/std                              0.06751      0.00057    0.06827     0.06659
mean/max                              0.05786      0.00053    0.05885     0.05713
mean/min                              -0.15593     0.00078    -0.15461    -0.15708
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 1, 5, 6, 0, 3, 9, 4, 8, 2]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.315916061401367 0.0021822452545166016
train_time 2.3194196224212646
2023-09-06 13:54:38,837 MainThread INFO: EPOCH:45
2023-09-06 13:54:38,838 MainThread INFO: Time Consumed:2.3301548957824707s
2023-09-06 13:54:38,838 MainThread INFO: Total Frames:69000s
 12%|‚ñà‚ñè        | 46/400 [01:18<13:53,  2.36s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               423.90460
Train_Epoch_Reward                    4596.03356
Running_Training_Average_Rewards      866.83408
Explore_Time                          0.00349
Train___Time                          2.31942
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.39055
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.87799
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.07215
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.30354
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.99249
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.55142
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  314.45795
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4217.77134
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.46246
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.69319
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.04944     0.66536    9.15485     6.91648
alpha_0                               0.87217     0.00075    0.87335     0.87100
alpha_1                               0.87210     0.00075    0.87327     0.87092
alpha_2                               0.87215     0.00075    0.87333     0.87098
alpha_3                               0.87211     0.00075    0.87329     0.87093
alpha_4                               0.87215     0.00075    0.87333     0.87098
alpha_5                               0.87212     0.00075    0.87330     0.87094
alpha_6                               0.87214     0.00075    0.87332     0.87097
alpha_7                               0.87212     0.00075    0.87330     0.87095
alpha_8                               0.87216     0.00075    0.87333     0.87098
alpha_9                               0.87217     0.00075    0.87335     0.87100
Alpha_loss                            -0.91705    0.00620    -0.90525    -0.92694
Training/policy_loss                  -5.78337    0.03435    -5.72058    -5.83327
Training/qf1_loss                     1209.54118  264.64693  1604.80835  777.19043
Training/qf2_loss                     1214.62249  264.96130  1610.82520  781.34930
Training/pf_norm                      0.11407     0.01685    0.14892     0.09631
Training/qf1_norm                     153.45806   13.63591   174.21220   130.29958
Training/qf2_norm                     153.58659   13.37998   173.75729   131.05522
log_std/mean                          -0.14336    0.00033    -0.14279    -0.14377
log_std/std                           0.00798     0.00017    0.00822     0.00767
log_std/max                           -0.12596    0.00045    -0.12513    -0.12653
log_std/min                           -0.16196    0.00075    -0.16015    -0.16289
log_probs/mean                        -2.71802    0.00867    -2.69779    -2.72900
log_probs/std                         0.27751     0.01226    0.30581     0.26215
log_probs/max                         -1.94704    0.04917    -1.82568    -2.01578
log_probs/min                         -4.84959    0.57709    -4.16207    -6.10487
mean/mean                             -0.01663    0.00005    -0.01656    -0.01676
mean/std                              0.06855     0.00008    0.06864     0.06839
mean/max                              0.06069     0.00097    0.06186     0.05898
mean/min                              -0.15790    0.00120    -0.15542    -0.15947
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 5, 3, 1, 4, 8, 6, 7, 2, 0]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.424294948577881 0.002704143524169922
train_time 2.4286890029907227
2023-09-06 13:54:41,379 MainThread INFO: EPOCH:46
2023-09-06 13:54:41,380 MainThread INFO: Time Consumed:2.439244031906128s
2023-09-06 13:54:41,380 MainThread INFO: Total Frames:70500s
 12%|‚ñà‚ñè        | 47/400 [01:21<14:12,  2.41s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               426.27834
Train_Epoch_Reward                    8393.98298
Running_Training_Average_Rewards      831.03091
Explore_Time                          0.00279
Train___Time                          2.42869
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.65564
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.79322
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.06733
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.39439
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.58369
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.32296
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  324.84237
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4108.68250
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.62380
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.79298
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.74391     0.75525    9.44810     6.91942
alpha_0                               0.86957     0.00075    0.87074     0.86839
alpha_1                               0.86948     0.00075    0.87066     0.86831
alpha_2                               0.86955     0.00075    0.87072     0.86838
alpha_3                               0.86949     0.00075    0.87067     0.86832
alpha_4                               0.86954     0.00075    0.87072     0.86837
alpha_5                               0.86951     0.00075    0.87068     0.86834
alpha_6                               0.86953     0.00075    0.87070     0.86835
alpha_7                               0.86951     0.00075    0.87069     0.86834
alpha_8                               0.86955     0.00075    0.87072     0.86838
alpha_9                               0.86956     0.00075    0.87074     0.86839
Alpha_loss                            -0.93699    0.00562    -0.92846    -0.94683
Training/policy_loss                  -5.89306    0.03283    -5.83934    -5.94647
Training/qf1_loss                     1186.47249  492.44166  2366.08838  710.32288
Training/qf2_loss                     1191.65654  493.02274  2372.70361  715.14233
Training/pf_norm                      0.11282     0.01738    0.14061     0.08232
Training/qf1_norm                     152.47806   15.26758   187.01378   134.93323
Training/qf2_norm                     152.60757   14.91295   186.21922   135.32874
log_std/mean                          -0.14202    0.00044    -0.14132    -0.14274
log_std/std                           0.00843     0.00013    0.00860     0.00824
log_std/max                           -0.12380    0.00078    -0.12290    -0.12505
log_std/min                           -0.16067    0.00069    -0.15961    -0.16171
log_probs/mean                        -2.71665    0.00846    -2.70283    -2.73247
log_probs/std                         0.27830     0.01156    0.29909     0.26081
log_probs/max                         -1.93001    0.04805    -1.87111    -2.01421
log_probs/min                         -4.93426    0.58318    -4.30298    -6.04471
mean/mean                             -0.01617    0.00035    -0.01546    -0.01647
mean/std                              0.06928     0.00039    0.06985     0.06875
mean/max                              0.06467     0.00152    0.06694     0.06241
mean/min                              -0.16011    0.00257    -0.15695    -0.16327
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 0, 4, 2, 8, 1, 3, 9, 6, 5]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.264730453491211 0.0021140575408935547
train_time 2.268101930618286
2023-09-06 13:54:43,774 MainThread INFO: EPOCH:47
2023-09-06 13:54:43,774 MainThread INFO: Time Consumed:2.2788140773773193s
2023-09-06 13:54:43,774 MainThread INFO: Total Frames:72000s
 12%|‚ñà‚ñè        | 48/400 [01:23<14:07,  2.41s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               427.94365
Train_Epoch_Reward                    6054.81054
Running_Training_Average_Rewards      634.82757
Explore_Time                          0.00279
Train___Time                          2.26810
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.26694
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.78555
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.21189
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.04841
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.12787
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.06096
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  331.20800
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4210.71553
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.73638
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.55253
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.48158     0.58976    8.63784     6.36642
alpha_0                               0.86696     0.00075    0.86813     0.86580
alpha_1                               0.86688     0.00075    0.86805     0.86571
alpha_2                               0.86695     0.00075    0.86812     0.86578
alpha_3                               0.86689     0.00075    0.86806     0.86572
alpha_4                               0.86694     0.00075    0.86811     0.86577
alpha_5                               0.86691     0.00075    0.86808     0.86574
alpha_6                               0.86692     0.00075    0.86809     0.86575
alpha_7                               0.86691     0.00075    0.86808     0.86575
alpha_8                               0.86695     0.00074    0.86812     0.86578
alpha_9                               0.86696     0.00075    0.86813     0.86579
Alpha_loss                            -0.95758    0.00589    -0.94733    -0.96700
Training/policy_loss                  -6.00968    0.03347    -5.95449    -6.06443
Training/qf1_loss                     1131.78321  368.61318  1946.39282  680.60828
Training/qf2_loss                     1137.03786  368.94814  1952.31665  685.36432
Training/pf_norm                      0.12434     0.01548    0.15592     0.10295
Training/qf1_norm                     152.20892   13.09394   179.44058   130.05008
Training/qf2_norm                     152.37750   13.00088   179.68477   130.35245
log_std/mean                          -0.14096    0.00022    -0.14065    -0.14131
log_std/std                           0.00864     0.00005    0.00872     0.00856
log_std/max                           -0.12260    0.00033    -0.12203    -0.12306
log_std/min                           -0.15950    0.00059    -0.15844    -0.16021
log_probs/mean                        -2.71983    0.00754    -2.71039    -2.73300
log_probs/std                         0.28643     0.01144    0.30800     0.26641
log_probs/max                         -1.91815    0.06554    -1.77749    -2.02388
log_probs/min                         -5.27836    0.49203    -4.48235    -5.95575
mean/mean                             -0.01470    0.00028    -0.01423    -0.01524
mean/std                              0.06973     0.00020    0.06993     0.06928
mean/max                              0.06948     0.00168    0.07254     0.06714
mean/min                              -0.16226    0.00161    -0.15965    -0.16420
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 4, 5, 8, 2, 1, 3, 6, 7, 9]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.2597877979278564 0.001999378204345703
train_time 2.262972116470337
2023-09-06 13:54:46,158 MainThread INFO: EPOCH:48
2023-09-06 13:54:46,158 MainThread INFO: Time Consumed:2.2743353843688965s
2023-09-06 13:54:46,159 MainThread INFO: Total Frames:73500s
 12%|‚ñà‚ñè        | 49/400 [01:25<14:02,  2.40s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               431.52777
Train_Epoch_Reward                    1803.52049
Running_Training_Average_Rewards      541.74380
Explore_Time                          0.00346
Train___Time                          2.26297
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.48573
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.59193
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.51411
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.75245
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.04106
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.17471
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  319.70146
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4315.10096
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.63925
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.19398
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.05122     0.96613    10.34200    6.70674
alpha_0                               0.86437     0.00074    0.86554     0.86320
alpha_1                               0.86429     0.00074    0.86545     0.86312
alpha_2                               0.86435     0.00074    0.86552     0.86319
alpha_3                               0.86429     0.00075    0.86546     0.86312
alpha_4                               0.86434     0.00075    0.86551     0.86318
alpha_5                               0.86432     0.00074    0.86548     0.86315
alpha_6                               0.86433     0.00074    0.86549     0.86316
alpha_7                               0.86432     0.00074    0.86549     0.86315
alpha_8                               0.86436     0.00074    0.86552     0.86319
alpha_9                               0.86436     0.00074    0.86553     0.86320
Alpha_loss                            -0.97828    0.00518    -0.97183    -0.98792
Training/policy_loss                  -6.12262    0.03113    -6.08202    -6.17526
Training/qf1_loss                     1437.88033  711.01226  3364.05859  778.01642
Training/qf2_loss                     1443.90034  711.87634  3372.19971  782.83026
Training/pf_norm                      0.13854     0.02544    0.17755     0.07703
Training/qf1_norm                     169.15946   22.64553   224.35315   137.59979
Training/qf2_norm                     169.12190   22.26127   223.34859   138.06621
log_std/mean                          -0.14075    0.00041    -0.14020    -0.14153
log_std/std                           0.00848     0.00005    0.00857     0.00840
log_std/max                           -0.12211    0.00027    -0.12171    -0.12260
log_std/min                           -0.15840    0.00129    -0.15683    -0.16060
log_probs/mean                        -2.72370    0.00985    -2.70885    -2.74187
log_probs/std                         0.29192     0.01193    0.31296     0.27595
log_probs/max                         -1.89911    0.03192    -1.83171    -1.94583
log_probs/min                         -5.34866    0.64875    -4.61096    -6.49647
mean/mean                             -0.01434    0.00018    -0.01405    -0.01451
mean/std                              0.06935     0.00036    0.06991     0.06890
mean/max                              0.07563     0.00156    0.07843     0.07340
mean/min                              -0.16393    0.00237    -0.16056    -0.16825
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 7, 6, 8, 9, 1, 4, 5, 2, 0]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.3813064098358154 0.0023796558380126953
train_time 2.3851428031921387
2023-09-06 13:54:48,664 MainThread INFO: EPOCH:49
2023-09-06 13:54:48,664 MainThread INFO: Time Consumed:2.3965110778808594s
2023-09-06 13:54:48,665 MainThread INFO: Total Frames:75000s
 12%|‚ñà‚ñé        | 50/400 [01:28<14:11,  2.43s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               454.85581
Train_Epoch_Reward                    2498.36387
Running_Training_Average_Rewards      345.22316
Explore_Time                          0.00303
Train___Time                          2.38514
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.09656
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.43841
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.79403
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.25234
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.13709
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.28411
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  292.99573
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4829.24136
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.50911
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.59348
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.61200     0.95695    9.42914     6.54217
alpha_0                               0.86178     0.00074    0.86295     0.86062
alpha_1                               0.86170     0.00074    0.86286     0.86053
alpha_2                               0.86176     0.00074    0.86293     0.86060
alpha_3                               0.86170     0.00074    0.86287     0.86054
alpha_4                               0.86175     0.00074    0.86292     0.86059
alpha_5                               0.86173     0.00074    0.86289     0.86057
alpha_6                               0.86174     0.00074    0.86290     0.86058
alpha_7                               0.86173     0.00074    0.86290     0.86057
alpha_8                               0.86177     0.00074    0.86294     0.86061
alpha_9                               0.86177     0.00074    0.86294     0.86061
Alpha_loss                            -0.99786    0.00583    -0.98947    -1.00709
Training/policy_loss                  -6.23287    0.03209    -6.18302    -6.28371
Training/qf1_loss                     1255.70505  522.21660  2137.69434  668.11877
Training/qf2_loss                     1261.66303  523.00485  2145.02856  673.63025
Training/pf_norm                      0.11762     0.02859    0.17450     0.08854
Training/qf1_norm                     164.51813   21.87372   203.11263   139.08058
Training/qf2_norm                     164.59539   21.64807   202.84766   139.57693
log_std/mean                          -0.14260    0.00035    -0.14186    -0.14296
log_std/std                           0.00874     0.00010    0.00890     0.00860
log_std/max                           -0.12172    0.00039    -0.12113    -0.12233
log_std/min                           -0.16383    0.00242    -0.16026    -0.16802
log_probs/mean                        -2.71975    0.00388    -2.71237    -2.72612
log_probs/std                         0.28607     0.01242    0.30560     0.25804
log_probs/max                         -1.91361    0.05263    -1.84611    -1.99915
log_probs/min                         -5.09182    0.59240    -4.52297    -6.54063
mean/mean                             -0.01429    0.00011    -0.01408    -0.01443
mean/std                              0.07075     0.00039    0.07136     0.07011
mean/max                              0.07957     0.00043    0.08041     0.07879
mean/min                              -0.17090    0.00259    -0.16710    -0.17582
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 5, 8, 4, 7, 2, 0, 3, 9, 6]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.3572404384613037 0.002103567123413086
train_time 2.361934185028076
2023-09-06 13:54:51,148 MainThread INFO: EPOCH:50
2023-09-06 13:54:51,149 MainThread INFO: Time Consumed:2.375154495239258s
2023-09-06 13:54:51,149 MainThread INFO: Total Frames:76500s
 13%|‚ñà‚ñé        | 51/400 [01:30<14:14,  2.45s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               468.99847
Train_Epoch_Reward                    11449.67999
Running_Training_Average_Rewards      525.05214
Explore_Time                          0.00338
Train___Time                          2.36193
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.65509
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.33619
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.02821
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.03320
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.32505
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.34904
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  286.25866
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4670.78737
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.51111
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.39524
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.36622      0.83196    8.63354     5.97911
alpha_0                               0.85921      0.00074    0.86036     0.85805
alpha_1                               0.85911      0.00074    0.86028     0.85796
alpha_2                               0.85919      0.00074    0.86034     0.85803
alpha_3                               0.85912      0.00074    0.86028     0.85796
alpha_4                               0.85917      0.00074    0.86033     0.85801
alpha_5                               0.85915      0.00074    0.86031     0.85799
alpha_6                               0.85916      0.00074    0.86032     0.85800
alpha_7                               0.85915      0.00074    0.86031     0.85800
alpha_8                               0.85919      0.00074    0.86035     0.85803
alpha_9                               0.85919      0.00074    0.86035     0.85803
Alpha_loss                            -1.01794     0.00580    -1.00838    -1.02582
Training/policy_loss                  -6.34296     0.03386    -6.29149    -6.38800
Training/qf1_loss                     1113.45360   429.72708  1731.09399  525.66614
Training/qf2_loss                     1119.45987   430.33387  1737.81897  530.42615
Training/pf_norm                      0.11781      0.01656    0.15345     0.09631
Training/qf1_norm                     163.65274    20.35028   191.88280   130.04050
Training/qf2_norm                     163.86518    20.15008   192.18771   130.57195
log_std/mean                          -0.14275     0.00009    -0.14262    -0.14287
log_std/std                           0.00911      0.00015    0.00936     0.00893
log_std/max                           -0.12190     0.00026    -0.12152    -0.12238
log_std/min                           -0.16874     0.00142    -0.16543    -0.17015
log_probs/mean                        -2.71929     0.00567    -2.71158    -2.72816
log_probs/std                         0.28216      0.00938    0.29709     0.26764
log_probs/max                         -1.88587     0.05026    -1.82515    -1.97961
log_probs/min                         -4.87432     0.39119    -4.30695    -5.63766
mean/mean                             -0.01365     0.00016    -0.01346    -0.01396
mean/std                              0.07245      0.00070    0.07364     0.07151
mean/max                              0.08177      0.00144    0.08451     0.08022
mean/min                              -0.18000     0.00330    -0.17469    -0.18458
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 3, 6, 2, 0, 8, 7, 4, 9, 1]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.507232666015625 0.002008676528930664
train_time 2.510427236557007
2023-09-06 13:54:53,784 MainThread INFO: EPOCH:51
2023-09-06 13:54:53,785 MainThread INFO: Time Consumed:2.522228240966797s
2023-09-06 13:54:53,785 MainThread INFO: Total Frames:78000s
 13%|‚ñà‚ñé        | 52/400 [01:33<14:31,  2.50s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               476.91746
Train_Epoch_Reward                    2547.62325
Running_Training_Average_Rewards      549.85557
Explore_Time                          0.00370
Train___Time                          2.51043
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.28986
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.26142
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.14708
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.93391
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.96760
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.39847
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  286.60814
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4593.37398
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.59871
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.40628
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.44800     0.39405    8.28616     6.89547
alpha_0                               0.85664     0.00074    0.85779     0.85549
alpha_1                               0.85654     0.00074    0.85770     0.85538
alpha_2                               0.85662     0.00074    0.85777     0.85547
alpha_3                               0.85654     0.00074    0.85770     0.85539
alpha_4                               0.85660     0.00074    0.85775     0.85544
alpha_5                               0.85658     0.00074    0.85773     0.85542
alpha_6                               0.85659     0.00074    0.85775     0.85543
alpha_7                               0.85659     0.00074    0.85774     0.85543
alpha_8                               0.85662     0.00074    0.85778     0.85547
alpha_9                               0.85662     0.00074    0.85778     0.85546
Alpha_loss                            -1.03781    0.00620    -1.02838    -1.04592
Training/policy_loss                  -6.45649    0.03478    -6.39677    -6.50020
Training/qf1_loss                     1177.23065  364.73642  2077.07471  807.14587
Training/qf2_loss                     1183.68901  365.06196  2084.50610  813.18024
Training/pf_norm                      0.10634     0.01562    0.12842     0.08161
Training/qf1_norm                     170.88844   10.37354   192.46272   157.64664
Training/qf2_norm                     170.86689   10.32772   191.93767   157.18810
log_std/mean                          -0.14275    0.00005    -0.14263    -0.14281
log_std/std                           0.00986     0.00027    0.01023     0.00939
log_std/max                           -0.12111    0.00053    -0.12022    -0.12189
log_std/min                           -0.17186    0.00169    -0.16924    -0.17437
log_probs/mean                        -2.71753    0.00800    -2.70389    -2.73088
log_probs/std                         0.29403     0.02226    0.34633     0.26996
log_probs/max                         -1.88587    0.04613    -1.79468    -1.94513
log_probs/min                         -5.40871    1.37981    -4.22884    -9.19758
mean/mean                             -0.01382    0.00009    -0.01362    -0.01392
mean/std                              0.07531     0.00088    0.07668     0.07390
mean/max                              0.08857     0.00248    0.09197     0.08528
mean/min                              -0.19087    0.00350    -0.18631    -0.19551
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 9, 4, 8, 5, 1, 7, 3, 0, 2]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.4550015926361084 0.0020170211791992188
train_time 2.458258628845215
2023-09-06 13:54:56,360 MainThread INFO: EPOCH:52
2023-09-06 13:54:56,361 MainThread INFO: Time Consumed:2.470144271850586s
2023-09-06 13:54:56,361 MainThread INFO: Total Frames:79500s
 13%|‚ñà‚ñé        | 53/400 [01:35<14:36,  2.53s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               474.20090
Train_Epoch_Reward                    2958.61670
Running_Training_Average_Rewards      565.19733
Explore_Time                          0.00291
Train___Time                          2.45826
Eval____Time                          0.00413
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.69337
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.27213
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.19833
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.85126
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.13000
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.20196
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  293.67635
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4754.48579
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.74090
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.43886
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.36342     0.64500    8.50716     6.51473
alpha_0                               0.85408     0.00073    0.85523     0.85293
alpha_1                               0.85397     0.00074    0.85513     0.85282
alpha_2                               0.85406     0.00074    0.85521     0.85291
alpha_3                               0.85398     0.00074    0.85513     0.85282
alpha_4                               0.85403     0.00074    0.85518     0.85288
alpha_5                               0.85402     0.00074    0.85517     0.85286
alpha_6                               0.85402     0.00074    0.85518     0.85287
alpha_7                               0.85402     0.00074    0.85517     0.85287
alpha_8                               0.85406     0.00073    0.85521     0.85291
alpha_9                               0.85405     0.00074    0.85521     0.85290
Alpha_loss                            -1.05800    0.00536    -1.04983    -1.06586
Training/policy_loss                  -6.56744    0.03252    -6.51648    -6.61430
Training/qf1_loss                     1071.55895  324.38651  1814.73145  686.09637
Training/qf2_loss                     1078.12487  324.73839  1821.70483  691.88281
Training/pf_norm                      0.12372     0.01605    0.15509     0.09531
Training/qf1_norm                     172.43770   16.10561   202.31453   152.69644
Training/qf2_norm                     172.59915   16.21587   203.04538   152.36838
log_std/mean                          -0.14284    0.00024    -0.14235    -0.14311
log_std/std                           0.01110     0.00039    0.01162     0.01045
log_std/max                           -0.11875    0.00115    -0.11664    -0.12021
log_std/min                           -0.17594    0.00221    -0.17301    -0.17849
log_probs/mean                        -2.71791    0.00825    -2.70906    -2.73113
log_probs/std                         0.29470     0.00958    0.30978     0.27326
log_probs/max                         -1.90232    0.04181    -1.80457    -1.97081
log_probs/min                         -5.03950    0.32495    -4.68419    -5.78637
mean/mean                             -0.01496    0.00066    -0.01396    -0.01601
mean/std                              0.07845     0.00083    0.07946     0.07701
mean/max                              0.09357     0.00102    0.09476     0.09210
mean/min                              -0.20313    0.00464    -0.19561    -0.20951
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 4, 3, 0, 7, 9, 2, 6, 1, 8]
replay_buffer._size: [8250 8250 8250 8250 8250 8250 8250 8250 8250 8250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.429650068283081 0.0020258426666259766
train_time 2.4329299926757812
2023-09-06 13:54:58,916 MainThread INFO: EPOCH:53
2023-09-06 13:54:58,916 MainThread INFO: Time Consumed:2.4435582160949707s
2023-09-06 13:54:58,917 MainThread INFO: Total Frames:81000s
 14%|‚ñà‚ñé        | 54/400 [01:38<14:36,  2.53s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               481.68066
Train_Epoch_Reward                    17016.25605
Running_Training_Average_Rewards      750.74987
Explore_Time                          0.00278
Train___Time                          2.43293
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.03123
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.42191
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.33962
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.66999
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.44841
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.55594
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  301.33965
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4893.12313
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.96082
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.22909
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.51305      0.49840    8.24996     6.42337
alpha_0                               0.85153      0.00073    0.85268     0.85039
alpha_1                               0.85141      0.00073    0.85257     0.85027
alpha_2                               0.85150      0.00073    0.85265     0.85035
alpha_3                               0.85142      0.00073    0.85257     0.85027
alpha_4                               0.85147      0.00073    0.85262     0.85032
alpha_5                               0.85146      0.00073    0.85261     0.85031
alpha_6                               0.85147      0.00073    0.85261     0.85032
alpha_7                               0.85147      0.00073    0.85262     0.85032
alpha_8                               0.85151      0.00073    0.85265     0.85036
alpha_9                               0.85150      0.00073    0.85265     0.85035
Alpha_loss                            -1.07842     0.00644    -1.06807    -1.08752
Training/policy_loss                  -6.68016     0.03375    -6.62962    -6.73850
Training/qf1_loss                     1212.91441   234.93255  1696.74902  1006.69171
Training/qf2_loss                     1219.97126   235.22933  1704.53052  1012.08270
Training/pf_norm                      0.12407      0.01603    0.14704     0.09406
Training/qf1_norm                     181.92994    13.36725   200.68608   153.04144
Training/qf2_norm                     182.00476    12.97473   200.50400   154.22639
log_std/mean                          -0.14172     0.00033    -0.14141    -0.14236
log_std/std                           0.01147      0.00010    0.01161     0.01134
log_std/max                           -0.11598     0.00057    -0.11525    -0.11698
log_std/min                           -0.17513     0.00227    -0.17148    -0.17783
log_probs/mean                        -2.71960     0.00850    -2.70062    -2.73232
log_probs/std                         0.29781      0.01128    0.31491     0.27502
log_probs/max                         -1.87429     0.05329    -1.79055    -1.96088
log_probs/min                         -5.26496     0.52594    -4.49530    -6.34231
mean/mean                             -0.01656     0.00012    -0.01628    -0.01673
mean/std                              0.08045      0.00069    0.08177     0.07968
mean/max                              0.09630      0.00155    0.09931     0.09460
mean/min                              -0.21495     0.00204    -0.21174    -0.21786
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 0, 8, 5, 7, 4, 6, 1, 9, 2]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.362751007080078 0.0019636154174804688
train_time 2.3659143447875977
2023-09-06 13:55:01,397 MainThread INFO: EPOCH:54
2023-09-06 13:55:01,397 MainThread INFO: Time Consumed:2.3761513233184814s
2023-09-06 13:55:01,398 MainThread INFO: Total Frames:82500s
 14%|‚ñà‚ñç        | 55/400 [01:41<14:32,  2.53s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               493.11283
Train_Epoch_Reward                    4582.45324
Running_Training_Average_Rewards      818.57753
Explore_Time                          0.00273
Train___Time                          2.36591
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.28179
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.62884
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.46489
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.56431
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.07837
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.10463
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  315.57886
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4896.94466
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.43478
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.02220
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.75733     0.64777    8.70355     6.85413
alpha_0                               0.84899     0.00073    0.85013     0.84785
alpha_1                               0.84886     0.00073    0.85001     0.84772
alpha_2                               0.84895     0.00073    0.85010     0.84781
alpha_3                               0.84887     0.00073    0.85001     0.84772
alpha_4                               0.84892     0.00073    0.85007     0.84778
alpha_5                               0.84891     0.00073    0.85005     0.84776
alpha_6                               0.84892     0.00073    0.85006     0.84777
alpha_7                               0.84892     0.00073    0.85006     0.84777
alpha_8                               0.84896     0.00073    0.85011     0.84782
alpha_9                               0.84895     0.00073    0.85009     0.84780
Alpha_loss                            -1.09815    0.00542    -1.09005    -1.10718
Training/policy_loss                  -6.79454    0.03025    -6.75085    -6.83930
Training/qf1_loss                     1286.15220  439.34580  1901.28882  706.55487
Training/qf2_loss                     1293.64184  439.71386  1909.74634  713.84393
Training/pf_norm                      0.12686     0.02041    0.17160     0.10259
Training/qf1_norm                     192.85719   15.84974   215.26202   171.29494
Training/qf2_norm                     192.99690   15.80340   215.89256   171.51562
log_std/mean                          -0.14069    0.00029    -0.14039    -0.14129
log_std/std                           0.01157     0.00015    0.01187     0.01140
log_std/max                           -0.11388    0.00062    -0.11319    -0.11530
log_std/min                           -0.17166    0.00168    -0.16968    -0.17447
log_probs/mean                        -2.71716    0.00829    -2.70051    -2.72919
log_probs/std                         0.30337     0.00994    0.32224     0.29212
log_probs/max                         -1.84251    0.06118    -1.75807    -1.95905
log_probs/min                         -4.83401    0.40051    -4.16130    -5.43552
mean/mean                             -0.01644    0.00031    -0.01572    -0.01665
mean/std                              0.08426     0.00129    0.08625     0.08223
mean/max                              0.10645     0.00388    0.11396     0.10090
mean/min                              -0.22834    0.00497    -0.22035    -0.23786
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 7, 0, 8, 5, 6, 2, 9, 3, 1]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.5794427394866943 0.0020575523376464844
train_time 1.5827405452728271
2023-09-06 13:55:03,828 MainThread INFO: EPOCH:55
2023-09-06 13:55:03,828 MainThread INFO: Time Consumed:2.286571979522705s
2023-09-06 13:55:03,828 MainThread INFO: Total Frames:84000s
 14%|‚ñà‚ñç        | 56/400 [01:43<14:15,  2.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               496.08867
Train_Epoch_Reward                    7540.77205
Running_Training_Average_Rewards      971.31604
Explore_Time                          0.69704
Train___Time                          1.58274
Eval____Time                          0.00291
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.09997
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.75197
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.46745
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.48275
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42341
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.11898
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  329.47010
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4795.83763
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.83463
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.21782
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.10839     0.53123    7.97105     5.95513
alpha_0                               0.84645     0.00073    0.84759     0.84531
alpha_1                               0.84632     0.00073    0.84746     0.84518
alpha_2                               0.84642     0.00073    0.84756     0.84528
alpha_3                               0.84632     0.00073    0.84747     0.84518
alpha_4                               0.84638     0.00073    0.84752     0.84524
alpha_5                               0.84636     0.00073    0.84751     0.84522
alpha_6                               0.84637     0.00073    0.84752     0.84523
alpha_7                               0.84638     0.00073    0.84752     0.84524
alpha_8                               0.84642     0.00073    0.84756     0.84528
alpha_9                               0.84641     0.00073    0.84755     0.84527
Alpha_loss                            -1.11746    0.00602    -1.10717    -1.12768
Training/policy_loss                  -6.91206    0.03712    -6.85069    -6.96870
Training/qf1_loss                     1080.36353  310.74352  1518.84106  531.20331
Training/qf2_loss                     1087.27996  311.03449  1525.67578  537.04358
Training/pf_norm                      0.12183     0.01886    0.15564     0.07882
Training/qf1_norm                     178.89789   13.31463   199.91835   149.58748
Training/qf2_norm                     179.51711   13.30353   200.52170   150.74490
log_std/mean                          -0.14210    0.00056    -0.14120    -0.14299
log_std/std                           0.01214     0.00018    0.01239     0.01183
log_std/max                           -0.11373    0.00039    -0.11336    -0.11433
log_std/min                           -0.17579    0.00310    -0.16938    -0.18014
log_probs/mean                        -2.71215    0.00737    -2.70394    -2.72765
log_probs/std                         0.31146     0.01247    0.32818     0.28457
log_probs/max                         -1.80551    0.03124    -1.75617    -1.85287
log_probs/min                         -4.95911    0.50216    -4.09456    -5.56093
mean/mean                             -0.01431    0.00071    -0.01318    -0.01542
mean/std                              0.08925     0.00149    0.09126     0.08675
mean/max                              0.12342     0.00564    0.13167     0.11267
mean/min                              -0.24527    0.00661    -0.23158    -0.25477
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 9, 5, 6, 7, 1, 0, 3, 8, 4]
replay_buffer._size: [8700 8700 8700 8700 8700 8700 8700 8700 8700 8700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.137890577316284 0.0020384788513183594
train_time 9.141217470169067
2023-09-06 13:55:13,087 MainThread INFO: EPOCH:56
2023-09-06 13:55:13,087 MainThread INFO: Time Consumed:9.153940677642822s
2023-09-06 13:55:13,088 MainThread INFO: Total Frames:85500s
 14%|‚ñà‚ñç        | 57/400 [01:52<25:54,  4.53s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               502.04858
Train_Epoch_Reward                    6016.47212
Running_Training_Average_Rewards      604.65658
Explore_Time                          0.00345
Train___Time                          9.14122
Eval____Time                          0.00466
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.99448
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.69878
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.63207
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.28964
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.76229
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.53066
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  354.08041
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5003.78556
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.11227
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.24286
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.34414     0.66003    8.67231     6.44682
alpha_0                               0.84393     0.00072    0.84506     0.84279
alpha_1                               0.84379     0.00073    0.84493     0.84265
alpha_2                               0.84388     0.00073    0.84502     0.84275
alpha_3                               0.84379     0.00073    0.84493     0.84265
alpha_4                               0.84385     0.00073    0.84499     0.84272
alpha_5                               0.84383     0.00073    0.84497     0.84269
alpha_6                               0.84384     0.00073    0.84498     0.84271
alpha_7                               0.84385     0.00072    0.84498     0.84271
alpha_8                               0.84389     0.00073    0.84503     0.84275
alpha_9                               0.84388     0.00073    0.84501     0.84274
Alpha_loss                            -1.13779    0.00590    -1.12950    -1.14669
Training/policy_loss                  -7.03041    0.03124    -6.97247    -7.07134
Training/qf1_loss                     1023.34738  296.12414  1687.81018  724.07574
Training/qf2_loss                     1031.13984  296.74063  1696.57654  730.69885
Training/pf_norm                      0.12410     0.02131    0.15686     0.09293
Training/qf1_norm                     191.94480   18.38478   227.92325   167.18196
Training/qf2_norm                     192.12207   18.16127   227.90356   167.83397
log_std/mean                          -0.14383    0.00023    -0.14331    -0.14418
log_std/std                           0.01253     0.00006    0.01260     0.01241
log_std/max                           -0.11518    0.00040    -0.11463    -0.11595
log_std/min                           -0.17978    0.00138    -0.17813    -0.18201
log_probs/mean                        -2.71350    0.00670    -2.69922    -2.72163
log_probs/std                         0.31784     0.00904    0.33989     0.30781
log_probs/max                         -1.76355    0.08465    -1.63205    -1.87860
log_probs/min                         -5.26931    0.71055    -4.22996    -6.38781
mean/mean                             -0.01229    0.00032    -0.01199    -0.01293
mean/std                              0.09377     0.00115    0.09549     0.09177
mean/max                              0.13890     0.00333    0.14307     0.13302
mean/min                              -0.26152    0.00400    -0.25439    -0.26710
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 3, 5, 0, 2, 8, 6, 7, 1, 9]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.6001923084259033 0.001982450485229492
train_time 1.603398323059082
2023-09-06 13:55:15,934 MainThread INFO: EPOCH:57
2023-09-06 13:55:15,935 MainThread INFO: Time Consumed:1.8819684982299805s
2023-09-06 13:55:15,935 MainThread INFO: Total Frames:87000s
 14%|‚ñà‚ñç        | 58/400 [01:55<22:52,  4.01s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               517.57356
Train_Epoch_Reward                    5982.85794
Running_Training_Average_Rewards      651.33674
Explore_Time                          0.00532
Train___Time                          1.60340
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.79154
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.58772
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85520
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.07898
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.64745
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.82044
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  347.27480
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5338.51697
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.11455
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.20279
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.21676     0.54164    8.03365     6.00434
alpha_0                               0.84141     0.00072    0.84254     0.84028
alpha_1                               0.84126     0.00072    0.84240     0.84013
alpha_2                               0.84136     0.00072    0.84249     0.84022
alpha_3                               0.84126     0.00073    0.84240     0.84012
alpha_4                               0.84133     0.00072    0.84246     0.84020
alpha_5                               0.84130     0.00072    0.84244     0.84017
alpha_6                               0.84132     0.00072    0.84245     0.84018
alpha_7                               0.84133     0.00072    0.84246     0.84020
alpha_8                               0.84136     0.00072    0.84250     0.84023
alpha_9                               0.84135     0.00072    0.84249     0.84022
Alpha_loss                            -1.15674    0.00576    -1.14818    -1.16600
Training/policy_loss                  -7.14774    0.03441    -7.08827    -7.20104
Training/qf1_loss                     1019.10244  249.00606  1436.10730  548.29242
Training/qf2_loss                     1027.13898  249.41062  1444.65271  555.03662
Training/pf_norm                      0.12394     0.01825    0.16254     0.10013
Training/qf1_norm                     192.67766   15.59517   216.59900   157.11966
Training/qf2_norm                     192.85699   15.55225   217.02979   157.70732
log_std/mean                          -0.14327    0.00023    -0.14291    -0.14367
log_std/std                           0.01266     0.00010    0.01284     0.01254
log_std/max                           -0.11348    0.00105    -0.11198    -0.11512
log_std/min                           -0.17993    0.00153    -0.17713    -0.18155
log_probs/mean                        -2.70676    0.00841    -2.69180    -2.72665
log_probs/std                         0.32278     0.01240    0.35388     0.30888
log_probs/max                         -1.71019    0.06326    -1.61348    -1.82827
log_probs/min                         -5.21141    0.60595    -4.58442    -6.59875
mean/mean                             -0.01163    0.00012    -0.01144    -0.01184
mean/std                              0.09717     0.00063    0.09797     0.09597
mean/max                              0.14826     0.00148    0.15061     0.14644
mean/min                              -0.27776    0.00416    -0.27286    -0.28580
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 3, 5, 4, 6, 1, 0, 2, 9, 7]
replay_buffer._size: [9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.2744016647338867 0.0020592212677001953
train_time 2.277758836746216
2023-09-06 13:55:18,331 MainThread INFO: EPOCH:58
2023-09-06 13:55:18,331 MainThread INFO: Time Consumed:2.2895193099975586s
2023-09-06 13:55:18,332 MainThread INFO: Total Frames:88500s
 15%|‚ñà‚ñç        | 59/400 [01:57<20:03,  3.53s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               545.60415
Train_Epoch_Reward                    4065.43102
Running_Training_Average_Rewards      535.49204
Explore_Time                          0.00369
Train___Time                          2.27776
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.47772
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.64021
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.95599
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.90595
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.54624
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -15.87620
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  358.73384
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5607.81768
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.21340
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.10724
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.12944     0.52907    8.19064     6.60135
alpha_0                               0.83891     0.00072    0.84003     0.83779
alpha_1                               0.83874     0.00072    0.83987     0.83761
alpha_2                               0.83884     0.00072    0.83997     0.83771
alpha_3                               0.83874     0.00072    0.83987     0.83761
alpha_4                               0.83882     0.00072    0.83995     0.83769
alpha_5                               0.83879     0.00072    0.83992     0.83766
alpha_6                               0.83880     0.00072    0.83993     0.83767
alpha_7                               0.83882     0.00072    0.83995     0.83769
alpha_8                               0.83885     0.00072    0.83998     0.83772
alpha_9                               0.83883     0.00072    0.83997     0.83770
Alpha_loss                            -1.17774    0.00614    -1.16681    -1.18611
Training/policy_loss                  -7.27061    0.03353    -7.21768    -7.32220
Training/qf1_loss                     920.26309   163.97044  1198.48047  723.30884
Training/qf2_loss                     928.41633   164.17631  1206.51294  731.54047
Training/pf_norm                      0.14182     0.01460    0.16725     0.11593
Training/qf1_norm                     195.06714   14.41577   224.61609   180.10124
Training/qf2_norm                     195.50211   14.48005   224.66862   180.32024
log_std/mean                          -0.14187    0.00049    -0.14137    -0.14282
log_std/std                           0.01295     0.00008    0.01312     0.01285
log_std/max                           -0.11071    0.00049    -0.10995    -0.11159
log_std/min                           -0.17967    0.00169    -0.17806    -0.18301
log_probs/mean                        -2.71199    0.00817    -2.70114    -2.73001
log_probs/std                         0.33062     0.02024    0.36940     0.30717
log_probs/max                         -1.73520    0.09865    -1.59460    -1.86228
log_probs/min                         -5.48545    0.99864    -4.34579    -7.94058
mean/mean                             -0.01220    0.00017    -0.01187    -0.01243
mean/std                              0.09873     0.00066    0.10005     0.09807
mean/max                              0.14934     0.00209    0.15378     0.14667
mean/min                              -0.28760    0.00476    -0.28176    -0.29752
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 5, 7, 9, 6, 1, 0, 2, 4, 3]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.5135092735290527 0.002632617950439453
train_time 2.517805576324463
2023-09-06 13:55:20,965 MainThread INFO: EPOCH:59
2023-09-06 13:55:20,965 MainThread INFO: Time Consumed:2.53165340423584s
2023-09-06 13:55:20,966 MainThread INFO: Total Frames:90000s
 15%|‚ñà‚ñå        | 60/400 [02:00<18:31,  3.27s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               566.54659
Train_Epoch_Reward                    3779.85445
Running_Training_Average_Rewards      460.93811
Explore_Time                          0.00304
Train___Time                          2.51781
Eval____Time                          0.00595
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.00067
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.69091
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.05739
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.89422
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.99353
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.27712
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  323.96042
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5669.44755
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.37356
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.24443
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.07449     0.71377    8.27967     5.84441
alpha_0                               0.83641     0.00072    0.83754     0.83529
alpha_1                               0.83623     0.00072    0.83736     0.83510
alpha_2                               0.83633     0.00072    0.83746     0.83520
alpha_3                               0.83623     0.00072    0.83736     0.83510
alpha_4                               0.83631     0.00072    0.83743     0.83518
alpha_5                               0.83628     0.00072    0.83741     0.83516
alpha_6                               0.83629     0.00072    0.83742     0.83516
alpha_7                               0.83631     0.00072    0.83744     0.83519
alpha_8                               0.83634     0.00072    0.83747     0.83521
alpha_9                               0.83632     0.00072    0.83745     0.83519
Alpha_loss                            -1.19748    0.00577    -1.18551    -1.20534
Training/policy_loss                  -7.39234    0.03340    -7.33785    -7.44515
Training/qf1_loss                     992.29186   410.49566  1990.71130  483.42392
Training/qf2_loss                     1000.81230  411.18141  2000.23767  490.50293
Training/pf_norm                      0.13037     0.02248    0.16908     0.09542
Training/qf1_norm                     197.72551   21.36607   233.35995   160.23671
Training/qf2_norm                     198.05374   20.97926   233.50900   160.96495
log_std/mean                          -0.14200    0.00055    -0.14141    -0.14313
log_std/std                           0.01357     0.00026    0.01403     0.01325
log_std/max                           -0.11005    0.00035    -0.10965    -0.11074
log_std/min                           -0.18355    0.00252    -0.17981    -0.18721
log_probs/mean                        -2.70997    0.01325    -2.68845    -2.72701
log_probs/std                         0.34179     0.01668    0.36525     0.31828
log_probs/max                         -1.66191    0.06681    -1.54434    -1.77196
log_probs/min                         -5.63872    1.00553    -4.42258    -7.73818
mean/mean                             -0.01302    0.00037    -0.01246    -0.01340
mean/std                              0.10223     0.00115    0.10411     0.10054
mean/max                              0.15487     0.00286    0.15972     0.15150
mean/min                              -0.30299    0.00587    -0.29396    -0.31096
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 9, 3, 0, 6, 2, 1, 8, 5, 4]
replay_buffer._size: [9300 9300 9300 9300 9300 9300 9300 9300 9300 9300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.7520077228546143 0.0030183792114257812
train_time 1.756882905960083
2023-09-06 13:55:23,585 MainThread INFO: EPOCH:60
2023-09-06 13:55:23,585 MainThread INFO: Time Consumed:2.480325698852539s
2023-09-06 13:55:23,586 MainThread INFO: Total Frames:91500s
 15%|‚ñà‚ñå        | 61/400 [02:03<17:20,  3.07s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               593.96647
Train_Epoch_Reward                    7836.09892
Running_Training_Average_Rewards      522.71281
Explore_Time                          0.71353
Train___Time                          1.75688
Eval____Time                          0.00456
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.85953
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.82811
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26207
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.76835
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50589
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -13.46293
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  147.70978
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6359.61240
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.50067
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.84527
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.94590     0.79202    8.46981     6.11050
alpha_0                               0.83392     0.00071    0.83504     0.83281
alpha_1                               0.83372     0.00072    0.83485     0.83260
alpha_2                               0.83382     0.00072    0.83495     0.83270
alpha_3                               0.83372     0.00072    0.83485     0.83259
alpha_4                               0.83381     0.00072    0.83493     0.83269
alpha_5                               0.83379     0.00072    0.83491     0.83266
alpha_6                               0.83379     0.00072    0.83491     0.83267
alpha_7                               0.83381     0.00072    0.83494     0.83269
alpha_8                               0.83384     0.00072    0.83496     0.83272
alpha_9                               0.83382     0.00072    0.83494     0.83269
Alpha_loss                            -1.21694    0.00622    -1.20801    -1.22735
Training/policy_loss                  -7.51212    0.03597    -7.45198    -7.56256
Training/qf1_loss                     980.10703   357.88785  1687.21069  577.40509
Training/qf2_loss                     988.68809   358.72468  1697.64819  585.35413
Training/pf_norm                      0.12984     0.01929    0.15804     0.08598
Training/qf1_norm                     198.21619   25.08957   247.56535   173.21486
Training/qf2_norm                     198.84285   24.87552   247.69615   173.83839
log_std/mean                          -0.14476    0.00068    -0.14345    -0.14558
log_std/std                           0.01451     0.00024    0.01484     0.01411
log_std/max                           -0.11221    0.00080    -0.11103    -0.11363
log_std/min                           -0.19222    0.00231    -0.18927    -0.19566
log_probs/mean                        -2.70644    0.00968    -2.68894    -2.72365
log_probs/std                         0.33830     0.01266    0.37269     0.32814
log_probs/max                         -1.64298    0.03469    -1.58267    -1.70281
log_probs/min                         -4.98997    0.92791    -4.39215    -7.68593
mean/mean                             -0.01385    0.00025    -0.01349    -0.01420
mean/std                              0.10618     0.00113    0.10805     0.10437
mean/max                              0.16718     0.00344    0.17301     0.16256
mean/min                              -0.32590    0.00650    -0.31718    -0.33739
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 2, 9, 1, 6, 5, 0, 8, 4, 3]
replay_buffer._size: [9450 9450 9450 9450 9450 9450 9450 9450 9450 9450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.5042061805725098 0.0020258426666259766
train_time 2.507493734359741
2023-09-06 13:55:26,219 MainThread INFO: EPOCH:61
2023-09-06 13:55:26,220 MainThread INFO: Time Consumed:2.5176334381103516s
2023-09-06 13:55:26,220 MainThread INFO: Total Frames:93000s
 16%|‚ñà‚ñå        | 62/400 [02:05<16:35,  2.95s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               609.58954
Train_Epoch_Reward                    1068.36370
Running_Training_Average_Rewards      422.81057
Explore_Time                          0.00287
Train___Time                          2.50749
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.26685
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.96119
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29448
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.75246
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.56128
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -16.43961
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  157.53912
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6277.06553
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.87419
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.93384
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.67959     0.61949    7.47077     5.81025
alpha_0                               0.83145     0.00071    0.83256     0.83033
alpha_1                               0.83123     0.00072    0.83235     0.83010
alpha_2                               0.83132     0.00072    0.83245     0.83020
alpha_3                               0.83122     0.00072    0.83235     0.83010
alpha_4                               0.83132     0.00071    0.83244     0.83020
alpha_5                               0.83130     0.00071    0.83242     0.83018
alpha_6                               0.83130     0.00072    0.83242     0.83018
alpha_7                               0.83132     0.00071    0.83244     0.83020
alpha_8                               0.83135     0.00071    0.83247     0.83024
alpha_9                               0.83132     0.00072    0.83244     0.83020
Alpha_loss                            -1.23566    0.00586    -1.22698    -1.24435
Training/policy_loss                  -7.63961    0.03473    -7.58590    -7.69157
Training/qf1_loss                     875.19656   272.95764  1355.04749  508.29184
Training/qf2_loss                     883.71833   273.60869  1364.22363  515.66736
Training/pf_norm                      0.13147     0.02499    0.18501     0.09471
Training/qf1_norm                     193.17280   18.93530   218.17363   166.61482
Training/qf2_norm                     193.95964   18.69132   218.35968   167.48138
log_std/mean                          -0.14634    0.00024    -0.14581    -0.14660
log_std/std                           0.01508     0.00009    0.01519     0.01492
log_std/max                           -0.11487    0.00090    -0.11341    -0.11602
log_std/min                           -0.19407    0.00166    -0.19232    -0.19668
log_probs/mean                        -2.69916    0.01104    -2.67224    -2.71244
log_probs/std                         0.34467     0.01165    0.36584     0.32853
log_probs/max                         -1.63098    0.06600    -1.49658    -1.74891
log_probs/min                         -5.17016    0.55722    -4.24837    -6.50432
mean/mean                             -0.01505    0.00038    -0.01435    -0.01549
mean/std                              0.11083     0.00125    0.11252     0.10867
mean/max                              0.17969     0.00420    0.18679     0.17365
mean/min                              -0.34920    0.00823    -0.33704    -0.36283
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 9, 5, 0, 2, 8, 4, 3, 7, 1]
replay_buffer._size: [9600 9600 9600 9600 9600 9600 9600 9600 9600 9600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.5880486965179443 0.001987457275390625
train_time 1.5912623405456543
2023-09-06 13:55:29,040 MainThread INFO: EPOCH:62
2023-09-06 13:55:29,040 MainThread INFO: Time Consumed:1.6046288013458252s
2023-09-06 13:55:29,040 MainThread INFO: Total Frames:94500s
 16%|‚ñà‚ñå        | 63/400 [02:08<16:16,  2.90s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               616.13345
Train_Epoch_Reward                    996.68716
Running_Training_Average_Rewards      330.03833
Explore_Time                          0.00524
Train___Time                          1.59126
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.45621
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.06528
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26167
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.76441
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.69801
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -14.80788
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  275.16284
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5911.78657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.48166
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.22100
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.80735     0.85116    8.40733     5.54696
alpha_0                               0.82898     0.00071    0.83009     0.82787
alpha_1                               0.82874     0.00071    0.82985     0.82762
alpha_2                               0.82883     0.00071    0.82995     0.82771
alpha_3                               0.82873     0.00071    0.82985     0.82761
alpha_4                               0.82884     0.00071    0.82995     0.82772
alpha_5                               0.82882     0.00071    0.82993     0.82770
alpha_6                               0.82881     0.00071    0.82993     0.82769
alpha_7                               0.82884     0.00071    0.82996     0.82773
alpha_8                               0.82887     0.00071    0.82999     0.82776
alpha_9                               0.82884     0.00071    0.82996     0.82772
Alpha_loss                            -1.25585    0.00650    -1.24552    -1.26617
Training/policy_loss                  -7.76401    0.03914    -7.70514    -7.82005
Training/qf1_loss                     896.16983   328.18745  1450.74988  448.67520
Training/qf2_loss                     905.06199   329.18477  1460.07104  454.89374
Training/pf_norm                      0.12838     0.01623    0.15277     0.09613
Training/qf1_norm                     202.50553   27.82182   254.65164   159.04434
Training/qf2_norm                     203.40232   27.37629   254.78970   161.52570
log_std/mean                          -0.14565    0.00025    -0.14534    -0.14621
log_std/std                           0.01528     0.00020    0.01567     0.01502
log_std/max                           -0.11586    0.00032    -0.11541    -0.11651
log_std/min                           -0.19886    0.00150    -0.19703    -0.20214
log_probs/mean                        -2.69990    0.01013    -2.67655    -2.71212
log_probs/std                         0.35627     0.00863    0.37329     0.34256
log_probs/max                         -1.54638    0.06910    -1.45111    -1.66321
log_probs/min                         -5.15674    0.45227    -4.56597    -5.99813
mean/mean                             -0.01516    0.00015    -0.01496    -0.01542
mean/std                              0.11366     0.00059    0.11463     0.11278
mean/max                              0.19026     0.00153    0.19285     0.18785
mean/min                              -0.36838    0.00225    -0.36456    -0.37222
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 7, 0, 5, 1, 4, 2, 8, 3, 9]
replay_buffer._size: [9750 9750 9750 9750 9750 9750 9750 9750 9750 9750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.5231480598449707 0.0019714832305908203
train_time 2.526322364807129
2023-09-06 13:55:31,678 MainThread INFO: EPOCH:63
2023-09-06 13:55:31,678 MainThread INFO: Time Consumed:2.5367369651794434s
2023-09-06 13:55:31,679 MainThread INFO: Total Frames:96000s
 16%|‚ñà‚ñå        | 64/400 [02:11<15:48,  2.82s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               598.30393
Train_Epoch_Reward                    2975.47755
Running_Training_Average_Rewards      168.01761
Explore_Time                          0.00311
Train___Time                          2.52632
Eval____Time                          0.00346
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.90639
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.23025
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.24885
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.66885
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.47367
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -12.38741
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  338.96908
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5627.85197
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.02630
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.47553
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.69595     0.59345    7.72577     5.54425
alpha_0                               0.82653     0.00070    0.82763     0.82543
alpha_1                               0.82626     0.00071    0.82737     0.82514
alpha_2                               0.82635     0.00071    0.82747     0.82523
alpha_3                               0.82625     0.00071    0.82737     0.82513
alpha_4                               0.82636     0.00071    0.82747     0.82525
alpha_5                               0.82635     0.00071    0.82746     0.82524
alpha_6                               0.82633     0.00071    0.82744     0.82522
alpha_7                               0.82637     0.00071    0.82748     0.82526
alpha_8                               0.82640     0.00071    0.82751     0.82529
alpha_9                               0.82636     0.00071    0.82747     0.82525
Alpha_loss                            -1.27438    0.00575    -1.26674    -1.28203
Training/policy_loss                  -7.89301    0.03839    -7.83581    -7.94241
Training/qf1_loss                     875.17483   307.15400  1359.17883  476.81183
Training/qf2_loss                     884.20720   307.95611  1369.54126  483.80194
Training/pf_norm                      0.12515     0.02145    0.15468     0.08656
Training/qf1_norm                     202.84047   19.67771   236.12439   165.21404
Training/qf2_norm                     203.93650   19.19774   236.67435   167.55951
log_std/mean                          -0.14486    0.00058    -0.14379    -0.14562
log_std/std                           0.01612     0.00019    0.01636     0.01579
log_std/max                           -0.11480    0.00061    -0.11364    -0.11554
log_std/min                           -0.20646    0.00266    -0.20084    -0.20864
log_probs/mean                        -2.69205    0.00809    -2.67710    -2.70327
log_probs/std                         0.34791     0.00940    0.36427     0.33681
log_probs/max                         -1.49580    0.12429    -1.27324    -1.68083
log_probs/min                         -4.89965    0.43021    -4.25946    -5.86798
mean/mean                             -0.01508    0.00016    -0.01490    -0.01541
mean/std                              0.11617     0.00071    0.11696     0.11490
mean/max                              0.20004     0.00403    0.20480     0.19215
mean/min                              -0.38409    0.00710    -0.37007    -0.39267
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 9, 2, 4, 8, 5, 7, 0, 3, 1]
replay_buffer._size: [9900 9900 9900 9900 9900 9900 9900 9900 9900 9900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.905093193054199 0.0026400089263916016
train_time 2.9093449115753174
2023-09-06 13:55:34,713 MainThread INFO: EPOCH:64
2023-09-06 13:55:34,713 MainThread INFO: Time Consumed:2.9236109256744385s
2023-09-06 13:55:34,714 MainThread INFO: Total Frames:97500s
 16%|‚ñà‚ñã        | 65/400 [02:14<16:09,  2.89s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               592.30423
Train_Epoch_Reward                    5837.45862
Running_Training_Average_Rewards      326.98744
Explore_Time                          0.00284
Train___Time                          2.90934
Eval____Time                          0.00526
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.47355
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.41137
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.38050
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.33111
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.75130
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.72719
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  267.01296
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5992.28042
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.35291
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.33557
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.13132     0.68554    8.50992     6.31120
alpha_0                               0.82409     0.00070    0.82518     0.82299
alpha_1                               0.82379     0.00071    0.82490     0.82268
alpha_2                               0.82387     0.00071    0.82498     0.82276
alpha_3                               0.82377     0.00071    0.82489     0.82266
alpha_4                               0.82389     0.00071    0.82500     0.82278
alpha_5                               0.82388     0.00071    0.82499     0.82278
alpha_6                               0.82386     0.00071    0.82497     0.82275
alpha_7                               0.82391     0.00071    0.82502     0.82280
alpha_8                               0.82393     0.00071    0.82504     0.82283
alpha_9                               0.82389     0.00071    0.82500     0.82278
Alpha_loss                            -1.29547    0.00551    -1.28557    -1.30464
Training/policy_loss                  -8.02667    0.03871    -7.95851    -8.08539
Training/qf1_loss                     1080.69858  366.56535  1860.67163  614.63953
Training/qf2_loss                     1090.63035  367.45647  1872.27930  623.76282
Training/pf_norm                      0.14817     0.02292    0.20019     0.12170
Training/qf1_norm                     223.37478   23.97276   267.73932   193.77084
Training/qf2_norm                     224.48260   23.68500   268.23041   195.03865
log_std/mean                          -0.14351    0.00008    -0.14340    -0.14364
log_std/std                           0.01649     0.00009    0.01665     0.01633
log_std/max                           -0.11430    0.00047    -0.11361    -0.11494
log_std/min                           -0.20608    0.00246    -0.20158    -0.21028
log_probs/mean                        -2.69764    0.00662    -2.68472    -2.71161
log_probs/std                         0.35441     0.01320    0.38622     0.33868
log_probs/max                         -1.45129    0.13230    -1.23640    -1.60732
log_probs/min                         -4.94721    0.46414    -4.24755    -5.66544
mean/mean                             -0.01565    0.00007    -0.01553    -0.01573
mean/std                              0.11864     0.00119    0.12066     0.11707
mean/max                              0.20607     0.00421    0.21191     0.19946
mean/min                              -0.39694    0.00905    -0.38164    -0.40881
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 0, 9, 3, 5, 1, 2, 8, 4, 6]
replay_buffer._size: [10050 10050 10050 10050 10050 10050 10050 10050 10050 10050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.620187759399414 0.001981019973754883
train_time 1.6234345436096191
2023-09-06 13:55:37,526 MainThread INFO: EPOCH:65
2023-09-06 13:55:37,526 MainThread INFO: Time Consumed:1.635073184967041s
2023-09-06 13:55:37,527 MainThread INFO: Total Frames:99000s
 16%|‚ñà‚ñã        | 66/400 [02:17<15:55,  2.86s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               612.39978
Train_Epoch_Reward                    14276.80171
Running_Training_Average_Rewards      769.65793
Explore_Time                          0.00349
Train___Time                          1.62343
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.34239
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.81291
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47342
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.94489
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.47370
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.41654
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.23841
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6795.32840
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.68274
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.88381
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.69159      0.43614    7.42115     6.08051
alpha_0                               0.82165      0.00070    0.82275     0.82056
alpha_1                               0.82132      0.00071    0.82243     0.82022
alpha_2                               0.82140      0.00071    0.82251     0.82029
alpha_3                               0.82130      0.00071    0.82241     0.82020
alpha_4                               0.82143      0.00071    0.82254     0.82033
alpha_5                               0.82143      0.00071    0.82253     0.82032
alpha_6                               0.82139      0.00071    0.82250     0.82028
alpha_7                               0.82145      0.00071    0.82255     0.82034
alpha_8                               0.82148      0.00070    0.82258     0.82038
alpha_9                               0.82143      0.00071    0.82254     0.82033
Alpha_loss                            -1.31462     0.00623    -1.30439    -1.32297
Training/policy_loss                  -8.16295     0.03910    -8.09700    -8.21547
Training/qf1_loss                     855.06580    335.10642  1672.12891  524.71124
Training/qf2_loss                     864.67380    335.65112  1682.99316  533.94055
Training/pf_norm                      0.13780      0.01437    0.15813     0.11397
Training/qf1_norm                     210.95501    15.72348   240.46121   192.00362
Training/qf2_norm                     212.40445    15.59904   241.83952   193.18149
log_std/mean                          -0.14377     0.00016    -0.14348    -0.14404
log_std/std                           0.01673      0.00009    0.01688     0.01661
log_std/max                           -0.11584     0.00036    -0.11522    -0.11642
log_std/min                           -0.20906     0.00182    -0.20722    -0.21175
log_probs/mean                        -2.69319     0.01189    -2.67782    -2.71661
log_probs/std                         0.36954      0.01369    0.39013     0.34432
log_probs/max                         -1.30596     0.10090    -1.07485    -1.41550
log_probs/min                         -5.09540     0.54448    -4.39482    -5.95090
mean/mean                             -0.01600     0.00009    -0.01581    -0.01610
mean/std                              0.12351      0.00140    0.12573     0.12119
mean/max                              0.21959      0.00438    0.22638     0.21328
mean/min                              -0.42349     0.00827    -0.41069    -0.43653
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 3, 6, 8, 2, 0, 7, 1, 9, 5]
replay_buffer._size: [10200 10200 10200 10200 10200 10200 10200 10200 10200 10200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.7133171558380127 0.001987934112548828
train_time 2.7165231704711914
2023-09-06 13:55:40,362 MainThread INFO: EPOCH:66
2023-09-06 13:55:40,363 MainThread INFO: Time Consumed:2.726114273071289s
2023-09-06 13:55:40,363 MainThread INFO: Total Frames:100500s
 17%|‚ñà‚ñã        | 67/400 [02:20<15:52,  2.86s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               646.71331
Train_Epoch_Reward                    1862.47911
Running_Training_Average_Rewards      732.55798
Explore_Time                          0.00286
Train___Time                          2.71652
Eval____Time                          0.00295
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.75985
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.08538
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.57469
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.77355
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.89198
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.33523
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.36219
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7000.61524
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.16988
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.85268
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.67267     0.58569    7.58358     5.80553
alpha_0                               0.81923     0.00069    0.82032     0.81815
alpha_1                               0.81886     0.00070    0.81997     0.81776
alpha_2                               0.81894     0.00071    0.82005     0.81783
alpha_3                               0.81884     0.00070    0.81995     0.81774
alpha_4                               0.81898     0.00070    0.82008     0.81788
alpha_5                               0.81897     0.00070    0.82008     0.81787
alpha_6                               0.81893     0.00071    0.82004     0.81783
alpha_7                               0.81900     0.00070    0.82010     0.81790
alpha_8                               0.81904     0.00070    0.82013     0.81794
alpha_9                               0.81898     0.00070    0.82008     0.81788
Alpha_loss                            -1.33288    0.00494    -1.32456    -1.33884
Training/policy_loss                  -8.29706    0.04262    -8.24014    -8.36260
Training/qf1_loss                     860.22258   262.06951  1513.50000  517.39551
Training/qf2_loss                     870.22812   262.92286  1525.77161  525.89569
Training/pf_norm                      0.13594     0.02100    0.17859     0.11199
Training/qf1_norm                     213.95609   21.09871   249.58646   181.60657
Training/qf2_norm                     215.40827   20.42359   249.76411   184.06227
log_std/mean                          -0.14557    0.00088    -0.14415    -0.14681
log_std/std                           0.01720     0.00024    0.01753     0.01687
log_std/max                           -0.11770    0.00088    -0.11634    -0.11911
log_std/min                           -0.21192    0.00238    -0.20695    -0.21560
log_probs/mean                        -2.68444    0.00746    -2.66934    -2.69463
log_probs/std                         0.37962     0.01651    0.40525     0.35595
log_probs/max                         -1.30488    0.14839    -1.07636    -1.50184
log_probs/min                         -5.50995    0.95024    -4.49996    -7.71469
mean/mean                             -0.01584    0.00010    -0.01560    -0.01600
mean/std                              0.12963     0.00238    0.13342     0.12626
mean/max                              0.23857     0.00666    0.24770     0.22846
mean/min                              -0.45281    0.01131    -0.43329    -0.46921
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 7, 3, 5, 9, 2, 0, 4, 8, 1]
replay_buffer._size: [10350 10350 10350 10350 10350 10350 10350 10350 10350 10350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.685582160949707 0.001979827880859375
train_time 1.6887755393981934
2023-09-06 13:55:43,292 MainThread INFO: EPOCH:67
2023-09-06 13:55:43,292 MainThread INFO: Time Consumed:1.700782060623169s
2023-09-06 13:55:43,292 MainThread INFO: Total Frames:102000s
 17%|‚ñà‚ñã        | 68/400 [02:22<15:56,  2.88s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               673.57073
Train_Epoch_Reward                    11374.20056
Running_Training_Average_Rewards      917.11605
Explore_Time                          0.00406
Train___Time                          1.68878
Eval____Time                          0.00391
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -35.71015
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33645
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.61352
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.89595
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.40812
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.44827
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.25622
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7055.69525
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.86416
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.90982
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.80649      0.68473    8.42046     5.80472
alpha_0                               0.81683      0.00069    0.81791     0.81575
alpha_1                               0.81641      0.00070    0.81752     0.81531
alpha_2                               0.81648      0.00070    0.81759     0.81538
alpha_3                               0.81640      0.00070    0.81750     0.81530
alpha_4                               0.81654      0.00070    0.81764     0.81544
alpha_5                               0.81653      0.00070    0.81763     0.81543
alpha_6                               0.81648      0.00070    0.81758     0.81538
alpha_7                               0.81656      0.00070    0.81766     0.81547
alpha_8                               0.81660      0.00070    0.81769     0.81550
alpha_9                               0.81653      0.00070    0.81763     0.81544
Alpha_loss                            -1.35272     0.00641    -1.34179    -1.36081
Training/policy_loss                  -8.43960     0.04020    -8.38401    -8.50209
Training/qf1_loss                     960.81669    347.83908  1706.90796  512.39032
Training/qf2_loss                     971.17317    349.05779  1721.05798  521.36633
Training/pf_norm                      0.15333      0.03613    0.22424     0.11221
Training/qf1_norm                     223.65777    26.56509   286.74756   185.33583
Training/qf2_norm                     225.41614    25.97721   286.74408   187.56906
log_std/mean                          -0.14725     0.00037    -0.14693    -0.14806
log_std/std                           0.01835      0.00059    0.01941     0.01760
log_std/max                           -0.11925     0.00024    -0.11885    -0.11965
log_std/min                           -0.21627     0.00392    -0.20959    -0.22242
log_probs/mean                        -2.68385     0.01734    -2.66061    -2.71525
log_probs/std                         0.38682      0.01061    0.40164     0.36657
log_probs/max                         -1.22734     0.15637    -0.93679    -1.43233
log_probs/min                         -5.17155     0.75118    -4.20733    -7.15299
mean/mean                             -0.01447     0.00075    -0.01313    -0.01546
mean/std                              0.13649      0.00203    0.14010     0.13390
mean/max                              0.25747      0.00693    0.26844     0.24757
mean/min                              -0.48406     0.01035    -0.46785    -0.49849
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 4, 1, 3, 5, 7, 6, 0, 8, 9]
replay_buffer._size: [10500 10500 10500 10500 10500 10500 10500 10500 10500 10500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.7112958431243896 0.0021653175354003906
train_time 1.7148871421813965
2023-09-06 13:55:46,284 MainThread INFO: EPOCH:68
2023-09-06 13:55:46,284 MainThread INFO: Time Consumed:1.7689130306243896s
2023-09-06 13:55:46,285 MainThread INFO: Total Frames:103500s
 17%|‚ñà‚ñã        | 69/400 [02:25<16:02,  2.91s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               711.90307
Train_Epoch_Reward                    3363.98192
Running_Training_Average_Rewards      553.35539
Explore_Time                          0.04706
Train___Time                          1.71489
Eval____Time                          0.00264
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.42048
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.59967
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.79609
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.52698
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.03333
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.27647
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.44443
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7938.86657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.16327
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.57618
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.28425     0.44941    6.99706     5.40609
alpha_0                               0.81443     0.00068    0.81551     0.81336
alpha_1                               0.81397     0.00070    0.81507     0.81287
alpha_2                               0.81404     0.00070    0.81514     0.81294
alpha_3                               0.81395     0.00070    0.81505     0.81286
alpha_4                               0.81411     0.00070    0.81520     0.81301
alpha_5                               0.81409     0.00070    0.81519     0.81300
alpha_6                               0.81404     0.00070    0.81514     0.81295
alpha_7                               0.81413     0.00070    0.81522     0.81304
alpha_8                               0.81416     0.00070    0.81526     0.81307
alpha_9                               0.81410     0.00070    0.81519     0.81300
Alpha_loss                            -1.37112    0.00665    -1.35945    -1.38282
Training/policy_loss                  -8.57857    0.04487    -8.50530    -8.66093
Training/qf1_loss                     655.82603   192.90835  1106.63232  388.60626
Training/qf2_loss                     665.91074   193.66390  1118.01172  397.23520
Training/pf_norm                      0.13983     0.02273    0.17223     0.10187
Training/qf1_norm                     207.84335   17.65366   236.89149   173.76572
Training/qf2_norm                     209.73960   17.23126   238.19684   176.29480
log_std/mean                          -0.14883    0.00027    -0.14828    -0.14920
log_std/std                           0.02018     0.00034    0.02056     0.01945
log_std/max                           -0.12056    0.00073    -0.11934    -0.12154
log_std/min                           -0.23312    0.00354    -0.22740    -0.23813
log_probs/mean                        -2.67627    0.00970    -2.66087    -2.68948
log_probs/std                         0.40580     0.01554    0.44126     0.38837
log_probs/max                         -1.12942    0.13911    -0.89313    -1.39101
log_probs/min                         -5.14553    0.61480    -4.27738    -6.06334
mean/mean                             -0.01130    0.00078    -0.01046    -0.01276
mean/std                              0.14341     0.00170    0.14590     0.14058
mean/max                              0.28114     0.00426    0.28837     0.27455
mean/min                              -0.52005    0.00812    -0.50923    -0.53410
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 3, 5, 7, 6, 4, 0, 1, 9, 2]
replay_buffer._size: [10650 10650 10650 10650 10650 10650 10650 10650 10650 10650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.212123155593872 0.002121448516845703
train_time 3.2155210971832275
2023-09-06 13:55:49,628 MainThread INFO: EPOCH:69
2023-09-06 13:55:49,629 MainThread INFO: Time Consumed:3.2293646335601807s
2023-09-06 13:55:49,629 MainThread INFO: Total Frames:105000s
 18%|‚ñà‚ñä        | 70/400 [02:29<16:43,  3.04s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               741.08292
Train_Epoch_Reward                    14258.70416
Running_Training_Average_Rewards      966.56289
Explore_Time                          0.00514
Train___Time                          3.21552
Eval____Time                          0.00371
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.49576
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.46571
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.93791
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.29784
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.99768
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -9.81768
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.37092
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7867.56754
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.10111
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.87770
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.63079      0.72371    8.24998     5.66356
alpha_0                               0.81206      0.00068    0.81313     0.81100
alpha_1                               0.81153      0.00070    0.81263     0.81044
alpha_2                               0.81160      0.00070    0.81269     0.81050
alpha_3                               0.81152      0.00070    0.81261     0.81042
alpha_4                               0.81168      0.00070    0.81277     0.81059
alpha_5                               0.81167      0.00070    0.81276     0.81058
alpha_6                               0.81161      0.00070    0.81270     0.81052
alpha_7                               0.81171      0.00069    0.81280     0.81062
alpha_8                               0.81173      0.00070    0.81283     0.81064
alpha_9                               0.81167      0.00070    0.81276     0.81058
Alpha_loss                            -1.39103     0.00639    -1.38247    -1.39998
Training/policy_loss                  -8.72149     0.03844    -8.66751    -8.78477
Training/qf1_loss                     894.35030    328.64648  1655.74927  546.31415
Training/qf2_loss                     904.91870    329.66460  1669.35962  555.59717
Training/pf_norm                      0.14303      0.02126    0.17426     0.11079
Training/qf1_norm                     224.72156    29.45332   292.70847   187.80154
Training/qf2_norm                     227.02808    29.09608   294.17380   190.30026
log_std/mean                          -0.14712     0.00081    -0.14620    -0.14852
log_std/std                           0.02040      0.00007    0.02052     0.02031
log_std/max                           -0.12030     0.00093    -0.11888    -0.12175
log_std/min                           -0.23663     0.00318    -0.23080    -0.23960
log_probs/mean                        -2.67623     0.00884    -2.65818    -2.69216
log_probs/std                         0.41219      0.00955    0.42995     0.39798
log_probs/max                         -0.96542     0.12628    -0.68384    -1.08218
log_probs/min                         -5.12882     0.42848    -4.41983    -5.84499
mean/mean                             -0.01091     0.00048    -0.01037    -0.01173
mean/std                              0.14856      0.00151    0.15147     0.14646
mean/max                              0.29321      0.00631    0.30207     0.28178
mean/min                              -0.54260     0.01269    -0.51926    -0.55973
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 2, 1, 6, 7, 5, 0, 8, 9, 3]
replay_buffer._size: [10800 10800 10800 10800 10800 10800 10800 10800 10800 10800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.8271842002868652 0.001978635787963867
train_time 2.830371379852295
2023-09-06 13:55:52,591 MainThread INFO: EPOCH:70
2023-09-06 13:55:52,591 MainThread INFO: Time Consumed:2.8403244018554688s
2023-09-06 13:55:52,592 MainThread INFO: Total Frames:106500s
 18%|‚ñà‚ñä        | 71/400 [02:32<16:31,  3.01s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               741.42280
Train_Epoch_Reward                    5599.62968
Running_Training_Average_Rewards      774.07719
Explore_Time                          0.00337
Train___Time                          2.83037
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.75851
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.11674
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.06590
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.06673
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.63812
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94117
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.35260
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7084.08285
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.24753
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.44635
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.27393     0.92827    9.05006     6.05448
alpha_0                               0.80971     0.00067    0.81077     0.80866
alpha_1                               0.80910     0.00070    0.81019     0.80801
alpha_2                               0.80916     0.00070    0.81026     0.80807
alpha_3                               0.80909     0.00070    0.81018     0.80800
alpha_4                               0.80925     0.00070    0.81034     0.80816
alpha_5                               0.80925     0.00069    0.81033     0.80816
alpha_6                               0.80919     0.00070    0.81028     0.80810
alpha_7                               0.80930     0.00069    0.81038     0.80821
alpha_8                               0.80931     0.00070    0.81040     0.80822
alpha_9                               0.80925     0.00069    0.81034     0.80817
Alpha_loss                            -1.40834    0.00613    -1.39851    -1.41893
Training/policy_loss                  -8.87037    0.04278    -8.80039    -8.94157
Training/qf1_loss                     1089.65341  501.79610  1954.49146  502.67221
Training/qf2_loss                     1101.89136  503.30952  1968.33960  513.35083
Training/pf_norm                      0.13489     0.02455    0.19308     0.10201
Training/qf1_norm                     255.17616   37.35516   326.61731   208.23138
Training/qf2_norm                     257.19259   36.90642   327.56659   210.32297
log_std/mean                          -0.14711    0.00052    -0.14625    -0.14778
log_std/std                           0.02130     0.00040    0.02180     0.02064
log_std/max                           -0.11929    0.00032    -0.11878    -0.11995
log_std/min                           -0.24393    0.00539    -0.23583    -0.25042
log_probs/mean                        -2.66390    0.01017    -2.64890    -2.67875
log_probs/std                         0.42800     0.01501    0.45793     0.41062
log_probs/max                         -0.85890    0.11432    -0.65992    -1.11273
log_probs/min                         -5.22866    0.63596    -4.42353    -6.39776
mean/mean                             -0.01225    0.00035    -0.01183    -0.01277
mean/std                              0.15560     0.00188    0.15817     0.15235
mean/max                              0.30874     0.00675    0.31674     0.29817
mean/min                              -0.57235    0.01357    -0.55092    -0.58857
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 6, 7, 8, 4, 2, 0, 5, 1, 9]
replay_buffer._size: [10950 10950 10950 10950 10950 10950 10950 10950 10950 10950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.035982608795166 0.001996278762817383
train_time 3.0399081707000732
2023-09-06 13:55:55,748 MainThread INFO: EPOCH:71
2023-09-06 13:55:55,748 MainThread INFO: Time Consumed:3.050861120223999s
2023-09-06 13:55:55,749 MainThread INFO: Total Frames:108000s
 18%|‚ñà‚ñä        | 72/400 [02:35<16:43,  3.06s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               703.58414
Train_Epoch_Reward                    1718.94506
Running_Training_Average_Rewards      719.24263
Explore_Time                          0.00318
Train___Time                          3.03991
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.05494
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.44608
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.98819
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.35927
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.25846
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -26.22936
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -11.98426
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6819.12562
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -36.13455
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.80072
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.33572     0.49115    7.20959     5.38733
alpha_0                               0.80738     0.00067    0.80843     0.80634
alpha_1                               0.80668     0.00069    0.80777     0.80559
alpha_2                               0.80674     0.00070    0.80783     0.80565
alpha_3                               0.80667     0.00069    0.80775     0.80558
alpha_4                               0.80683     0.00069    0.80792     0.80575
alpha_5                               0.80684     0.00069    0.80792     0.80575
alpha_6                               0.80677     0.00069    0.80786     0.80569
alpha_7                               0.80689     0.00069    0.80797     0.80581
alpha_8                               0.80689     0.00069    0.80798     0.80581
alpha_9                               0.80684     0.00069    0.80792     0.80576
Alpha_loss                            -1.42784    0.00668    -1.41899    -1.43870
Training/policy_loss                  -9.01637    0.04208    -8.95233    -9.08732
Training/qf1_loss                     709.08536   198.38739  1089.56152  428.69635
Training/qf2_loss                     719.96493   199.30859  1102.69678  437.32413
Training/pf_norm                      0.13505     0.01316    0.16119     0.11603
Training/qf1_norm                     219.58218   20.23431   256.95612   180.78224
Training/qf2_norm                     222.29255   19.74658   258.44031   184.45465
log_std/mean                          -0.14723    0.00061    -0.14618    -0.14797
log_std/std                           0.02191     0.00008    0.02204     0.02179
log_std/max                           -0.11921    0.00054    -0.11851    -0.11997
log_std/min                           -0.24849    0.00225    -0.24505    -0.25262
log_probs/mean                        -2.66226    0.01065    -2.63477    -2.67347
log_probs/std                         0.43032     0.01007    0.45472     0.42062
log_probs/max                         -0.80462    0.11072    -0.59862    -0.96029
log_probs/min                         -5.04143    0.41419    -4.45667    -5.75619
mean/mean                             -0.01326    0.00026    -0.01291    -0.01366
mean/std                              0.16125     0.00140    0.16338     0.15892
mean/max                              0.31826     0.00346    0.32691     0.31457
mean/min                              -0.59461    0.00831    -0.58563    -0.61538
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 2, 1, 3, 4, 5, 9, 8, 0, 7]
replay_buffer._size: [11100 11100 11100 11100 11100 11100 11100 11100 11100 11100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.8323428630828857 0.002440929412841797
train_time 2.836095094680786
2023-09-06 13:55:58,707 MainThread INFO: EPOCH:72
2023-09-06 13:55:58,707 MainThread INFO: Time Consumed:2.8464126586914062s
2023-09-06 13:55:58,708 MainThread INFO: Total Frames:109500s
 18%|‚ñà‚ñä        | 73/400 [02:38<16:30,  3.03s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               693.58607
Train_Epoch_Reward                    9112.64439
Running_Training_Average_Rewards      547.70730
Explore_Time                          0.00419
Train___Time                          2.83610
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.72019
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.06946
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.03923
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.19458
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.89684
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.37727
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.09117
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7591.84675
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -36.68508
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.50988
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.67378     0.64847    7.76642     5.66946
alpha_0                               0.80506     0.00067    0.80610     0.80402
alpha_1                               0.80427     0.00069    0.80535     0.80318
alpha_2                               0.80432     0.00069    0.80541     0.80324
alpha_3                               0.80425     0.00069    0.80534     0.80317
alpha_4                               0.80443     0.00069    0.80551     0.80335
alpha_5                               0.80443     0.00069    0.80551     0.80335
alpha_6                               0.80437     0.00069    0.80545     0.80329
alpha_7                               0.80450     0.00069    0.80557     0.80342
alpha_8                               0.80449     0.00069    0.80557     0.80341
alpha_9                               0.80444     0.00069    0.80552     0.80336
Alpha_loss                            -1.44598    0.00502    -1.43674    -1.45206
Training/policy_loss                  -9.17197    0.04622    -9.10325    -9.24060
Training/qf1_loss                     815.96683   332.56369  1644.15552  423.34259
Training/qf2_loss                     827.91471   333.61404  1658.09888  432.76263
Training/pf_norm                      0.15628     0.02921    0.23379     0.12674
Training/qf1_norm                     239.05924   27.60521   285.44641   195.20314
Training/qf2_norm                     241.79027   27.20787   288.03760   199.36713
log_std/mean                          -0.14613    0.00034    -0.14568    -0.14667
log_std/std                           0.02189     0.00010    0.02207     0.02174
log_std/max                           -0.11708    0.00042    -0.11660    -0.11805
log_std/min                           -0.25168    0.00261    -0.24580    -0.25454
log_probs/mean                        -2.65445    0.01047    -2.64140    -2.67354
log_probs/std                         0.44983     0.01262    0.47135     0.43363
log_probs/max                         -0.74245    0.15204    -0.37821    -0.97654
log_probs/min                         -5.12112    0.58226    -4.57876    -6.31655
mean/mean                             -0.01343    0.00021    -0.01294    -0.01362
mean/std                              0.16715     0.00224    0.17056     0.16407
mean/max                              0.33479     0.00685    0.34678     0.32456
mean/min                              -0.62926    0.01232    -0.60789    -0.64897
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 1, 0, 4, 8, 2, 6, 3, 7, 5]
replay_buffer._size: [11250 11250 11250 11250 11250 11250 11250 11250 11250 11250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.007276773452759 0.0029022693634033203
train_time 3.0120303630828857
2023-09-06 13:56:01,842 MainThread INFO: EPOCH:73
2023-09-06 13:56:01,843 MainThread INFO: Time Consumed:3.023918628692627s
2023-09-06 13:56:01,843 MainThread INFO: Total Frames:111000s
 18%|‚ñà‚ñä        | 74/400 [02:41<16:37,  3.06s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               727.20128
Train_Epoch_Reward                    11826.40780
Running_Training_Average_Rewards      755.26657
Explore_Time                          0.00330
Train___Time                          3.01203
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.13961
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.51631
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.20432
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.97390
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.68189
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.55262
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.38057
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8096.65655
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -37.02831
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.27334
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.27847      0.37138    7.06228    5.72560
alpha_0                               0.80275      0.00066    0.80379    0.80171
alpha_1                               0.80186      0.00069    0.80294    0.80078
alpha_2                               0.80191      0.00069    0.80299    0.80083
alpha_3                               0.80184      0.00069    0.80293    0.80076
alpha_4                               0.80203      0.00069    0.80311    0.80096
alpha_5                               0.80204      0.00069    0.80312    0.80097
alpha_6                               0.80197      0.00069    0.80305    0.80089
alpha_7                               0.80211      0.00069    0.80318    0.80103
alpha_8                               0.80209      0.00069    0.80317    0.80102
alpha_9                               0.80205      0.00069    0.80312    0.80098
Alpha_loss                            -1.46466     0.00621    -1.45707   -1.47290
Training/policy_loss                  -9.31976     0.04494    -9.25799   -9.37849
Training/qf1_loss                     641.18481    131.42257  937.61359  458.42807
Training/qf2_loss                     652.25275    132.07921  950.56006  468.47784
Training/pf_norm                      0.15453      0.02071    0.18769    0.11364
Training/qf1_norm                     224.94463    17.34309   261.85889  201.66638
Training/qf2_norm                     228.32350    17.06045   264.60989  205.05965
log_std/mean                          -0.14663     0.00065    -0.14602   -0.14790
log_std/std                           0.02172      0.00011    0.02190    0.02153
log_std/max                           -0.11708     0.00080    -0.11600   -0.11864
log_std/min                           -0.25090     0.00282    -0.24666   -0.25449
log_probs/mean                        -2.64932     0.01344    -2.62598   -2.67087
log_probs/std                         0.46679      0.01128    0.48552    0.44771
log_probs/max                         -0.61503     0.11728    -0.43778   -0.81641
log_probs/min                         -5.40443     0.60571    -4.44246   -6.49729
mean/mean                             -0.01219     0.00032    -0.01171   -0.01269
mean/std                              0.17252      0.00114    0.17458    0.17078
mean/max                              0.35052      0.00610    0.35846    0.34143
mean/min                              -0.65351     0.01166    -0.63547   -0.66903
------------------------------------  -----------  ---------  ---------  ---------
sample: [1, 4, 8, 0, 6, 5, 2, 3, 7, 9]
replay_buffer._size: [11400 11400 11400 11400 11400 11400 11400 11400 11400 11400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.786656618118286 0.0021927356719970703
train_time 2.790225028991699
2023-09-06 13:56:04,747 MainThread INFO: EPOCH:74
2023-09-06 13:56:04,748 MainThread INFO: Time Consumed:2.800143241882324s
2023-09-06 13:56:04,748 MainThread INFO: Total Frames:112500s
 19%|‚ñà‚ñâ        | 75/400 [02:44<16:20,  3.02s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               747.86828
Train_Epoch_Reward                    6623.28077
Running_Training_Average_Rewards      918.74443
Explore_Time                          0.00292
Train___Time                          2.79023
Eval____Time                          0.00287
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.78529
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.61722
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.21123
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.89142
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.74358
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -29.15998
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.10031
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7445.69764
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -37.60653
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.70251
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.58560     0.46674    7.27282     5.80846
alpha_0                               0.80045     0.00066    0.80148     0.79943
alpha_1                               0.79947     0.00069    0.80054     0.79839
alpha_2                               0.79951     0.00069    0.80059     0.79843
alpha_3                               0.79944     0.00069    0.80052     0.79836
alpha_4                               0.79964     0.00069    0.80072     0.79857
alpha_5                               0.79966     0.00068    0.80073     0.79859
alpha_6                               0.79958     0.00069    0.80065     0.79850
alpha_7                               0.79973     0.00068    0.80080     0.79866
alpha_8                               0.79971     0.00068    0.80078     0.79864
alpha_9                               0.79967     0.00068    0.80074     0.79860
Alpha_loss                            -1.48455    0.00737    -1.47473    -1.49764
Training/policy_loss                  -9.48405    0.05081    -9.41494    -9.56845
Training/qf1_loss                     762.51458   292.74406  1428.72534  453.75040
Training/qf2_loss                     774.92206   293.69491  1443.62964  464.59967
Training/pf_norm                      0.16375     0.02711    0.20150     0.11685
Training/qf1_norm                     242.80437   21.55163   277.55313   209.02489
Training/qf2_norm                     246.09999   21.11004   279.17496   212.70587
log_std/mean                          -0.15084    0.00161    -0.14847    -0.15349
log_std/std                           0.02134     0.00012    0.02151     0.02121
log_std/max                           -0.12355    0.00251    -0.11957    -0.12733
log_std/min                           -0.25793    0.00245    -0.25436    -0.26239
log_probs/mean                        -2.64981    0.01501    -2.62119    -2.67005
log_probs/std                         0.48419     0.01725    0.52753     0.46422
log_probs/max                         -0.64728    0.19081    -0.17202    -0.89108
log_probs/min                         -5.77642    0.72819    -5.04937    -7.44024
mean/mean                             -0.01159    0.00022    -0.01145    -0.01214
mean/std                              0.17862     0.00229    0.18241     0.17534
mean/max                              0.37332     0.00702    0.38433     0.36151
mean/min                              -0.68950    0.01113    -0.67360    -0.70919
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 9, 6, 5, 2, 8, 7, 1, 0, 3]
replay_buffer._size: [11550 11550 11550 11550 11550 11550 11550 11550 11550 11550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.989097833633423 0.0019919872283935547
train_time 2.992328643798828
2023-09-06 13:56:07,867 MainThread INFO: EPOCH:75
2023-09-06 13:56:07,867 MainThread INFO: Time Consumed:3.003358840942383s
2023-09-06 13:56:07,867 MainThread INFO: Total Frames:114000s
 19%|‚ñà‚ñâ        | 76/400 [02:47<16:25,  3.04s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               716.53910
Train_Epoch_Reward                    9860.18817
Running_Training_Average_Rewards      943.66256
Explore_Time                          0.00455
Train___Time                          2.99233
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.78532
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.74495
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.15685
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.98048
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.13767
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -35.80993
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  202.58595
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6443.39928
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.81338
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.16897
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.00271     0.58524    7.89645     6.01059
alpha_0                               0.79817     0.00065    0.79920     0.79715
alpha_1                               0.79708     0.00069    0.79815     0.79600
alpha_2                               0.79712     0.00069    0.79819     0.79604
alpha_3                               0.79705     0.00069    0.79813     0.79597
alpha_4                               0.79726     0.00068    0.79833     0.79619
alpha_5                               0.79728     0.00068    0.79835     0.79621
alpha_6                               0.79719     0.00068    0.79826     0.79612
alpha_7                               0.79735     0.00068    0.79842     0.79629
alpha_8                               0.79733     0.00068    0.79840     0.79626
alpha_9                               0.79729     0.00068    0.79836     0.79622
Alpha_loss                            -1.50234    0.00652    -1.49057    -1.51058
Training/policy_loss                  -9.64105    0.04475    -9.57211    -9.70649
Training/qf1_loss                     992.42893   318.65976  1510.37732  474.34003
Training/qf2_loss                     1005.86751  319.61324  1524.49878  486.59570
Training/pf_norm                      0.15272     0.04044    0.24617     0.11155
Training/qf1_norm                     266.33246   25.37574   308.84027   225.23198
Training/qf2_norm                     269.76701   24.95195   311.41180   229.14439
log_std/mean                          -0.15466    0.00044    -0.15382    -0.15515
log_std/std                           0.02207     0.00035    0.02266     0.02154
log_std/max                           -0.12677    0.00083    -0.12555    -0.12777
log_std/min                           -0.26545    0.00236    -0.26152    -0.26957
log_probs/mean                        -2.64105    0.01552    -2.61939    -2.66889
log_probs/std                         0.49292     0.01666    0.52818     0.46782
log_probs/max                         -0.40435    0.18337    -0.09440    -0.72381
log_probs/min                         -5.52214    0.81771    -4.77349    -7.41964
mean/mean                             -0.01405    0.00122    -0.01238    -0.01586
mean/std                              0.18730     0.00269    0.19159     0.18310
mean/max                              0.39129     0.00521    0.40130     0.38340
mean/min                              -0.73341    0.01580    -0.70857    -0.76201
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 2, 0, 6, 5, 8, 3, 9, 4, 7]
replay_buffer._size: [11700 11700 11700 11700 11700 11700 11700 11700 11700 11700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.8303463459014893 0.002016305923461914
train_time 2.833613634109497
2023-09-06 13:56:10,812 MainThread INFO: EPOCH:76
2023-09-06 13:56:10,812 MainThread INFO: Time Consumed:2.8436334133148193s
2023-09-06 13:56:10,812 MainThread INFO: Total Frames:115500s
 19%|‚ñà‚ñâ        | 77/400 [02:50<16:13,  3.02s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               663.88294
Train_Epoch_Reward                    9638.57811
Running_Training_Average_Rewards      870.73490
Explore_Time                          0.00300
Train___Time                          2.83361
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.66337
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.28324
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.07652
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.22123
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.46439
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -39.27416
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  378.62427
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6140.90430
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.03979
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.28504
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.85853     0.37901    7.73734     6.25807
alpha_0                               0.79591     0.00065    0.79693     0.79490
alpha_1                               0.79469     0.00068    0.79576     0.79362
alpha_2                               0.79473     0.00068    0.79580     0.79366
alpha_3                               0.79466     0.00068    0.79574     0.79359
alpha_4                               0.79488     0.00068    0.79595     0.79381
alpha_5                               0.79490     0.00068    0.79597     0.79384
alpha_6                               0.79481     0.00068    0.79588     0.79375
alpha_7                               0.79499     0.00068    0.79605     0.79392
alpha_8                               0.79496     0.00068    0.79602     0.79389
alpha_9                               0.79492     0.00068    0.79599     0.79386
Alpha_loss                            -1.51912    0.00464    -1.51158    -1.52763
Training/policy_loss                  -9.80662    0.04787    -9.73042    -9.88593
Training/qf1_loss                     824.33542   338.73012  1599.22302  527.87067
Training/qf2_loss                     837.79269   339.82158  1616.62000  539.99048
Training/pf_norm                      0.16712     0.01658    0.20016     0.13830
Training/qf1_norm                     262.59887   18.73274   305.25186   232.13403
Training/qf2_norm                     266.47090   18.26258   306.95758   236.09398
log_std/mean                          -0.15519    0.00023    -0.15477    -0.15555
log_std/std                           0.02299     0.00019    0.02325     0.02265
log_std/max                           -0.12526    0.00026    -0.12486    -0.12575
log_std/min                           -0.26990    0.00354    -0.26440    -0.27479
log_probs/mean                        -2.62816    0.01555    -2.60456    -2.65814
log_probs/std                         0.52581     0.01484    0.54807     0.50387
log_probs/max                         -0.21645    0.08090    -0.07527    -0.33526
log_probs/min                         -5.50426    0.37857    -5.22850    -6.55283
mean/mean                             -0.01575    0.00037    -0.01511    -0.01624
mean/std                              0.19821     0.00355    0.20335     0.19253
mean/max                              0.41077     0.00996    0.42593     0.39760
mean/min                              -0.77887    0.01685    -0.75561    -0.80291
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 7, 1, 6, 2, 0, 9, 3, 8, 4]
replay_buffer._size: [11850 11850 11850 11850 11850 11850 11850 11850 11850 11850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.1030983924865723 0.0019421577453613281
train_time 3.1062538623809814
2023-09-06 13:56:14,037 MainThread INFO: EPOCH:77
2023-09-06 13:56:14,037 MainThread INFO: Time Consumed:3.1156551837921143s
2023-09-06 13:56:14,037 MainThread INFO: Total Frames:117000s
 20%|‚ñà‚ñâ        | 78/400 [02:53<16:33,  3.09s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               638.86674
Train_Epoch_Reward                    12823.62233
Running_Training_Average_Rewards      1077.41295
Explore_Time                          0.00324
Train___Time                          3.10625
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.40878
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.08135
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.93126
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.45030
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.51941
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.28026
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  451.34012
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6248.79128
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.86819
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.19822
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.22732      0.49209    7.40942     5.55896
alpha_0                               0.79368      0.00064    0.79468     0.79268
alpha_1                               0.79232      0.00068    0.79339     0.79125
alpha_2                               0.79235      0.00068    0.79342     0.79129
alpha_3                               0.79229      0.00068    0.79336     0.79122
alpha_4                               0.79251      0.00068    0.79358     0.79145
alpha_5                               0.79254      0.00068    0.79360     0.79149
alpha_6                               0.79244      0.00068    0.79351     0.79138
alpha_7                               0.79263      0.00068    0.79369     0.79157
alpha_8                               0.79259      0.00068    0.79365     0.79152
alpha_9                               0.79257      0.00068    0.79362     0.79151
Alpha_loss                            -1.53735     0.00860    -1.52349    -1.54714
Training/policy_loss                  -9.97344     0.04656    -9.89620    -10.04324
Training/qf1_loss                     714.19421    284.97144  1307.18604  448.44952
Training/qf2_loss                     726.47195    285.84557  1321.66064  459.69849
Training/pf_norm                      0.17433      0.02754    0.22116     0.13279
Training/qf1_norm                     237.38490    23.34428   292.35437   207.76465
Training/qf2_norm                     242.09482    22.99093   296.15732   212.62610
log_std/mean                          -0.15470     0.00014    -0.15456    -0.15491
log_std/std                           0.02375      0.00046    0.02478     0.02331
log_std/max                           -0.12506     0.00134    -0.12220    -0.12685
log_std/min                           -0.27958     0.00420    -0.27345    -0.28652
log_probs/mean                        -2.62192     0.01802    -2.59590    -2.65908
log_probs/std                         0.54054      0.01129    0.55579     0.51722
log_probs/max                         -0.11557     0.12905    0.16318     -0.28203
log_probs/min                         -5.81664     0.70678    -4.79473    -6.91422
mean/mean                             -0.01297     0.00128    -0.01114    -0.01480
mean/std                              0.20717      0.00222    0.21125     0.20419
mean/max                              0.43655      0.00752    0.44741     0.42496
mean/min                              -0.81592     0.01141    -0.79696    -0.83269
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 0, 5, 9, 6, 8, 2, 1, 7, 3]
replay_buffer._size: [12000 12000 12000 12000 12000 12000 12000 12000 12000 12000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 1.8979477882385254 0.0019445419311523438
train_time 1.9010818004608154
2023-09-06 13:56:17,242 MainThread INFO: EPOCH:78
2023-09-06 13:56:17,242 MainThread INFO: Time Consumed:1.9114086627960205s
2023-09-06 13:56:17,243 MainThread INFO: Total Frames:118500s
 20%|‚ñà‚ñâ        | 79/400 [02:56<16:40,  3.12s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               650.49146
Train_Epoch_Reward                    9498.77921
Running_Training_Average_Rewards      1065.36599
Explore_Time                          0.00392
Train___Time                          1.90108
Eval____Time                          0.00216
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.73956
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.33532
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.09550
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.22316
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.98666
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.81964
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  472.55257
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6530.75837
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.88691
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.09487
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.47844     0.27771    7.00235     6.14991
alpha_0                               0.79146     0.00063    0.79246     0.79047
alpha_1                               0.78995     0.00068    0.79102     0.78889
alpha_2                               0.78999     0.00068    0.79105     0.78892
alpha_3                               0.78992     0.00068    0.79098     0.78885
alpha_4                               0.79015     0.00068    0.79122     0.78909
alpha_5                               0.79020     0.00067    0.79125     0.78914
alpha_6                               0.79008     0.00068    0.79114     0.78903
alpha_7                               0.79028     0.00067    0.79134     0.78923
alpha_8                               0.79023     0.00068    0.79129     0.78917
alpha_9                               0.79022     0.00067    0.79127     0.78916
Alpha_loss                            -1.55188    0.00516    -1.54240    -1.56036
Training/policy_loss                  -10.14410   0.04710    -10.06570   -10.21688
Training/qf1_loss                     766.97108   197.00044  1114.07727  512.31415
Training/qf2_loss                     780.19017   197.66302  1128.98108  525.68243
Training/pf_norm                      0.16846     0.01502    0.18873     0.14213
Training/qf1_norm                     252.75039   14.52518   279.99155   236.42145
Training/qf2_norm                     257.60684   14.25477   284.59952   240.88863
log_std/mean                          -0.15571    0.00030    -0.15517    -0.15618
log_std/std                           0.02664     0.00067    0.02744     0.02532
log_std/max                           -0.11875    0.00196    -0.11609    -0.12211
log_std/min                           -0.29543    0.00174    -0.29223    -0.29827
log_probs/mean                        -2.60019    0.01928    -2.56542    -2.62537
log_probs/std                         0.55756     0.02609    0.61326     0.53130
log_probs/max                         -0.03776    0.18138    0.17249     -0.37095
log_probs/min                         -5.25353    0.59602    -4.66568    -6.15984
mean/mean                             -0.00974    0.00042    -0.00941    -0.01076
mean/std                              0.21711     0.00222    0.21976     0.21275
mean/max                              0.46257     0.00453    0.47097     0.45527
mean/min                              -0.85886    0.00886    -0.84629    -0.87683
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 6, 4, 3, 7, 9, 0, 2, 8, 1]
replay_buffer._size: [12150 12150 12150 12150 12150 12150 12150 12150 12150 12150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.161182403564453 0.0020422935485839844
train_time 3.1644506454467773
2023-09-06 13:56:20,530 MainThread INFO: EPOCH:79
2023-09-06 13:56:20,531 MainThread INFO: Time Consumed:3.1751086711883545s
2023-09-06 13:56:20,531 MainThread INFO: Total Frames:120000s
 20%|‚ñà‚ñà        | 80/400 [03:00<16:55,  3.17s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               652.44315
Train_Epoch_Reward                    9326.97478
Running_Training_Average_Rewards      1054.97921
Explore_Time                          0.00305
Train___Time                          3.16445
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.22022
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.58132
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.25044
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.81844
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.89543
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -38.66068
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  234.46728
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6346.91808
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.29644
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.89079
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.43344     0.51663    7.31907     5.75020
alpha_0                               0.78927     0.00063    0.79026     0.78829
alpha_1                               0.78759     0.00068    0.78865     0.78653
alpha_2                               0.78762     0.00068    0.78869     0.78656
alpha_3                               0.78756     0.00068    0.78862     0.78650
alpha_4                               0.78780     0.00067    0.78886     0.78674
alpha_5                               0.78785     0.00067    0.78891     0.78680
alpha_6                               0.78774     0.00067    0.78879     0.78668
alpha_7                               0.78794     0.00067    0.78899     0.78689
alpha_8                               0.78788     0.00067    0.78894     0.78683
alpha_9                               0.78788     0.00067    0.78893     0.78683
Alpha_loss                            -1.57133    0.00528    -1.56476    -1.58391
Training/policy_loss                  -10.30946   0.05337    -10.21862   -10.39050
Training/qf1_loss                     765.31234   322.19763  1423.72693  442.81348
Training/qf2_loss                     778.74681   323.37936  1439.49170  453.76718
Training/pf_norm                      0.15484     0.01946    0.20027     0.12802
Training/qf1_norm                     253.50188   25.77692   299.30579   218.92477
Training/qf2_norm                     258.82535   25.26719   303.58212   225.64658
log_std/mean                          -0.15508    0.00017    -0.15473    -0.15529
log_std/std                           0.02713     0.00020    0.02738     0.02683
log_std/max                           -0.11676    0.00072    -0.11556    -0.11752
log_std/min                           -0.29367    0.00210    -0.28913    -0.29748
log_probs/mean                        -2.59983    0.01766    -2.56843    -2.62396
log_probs/std                         0.56720     0.01645    0.59077     0.53608
log_probs/max                         0.10791     0.21762    0.44138     -0.25168
log_probs/min                         -5.40756    0.40797    -4.59585    -5.94001
mean/mean                             -0.00875    0.00036    -0.00827    -0.00938
mean/std                              0.22277     0.00215    0.22640     0.21994
mean/max                              0.47624     0.00873    0.49240     0.46660
mean/min                              -0.88032    0.01335    -0.86392    -0.90567
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 0, 8, 6, 1, 9, 7, 4, 2, 5]
replay_buffer._size: [12300 12300 12300 12300 12300 12300 12300 12300 12300 12300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.164651393890381 0.0019469261169433594
train_time 3.167816162109375
2023-09-06 13:56:23,850 MainThread INFO: EPOCH:80
2023-09-06 13:56:23,850 MainThread INFO: Time Consumed:3.1806209087371826s
2023-09-06 13:56:23,851 MainThread INFO: Total Frames:121500s
 20%|‚ñà‚ñà        | 81/400 [03:03<17:05,  3.22s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               635.13031
Train_Epoch_Reward                    15921.94496
Running_Training_Average_Rewards      1158.25663
Explore_Time                          0.00542
Train___Time                          3.16782
Eval____Time                          0.00331
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -35.97622
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.12242
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.37054
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.62268
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.96956
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -36.65963
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -11.95653
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6183.40495
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.92697
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.79198
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.32214      0.56770    7.33745     5.39944
alpha_0                               0.78711      0.00062    0.78808     0.78614
alpha_1                               0.78524      0.00068    0.78630     0.78418
alpha_2                               0.78527      0.00068    0.78633     0.78421
alpha_3                               0.78520      0.00068    0.78626     0.78415
alpha_4                               0.78546      0.00067    0.78651     0.78440
alpha_5                               0.78552      0.00067    0.78657     0.78447
alpha_6                               0.78540      0.00067    0.78645     0.78435
alpha_7                               0.78562      0.00067    0.78666     0.78457
alpha_8                               0.78554      0.00067    0.78659     0.78449
alpha_9                               0.78555      0.00067    0.78660     0.78451
Alpha_loss                            -1.58875     0.00436    -1.58083    -1.59813
Training/policy_loss                  -10.48861    0.04993    -10.40246   -10.56026
Training/qf1_loss                     717.89157    339.74783  1477.60132  394.09613
Training/qf2_loss                     731.15395    340.89390  1493.98303  405.65125
Training/pf_norm                      0.16359      0.00796    0.17983     0.15299
Training/qf1_norm                     251.74583    30.59210   311.05075   204.39737
Training/qf2_norm                     257.62280    30.08686   315.69104   210.60199
log_std/mean                          -0.15629     0.00082    -0.15520    -0.15752
log_std/std                           0.02700      0.00033    0.02775     0.02667
log_std/max                           -0.11896     0.00091    -0.11769    -0.12005
log_std/min                           -0.29394     0.00343    -0.28796    -0.30108
log_probs/mean                        -2.59109     0.01417    -2.56765    -2.61472
log_probs/std                         0.60193      0.01675    0.63793     0.57558
log_probs/max                         0.21316      0.16989    0.50117     -0.06969
log_probs/min                         -5.90287     0.74546    -5.12551    -7.71346
mean/mean                             -0.00905     0.00040    -0.00872    -0.01006
mean/std                              0.23195      0.00332    0.23715     0.22692
mean/max                              0.50351      0.00708    0.51594     0.49386
mean/min                              -0.92115     0.01458    -0.90349    -0.95009
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 4, 9, 8, 2, 5, 0, 6, 3, 1]
replay_buffer._size: [12450 12450 12450 12450 12450 12450 12450 12450 12450 12450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.3379552364349365 0.002040386199951172
train_time 3.341226816177368
2023-09-06 13:56:27,341 MainThread INFO: EPOCH:81
2023-09-06 13:56:27,341 MainThread INFO: Time Consumed:3.353419065475464s
2023-09-06 13:56:27,342 MainThread INFO: Total Frames:123000s
 20%|‚ñà‚ñà        | 82/400 [03:06<17:28,  3.30s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               584.84365
Train_Epoch_Reward                    4118.37195
Running_Training_Average_Rewards      978.90972
Explore_Time                          0.00359
Train___Time                          3.34123
Eval____Time                          0.00385
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.48999
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.63882
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.32777
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.87210
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.92213
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -39.68072
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  180.31191
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5333.98636
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.72841
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.10893
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.56266     0.32552    7.14481     5.95014
alpha_0                               0.78497     0.00061    0.78593     0.78401
alpha_1                               0.78289     0.00067    0.78395     0.78184
alpha_2                               0.78292     0.00067    0.78397     0.78186
alpha_3                               0.78285     0.00067    0.78391     0.78180
alpha_4                               0.78312     0.00067    0.78417     0.78207
alpha_5                               0.78320     0.00067    0.78424     0.78216
alpha_6                               0.78307     0.00067    0.78411     0.78202
alpha_7                               0.78330     0.00066    0.78434     0.78226
alpha_8                               0.78320     0.00067    0.78425     0.78215
alpha_9                               0.78324     0.00067    0.78428     0.78220
Alpha_loss                            -1.60315    0.00207    -1.60027    -1.60650
Training/policy_loss                  -10.66489   0.04683    -10.59794   -10.73979
Training/qf1_loss                     742.10221   249.62502  1228.19458  435.41620
Training/qf2_loss                     756.25251   250.20784  1243.31714  448.43057
Training/pf_norm                      0.16819     0.01966    0.19838     0.13229
Training/qf1_norm                     266.44283   15.76021   291.61642   235.83432
Training/qf2_norm                     272.53612   15.31068   297.05081   242.59660
log_std/mean                          -0.15963    0.00124    -0.15789    -0.16144
log_std/std                           0.02935     0.00087    0.03055     0.02806
log_std/max                           -0.12105    0.00095    -0.11982    -0.12298
log_std/min                           -0.31136    0.00842    -0.29760    -0.32399
log_probs/mean                        -2.57023    0.01699    -2.53926    -2.59434
log_probs/std                         0.63773     0.01525    0.66544     0.61426
log_probs/max                         0.40378     0.11538    0.64858     0.25385
log_probs/min                         -6.00308    0.85269    -4.68425    -8.01949
mean/mean                             -0.01186    0.00067    -0.01056    -0.01255
mean/std                              0.24499     0.00401    0.25099     0.23877
mean/max                              0.52373     0.00939    0.53841     0.50706
mean/min                              -0.96951    0.01885    -0.93531    -0.99855
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 1, 8, 3, 7, 9, 6, 0, 2, 4]
replay_buffer._size: [12600 12600 12600 12600 12600 12600 12600 12600 12600 12600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.3986687660217285 0.0020799636840820312
train_time 3.40202260017395
2023-09-06 13:56:30,880 MainThread INFO: EPOCH:82
2023-09-06 13:56:30,880 MainThread INFO: Time Consumed:3.413546562194824s
2023-09-06 13:56:30,881 MainThread INFO: Total Frames:124500s
 21%|‚ñà‚ñà        | 83/400 [03:10<17:46,  3.36s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               520.60017
Train_Epoch_Reward                    5717.80508
Running_Training_Average_Rewards      858.60407
Explore_Time                          0.00320
Train___Time                          3.40202
Eval____Time                          0.00346
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.59267
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.91391
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.20845
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.44526
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.30882
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -43.37805
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  337.18831
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4352.71078
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -41.75792
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.82686
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.78138     0.61143    7.76332     5.78103
alpha_0                               0.78286     0.00060    0.78380     0.78191
alpha_1                               0.78055     0.00067    0.78160     0.77951
alpha_2                               0.78057     0.00067    0.78162     0.77952
alpha_3                               0.78051     0.00067    0.78157     0.77946
alpha_4                               0.78080     0.00067    0.78184     0.77976
alpha_5                               0.78089     0.00066    0.78193     0.77985
alpha_6                               0.78075     0.00066    0.78179     0.77971
alpha_7                               0.78100     0.00066    0.78203     0.77996
alpha_8                               0.78087     0.00067    0.78192     0.77983
alpha_9                               0.78093     0.00066    0.78196     0.77989
Alpha_loss                            -1.61865    0.00649    -1.60556    -1.62875
Training/policy_loss                  -10.85043   0.05400    -10.76174   -10.92372
Training/qf1_loss                     959.05363   246.15610  1298.44080  503.46133
Training/qf2_loss                     974.18607   247.19591  1312.65942  516.05292
Training/pf_norm                      0.16027     0.02719    0.19106     0.11934
Training/qf1_norm                     280.76727   31.35818   329.30194   226.45192
Training/qf2_norm                     287.10708   30.65882   334.96780   234.08234
log_std/mean                          -0.16162    0.00022    -0.16121    -0.16195
log_std/std                           0.03133     0.00043    0.03197     0.03066
log_std/max                           -0.12382    0.00038    -0.12315    -0.12439
log_std/min                           -0.32877    0.00459    -0.32142    -0.33515
log_probs/mean                        -2.55449    0.01079    -2.53675    -2.57255
log_probs/std                         0.65280     0.01833    0.68755     0.62509
log_probs/max                         0.46825     0.22631    0.73488     0.12067
log_probs/min                         -6.36085    1.08568    -5.46899    -8.96289
mean/mean                             -0.01320    0.00029    -0.01285    -0.01384
mean/std                              0.25546     0.00229    0.25889     0.25190
mean/max                              0.54459     0.00826    0.55583     0.53285
mean/min                              -1.00348    0.01291    -0.98428    -1.02075
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 1, 8, 5, 2, 7, 3, 6, 4]
replay_buffer._size: [12750 12750 12750 12750 12750 12750 12750 12750 12750 12750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.444354772567749 0.002026796340942383
train_time 3.447605848312378
2023-09-06 13:56:34,450 MainThread INFO: EPOCH:83
2023-09-06 13:56:34,451 MainThread INFO: Time Consumed:3.4575188159942627s
2023-09-06 13:56:34,451 MainThread INFO: Total Frames:126000s
 21%|‚ñà‚ñà        | 84/400 [03:14<18:03,  3.43s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               468.10056
Train_Epoch_Reward                    1164.37534
Running_Training_Average_Rewards      366.68508
Explore_Time                          0.00308
Train___Time                          3.44761
Eval____Time                          0.00262
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.38126
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.08331
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.15899
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.79694
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.90302
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -46.87638
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  673.42156
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3961.56585
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.25172
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.51562
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.40267     0.85191    7.55994     5.03403
alpha_0                               0.78077     0.00060    0.78171     0.77984
alpha_1                               0.77823     0.00067    0.77927     0.77718
alpha_2                               0.77823     0.00067    0.77928     0.77719
alpha_3                               0.77818     0.00067    0.77923     0.77714
alpha_4                               0.77848     0.00066    0.77952     0.77745
alpha_5                               0.77858     0.00066    0.77962     0.77754
alpha_6                               0.77845     0.00066    0.77948     0.77741
alpha_7                               0.77870     0.00066    0.77973     0.77767
alpha_8                               0.77855     0.00067    0.77959     0.77751
alpha_9                               0.77863     0.00066    0.77966     0.77760
Alpha_loss                            -1.63632    0.00572    -1.62554    -1.64474
Training/policy_loss                  -11.03581   0.05473    -10.96037   -11.12451
Training/qf1_loss                     772.85165   393.05210  1533.17358  354.82718
Training/qf2_loss                     787.37206   395.24881  1551.15894  365.87762
Training/pf_norm                      0.18640     0.02888    0.24931     0.14391
Training/qf1_norm                     265.16158   45.85496   328.12393   191.19661
Training/qf2_norm                     272.28471   45.08899   333.66470   199.28673
log_std/mean                          -0.16138    0.00008    -0.16125    -0.16155
log_std/std                           0.03265     0.00043    0.03333     0.03201
log_std/max                           -0.12420    0.00034    -0.12378    -0.12501
log_std/min                           -0.33870    0.00444    -0.32853    -0.34418
log_probs/mean                        -2.54795    0.01513    -2.52386    -2.57607
log_probs/std                         0.67062     0.02326    0.71597     0.63968
log_probs/max                         0.53061     0.19749    0.80691     0.26337
log_probs/min                         -6.39882    0.51551    -5.69166    -7.33276
mean/mean                             -0.01543    0.00062    -0.01418    -0.01603
mean/std                              0.26384     0.00292    0.26868     0.25960
mean/max                              0.55917     0.00684    0.56819     0.54627
mean/min                              -1.04117    0.01830    -1.00189    -1.06787
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 0, 3, 8, 1, 2, 6, 4, 7, 5]
replay_buffer._size: [12900 12900 12900 12900 12900 12900 12900 12900 12900 12900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.319289207458496 0.0019936561584472656
train_time 3.3224899768829346
2023-09-06 13:56:37,898 MainThread INFO: EPOCH:84
2023-09-06 13:56:37,898 MainThread INFO: Time Consumed:3.333951711654663s
2023-09-06 13:56:37,898 MainThread INFO: Total Frames:127500s
 21%|‚ñà‚ñà‚ñè       | 85/400 [03:17<18:02,  3.44s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               445.27493
Train_Epoch_Reward                    4615.74640
Running_Training_Average_Rewards      383.26423
Explore_Time                          0.00385
Train___Time                          3.32249
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.90234
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.49080
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.15410
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.97296
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.13693
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -48.50325
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  649.71442
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4194.42493
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.64352
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.57499
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.38718     0.49073    7.27954     5.70209
alpha_0                               0.77871     0.00059    0.77963     0.77779
alpha_1                               0.77590     0.00067    0.77695     0.77486
alpha_2                               0.77591     0.00067    0.77695     0.77486
alpha_3                               0.77586     0.00067    0.77690     0.77481
alpha_4                               0.77618     0.00066    0.77722     0.77514
alpha_5                               0.77628     0.00066    0.77731     0.77525
alpha_6                               0.77616     0.00066    0.77718     0.77513
alpha_7                               0.77641     0.00066    0.77744     0.77539
alpha_8                               0.77624     0.00066    0.77728     0.77521
alpha_9                               0.77633     0.00066    0.77737     0.77530
Alpha_loss                            -1.65051    0.00876    -1.63098    -1.66284
Training/policy_loss                  -11.22542   0.05802    -11.13631   -11.32178
Training/qf1_loss                     650.71917   212.29562  1107.22583  437.91202
Training/qf2_loss                     665.73203   213.70608  1125.83472  451.25952
Training/pf_norm                      0.17397     0.04860    0.28654     0.11361
Training/qf1_norm                     268.01993   27.93740   319.50742   228.99155
Training/qf2_norm                     275.49527   27.26462   325.18082   237.10936
log_std/mean                          -0.16054    0.00050    -0.15993    -0.16119
log_std/std                           0.03464     0.00050    0.03541     0.03369
log_std/max                           -0.12105    0.00159    -0.11902    -0.12373
log_std/min                           -0.34473    0.00174    -0.34169    -0.34828
log_probs/mean                        -2.52787    0.02228    -2.46918    -2.55022
log_probs/std                         0.68980     0.01675    0.71951     0.66720
log_probs/max                         0.77542     0.15965    1.03392     0.56899
log_probs/min                         -5.94767    0.89417    -4.74665    -7.53149
mean/mean                             -0.01533    0.00063    -0.01413    -0.01597
mean/std                              0.27285     0.00179    0.27619     0.26986
mean/max                              0.57178     0.00671    0.58312     0.56177
mean/min                              -1.06701    0.00507    -1.05788    -1.07682
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 5, 7, 2, 0, 6, 8, 9, 1, 3]
replay_buffer._size: [13050 13050 13050 13050 13050 13050 13050 13050 13050 13050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.5519301891326904 0.0019788742065429688
train_time 3.555119514465332
2023-09-06 13:56:41,584 MainThread INFO: EPOCH:85
2023-09-06 13:56:41,585 MainThread INFO: Time Consumed:3.5655431747436523s
2023-09-06 13:56:41,585 MainThread INFO: Total Frames:129000s
 22%|‚ñà‚ñà‚ñè       | 86/400 [03:21<18:23,  3.51s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               470.55210
Train_Epoch_Reward                    7194.65648
Running_Training_Average_Rewards      432.49261
Explore_Time                          0.00276
Train___Time                          3.55512
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.75211
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.58118
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.36178
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.98968
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.38602
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -48.69210
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  602.19621
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4850.93187
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.41903
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.16368
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.27926     0.52582    6.87041     5.18766
alpha_0                               0.77668     0.00058    0.77759     0.77577
alpha_1                               0.77359     0.00066    0.77463     0.77255
alpha_2                               0.77359     0.00066    0.77463     0.77255
alpha_3                               0.77354     0.00067    0.77458     0.77250
alpha_4                               0.77388     0.00066    0.77491     0.77285
alpha_5                               0.77400     0.00065    0.77503     0.77298
alpha_6                               0.77388     0.00065    0.77490     0.77285
alpha_7                               0.77413     0.00065    0.77516     0.77311
alpha_8                               0.77394     0.00066    0.77498     0.77291
alpha_9                               0.77405     0.00065    0.77508     0.77303
Alpha_loss                            -1.66674    0.00640    -1.65318    -1.67557
Training/policy_loss                  -11.41929   0.05478    -11.32683   -11.50000
Training/qf1_loss                     718.81848   279.35645  1288.35461  377.48276
Training/qf2_loss                     733.88963   280.48853  1304.99939  389.72568
Training/pf_norm                      0.18534     0.03173    0.23069     0.13970
Training/qf1_norm                     263.83957   29.41406   298.55862   201.11519
Training/qf2_norm                     271.78510   28.75851   306.00266   210.35963
log_std/mean                          -0.16067    0.00025    -0.16034    -0.16112
log_std/std                           0.03628     0.00044    0.03706     0.03557
log_std/max                           -0.11988    0.00037    -0.11909    -0.12030
log_std/min                           -0.35305    0.00404    -0.34725    -0.35979
log_probs/mean                        -2.51637    0.01585    -2.49687    -2.55484
log_probs/std                         0.71843     0.02452    0.75654     0.68289
log_probs/max                         0.88813     0.21379    1.18362     0.44323
log_probs/min                         -5.89077    0.62880    -4.99654    -6.94226
mean/mean                             -0.01274    0.00082    -0.01158    -0.01390
mean/std                              0.28205     0.00336    0.28726     0.27692
mean/max                              0.59985     0.00975    0.61647     0.58383
mean/min                              -1.09168    0.01432    -1.07056    -1.11411
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 5, 7, 2, 0, 6, 1, 4, 8, 9]
replay_buffer._size: [13200 13200 13200 13200 13200 13200 13200 13200 13200 13200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.4693048000335693 0.0020749568939208984
train_time 3.4726669788360596
2023-09-06 13:56:45,200 MainThread INFO: EPOCH:86
2023-09-06 13:56:45,201 MainThread INFO: Time Consumed:3.4843037128448486s
2023-09-06 13:56:45,201 MainThread INFO: Total Frames:130500s
 22%|‚ñà‚ñà‚ñè       | 87/400 [03:24<18:31,  3.55s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               502.48556
Train_Epoch_Reward                    5165.42661
Running_Training_Average_Rewards      565.86098
Explore_Time                          0.00348
Train___Time                          3.47267
Eval____Time                          0.00351
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.94118
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.74691
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.43108
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.77434
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.55369
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -16.17313
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  549.39914
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5015.72152
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.40750
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.06897
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.32336     0.50429    7.38222     5.53195
alpha_0                               0.77467     0.00057    0.77557     0.77377
alpha_1                               0.77129     0.00066    0.77232     0.77026
alpha_2                               0.77128     0.00066    0.77232     0.77024
alpha_3                               0.77122     0.00066    0.77226     0.77019
alpha_4                               0.77160     0.00065    0.77262     0.77057
alpha_5                               0.77173     0.00065    0.77275     0.77070
alpha_6                               0.77160     0.00065    0.77263     0.77058
alpha_7                               0.77186     0.00065    0.77288     0.77084
alpha_8                               0.77165     0.00066    0.77268     0.77062
alpha_9                               0.77179     0.00065    0.77281     0.77077
Alpha_loss                            -1.68117    0.00606    -1.67281    -1.69013
Training/policy_loss                  -11.61356   0.05565    -11.52955   -11.70437
Training/qf1_loss                     713.16201   244.97320  1111.69263  376.55389
Training/qf2_loss                     728.54773   246.11553  1127.62622  388.96484
Training/pf_norm                      0.16549     0.02223    0.20436     0.13304
Training/qf1_norm                     269.23179   30.71891   332.73605   220.93858
Training/qf2_norm                     277.68463   30.13126   339.62125   230.63281
log_std/mean                          -0.16168    0.00056    -0.16110    -0.16277
log_std/std                           0.03807     0.00055    0.03883     0.03719
log_std/max                           -0.12046    0.00098    -0.11958    -0.12246
log_std/min                           -0.36169    0.00465    -0.35127    -0.36744
log_probs/mean                        -2.49825    0.00718    -2.48433    -2.50710
log_probs/std                         0.74563     0.01938    0.78025     0.71922
log_probs/max                         1.04134     0.18040    1.47299     0.81551
log_probs/min                         -6.11027    0.93684    -4.99457    -8.06745
mean/mean                             -0.00881    0.00142    -0.00683    -0.01121
mean/std                              0.29279     0.00268    0.29723     0.28851
mean/max                              0.63330     0.01367    0.65206     0.60704
mean/min                              -1.11448    0.01352    -1.08403    -1.12844
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 3, 8, 9, 7, 1, 6, 5, 4]
replay_buffer._size: [13350 13350 13350 13350 13350 13350 13350 13350 13350 13350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.257798671722412 0.002865314483642578
train_time 2.2624573707580566
2023-09-06 13:56:49,076 MainThread INFO: EPOCH:87
2023-09-06 13:56:49,077 MainThread INFO: Time Consumed:2.348560333251953s
2023-09-06 13:56:49,078 MainThread INFO: Total Frames:132000s
 22%|‚ñà‚ñà‚ñè       | 88/400 [03:28<18:55,  3.64s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               517.84623
Train_Epoch_Reward                    9234.07460
Running_Training_Average_Rewards      719.80526
Explore_Time                          0.07734
Train___Time                          2.26246
Eval____Time                          0.00313
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.53292
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.82869
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.83027
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.63175
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.81691
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -48.38014
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  536.09998
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4772.81991
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.11137
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.20717
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.40793     0.56810    7.62252     5.61924
alpha_0                               0.77268     0.00057    0.77357     0.77180
alpha_1                               0.76900     0.00066    0.77003     0.76797
alpha_2                               0.76898     0.00066    0.77001     0.76794
alpha_3                               0.76892     0.00066    0.76995     0.76788
alpha_4                               0.76933     0.00065    0.77035     0.76831
alpha_5                               0.76946     0.00065    0.77048     0.76844
alpha_6                               0.76934     0.00065    0.77036     0.76832
alpha_7                               0.76960     0.00065    0.77062     0.76858
alpha_8                               0.76936     0.00066    0.77039     0.76834
alpha_9                               0.76953     0.00065    0.77054     0.76851
Alpha_loss                            -1.69665    0.00628    -1.68452    -1.70399
Training/policy_loss                  -11.81498   0.06035    -11.73121   -11.92122
Training/qf1_loss                     671.58621   266.23761  1163.91711  382.84375
Training/qf2_loss                     687.20839   267.72800  1182.44824  396.01117
Training/pf_norm                      0.16979     0.02707    0.21933     0.11558
Training/qf1_norm                     277.05598   33.68664   349.64240   228.25844
Training/qf2_norm                     286.16793   33.26326   357.78696   237.89789
log_std/mean                          -0.16479    0.00070    -0.16327    -0.16546
log_std/std                           0.04040     0.00083    0.04159     0.03900
log_std/max                           -0.12570    0.00131    -0.12310    -0.12734
log_std/min                           -0.37899    0.00405    -0.37355    -0.38414
log_probs/mean                        -2.48464    0.02323    -2.45656    -2.53326
log_probs/std                         0.76994     0.01607    0.80759     0.75007
log_probs/max                         1.06798     0.18137    1.45285     0.76745
log_probs/min                         -6.16249    0.77533    -5.27812    -7.82945
mean/mean                             -0.00583    0.00033    -0.00546    -0.00652
mean/std                              0.30580     0.00477    0.31321     0.29816
mean/max                              0.67851     0.00947    0.69234     0.66554
mean/min                              -1.15526    0.01120    -1.13989    -1.17130
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 4, 5, 0, 7, 2, 8, 6, 3, 1]
replay_buffer._size: [13500 13500 13500 13500 13500 13500 13500 13500 13500 13500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.460887908935547 0.002063274383544922
train_time 3.464172124862671
2023-09-06 13:56:52,675 MainThread INFO: EPOCH:88
2023-09-06 13:56:52,676 MainThread INFO: Time Consumed:3.478019952774048s
2023-09-06 13:56:52,677 MainThread INFO: Total Frames:133500s
 22%|‚ñà‚ñà‚ñè       | 89/400 [03:32<18:46,  3.62s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               510.45524
Train_Epoch_Reward                    2651.82842
Running_Training_Average_Rewards      568.37765
Explore_Time                          0.00362
Train___Time                          3.46417
Eval____Time                          0.00429
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.77263
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.27065
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.83823
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.20656
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -31.66238
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -41.64509
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  709.55101
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4511.77296
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.52288
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.35301
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.54608     0.63738    7.63526     5.63546
alpha_0                               0.77073     0.00055    0.77160     0.76987
alpha_1                               0.76671     0.00066    0.76774     0.76568
alpha_2                               0.76668     0.00066    0.76772     0.76565
alpha_3                               0.76662     0.00066    0.76765     0.76559
alpha_4                               0.76706     0.00065    0.76808     0.76605
alpha_5                               0.76721     0.00065    0.76822     0.76619
alpha_6                               0.76709     0.00064    0.76810     0.76608
alpha_7                               0.76734     0.00065    0.76836     0.76633
alpha_8                               0.76709     0.00065    0.76811     0.76607
alpha_9                               0.76728     0.00064    0.76829     0.76627
Alpha_loss                            -1.70692    0.00654    -1.69888    -1.71848
Training/policy_loss                  -12.01645   0.06058    -11.92196   -12.11499
Training/qf1_loss                     836.30273   294.97562  1249.67944  416.72852
Training/qf2_loss                     852.56210   296.69216  1267.24683  430.59033
Training/pf_norm                      0.18285     0.02968    0.23972     0.14041
Training/qf1_norm                     286.17963   35.32769   342.23068   232.83876
Training/qf2_norm                     295.86530   34.61368   350.79187   243.18292
log_std/mean                          -0.16386    0.00062    -0.16319    -0.16502
log_std/std                           0.04241     0.00040    0.04293     0.04178
log_std/max                           -0.12543    0.00120    -0.12364    -0.12696
log_std/min                           -0.38812    0.00451    -0.37966    -0.39401
log_probs/mean                        -2.45166    0.01815    -2.41752    -2.47764
log_probs/std                         0.80548     0.02206    0.82879     0.76909
log_probs/max                         1.31125     0.21317    1.70237     0.98359
log_probs/min                         -5.96437    0.67203    -4.99145    -7.29694
mean/mean                             -0.00678    0.00049    -0.00591    -0.00731
mean/std                              0.31775     0.00140    0.31939     0.31469
mean/max                              0.70451     0.00847    0.71555     0.68781
mean/min                              -1.19251    0.01607    -1.16145    -1.21432
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 7, 6, 2, 9, 3, 0, 8, 4, 5]
replay_buffer._size: [13650 13650 13650 13650 13650 13650 13650 13650 13650 13650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.5779480934143066 0.002067089080810547
train_time 3.5812413692474365
2023-09-06 13:56:56,373 MainThread INFO: EPOCH:89
2023-09-06 13:56:56,374 MainThread INFO: Time Consumed:3.5920908451080322s
2023-09-06 13:56:56,374 MainThread INFO: Total Frames:135000s
 22%|‚ñà‚ñà‚ñé       | 90/400 [03:36<18:50,  3.65s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               496.39610
Train_Epoch_Reward                    5813.61998
Running_Training_Average_Rewards      589.98410
Explore_Time                          0.00304
Train___Time                          3.58124
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.77935
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.49648
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.58441
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.16307
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.52490
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            121.21376
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  902.50011
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4102.96197
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.07479
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.80301
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.24941     0.52183    6.96909     5.16277
alpha_0                               0.76882     0.00055    0.76968     0.76797
alpha_1                               0.76443     0.00065    0.76546     0.76341
alpha_2                               0.76440     0.00066    0.76543     0.76337
alpha_3                               0.76433     0.00066    0.76536     0.76330
alpha_4                               0.76481     0.00065    0.76582     0.76380
alpha_5                               0.76496     0.00064    0.76597     0.76396
alpha_6                               0.76485     0.00064    0.76585     0.76384
alpha_7                               0.76510     0.00064    0.76611     0.76410
alpha_8                               0.76483     0.00065    0.76585     0.76381
alpha_9                               0.76504     0.00064    0.76604     0.76404
Alpha_loss                            -1.72503    0.00759    -1.71305    -1.73694
Training/policy_loss                  -12.23046   0.06520    -12.13133   -12.33358
Training/qf1_loss                     664.24549   255.93649  1187.29565  308.83609
Training/qf2_loss                     680.07712   257.48306  1206.44556  321.56403
Training/pf_norm                      0.19415     0.03776    0.26132     0.14374
Training/qf1_norm                     272.63292   31.80579   318.65924   209.08771
Training/qf2_norm                     283.27840   31.11506   327.35864   221.00090
log_std/mean                          -0.16478    0.00086    -0.16375    -0.16665
log_std/std                           0.04286     0.00025    0.04322     0.04248
log_std/max                           -0.12333    0.00027    -0.12285    -0.12362
log_std/min                           -0.39053    0.00373    -0.38285    -0.39494
log_probs/mean                        -2.44919    0.01502    -2.42193    -2.46916
log_probs/std                         0.81055     0.01969    0.85143     0.78980
log_probs/max                         1.43114     0.16196    1.66051     1.14158
log_probs/min                         -5.95139    0.74906    -4.94890    -7.17150
mean/mean                             -0.00562    0.00098    -0.00431    -0.00726
mean/std                              0.32247     0.00249    0.32790     0.31975
mean/max                              0.72351     0.00860    0.73837     0.71056
mean/min                              -1.20174    0.00924    -1.18288    -1.21108
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 3, 7, 8, 2, 9, 4, 6, 5, 1]
replay_buffer._size: [13800 13800 13800 13800 13800 13800 13800 13800 13800 13800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.8179843425750732 0.0019555091857910156
train_time 3.8211605548858643
2023-09-06 13:57:00,313 MainThread INFO: EPOCH:90
2023-09-06 13:57:00,313 MainThread INFO: Time Consumed:3.8326900005340576s
2023-09-06 13:57:00,313 MainThread INFO: Total Frames:136500s
 23%|‚ñà‚ñà‚ñé       | 91/400 [03:39<19:15,  3.74s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               482.56151
Train_Epoch_Reward                    3341.81641
Running_Training_Average_Rewards      393.57549
Explore_Time                          0.00453
Train___Time                          3.82116
Eval____Time                          0.00323
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.97008
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.92615
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.51000
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.35691
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.73927
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            106.11323
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  817.97849
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3921.88028
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.83642
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.09009
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.17400     0.52573    6.95350     5.21299
alpha_0                               0.76693     0.00054    0.76778     0.76608
alpha_1                               0.76216     0.00065    0.76318     0.76114
alpha_2                               0.76212     0.00065    0.76314     0.76109
alpha_3                               0.76205     0.00065    0.76307     0.76102
alpha_4                               0.76257     0.00064    0.76358     0.76156
alpha_5                               0.76274     0.00064    0.76373     0.76174
alpha_6                               0.76262     0.00064    0.76362     0.76162
alpha_7                               0.76287     0.00064    0.76387     0.76187
alpha_8                               0.76257     0.00065    0.76359     0.76156
alpha_9                               0.76281     0.00064    0.76381     0.76182
Alpha_loss                            -1.73504    0.00766    -1.72309    -1.75132
Training/policy_loss                  -12.44902   0.06329    -12.35054   -12.55391
Training/qf1_loss                     605.93969   272.95390  1258.44287  303.73358
Training/qf2_loss                     621.74946   274.28874  1277.28174  316.94113
Training/pf_norm                      0.18787     0.03130    0.24606     0.14315
Training/qf1_norm                     270.79222   32.37140   324.75015   210.45773
Training/qf2_norm                     282.03341   31.50465   334.07614   223.41504
log_std/mean                          -0.16962    0.00095    -0.16748    -0.17041
log_std/std                           0.04497     0.00091    0.04641     0.04359
log_std/max                           -0.12399    0.00046    -0.12328    -0.12487
log_std/min                           -0.39764    0.00709    -0.38396    -0.40782
log_probs/mean                        -2.41663    0.02231    -2.37146    -2.45294
log_probs/std                         0.85574     0.02028    0.88958     0.83098
log_probs/max                         1.47070     0.18169    1.67054     1.00254
log_probs/min                         -6.47107    0.58544    -5.72879    -7.86672
mean/mean                             -0.00418    0.00008    -0.00405    -0.00434
mean/std                              0.33833     0.00484    0.34511     0.32984
mean/max                              0.76041     0.01730    0.78461     0.72649
mean/min                              -1.22806    0.02238    -1.18300    -1.25769
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 6, 5, 1, 3, 7, 2, 9, 8, 0]
replay_buffer._size: [13950 13950 13950 13950 13950 13950 13950 13950 13950 13950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.5188117027282715 0.0019576549530029297
train_time 3.521991014480591
2023-09-06 13:57:03,966 MainThread INFO: EPOCH:91
2023-09-06 13:57:03,966 MainThread INFO: Time Consumed:3.5343804359436035s
2023-09-06 13:57:03,967 MainThread INFO: Total Frames:138000s
 23%|‚ñà‚ñà‚ñé       | 92/400 [03:43<19:02,  3.71s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               477.09116
Train_Epoch_Reward                    7176.15455
Running_Training_Average_Rewards      544.38636
Explore_Time                          0.00309
Train___Time                          3.52199
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.64601
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.14382
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.83083
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.28347
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.01655
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            109.05915
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  859.23218
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4050.46573
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.80495
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.08951
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.17036     0.57634    7.12367     5.42056
alpha_0                               0.76507     0.00053    0.76590     0.76424
alpha_1                               0.75990     0.00065    0.76092     0.75889
alpha_2                               0.75985     0.00065    0.76087     0.75883
alpha_3                               0.75977     0.00065    0.76080     0.75875
alpha_4                               0.76033     0.00064    0.76133     0.75932
alpha_5                               0.76052     0.00063    0.76152     0.75953
alpha_6                               0.76041     0.00063    0.76140     0.75942
alpha_7                               0.76065     0.00064    0.76165     0.75965
alpha_8                               0.76033     0.00064    0.76134     0.75932
alpha_9                               0.76061     0.00063    0.76160     0.75962
Alpha_loss                            -1.74612    0.00584    -1.73494    -1.75602
Training/policy_loss                  -12.66734   0.06392    -12.57364   -12.76178
Training/qf1_loss                     626.95746   257.74913  1109.70337  367.25555
Training/qf2_loss                     642.99705   259.59970  1130.70264  382.46738
Training/pf_norm                      0.19883     0.01995    0.23366     0.17370
Training/qf1_norm                     270.89127   35.96534   333.50421   224.92427
Training/qf2_norm                     283.03981   35.08532   343.16696   237.98427
log_std/mean                          -0.17123    0.00056    -0.17042    -0.17215
log_std/std                           0.04794     0.00070    0.04888     0.04681
log_std/max                           -0.12303    0.00051    -0.12240    -0.12400
log_std/min                           -0.41356    0.00505    -0.40435    -0.41992
log_probs/mean                        -2.38893    0.01608    -2.36333    -2.41054
log_probs/std                         0.89060     0.01788    0.91870     0.85311
log_probs/max                         1.64953     0.13687    1.91196     1.44309
log_probs/min                         -5.79234    0.64117    -4.97029    -6.93234
mean/mean                             -0.00379    0.00015    -0.00354    -0.00403
mean/std                              0.35257     0.00380    0.35870     0.34668
mean/max                              0.80266     0.01051    0.81475     0.78040
mean/min                              -1.26563    0.01307    -1.24020    -1.28129
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 2, 7, 4, 3, 1, 5, 0, 8, 9]
replay_buffer._size: [14100 14100 14100 14100 14100 14100 14100 14100 14100 14100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.756481409072876 0.0020356178283691406
train_time 3.7598488330841064
2023-09-06 13:57:07,850 MainThread INFO: EPOCH:92
2023-09-06 13:57:07,850 MainThread INFO: Time Consumed:3.769423723220825s
2023-09-06 13:57:07,851 MainThread INFO: Total Frames:139500s
 23%|‚ñà‚ñà‚ñé       | 93/400 [03:47<19:16,  3.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               494.20931
Train_Epoch_Reward                    4689.36415
Running_Training_Average_Rewards      506.91117
Explore_Time                          0.00314
Train___Time                          3.75985
Eval____Time                          0.00236
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.18661
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.98495
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.14866
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.18763
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.85012
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            121.62675
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  922.13215
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4600.69163
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.59236
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.70603
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.40733     0.50595    7.39070     5.65067
alpha_0                               0.76323     0.00052    0.76405     0.76242
alpha_1                               0.75765     0.00064    0.75866     0.75664
alpha_2                               0.75759     0.00065    0.75860     0.75657
alpha_3                               0.75751     0.00065    0.75853     0.75649
alpha_4                               0.75810     0.00064    0.75910     0.75711
alpha_5                               0.75832     0.00063    0.75931     0.75734
alpha_6                               0.75822     0.00063    0.75920     0.75724
alpha_7                               0.75844     0.00063    0.75943     0.75745
alpha_8                               0.75810     0.00064    0.75910     0.75709
alpha_9                               0.75841     0.00063    0.75940     0.75742
Alpha_loss                            -1.75588    0.00582    -1.74667    -1.76823
Training/policy_loss                  -12.88983   0.05746    -12.80184   -12.99843
Training/qf1_loss                     769.46230   288.03970  1086.57874  378.87958
Training/qf2_loss                     786.64272   289.50378  1105.82056  392.91275
Training/pf_norm                      0.20378     0.02851    0.26472     0.15883
Training/qf1_norm                     288.10992   32.73689   356.85168   240.74599
Training/qf2_norm                     300.35398   32.13451   368.25323   254.29863
log_std/mean                          -0.17220    0.00020    -0.17183    -0.17249
log_std/std                           0.04990     0.00040    0.05047     0.04920
log_std/max                           -0.12305    0.00045    -0.12236    -0.12370
log_std/min                           -0.42372    0.00285    -0.41820    -0.42825
log_probs/mean                        -2.35721    0.03132    -2.30448    -2.40604
log_probs/std                         0.92845     0.03299    0.99310     0.87887
log_probs/max                         1.87417     0.26232    2.35068     1.45024
log_probs/min                         -6.39128    0.68137    -5.38201    -7.34160
mean/mean                             -0.00152    0.00163    0.00099     -0.00342
mean/std                              0.36910     0.00543    0.37701     0.36081
mean/max                              0.84510     0.01608    0.86966     0.82499
mean/min                              -1.30176    0.01256    -1.28386    -1.31942
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 5, 8, 4, 6, 2, 9, 0, 1, 3]
replay_buffer._size: [14250 14250 14250 14250 14250 14250 14250 14250 14250 14250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.241071939468384 0.0020110607147216797
train_time 2.244356393814087
2023-09-06 13:57:11,702 MainThread INFO: EPOCH:93
2023-09-06 13:57:11,703 MainThread INFO: Time Consumed:3.7223777770996094s
2023-09-06 13:57:11,703 MainThread INFO: Total Frames:141000s
 24%|‚ñà‚ñà‚ñé       | 94/400 [03:51<19:20,  3.79s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               543.09226
Train_Epoch_Reward                    2952.86892
Running_Training_Average_Rewards      493.94625
Explore_Time                          1.46987
Train___Time                          2.24436
Eval____Time                          0.00271
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.79076
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.63577
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.03320
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.09872
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.06496
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            106.12986
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  994.60987
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5214.91198
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.60813
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.38833
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.59460     0.48647    7.48807     5.85839
alpha_0                               0.76144     0.00051    0.76224     0.76064
alpha_1                               0.75541     0.00064    0.75642     0.75441
alpha_2                               0.75533     0.00065    0.75634     0.75432
alpha_3                               0.75525     0.00065    0.75627     0.75424
alpha_4                               0.75589     0.00063    0.75689     0.75490
alpha_5                               0.75614     0.00063    0.75712     0.75516
alpha_6                               0.75604     0.00062    0.75702     0.75506
alpha_7                               0.75625     0.00063    0.75723     0.75526
alpha_8                               0.75588     0.00064    0.75687     0.75488
alpha_9                               0.75622     0.00063    0.75720     0.75524
Alpha_loss                            -1.76967    0.00785    -1.76052    -1.78803
Training/policy_loss                  -13.12153   0.06655    -13.00348   -13.21683
Training/qf1_loss                     952.88157   238.49024  1283.56897  492.00153
Training/qf2_loss                     970.71360   239.51555  1303.02295  509.40073
Training/pf_norm                      0.19841     0.02995    0.26471     0.14661
Training/qf1_norm                     301.70075   29.53391   353.49130   258.64355
Training/qf2_norm                     314.83725   29.06984   365.16727   272.28510
log_std/mean                          -0.17377    0.00104    -0.17234    -0.17534
log_std/std                           0.05176     0.00079    0.05272     0.05048
log_std/max                           -0.12464    0.00093    -0.12316    -0.12597
log_std/min                           -0.43113    0.00394    -0.42542    -0.43715
log_probs/mean                        -2.34071    0.02408    -2.29225    -2.37717
log_probs/std                         0.96710     0.02363    1.01069     0.92408
log_probs/max                         1.93791     0.19848    2.19969     1.48349
log_probs/min                         -6.52594    0.65743    -5.58687    -7.74262
mean/mean                             0.00230     0.00039    0.00271     0.00143
mean/std                              0.38341     0.00396    0.38935     0.37759
mean/max                              0.88746     0.00982    0.90266     0.87520
mean/min                              -1.33941    0.01367    -1.32059    -1.36133
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 8, 4, 3, 9, 5, 1, 0, 6, 7]
replay_buffer._size: [14400 14400 14400 14400 14400 14400 14400 14400 14400 14400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.279623508453369 0.0020885467529296875
train_time 2.2829577922821045
2023-09-06 13:57:15,615 MainThread INFO: EPOCH:94
2023-09-06 13:57:15,616 MainThread INFO: Time Consumed:3.7783052921295166s
2023-09-06 13:57:15,616 MainThread INFO: Total Frames:142500s
 24%|‚ñà‚ñà‚ñç       | 95/400 [03:55<19:26,  3.82s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               586.77164
Train_Epoch_Reward                    6198.77257
Running_Training_Average_Rewards      461.36685
Explore_Time                          1.48858
Train___Time                          2.28296
Eval____Time                          0.00231
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.86195
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.18221
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.21294
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.60135
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.59420
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.96875
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  786.75100
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5563.87754
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.88755
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.99644
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           6.07554     0.32555    6.65528    5.61402
alpha_0                               0.75968     0.00050    0.76047    0.75891
alpha_1                               0.75319     0.00064    0.75419    0.75219
alpha_2                               0.75308     0.00065    0.75409    0.75207
alpha_3                               0.75300     0.00064    0.75401    0.75199
alpha_4                               0.75370     0.00063    0.75468    0.75271
alpha_5                               0.75397     0.00062    0.75494    0.75299
alpha_6                               0.75387     0.00062    0.75485    0.75290
alpha_7                               0.75407     0.00062    0.75504    0.75309
alpha_8                               0.75367     0.00063    0.75466    0.75268
alpha_9                               0.75405     0.00062    0.75503    0.75307
Alpha_loss                            -1.77752    0.00680    -1.76430   -1.79074
Training/policy_loss                  -13.35567   0.07164    -13.24585  -13.46430
Training/qf1_loss                     604.36044   139.11691  858.93048  398.63348
Training/qf2_loss                     620.36475   139.34980  874.15918  413.26556
Training/pf_norm                      0.22681     0.05347    0.31100    0.15957
Training/qf1_norm                     268.64570   23.95659   311.14703  234.23651
Training/qf2_norm                     283.37205   23.67788   325.67615  249.09489
log_std/mean                          -0.17640    0.00085    -0.17522   -0.17767
log_std/std                           0.05409     0.00094    0.05538    0.05288
log_std/max                           -0.12015    0.00125    -0.11884   -0.12265
log_std/min                           -0.43693    0.00401    -0.42803   -0.44103
log_probs/mean                        -2.30354    0.03368    -2.24067   -2.35540
log_probs/std                         1.01459     0.02066    1.04869    0.97080
log_probs/max                         2.23662     0.24675    2.62065    1.85760
log_probs/min                         -6.19037    0.55131    -5.58102   -7.50877
mean/mean                             0.00081     0.00066    0.00186    -0.00030
mean/std                              0.39921     0.00437    0.40438    0.39176
mean/max                              0.91169     0.00668    0.91928    0.89999
mean/min                              -1.38001    0.01274    -1.35949   -1.39660
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 0, 7, 3, 2, 1, 5, 4, 8, 6]
replay_buffer._size: [14550 14550 14550 14550 14550 14550 14550 14550 14550 14550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.1545538902282715 0.0020325183868408203
train_time 4.1578309535980225
2023-09-06 13:57:19,897 MainThread INFO: EPOCH:95
2023-09-06 13:57:19,897 MainThread INFO: Time Consumed:4.1695475578308105s
2023-09-06 13:57:19,898 MainThread INFO: Total Frames:144000s
 24%|‚ñà‚ñà‚ñç       | 96/400 [03:59<20:04,  3.96s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               609.41522
Train_Epoch_Reward                    4270.43470
Running_Training_Average_Rewards      447.40254
Explore_Time                          0.00285
Train___Time                          4.15783
Eval____Time                          0.00492
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.92511
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.64091
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.98631
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.31026
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.93453
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93160
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  643.21046
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5700.19277
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.86011
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.71275
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.16809     0.55552    7.27296     5.51618
alpha_0                               0.75798     0.00048    0.75874     0.75723
alpha_1                               0.75097     0.00064    0.75197     0.74998
alpha_2                               0.75084     0.00064    0.75185     0.74983
alpha_3                               0.75076     0.00064    0.75177     0.74975
alpha_4                               0.75151     0.00063    0.75250     0.75053
alpha_5                               0.75180     0.00062    0.75277     0.75083
alpha_6                               0.75172     0.00062    0.75269     0.75076
alpha_7                               0.75190     0.00062    0.75287     0.75093
alpha_8                               0.75148     0.00063    0.75246     0.75049
alpha_9                               0.75188     0.00062    0.75285     0.75091
Alpha_loss                            -1.79136    0.01000    -1.77079    -1.80445
Training/policy_loss                  -13.58341   0.06694    -13.46815   -13.68506
Training/qf1_loss                     727.71257   339.87669  1454.80518  373.52985
Training/qf2_loss                     744.91628   342.42389  1477.78821  387.97549
Training/pf_norm                      0.21224     0.04161    0.28684     0.15441
Training/qf1_norm                     278.90342   39.03505   356.26758   232.42851
Training/qf2_norm                     293.60344   38.05958   368.14105   247.74908
log_std/mean                          -0.17780    0.00021    -0.17743    -0.17816
log_std/std                           0.05485     0.00026    0.05527     0.05445
log_std/max                           -0.12195    0.00111    -0.11980    -0.12357
log_std/min                           -0.43981    0.00322    -0.43486    -0.44646
log_probs/mean                        -2.28836    0.02486    -2.23143    -2.32865
log_probs/std                         1.03338     0.02961    1.07104     0.96997
log_probs/max                         2.28394     0.24072    2.66120     1.85456
log_probs/min                         -6.58489    1.04766    -5.48503    -8.85972
mean/mean                             0.00034     0.00094    0.00239     -0.00052
mean/std                              0.40233     0.00098    0.40385     0.40125
mean/max                              0.90715     0.00591    0.91637     0.89620
mean/min                              -1.36204    0.01385    -1.34079    -1.38819
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 8, 7, 9, 2, 0, 4, 5, 6, 1]
replay_buffer._size: [14700 14700 14700 14700 14700 14700 14700 14700 14700 14700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.148602724075317 0.002952098846435547
train_time 4.153520822525024
2023-09-06 13:57:24,177 MainThread INFO: EPOCH:96
2023-09-06 13:57:24,177 MainThread INFO: Time Consumed:4.16776704788208s
2023-09-06 13:57:24,178 MainThread INFO: Total Frames:145500s
 24%|‚ñà‚ñà‚ñç       | 97/400 [04:03<20:32,  4.07s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               599.56095
Train_Epoch_Reward                    8772.95242
Running_Training_Average_Rewards      641.40532
Explore_Time                          0.00334
Train___Time                          4.15352
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.02714
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.74456
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.96120
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.65593
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.91148
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            119.72818
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  696.54867
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5205.57165
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.95186
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.19252
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.80530     0.55921    6.54445    4.62894
alpha_0                               0.75631     0.00048    0.75706    0.75556
alpha_1                               0.74876     0.00063    0.74976    0.74777
alpha_2                               0.74861     0.00064    0.74961    0.74760
alpha_3                               0.74853     0.00064    0.74953    0.74752
alpha_4                               0.74933     0.00062    0.75031    0.74835
alpha_5                               0.74965     0.00062    0.75062    0.74869
alpha_6                               0.74958     0.00061    0.75054    0.74862
alpha_7                               0.74974     0.00062    0.75071    0.74876
alpha_8                               0.74929     0.00063    0.75027    0.74831
alpha_9                               0.74973     0.00062    0.75069    0.74876
Alpha_loss                            -1.80660    0.00701    -1.79921   -1.82476
Training/policy_loss                  -13.82399   0.06679    -13.73213  -13.93401
Training/qf1_loss                     566.86143   216.17068  878.11316  231.01372
Training/qf2_loss                     582.98638   218.18251  897.91473  242.40555
Training/pf_norm                      0.20463     0.04450    0.32447    0.15223
Training/qf1_norm                     258.85689   38.33216   312.35480  179.43143
Training/qf2_norm                     274.85320   37.34401   326.44958  196.74028
log_std/mean                          -0.17871    0.00037    -0.17832   -0.17956
log_std/std                           0.05389     0.00023    0.05431    0.05357
log_std/max                           -0.12386    0.00025    -0.12361   -0.12437
log_std/min                           -0.43275    0.00615    -0.42454   -0.44055
log_probs/mean                        -2.27908    0.02561    -2.25011   -2.32702
log_probs/std                         1.03421     0.03107    1.08464    0.99454
log_probs/max                         2.21398     0.18541    2.46492    1.83482
log_probs/min                         -6.69250    0.87380    -5.47414   -8.24031
mean/mean                             0.00854     0.00327    0.01360    0.00330
mean/std                              0.40844     0.00428    0.41623    0.40289
mean/max                              0.92586     0.00727    0.94196    0.91493
mean/min                              -1.34311    0.01208    -1.32426   -1.35836
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 0, 6, 2, 9, 7, 4, 1, 3, 8]
replay_buffer._size: [14850 14850 14850 14850 14850 14850 14850 14850 14850 14850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.286207675933838 0.0019288063049316406
train_time 2.28934907913208
2023-09-06 13:57:28,393 MainThread INFO: EPOCH:97
2023-09-06 13:57:28,394 MainThread INFO: Time Consumed:2.3026323318481445s
2023-09-06 13:57:28,395 MainThread INFO: Total Frames:147000s
 24%|‚ñà‚ñà‚ñç       | 98/400 [04:08<20:42,  4.11s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               607.56348
Train_Epoch_Reward                    10951.02193
Running_Training_Average_Rewards      799.81364
Explore_Time                          0.00440
Train___Time                          2.28935
Eval____Time                          0.00297
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.66472
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.35332
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.97718
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.26316
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.26245
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            120.61207
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  637.05274
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5814.03709
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.97577
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.80646
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.15198      0.54890    7.61313     5.53996
alpha_0                               0.75464      0.00048    0.75539     0.75389
alpha_1                               0.74657      0.00063    0.74755     0.74558
alpha_2                               0.74638      0.00064    0.74738     0.74538
alpha_3                               0.74630      0.00064    0.74730     0.74530
alpha_4                               0.74717      0.00062    0.74814     0.74621
alpha_5                               0.74751      0.00061    0.74847     0.74656
alpha_6                               0.74745      0.00061    0.74840     0.74650
alpha_7                               0.74758      0.00062    0.74855     0.74662
alpha_8                               0.74711      0.00062    0.74809     0.74614
alpha_9                               0.74759      0.00061    0.74855     0.74664
Alpha_loss                            -1.81081     0.00726    -1.79538    -1.82022
Training/policy_loss                  -14.06977    0.07283    -13.96694   -14.19250
Training/qf1_loss                     628.75093    246.56354  1258.06238  358.15457
Training/qf2_loss                     646.44032    248.50370  1281.56189  373.97955
Training/pf_norm                      0.21381      0.01931    0.24064     0.18021
Training/qf1_norm                     282.78116    39.19427   387.14334   237.72456
Training/qf2_norm                     299.28833    38.56881   402.56812   255.30246
log_std/mean                          -0.18278     0.00134    -0.18024    -0.18468
log_std/std                           0.05614      0.00118    0.05827     0.05449
log_std/max                           -0.12565     0.00100    -0.12361    -0.12666
log_std/min                           -0.44260     0.00833    -0.43200    -0.45704
log_probs/mean                        -2.23203     0.03196    -2.17502    -2.27287
log_probs/std                         1.07299      0.03908    1.12518     0.99581
log_probs/max                         2.43703      0.14955    2.62535     2.17372
log_probs/min                         -6.43541     0.87874    -5.33554    -7.93762
mean/mean                             0.01688      0.00101    0.01767     0.01463
mean/std                              0.43085      0.00761    0.44283     0.41862
mean/max                              0.98446      0.02065    1.01735     0.95678
mean/min                              -1.38336     0.02664    -1.35086    -1.43152
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 0, 1, 8, 3, 5, 4, 2, 9, 6]
replay_buffer._size: [15000 15000 15000 15000 15000 15000 15000 15000 15000 15000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.502804756164551 0.002194643020629883
train_time 2.5063841342926025
2023-09-06 13:57:32,793 MainThread INFO: EPOCH:98
2023-09-06 13:57:32,793 MainThread INFO: Time Consumed:2.631295680999756s
2023-09-06 13:57:32,794 MainThread INFO: Total Frames:148500s
 25%|‚ñà‚ñà‚ñç       | 99/400 [04:12<21:04,  4.20s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               590.31095
Train_Epoch_Reward                    7662.96143
Running_Training_Average_Rewards      912.89786
Explore_Time                          0.11597
Train___Time                          2.50638
Eval____Time                          0.00304
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.80834
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.48486
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.81751
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.80062
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.58013
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            150.09147
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  320.43669
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5335.16321
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.52365
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.15052
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           6.06157     0.42279    6.78764    5.17362
alpha_0                               0.75298     0.00047    0.75372    0.75225
alpha_1                               0.74438     0.00063    0.74536    0.74340
alpha_2                               0.74417     0.00063    0.74516    0.74317
alpha_3                               0.74409     0.00063    0.74508    0.74310
alpha_4                               0.74504     0.00061    0.74599    0.74408
alpha_5                               0.74540     0.00060    0.74634    0.74445
alpha_6                               0.74534     0.00060    0.74628    0.74440
alpha_7                               0.74544     0.00061    0.74640    0.74449
alpha_8                               0.74495     0.00062    0.74592    0.74399
alpha_9                               0.74548     0.00060    0.74643    0.74453
Alpha_loss                            -1.81061    0.00628    -1.79908   -1.82002
Training/policy_loss                  -14.31412   0.07291    -14.19772  -14.44012
Training/qf1_loss                     616.05034   189.78325  918.78479  401.65500
Training/qf2_loss                     633.02418   191.20588  937.98596  415.76474
Training/pf_norm                      0.19432     0.04044    0.26190    0.12857
Training/qf1_norm                     274.53416   29.77593   327.93915  216.44991
Training/qf2_norm                     292.24941   29.10863   344.47220  235.50211
log_std/mean                          -0.18583    0.00030    -0.18519   -0.18636
log_std/std                           0.06053     0.00082    0.06137    0.05882
log_std/max                           -0.12361    0.00077    -0.12243   -0.12520
log_std/min                           -0.46282    0.00402    -0.45420   -0.46805
log_probs/mean                        -2.17015    0.02027    -2.12648   -2.19606
log_probs/std                         1.13756     0.01990    1.17248    1.10177
log_probs/max                         2.64276     0.26406    3.21760    2.22043
log_probs/min                         -6.65946    1.08690    -5.38880   -8.85765
mean/mean                             0.01699     0.00040    0.01743    0.01600
mean/std                              0.44992     0.00263    0.45287    0.44443
mean/max                              1.02187     0.00739    1.03186    1.00872
mean/min                              -1.43808    0.01061    -1.41927   -1.45118
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 5, 7, 3, 0, 9, 6, 8, 2, 4]
replay_buffer._size: [15150 15150 15150 15150 15150 15150 15150 15150 15150 15150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.3559370040893555 0.001827239990234375
train_time 2.3590259552001953
2023-09-06 13:57:37,098 MainThread INFO: EPOCH:99
2023-09-06 13:57:37,098 MainThread INFO: Time Consumed:2.37721586227417s
2023-09-06 13:57:37,098 MainThread INFO: Total Frames:150000s
 25%|‚ñà‚ñà‚ñå       | 100/400 [04:16<21:07,  4.23s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               565.51128
Train_Epoch_Reward                    4296.97702
Running_Training_Average_Rewards      763.69868
Explore_Time                          0.00816
Train___Time                          2.35903
Eval____Time                          0.00556
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.90691
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.53808
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.73612
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.98129
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.51974
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            149.43273
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  408.89849
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4722.47544
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.94853
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.76230
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.43354     0.61674    7.91318     5.73644
alpha_0                               0.75138     0.00045    0.75209     0.75067
alpha_1                               0.74221     0.00062    0.74319     0.74124
alpha_2                               0.74197     0.00063    0.74295     0.74098
alpha_3                               0.74188     0.00063    0.74288     0.74089
alpha_4                               0.74291     0.00061    0.74387     0.74196
alpha_5                               0.74330     0.00060    0.74424     0.74236
alpha_6                               0.74325     0.00060    0.74419     0.74232
alpha_7                               0.74333     0.00060    0.74428     0.74238
alpha_8                               0.74281     0.00062    0.74377     0.74184
alpha_9                               0.74338     0.00060    0.74432     0.74244
Alpha_loss                            -1.82144    0.00381    -1.81448    -1.82802
Training/policy_loss                  -14.57521   0.07923    -14.45086   -14.69877
Training/qf1_loss                     903.46018   508.82527  1873.79004  348.84045
Training/qf2_loss                     922.64715   511.05113  1898.38892  364.90714
Training/pf_norm                      0.21358     0.03319    0.26938     0.16456
Training/qf1_norm                     304.10095   42.66798   403.14233   254.95280
Training/qf2_norm                     321.62064   41.88903   419.46475   273.76147
log_std/mean                          -0.18881    0.00123    -0.18670    -0.19026
log_std/std                           0.06275     0.00072    0.06360     0.06141
log_std/max                           -0.12169    0.00081    -0.12005    -0.12270
log_std/min                           -0.47182    0.00291    -0.46615    -0.47580
log_probs/mean                        -2.14744    0.02332    -2.09764    -2.18303
log_probs/std                         1.16219     0.03209    1.21463     1.11227
log_probs/max                         2.69640     0.20358    3.07123     2.46644
log_probs/min                         -6.39639    0.85532    -5.26896    -8.14143
mean/mean                             0.01464     0.00062    0.01577     0.01395
mean/std                              0.45394     0.00093    0.45539     0.45237
mean/max                              1.02066     0.00792    1.03500     1.00403
mean/min                              -1.44538    0.01063    -1.42658    -1.46030
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 8, 1, 5, 7, 3, 4, 9, 0, 6]
replay_buffer._size: [15300 15300 15300 15300 15300 15300 15300 15300 15300 15300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.233886957168579 0.0020363330841064453
train_time 4.237222671508789
2023-09-06 13:57:41,482 MainThread INFO: EPOCH:100
2023-09-06 13:57:41,482 MainThread INFO: Time Consumed:4.247086524963379s
2023-09-06 13:57:41,482 MainThread INFO: Total Frames:151500s
 25%|‚ñà‚ñà‚ñå       | 101/400 [04:22<22:58,  4.61s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               504.60698
Train_Epoch_Reward                    3922.35264
Running_Training_Average_Rewards      529.40970
Explore_Time                          0.00355
Train___Time                          4.23722
Eval____Time                          0.00225
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.14763
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.36369
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.74414
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.18869
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -38.89415
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            109.40942
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  465.82153
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4173.79345
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.92235
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.49381
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.20300     0.76587    7.65646     5.19299
alpha_0                               0.74981     0.00045    0.75051     0.74910
alpha_1                               0.74005     0.00062    0.74102     0.73908
alpha_2                               0.73978     0.00063    0.74076     0.73879
alpha_3                               0.73968     0.00063    0.74067     0.73870
alpha_4                               0.74080     0.00061    0.74175     0.73985
alpha_5                               0.74122     0.00060    0.74216     0.74029
alpha_6                               0.74118     0.00059    0.74211     0.74025
alpha_7                               0.74123     0.00060    0.74217     0.74029
alpha_8                               0.74067     0.00061    0.74163     0.73970
alpha_9                               0.74130     0.00060    0.74223     0.74036
Alpha_loss                            -1.84076    0.00752    -1.83284    -1.85432
Training/policy_loss                  -14.83426   0.07425    -14.73283   -14.95347
Training/qf1_loss                     813.00977   467.97033  1627.22009  295.70422
Training/qf2_loss                     831.04657   470.75175  1651.48364  309.90680
Training/pf_norm                      0.24963     0.06017    0.32345     0.16330
Training/qf1_norm                     287.74624   55.69173   400.47992   216.44501
Training/qf2_norm                     306.54419   54.59218   416.33710   235.96048
log_std/mean                          -0.18916    0.00110    -0.18784    -0.19134
log_std/std                           0.06409     0.00056    0.06516     0.06339
log_std/max                           -0.11674    0.00123    -0.11549    -0.11950
log_std/min                           -0.47348    0.00374    -0.46773    -0.47900
log_probs/mean                        -2.15438    0.02328    -2.11360    -2.19185
log_probs/std                         1.16666     0.03105    1.22447     1.13070
log_probs/max                         2.74885     0.23325    3.11522     2.36204
log_probs/min                         -6.79267    1.17830    -5.46302    -9.52676
mean/mean                             0.02007     0.00236    0.02401     0.01638
mean/std                              0.45990     0.00493    0.46920     0.45485
mean/max                              1.03523     0.01255    1.05710     1.01806
mean/min                              -1.44675    0.01222    -1.42852    -1.46598
------------------------------------  ----------  ---------  ----------  ---------
snapshot at 100
history save at ./log/testing_must_mtsac/mt10/18/model
sample: [6, 2, 0, 5, 4, 7, 9, 3, 1, 8]
replay_buffer._size: [15450 15450 15450 15450 15450 15450 15450 15450 15450 15450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.260610342025757 0.002092123031616211
train_time 2.263969659805298
2023-09-06 13:57:45,739 MainThread INFO: EPOCH:101
2023-09-06 13:57:45,739 MainThread INFO: Time Consumed:2.275207757949829s
2023-09-06 13:57:45,739 MainThread INFO: Total Frames:153000s
 26%|‚ñà‚ñà‚ñå       | 102/400 [04:25<20:40,  4.16s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               500.99096
Train_Epoch_Reward                    4162.20378
Running_Training_Average_Rewards      412.71778
Explore_Time                          0.00315
Train___Time                          2.26397
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.61135
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.27351
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.80343
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.07946
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -40.10094
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            96.10654
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  1765.93865
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3845.49225
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.49026
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.13321
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           6.00105     0.49188    6.71776    5.26143
alpha_0                               0.74825     0.00044    0.74895    0.74757
alpha_1                               0.73790     0.00062    0.73886    0.73693
alpha_2                               0.73760     0.00062    0.73858    0.73662
alpha_3                               0.73749     0.00063    0.73848    0.73651
alpha_4                               0.73870     0.00060    0.73964    0.73775
alpha_5                               0.73916     0.00059    0.74008    0.73824
alpha_6                               0.73912     0.00059    0.74004    0.73820
alpha_7                               0.73914     0.00060    0.74008    0.73820
alpha_8                               0.73854     0.00061    0.73949    0.73758
alpha_9                               0.73922     0.00060    0.74016    0.73829
Alpha_loss                            -1.83602    0.01047    -1.82211   -1.84878
Training/policy_loss                  -15.08744   0.07641    -14.97262  -15.20892
Training/qf1_loss                     636.57171   238.17742  961.13879  366.33118
Training/qf2_loss                     654.29711   239.24771  979.49152  381.33307
Training/pf_norm                      0.20304     0.03104    0.24126    0.15374
Training/qf1_norm                     277.31439   37.62938   330.38019  221.32193
Training/qf2_norm                     297.06670   37.07838   349.34686  242.50418
log_std/mean                          -0.19522    0.00150    -0.19234   -0.19702
log_std/std                           0.06728     0.00084    0.06833    0.06555
log_std/max                           -0.12026    0.00165    -0.11786   -0.12282
log_std/min                           -0.48674    0.00603    -0.47814   -0.49627
log_probs/mean                        -2.08082    0.04288    -2.01513   -2.14866
log_probs/std                         1.21210     0.03296    1.27300    1.13949
log_probs/max                         3.00579     0.16197    3.36515    2.86352
log_probs/min                         -6.36030    0.74402    -5.64675   -8.41870
mean/mean                             0.02888     0.00227    0.03241    0.02502
mean/std                              0.48264     0.00634    0.49208    0.47166
mean/max                              1.09043     0.02138    1.12285    1.05752
mean/min                              -1.47838    0.01740    -1.45696   -1.50629
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 8, 9, 1, 7, 2, 6, 0, 3, 5]
replay_buffer._size: [15600 15600 15600 15600 15600 15600 15600 15600 15600 15600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.272979259490967 0.0024712085723876953
train_time 4.276723146438599
2023-09-06 13:57:50,149 MainThread INFO: EPOCH:102
2023-09-06 13:57:50,149 MainThread INFO: Time Consumed:4.2858922481536865s
2023-09-06 13:57:50,150 MainThread INFO: Total Frames:154500s
 26%|‚ñà‚ñà‚ñå       | 103/400 [04:29<20:56,  4.23s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               464.26791
Train_Epoch_Reward                    6268.43254
Running_Training_Average_Rewards      478.43297
Explore_Time                          0.00291
Train___Time                          4.27672
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.78540
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.43989
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.90100
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.62348
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -41.28263
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            124.07956
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  263.11229
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3798.15127
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.66261
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.92609
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.65189     0.28467    6.11418    5.15833
alpha_0                               0.74675     0.00043    0.74742    0.74608
alpha_1                               0.73575     0.00061    0.73671    0.73479
alpha_2                               0.73542     0.00062    0.73640    0.73445
alpha_3                               0.73532     0.00062    0.73630    0.73434
alpha_4                               0.73660     0.00060    0.73754    0.73567
alpha_5                               0.73712     0.00058    0.73803    0.73621
alpha_6                               0.73708     0.00058    0.73800    0.73617
alpha_7                               0.73707     0.00059    0.73800    0.73614
alpha_8                               0.73642     0.00061    0.73737    0.73547
alpha_9                               0.73715     0.00059    0.73808    0.73623
Alpha_loss                            -1.84604    0.00692    -1.83555   -1.86367
Training/policy_loss                  -15.36647   0.07543    -15.25332  -15.49061
Training/qf1_loss                     448.88576   135.72588  774.69775  310.22003
Training/qf2_loss                     464.85767   136.55662  792.81946  324.85199
Training/pf_norm                      0.23410     0.03206    0.27800    0.19013
Training/qf1_norm                     248.48795   22.32461   283.55841  213.98747
Training/qf2_norm                     269.95974   21.68998   303.70630  236.47157
log_std/mean                          -0.19874    0.00135    -0.19699   -0.20056
log_std/std                           0.06843     0.00015    0.06864    0.06814
log_std/max                           -0.12571    0.00230    -0.12303   -0.12949
log_std/min                           -0.49679    0.00313    -0.49184   -0.50345
log_probs/mean                        -2.05726    0.02389    -2.01974   -2.09126
log_probs/std                         1.26697     0.02454    1.29405    1.22231
log_probs/max                         3.30069     0.19112    3.70859    3.05413
log_probs/min                         -6.36997    0.69057    -5.33631   -7.64610
mean/mean                             0.03467     0.00094    0.03576    0.03293
mean/std                              0.49829     0.00315    0.50293    0.49342
mean/max                              1.13674     0.00591    1.14724    1.12807
mean/min                              -1.50901    0.00976    -1.49514   -1.52797
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 4, 6, 0, 9, 7, 2, 3, 8, 5]
replay_buffer._size: [15750 15750 15750 15750 15750 15750 15750 15750 15750 15750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.297122478485107 0.002294301986694336
train_time 4.3023600578308105
2023-09-06 13:57:54,570 MainThread INFO: EPOCH:103
2023-09-06 13:57:54,571 MainThread INFO: Time Consumed:4.315076112747192s
2023-09-06 13:57:54,571 MainThread INFO: Total Frames:156000s
 26%|‚ñà‚ñà‚ñå       | 104/400 [04:34<21:09,  4.29s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               439.87115
Train_Epoch_Reward                    5148.56575
Running_Training_Average_Rewards      519.30674
Explore_Time                          0.00448
Train___Time                          4.30236
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.07001
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.75019
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.39032
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.54217
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -43.23678
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            108.71381
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  573.32858
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3341.17172
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.79232
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.06506
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.07962     0.69289    7.16604     5.05497
alpha_0                               0.74527     0.00042    0.74593     0.74462
alpha_1                               0.73363     0.00061    0.73458     0.73268
alpha_2                               0.73326     0.00062    0.73423     0.73229
alpha_3                               0.73315     0.00062    0.73412     0.73217
alpha_4                               0.73453     0.00059    0.73546     0.73360
alpha_5                               0.73510     0.00058    0.73600     0.73419
alpha_6                               0.73507     0.00058    0.73597     0.73416
alpha_7                               0.73501     0.00059    0.73593     0.73409
alpha_8                               0.73431     0.00061    0.73526     0.73337
alpha_9                               0.73511     0.00058    0.73602     0.73419
Alpha_loss                            -1.84956    0.00673    -1.83975    -1.86401
Training/policy_loss                  -15.64123   0.08322    -15.49885   -15.77872
Training/qf1_loss                     605.84530   254.38426  1041.40894  254.56918
Training/qf2_loss                     624.06455   256.49179  1059.72559  268.88004
Training/pf_norm                      0.22454     0.03600    0.26363     0.13429
Training/qf1_norm                     280.28340   53.36484   359.48508   205.71924
Training/qf2_norm                     301.83420   52.66097   378.92328   228.84511
log_std/mean                          -0.20017    0.00041    -0.19959    -0.20084
log_std/std                           0.06949     0.00056    0.07022     0.06839
log_std/max                           -0.12894    0.00140    -0.12670    -0.13104
log_std/min                           -0.50468    0.00452    -0.49672    -0.50970
log_probs/mean                        -2.01374    0.02289    -1.98148    -2.05367
log_probs/std                         1.28045     0.01806    1.30423     1.25275
log_probs/max                         3.31791     0.30904    3.72356     2.69333
log_probs/min                         -6.82137    1.34049    -5.31542    -8.90804
mean/mean                             0.03866     0.00239    0.04277     0.03573
mean/std                              0.51132     0.00431    0.51866     0.50465
mean/max                              1.14173     0.00658    1.15746     1.13126
mean/min                              -1.53633    0.01025    -1.52013    -1.55676
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 2, 3, 7, 4, 5, 6, 8, 9, 0]
replay_buffer._size: [15900 15900 15900 15900 15900 15900 15900 15900 15900 15900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.269983291625977 0.0020799636840820312
train_time 4.273249387741089
2023-09-06 13:57:58,963 MainThread INFO: EPOCH:104
2023-09-06 13:57:58,963 MainThread INFO: Time Consumed:4.2825093269348145s
2023-09-06 13:57:58,964 MainThread INFO: Total Frames:157500s
 26%|‚ñà‚ñà‚ñã       | 105/400 [04:38<21:14,  4.32s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               363.35767
Train_Epoch_Reward                    4145.45844
Running_Training_Average_Rewards      518.74856
Explore_Time                          0.00301
Train___Time                          4.27325
Eval____Time                          0.00231
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.44237
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.72825
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.11780
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.90621
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -45.49286
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            97.32047
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  422.39557
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2898.39407
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.21454
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.56717
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.82918     0.48654    6.69638    5.05368
alpha_0                               0.74383     0.00041    0.74447    0.74319
alpha_1                               0.73152     0.00061    0.73247    0.73057
alpha_2                               0.73111     0.00061    0.73208    0.73015
alpha_3                               0.73098     0.00062    0.73195    0.73001
alpha_4                               0.73247     0.00059    0.73339    0.73155
alpha_5                               0.73310     0.00057    0.73399    0.73220
alpha_6                               0.73306     0.00057    0.73396    0.73217
alpha_7                               0.73297     0.00059    0.73389    0.73205
alpha_8                               0.73222     0.00060    0.73316    0.73129
alpha_9                               0.73308     0.00058    0.73399    0.73218
Alpha_loss                            -1.85326    0.00851    -1.84089   -1.86983
Training/policy_loss                  -15.90969   0.07135    -15.79624  -16.01306
Training/qf1_loss                     507.92796   182.52678  913.97473  307.06268
Training/qf2_loss                     525.52057   184.53244  936.16699  322.10516
Training/pf_norm                      0.22484     0.03247    0.29486    0.19094
Training/qf1_norm                     263.20482   38.85588   336.75055  201.11484
Training/qf2_norm                     285.65647   37.98129   356.71436  225.01762
log_std/mean                          -0.19874    0.00070    -0.19794   -0.19988
log_std/std                           0.06986     0.00026    0.07033    0.06950
log_std/max                           -0.12474    0.00129    -0.12233   -0.12677
log_std/min                           -0.48864    0.00715    -0.47798   -0.50064
log_probs/mean                        -1.97154    0.01800    -1.95311   -2.00247
log_probs/std                         1.31431     0.02412    1.35123    1.28213
log_probs/max                         3.44556     0.20740    3.84057    3.18709
log_probs/min                         -6.50107    0.76485    -5.57949   -7.82754
mean/mean                             0.04746     0.00177    0.04994    0.04398
mean/std                              0.52203     0.00119    0.52384    0.51982
mean/max                              1.15723     0.01057    1.17378    1.13966
mean/min                              -1.53532    0.01414    -1.51654   -1.55469
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 4, 2, 5, 7, 9, 8, 3, 1, 6]
replay_buffer._size: [16050 16050 16050 16050 16050 16050 16050 16050 16050 16050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.453226566314697 0.0020334720611572266
train_time 4.456440448760986
2023-09-06 13:58:03,546 MainThread INFO: EPOCH:105
2023-09-06 13:58:03,547 MainThread INFO: Time Consumed:4.469240427017212s
2023-09-06 13:58:03,547 MainThread INFO: Total Frames:159000s
 26%|‚ñà‚ñà‚ñã       | 106/400 [04:43<21:34,  4.40s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               319.64747
Train_Epoch_Reward                    4232.12931
Running_Training_Average_Rewards      450.87178
Explore_Time                          0.00532
Train___Time                          4.45644
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.72416
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.92245
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.58595
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.80198
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.78140
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -59.68784
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  308.04129
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2631.76199
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.16240
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.72120
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.64191     0.32821    6.29611    5.25021
alpha_0                               0.74243     0.00039    0.74305    0.74181
alpha_1                               0.72941     0.00060    0.73036    0.72847
alpha_2                               0.72897     0.00061    0.72994    0.72801
alpha_3                               0.72883     0.00062    0.72979    0.72786
alpha_4                               0.73043     0.00059    0.73135    0.72951
alpha_5                               0.73111     0.00057    0.73200    0.73022
alpha_6                               0.73108     0.00057    0.73197    0.73020
alpha_7                               0.73092     0.00059    0.73184    0.73001
alpha_8                               0.73015     0.00059    0.73108    0.72922
alpha_9                               0.73108     0.00058    0.73198    0.73018
Alpha_loss                            -1.85990    0.01133    -1.84790   -1.88513
Training/policy_loss                  -16.18308   0.07575    -16.07099  -16.30021
Training/qf1_loss                     432.77368   145.53084  730.11194  301.94467
Training/qf2_loss                     449.71305   146.69667  749.88928  317.22845
Training/pf_norm                      0.25850     0.05131    0.34312    0.17324
Training/qf1_norm                     250.84007   26.11630   301.07452  220.22113
Training/qf2_norm                     274.18615   25.59167   323.86014  243.89682
log_std/mean                          -0.20329    0.00282    -0.19890   -0.20772
log_std/std                           0.07397     0.00174    0.07654    0.07105
log_std/max                           -0.12318    0.00090    -0.12197   -0.12499
log_std/min                           -0.49641    0.00716    -0.48646   -0.50973
log_probs/mean                        -1.93886    0.03890    -1.87744   -2.00720
log_probs/std                         1.35882     0.03660    1.42905    1.29154
log_probs/max                         3.51269     0.14578    3.74437    3.35554
log_probs/min                         -6.68136    0.54810    -5.77034   -7.72501
mean/mean                             0.05101     0.00016    0.05121    0.05059
mean/std                              0.53101     0.00367    0.53776    0.52554
mean/max                              1.18491     0.00970    1.20588    1.17581
mean/min                              -1.54197    0.01292    -1.52809   -1.56813
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 8, 2, 4, 6, 3, 1, 0, 7, 5]
replay_buffer._size: [16200 16200 16200 16200 16200 16200 16200 16200 16200 16200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.285577058792114 0.002023935317993164
train_time 4.288830518722534
2023-09-06 13:58:07,967 MainThread INFO: EPOCH:106
2023-09-06 13:58:07,968 MainThread INFO: Time Consumed:4.300307989120483s
2023-09-06 13:58:07,968 MainThread INFO: Total Frames:160500s
 27%|‚ñà‚ñà‚ñã       | 107/400 [04:47<21:30,  4.40s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               267.96307
Train_Epoch_Reward                    3600.29788
Running_Training_Average_Rewards      399.26285
Explore_Time                          0.00309
Train___Time                          4.28883
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.13967
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.81377
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.63775
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.63680
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.49278
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -61.39528
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.75576
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2561.14419
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.28378
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.15333
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.96025     0.46601    7.14986     5.20182
alpha_0                               0.74107     0.00039    0.74168     0.74046
alpha_1                               0.72732     0.00060    0.72826     0.72639
alpha_2                               0.72684     0.00061    0.72780     0.72588
alpha_3                               0.72668     0.00061    0.72764     0.72572
alpha_4                               0.72840     0.00058    0.72931     0.72749
alpha_5                               0.72914     0.00056    0.73002     0.72827
alpha_6                               0.72912     0.00056    0.73000     0.72823
alpha_7                               0.72890     0.00058    0.72981     0.72800
alpha_8                               0.72809     0.00059    0.72901     0.72716
alpha_9                               0.72908     0.00057    0.72998     0.72818
Alpha_loss                            -1.86534    0.01058    -1.84885    -1.88440
Training/policy_loss                  -16.46875   0.08497    -16.34211   -16.61523
Training/qf1_loss                     613.00684   263.19042  1193.16785  306.86639
Training/qf2_loss                     631.67000   265.35268  1218.60535  322.09521
Training/pf_norm                      0.25139     0.03422    0.32755     0.20297
Training/qf1_norm                     275.26256   38.21354   376.05713   216.77905
Training/qf2_norm                     298.74759   37.56968   397.91992   241.25766
log_std/mean                          -0.20910    0.00034    -0.20872    -0.20982
log_std/std                           0.07825     0.00079    0.07919     0.07697
log_std/max                           -0.12496    0.00054    -0.12439    -0.12608
log_std/min                           -0.51005    0.00336    -0.50454    -0.51636
log_probs/mean                        -1.90474    0.02986    -1.86430    -1.95433
log_probs/std                         1.36488     0.01385    1.38554     1.34544
log_probs/max                         3.53678     0.26238    3.98690     3.11535
log_probs/min                         -6.79534    0.59517    -6.11112    -8.13916
mean/mean                             0.05473     0.00196    0.05807     0.05186
mean/std                              0.54493     0.00360    0.55089     0.53953
mean/max                              1.20796     0.00851    1.22606     1.19595
mean/min                              -1.56281    0.00953    -1.54882    -1.58170
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 2, 4, 1, 6, 3, 8, 5, 9, 0]
replay_buffer._size: [16350 16350 16350 16350 16350 16350 16350 16350 16350 16350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.440732717514038 0.0019927024841308594
train_time 4.443938255310059
2023-09-06 13:58:12,531 MainThread INFO: EPOCH:107
2023-09-06 13:58:12,532 MainThread INFO: Time Consumed:4.4548187255859375s
2023-09-06 13:58:12,532 MainThread INFO: Total Frames:162000s
 27%|‚ñà‚ñà‚ñã       | 108/400 [04:52<21:41,  4.46s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               249.85005
Train_Epoch_Reward                    2521.26301
Running_Training_Average_Rewards      345.12301
Explore_Time                          0.00325
Train___Time                          4.44394
Eval____Time                          0.00373
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.21957
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.54162
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.54867
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.46761
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.91258
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.18037
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  275.27419
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2662.92437
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.33306
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.74467
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.77005     0.61276    6.68740    4.69021
alpha_0                               0.73973     0.00038    0.74033    0.73913
alpha_1                               0.72525     0.00059    0.72618    0.72433
alpha_2                               0.72471     0.00061    0.72567    0.72375
alpha_3                               0.72454     0.00061    0.72550    0.72359
alpha_4                               0.72638     0.00058    0.72729    0.72548
alpha_5                               0.72721     0.00055    0.72808    0.72635
alpha_6                               0.72715     0.00056    0.72804    0.72627
alpha_7                               0.72691     0.00057    0.72780    0.72602
alpha_8                               0.72604     0.00059    0.72696    0.72512
alpha_9                               0.72709     0.00057    0.72798    0.72620
Alpha_loss                            -1.86422    0.01269    -1.83980   -1.88248
Training/policy_loss                  -16.75304   0.08508    -16.62674  -16.86686
Training/qf1_loss                     503.51458   190.90826  890.23370  232.13777
Training/qf2_loss                     521.32249   193.55584  912.58386  245.75310
Training/pf_norm                      0.23840     0.03929    0.32631    0.18632
Training/qf1_norm                     262.28751   49.64603   336.00150  171.73663
Training/qf2_norm                     287.14332   48.70276   358.97864  198.02295
log_std/mean                          -0.21169    0.00119    -0.20997   -0.21346
log_std/std                           0.07939     0.00055    0.07997    0.07818
log_std/max                           -0.12620    0.00203    -0.12405   -0.13003
log_std/min                           -0.51414    0.00600    -0.50482   -0.52470
log_probs/mean                        -1.84966    0.04538    -1.76459   -1.91988
log_probs/std                         1.42074     0.03772    1.47738    1.33677
log_probs/max                         3.85475     0.20348    4.19420    3.49195
log_probs/min                         -6.86071    0.52386    -5.79891   -7.54747
mean/mean                             0.06474     0.00350    0.06935    0.05906
mean/std                              0.56247     0.00534    0.56801    0.55252
mean/max                              1.24437     0.01734    1.27186    1.21691
mean/min                              -1.57628    0.01793    -1.55127   -1.60790
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 4, 6, 0, 5, 8, 9, 2, 7, 3]
replay_buffer._size: [16500 16500 16500 16500 16500 16500 16500 16500 16500 16500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.437756061553955 0.0022602081298828125
train_time 4.44124698638916
2023-09-06 13:58:17,108 MainThread INFO: EPOCH:108
2023-09-06 13:58:17,109 MainThread INFO: Time Consumed:4.452919960021973s
2023-09-06 13:58:17,109 MainThread INFO: Total Frames:163500s
 27%|‚ñà‚ñà‚ñã       | 109/400 [04:56<21:45,  4.49s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               230.71376
Train_Epoch_Reward                    2948.00477
Running_Training_Average_Rewards      302.31886
Explore_Time                          0.00309
Train___Time                          4.44125
Eval____Time                          0.00454
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.76066
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.32808
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.08637
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.59676
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.43895
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.57554
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.37402
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2398.74795
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.23453
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.02592
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.78759     0.70879    6.91879    4.60195
alpha_0                               0.73842     0.00037    0.73900    0.73783
alpha_1                               0.72320     0.00059    0.72412    0.72228
alpha_2                               0.72259     0.00061    0.72354    0.72164
alpha_3                               0.72242     0.00061    0.72337    0.72146
alpha_4                               0.72439     0.00057    0.72529    0.72350
alpha_5                               0.72530     0.00055    0.72616    0.72445
alpha_6                               0.72521     0.00055    0.72608    0.72434
alpha_7                               0.72494     0.00056    0.72582    0.72405
alpha_8                               0.72400     0.00058    0.72491    0.72309
alpha_9                               0.72511     0.00056    0.72600    0.72423
Alpha_loss                            -1.86856    0.00464    -1.86186   -1.87630
Training/policy_loss                  -17.04204   0.08870    -16.91189  -17.18753
Training/qf1_loss                     621.06880   230.27789  935.20215  217.84714
Training/qf2_loss                     639.38517   233.43268  956.79688  229.65283
Training/pf_norm                      0.24021     0.03825    0.33443    0.20221
Training/qf1_norm                     266.54337   59.39717   365.37213  168.91393
Training/qf2_norm                     292.00600   58.60639   390.90973  196.94046
log_std/mean                          -0.21631    0.00153    -0.21401   -0.21874
log_std/std                           0.07790     0.00068    0.07930    0.07714
log_std/max                           -0.13449    0.00184    -0.13120   -0.13647
log_std/min                           -0.51859    0.00564    -0.50971   -0.52798
log_probs/mean                        -1.81368    0.01898    -1.77915   -1.84156
log_probs/std                         1.44615     0.01858    1.47965    1.41823
log_probs/max                         4.03601     0.16848    4.29190    3.70191
log_probs/min                         -6.61750    0.64793    -5.84936   -7.97653
mean/mean                             0.07253     0.00127    0.07371    0.06997
mean/std                              0.57210     0.00267    0.57658    0.56849
mean/max                              1.26985     0.01015    1.28395    1.25306
mean/min                              -1.57613    0.01225    -1.55748   -1.59048
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 4, 9, 0, 8, 6, 2, 5, 1, 3]
replay_buffer._size: [16650 16650 16650 16650 16650 16650 16650 16650 16650 16650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.367409706115723 0.0020475387573242188
train_time 4.370664119720459
2023-09-06 13:58:21,596 MainThread INFO: EPOCH:109
2023-09-06 13:58:21,597 MainThread INFO: Time Consumed:4.381683826446533s
2023-09-06 13:58:21,597 MainThread INFO: Total Frames:165000s
 28%|‚ñà‚ñà‚ñä       | 110/400 [05:01<21:41,  4.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               218.53953
Train_Epoch_Reward                    5043.18429
Running_Training_Average_Rewards      350.41507
Explore_Time                          0.00319
Train___Time                          4.37066
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.58501
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.42466
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.16749
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.48689
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.37190
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.43697
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.24882
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2210.72611
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.42875
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.96717
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.99142     0.66270    7.21382     4.66529
alpha_0                               0.73712     0.00037    0.73770     0.73655
alpha_1                               0.72115     0.00059    0.72207     0.72023
alpha_2                               0.72049     0.00060    0.72143     0.71954
alpha_3                               0.72030     0.00061    0.72125     0.71936
alpha_4                               0.72241     0.00057    0.72330     0.72152
alpha_5                               0.72341     0.00054    0.72426     0.72256
alpha_6                               0.72329     0.00055    0.72415     0.72243
alpha_7                               0.72298     0.00056    0.72386     0.72210
alpha_8                               0.72199     0.00057    0.72289     0.72109
alpha_9                               0.72316     0.00056    0.72403     0.72228
Alpha_loss                            -1.86595    0.01100    -1.85417    -1.89089
Training/policy_loss                  -17.33285   0.08790    -17.18763   -17.47525
Training/qf1_loss                     603.54617   318.64882  1310.02185  241.69218
Training/qf2_loss                     622.66891   321.60639  1335.67163  253.70728
Training/pf_norm                      0.23070     0.02050    0.26833     0.19111
Training/qf1_norm                     278.96713   56.44739   383.93793   168.77202
Training/qf2_norm                     305.01443   55.50691   408.35678   197.37389
log_std/mean                          -0.22073    0.00089    -0.21905    -0.22182
log_std/std                           0.08241     0.00100    0.08340     0.08029
log_std/max                           -0.13502    0.00061    -0.13421    -0.13621
log_std/min                           -0.53922    0.00655    -0.52835    -0.55246
log_probs/mean                        -1.75635    0.04605    -1.70034    -1.85494
log_probs/std                         1.47664     0.02294    1.51263     1.43612
log_probs/max                         4.04167     0.18941    4.47023     3.80511
log_probs/min                         -7.64746    1.68677    -5.95590    -11.07741
mean/mean                             0.07368     0.00015    0.07398     0.07350
mean/std                              0.58710     0.00513    0.59297     0.57808
mean/max                              1.29000     0.01104    1.31347     1.27676
mean/min                              -1.59938    0.01695    -1.57770    -1.63542
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 3, 6, 2, 7, 9, 1, 4, 8, 0]
replay_buffer._size: [16800 16800 16800 16800 16800 16800 16800 16800 16800 16800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.430530071258545 0.0019450187683105469
train_time 4.433706283569336
2023-09-06 13:58:26,142 MainThread INFO: EPOCH:110
2023-09-06 13:58:26,143 MainThread INFO: Time Consumed:4.444288492202759s
2023-09-06 13:58:26,143 MainThread INFO: Total Frames:166500s
 28%|‚ñà‚ñà‚ñä       | 111/400 [05:05<21:43,  4.51s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               188.28078
Train_Epoch_Reward                    4328.50752
Running_Training_Average_Rewards      410.65655
Explore_Time                          0.00294
Train___Time                          4.43371
Eval____Time                          0.00343
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.92694
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.40180
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.20153
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.90685
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.42299
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.26448
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.82854
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2072.66107
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.43665
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.78337
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.49775     0.51764    6.32318     4.65321
alpha_0                               0.73586     0.00036    0.73643     0.73530
alpha_1                               0.71912     0.00058    0.72003     0.71821
alpha_2                               0.71839     0.00060    0.71933     0.71745
alpha_3                               0.71820     0.00060    0.71914     0.71725
alpha_4                               0.72045     0.00056    0.72133     0.71957
alpha_5                               0.72154     0.00053    0.72237     0.72070
alpha_6                               0.72140     0.00054    0.72224     0.72055
alpha_7                               0.72104     0.00055    0.72191     0.72017
alpha_8                               0.72000     0.00057    0.72089     0.71910
alpha_9                               0.72123     0.00055    0.72209     0.72037
Alpha_loss                            -1.87578    0.00937    -1.86554    -1.89644
Training/policy_loss                  -17.61763   0.08401    -17.51073   -17.75464
Training/qf1_loss                     574.15695   291.99717  1095.78784  236.98528
Training/qf2_loss                     591.27762   294.44074  1117.04529  249.55942
Training/pf_norm                      0.24353     0.04034    0.31414     0.17739
Training/qf1_norm                     239.77064   45.18563   307.20486   169.37273
Training/qf2_norm                     266.83095   44.76051   334.37006   196.69305
log_std/mean                          -0.21631    0.00158    -0.21478    -0.21964
log_std/std                           0.08047     0.00116    0.08258     0.07922
log_std/max                           -0.13214    0.00171    -0.13052    -0.13561
log_std/min                           -0.52959    0.00741    -0.52138    -0.54273
log_probs/mean                        -1.73897    0.02157    -1.71426    -1.79015
log_probs/std                         1.48150     0.03717    1.52765     1.41672
log_probs/max                         4.28065     0.20835    4.58346     3.92020
log_probs/min                         -7.11372    1.20289    -5.78964    -9.77015
mean/mean                             0.07555     0.00150    0.07773     0.07373
mean/std                              0.59307     0.00098    0.59552     0.59227
mean/max                              1.29563     0.00785    1.30588     1.28146
mean/min                              -1.60948    0.01017    -1.59418    -1.62583
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 5, 8, 1, 3, 4, 7, 2, 0, 9]
replay_buffer._size: [16950 16950 16950 16950 16950 16950 16950 16950 16950 16950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.411535739898682 0.0022962093353271484
train_time 4.415155410766602
2023-09-06 13:58:30,695 MainThread INFO: EPOCH:111
2023-09-06 13:58:30,695 MainThread INFO: Time Consumed:4.431514739990234s
2023-09-06 13:58:30,696 MainThread INFO: Total Frames:168000s
 28%|‚ñà‚ñà‚ñä       | 112/400 [05:10<21:43,  4.53s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               175.09855
Train_Epoch_Reward                    2412.36745
Running_Training_Average_Rewards      392.80198
Explore_Time                          0.00309
Train___Time                          4.41516
Eval____Time                          0.00787
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.28399
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.74502
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.24018
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.96723
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.20557
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.84305
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.50739
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2018.33076
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.99280
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.68536
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.97790     0.98198    8.28055     4.43839
alpha_0                               0.73460     0.00036    0.73517     0.73404
alpha_1                               0.71710     0.00058    0.71800     0.71620
alpha_2                               0.71630     0.00060    0.71724     0.71536
alpha_3                               0.71610     0.00060    0.71704     0.71516
alpha_4                               0.71849     0.00056    0.71937     0.71761
alpha_5                               0.71968     0.00053    0.72051     0.71885
alpha_6                               0.71952     0.00053    0.72036     0.71870
alpha_7                               0.71911     0.00055    0.71998     0.71825
alpha_8                               0.71802     0.00057    0.71891     0.71713
alpha_9                               0.71932     0.00055    0.72018     0.71846
Alpha_loss                            -1.87319    0.01037    -1.85669    -1.89015
Training/policy_loss                  -17.90576   0.08032    -17.78319   -18.00551
Training/qf1_loss                     809.90214   463.88672  1864.63647  285.70071
Training/qf2_loss                     829.76164   469.39576  1897.63245  296.35181
Training/pf_norm                      0.24866     0.04718    0.35908     0.19006
Training/qf1_norm                     278.81663   85.76009   477.49136   139.12140
Training/qf2_norm                     305.78967   83.77856   498.91589   168.42267
log_std/mean                          -0.22086    0.00260    -0.21686    -0.22459
log_std/std                           0.08239     0.00193    0.08559     0.07993
log_std/max                           -0.13171    0.00153    -0.12908    -0.13439
log_std/min                           -0.53168    0.00798    -0.51790    -0.54206
log_probs/mean                        -1.68362    0.04094    -1.62945    -1.74718
log_probs/std                         1.50895     0.04945    1.60457     1.43776
log_probs/max                         4.12488     0.32299    4.67568     3.63562
log_probs/min                         -7.00172    0.83567    -5.58369    -8.47338
mean/mean                             0.07954     0.00089    0.08063     0.07806
mean/std                              0.60559     0.00491    0.61174     0.59757
mean/max                              1.31969     0.01351    1.33241     1.29447
mean/min                              -1.63087    0.01661    -1.59879    -1.64541
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 4, 7, 3, 6, 5, 1, 8, 2]
replay_buffer._size: [17100 17100 17100 17100 17100 17100 17100 17100 17100 17100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.465455055236816 0.002018451690673828
train_time 4.468711614608765
2023-09-06 13:58:35,312 MainThread INFO: EPOCH:112
2023-09-06 13:58:35,313 MainThread INFO: Time Consumed:4.483813285827637s
2023-09-06 13:58:35,314 MainThread INFO: Total Frames:169500s
 28%|‚ñà‚ñà‚ñä       | 113/400 [05:14<21:45,  4.55s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               170.43715
Train_Epoch_Reward                    4782.26851
Running_Training_Average_Rewards      384.10478
Explore_Time                          0.00330
Train___Time                          4.46871
Eval____Time                          0.00593
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.12059
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.49860
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.03513
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.59021
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.52083
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.88642
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.31676
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2077.21953
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.49883
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.98587
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.72328     0.50889    6.47101     4.61053
alpha_0                               0.73339     0.00034    0.73392     0.73285
alpha_1                               0.71509     0.00058    0.71599     0.71419
alpha_2                               0.71422     0.00060    0.71516     0.71329
alpha_3                               0.71402     0.00060    0.71495     0.71308
alpha_4                               0.71654     0.00056    0.71742     0.71567
alpha_5                               0.71784     0.00053    0.71867     0.71702
alpha_6                               0.71768     0.00053    0.71851     0.71685
alpha_7                               0.71720     0.00055    0.71806     0.71634
alpha_8                               0.71605     0.00057    0.71694     0.71516
alpha_9                               0.71741     0.00055    0.71827     0.71655
Alpha_loss                            -1.88714    0.00756    -1.87595    -1.89809
Training/policy_loss                  -18.19147   0.08349    -18.08800   -18.35231
Training/qf1_loss                     599.81387   268.89845  1237.93311  280.16327
Training/qf2_loss                     618.35394   271.58846  1261.05273  292.24725
Training/pf_norm                      0.24532     0.05847    0.39601     0.18887
Training/qf1_norm                     258.17389   45.37622   329.73734   167.12807
Training/qf2_norm                     286.02430   44.07247   355.46518   197.26823
log_std/mean                          -0.22781    0.00210    -0.22524    -0.23172
log_std/std                           0.08989     0.00260    0.09365     0.08607
log_std/max                           -0.12830    0.00097    -0.12650    -0.12963
log_std/min                           -0.56100    0.01174    -0.53974    -0.58064
log_probs/mean                        -1.67911    0.03359    -1.62472    -1.72890
log_probs/std                         1.55757     0.03429    1.60313     1.47514
log_probs/max                         4.43669     0.16532    4.69802     4.14852
log_probs/min                         -7.15701    0.73346    -5.85967    -8.94101
mean/mean                             0.07569     0.00203    0.07892     0.07269
mean/std                              0.61663     0.00368    0.62316     0.61212
mean/max                              1.33130     0.01112    1.34933     1.31150
mean/min                              -1.65510    0.01598    -1.62328    -1.68127
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 9, 0, 2, 6, 7, 3, 1, 4, 5]
replay_buffer._size: [17250 17250 17250 17250 17250 17250 17250 17250 17250 17250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.446390151977539 0.0020966529846191406
train_time 4.449720144271851
2023-09-06 13:58:39,897 MainThread INFO: EPOCH:113
2023-09-06 13:58:39,897 MainThread INFO: Time Consumed:4.466048002243042s
2023-09-06 13:58:39,898 MainThread INFO: Total Frames:171000s
 28%|‚ñà‚ñà‚ñä       | 114/400 [05:19<21:44,  4.56s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               174.65773
Train_Epoch_Reward                    2483.71348
Running_Training_Average_Rewards      322.61165
Explore_Time                          0.00327
Train___Time                          4.44972
Eval____Time                          0.00852
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.23326
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.48322
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.58033
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.22697
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.45548
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -56.35618
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.64988
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2182.36149
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.99996
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.27061
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.78470     0.57108    6.66202     4.83339
alpha_0                               0.73221     0.00033    0.73273     0.73169
alpha_1                               0.71309     0.00057    0.71399     0.71220
alpha_2                               0.71215     0.00059    0.71308     0.71122
alpha_3                               0.71193     0.00060    0.71287     0.71100
alpha_4                               0.71462     0.00055    0.71548     0.71377
alpha_5                               0.71602     0.00052    0.71684     0.71521
alpha_6                               0.71584     0.00053    0.71667     0.71502
alpha_7                               0.71529     0.00054    0.71615     0.71445
alpha_8                               0.71408     0.00056    0.71497     0.71320
alpha_9                               0.71551     0.00054    0.71636     0.71467
Alpha_loss                            -1.87926    0.00598    -1.87086    -1.89125
Training/policy_loss                  -18.49320   0.08801    -18.35787   -18.63267
Training/qf1_loss                     627.65800   298.92243  1310.05933  349.30472
Training/qf2_loss                     646.78524   301.00628  1331.81323  368.34610
Training/pf_norm                      0.25984     0.03235    0.30500     0.18473
Training/qf1_norm                     267.34988   49.93924   333.21835   177.83257
Training/qf2_norm                     295.95376   49.23847   359.39160   207.40538
log_std/mean                          -0.23197    0.00132    -0.22926    -0.23318
log_std/std                           0.09311     0.00115    0.09433     0.09085
log_std/max                           -0.13311    0.00155    -0.12985    -0.13486
log_std/min                           -0.58193    0.00545    -0.57019    -0.59054
log_probs/mean                        -1.60940    0.02244    -1.57245    -1.63871
log_probs/std                         1.56226     0.03259    1.61509     1.50713
log_probs/max                         4.35570     0.31780    4.91684     3.87813
log_probs/min                         -6.50508    0.73781    -5.81178    -8.43775
mean/mean                             0.07222     0.00089    0.07411     0.07139
mean/std                              0.62439     0.00075    0.62576     0.62306
mean/max                              1.34073     0.00934    1.35608     1.32510
mean/min                              -1.66707    0.01355    -1.64861    -1.69510
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 7, 8, 6, 9, 5, 3, 1, 4]
replay_buffer._size: [17400 17400 17400 17400 17400 17400 17400 17400 17400 17400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.608853578567505 0.0020651817321777344
train_time 4.612154483795166
2023-09-06 13:58:44,647 MainThread INFO: EPOCH:114
2023-09-06 13:58:44,648 MainThread INFO: Time Consumed:4.628862380981445s
2023-09-06 13:58:44,648 MainThread INFO: Total Frames:172500s
 29%|‚ñà‚ñà‚ñâ       | 115/400 [05:24<21:55,  4.62s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               179.62932
Train_Epoch_Reward                    3230.77901
Running_Training_Average_Rewards      349.89203
Explore_Time                          0.00287
Train___Time                          4.61215
Eval____Time                          0.00984
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.42181
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.27721
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.87674
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.69910
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.14386
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -54.68273
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.38746
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2151.48797
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.37993
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.61146
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.65917     0.48453    6.65822    4.93140
alpha_0                               0.73106     0.00033    0.73158    0.73054
alpha_1                               0.71111     0.00057    0.71200    0.71021
alpha_2                               0.71008     0.00059    0.71101    0.70915
alpha_3                               0.70986     0.00059    0.71079    0.70893
alpha_4                               0.71273     0.00054    0.71358    0.71187
alpha_5                               0.71422     0.00052    0.71503    0.71341
alpha_6                               0.71401     0.00053    0.71483    0.71319
alpha_7                               0.71340     0.00055    0.71426    0.71255
alpha_8                               0.71213     0.00056    0.71301    0.71126
alpha_9                               0.71363     0.00054    0.71448    0.71279
Alpha_loss                            -1.90350    0.01355    -1.88235   -1.93122
Training/policy_loss                  -18.79048   0.08382    -18.67025  -18.92667
Training/qf1_loss                     485.06124   177.64947  897.80859  263.18561
Training/qf2_loss                     504.11684   179.56429  922.18134  278.63461
Training/pf_norm                      0.27816     0.05423    0.41585    0.23670
Training/qf1_norm                     256.53072   41.33043   343.26868  196.87010
Training/qf2_norm                     284.97270   41.10985   370.41663  225.40781
log_std/mean                          -0.22708    0.00092    -0.22594   -0.22885
log_std/std                           0.08756     0.00115    0.09014    0.08646
log_std/max                           -0.13252    0.00068    -0.13090   -0.13351
log_std/min                           -0.54635    0.00849    -0.53440   -0.56535
log_probs/mean                        -1.63761    0.03566    -1.58584   -1.71316
log_probs/std                         1.56149     0.02899    1.61917    1.52115
log_probs/max                         4.19628     0.15202    4.39792    3.92972
log_probs/min                         -6.69962    0.48889    -6.04039   -7.48235
mean/mean                             0.07909     0.00276    0.08314    0.07488
mean/std                              0.62278     0.00318    0.63037    0.62015
mean/max                              1.32553     0.00504    1.33327    1.31791
mean/min                              -1.61932    0.00991    -1.60699   -1.64466
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 7, 3, 5, 2, 9, 0, 6, 8, 4]
replay_buffer._size: [17550 17550 17550 17550 17550 17550 17550 17550 17550 17550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.503963470458984 0.002199411392211914
train_time 4.507389068603516
2023-09-06 13:58:49,282 MainThread INFO: EPOCH:115
2023-09-06 13:58:49,283 MainThread INFO: Time Consumed:4.520953178405762s
2023-09-06 13:58:49,283 MainThread INFO: Total Frames:174000s
 29%|‚ñà‚ñà‚ñâ       | 116/400 [05:28<21:52,  4.62s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               182.98314
Train_Epoch_Reward                    3184.06243
Running_Training_Average_Rewards      296.61850
Explore_Time                          0.00350
Train___Time                          4.50739
Eval____Time                          0.00590
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.65320
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.12735
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.59774
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.45696
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.26118
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.71160
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.74269
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2168.65007
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.95043
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.76807
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.62732     0.68546    7.53955     4.93908
alpha_0                               0.72990     0.00033    0.73043     0.72939
alpha_1                               0.70912     0.00057    0.71002     0.70823
alpha_2                               0.70802     0.00059    0.70895     0.70709
alpha_3                               0.70780     0.00059    0.70873     0.70688
alpha_4                               0.71084     0.00054    0.71169     0.71000
alpha_5                               0.71242     0.00051    0.71323     0.71162
alpha_6                               0.71219     0.00052    0.71300     0.71138
alpha_7                               0.71151     0.00054    0.71236     0.71066
alpha_8                               0.71019     0.00055    0.71106     0.70933
alpha_9                               0.71176     0.00053    0.71260     0.71093
Alpha_loss                            -1.89209    0.01484    -1.85779    -1.91017
Training/policy_loss                  -19.08007   0.07940    -18.96922   -19.19257
Training/qf1_loss                     591.42702   374.76615  1633.81860  294.43680
Training/qf2_loss                     610.61899   378.89591  1665.21094  309.86020
Training/pf_norm                      0.27249     0.05533    0.41038     0.18759
Training/qf1_norm                     253.36270   62.14370   426.90259   193.00935
Training/qf2_norm                     282.05198   60.69853   451.34290   222.01395
log_std/mean                          -0.23362    0.00201    -0.23002    -0.23560
log_std/std                           0.08814     0.00080    0.08909     0.08681
log_std/max                           -0.13352    0.00072    -0.13275    -0.13512
log_std/min                           -0.54780    0.00782    -0.53499    -0.55872
log_probs/mean                        -1.56002    0.05043    -1.44870    -1.63006
log_probs/std                         1.58928     0.05128    1.69022     1.52506
log_probs/max                         4.51897     0.25020    5.04063     4.16154
log_probs/min                         -7.33489    0.89237    -6.06366    -9.32556
mean/mean                             0.08629     0.00138    0.08776     0.08372
mean/std                              0.64727     0.00816    0.65711     0.63295
mean/max                              1.36458     0.02412    1.39503     1.32086
mean/min                              -1.66598    0.03035    -1.61130    -1.70569
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 2, 4, 0, 8, 6, 9, 3, 1, 7]
replay_buffer._size: [17700 17700 17700 17700 17700 17700 17700 17700 17700 17700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.659133672714233 0.002618074417114258
train_time 4.663407325744629
2023-09-06 13:58:54,078 MainThread INFO: EPOCH:116
2023-09-06 13:58:54,079 MainThread INFO: Time Consumed:4.687293291091919s
2023-09-06 13:58:54,079 MainThread INFO: Total Frames:175500s
 29%|‚ñà‚ñà‚ñâ       | 117/400 [05:33<22:03,  4.68s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               188.83305
Train_Epoch_Reward                    4109.74330
Running_Training_Average_Rewards      350.81949
Explore_Time                          0.00480
Train___Time                          4.66341
Eval____Time                          0.01421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.47940
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.99038
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.42872
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.10255
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.05747
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            108.73825
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.62055
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2199.91953
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.73697
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.63885
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std       Max        Min
Reward_Mean                           5.39549     0.37041   6.13014    4.73286
alpha_0                               0.72878     0.00032   0.72928    0.72827
alpha_1                               0.70715     0.00057   0.70803    0.70626
alpha_2                               0.70596     0.00059   0.70689    0.70504
alpha_3                               0.70576     0.00059   0.70667    0.70484
alpha_4                               0.70898     0.00053   0.70981    0.70814
alpha_5                               0.71064     0.00051   0.71144    0.70985
alpha_6                               0.71040     0.00051   0.71120    0.70961
alpha_7                               0.70964     0.00053   0.71048    0.70880
alpha_8                               0.70828     0.00055   0.70914    0.70742
alpha_9                               0.70991     0.00053   0.71074    0.70908
Alpha_loss                            -1.88919    0.01107   -1.87030   -1.91138
Training/policy_loss                  -19.36555   0.07418   -19.24205  -19.47312
Training/qf1_loss                     362.93623   89.18096  535.03906  276.28082
Training/qf2_loss                     381.06833   90.96959  557.94995  292.24658
Training/pf_norm                      0.26022     0.04361   0.36824    0.19804
Training/qf1_norm                     230.92695   31.35517  293.70602  173.74411
Training/qf2_norm                     260.33215   30.78249  321.62863  203.62550
log_std/mean                          -0.23687    0.00043   -0.23609   -0.23765
log_std/std                           0.08775     0.00055   0.08871    0.08708
log_std/max                           -0.14076    0.00246   -0.13625   -0.14395
log_std/min                           -0.55777    0.00465   -0.55030   -0.56515
log_probs/mean                        -1.50796    0.02646   -1.46498   -1.56335
log_probs/std                         1.61640     0.03075   1.67442    1.57070
log_probs/max                         4.56883     0.24392   4.99526    4.16325
log_probs/min                         -7.04378    0.62564   -6.03536   -7.92054
mean/mean                             0.08461     0.00163   0.08695    0.08233
mean/std                              0.65848     0.00091   0.66013    0.65710
mean/max                              1.37474     0.00871   1.38869    1.35897
mean/min                              -1.70565    0.01303   -1.68395   -1.72065
------------------------------------  ----------  --------  ---------  ---------
sample: [6, 8, 2, 0, 5, 1, 7, 3, 4, 9]
replay_buffer._size: [17850 17850 17850 17850 17850 17850 17850 17850 17850 17850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.5237157344818115 0.0022819042205810547
train_time 4.527277946472168
2023-09-06 13:58:58,740 MainThread INFO: EPOCH:117
2023-09-06 13:58:58,741 MainThread INFO: Time Consumed:4.5380895137786865s
2023-09-06 13:58:58,741 MainThread INFO: Total Frames:177000s
 30%|‚ñà‚ñà‚ñâ       | 118/400 [05:38<21:55,  4.67s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               191.04993
Train_Epoch_Reward                    2897.79310
Running_Training_Average_Rewards      339.71996
Explore_Time                          0.00299
Train___Time                          4.52728
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.06487
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.23600
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.43959
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.12796
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.93595
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            101.52516
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.29359
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2068.08646
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.53092
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.46850
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.56233     0.52574    6.58527    4.76801
alpha_0                               0.72766     0.00032    0.72816    0.72717
alpha_1                               0.70518     0.00056    0.70606    0.70430
alpha_2                               0.70392     0.00059    0.70484    0.70301
alpha_3                               0.70372     0.00058    0.70464    0.70281
alpha_4                               0.70712     0.00053    0.70796    0.70629
alpha_5                               0.70888     0.00050    0.70967    0.70809
alpha_6                               0.70864     0.00051    0.70943    0.70784
alpha_7                               0.70779     0.00053    0.70862    0.70696
alpha_8                               0.70637     0.00055    0.70723    0.70552
alpha_9                               0.70808     0.00052    0.70890    0.70725
Alpha_loss                            -1.90537    0.01491    -1.87772   -1.92951
Training/policy_loss                  -19.66044   0.08608    -19.52249  -19.78931
Training/qf1_loss                     526.00326   207.81597  873.08972  268.94073
Training/qf2_loss                     545.74389   209.99081  894.83203  284.47458
Training/pf_norm                      0.26081     0.04821    0.31682    0.16072
Training/qf1_norm                     248.68098   49.90433   345.40665  178.15872
Training/qf2_norm                     277.63258   48.90036   373.10324  208.98210
log_std/mean                          -0.23798    0.00038    -0.23721   -0.23854
log_std/std                           0.08928     0.00095    0.09090    0.08786
log_std/max                           -0.13799    0.00212    -0.13583   -0.14239
log_std/min                           -0.55829    0.00324    -0.55062   -0.56186
log_probs/mean                        -1.51243    0.03781    -1.44144   -1.58192
log_probs/std                         1.63473     0.02486    1.67210    1.59691
log_probs/max                         4.45729     0.14596    4.77558    4.21495
log_probs/min                         -7.52524    0.93301    -6.41184   -9.59284
mean/mean                             0.08531     0.00223    0.08917    0.08245
mean/std                              0.65365     0.00282    0.65771    0.65035
mean/max                              1.34772     0.00685    1.35758    1.33287
mean/min                              -1.67543    0.01519    -1.64999   -1.69812
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 7, 0, 5, 3, 6, 4, 8, 9, 1]
replay_buffer._size: [18000 18000 18000 18000 18000 18000 18000 18000 18000 18000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.5468292236328125 0.0020780563354492188
train_time 4.550170660018921
2023-09-06 13:59:03,407 MainThread INFO: EPOCH:118
2023-09-06 13:59:03,408 MainThread INFO: Time Consumed:4.56436014175415s
2023-09-06 13:59:03,408 MainThread INFO: Total Frames:178500s
 30%|‚ñà‚ñà‚ñâ       | 119/400 [05:43<21:50,  4.67s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               187.07007
Train_Epoch_Reward                    2835.70396
Running_Training_Average_Rewards      328.10801
Explore_Time                          0.00341
Train___Time                          4.55017
Eval____Time                          0.00304
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.54339
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.12627
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.02741
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.56052
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.92635
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            84.09295
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.20567
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1922.28658
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.27974
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.72526
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.44103     0.50599    6.37195     4.63917
alpha_0                               0.72656     0.00032    0.72706     0.72607
alpha_1                               0.70323     0.00056    0.70410     0.70236
alpha_2                               0.70189     0.00058    0.70280     0.70097
alpha_3                               0.70170     0.00058    0.70261     0.70079
alpha_4                               0.70527     0.00053    0.70610     0.70444
alpha_5                               0.70712     0.00050    0.70791     0.70633
alpha_6                               0.70686     0.00051    0.70767     0.70606
alpha_7                               0.70594     0.00053    0.70677     0.70512
alpha_8                               0.70448     0.00054    0.70533     0.70363
alpha_9                               0.70625     0.00053    0.70707     0.70542
Alpha_loss                            -1.91691    0.01048    -1.89926    -1.93540
Training/policy_loss                  -19.95352   0.08478    -19.80378   -20.09975
Training/qf1_loss                     590.15504   348.84181  1349.89380  249.90686
Training/qf2_loss                     609.61784   350.89115  1369.71570  266.74149
Training/pf_norm                      0.25981     0.03190    0.31554     0.19010
Training/qf1_norm                     236.18058   48.96337   324.70422   160.08365
Training/qf2_norm                     265.07205   48.66313   351.69083   189.54829
log_std/mean                          -0.24085    0.00146    -0.23858    -0.24294
log_std/std                           0.09350     0.00122    0.09494     0.09138
log_std/max                           -0.13435    0.00078    -0.13333    -0.13583
log_std/min                           -0.56711    0.00492    -0.55856    -0.57530
log_probs/mean                        -1.50422    0.03439    -1.44488    -1.56196
log_probs/std                         1.62661     0.03987    1.68805     1.56773
log_probs/max                         4.79649     0.25044    5.11242     4.37943
log_probs/min                         -6.82090    0.79460    -5.98234    -8.20159
mean/mean                             0.09232     0.00107    0.09340     0.09010
mean/std                              0.65858     0.00509    0.66674     0.65109
mean/max                              1.35351     0.00667    1.36760     1.34238
mean/min                              -1.67058    0.01163    -1.64996    -1.68903
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 0, 1, 3, 4, 9, 7, 8, 2, 6]
replay_buffer._size: [18150 18150 18150 18150 18150 18150 18150 18150 18150 18150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.400697469711304 0.0020227432250976562
train_time 4.403979539871216
2023-09-06 13:59:07,919 MainThread INFO: EPOCH:119
2023-09-06 13:59:07,920 MainThread INFO: Time Consumed:4.414663076400757s
2023-09-06 13:59:07,920 MainThread INFO: Total Frames:180000s
 30%|‚ñà‚ñà‚ñà       | 120/400 [05:47<21:34,  4.62s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               173.94383
Train_Epoch_Reward                    1419.32137
Running_Training_Average_Rewards      238.42728
Explore_Time                          0.00272
Train___Time                          4.40398
Eval____Time                          0.00406
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.08023
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.06343
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.91444
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.52613
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.36716
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            88.12979
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.45619
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1841.80391
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.20916
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.50122
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.14764     0.36136    5.91283    4.36155
alpha_0                               0.72547     0.00031    0.72596    0.72498
alpha_1                               0.70129     0.00056    0.70216    0.70042
alpha_2                               0.69985     0.00058    0.70077    0.69894
alpha_3                               0.69968     0.00058    0.70059    0.69878
alpha_4                               0.70342     0.00053    0.70425    0.70260
alpha_5                               0.70538     0.00049    0.70616    0.70461
alpha_6                               0.70509     0.00051    0.70588    0.70430
alpha_7                               0.70411     0.00052    0.70493    0.70329
alpha_8                               0.70260     0.00054    0.70344    0.70176
alpha_9                               0.70443     0.00052    0.70524    0.70361
Alpha_loss                            -1.90953    0.01686    -1.88406   -1.95090
Training/policy_loss                  -20.21914   0.08449    -20.08026  -20.32646
Training/qf1_loss                     355.23618   162.81656  828.48163  218.20320
Training/qf2_loss                     372.54188   164.48350  850.39502  230.77136
Training/pf_norm                      0.27356     0.07780    0.40140    0.16837
Training/qf1_norm                     207.33383   35.85379   283.94659  135.00627
Training/qf2_norm                     237.33513   35.70849   313.81030  164.80772
log_std/mean                          -0.24321    0.00061    -0.24220   -0.24400
log_std/std                           0.09563     0.00022    0.09595    0.09515
log_std/max                           -0.13056    0.00229    -0.12681   -0.13309
log_std/min                           -0.57362    0.00523    -0.56662   -0.58247
log_probs/mean                        -1.44218    0.04379    -1.38441   -1.54820
log_probs/std                         1.64108     0.03160    1.71646    1.60693
log_probs/max                         4.63521     0.13655    4.84133    4.45635
log_probs/min                         -6.71520    0.46982    -6.09929   -7.68578
mean/mean                             0.08886     0.00277    0.09306    0.08487
mean/std                              0.67036     0.00121    0.67185    0.66789
mean/max                              1.36432     0.01311    1.38413    1.34335
mean/min                              -1.70258    0.01505    -1.68126   -1.72606
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 5, 0, 9, 4, 3, 1, 6, 8, 2]
replay_buffer._size: [18300 18300 18300 18300 18300 18300 18300 18300 18300 18300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.453044652938843 0.002020597457885742
train_time 4.4562788009643555
2023-09-06 13:59:12,504 MainThread INFO: EPOCH:120
2023-09-06 13:59:12,504 MainThread INFO: Time Consumed:4.473023176193237s
2023-09-06 13:59:12,505 MainThread INFO: Total Frames:181500s
 30%|‚ñà‚ñà‚ñà       | 121/400 [05:52<21:27,  4.61s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               164.00602
Train_Epoch_Reward                    4654.40410
Running_Training_Average_Rewards      296.98098
Explore_Time                          0.00317
Train___Time                          4.45628
Eval____Time                          0.00784
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.49578
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.54509
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.77096
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.31667
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.43712
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            92.35661
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.48204
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1790.73364
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.94069
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.72186
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.48948     0.49394    6.77452     4.83747
alpha_0                               0.72437     0.00031    0.72487     0.72388
alpha_1                               0.69936     0.00056    0.70023     0.69849
alpha_2                               0.69782     0.00058    0.69874     0.69691
alpha_3                               0.69767     0.00058    0.69858     0.69677
alpha_4                               0.70159     0.00053    0.70241     0.70077
alpha_5                               0.70366     0.00049    0.70444     0.70289
alpha_6                               0.70334     0.00050    0.70413     0.70256
alpha_7                               0.70230     0.00052    0.70311     0.70149
alpha_8                               0.70074     0.00053    0.70157     0.69990
alpha_9                               0.70261     0.00052    0.70343     0.70180
Alpha_loss                            -1.92687    0.01001    -1.91058    -1.95081
Training/policy_loss                  -20.50828   0.08240    -20.36893   -20.62572
Training/qf1_loss                     514.24301   216.95088  1002.05255  285.24719
Training/qf2_loss                     534.22817   219.56098  1028.76843  300.73087
Training/pf_norm                      0.24569     0.02346    0.28176     0.19100
Training/qf1_norm                     242.51732   48.57506   365.08206   173.91199
Training/qf2_norm                     271.52094   48.19154   393.12018   203.19345
log_std/mean                          -0.24456    0.00107    -0.24269    -0.24585
log_std/std                           0.09846     0.00108    0.09940     0.09633
log_std/max                           -0.12476    0.00060    -0.12411    -0.12605
log_std/min                           -0.57884    0.00560    -0.56758    -0.58518
log_probs/mean                        -1.45051    0.02710    -1.40757    -1.50003
log_probs/std                         1.63574     0.03900    1.69216     1.58552
log_probs/max                         4.67541     0.28022    5.09033     4.05012
log_probs/min                         -7.20871    0.88594    -5.98568    -9.18600
mean/mean                             0.08320     0.00033    0.08393     0.08287
mean/std                              0.67050     0.00090    0.67182     0.66907
mean/max                              1.37690     0.01248    1.39084     1.35203
mean/min                              -1.70037    0.01396    -1.68070    -1.72753
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 5, 6, 4, 9, 3, 8, 0, 1, 2]
replay_buffer._size: [18450 18450 18450 18450 18450 18450 18450 18450 18450 18450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.615500211715698 0.0019273757934570312
train_time 4.618647336959839
2023-09-06 13:59:17,250 MainThread INFO: EPOCH:121
2023-09-06 13:59:17,251 MainThread INFO: Time Consumed:4.6291821002960205s
2023-09-06 13:59:17,251 MainThread INFO: Total Frames:183000s
 30%|‚ñà‚ñà‚ñà       | 122/400 [05:56<21:35,  4.66s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               165.33736
Train_Epoch_Reward                    5043.72159
Running_Training_Average_Rewards      370.58157
Explore_Time                          0.00301
Train___Time                          4.61865
Eval____Time                          0.00364
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.59873
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.66132
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.43803
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.36294
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.45843
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            102.69545
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.03561
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1942.25773
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.29451
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.17866
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.41036     0.38184    6.21160     4.87770
alpha_0                               0.72329     0.00031    0.72377     0.72280
alpha_1                               0.69743     0.00055    0.69830     0.69656
alpha_2                               0.69580     0.00058    0.69671     0.69489
alpha_3                               0.69566     0.00057    0.69656     0.69476
alpha_4                               0.69976     0.00052    0.70059     0.69894
alpha_5                               0.70194     0.00049    0.70271     0.70117
alpha_6                               0.70160     0.00050    0.70239     0.70081
alpha_7                               0.70049     0.00052    0.70130     0.69968
alpha_8                               0.69888     0.00053    0.69971     0.69805
alpha_9                               0.70082     0.00051    0.70162     0.70001
Alpha_loss                            -1.93552    0.01067    -1.91369    -1.94982
Training/policy_loss                  -20.79487   0.08647    -20.67670   -20.93655
Training/qf1_loss                     571.10332   289.97223  1130.54016  284.76074
Training/qf2_loss                     591.34782   291.96272  1153.71118  301.76782
Training/pf_norm                      0.25978     0.03527    0.33181     0.19991
Training/qf1_norm                     235.73500   35.32661   307.66605   188.41377
Training/qf2_norm                     264.24822   34.76443   334.88528   218.21701
log_std/mean                          -0.24651    0.00036    -0.24600    -0.24698
log_std/std                           0.09930     0.00026    0.09967     0.09875
log_std/max                           -0.12512    0.00087    -0.12354    -0.12610
log_std/min                           -0.57230    0.00613    -0.56131    -0.58395
log_probs/mean                        -1.43447    0.03296    -1.37193    -1.48706
log_probs/std                         1.66728     0.03640    1.73142     1.62425
log_probs/max                         4.66458     0.21114    5.07018     4.36784
log_probs/min                         -7.22251    0.86212    -6.11932    -9.42453
mean/mean                             0.08626     0.00154    0.08845     0.08412
mean/std                              0.67450     0.00322    0.67871     0.66998
mean/max                              1.40921     0.01026    1.42411     1.39378
mean/min                              -1.69809    0.01043    -1.68437    -1.71759
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 1, 7, 9, 5, 4, 0, 3, 2, 8]
replay_buffer._size: [18600 18600 18600 18600 18600 18600 18600 18600 18600 18600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.228783369064331 0.002025604248046875
train_time 3.23205304145813
2023-09-06 13:59:21,991 MainThread INFO: EPOCH:122
2023-09-06 13:59:21,992 MainThread INFO: Time Consumed:4.600686550140381s
2023-09-06 13:59:21,992 MainThread INFO: Total Frames:184500s
 31%|‚ñà‚ñà‚ñà       | 123/400 [06:01<21:34,  4.67s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               171.14687
Train_Epoch_Reward                    2072.00008
Running_Training_Average_Rewards      392.33753
Explore_Time                          1.35894
Train___Time                          3.23205
Eval____Time                          0.00470
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.17673
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.01351
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.53657
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.39805
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.94975
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            101.83476
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.34205
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1996.22378
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.06712
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.47361
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.39145     0.58188    6.44559    4.63613
alpha_0                               0.72222     0.00030    0.72270    0.72175
alpha_1                               0.69551     0.00055    0.69637    0.69464
alpha_2                               0.69377     0.00058    0.69468    0.69286
alpha_3                               0.69367     0.00057    0.69456    0.69278
alpha_4                               0.69794     0.00052    0.69876    0.69713
alpha_5                               0.70023     0.00049    0.70100    0.69946
alpha_6                               0.69985     0.00050    0.70064    0.69907
alpha_7                               0.69869     0.00052    0.69950    0.69788
alpha_8                               0.69703     0.00053    0.69786    0.69621
alpha_9                               0.69903     0.00051    0.69983    0.69824
Alpha_loss                            -1.93523    0.01716    -1.91346   -1.96230
Training/policy_loss                  -21.05326   0.06810    -20.93682  -21.15334
Training/qf1_loss                     561.89524   170.91642  771.16370  275.62329
Training/qf2_loss                     582.48669   174.12887  795.02747  292.95438
Training/pf_norm                      0.26648     0.05638    0.37128    0.18360
Training/qf1_norm                     236.62673   58.51185   339.03336  159.36182
Training/qf2_norm                     265.42256   58.03357   367.32465  189.34218
log_std/mean                          -0.24527    0.00100    -0.24327   -0.24633
log_std/std                           0.09780     0.00064    0.09865    0.09652
log_std/max                           -0.12525    0.00067    -0.12377   -0.12615
log_std/min                           -0.56738    0.00424    -0.56029   -0.57374
log_probs/mean                        -1.39367    0.04608    -1.34050   -1.46771
log_probs/std                         1.66753     0.01753    1.70771    1.63490
log_probs/max                         4.74692     0.33147    5.06904    4.13431
log_probs/min                         -7.40870    0.99033    -6.35883   -9.69400
mean/mean                             0.08968     0.00064    0.09049    0.08846
mean/std                              0.67931     0.00242    0.68150    0.67392
mean/max                              1.42974     0.00930    1.44642    1.41309
mean/min                              -1.70737    0.01238    -1.68588   -1.72537
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 1, 7, 2, 5, 8, 4, 6, 9, 3]
replay_buffer._size: [18750 18750 18750 18750 18750 18750 18750 18750 18750 18750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.768524169921875 0.002033233642578125
train_time 4.771835565567017
2023-09-06 13:59:26,878 MainThread INFO: EPOCH:123
2023-09-06 13:59:26,878 MainThread INFO: Time Consumed:4.783900260925293s
2023-09-06 13:59:26,879 MainThread INFO: Total Frames:186000s
 31%|‚ñà‚ñà‚ñà       | 124/400 [06:06<21:48,  4.74s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               174.94153
Train_Epoch_Reward                    1056.41041
Running_Training_Average_Rewards      272.40440
Explore_Time                          0.00270
Train___Time                          4.77184
Eval____Time                          0.00534
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.24494
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.38505
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.49912
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.43261
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.21082
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            95.80020
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.06317
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1897.11628
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.76129
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.09956
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.24996     0.31187    5.53784    4.55767
alpha_0                               0.72116     0.00031    0.72164    0.72068
alpha_1                               0.69358     0.00055    0.69445    0.69272
alpha_2                               0.69175     0.00058    0.69266    0.69084
alpha_3                               0.69168     0.00057    0.69258    0.69079
alpha_4                               0.69613     0.00052    0.69694    0.69531
alpha_5                               0.69853     0.00049    0.69929    0.69776
alpha_6                               0.69812     0.00050    0.69890    0.69734
alpha_7                               0.69690     0.00052    0.69770    0.69609
alpha_8                               0.69520     0.00053    0.69603    0.69437
alpha_9                               0.69726     0.00051    0.69806    0.69646
Alpha_loss                            -1.96663    0.01279    -1.93815   -1.98437
Training/policy_loss                  -21.31013   0.07532    -21.18262  -21.42504
Training/qf1_loss                     440.10792   131.14038  697.89148  281.43698
Training/qf2_loss                     460.18443   132.13215  719.82855  296.58200
Training/pf_norm                      0.26828     0.06770    0.39102    0.17484
Training/qf1_norm                     225.37598   30.27927   254.94434  160.98344
Training/qf2_norm                     254.09207   30.48542   284.68307  190.62486
log_std/mean                          -0.24474    0.00128    -0.24303   -0.24685
log_std/std                           0.09824     0.00175    0.10106    0.09600
log_std/max                           -0.12478    0.00080    -0.12287   -0.12562
log_std/min                           -0.57449    0.01247    -0.55499   -0.58945
log_probs/mean                        -1.44283    0.03704    -1.35935   -1.48314
log_probs/std                         1.65129     0.02656    1.68337    1.58343
log_probs/max                         4.66875     0.18325    4.84614    4.31729
log_probs/min                         -7.28251    0.49786    -6.41188   -7.81590
mean/mean                             0.08822     0.00061    0.08904    0.08726
mean/std                              0.67363     0.00166    0.67677    0.67152
mean/max                              1.41733     0.01145    1.43196    1.39864
mean/min                              -1.69137    0.01567    -1.66578   -1.71199
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 0, 8, 6, 4, 9, 5, 1, 7, 2]
replay_buffer._size: [18900 18900 18900 18900 18900 18900 18900 18900 18900 18900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.780275821685791 0.003710031509399414
train_time 4.786251783370972
2023-09-06 13:59:31,792 MainThread INFO: EPOCH:124
2023-09-06 13:59:31,793 MainThread INFO: Time Consumed:4.799438238143921s
2023-09-06 13:59:31,793 MainThread INFO: Total Frames:187500s
 31%|‚ñà‚ñà‚ñà‚ñè      | 125/400 [06:11<22:00,  4.80s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               173.04974
Train_Epoch_Reward                    1711.22192
Running_Training_Average_Rewards      161.32108
Explore_Time                          0.00275
Train___Time                          4.78625
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.13719
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.36855
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.74945
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.55834
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.74718
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            96.64171
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.24932
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1893.29304
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.84729
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.10634
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.18295     0.26831    5.60691    4.65875
alpha_0                               0.72008     0.00031    0.72057    0.71960
alpha_1                               0.69165     0.00055    0.69252    0.69079
alpha_2                               0.68973     0.00058    0.69063    0.68882
alpha_3                               0.68970     0.00057    0.69059    0.68881
alpha_4                               0.69431     0.00052    0.69513    0.69349
alpha_5                               0.69682     0.00049    0.69759    0.69605
alpha_6                               0.69640     0.00049    0.69717    0.69562
alpha_7                               0.69510     0.00052    0.69591    0.69430
alpha_8                               0.69336     0.00053    0.69419    0.69253
alpha_9                               0.69549     0.00051    0.69628    0.69469
Alpha_loss                            -1.97075    0.01079    -1.95284   -1.98987
Training/policy_loss                  -21.56120   0.06991    -21.46313  -21.67291
Training/qf1_loss                     371.76270   138.98818  675.45966  253.50339
Training/qf2_loss                     391.93820   140.22993  696.54858  269.88721
Training/pf_norm                      0.27891     0.05301    0.35605    0.15178
Training/qf1_norm                     219.91499   26.07775   258.43915  166.86334
Training/qf2_norm                     247.98473   25.97661   284.52472  195.38423
log_std/mean                          -0.24873    0.00046    -0.24778   -0.24934
log_std/std                           0.10488     0.00153    0.10650    0.10189
log_std/max                           -0.12099    0.00189    -0.11847   -0.12459
log_std/min                           -0.59545    0.00595    -0.58314   -0.60643
log_probs/mean                        -1.41426    0.03786    -1.35670   -1.47520
log_probs/std                         1.69122     0.03934    1.76896    1.64087
log_probs/max                         4.84378     0.29897    5.32832    4.17873
log_probs/min                         -7.14559    0.62032    -6.17336   -8.21567
mean/mean                             0.08772     0.00059    0.08863    0.08657
mean/std                              0.68549     0.00355    0.68908    0.67885
mean/max                              1.42994     0.01351    1.45250    1.40004
mean/min                              -1.70682    0.01581    -1.67459   -1.73410
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 6, 3, 0, 4, 2, 1, 8, 5, 7]
replay_buffer._size: [19050 19050 19050 19050 19050 19050 19050 19050 19050 19050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.7863359451293945 0.002077341079711914
train_time 2.789677143096924
2023-09-06 13:59:36,884 MainThread INFO: EPOCH:125
2023-09-06 13:59:36,884 MainThread INFO: Time Consumed:2.8022563457489014s
2023-09-06 13:59:36,884 MainThread INFO: Total Frames:189000s
 32%|‚ñà‚ñà‚ñà‚ñè      | 126/400 [06:16<22:18,  4.89s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               171.48078
Train_Epoch_Reward                    2625.99208
Running_Training_Average_Rewards      179.78748
Explore_Time                          0.00370
Train___Time                          2.78968
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.93064
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.54761
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.46229
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.46955
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.30612
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            100.30196
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.96887
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1953.79033
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.00957
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.36520
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.32698     0.39645    5.96531     4.76815
alpha_0                               0.71902     0.00030    0.71950     0.71854
alpha_1                               0.68973     0.00055    0.69059     0.68886
alpha_2                               0.68770     0.00058    0.68861     0.68679
alpha_3                               0.68772     0.00057    0.68861     0.68683
alpha_4                               0.69250     0.00052    0.69331     0.69169
alpha_5                               0.69511     0.00049    0.69588     0.69434
alpha_6                               0.69468     0.00049    0.69545     0.69390
alpha_7                               0.69332     0.00051    0.69412     0.69252
alpha_8                               0.69153     0.00052    0.69235     0.69071
alpha_9                               0.69372     0.00051    0.69451     0.69292
Alpha_loss                            -1.98588    0.01759    -1.94984    -2.01098
Training/policy_loss                  -21.81893   0.06752    -21.71948   -21.94752
Training/qf1_loss                     526.80047   259.68411  1151.10083  284.14673
Training/qf2_loss                     548.30013   262.04233  1177.90186  304.11212
Training/pf_norm                      0.27722     0.04846    0.39709     0.20442
Training/qf1_norm                     237.87430   38.60353   304.35513   181.05524
Training/qf2_norm                     265.84371   37.83099   330.58615   209.76773
log_std/mean                          -0.24472    0.00196    -0.24268    -0.24863
log_std/std                           0.10501     0.00080    0.10638     0.10391
log_std/max                           -0.11883    0.00064    -0.11804    -0.11995
log_std/min                           -0.59068    0.00794    -0.57652    -0.60634
log_probs/mean                        -1.41681    0.04178    -1.33281    -1.49094
log_probs/std                         1.67405     0.04675    1.73941     1.60226
log_probs/max                         4.80912     0.19436    5.16027     4.58452
log_probs/min                         -7.13215    0.62270    -6.12280    -8.56038
mean/mean                             0.08519     0.00047    0.08624     0.08468
mean/std                              0.67894     0.00468    0.68725     0.67345
mean/max                              1.41999     0.01848    1.45325     1.38400
mean/min                              -1.70178    0.02170    -1.65863    -1.74003
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 3, 1, 5, 2, 8, 6, 7, 4]
replay_buffer._size: [19200 19200 19200 19200 19200 19200 19200 19200 19200 19200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.612318515777588 0.0022149085998535156
train_time 2.615805149078369
2023-09-06 13:59:41,816 MainThread INFO: EPOCH:126
2023-09-06 13:59:41,816 MainThread INFO: Time Consumed:2.6286370754241943s
2023-09-06 13:59:41,817 MainThread INFO: Total Frames:190500s
 32%|‚ñà‚ñà‚ñà‚ñè      | 127/400 [06:21<22:16,  4.90s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               174.01062
Train_Epoch_Reward                    1472.38445
Running_Training_Average_Rewards      193.65328
Explore_Time                          0.00359
Train___Time                          2.61581
Eval____Time                          0.00483
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.30035
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.39672
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.57423
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.54724
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.31077
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            102.50043
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.91792
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1969.17686
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.47187
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.04314
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.55727     0.33828    6.09879     5.02497
alpha_0                               0.71795     0.00031    0.71844     0.71745
alpha_1                               0.68780     0.00055    0.68866     0.68693
alpha_2                               0.68567     0.00058    0.68659     0.68476
alpha_3                               0.68574     0.00057    0.68663     0.68485
alpha_4                               0.69070     0.00052    0.69151     0.68988
alpha_5                               0.69338     0.00050    0.69416     0.69260
alpha_6                               0.69296     0.00049    0.69373     0.69218
alpha_7                               0.69155     0.00051    0.69235     0.69076
alpha_8                               0.68971     0.00052    0.69053     0.68889
alpha_9                               0.69195     0.00050    0.69274     0.69117
Alpha_loss                            -2.00965    0.00906    -1.99366    -2.02562
Training/policy_loss                  -22.08223   0.07252    -21.96275   -22.17392
Training/qf1_loss                     558.75786   294.90099  1187.26758  294.77231
Training/qf2_loss                     581.81091   296.91160  1214.15955  315.33636
Training/pf_norm                      0.24078     0.03916    0.30654     0.17370
Training/qf1_norm                     261.65136   38.17150   337.92215   208.22813
Training/qf2_norm                     289.42871   38.15665   366.41354   237.10867
log_std/mean                          -0.24211    0.00066    -0.24141    -0.24358
log_std/std                           0.10301     0.00030    0.10345     0.10259
log_std/max                           -0.12063    0.00075    -0.11951    -0.12205
log_std/min                           -0.57926    0.00483    -0.57183    -0.58628
log_probs/mean                        -1.44393    0.02575    -1.40422    -1.50269
log_probs/std                         1.67269     0.04177    1.72967     1.59685
log_probs/max                         4.68228     0.22968    5.12991     4.35518
log_probs/min                         -7.63010    1.35329    -6.23850    -10.30387
mean/mean                             0.08694     0.00083    0.08805     0.08545
mean/std                              0.67429     0.00234    0.67835     0.67134
mean/max                              1.40639     0.01206    1.42532     1.38668
mean/min                              -1.68059    0.01345    -1.65899    -1.70265
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 9, 3, 2, 0, 1, 8, 6, 7, 4]
replay_buffer._size: [19350 19350 19350 19350 19350 19350 19350 19350 19350 19350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.15093469619751 0.001966714859008789
train_time 5.154112815856934
2023-09-06 13:59:47,103 MainThread INFO: EPOCH:127
2023-09-06 13:59:47,104 MainThread INFO: Time Consumed:5.168829679489136s
2023-09-06 13:59:47,104 MainThread INFO: Total Frames:192000s
 32%|‚ñà‚ñà‚ñà‚ñè      | 128/400 [06:26<22:43,  5.01s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               174.33724
Train_Epoch_Reward                    2971.40487
Running_Training_Average_Rewards      235.65938
Explore_Time                          0.00281
Train___Time                          5.15411
Eval____Time                          0.00667
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.67676
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.58826
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.61980
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.81597
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.68879
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            83.08314
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.57065
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1918.98685
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.52806
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.61194
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.41425     0.41470    6.36516    4.86426
alpha_0                               0.71686     0.00031    0.71734    0.71637
alpha_1                               0.68586     0.00056    0.68673    0.68499
alpha_2                               0.68365     0.00058    0.68456    0.68275
alpha_3                               0.68376     0.00057    0.68465    0.68287
alpha_4                               0.68888     0.00052    0.68970    0.68806
alpha_5                               0.69164     0.00050    0.69242    0.69086
alpha_6                               0.69124     0.00049    0.69201    0.69046
alpha_7                               0.68980     0.00050    0.69059    0.68901
alpha_8                               0.68789     0.00052    0.68871    0.68708
alpha_9                               0.69021     0.00050    0.69099    0.68943
Alpha_loss                            -2.01139    0.01127    -1.98906   -2.02451
Training/policy_loss                  -22.35110   0.07218    -22.23675  -22.45765
Training/qf1_loss                     483.78473   162.81318  828.25684  292.88947
Training/qf2_loss                     506.31945   165.18916  857.29755  311.52838
Training/pf_norm                      0.24556     0.05237    0.35180    0.18956
Training/qf1_norm                     242.87932   42.95901   342.69611  172.63524
Training/qf2_norm                     270.10934   42.61693   368.65964  198.79770
log_std/mean                          -0.24818    0.00180    -0.24455   -0.25038
log_std/std                           0.10441     0.00042    0.10493    0.10373
log_std/max                           -0.12256    0.00134    -0.12031   -0.12507
log_std/min                           -0.59698    0.00626    -0.58377   -0.60468
log_probs/mean                        -1.40892    0.03074    -1.35049   -1.45910
log_probs/std                         1.68199     0.03578    1.72457    1.61682
log_probs/max                         4.81818     0.19948    5.12538    4.54324
log_probs/min                         -7.13156    1.06722    -6.10142   -9.48045
mean/mean                             0.08970     0.00051    0.09018    0.08851
mean/std                              0.68390     0.00182    0.68592    0.67971
mean/max                              1.43109     0.01082    1.45201    1.41349
mean/min                              -1.71231    0.01413    -1.68565   -1.73263
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 6, 4, 2, 8, 3, 1, 7, 5, 0]
replay_buffer._size: [19500 19500 19500 19500 19500 19500 19500 19500 19500 19500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.190366983413696 0.0020101070404052734
train_time 5.193662881851196
2023-09-06 13:59:52,432 MainThread INFO: EPOCH:128
2023-09-06 13:59:52,433 MainThread INFO: Time Consumed:5.205962657928467s
2023-09-06 13:59:52,433 MainThread INFO: Total Frames:193500s
 32%|‚ñà‚ñà‚ñà‚ñè      | 129/400 [06:32<23:02,  5.10s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               164.30674
Train_Epoch_Reward                    2169.81951
Running_Training_Average_Rewards      220.45363
Explore_Time                          0.00278
Train___Time                          5.19366
Eval____Time                          0.00519
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.81040
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.12203
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.23031
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.97279
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.28178
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -42.42643
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.54444
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1808.13436
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.66629
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.96240
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.81281     0.54174    5.92128    4.17878
alpha_0                               0.71580     0.00029    0.71626    0.71534
alpha_1                               0.68393     0.00056    0.68480    0.68306
alpha_2                               0.68164     0.00058    0.68255    0.68073
alpha_3                               0.68178     0.00057    0.68267    0.68090
alpha_4                               0.68706     0.00052    0.68788    0.68624
alpha_5                               0.68990     0.00050    0.69069    0.68912
alpha_6                               0.68952     0.00049    0.69029    0.68875
alpha_7                               0.68805     0.00050    0.68883    0.68727
alpha_8                               0.68608     0.00052    0.68690    0.68527
alpha_9                               0.68848     0.00050    0.68926    0.68770
Alpha_loss                            -2.02129    0.01197    -2.00356   -2.03845
Training/policy_loss                  -22.60985   0.06320    -22.51164  -22.69687
Training/qf1_loss                     293.62550   107.17145  590.85089  201.34911
Training/qf2_loss                     313.22829   110.62034  619.11823  217.13925
Training/pf_norm                      0.28746     0.03929    0.36059    0.22227
Training/qf1_norm                     186.74606   59.17872   310.32874  119.42252
Training/qf2_norm                     214.57119   59.03305   337.05066  147.41641
log_std/mean                          -0.25111    0.00092    -0.24918   -0.25224
log_std/std                           0.10123     0.00148    0.10322    0.09857
log_std/max                           -0.12601    0.00063    -0.12497   -0.12721
log_std/min                           -0.58861    0.00748    -0.57865   -0.60240
log_probs/mean                        -1.39482    0.03348    -1.34894   -1.45519
log_probs/std                         1.73060     0.03525    1.82524    1.68859
log_probs/max                         4.83947     0.23058    5.14819    4.42275
log_probs/min                         -7.65007    1.07563    -5.80720   -9.81462
mean/mean                             0.08898     0.00106    0.09010    0.08749
mean/std                              0.68506     0.00213    0.68724    0.68064
mean/max                              1.42258     0.01324    1.44924    1.39852
mean/min                              -1.72244    0.01368    -1.70095   -1.75031
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 9, 1, 8, 7, 6, 2, 3, 0, 4]
replay_buffer._size: [19650 19650 19650 19650 19650 19650 19650 19650 19650 19650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.135702610015869 0.001985311508178711
train_time 5.138921022415161
2023-09-06 13:59:57,689 MainThread INFO: EPOCH:129
2023-09-06 13:59:57,689 MainThread INFO: Time Consumed:5.149013042449951s
2023-09-06 13:59:57,689 MainThread INFO: Total Frames:195000s
 32%|‚ñà‚ñà‚ñà‚ñé      | 130/400 [06:37<23:11,  5.15s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               151.84689
Train_Epoch_Reward                    2109.99868
Running_Training_Average_Rewards      241.70744
Explore_Time                          0.00299
Train___Time                          5.13892
Eval____Time                          0.00283
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.08776
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.70895
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.01238
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.84905
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.51134
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.01054
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.00182
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1726.38790
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.24676
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.63978
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.23920     0.45102    5.95029    4.40865
alpha_0                               0.71477     0.00030    0.71524    0.71430
alpha_1                               0.68199     0.00056    0.68286    0.68112
alpha_2                               0.67962     0.00058    0.68053    0.67872
alpha_3                               0.67981     0.00057    0.68070    0.67893
alpha_4                               0.68525     0.00052    0.68606    0.68444
alpha_5                               0.68816     0.00050    0.68894    0.68737
alpha_6                               0.68781     0.00049    0.68857    0.68704
alpha_7                               0.68631     0.00050    0.68709    0.68553
alpha_8                               0.68427     0.00052    0.68509    0.68345
alpha_9                               0.68675     0.00050    0.68753    0.68596
Alpha_loss                            -2.05206    0.01784    -2.02724   -2.08687
Training/policy_loss                  -22.80199   0.05519    -22.69453  -22.87694
Training/qf1_loss                     430.92574   167.58954  775.84875  244.46738
Training/qf2_loss                     453.67719   170.33126  803.79626  263.15900
Training/pf_norm                      0.27953     0.05303    0.42285    0.23311
Training/qf1_norm                     233.88617   45.67280   305.05411  149.25186
Training/qf2_norm                     261.19421   45.05385   330.15125  178.22403
log_std/mean                          -0.24586    0.00113    -0.24496   -0.24830
log_std/std                           0.09714     0.00054    0.09803    0.09644
log_std/max                           -0.12215    0.00090    -0.12058   -0.12385
log_std/min                           -0.55819    0.00546    -0.55079   -0.56801
log_probs/mean                        -1.44195    0.04096    -1.39151   -1.52945
log_probs/std                         1.66956     0.04042    1.76143    1.61512
log_probs/max                         4.71516     0.34974    5.15863    4.08377
log_probs/min                         -7.08139    0.76083    -6.15964   -8.84443
mean/mean                             0.08451     0.00203    0.08731    0.08116
mean/std                              0.67310     0.00294    0.67877    0.67013
mean/max                              1.38505     0.00971    1.39843    1.36573
mean/min                              -1.67338    0.01283    -1.65193   -1.69300
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 5, 1, 2, 3, 7, 4, 8, 6, 0]
replay_buffer._size: [19800 19800 19800 19800 19800 19800 19800 19800 19800 19800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.270990610122681 0.002011537551879883
train_time 5.27423095703125
2023-09-06 14:00:03,097 MainThread INFO: EPOCH:130
2023-09-06 14:00:03,097 MainThread INFO: Time Consumed:5.286192893981934s
2023-09-06 14:00:03,098 MainThread INFO: Total Frames:196500s
 33%|‚ñà‚ñà‚ñà‚ñé      | 131/400 [06:42<23:27,  5.23s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               140.72614
Train_Epoch_Reward                    2443.33980
Running_Training_Average_Rewards      224.10527
Explore_Time                          0.00518
Train___Time                          5.27423
Eval____Time                          0.00261
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.05075
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.74435
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.93104
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.84702
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.45679
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.89596
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.62175
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1741.29978
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.77474
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.63023
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.38379     0.78795    7.22135     4.60201
alpha_0                               0.71370     0.00031    0.71419     0.71321
alpha_1                               0.68006     0.00056    0.68093     0.67918
alpha_2                               0.67761     0.00058    0.67852     0.67671
alpha_3                               0.67785     0.00056    0.67873     0.67697
alpha_4                               0.68344     0.00052    0.68426     0.68262
alpha_5                               0.68640     0.00051    0.68719     0.68561
alpha_6                               0.68609     0.00049    0.68686     0.68532
alpha_7                               0.68457     0.00050    0.68535     0.68379
alpha_8                               0.68245     0.00052    0.68327     0.68164
alpha_9                               0.68500     0.00050    0.68579     0.68422
Alpha_loss                            -2.06861    0.01586    -2.04561    -2.10268
Training/policy_loss                  -23.03593   0.06994    -22.93006   -23.14742
Training/qf1_loss                     539.41395   355.30109  1445.49756  270.09210
Training/qf2_loss                     564.34026   361.01389  1485.18420  289.79956
Training/pf_norm                      0.28797     0.03553    0.35430     0.21933
Training/qf1_norm                     255.57665   89.56574   467.67667   173.98857
Training/qf2_norm                     281.59202   88.30905   490.22391   202.35196
log_std/mean                          -0.24621    0.00038    -0.24555    -0.24676
log_std/std                           0.10155     0.00181    0.10411     0.09860
log_std/max                           -0.12207    0.00108    -0.12032    -0.12356
log_std/min                           -0.57947    0.00963    -0.56452    -0.59594
log_probs/mean                        -1.44821    0.04209    -1.39295    -1.53809
log_probs/std                         1.65561     0.03009    1.71402     1.59642
log_probs/max                         4.67834     0.28238    5.05575     4.23735
log_probs/min                         -6.82815    0.68145    -6.13660    -8.09831
mean/mean                             0.07657     0.00194    0.08012     0.07408
mean/std                              0.67093     0.00027    0.67150     0.67068
mean/max                              1.38499     0.01088    1.40296     1.36843
mean/min                              -1.68974    0.01489    -1.67192    -1.71822
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 3, 7, 5, 2, 1, 8, 9, 6, 4]
replay_buffer._size: [19950 19950 19950 19950 19950 19950 19950 19950 19950 19950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.241178035736084 0.002791881561279297
train_time 5.24533224105835
2023-09-06 14:00:08,488 MainThread INFO: EPOCH:131
2023-09-06 14:00:08,489 MainThread INFO: Time Consumed:5.259760141372681s
2023-09-06 14:00:08,489 MainThread INFO: Total Frames:198000s
 33%|‚ñà‚ñà‚ñà‚ñé      | 132/400 [06:48<23:33,  5.28s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               136.89312
Train_Epoch_Reward                    4360.82268
Running_Training_Average_Rewards      297.13871
Explore_Time                          0.00529
Train___Time                          5.24533
Eval____Time                          0.00505
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.84220
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.74960
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.25654
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.04911
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.05262
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.37486
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.23306
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1719.62255
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.19484
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.74267
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.90918     0.41221   5.73917    4.32490
alpha_0                               0.71259     0.00032   0.71310    0.71208
alpha_1                               0.67811     0.00056   0.67899    0.67724
alpha_2                               0.67560     0.00058   0.67651    0.67470
alpha_3                               0.67590     0.00056   0.67678    0.67502
alpha_4                               0.68162     0.00052   0.68244    0.68079
alpha_5                               0.68463     0.00051   0.68543    0.68383
alpha_6                               0.68438     0.00049   0.68515    0.68361
alpha_7                               0.68284     0.00050   0.68362    0.68206
alpha_8                               0.68065     0.00052   0.68146    0.67984
alpha_9                               0.68327     0.00050   0.68405    0.68249
Alpha_loss                            -2.09465    0.01937   -2.05953   -2.12553
Training/policy_loss                  -23.25456   0.06106   -23.15574  -23.36919
Training/qf1_loss                     325.56936   87.28134  448.76263  219.90878
Training/qf2_loss                     347.08224   88.88667  475.14966  237.58427
Training/pf_norm                      0.27380     0.05889   0.41222    0.20033
Training/qf1_norm                     201.38842   45.00949  290.04224  136.41954
Training/qf2_norm                     227.86641   45.13505  315.37262  161.81319
log_std/mean                          -0.24336    0.00173   -0.24097   -0.24608
log_std/std                           0.10401     0.00028   0.10439    0.10345
log_std/max                           -0.11775    0.00123   -0.11592   -0.11969
log_std/min                           -0.58537    0.00486   -0.57970   -0.59641
log_probs/mean                        -1.48019    0.04338   -1.40264   -1.55289
log_probs/std                         1.64339     0.03456   1.69074    1.57197
log_probs/max                         4.69044     0.24400   4.93812    4.11825
log_probs/min                         -7.82065    1.22669   -6.13264   -9.47228
mean/mean                             0.07104     0.00198   0.07340    0.06735
mean/std                              0.66548     0.00253   0.66954    0.66186
mean/max                              1.37027     0.01141   1.39679    1.35685
mean/min                              -1.68300    0.01326   -1.66877   -1.71146
------------------------------------  ----------  --------  ---------  ---------
sample: [6, 4, 9, 8, 0, 7, 5, 2, 3, 1]
replay_buffer._size: [20100 20100 20100 20100 20100 20100 20100 20100 20100 20100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.353029489517212 0.002737283706665039
train_time 5.3571367263793945
2023-09-06 14:00:13,971 MainThread INFO: EPOCH:132
2023-09-06 14:00:13,972 MainThread INFO: Time Consumed:5.369180202484131s
2023-09-06 14:00:13,972 MainThread INFO: Total Frames:199500s
 33%|‚ñà‚ñà‚ñà‚ñé      | 133/400 [06:53<23:45,  5.34s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               133.15799
Train_Epoch_Reward                    2951.00727
Running_Training_Average_Rewards      325.17233
Explore_Time                          0.00314
Train___Time                          5.35714
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.77726
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.43438
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.58770
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.24048
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.07267
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.97463
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  1.16517
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1648.44403
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.40172
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.85480
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.84979     0.48196    5.73112    4.28053
alpha_0                               0.71146     0.00033    0.71197    0.71094
alpha_1                               0.67616     0.00056    0.67704    0.67529
alpha_2                               0.67359     0.00058    0.67450    0.67269
alpha_3                               0.67395     0.00056    0.67482    0.67307
alpha_4                               0.67979     0.00052    0.68061    0.67897
alpha_5                               0.68283     0.00052    0.68365    0.68202
alpha_6                               0.68267     0.00049    0.68344    0.68190
alpha_7                               0.68111     0.00050    0.68188    0.68033
alpha_8                               0.67884     0.00052    0.67965    0.67802
alpha_9                               0.68154     0.00050    0.68231    0.68076
Alpha_loss                            -2.10857    0.01871    -2.06100   -2.13328
Training/policy_loss                  -23.44620   0.05997    -23.35992  -23.56243
Training/qf1_loss                     435.87232   248.63887  868.63251  230.02267
Training/qf2_loss                     457.78298   252.52083  897.38660  247.92026
Training/pf_norm                      0.27958     0.05641    0.39169    0.20995
Training/qf1_norm                     199.03219   51.45017   294.23334  136.62704
Training/qf2_norm                     225.58307   50.30647   318.58560  163.32304
log_std/mean                          -0.24065    0.00027    -0.24026   -0.24101
log_std/std                           0.10451     0.00067    0.10576    0.10365
log_std/max                           -0.11440    0.00070    -0.11335   -0.11556
log_std/min                           -0.59092    0.00522    -0.58405   -0.60269
log_probs/mean                        -1.47735    0.04698    -1.35425   -1.52717
log_probs/std                         1.65261     0.03474    1.70783    1.58241
log_probs/max                         4.79019     0.28863    5.14950    4.19227
log_probs/min                         -7.24321    0.74445    -5.54454   -8.61699
mean/mean                             0.06053     0.00370    0.06614    0.05463
mean/std                              0.66176     0.00230    0.66423    0.65745
mean/max                              1.37031     0.00920    1.39135    1.35682
mean/min                              -1.70500    0.01034    -1.69104   -1.72464
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 2, 5, 3, 1, 8, 7, 0, 4, 9]
replay_buffer._size: [20250 20250 20250 20250 20250 20250 20250 20250 20250 20250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.284393548965454 0.0020923614501953125
train_time 5.28774356842041
2023-09-06 14:00:19,394 MainThread INFO: EPOCH:133
2023-09-06 14:00:19,394 MainThread INFO: Time Consumed:5.301862716674805s
2023-09-06 14:00:19,395 MainThread INFO: Total Frames:201000s
 34%|‚ñà‚ñà‚ñà‚ñé      | 134/400 [06:59<23:47,  5.37s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               132.59096
Train_Epoch_Reward                    1351.61035
Running_Training_Average_Rewards      288.78134
Explore_Time                          0.00322
Train___Time                          5.28774
Eval____Time                          0.00315
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.49025
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.74991
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.94249
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.27269
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.16040
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.30091
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  31.57018
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1682.17779
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.84387
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.65134
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.90738     0.48118    5.57776     4.08636
alpha_0                               0.71032     0.00033    0.71083     0.70980
alpha_1                               0.67421     0.00056    0.67509     0.67333
alpha_2                               0.67159     0.00058    0.67249     0.67069
alpha_3                               0.67199     0.00056    0.67287     0.67111
alpha_4                               0.67796     0.00052    0.67878     0.67715
alpha_5                               0.68102     0.00052    0.68184     0.68019
alpha_6                               0.68095     0.00050    0.68172     0.68017
alpha_7                               0.67937     0.00050    0.68015     0.67859
alpha_8                               0.67702     0.00052    0.67784     0.67620
alpha_9                               0.67982     0.00050    0.68059     0.67903
Alpha_loss                            -2.13932    0.01541    -2.11562    -2.16430
Training/policy_loss                  -23.63326   0.04615    -23.57438   -23.73018
Training/qf1_loss                     463.12156   230.28723  973.17639   232.66330
Training/qf2_loss                     484.94503   232.91729  1001.04285  250.82195
Training/pf_norm                      0.28097     0.03915    0.34856     0.22543
Training/qf1_norm                     206.16137   56.64501   296.94543   110.96230
Training/qf2_norm                     232.62138   56.64238   323.46411   136.58424
log_std/mean                          -0.23966    0.00080    -0.23778    -0.24042
log_std/std                           0.10656     0.00025    0.10692     0.10612
log_std/max                           -0.11706    0.00063    -0.11596    -0.11791
log_std/min                           -0.59790    0.00509    -0.59097    -0.60801
log_probs/mean                        -1.51936    0.03880    -1.46174    -1.59472
log_probs/std                         1.61082     0.03378    1.67052     1.54977
log_probs/max                         4.46371     0.19078    4.77805     4.20938
log_probs/min                         -7.05806    1.19200    -5.68768    -10.18387
mean/mean                             0.04934     0.00311    0.05359     0.04389
mean/std                              0.64952     0.00552    0.65646     0.64007
mean/max                              1.34594     0.02097    1.37607     1.31192
mean/min                              -1.68906    0.02239    -1.65770    -1.72209
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 1, 3, 9, 2, 5, 7, 4, 8, 6]
replay_buffer._size: [20400 20400 20400 20400 20400 20400 20400 20400 20400 20400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.521062612533569 0.0021355152130126953
train_time 5.524438858032227
2023-09-06 14:00:25,054 MainThread INFO: EPOCH:134
2023-09-06 14:00:25,055 MainThread INFO: Time Consumed:5.535033464431763s
2023-09-06 14:00:25,055 MainThread INFO: Total Frames:202500s
 34%|‚ñà‚ñà‚ñà‚ñç      | 135/400 [07:04<24:04,  5.45s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               137.49695
Train_Epoch_Reward                    2506.16812
Running_Training_Average_Rewards      226.95952
Explore_Time                          0.00381
Train___Time                          5.52444
Eval____Time                          0.00247
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.25381
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.49593
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.89535
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.42232
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.94903
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.02658
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  95.91166
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1755.01906
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.15215
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.42873
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.98892     0.31383    5.40758    4.50978
alpha_0                               0.70916     0.00034    0.70969    0.70862
alpha_1                               0.67226     0.00056    0.67314    0.67137
alpha_2                               0.66958     0.00058    0.67049    0.66868
alpha_3                               0.67004     0.00056    0.67092    0.66916
alpha_4                               0.67614     0.00053    0.67696    0.67532
alpha_5                               0.67918     0.00053    0.68001    0.67835
alpha_6                               0.67921     0.00050    0.68000    0.67842
alpha_7                               0.67764     0.00050    0.67842    0.67685
alpha_8                               0.67521     0.00052    0.67602    0.67439
alpha_9                               0.67807     0.00050    0.67886    0.67729
Alpha_loss                            -2.17571    0.01880    -2.14693   -2.21010
Training/policy_loss                  -23.83281   0.06458    -23.72531  -23.94057
Training/qf1_loss                     437.26563   194.69039  873.39783  235.94987
Training/qf2_loss                     460.44610   197.21601  902.14502  257.09015
Training/pf_norm                      0.30103     0.04867    0.41213    0.25020
Training/qf1_norm                     217.52325   38.19199   278.73535  163.41379
Training/qf2_norm                     244.20116   37.74928   305.86484  190.61765
log_std/mean                          -0.23490    0.00091    -0.23370   -0.23675
log_std/std                           0.10564     0.00030    0.10612    0.10529
log_std/max                           -0.11772    0.00081    -0.11637   -0.11888
log_std/min                           -0.59317    0.00472    -0.58496   -0.60217
log_probs/mean                        -1.57699    0.04981    -1.48792   -1.65596
log_probs/std                         1.56815     0.04345    1.63884    1.50127
log_probs/max                         4.31741     0.33931    4.75705    3.61903
log_probs/min                         -6.85193    0.86252    -5.03008   -8.19000
mean/mean                             0.03286     0.00541    0.04197    0.02531
mean/std                              0.63193     0.00340    0.63781    0.62715
mean/max                              1.30171     0.01532    1.32899    1.27605
mean/min                              -1.66617    0.01195    -1.64419   -1.69081
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 6, 0, 2, 9, 4, 8, 5, 7, 1]
replay_buffer._size: [20550 20550 20550 20550 20550 20550 20550 20550 20550 20550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.2084105014801025 0.002424955368041992
train_time 5.212095499038696
2023-09-06 14:00:30,392 MainThread INFO: EPOCH:135
2023-09-06 14:00:30,393 MainThread INFO: Time Consumed:5.2219953536987305s
2023-09-06 14:00:30,393 MainThread INFO: Total Frames:204000s
 34%|‚ñà‚ñà‚ñà‚ñç      | 136/400 [07:10<23:49,  5.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               151.99606
Train_Epoch_Reward                    2838.96763
Running_Training_Average_Rewards      223.22487
Explore_Time                          0.00267
Train___Time                          5.21210
Eval____Time                          0.00318
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.30201
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.03882
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.26493
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.57800
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.78506
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.60561
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  221.13962
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1862.09154
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.23911
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.17873
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.37052     0.57390    6.48051    4.67207
alpha_0                               0.70794     0.00036    0.70850    0.70738
alpha_1                               0.67029     0.00056    0.67118    0.66941
alpha_2                               0.66758     0.00057    0.66848    0.66668
alpha_3                               0.66808     0.00056    0.66896    0.66720
alpha_4                               0.67430     0.00053    0.67513    0.67347
alpha_5                               0.67733     0.00054    0.67817    0.67648
alpha_6                               0.67746     0.00050    0.67825    0.67667
alpha_7                               0.67589     0.00050    0.67668    0.67510
alpha_8                               0.67339     0.00052    0.67421    0.67257
alpha_9                               0.67633     0.00050    0.67711    0.67554
Alpha_loss                            -2.20925    0.02299    -2.17618   -2.24487
Training/policy_loss                  -24.05233   0.06553    -23.95989  -24.16700
Training/qf1_loss                     492.36378   233.82831  902.84167  263.02530
Training/qf2_loss                     519.18796   238.64247  939.01495  283.43536
Training/pf_norm                      0.28039     0.04562    0.37544    0.22701
Training/qf1_norm                     265.53343   69.74185   402.16080  175.00557
Training/qf2_norm                     291.69310   68.98188   427.34561  202.50381
log_std/mean                          -0.23215    0.00061    -0.23141   -0.23330
log_std/std                           0.10463     0.00035    0.10521    0.10412
log_std/max                           -0.11798    0.00054    -0.11724   -0.11892
log_std/min                           -0.58974    0.00604    -0.58322   -0.60011
log_probs/mean                        -1.62570    0.05227    -1.54629   -1.70837
log_probs/std                         1.54002     0.01961    1.57410    1.50909
log_probs/max                         4.27855     0.21726    4.60148    3.98490
log_probs/min                         -7.09908    0.65989    -5.80549   -8.17702
mean/mean                             0.02095     0.00179    0.02434    0.01868
mean/std                              0.62181     0.00226    0.62597    0.61909
mean/max                              1.28333     0.01398    1.30588    1.26047
mean/min                              -1.66303    0.01597    -1.64485   -1.68754
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 9, 2, 0, 3, 4, 1, 7, 6, 5]
replay_buffer._size: [20700 20700 20700 20700 20700 20700 20700 20700 20700 20700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.278701543807983 0.0025496482849121094
train_time 5.282866477966309
2023-09-06 14:00:35,800 MainThread INFO: EPOCH:136
2023-09-06 14:00:35,800 MainThread INFO: Time Consumed:5.298169374465942s
2023-09-06 14:00:35,801 MainThread INFO: Total Frames:205500s
 34%|‚ñà‚ñà‚ñà‚ñç      | 137/400 [07:15<23:44,  5.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               163.95856
Train_Epoch_Reward                    1725.65660
Running_Training_Average_Rewards      235.69308
Explore_Time                          0.00491
Train___Time                          5.28287
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.76934
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.08135
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.42666
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.79281
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.93667
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.77253
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  162.22960
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1911.98855
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.91056
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.31713
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.08643     0.52149    5.87792    4.22516
alpha_0                               0.70667     0.00037    0.70725    0.70610
alpha_1                               0.66833     0.00056    0.66921    0.66745
alpha_2                               0.66558     0.00057    0.66648    0.66468
alpha_3                               0.66612     0.00056    0.66700    0.66524
alpha_4                               0.67246     0.00053    0.67329    0.67163
alpha_5                               0.67545     0.00054    0.67629    0.67460
alpha_6                               0.67570     0.00051    0.67650    0.67490
alpha_7                               0.67413     0.00050    0.67492    0.67334
alpha_8                               0.67156     0.00053    0.67239    0.67073
alpha_9                               0.67459     0.00050    0.67537    0.67380
Alpha_loss                            -2.22499    0.01264    -2.20559   -2.25538
Training/policy_loss                  -24.27886   0.05688    -24.20208  -24.35415
Training/qf1_loss                     432.15390   188.63861  835.17249  187.52695
Training/qf2_loss                     456.94730   191.87072  865.92023  205.78040
Training/pf_norm                      0.23815     0.04289    0.31460    0.17143
Training/qf1_norm                     234.73596   62.33373   332.52737  134.98662
Training/qf2_norm                     260.67137   62.21127   356.95499  161.41745
log_std/mean                          -0.23528    0.00123    -0.23327   -0.23682
log_std/std                           0.10438     0.00026    0.10472    0.10377
log_std/max                           -0.11814    0.00054    -0.11729   -0.11890
log_std/min                           -0.59487    0.00513    -0.58624   -0.60394
log_probs/mean                        -1.62675    0.03173    -1.57524   -1.69149
log_probs/std                         1.54600     0.04942    1.65566    1.48635
log_probs/max                         4.28186     0.19361    4.54748    3.99717
log_probs/min                         -7.14060    0.86315    -5.74725   -8.35287
mean/mean                             0.01679     0.00109    0.01834    0.01499
mean/std                              0.62523     0.00163    0.62735    0.62213
mean/max                              1.29045     0.01231    1.30989    1.26485
mean/min                              -1.68379    0.01444    -1.65515   -1.70689
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 6, 7, 3, 8, 4, 5, 2, 9, 0]
replay_buffer._size: [20850 20850 20850 20850 20850 20850 20850 20850 20850 20850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.417766094207764 0.002078533172607422
train_time 5.4211585521698
2023-09-06 14:00:41,344 MainThread INFO: EPOCH:137
2023-09-06 14:00:41,344 MainThread INFO: Time Consumed:5.43193244934082s
2023-09-06 14:00:41,344 MainThread INFO: Total Frames:207000s
 34%|‚ñà‚ñà‚ñà‚ñç      | 138/400 [07:20<23:49,  5.45s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               167.08546
Train_Epoch_Reward                    3397.05543
Running_Training_Average_Rewards      265.38932
Explore_Time                          0.00445
Train___Time                          5.42116
Eval____Time                          0.00249
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.88763
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.54894
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.09429
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.85405
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.07985
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.88927
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  136.60821
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1817.54036
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.80197
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.87890
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.60281     0.54399    5.63373    3.77345
alpha_0                               0.70540     0.00036    0.70597    0.70483
alpha_1                               0.66637     0.00057    0.66725    0.66548
alpha_2                               0.66359     0.00057    0.66448    0.66269
alpha_3                               0.66416     0.00056    0.66504    0.66329
alpha_4                               0.67061     0.00053    0.67144    0.66977
alpha_5                               0.67356     0.00054    0.67441    0.67270
alpha_6                               0.67392     0.00051    0.67472    0.67312
alpha_7                               0.67238     0.00050    0.67317    0.67160
alpha_8                               0.66972     0.00053    0.67055    0.66889
alpha_9                               0.67285     0.00050    0.67363    0.67207
Alpha_loss                            -2.24273    0.01454    -2.22414   -2.26842
Training/policy_loss                  -24.49753   0.06665    -24.40775  -24.60692
Training/qf1_loss                     329.35015   181.22525  831.20471  158.30037
Training/qf2_loss                     350.38233   184.71485  858.98572  171.07394
Training/pf_norm                      0.26231     0.04071    0.32393    0.20333
Training/qf1_norm                     175.73291   66.36887   298.00388  69.31740
Training/qf2_norm                     202.92032   67.10295   325.54767  94.18905
log_std/mean                          -0.23586    0.00112    -0.23398   -0.23719
log_std/std                           0.10157     0.00136    0.10376    0.09989
log_std/max                           -0.11720    0.00093    -0.11577   -0.11845
log_std/min                           -0.58395    0.00673    -0.57593   -0.59690
log_probs/mean                        -1.63127    0.02791    -1.59664   -1.68428
log_probs/std                         1.55227     0.02696    1.59101    1.51108
log_probs/max                         4.35333     0.13590    4.53949    4.20463
log_probs/min                         -6.54509    0.43894    -5.87570   -7.26576
mean/mean                             0.01177     0.00230    0.01487    0.00784
mean/std                              0.62025     0.00396    0.62610    0.61409
mean/max                              1.28098     0.01229    1.30870    1.26645
mean/min                              -1.67584    0.01246    -1.65978   -1.70548
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 2, 3, 7, 8, 1, 4, 6, 9, 0]
replay_buffer._size: [21000 21000 21000 21000 21000 21000 21000 21000 21000 21000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.644177198410034 0.0021774768829345703
train_time 5.647662401199341
2023-09-06 14:00:47,124 MainThread INFO: EPOCH:138
2023-09-06 14:00:47,124 MainThread INFO: Time Consumed:5.663068771362305s
2023-09-06 14:00:47,125 MainThread INFO: Total Frames:208500s
 35%|‚ñà‚ñà‚ñà‚ñç      | 139/400 [07:26<24:10,  5.56s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               158.74046
Train_Epoch_Reward                    3032.76305
Running_Training_Average_Rewards      271.84917
Explore_Time                          0.00305
Train___Time                          5.64766
Eval____Time                          0.00793
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.52420
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.41936
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.08734
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.85459
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.59872
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.25482
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  60.22029
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1787.57553
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.23357
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.93431
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.09838     0.29048    5.55178    4.58846
alpha_0                               0.70412     0.00037    0.70470    0.70353
alpha_1                               0.66439     0.00057    0.66528    0.66350
alpha_2                               0.66160     0.00057    0.66249    0.66070
alpha_3                               0.66222     0.00056    0.66309    0.66134
alpha_4                               0.66874     0.00054    0.66958    0.66789
alpha_5                               0.67165     0.00055    0.67251    0.67078
alpha_6                               0.67213     0.00052    0.67294    0.67133
alpha_7                               0.67065     0.00050    0.67143    0.66987
alpha_8                               0.66787     0.00053    0.66871    0.66704
alpha_9                               0.67113     0.00049    0.67190    0.67036
Alpha_loss                            -2.27783    0.02094    -2.24563   -2.30557
Training/policy_loss                  -24.68552   0.05686    -24.62005  -24.79840
Training/qf1_loss                     446.50213   150.29865  779.38684  287.54562
Training/qf2_loss                     472.04790   151.47266  810.92456  311.85455
Training/pf_norm                      0.29262     0.03065    0.34439    0.23993
Training/qf1_norm                     236.81143   35.95982   299.71750  166.13512
Training/qf2_norm                     263.99358   35.82459   325.65359  193.51433
log_std/mean                          -0.23257    0.00096    -0.23084   -0.23375
log_std/std                           0.09891     0.00044    0.09959    0.09812
log_std/max                           -0.11635    0.00055    -0.11563   -0.11748
log_std/min                           -0.56936    0.00515    -0.56306   -0.57784
log_probs/mean                        -1.68275    0.04798    -1.61138   -1.73990
log_probs/std                         1.51228     0.02701    1.58068    1.48419
log_probs/max                         4.04351     0.19974    4.30463    3.57727
log_probs/min                         -7.25636    0.88450    -5.85788   -8.97344
mean/mean                             0.00220     0.00272    0.00689    -0.00180
mean/std                              0.60799     0.00291    0.61267    0.60331
mean/max                              1.25522     0.01108    1.27232    1.24172
mean/min                              -1.65648    0.01180    -1.63715   -1.67706
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 9, 8, 6, 0, 2, 7, 1, 4, 5]
replay_buffer._size: [21150 21150 21150 21150 21150 21150 21150 21150 21150 21150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.5154240131378174 0.002239704132080078
train_time 3.518939256668091
2023-09-06 14:00:52,718 MainThread INFO: EPOCH:139
2023-09-06 14:00:52,719 MainThread INFO: Time Consumed:5.457687616348267s
2023-09-06 14:00:52,720 MainThread INFO: Total Frames:210000s
 35%|‚ñà‚ñà‚ñà‚ñå      | 140/400 [07:32<24:05,  5.56s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               147.65031
Train_Epoch_Reward                    2422.03625
Running_Training_Average_Rewards      295.06182
Explore_Time                          1.93068
Train___Time                          3.51894
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.42822
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.40660
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.16466
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.88251
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.56932
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.13843
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.16965
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1777.91285
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.53942
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.10725
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.20956     0.45986    6.12604     4.39929
alpha_0                               0.70279     0.00039    0.70340     0.70218
alpha_1                               0.66241     0.00057    0.66330     0.66152
alpha_2                               0.65961     0.00057    0.66051     0.65872
alpha_3                               0.66027     0.00056    0.66114     0.65939
alpha_4                               0.66685     0.00054    0.66770     0.66600
alpha_5                               0.66972     0.00056    0.67059     0.66885
alpha_6                               0.67034     0.00052    0.67115     0.66953
alpha_7                               0.66891     0.00050    0.66969     0.66813
alpha_8                               0.66602     0.00053    0.66685     0.66519
alpha_9                               0.66941     0.00050    0.67019     0.66863
Alpha_loss                            -2.30848    0.01202    -2.29223    -2.32630
Training/policy_loss                  -24.90764   0.06731    -24.80436   -25.00627
Training/qf1_loss                     494.00008   250.43825  1090.10437  201.49776
Training/qf2_loss                     521.15903   251.71070  1116.21838  221.95752
Training/pf_norm                      0.23378     0.03796    0.29831     0.15538
Training/qf1_norm                     257.27135   57.43694   369.10349   155.68271
Training/qf2_norm                     285.08084   56.83439   396.37830   183.45154
log_std/mean                          -0.23036    0.00020    -0.23016    -0.23083
log_std/std                           0.09793     0.00018    0.09825     0.09769
log_std/max                           -0.11785    0.00133    -0.11524    -0.11976
log_std/min                           -0.56890    0.00387    -0.56403    -0.57551
log_probs/mean                        -1.72154    0.02351    -1.68365    -1.75930
log_probs/std                         1.48406     0.03324    1.54145     1.42778
log_probs/max                         3.96624     0.32062    4.60964     3.43944
log_probs/min                         -6.63916    0.56809    -5.80205    -7.56958
mean/mean                             -0.00800    0.00323    -0.00288    -0.01268
mean/std                              0.59990     0.00187    0.60299     0.59682
mean/max                              1.24707     0.01213    1.26781     1.22995
mean/min                              -1.65616    0.01198    -1.64035    -1.67385
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 4, 8, 9, 3, 5, 6, 0, 1, 2]
replay_buffer._size: [21300 21300 21300 21300 21300 21300 21300 21300 21300 21300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.1918816566467285 0.0021255016326904297
train_time 5.195215463638306
2023-09-06 14:00:58,032 MainThread INFO: EPOCH:140
2023-09-06 14:00:58,033 MainThread INFO: Time Consumed:5.207083702087402s
2023-09-06 14:00:58,033 MainThread INFO: Total Frames:211500s
 35%|‚ñà‚ñà‚ñà‚ñå      | 141/400 [07:37<23:42,  5.49s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               141.72543
Train_Epoch_Reward                    3142.63682
Running_Training_Average_Rewards      286.58120
Explore_Time                          0.00282
Train___Time                          5.19522
Eval____Time                          0.00498
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.91997
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.39555
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.06376
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.93085
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.85783
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.39624
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.86168
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1806.64948
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.60386
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.25248
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.82795     0.42451    5.69168    4.32145
alpha_0                               0.70142     0.00040    0.70204    0.70079
alpha_1                               0.66043     0.00057    0.66132    0.65954
alpha_2                               0.65763     0.00057    0.65852    0.65675
alpha_3                               0.65832     0.00056    0.65920    0.65745
alpha_4                               0.66497     0.00054    0.66582    0.66412
alpha_5                               0.66778     0.00056    0.66865    0.66690
alpha_6                               0.66854     0.00052    0.66935    0.66773
alpha_7                               0.66716     0.00050    0.66795    0.66637
alpha_8                               0.66418     0.00053    0.66501    0.66335
alpha_9                               0.66768     0.00050    0.66846    0.66690
Alpha_loss                            -2.32893    0.01877    -2.29536   -2.35446
Training/policy_loss                  -25.12784   0.06330    -25.03346  -25.22948
Training/qf1_loss                     393.00051   208.41687  836.27307  186.28503
Training/qf2_loss                     416.61590   211.33265  863.98096  205.32793
Training/pf_norm                      0.27098     0.04088    0.34047    0.22068
Training/qf1_norm                     211.21096   51.01370   315.94424  148.12395
Training/qf2_norm                     241.52034   50.51910   344.79745  178.05298
log_std/mean                          -0.22950    0.00073    -0.22807   -0.23030
log_std/std                           0.09954     0.00050    0.10010    0.09850
log_std/max                           -0.11334    0.00169    -0.11005   -0.11560
log_std/min                           -0.57554    0.00430    -0.56864   -0.58295
log_probs/mean                        -1.73314    0.03812    -1.66753   -1.78181
log_probs/std                         1.46931     0.03468    1.51534    1.39150
log_probs/max                         3.96365     0.21794    4.37217    3.71539
log_probs/min                         -7.23405    0.63147    -6.70213   -9.00919
mean/mean                             -0.01724    0.00211    -0.01340   -0.02007
mean/std                              0.59065     0.00385    0.59645    0.58419
mean/max                              1.23342     0.01030    1.24991    1.22037
mean/min                              -1.64607    0.01306    -1.62397   -1.66504
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 5, 2, 6, 9, 0, 4, 8, 7, 3]
replay_buffer._size: [21450 21450 21450 21450 21450 21450 21450 21450 21450 21450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.391957759857178 0.002953767776489258
train_time 5.396689414978027
2023-09-06 14:01:03,570 MainThread INFO: EPOCH:141
2023-09-06 14:01:03,570 MainThread INFO: Time Consumed:5.408689260482788s
2023-09-06 14:01:03,571 MainThread INFO: Total Frames:213000s
 36%|‚ñà‚ñà‚ñà‚ñå      | 142/400 [07:43<23:40,  5.50s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               142.61026
Train_Epoch_Reward                    8842.46421
Running_Training_Average_Rewards      480.23791
Explore_Time                          0.00336
Train___Time                          5.39669
Eval____Time                          0.00270
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.05016
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.82781
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.88630
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.91055
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.94523
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.60686
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.50904
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1906.20837
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.53968
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.49913
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.64840     0.44076    5.53245    3.91701
alpha_0                               0.70002     0.00040    0.70065    0.69939
alpha_1                               0.65845     0.00057    0.65934    0.65756
alpha_2                               0.65567     0.00056    0.65655    0.65478
alpha_3                               0.65638     0.00056    0.65725    0.65551
alpha_4                               0.66308     0.00055    0.66393    0.66222
alpha_5                               0.66581     0.00057    0.66670    0.66492
alpha_6                               0.66673     0.00052    0.66755    0.66592
alpha_7                               0.66540     0.00051    0.66619    0.66460
alpha_8                               0.66234     0.00053    0.66317    0.66151
alpha_9                               0.66594     0.00050    0.66673    0.66516
Alpha_loss                            -2.36348    0.01810    -2.33051   -2.38355
Training/policy_loss                  -25.36319   0.06870    -25.26126  -25.47612
Training/qf1_loss                     294.60538   121.42884  605.57574  196.65884
Training/qf2_loss                     316.53547   124.13669  631.50940  214.16138
Training/pf_norm                      0.28944     0.04009    0.33386    0.21158
Training/qf1_norm                     185.80141   54.62425   296.66260  92.24170
Training/qf2_norm                     216.69863   54.06272   325.35989  121.44647
log_std/mean                          -0.22839    0.00052    -0.22783   -0.22965
log_std/std                           0.09986     0.00061    0.10068    0.09883
log_std/max                           -0.11062    0.00071    -0.10939   -0.11220
log_std/min                           -0.57625    0.00795    -0.56563   -0.58641
log_probs/mean                        -1.77877    0.04159    -1.70330   -1.82554
log_probs/std                         1.45150     0.03634    1.54125    1.40524
log_probs/max                         3.75270     0.20508    3.97153    3.26229
log_probs/min                         -6.84797    0.69872    -6.12504   -8.01492
mean/mean                             -0.02586    0.00378    -0.02057   -0.03224
mean/std                              0.58072     0.00175    0.58351    0.57876
mean/max                              1.20873     0.02059    1.24019    1.17746
mean/min                              -1.63622    0.01682    -1.61481   -1.65740
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 5, 2, 8, 3, 0, 7, 9, 6, 4]
replay_buffer._size: [21600 21600 21600 21600 21600 21600 21600 21600 21600 21600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.382939338684082 0.0022284984588623047
train_time 5.386478424072266
2023-09-06 14:01:09,094 MainThread INFO: EPOCH:142
2023-09-06 14:01:09,094 MainThread INFO: Time Consumed:5.399019241333008s
2023-09-06 14:01:09,095 MainThread INFO: Total Frames:214500s
 36%|‚ñà‚ñà‚ñà‚ñå      | 143/400 [07:48<23:37,  5.52s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               150.59083
Train_Epoch_Reward                    5495.98998
Running_Training_Average_Rewards      582.70303
Explore_Time                          0.00367
Train___Time                          5.38648
Eval____Time                          0.00463
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -28.84842
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.33321
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.67139
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.82848
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.94848
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.12840
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.23783
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2017.34975
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.30904
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.12036
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.09016     0.42490    5.80970    4.39290
alpha_0                               0.69860     0.00042    0.69925    0.69795
alpha_1                               0.65647     0.00057    0.65736    0.65559
alpha_2                               0.65371     0.00056    0.65459    0.65283
alpha_3                               0.65445     0.00055    0.65532    0.65358
alpha_4                               0.66117     0.00055    0.66203    0.66032
alpha_5                               0.66383     0.00057    0.66472    0.66294
alpha_6                               0.66491     0.00052    0.66573    0.66409
alpha_7                               0.66362     0.00051    0.66442    0.66282
alpha_8                               0.66049     0.00053    0.66132    0.65966
alpha_9                               0.66420     0.00050    0.66498    0.66341
Alpha_loss                            -2.38094    0.01335    -2.35264   -2.39664
Training/policy_loss                  -25.55238   0.07933    -25.45368  -25.68839
Training/qf1_loss                     398.50465   186.13730  770.28339  188.39479
Training/qf2_loss                     423.51928   188.93176  799.43652  208.19138
Training/pf_norm                      0.29121     0.04847    0.40062    0.23271
Training/qf1_norm                     239.84853   51.77054   331.01074  158.68973
Training/qf2_norm                     271.27142   51.16762   358.67999  190.43436
log_std/mean                          -0.23349    0.00159    -0.23063   -0.23569
log_std/std                           0.09854     0.00026    0.09888    0.09813
log_std/max                           -0.11341    0.00101    -0.11189   -0.11486
log_std/min                           -0.57793    0.00331    -0.57193   -0.58190
log_probs/mean                        -1.78399    0.03028    -1.72353   -1.81417
log_probs/std                         1.43104     0.02903    1.48115    1.37580
log_probs/max                         3.66096     0.26684    3.95226    3.13013
log_probs/min                         -6.53519    0.58298    -5.57373   -7.62325
mean/mean                             -0.04128    0.00465    -0.03405   -0.04882
mean/std                              0.57957     0.00105    0.58096    0.57749
mean/max                              1.18255     0.01180    1.19875    1.16100
mean/min                              -1.65130    0.00783    -1.63882   -1.66259
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 7, 2, 1, 0, 8, 5, 9, 4, 3]
replay_buffer._size: [21750 21750 21750 21750 21750 21750 21750 21750 21750 21750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 2.9053895473480225 0.002149820327758789
train_time 2.9088613986968994
2023-09-06 14:01:14,470 MainThread INFO: EPOCH:143
2023-09-06 14:01:14,470 MainThread INFO: Time Consumed:2.92388916015625s
2023-09-06 14:01:14,471 MainThread INFO: Total Frames:216000s
 36%|‚ñà‚ñà‚ñà‚ñå      | 144/400 [07:54<23:18,  5.46s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               165.48231
Train_Epoch_Reward                    3726.49741
Running_Training_Average_Rewards      602.16505
Explore_Time                          0.00689
Train___Time                          2.90886
Eval____Time                          0.00372
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.64215
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.66063
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.51548
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.92485
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.31635
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.15986
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.39873
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2251.84408
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.91574
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.19868
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.93894     0.56436    6.07816     4.17760
alpha_0                               0.69714     0.00042    0.69780     0.69649
alpha_1                               0.65450     0.00057    0.65539     0.65362
alpha_2                               0.65175     0.00056    0.65263     0.65088
alpha_3                               0.65252     0.00055    0.65339     0.65165
alpha_4                               0.65927     0.00054    0.66013     0.65842
alpha_5                               0.66184     0.00057    0.66274     0.66095
alpha_6                               0.66308     0.00053    0.66391     0.66225
alpha_7                               0.66185     0.00051    0.66264     0.66105
alpha_8                               0.65864     0.00053    0.65948     0.65781
alpha_9                               0.66245     0.00050    0.66324     0.66167
Alpha_loss                            -2.40780    0.01815    -2.37632    -2.43780
Training/policy_loss                  -25.81818   0.08694    -25.67092   -25.97755
Training/qf1_loss                     431.93977   252.82136  996.35858   209.41035
Training/qf2_loss                     457.16518   257.87733  1034.30347  229.09830
Training/pf_norm                      0.31225     0.04901    0.38551     0.25678
Training/qf1_norm                     222.62343   68.78457   358.11453   128.92636
Training/qf2_norm                     254.75326   67.44338   385.93036   162.41293
log_std/mean                          -0.23464    0.00127    -0.23260    -0.23622
log_std/std                           0.09856     0.00014    0.09884     0.09837
log_std/max                           -0.11939    0.00182    -0.11696    -0.12233
log_std/min                           -0.58369    0.00649    -0.57299    -0.59496
log_probs/mean                        -1.80908    0.03882    -1.74926    -1.86323
log_probs/std                         1.42751     0.01905    1.46170     1.39278
log_probs/max                         3.56508     0.22897    3.83255     3.15159
log_probs/min                         -7.02907    0.95965    -5.83765    -9.45572
mean/mean                             -0.05876    0.00488    -0.05089    -0.06629
mean/std                              0.56833     0.00529    0.57623     0.55958
mean/max                              1.16706     0.01320    1.19412     1.14735
mean/min                              -1.66214    0.01659    -1.63544    -1.69103
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 1, 6, 0, 5, 7, 2, 3, 8, 4]
replay_buffer._size: [21900 21900 21900 21900 21900 21900 21900 21900 21900 21900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.157634735107422 0.0023956298828125
train_time 5.161516904830933
2023-09-06 14:01:19,749 MainThread INFO: EPOCH:144
2023-09-06 14:01:19,750 MainThread INFO: Time Consumed:5.1713707447052s
2023-09-06 14:01:19,750 MainThread INFO: Total Frames:217500s
 36%|‚ñà‚ñà‚ñà‚ñã      | 145/400 [07:59<23:00,  5.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               188.33972
Train_Epoch_Reward                    2773.21360
Running_Training_Average_Rewards      399.85670
Explore_Time                          0.00265
Train___Time                          5.16152
Eval____Time                          0.00279
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.46103
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.89100
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.39202
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.08805
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.67077
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.53988
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.02569
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2583.25955
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.25407
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.78104
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.96565     0.68885    6.13322    3.97031
alpha_0                               0.69567     0.00043    0.69634    0.69499
alpha_1                               0.65254     0.00056    0.65342    0.65166
alpha_2                               0.64981     0.00056    0.65068    0.64894
alpha_3                               0.65059     0.00055    0.65146    0.64973
alpha_4                               0.65738     0.00054    0.65823    0.65653
alpha_5                               0.65985     0.00058    0.66075    0.65895
alpha_6                               0.66123     0.00053    0.66207    0.66040
alpha_7                               0.66008     0.00051    0.66088    0.65928
alpha_8                               0.65679     0.00053    0.65762    0.65595
alpha_9                               0.66070     0.00050    0.66149    0.65991
Alpha_loss                            -2.43711    0.01739    -2.40785   -2.46683
Training/policy_loss                  -26.03441   0.06697    -25.90247  -26.11554
Training/qf1_loss                     433.47508   244.39103  864.61963  169.68881
Training/qf2_loss                     458.78777   249.79032  901.23505  186.82739
Training/pf_norm                      0.28131     0.05049    0.35805    0.19437
Training/qf1_norm                     224.71413   90.23792   374.39331  103.22816
Training/qf2_norm                     258.01839   89.97728   406.03842  136.82367
log_std/mean                          -0.22934    0.00156    -0.22738   -0.23195
log_std/std                           0.09808     0.00069    0.09878    0.09686
log_std/max                           -0.11916    0.00090    -0.11774   -0.12056
log_std/min                           -0.57455    0.00879    -0.56281   -0.58736
log_probs/mean                        -1.84241    0.03688    -1.78447   -1.90669
log_probs/std                         1.37039     0.03044    1.43234    1.32933
log_probs/max                         3.32365     0.26236    3.62585    2.85647
log_probs/min                         -6.87737    0.99141    -5.33081   -8.37109
mean/mean                             -0.07302    0.00306    -0.06779   -0.07751
mean/std                              0.55192     0.00363    0.55788    0.54708
mean/max                              1.12601     0.02134    1.16075    1.09848
mean/min                              -1.64487    0.01570    -1.62448   -1.66849
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 1, 6, 8, 2, 3, 0, 9, 5, 4]
replay_buffer._size: [22050 22050 22050 22050 22050 22050 22050 22050 22050 22050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.538658142089844 0.0022335052490234375
train_time 5.542145013809204
2023-09-06 14:01:25,436 MainThread INFO: EPOCH:145
2023-09-06 14:01:25,436 MainThread INFO: Time Consumed:5.562835454940796s
2023-09-06 14:01:25,437 MainThread INFO: Total Frames:219000s
 36%|‚ñà‚ñà‚ñà‚ñã      | 146/400 [08:05<23:14,  5.49s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               226.37045
Train_Epoch_Reward                    3527.34250
Running_Training_Average_Rewards      334.23512
Explore_Time                          0.01402
Train___Time                          5.54215
Eval____Time                          0.00266
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.73506
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.47819
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.83400
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.41159
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.51776
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -52.51340
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.98102
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3156.30857
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.13117
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.86056
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.78188     0.40599    5.26579    3.89917
alpha_0                               0.69415     0.00044    0.69484    0.69345
alpha_1                               0.65058     0.00056    0.65146    0.64970
alpha_2                               0.64788     0.00055    0.64874    0.64701
alpha_3                               0.64867     0.00055    0.64953    0.64781
alpha_4                               0.65548     0.00055    0.65634    0.65461
alpha_5                               0.65784     0.00058    0.65874    0.65694
alpha_6                               0.65938     0.00053    0.66021    0.65854
alpha_7                               0.65830     0.00051    0.65910    0.65750
alpha_8                               0.65493     0.00054    0.65576    0.65408
alpha_9                               0.65894     0.00051    0.65974    0.65815
Alpha_loss                            -2.46372    0.01270    -2.43575   -2.48162
Training/policy_loss                  -26.24056   0.06729    -26.14257  -26.33203
Training/qf1_loss                     378.87541   185.72613  848.60254  229.73123
Training/qf2_loss                     402.48390   188.31026  878.66956  249.21533
Training/pf_norm                      0.27647     0.02943    0.32852    0.22609
Training/qf1_norm                     200.51931   52.48708   272.29135  92.26048
Training/qf2_norm                     235.30257   52.96396   306.52249  127.00454
log_std/mean                          -0.22550    0.00078    -0.22461   -0.22714
log_std/std                           0.09651     0.00016    0.09672    0.09624
log_std/max                           -0.11652    0.00142    -0.11442   -0.11828
log_std/min                           -0.55811    0.00500    -0.55094   -0.56618
log_probs/mean                        -1.86696    0.02905    -1.79581   -1.90332
log_probs/std                         1.34550     0.02193    1.37930    1.31461
log_probs/max                         3.21563     0.17293    3.60277    3.03393
log_probs/min                         -6.76786    0.76214    -5.84637   -8.45611
mean/mean                             -0.08119    0.00135    -0.07843   -0.08253
mean/std                              0.54384     0.00148    0.54659    0.54138
mean/max                              1.07914     0.01145    1.10272    1.06013
mean/min                              -1.63817    0.01394    -1.61601   -1.65625
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 3, 9, 5, 6, 8, 1, 7, 0, 2]
replay_buffer._size: [22200 22200 22200 22200 22200 22200 22200 22200 22200 22200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.370617389678955 0.0019834041595458984
train_time 5.373803377151489
2023-09-06 14:01:30,935 MainThread INFO: EPOCH:146
2023-09-06 14:01:30,935 MainThread INFO: Time Consumed:5.385198354721069s
2023-09-06 14:01:30,936 MainThread INFO: Total Frames:220500s
 37%|‚ñà‚ñà‚ñà‚ñã      | 147/400 [08:10<23:10,  5.50s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               253.68258
Train_Epoch_Reward                    3118.70574
Running_Training_Average_Rewards      313.97539
Explore_Time                          0.00295
Train___Time                          5.37380
Eval____Time                          0.00303
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -34.03622
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.05482
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32675
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.83854
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.03172
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -47.44119
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.54728
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3072.51846
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.22800
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.53831
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.00420     0.60053    6.46799     4.02487
alpha_0                               0.69260     0.00045    0.69330     0.69189
alpha_1                               0.64862     0.00056    0.64950     0.64774
alpha_2                               0.64596     0.00055    0.64682     0.64510
alpha_3                               0.64676     0.00055    0.64762     0.64590
alpha_4                               0.65356     0.00055    0.65442     0.65270
alpha_5                               0.65583     0.00058    0.65674     0.65492
alpha_6                               0.65751     0.00054    0.65835     0.65667
alpha_7                               0.65653     0.00051    0.65732     0.65574
alpha_8                               0.65305     0.00054    0.65390     0.65221
alpha_9                               0.65718     0.00051    0.65797     0.65638
Alpha_loss                            -2.48562    0.01250    -2.46362    -2.50851
Training/policy_loss                  -26.49156   0.08349    -26.36721   -26.61209
Training/qf1_loss                     396.05507   227.48886  996.53406   230.02280
Training/qf2_loss                     421.57797   231.38569  1036.63831  253.55807
Training/pf_norm                      0.25090     0.03464    0.30829     0.18744
Training/qf1_norm                     227.08438   77.56495   416.18277   99.92519
Training/qf2_norm                     262.38260   76.11568   446.72885   137.01280
log_std/mean                          -0.22507    0.00024    -0.22471    -0.22546
log_std/std                           0.09553     0.00096    0.09672     0.09398
log_std/max                           -0.11597    0.00093    -0.11462    -0.11706
log_std/min                           -0.55771    0.00593    -0.54644    -0.56724
log_probs/mean                        -1.87993    0.02589    -1.83015    -1.92646
log_probs/std                         1.34517     0.02006    1.38062     1.30369
log_probs/max                         3.32455     0.23244    3.70886     2.98438
log_probs/min                         -7.45385    1.17907    -5.68428    -9.75318
mean/mean                             -0.08157    0.00078    -0.08063    -0.08322
mean/std                              0.53707     0.00293    0.54124     0.53199
mean/max                              1.05728     0.01399    1.08331     1.03638
mean/min                              -1.64668    0.01553    -1.61863    -1.67116
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 2, 5, 1, 9, 4, 0, 7, 8, 6]
replay_buffer._size: [22350 22350 22350 22350 22350 22350 22350 22350 22350 22350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.32245659828186 0.0020112991333007812
train_time 5.325679540634155
2023-09-06 14:01:36,387 MainThread INFO: EPOCH:147
2023-09-06 14:01:36,387 MainThread INFO: Time Consumed:5.336573123931885s
2023-09-06 14:01:36,388 MainThread INFO: Total Frames:222000s
 37%|‚ñà‚ñà‚ñà‚ñã      | 148/400 [08:16<23:02,  5.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               261.41510
Train_Epoch_Reward                    3519.59082
Running_Training_Average_Rewards      338.85464
Explore_Time                          0.00347
Train___Time                          5.32568
Eval____Time                          0.00280
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.96340
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.75500
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.03150
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.29261
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.26843
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -46.39082
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.84458
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2816.13961
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.56505
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.89675
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.16630     0.88641    6.51902     3.81271
alpha_0                               0.69102     0.00046    0.69174     0.69030
alpha_1                               0.64666     0.00056    0.64755     0.64578
alpha_2                               0.64405     0.00055    0.64491     0.64320
alpha_3                               0.64485     0.00055    0.64571     0.64400
alpha_4                               0.65165     0.00055    0.65251     0.65079
alpha_5                               0.65381     0.00058    0.65472     0.65290
alpha_6                               0.65564     0.00054    0.65648     0.65480
alpha_7                               0.65476     0.00051    0.65556     0.65397
alpha_8                               0.65117     0.00054    0.65202     0.65033
alpha_9                               0.65540     0.00051    0.65620     0.65460
Alpha_loss                            -2.51305    0.01635    -2.49112    -2.54262
Training/policy_loss                  -26.69451   0.07212    -26.56595   -26.80715
Training/qf1_loss                     572.50074   421.36819  1326.89844  189.00601
Training/qf2_loss                     600.82018   430.57989  1371.08752  202.77985
Training/pf_norm                      0.27515     0.04208    0.32910     0.19897
Training/qf1_norm                     252.52482   122.43464  445.31058   66.32746
Training/qf2_norm                     286.88740   121.70137  479.02136   98.14520
log_std/mean                          -0.22654    0.00077    -0.22549    -0.22793
log_std/std                           0.09280     0.00063    0.09371     0.09192
log_std/max                           -0.11516    0.00081    -0.11413    -0.11668
log_std/min                           -0.55256    0.00363    -0.54690    -0.55811
log_probs/mean                        -1.90619    0.03825    -1.84962    -1.97621
log_probs/std                         1.32223     0.02475    1.34901     1.26057
log_probs/max                         3.10059     0.14127    3.30677     2.87361
log_probs/min                         -7.04667    1.09301    -5.19813    -8.62921
mean/mean                             -0.08875    0.00362    -0.08390    -0.09503
mean/std                              0.52670     0.00289    0.53084     0.52208
mean/max                              1.02315     0.00963    1.04381     1.00928
mean/min                              -1.62527    0.00968    -1.61104    -1.64459
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 1, 3, 5, 6, 8, 9, 7, 2, 4]
replay_buffer._size: [22500 22500 22500 22500 22500 22500 22500 22500 22500 22500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.911653518676758 0.0020165443420410156
train_time 5.9148924350738525
2023-09-06 14:01:42,450 MainThread INFO: EPOCH:148
2023-09-06 14:01:42,451 MainThread INFO: Time Consumed:5.927079439163208s
2023-09-06 14:01:42,451 MainThread INFO: Total Frames:223500s
 37%|‚ñà‚ñà‚ñà‚ñã      | 149/400 [08:22<23:38,  5.65s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               245.68807
Train_Epoch_Reward                    3054.49573
Running_Training_Average_Rewards      323.09308
Explore_Time                          0.00356
Train___Time                          5.91489
Eval____Time                          0.00342
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.18432
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.51935
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.65510
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.71283
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.59798
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -50.53053
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.43326
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2692.16511
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.23648
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.26016
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.89524     0.53303    5.79861    4.04301
alpha_0                               0.68941     0.00046    0.69014    0.68869
alpha_1                               0.64471     0.00056    0.64559    0.64383
alpha_2                               0.64215     0.00054    0.64301    0.64130
alpha_3                               0.64295     0.00054    0.64381    0.64210
alpha_4                               0.64975     0.00055    0.65060    0.64889
alpha_5                               0.65179     0.00058    0.65270    0.65088
alpha_6                               0.65376     0.00054    0.65461    0.65291
alpha_7                               0.65299     0.00051    0.65379    0.65219
alpha_8                               0.64929     0.00054    0.65014    0.64844
alpha_9                               0.65362     0.00052    0.65443    0.65281
Alpha_loss                            -2.54509    0.01004    -2.53440   -2.57206
Training/policy_loss                  -26.93511   0.07488    -26.80726  -27.05458
Training/qf1_loss                     432.13856   258.99541  949.71954  171.28427
Training/qf2_loss                     457.11922   261.88211  983.60907  191.95226
Training/pf_norm                      0.25461     0.03396    0.32273    0.19972
Training/qf1_norm                     213.71494   69.68611   346.09940  105.11527
Training/qf2_norm                     251.16624   68.54693   379.63577  143.91170
log_std/mean                          -0.23012    0.00103    -0.22830   -0.23122
log_std/std                           0.09097     0.00040    0.09177    0.09043
log_std/max                           -0.11554    0.00105    -0.11418   -0.11690
log_std/min                           -0.55650    0.00306    -0.55064   -0.55982
log_probs/mean                        -1.94185    0.01859    -1.91879   -1.98971
log_probs/std                         1.29183     0.02590    1.35740    1.26080
log_probs/max                         3.01515     0.22757    3.36599    2.59716
log_probs/min                         -7.05548    0.66071    -6.41271   -8.66944
mean/mean                             -0.10311    0.00433    -0.09645   -0.10971
mean/std                              0.51425     0.00341    0.52034    0.50908
mean/max                              0.99676     0.01455    1.01830    0.97255
mean/min                              -1.62546    0.00782    -1.61225   -1.63621
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 0, 2, 7, 8, 9, 5, 4, 1, 6]
replay_buffer._size: [22650 22650 22650 22650 22650 22650 22650 22650 22650 22650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.784743785858154 0.0019335746765136719
train_time 5.787903547286987
2023-09-06 14:01:48,354 MainThread INFO: EPOCH:149
2023-09-06 14:01:48,355 MainThread INFO: Time Consumed:5.802253723144531s
2023-09-06 14:01:48,356 MainThread INFO: Total Frames:225000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 150/400 [08:28<23:54,  5.74s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               243.22971
Train_Epoch_Reward                    4980.02499
Running_Training_Average_Rewards      385.13705
Explore_Time                          0.00272
Train___Time                          5.78790
Eval____Time                          0.00605
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -30.84458
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.59735
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.90365
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.82710
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.47731
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.50622
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.81821
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3007.10659
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.02547
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.38184
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.85826     0.55454    5.91065    3.71570
alpha_0                               0.68777     0.00048    0.68852    0.68702
alpha_1                               0.64276     0.00056    0.64364    0.64188
alpha_2                               0.64027     0.00054    0.64112    0.63943
alpha_3                               0.64106     0.00054    0.64191    0.64021
alpha_4                               0.64784     0.00055    0.64870    0.64698
alpha_5                               0.64976     0.00058    0.65067    0.64885
alpha_6                               0.65186     0.00055    0.65272    0.65100
alpha_7                               0.65120     0.00052    0.65201    0.65040
alpha_8                               0.64740     0.00054    0.64825    0.64655
alpha_9                               0.65183     0.00052    0.65263    0.65102
Alpha_loss                            -2.57436    0.01404    -2.55292   -2.60919
Training/policy_loss                  -27.16132   0.07914    -26.99085  -27.25867
Training/qf1_loss                     400.01879   170.31634  713.76721  202.36316
Training/qf2_loss                     425.32950   175.60328  752.91132  217.67758
Training/pf_norm                      0.26878     0.02532    0.30881    0.23114
Training/qf1_norm                     209.92276   73.00361   354.97577  67.22195
Training/qf2_norm                     248.65484   73.58452   396.10321  103.77312
log_std/mean                          -0.23085    0.00053    -0.22989   -0.23142
log_std/std                           0.08989     0.00022    0.09028    0.08965
log_std/max                           -0.11574    0.00164    -0.11276   -0.11765
log_std/min                           -0.55119    0.00513    -0.54491   -0.56415
log_probs/mean                        -1.97317    0.03185    -1.91270   -2.04060
log_probs/std                         1.25822     0.02874    1.29870    1.19403
log_probs/max                         2.81249     0.21781    3.13507    2.45373
log_probs/min                         -6.78387    0.63545    -6.02131   -7.94481
mean/mean                             -0.11648    0.00332    -0.11105   -0.12161
mean/std                              0.50525     0.00135    0.50740    0.50291
mean/max                              0.95282     0.01193    0.97361    0.93174
mean/min                              -1.61520    0.01378    -1.59618   -1.64719
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 3, 4, 6, 7, 5, 8, 9, 1, 0]
replay_buffer._size: [22800 22800 22800 22800 22800 22800 22800 22800 22800 22800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.325507640838623 0.002165079116821289
train_time 3.329815626144409
2023-09-06 14:01:54,083 MainThread INFO: EPOCH:150
2023-09-06 14:01:54,084 MainThread INFO: Time Consumed:5.592174768447876s
2023-09-06 14:01:54,084 MainThread INFO: Total Frames:226500s
 38%|‚ñà‚ñà‚ñà‚ñä      | 151/400 [08:33<23:47,  5.73s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               259.44051
Train_Epoch_Reward                    2909.52574
Running_Training_Average_Rewards      364.80155
Explore_Time                          2.25366
Train___Time                          3.32982
Eval____Time                          0.00322
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -35.08679
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.72381
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.62586
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.02139
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.45770
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.01959
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.21217
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3322.94246
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.73888
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.60091
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.68060     0.44292   5.44122    3.94592
alpha_0                               0.68609     0.00049   0.68685    0.68532
alpha_1                               0.64081     0.00056   0.64169    0.63994
alpha_2                               0.63841     0.00053   0.63924    0.63757
alpha_3                               0.63918     0.00054   0.64002    0.63833
alpha_4                               0.64592     0.00055   0.64678    0.64506
alpha_5                               0.64774     0.00058   0.64865    0.64682
alpha_6                               0.64995     0.00055   0.65081    0.64908
alpha_7                               0.64941     0.00051   0.65022    0.64861
alpha_8                               0.64552     0.00054   0.64636    0.64467
alpha_9                               0.65002     0.00052   0.65084    0.64921
Alpha_loss                            -2.59391    0.01421   -2.57739   -2.61891
Training/policy_loss                  -27.37917   0.06021   -27.25221  -27.45234
Training/qf1_loss                     297.94150   82.35064  471.75031  188.48094
Training/qf2_loss                     321.30247   86.04481  503.91129  207.52409
Training/pf_norm                      0.29154     0.03714   0.35536    0.23249
Training/qf1_norm                     184.02615   57.73208  282.07904  93.72665
Training/qf2_norm                     222.74526   58.15806  319.03702  129.93791
log_std/mean                          -0.22811    0.00125   -0.22604   -0.22984
log_std/std                           0.08885     0.00089   0.09000    0.08735
log_std/max                           -0.10929    0.00116   -0.10775   -0.11144
log_std/min                           -0.54608    0.00939   -0.53069   -0.56447
log_probs/mean                        -1.97820    0.02313   -1.94448   -2.02105
log_probs/std                         1.24595     0.03746   1.33350    1.18449
log_probs/max                         2.67171     0.24752   3.06781    2.24947
log_probs/min                         -7.16732    0.92861   -5.37732   -8.75704
mean/mean                             -0.12722    0.00293   -0.12267   -0.13181
mean/std                              0.49669     0.00482   0.50301    0.48839
mean/max                              0.92307     0.01713   0.95483    0.89536
mean/min                              -1.60875    0.02219   -1.57478   -1.65330
------------------------------------  ----------  --------  ---------  ---------
sample: [6, 9, 2, 8, 4, 5, 7, 1, 0, 3]
replay_buffer._size: [22950 22950 22950 22950 22950 22950 22950 22950 22950 22950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.479663133621216 0.002063274383544922
train_time 5.483081102371216
2023-09-06 14:01:59,701 MainThread INFO: EPOCH:151
2023-09-06 14:01:59,702 MainThread INFO: Time Consumed:5.4925618171691895s
2023-09-06 14:01:59,702 MainThread INFO: Total Frames:228000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 152/400 [08:39<23:33,  5.70s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               291.85197
Train_Epoch_Reward                    5834.32091
Running_Training_Average_Rewards      457.46239
Explore_Time                          0.00297
Train___Time                          5.48308
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.57267
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.05112
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.04086
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.07981
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.17261
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.62410
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.75721
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3683.06780
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.58239
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.80811
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.83563     0.29030    5.27720    4.24586
alpha_0                               0.68437     0.00050    0.68515    0.68359
alpha_1                               0.63888     0.00056    0.63975    0.63801
alpha_2                               0.63655     0.00053    0.63739    0.63573
alpha_3                               0.63729     0.00054    0.63814    0.63645
alpha_4                               0.64401     0.00055    0.64487    0.64314
alpha_5                               0.64570     0.00058    0.64662    0.64479
alpha_6                               0.64803     0.00055    0.64889    0.64716
alpha_7                               0.64762     0.00052    0.64843    0.64680
alpha_8                               0.64364     0.00054    0.64449    0.64279
alpha_9                               0.64822     0.00052    0.64903    0.64741
Alpha_loss                            -2.62585    0.01865    -2.60388   -2.67406
Training/policy_loss                  -27.59048   0.06045    -27.48831  -27.69709
Training/qf1_loss                     347.99602   173.25393  726.16248  159.29080
Training/qf2_loss                     373.18650   175.88215  757.63727  177.55768
Training/pf_norm                      0.31393     0.05266    0.40639    0.23026
Training/qf1_norm                     203.42752   38.75781   262.35773  125.19802
Training/qf2_norm                     243.38819   39.88250   301.21579  163.00220
log_std/mean                          -0.22485    0.00041    -0.22418   -0.22542
log_std/std                           0.08630     0.00051    0.08721    0.08571
log_std/max                           -0.10509    0.00163    -0.10260   -0.10760
log_std/min                           -0.53326    0.00847    -0.51708   -0.54486
log_probs/mean                        -2.01402    0.03655    -1.97250   -2.10976
log_probs/std                         1.20721     0.02815    1.24780    1.15562
log_probs/max                         2.48038     0.18078    2.85765    2.21787
log_probs/min                         -6.90100    0.77459    -5.73457   -8.29776
mean/mean                             -0.13859    0.00361    -0.13299   -0.14408
mean/std                              0.47987     0.00478    0.48704    0.47252
mean/max                              0.89136     0.01635    0.91630    0.86444
mean/min                              -1.58246    0.02224    -1.54194   -1.61167
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 8, 2, 5, 9, 7, 0, 4, 6, 3]
replay_buffer._size: [23100 23100 23100 23100 23100 23100 23100 23100 23100 23100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.464513778686523 0.0019788742065429688
train_time 5.467744827270508
2023-09-06 14:02:05,312 MainThread INFO: EPOCH:152
2023-09-06 14:02:05,312 MainThread INFO: Time Consumed:5.477437257766724s
2023-09-06 14:02:05,313 MainThread INFO: Total Frames:229500s
 38%|‚ñà‚ñà‚ñà‚ñä      | 153/400 [08:44<23:20,  5.67s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               330.70673
Train_Epoch_Reward                    11514.64926
Running_Training_Average_Rewards      675.28320
Explore_Time                          0.00302
Train___Time                          5.46774
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.86029
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.49319
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.56302
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.20377
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.36655
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.19090
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.26248
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4198.05159
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.64426
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.09939
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.86111      0.49943    6.06938    4.32646
alpha_0                               0.68261      0.00051    0.68341    0.68180
alpha_1                               0.63695      0.00055    0.63782    0.63609
alpha_2                               0.63472      0.00052    0.63554    0.63390
alpha_3                               0.63543      0.00053    0.63626    0.63459
alpha_4                               0.64208      0.00055    0.64295    0.64122
alpha_5                               0.64367      0.00058    0.64459    0.64276
alpha_6                               0.64609      0.00056    0.64697    0.64522
alpha_7                               0.64581      0.00052    0.64662    0.64499
alpha_8                               0.64175      0.00054    0.64260    0.64090
alpha_9                               0.64642      0.00052    0.64723    0.64560
Alpha_loss                            -2.64919     0.01690    -2.62242   -2.67512
Training/policy_loss                  -27.81474    0.06965    -27.72615  -27.96244
Training/qf1_loss                     348.70595    170.91834  662.47815  182.70113
Training/qf2_loss                     372.61057    174.99995  693.90302  199.95282
Training/pf_norm                      0.28267      0.02532    0.31421    0.23907
Training/qf1_norm                     202.88900    70.60156   373.11096  126.99886
Training/qf2_norm                     244.41828    70.06355   413.30545  168.75734
log_std/mean                          -0.22556     0.00121    -0.22436   -0.22799
log_std/std                           0.08735      0.00092    0.08864    0.08594
log_std/max                           -0.10036     0.00088    -0.09911   -0.10194
log_std/min                           -0.52617     0.00342    -0.52333   -0.53546
log_probs/mean                        -2.02943     0.03274    -1.97623   -2.07174
log_probs/std                         1.16787      0.02335    1.21655    1.12899
log_probs/max                         2.29088      0.19286    2.61175    1.92259
log_probs/min                         -6.42701     0.57740    -5.43023   -7.42975
mean/mean                             -0.15061     0.00300    -0.14565   -0.15521
mean/std                              0.46882      0.00150    0.47159    0.46707
mean/max                              0.84813      0.01226    0.86313    0.82894
mean/min                              -1.54891     0.01067    -1.53591   -1.57478
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 7, 2, 9, 6, 0, 8, 1, 5, 4]
replay_buffer._size: [23250 23250 23250 23250 23250 23250 23250 23250 23250 23250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.595158338546753 0.0020656585693359375
train_time 5.598451614379883
2023-09-06 14:02:11,045 MainThread INFO: EPOCH:153
2023-09-06 14:02:11,046 MainThread INFO: Time Consumed:5.613567113876343s
2023-09-06 14:02:11,046 MainThread INFO: Total Frames:231000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 154/400 [08:50<23:18,  5.69s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               375.28670
Train_Epoch_Reward                    4378.83947
Running_Training_Average_Rewards      724.26032
Explore_Time                          0.00281
Train___Time                          5.59845
Eval____Time                          0.00832
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.99785
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.37957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.09034
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.38689
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.08048
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.02682
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.23531
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4687.10386
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.58097
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.47142
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.86431     0.66205    6.67033    4.26434
alpha_0                               0.68078     0.00053    0.68162    0.67995
alpha_1                               0.63503     0.00055    0.63589    0.63418
alpha_2                               0.63291     0.00052    0.63372    0.63211
alpha_3                               0.63357     0.00053    0.63440    0.63275
alpha_4                               0.64016     0.00055    0.64103    0.63929
alpha_5                               0.64164     0.00058    0.64256    0.64073
alpha_6                               0.64414     0.00056    0.64502    0.64327
alpha_7                               0.64400     0.00052    0.64481    0.64319
alpha_8                               0.63986     0.00054    0.64071    0.63901
alpha_9                               0.64461     0.00052    0.64542    0.64379
Alpha_loss                            -2.66160    0.01489    -2.63280   -2.68818
Training/policy_loss                  -28.06469   0.07777    -27.95339  -28.15895
Training/qf1_loss                     343.69227   197.36692  852.02118  192.68185
Training/qf2_loss                     368.74256   203.12607  895.61066  213.45346
Training/pf_norm                      0.27868     0.03436    0.31872    0.20058
Training/qf1_norm                     204.24752   92.87090   460.06592  128.36588
Training/qf2_norm                     247.07727   92.11716   500.59134  169.20177
log_std/mean                          -0.23166    0.00150    -0.22873   -0.23317
log_std/std                           0.08901     0.00033    0.08943    0.08854
log_std/max                           -0.09696    0.00099    -0.09567   -0.09853
log_std/min                           -0.53983    0.00744    -0.52863   -0.54991
log_probs/mean                        -2.02001    0.02916    -1.95930   -2.06139
log_probs/std                         1.15759     0.02864    1.21056    1.09943
log_probs/max                         2.05405     0.11594    2.28052    1.93678
log_probs/min                         -6.62685    0.89583    -5.55826   -8.29969
mean/mean                             -0.15873    0.00097    -0.15656   -0.15974
mean/std                              0.46737     0.00040    0.46794    0.46673
mean/max                              0.83539     0.00795    0.84871    0.82451
mean/min                              -1.57536    0.01872    -1.54847   -1.60279
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 9, 1, 4, 2, 3, 8, 7, 6, 5]
replay_buffer._size: [23400 23400 23400 23400 23400 23400 23400 23400 23400 23400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.909287452697754 0.0019207000732421875
train_time 5.912412405014038
2023-09-06 14:02:17,091 MainThread INFO: EPOCH:154
2023-09-06 14:02:17,091 MainThread INFO: Time Consumed:5.928077936172485s
2023-09-06 14:02:17,092 MainThread INFO: Total Frames:232500s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 155/400 [08:56<23:39,  5.79s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               412.70853
Train_Epoch_Reward                    11585.74023
Running_Training_Average_Rewards      915.97430
Explore_Time                          0.00333
Train___Time                          5.91241
Eval____Time                          0.00732
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.31110
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.08629
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.77314
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.89016
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.90838
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.52257
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.22232
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4830.54764
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.10346
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.69614
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.94461      0.74830    6.41251    3.97171
alpha_0                               0.67893      0.00053    0.67976    0.67809
alpha_1                               0.63313      0.00054    0.63399    0.63228
alpha_2                               0.63113      0.00051    0.63193    0.63034
alpha_3                               0.63174      0.00053    0.63256    0.63091
alpha_4                               0.63824      0.00055    0.63910    0.63737
alpha_5                               0.63961      0.00058    0.64053    0.63870
alpha_6                               0.64219      0.00056    0.64307    0.64132
alpha_7                               0.64220      0.00052    0.64301    0.64139
alpha_8                               0.63798      0.00054    0.63883    0.63714
alpha_9                               0.64279      0.00052    0.64361    0.64197
Alpha_loss                            -2.68567     0.02126    -2.65637   -2.71183
Training/policy_loss                  -28.33363    0.08268    -28.23359  -28.46477
Training/qf1_loss                     384.06455    235.89153  785.54126  183.30862
Training/qf2_loss                     408.34653    242.68023  817.87421  200.97482
Training/pf_norm                      0.29445      0.05235    0.39351    0.23186
Training/qf1_norm                     210.31256    106.81980  422.43546  83.44951
Training/qf2_norm                     253.87104    105.65341  463.56250  128.53610
log_std/mean                          -0.23150     0.00172    -0.22842   -0.23345
log_std/std                           0.08801      0.00034    0.08853    0.08747
log_std/max                           -0.09169     0.00230    -0.08813   -0.09499
log_std/min                           -0.53372     0.00802    -0.52262   -0.54687
log_probs/mean                        -2.03415     0.04226    -1.97157   -2.08463
log_probs/std                         1.14265      0.01698    1.17336    1.11781
log_probs/max                         2.03931      0.13051    2.29438    1.78889
log_probs/min                         -6.93207     0.70881    -6.16379   -8.68587
mean/mean                             -0.16010     0.00063    -0.15916   -0.16124
mean/std                              0.46171      0.00357    0.46631    0.45606
mean/max                              0.80673      0.01734    0.82836    0.78003
mean/min                              -1.56160     0.02142    -1.53177   -1.59499
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 0, 5, 7, 4, 3, 8, 6, 9, 1]
replay_buffer._size: [23550 23550 23550 23550 23550 23550 23550 23550 23550 23550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.644925355911255 0.0019006729125976562
train_time 5.648009300231934
2023-09-06 14:02:22,864 MainThread INFO: EPOCH:155
2023-09-06 14:02:22,865 MainThread INFO: Time Consumed:5.660830497741699s
2023-09-06 14:02:22,865 MainThread INFO: Total Frames:234000s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 156/400 [09:02<23:32,  5.79s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               462.06181
Train_Epoch_Reward                    11343.24167
Running_Training_Average_Rewards      910.26071
Explore_Time                          0.00428
Train___Time                          5.64801
Eval____Time                          0.00456
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.41403
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.49677
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.53591
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.45963
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.86147
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.88861
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.52997
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5694.60892
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.76392
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.69266
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           4.60201      0.42972   5.08352    3.80193
alpha_0                               0.67705      0.00054   0.67790    0.67620
alpha_1                               0.63123      0.00054   0.63209    0.63038
alpha_2                               0.62937      0.00050   0.63016    0.62859
alpha_3                               0.62991      0.00052   0.63073    0.62908
alpha_4                               0.63631      0.00055   0.63718    0.63544
alpha_5                               0.63759      0.00058   0.63850    0.63668
alpha_6                               0.64023      0.00057   0.64112    0.63935
alpha_7                               0.64039      0.00052   0.64121    0.63957
alpha_8                               0.63611      0.00054   0.63695    0.63527
alpha_9                               0.64096      0.00053   0.64179    0.64014
Alpha_loss                            -2.72030     0.01003   -2.70493   -2.73753
Training/policy_loss                  -28.49658    0.05432   -28.41362  -28.58713
Training/qf1_loss                     292.53232    86.96755  442.98407  174.26817
Training/qf2_loss                     314.63465    90.23853  468.26215  189.07834
Training/pf_norm                      0.27316      0.03031   0.31840    0.21958
Training/qf1_norm                     166.39414    58.78461  230.90263  58.62098
Training/qf2_norm                     212.59972    58.88070  277.13647  100.62269
log_std/mean                          -0.22485     0.00140   -0.22340   -0.22763
log_std/std                           0.08898      0.00073   0.09014    0.08790
log_std/max                           -0.08546     0.00124   -0.08353   -0.08746
log_std/min                           -0.53547     0.00695   -0.52660   -0.54751
log_probs/mean                        -2.07389     0.02032   -2.04529   -2.10207
log_probs/std                         1.13666      0.01782   1.16029    1.10941
log_probs/max                         1.95282      0.18813   2.30985    1.54884
log_probs/min                         -6.97577     0.63154   -5.92602   -8.37471
mean/mean                             -0.16456     0.00192   -0.16190   -0.16760
mean/std                              0.45217      0.00156   0.45502    0.44992
mean/max                              0.76487      0.01235   0.78332    0.74359
mean/min                              -1.55458     0.01660   -1.52873   -1.58041
------------------------------------  -----------  --------  ---------  ---------
sample: [8, 9, 2, 1, 7, 4, 0, 3, 5, 6]
replay_buffer._size: [23700 23700 23700 23700 23700 23700 23700 23700 23700 23700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.822981595993042 0.0019440650939941406
train_time 5.82617712020874
2023-09-06 14:02:28,825 MainThread INFO: EPOCH:156
2023-09-06 14:02:28,825 MainThread INFO: Time Consumed:5.838416576385498s
2023-09-06 14:02:28,825 MainThread INFO: Total Frames:235500s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 157/400 [09:08<23:39,  5.84s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               565.44646
Train_Epoch_Reward                    7548.66895
Running_Training_Average_Rewards      1015.92170
Explore_Time                          0.00571
Train___Time                          5.82618
Eval____Time                          0.00262
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -35.90656
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.19906
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.78356
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.30270
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.76042
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.69502
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.64172
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7794.68783
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.26290
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.74215
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.76413     0.57545    6.05612    4.08614
alpha_0                               0.67515     0.00055    0.67601    0.67430
alpha_1                               0.62934     0.00054    0.63019    0.62849
alpha_2                               0.62763     0.00050    0.62841    0.62685
alpha_3                               0.62808     0.00052    0.62890    0.62727
alpha_4                               0.63439     0.00055    0.63525    0.63352
alpha_5                               0.63556     0.00058    0.63647    0.63466
alpha_6                               0.63826     0.00057    0.63915    0.63737
alpha_7                               0.63857     0.00053    0.63939    0.63775
alpha_8                               0.63424     0.00054    0.63508    0.63340
alpha_9                               0.63912     0.00053    0.63995    0.63829
Alpha_loss                            -2.73383    0.01138    -2.71684   -2.74700
Training/policy_loss                  -28.70569   0.08335    -28.57397  -28.83123
Training/qf1_loss                     332.51180   232.87008  905.96521  167.75728
Training/qf2_loss                     354.51117   236.64191  930.21350  182.57495
Training/pf_norm                      0.28079     0.02959    0.33150    0.23235
Training/qf1_norm                     184.42039   83.22259   370.52426  83.85818
Training/qf2_norm                     229.68022   82.70437   414.68994  128.46968
log_std/mean                          -0.22462    0.00053    -0.22367   -0.22551
log_std/std                           0.09129     0.00060    0.09232    0.09037
log_std/max                           -0.08054    0.00193    -0.07763   -0.08336
log_std/min                           -0.53705    0.00380    -0.53218   -0.54491
log_probs/mean                        -2.06382    0.02342    -2.03058   -2.10304
log_probs/std                         1.11148     0.02497    1.15026    1.07348
log_probs/max                         1.75188     0.12364    1.97391    1.55362
log_probs/min                         -6.64517    0.75610    -5.39638   -8.03473
mean/mean                             -0.17010    0.00131    -0.16789   -0.17198
mean/std                              0.44754     0.00195    0.45009    0.44434
mean/max                              0.71428     0.01610    0.73901    0.68590
mean/min                              -1.53571    0.01279    -1.51108   -1.55495
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 7, 0, 9, 5, 8, 2, 6, 3, 4]
replay_buffer._size: [23850 23850 23850 23850 23850 23850 23850 23850 23850 23850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.592151880264282 0.002044200897216797
train_time 5.595431566238403
2023-09-06 14:02:34,553 MainThread INFO: EPOCH:157
2023-09-06 14:02:34,554 MainThread INFO: Time Consumed:5.6108174324035645s
2023-09-06 14:02:34,554 MainThread INFO: Total Frames:237000s
 40%|‚ñà‚ñà‚ñà‚ñâ      | 158/400 [09:14<23:24,  5.81s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               728.82709
Train_Epoch_Reward                    11690.50542
Running_Training_Average_Rewards      1019.41387
Explore_Time                          0.00309
Train___Time                          5.59543
Eval____Time                          0.00821
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -31.75968
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.97209
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.49261
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.26374
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.08018
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.34783
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.13934
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9733.35892
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.95924
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.89135
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.69689      0.43162    5.17262    3.57424
alpha_0                               0.67324      0.00056    0.67411    0.67237
alpha_1                               0.62746      0.00054    0.62830    0.62661
alpha_2                               0.62591      0.00049    0.62668    0.62514
alpha_3                               0.62627      0.00052    0.62708    0.62546
alpha_4                               0.63247      0.00055    0.63333    0.63161
alpha_5                               0.63355      0.00058    0.63446    0.63265
alpha_6                               0.63628      0.00057    0.63717    0.63539
alpha_7                               0.63674      0.00052    0.63756    0.63593
alpha_8                               0.63237      0.00054    0.63321    0.63152
alpha_9                               0.63727      0.00053    0.63810    0.63643
Alpha_loss                            -2.76133     0.00940    -2.74699   -2.77444
Training/policy_loss                  -28.94776    0.08453    -28.83039  -29.13420
Training/qf1_loss                     342.75583    217.97349  833.85120  133.76401
Training/qf2_loss                     364.72671    221.39625  859.86786  143.06207
Training/pf_norm                      0.26619      0.03477    0.32153    0.22647
Training/qf1_norm                     175.64488    57.97106   248.98241  32.61649
Training/qf2_norm                     219.21628    64.44597   298.68622  54.52860
log_std/mean                          -0.22724     0.00128    -0.22574   -0.22958
log_std/std                           0.09215      0.00033    0.09252    0.09157
log_std/max                           -0.07539     0.00062    -0.07474   -0.07694
log_std/min                           -0.54154     0.00533    -0.53117   -0.55025
log_probs/mean                        -2.08758     0.02268    -2.05368   -2.12553
log_probs/std                         1.11730      0.01840    1.15644    1.08315
log_probs/max                         1.71806      0.13749    1.88557    1.38005
log_probs/min                         -6.75468     0.84707    -5.71953   -8.59661
mean/mean                             -0.17237     0.00020    -0.17214   -0.17272
mean/std                              0.44243      0.00065    0.44413    0.44169
mean/max                              0.67800      0.01148    0.69568    0.66068
mean/min                              -1.52802     0.01266    -1.50498   -1.55008
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 4, 9, 3, 6, 7, 5, 2, 1, 8]
replay_buffer._size: [24000 24000 24000 24000 24000 24000 24000 24000 24000 24000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.753789901733398 0.0025119781494140625
train_time 5.757813930511475
2023-09-06 14:02:40,444 MainThread INFO: EPOCH:158
2023-09-06 14:02:40,444 MainThread INFO: Time Consumed:5.776463270187378s
2023-09-06 14:02:40,445 MainThread INFO: Total Frames:238500s
 40%|‚ñà‚ñà‚ñà‚ñâ      | 159/400 [09:20<23:25,  5.83s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               892.36800
Train_Epoch_Reward                    13360.17973
Running_Training_Average_Rewards      1086.64514
Explore_Time                          0.00304
Train___Time                          5.75781
Eval____Time                          0.01027
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.32550
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.94750
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -9.31829
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.23492
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.52653
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.21120
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.93122
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10607.59561
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.00909
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.89803
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.01500      0.31670    5.58096    4.52960
alpha_0                               0.67130      0.00056    0.67218    0.67042
alpha_1                               0.62558      0.00054    0.62642    0.62474
alpha_2                               0.62422      0.00048    0.62497    0.62347
alpha_3                               0.62447      0.00051    0.62528    0.62367
alpha_4                               0.63056      0.00055    0.63142    0.62970
alpha_5                               0.63154      0.00058    0.63245    0.63064
alpha_6                               0.63429      0.00057    0.63519    0.63340
alpha_7                               0.63492      0.00053    0.63574    0.63410
alpha_8                               0.63049      0.00054    0.63133    0.62964
alpha_9                               0.63541      0.00053    0.63625    0.63458
Alpha_loss                            -2.77728     0.01701    -2.74883   -2.80454
Training/policy_loss                  -29.17746    0.08499    -29.05262  -29.32695
Training/qf1_loss                     331.18415    109.81728  520.13171  194.25542
Training/qf2_loss                     356.40185    112.73638  550.92523  214.47461
Training/pf_norm                      0.28425      0.06090    0.41133    0.20909
Training/qf1_norm                     219.70140    46.72593   305.90802  149.36162
Training/qf2_norm                     266.36237    45.17183   350.82086  199.22388
log_std/mean                          -0.23114     0.00073    -0.23003   -0.23226
log_std/std                           0.09103      0.00010    0.09121    0.09089
log_std/max                           -0.07706     0.00121    -0.07560   -0.07894
log_std/min                           -0.54169     0.00492    -0.53206   -0.54973
log_probs/mean                        -2.08433     0.03015    -2.03843   -2.12716
log_probs/std                         1.11321      0.01469    1.14249    1.09059
log_probs/max                         1.56042      0.17152    1.83037    1.25802
log_probs/min                         -7.31361     0.97751    -6.23563   -9.72361
mean/mean                             -0.17255     0.00058    -0.17191   -0.17388
mean/std                              0.44169      0.00025    0.44202    0.44130
mean/max                              0.64926      0.00978    0.66977    0.63558
mean/min                              -1.52826     0.01149    -1.51275   -1.54917
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 6, 3, 8, 1, 5, 0, 7, 9, 4]
replay_buffer._size: [24150 24150 24150 24150 24150 24150 24150 24150 24150 24150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.823281526565552 0.001997709274291992
train_time 5.8266119956970215
2023-09-06 14:02:46,407 MainThread INFO: EPOCH:159
2023-09-06 14:02:46,408 MainThread INFO: Time Consumed:5.838148355484009s
2023-09-06 14:02:46,408 MainThread INFO: Total Frames:240000s
 40%|‚ñà‚ñà‚ñà‚ñà      | 160/400 [09:26<23:29,  5.87s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1019.52068
Train_Epoch_Reward                    9834.04509
Running_Training_Average_Rewards      1162.82434
Explore_Time                          0.00290
Train___Time                          5.82661
Eval____Time                          0.00450
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -33.95241
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.35333
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -9.33391
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.13252
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.70894
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.18623
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.13327
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11611.44441
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.86812
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.80145
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.90379      0.51274    5.59998    3.87044
alpha_0                               0.66934      0.00056    0.67022    0.66846
alpha_1                               0.62371      0.00054    0.62455    0.62287
alpha_2                               0.62255      0.00048    0.62330    0.62180
alpha_3                               0.62269      0.00051    0.62349    0.62189
alpha_4                               0.62864      0.00055    0.62950    0.62778
alpha_5                               0.62954      0.00057    0.63044    0.62864
alpha_6                               0.63231      0.00057    0.63320    0.63141
alpha_7                               0.63310      0.00052    0.63392    0.63228
alpha_8                               0.62861      0.00054    0.62945    0.62777
alpha_9                               0.63356      0.00053    0.63439    0.63272
Alpha_loss                            -2.79170     0.01163    -2.76965   -2.80696
Training/policy_loss                  -29.47625    0.08266    -29.36566  -29.62780
Training/qf1_loss                     362.27349    202.39329  714.70898  154.05769
Training/qf2_loss                     386.50339    206.43568  740.32684  171.47331
Training/pf_norm                      0.31315      0.05642    0.40697    0.23190
Training/qf1_norm                     202.04572    76.18029   305.95547  49.19002
Training/qf2_norm                     245.92345    77.90451   350.84769  84.39182
log_std/mean                          -0.23387     0.00045    -0.23283   -0.23436
log_std/std                           0.09275      0.00055    0.09333    0.09168
log_std/max                           -0.08179     0.00156    -0.07913   -0.08452
log_std/min                           -0.54109     0.00498    -0.53237   -0.55068
log_probs/mean                        -2.07557     0.02310    -2.03515   -2.11266
log_probs/std                         1.10691      0.01471    1.13113    1.08395
log_probs/max                         1.49104      0.16111    1.69337    1.14569
log_probs/min                         -6.61211     0.82698    -5.70050   -8.24420
mean/mean                             -0.17880     0.00302    -0.17455   -0.18398
mean/std                              0.44068      0.00150    0.44251    0.43793
mean/max                              0.65305      0.01474    0.68103    0.62969
mean/min                              -1.52128     0.01272    -1.49933   -1.54071
------------------------------------  -----------  ---------  ---------  ---------
sample: [8, 7, 0, 6, 2, 1, 5, 4, 3, 9]
replay_buffer._size: [24300 24300 24300 24300 24300 24300 24300 24300 24300 24300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.6551313400268555 0.0020682811737060547
train_time 5.65847373008728
snapshot at best
2023-09-06 14:02:53,015 MainThread INFO: EPOCH:160
2023-09-06 14:02:53,016 MainThread INFO: Time Consumed:6.4823267459869385s
2023-09-06 14:02:53,016 MainThread INFO: Total Frames:241500s
 40%|‚ñà‚ñà‚ñà‚ñà      | 161/400 [09:32<24:16,  6.09s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1161.70737
Train_Epoch_Reward                    10981.46235
Running_Training_Average_Rewards      1139.18957
Explore_Time                          0.00346
Train___Time                          5.65847
Eval____Time                          0.00364
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.04663
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.70604
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          737.33674
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.07353
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.40292
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.30826
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.56893
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13259.20209
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.59290
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.78625
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.76698      0.40638    5.29840    3.84366
alpha_0                               0.66738      0.00057    0.66827    0.66648
alpha_1                               0.62185      0.00053    0.62269    0.62102
alpha_2                               0.62090      0.00047    0.62164    0.62016
alpha_3                               0.62091      0.00051    0.62171    0.62012
alpha_4                               0.62673      0.00055    0.62759    0.62588
alpha_5                               0.62754      0.00057    0.62844    0.62665
alpha_6                               0.63032      0.00057    0.63121    0.62942
alpha_7                               0.63128      0.00052    0.63210    0.63046
alpha_8                               0.62674      0.00054    0.62758    0.62590
alpha_9                               0.63170      0.00053    0.63254    0.63087
Alpha_loss                            -2.80985     0.01381    -2.77816   -2.83518
Training/policy_loss                  -29.69519    0.06787    -29.57506  -29.81368
Training/qf1_loss                     295.47424    135.54849  605.01190  144.97612
Training/qf2_loss                     316.14074    138.92455  629.60785  156.44180
Training/pf_norm                      0.29300      0.03606    0.35043    0.21757
Training/qf1_norm                     173.19046    57.78325   240.09337  42.55643
Training/qf2_norm                     218.51817    58.96360   284.77356  82.58416
log_std/mean                          -0.23462     0.00050    -0.23406   -0.23538
log_std/std                           0.09252      0.00040    0.09326    0.09196
log_std/max                           -0.08643     0.00107    -0.08479   -0.08796
log_std/min                           -0.53180     0.00695    -0.52397   -0.54871
log_probs/mean                        -2.07897     0.02404    -2.02759   -2.11596
log_probs/std                         1.09171      0.02016    1.12294    1.05730
log_probs/max                         1.35363      0.19692    1.64471    1.09608
log_probs/min                         -6.53210     0.97477    -5.27846   -8.63824
mean/mean                             -0.19160     0.00417    -0.18542   -0.19822
mean/std                              0.43515      0.00109    0.43721    0.43357
mean/max                              0.69675      0.01129    0.71378    0.67972
mean/min                              -1.49108     0.01911    -1.46213   -1.53340
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 8, 6, 0, 3, 9, 1, 7, 5, 4]
replay_buffer._size: [24450 24450 24450 24450 24450 24450 24450 24450 24450 24450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.2353436946868896 0.0020868778228759766
train_time 3.238661527633667
snapshot at best
2023-09-06 14:02:58,886 MainThread INFO: EPOCH:161
2023-09-06 14:02:58,887 MainThread INFO: Time Consumed:3.8570494651794434s
2023-09-06 14:02:58,887 MainThread INFO: Total Frames:243000s
 40%|‚ñà‚ñà‚ñà‚ñà      | 162/400 [09:38<23:52,  6.02s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1348.13409
Train_Epoch_Reward                    14466.66405
Running_Training_Average_Rewards      1176.07238
Explore_Time                          0.00367
Train___Time                          3.23866
Eval____Time                          0.00517
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -35.77254
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.03775
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -9.76996
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.28930
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.65965
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.83877
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.99794
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16200.99403
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.35260
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.28056
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.95562      0.59059    5.78435    4.09574
alpha_0                               0.66538      0.00058    0.66628    0.66447
alpha_1                               0.62001      0.00053    0.62083    0.61918
alpha_2                               0.61927      0.00046    0.62000    0.61855
alpha_3                               0.61916      0.00050    0.61995    0.61837
alpha_4                               0.62483      0.00055    0.62569    0.62397
alpha_5                               0.62556      0.00057    0.62645    0.62468
alpha_6                               0.62832      0.00057    0.62922    0.62743
alpha_7                               0.62945      0.00052    0.63027    0.62864
alpha_8                               0.62488      0.00053    0.62572    0.62405
alpha_9                               0.62985      0.00053    0.63068    0.62902
Alpha_loss                            -2.81088     0.00928    -2.79573   -2.82374
Training/policy_loss                  -29.96653    0.09428    -29.75095  -30.09148
Training/qf1_loss                     341.20543    124.86667  546.24744  140.25691
Training/qf2_loss                     362.86370    129.18011  577.61060  156.39720
Training/pf_norm                      0.28566      0.03741    0.35808    0.24298
Training/qf1_norm                     203.72221    86.07072   312.44757  74.45621
Training/qf2_norm                     251.20138    86.76363   360.56857  122.64051
log_std/mean                          -0.23615     0.00046    -0.23524   -0.23664
log_std/std                           0.09245      0.00045    0.09311    0.09177
log_std/max                           -0.09069     0.00094    -0.08907   -0.09178
log_std/min                           -0.53040     0.00712    -0.52071   -0.54059
log_probs/mean                        -2.04360     0.02067    -2.01599   -2.07916
log_probs/std                         1.08852      0.01362    1.10835    1.06395
log_probs/max                         1.20885      0.19553    1.43259    0.87812
log_probs/min                         -6.53721     0.55942    -5.51795   -7.39915
mean/mean                             -0.20411     0.00224    -0.19962   -0.20630
mean/std                              0.43314      0.00048    0.43371    0.43227
mean/max                              0.72242      0.00471    0.73447    0.71808
mean/min                              -1.49470     0.01741    -1.46556   -1.51952
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 4, 9, 7, 2, 5, 6, 8, 3, 1]
replay_buffer._size: [24600 24600 24600 24600 24600 24600 24600 24600 24600 24600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.216158628463745 0.004428863525390625
train_time 3.2220444679260254
snapshot at best
2023-09-06 14:03:04,767 MainThread INFO: EPOCH:162
2023-09-06 14:03:04,768 MainThread INFO: Time Consumed:3.747434616088867s
2023-09-06 14:03:04,769 MainThread INFO: Total Frames:244500s
 41%|‚ñà‚ñà‚ñà‚ñà      | 163/400 [09:44<23:36,  5.98s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1533.17119
Train_Epoch_Reward                    14768.38589
Running_Training_Average_Rewards      1340.55041
Explore_Time                          0.00639
Train___Time                          3.22204
Eval____Time                          0.00429
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.61130
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.30462
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.77432
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.92054
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.15289
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.60524
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.07924
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17174.89365
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.45208
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.90608
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.00112      0.39578    5.78317    4.19206
alpha_0                               0.66337      0.00058    0.66427    0.66246
alpha_1                               0.61818      0.00052    0.61900    0.61735
alpha_2                               0.61768      0.00046    0.61839    0.61696
alpha_3                               0.61741      0.00050    0.61820    0.61663
alpha_4                               0.62293      0.00054    0.62378    0.62208
alpha_5                               0.62360      0.00056    0.62448    0.62272
alpha_6                               0.62634      0.00057    0.62723    0.62544
alpha_7                               0.62764      0.00052    0.62845    0.62682
alpha_8                               0.62304      0.00053    0.62387    0.62221
alpha_9                               0.62801      0.00053    0.62883    0.62718
Alpha_loss                            -2.83593     0.01571    -2.81821   -2.86486
Training/policy_loss                  -30.23163    0.09883    -30.07072  -30.37197
Training/qf1_loss                     358.61317    230.02905  822.59021  143.60355
Training/qf2_loss                     381.17611    233.29437  846.23083  155.80630
Training/pf_norm                      0.26814      0.02747    0.33287    0.22526
Training/qf1_norm                     203.72902    60.61301   327.04507  79.46181
Training/qf2_norm                     252.08425    58.93646   372.72079  129.92302
log_std/mean                          -0.23265     0.00084    -0.23162   -0.23452
log_std/std                           0.09319      0.00019    0.09346    0.09289
log_std/max                           -0.09442     0.00204    -0.09147   -0.09731
log_std/min                           -0.52708     0.00709    -0.51961   -0.53763
log_probs/mean                        -2.05842     0.02857    -2.01684   -2.10288
log_probs/std                         1.08885      0.01594    1.12463    1.06755
log_probs/max                         1.14735      0.16100    1.37726    0.84762
log_probs/min                         -6.89075     1.06806    -5.80589   -8.82471
mean/mean                             -0.20380     0.00173    -0.20069   -0.20617
mean/std                              0.43113      0.00081    0.43215    0.42947
mean/max                              0.72942      0.00372    0.73760    0.72545
mean/min                              -1.50008     0.01807    -1.47961   -1.52866
------------------------------------  -----------  ---------  ---------  ---------
sample: [8, 7, 6, 0, 5, 9, 3, 4, 2, 1]
replay_buffer._size: [24750 24750 24750 24750 24750 24750 24750 24750 24750 24750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.324275016784668 0.0021102428436279297
train_time 3.3276572227478027
2023-09-06 14:03:10,344 MainThread INFO: EPOCH:163
2023-09-06 14:03:10,345 MainThread INFO: Time Consumed:3.3451266288757324s
2023-09-06 14:03:10,345 MainThread INFO: Total Frames:246000s
 41%|‚ñà‚ñà‚ñà‚ñà      | 164/400 [09:49<23:02,  5.86s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1638.20102
Train_Epoch_Reward                    13752.97093
Running_Training_Average_Rewards      1432.93403
Explore_Time                          0.00564
Train___Time                          3.32766
Eval____Time                          0.00708
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.10853
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.93809
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.54703
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.69409
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.13049
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.86047
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -50.76133
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17166.12800
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.42857
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.71103
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.96752      0.41792    5.78161    4.45280
alpha_0                               0.66135      0.00058    0.66226    0.66044
alpha_1                               0.61635      0.00052    0.61717    0.61553
alpha_2                               0.61609      0.00045    0.61680    0.61538
alpha_3                               0.61567      0.00050    0.61645    0.61489
alpha_4                               0.62104      0.00054    0.62189    0.62019
alpha_5                               0.62165      0.00056    0.62253    0.62078
alpha_6                               0.62434      0.00057    0.62524    0.62345
alpha_7                               0.62583      0.00052    0.62664    0.62502
alpha_8                               0.62119      0.00053    0.62202    0.62036
alpha_9                               0.62616      0.00053    0.62700    0.62533
Alpha_loss                            -2.85925     0.01019    -2.84017   -2.87588
Training/policy_loss                  -30.56469    0.07281    -30.44316  -30.69631
Training/qf1_loss                     309.52504    119.00360  510.98071  179.57303
Training/qf2_loss                     332.35468    122.69054  538.45782  200.54790
Training/pf_norm                      0.25649      0.01717    0.28950    0.23277
Training/qf1_norm                     193.57440    65.20707   314.42612  104.54260
Training/qf2_norm                     242.62316    65.03227   363.92944  148.95428
log_std/mean                          -0.23254     0.00035    -0.23203   -0.23336
log_std/std                           0.09441      0.00065    0.09549    0.09332
log_std/max                           -0.10022     0.00133    -0.09830   -0.10256
log_std/min                           -0.53328     0.00790    -0.52087   -0.54476
log_probs/mean                        -2.07106     0.01535    -2.04692   -2.09258
log_probs/std                         1.08380      0.01939    1.11173    1.04191
log_probs/max                         1.11589      0.14023    1.32625    0.88702
log_probs/min                         -7.13126     1.03889    -6.20833   -9.49901
mean/mean                             -0.19949     0.00049    -0.19894   -0.20036
mean/std                              0.42907      0.00073    0.43020    0.42803
mean/max                              0.74420      0.00553    0.75844    0.73827
mean/min                              -1.50467     0.01955    -1.47393   -1.52709
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 0, 7, 5, 9, 1, 8, 3, 6, 4]
replay_buffer._size: [24900 24900 24900 24900 24900 24900 24900 24900 24900 24900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.134146690368652 0.002756357192993164
train_time 6.138557195663452
snapshot at best
2023-09-06 14:03:17,191 MainThread INFO: EPOCH:164
2023-09-06 14:03:17,191 MainThread INFO: Time Consumed:6.7345662117004395s
2023-09-06 14:03:17,192 MainThread INFO: Total Frames:247500s
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 165/400 [09:56<24:06,  6.15s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1671.31020
Train_Epoch_Reward                    10432.50171
Running_Training_Average_Rewards      1298.46195
Explore_Time                          0.00276
Train___Time                          6.13856
Eval____Time                          0.00287
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.76705
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.05924
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47458
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.22462
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.97065
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.69440
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.20146
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17209.34985
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.33508
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.35233
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.20500      0.61880    6.19163     4.27854
alpha_0                               0.65933      0.00058    0.66024     0.65842
alpha_1                               0.61453      0.00052    0.61535     0.61371
alpha_2                               0.61451      0.00046    0.61522     0.61379
alpha_3                               0.61393      0.00050    0.61471     0.61315
alpha_4                               0.61916      0.00054    0.62000     0.61832
alpha_5                               0.61971      0.00056    0.62058     0.61884
alpha_6                               0.62236      0.00057    0.62325     0.62146
alpha_7                               0.62403      0.00052    0.62484     0.62322
alpha_8                               0.61935      0.00053    0.62017     0.61852
alpha_9                               0.62431      0.00053    0.62515     0.62348
Alpha_loss                            -2.87322     0.01148    -2.85655    -2.90070
Training/policy_loss                  -30.84671    0.07615    -30.73410   -30.97026
Training/qf1_loss                     461.48967    311.05538  1127.19238  199.08203
Training/qf2_loss                     487.25268    318.07587  1167.54553  217.96619
Training/pf_norm                      0.27816      0.02557    0.32463     0.24610
Training/qf1_norm                     225.32525    96.80788   379.86716   78.85792
Training/qf2_norm                     279.27643    96.79198   434.36697   133.33470
log_std/mean                          -0.23719     0.00209    -0.23405    -0.24007
log_std/std                           0.09764      0.00100    0.09908     0.09590
log_std/max                           -0.10678     0.00252    -0.10259    -0.10982
log_std/min                           -0.53961     0.00852    -0.52629    -0.55795
log_probs/mean                        -2.06197     0.02863    -2.00806    -2.11958
log_probs/std                         1.08514      0.01258    1.11405     1.06581
log_probs/max                         0.99500      0.10584    1.15281     0.77831
log_probs/min                         -6.85464     0.91797    -5.93796    -8.94658
mean/mean                             -0.20189     0.00113    -0.20013    -0.20333
mean/std                              0.43203      0.00185    0.43497     0.42969
mean/max                              0.75962      0.00668    0.76853     0.74738
mean/min                              -1.51443     0.02167    -1.48257    -1.56360
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 8, 6, 4, 5, 0, 9, 3, 7, 2]
replay_buffer._size: [25050 25050 25050 25050 25050 25050 25050 25050 25050 25050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.869157314300537 0.0020194053649902344
train_time 3.872382640838623
2023-09-06 14:03:22,752 MainThread INFO: EPOCH:165
2023-09-06 14:03:22,753 MainThread INFO: Time Consumed:3.8916900157928467s
2023-09-06 14:03:22,753 MainThread INFO: Total Frames:249000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 166/400 [10:02<23:18,  5.98s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1671.93112
Train_Epoch_Reward                    13187.36666
Running_Training_Average_Rewards      1245.76131
Explore_Time                          0.01277
Train___Time                          3.87238
Eval____Time                          0.00219
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.68556
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.92398
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.72367
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.20566
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.79695
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.90697
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.77164
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17194.62081
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.41485
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.47669
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.81841      0.53994    5.88756    4.16378
alpha_0                               0.65731      0.00058    0.65821    0.65640
alpha_1                               0.61271      0.00052    0.61353    0.61190
alpha_2                               0.61293      0.00045    0.61363    0.61222
alpha_3                               0.61219      0.00050    0.61297    0.61141
alpha_4                               0.61730      0.00053    0.61814    0.61647
alpha_5                               0.61779      0.00055    0.61865    0.61692
alpha_6                               0.62038      0.00057    0.62127    0.61949
alpha_7                               0.62223      0.00051    0.62304    0.62143
alpha_8                               0.61751      0.00053    0.61834    0.61669
alpha_9                               0.62246      0.00053    0.62329    0.62163
Alpha_loss                            -2.88488     0.00900    -2.86851   -2.90260
Training/policy_loss                  -31.15757    0.09263    -31.03331  -31.28621
Training/qf1_loss                     263.83341    123.23731  559.38354  142.35738
Training/qf2_loss                     283.94430    127.15846  584.26355  156.71841
Training/pf_norm                      0.27635      0.03036    0.33392    0.23423
Training/qf1_norm                     160.83140    82.35579   316.57181  58.52892
Training/qf2_norm                     214.84565    83.64116   375.25159  107.79446
log_std/mean                          -0.24003     0.00054    -0.23902   -0.24056
log_std/std                           0.09904      0.00059    0.09958    0.09791
log_std/max                           -0.11077     0.00141    -0.10875   -0.11315
log_std/min                           -0.53812     0.00722    -0.52893   -0.55042
log_probs/mean                        -2.04884     0.01648    -2.02583   -2.07330
log_probs/std                         1.09553      0.01823    1.12535    1.06793
log_probs/max                         1.09957      0.18563    1.44685    0.88031
log_probs/min                         -6.58907     0.65419    -5.39516   -7.69979
mean/mean                             -0.20090     0.00195    -0.19735   -0.20318
mean/std                              0.43778      0.00103    0.43896    0.43615
mean/max                              0.78373      0.01246    0.81159    0.76839
mean/min                              -1.53141     0.01603    -1.50895   -1.56789
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 5, 3, 9, 8, 2, 7, 4, 6, 1]
replay_buffer._size: [25200 25200 25200 25200 25200 25200 25200 25200 25200 25200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.907922744750977 0.0020546913146972656
train_time 5.9111762046813965
2023-09-06 14:03:28,775 MainThread INFO: EPOCH:166
2023-09-06 14:03:28,776 MainThread INFO: Time Consumed:5.920907974243164s
2023-09-06 14:03:28,776 MainThread INFO: Total Frames:250500s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 167/400 [10:08<23:16,  5.99s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1665.22833
Train_Epoch_Reward                    15633.54654
Running_Training_Average_Rewards      1308.44716
Explore_Time                          0.00296
Train___Time                          5.91118
Eval____Time                          0.00288
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.62227
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.64708
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.75759
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.19791
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.40711
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.03526
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.44271
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16969.89513
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.42222
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.49822
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.13375      0.49538    6.04813    4.56364
alpha_0                               0.65530      0.00058    0.65620    0.65440
alpha_1                               0.61090      0.00052    0.61172    0.61009
alpha_2                               0.61136      0.00045    0.61206    0.61066
alpha_3                               0.61046      0.00050    0.61124    0.60968
alpha_4                               0.61544      0.00053    0.61628    0.61460
alpha_5                               0.61587      0.00055    0.61673    0.61501
alpha_6                               0.61840      0.00057    0.61929    0.61752
alpha_7                               0.62044      0.00051    0.62125    0.61964
alpha_8                               0.61568      0.00053    0.61650    0.61485
alpha_9                               0.62061      0.00053    0.62144    0.61979
Alpha_loss                            -2.90406     0.01199    -2.87918   -2.91877
Training/policy_loss                  -31.43427    0.08043    -31.33025  -31.54977
Training/qf1_loss                     299.04479    226.18905  886.44080  152.35345
Training/qf2_loss                     320.26497    231.13884  919.43964  166.72079
Training/pf_norm                      0.27678      0.01814    0.30126    0.24324
Training/qf1_norm                     202.56930    81.18040   366.72266  107.42210
Training/qf2_norm                     259.01511    80.75775   422.39441  166.42957
log_std/mean                          -0.23847     0.00027    -0.23803   -0.23882
log_std/std                           0.09712      0.00034    0.09772    0.09670
log_std/max                           -0.11628     0.00172    -0.11377   -0.11882
log_std/min                           -0.53431     0.00569    -0.52172   -0.54164
log_probs/mean                        -2.05182     0.02532    -2.01063   -2.09678
log_probs/std                         1.10270      0.02502    1.15570    1.07468
log_probs/max                         1.14598      0.10008    1.35789    1.01621
log_probs/min                         -6.78920     0.72516    -5.89716   -8.10731
mean/mean                             -0.19358     0.00173    -0.19160   -0.19664
mean/std                              0.44102      0.00137    0.44299    0.43891
mean/max                              0.81929      0.00867    0.83531    0.80754
mean/min                              -1.53848     0.01405    -1.51343   -1.55667
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 2, 1, 9, 4, 0, 8, 5, 6, 7]
replay_buffer._size: [25350 25350 25350 25350 25350 25350 25350 25350 25350 25350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.912223815917969 0.0021734237670898438
train_time 5.915639638900757
2023-09-06 14:03:34,823 MainThread INFO: EPOCH:167
2023-09-06 14:03:34,823 MainThread INFO: Time Consumed:5.9298295974731445s
2023-09-06 14:03:34,824 MainThread INFO: Total Frames:252000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 168/400 [10:14<23:13,  6.01s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1654.65409
Train_Epoch_Reward                    14084.77853
Running_Training_Average_Rewards      1430.18972
Explore_Time                          0.00608
Train___Time                          5.91564
Eval____Time                          0.00376
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.93760
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.97972
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.58261
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.08553
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.73971
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.10006
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.07550
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16897.13951
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.29787
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.29791
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.03279      0.43757    5.71870    4.37521
alpha_0                               0.65330      0.00057    0.65420    0.65240
alpha_1                               0.60910      0.00051    0.60991    0.60830
alpha_2                               0.60980      0.00045    0.61050    0.60910
alpha_3                               0.60873      0.00050    0.60951    0.60795
alpha_4                               0.61358      0.00053    0.61442    0.61275
alpha_5                               0.61397      0.00054    0.61482    0.61312
alpha_6                               0.61644      0.00057    0.61732    0.61555
alpha_7                               0.61865      0.00051    0.61946    0.61785
alpha_8                               0.61384      0.00053    0.61467    0.61302
alpha_9                               0.61879      0.00052    0.61961    0.61796
Alpha_loss                            -2.91937     0.00971    -2.89973   -2.93350
Training/policy_loss                  -31.72214    0.11654    -31.52422  -31.89686
Training/qf1_loss                     346.61250    184.48997  783.60382  172.80341
Training/qf2_loss                     367.27535    186.75172  809.23718  191.70975
Training/pf_norm                      0.27065      0.03696    0.34017    0.21268
Training/qf1_norm                     187.82868    67.65146   285.95624  90.66839
Training/qf2_norm                     243.91994    68.83840   343.21799  142.84439
log_std/mean                          -0.23916     0.00052    -0.23866   -0.24037
log_std/std                           0.09666      0.00010    0.09682    0.09643
log_std/max                           -0.11704     0.00059    -0.11643   -0.11812
log_std/min                           -0.53249     0.00698    -0.52282   -0.54471
log_probs/mean                        -2.04625     0.02051    -2.01489   -2.08081
log_probs/std                         1.10460      0.02207    1.13859    1.07058
log_probs/max                         1.06722      0.11307    1.31323    0.89417
log_probs/min                         -7.23761     0.96025    -6.11081   -8.99637
mean/mean                             -0.19196     0.00083    -0.19093   -0.19334
mean/std                              0.44546      0.00135    0.44780    0.44364
mean/max                              0.83575      0.00484    0.84125    0.82752
mean/min                              -1.53539     0.01621    -1.51304   -1.56582
------------------------------------  -----------  ---------  ---------  ---------
sample: [1, 9, 4, 5, 7, 8, 2, 6, 0, 3]
replay_buffer._size: [25500 25500 25500 25500 25500 25500 25500 25500 25500 25500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.962029457092285 0.002056598663330078
train_time 5.965311765670776
2023-09-06 14:03:40,908 MainThread INFO: EPOCH:168
2023-09-06 14:03:40,909 MainThread INFO: Time Consumed:5.976424932479858s
2023-09-06 14:03:40,909 MainThread INFO: Total Frames:253500s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 169/400 [10:20<23:13,  6.03s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1648.82984
Train_Epoch_Reward                    15028.16927
Running_Training_Average_Rewards      1491.54981
Explore_Time                          0.00325
Train___Time                          5.96531
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.65804
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.28865
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.16157
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.93138
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.92514
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.90478
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.63440
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17032.50499
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.17090
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.84269
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.78442      0.45539    5.86633    4.33453
alpha_0                               0.65130      0.00057    0.65220    0.65041
alpha_1                               0.60732      0.00051    0.60812    0.60651
alpha_2                               0.60825      0.00045    0.60895    0.60755
alpha_3                               0.60700      0.00050    0.60778    0.60622
alpha_4                               0.61173      0.00053    0.61256    0.61090
alpha_5                               0.61209      0.00054    0.61293    0.61125
alpha_6                               0.61447      0.00056    0.61536    0.61359
alpha_7                               0.61687      0.00051    0.61767    0.61607
alpha_8                               0.61201      0.00052    0.61283    0.61119
alpha_9                               0.61696      0.00052    0.61778    0.61614
Alpha_loss                            -2.92340     0.01262    -2.89764   -2.93978
Training/policy_loss                  -32.00282    0.06675    -31.89856  -32.10511
Training/qf1_loss                     271.74363    144.82353  616.11713  151.55374
Training/qf2_loss                     291.58411    149.33979  646.37360  167.10608
Training/pf_norm                      0.27190      0.03417    0.30616    0.20942
Training/qf1_norm                     142.01316    71.90207   308.06989  67.29709
Training/qf2_norm                     200.65274    72.47089   367.04233  121.70065
log_std/mean                          -0.24301     0.00168    -0.24059   -0.24506
log_std/std                           0.09737      0.00106    0.09927    0.09623
log_std/max                           -0.11637     0.00053    -0.11541   -0.11720
log_std/min                           -0.54336     0.00773    -0.52870   -0.55192
log_probs/mean                        -2.01814     0.03259    -1.95818   -2.06536
log_probs/std                         1.11118      0.02215    1.14198    1.06656
log_probs/max                         1.04648      0.08778    1.14396    0.86747
log_probs/min                         -6.63946     0.50575    -5.95016   -7.42162
mean/mean                             -0.19558     0.00116    -0.19357   -0.19677
mean/std                              0.45043      0.00131    0.45215    0.44830
mean/max                              0.83876      0.00561    0.84784    0.83237
mean/min                              -1.55655     0.01622    -1.53230   -1.58325
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 4, 3, 6, 7, 8, 9, 5, 2, 1]
replay_buffer._size: [25650 25650 25650 25650 25650 25650 25650 25650 25650 25650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.001477241516113 0.0019481182098388672
train_time 6.0046303272247314
2023-09-06 14:03:47,039 MainThread INFO: EPOCH:169
2023-09-06 14:03:47,040 MainThread INFO: Time Consumed:6.019618034362793s
2023-09-06 14:03:47,040 MainThread INFO: Total Frames:255000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 170/400 [10:26<23:13,  6.06s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1641.45710
Train_Epoch_Reward                    13918.59739
Running_Training_Average_Rewards      1434.38484
Explore_Time                          0.00611
Train___Time                          6.00463
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.55988
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.95391
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -25.97519
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.91082
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.93207
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.19175
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.51312
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16759.60208
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.21076
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.67189
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.18977      0.38373   5.90343    4.57849
alpha_0                               0.64932      0.00057   0.65021    0.64843
alpha_1                               0.60554      0.00051   0.60634    0.60475
alpha_2                               0.60670      0.00044   0.60740    0.60601
alpha_3                               0.60527      0.00050   0.60605    0.60449
alpha_4                               0.60990      0.00053   0.61072    0.60907
alpha_5                               0.61023      0.00053   0.61106    0.60940
alpha_6                               0.61252      0.00056   0.61340    0.61164
alpha_7                               0.61510      0.00051   0.61589    0.61430
alpha_8                               0.61019      0.00052   0.61101    0.60938
alpha_9                               0.61515      0.00052   0.61596    0.61433
Alpha_loss                            -2.94068     0.01556   -2.92081   -2.96555
Training/policy_loss                  -32.25801    0.10628   -32.07307  -32.44805
Training/qf1_loss                     237.00094    55.56222  353.94019  136.89439
Training/qf2_loss                     259.58709    59.13397  385.92975  152.45659
Training/pf_norm                      0.30399      0.04544   0.39200    0.24021
Training/qf1_norm                     200.26278    61.23047  318.87726  106.26458
Training/qf2_norm                     260.76224    60.86094  379.24823  170.17775
log_std/mean                          -0.24423     0.00080   -0.24256   -0.24506
log_std/std                           0.10047      0.00058   0.10139    0.09965
log_std/max                           -0.11239     0.00208   -0.10901   -0.11540
log_std/min                           -0.56504     0.00718   -0.55451   -0.57990
log_probs/mean                        -2.01702     0.02510   -1.98205   -2.05907
log_probs/std                         1.10176      0.01896   1.13044    1.06673
log_probs/max                         1.11817      0.14132   1.35401    0.92228
log_probs/min                         -6.53691     0.44500   -6.04634   -7.21998
mean/mean                             -0.19753     0.00109   -0.19642   -0.19969
mean/std                              0.44996      0.00140   0.45219    0.44775
mean/max                              0.84295      0.00798   0.85448    0.83244
mean/min                              -1.57032     0.01499   -1.55480   -1.59724
------------------------------------  -----------  --------  ---------  ---------
sample: [6, 7, 0, 1, 8, 2, 4, 5, 3, 9]
replay_buffer._size: [25800 25800 25800 25800 25800 25800 25800 25800 25800 25800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.088092803955078 0.00462031364440918
train_time 6.094005346298218
2023-09-06 14:03:53,249 MainThread INFO: EPOCH:170
2023-09-06 14:03:53,249 MainThread INFO: Time Consumed:6.104887247085571s
2023-09-06 14:03:53,250 MainThread INFO: Total Frames:256500s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 171/400 [10:32<23:18,  6.11s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1619.28225
Train_Epoch_Reward                    10694.33323
Running_Training_Average_Rewards      1321.37000
Explore_Time                          0.00282
Train___Time                          6.09401
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.48364
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.62332
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -27.72575
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.94743
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.36220
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.85304
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.77207
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16237.47209
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.21844
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.68895
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.14507      0.49583    5.89459    4.36005
alpha_0                               0.64734      0.00057    0.64823    0.64646
alpha_1                               0.60379      0.00050    0.60457    0.60299
alpha_2                               0.60515      0.00045    0.60585    0.60445
alpha_3                               0.60353      0.00050    0.60431    0.60275
alpha_4                               0.60807      0.00053    0.60889    0.60724
alpha_5                               0.60840      0.00052    0.60922    0.60758
alpha_6                               0.61057      0.00056    0.61144    0.60969
alpha_7                               0.61333      0.00051    0.61412    0.61253
alpha_8                               0.60838      0.00052    0.60920    0.60757
alpha_9                               0.61334      0.00052    0.61415    0.61252
Alpha_loss                            -2.95869     0.01088    -2.94074   -2.98035
Training/policy_loss                  -32.59668    0.08981    -32.47097  -32.74926
Training/qf1_loss                     334.25064    142.08533  613.61517  189.90205
Training/qf2_loss                     356.85695    145.48852  635.62616  207.67525
Training/pf_norm                      0.29875      0.02908    0.33939    0.23203
Training/qf1_norm                     188.85347    81.21382   308.77682  58.54608
Training/qf2_norm                     247.26524    82.50992   373.07428  113.43212
log_std/mean                          -0.24210     0.00033    -0.24159   -0.24266
log_std/std                           0.10113      0.00024    0.10154    0.10082
log_std/max                           -0.10991     0.00149    -0.10810   -0.11232
log_std/min                           -0.55786     0.00674    -0.55021   -0.57597
log_probs/mean                        -2.01737     0.02048    -1.98445   -2.05170
log_probs/std                         1.10029      0.02213    1.13219    1.05190
log_probs/max                         1.02941      0.09088    1.13630    0.86939
log_probs/min                         -6.68096     0.94414    -5.70194   -8.81323
mean/mean                             -0.20508     0.00323    -0.20080   -0.21063
mean/std                              0.44748      0.00025    0.44788    0.44702
mean/max                              0.86503      0.01010    0.88518    0.85141
mean/min                              -1.54255     0.01671    -1.52504   -1.58572
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 9, 4, 3, 0, 7, 1, 8, 5, 2]
replay_buffer._size: [25950 25950 25950 25950 25950 25950 25950 25950 25950 25950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.025295734405518 0.0019588470458984375
train_time 6.028489351272583
2023-09-06 14:03:59,400 MainThread INFO: EPOCH:171
2023-09-06 14:03:59,400 MainThread INFO: Time Consumed:6.0418829917907715s
2023-09-06 14:03:59,401 MainThread INFO: Total Frames:258000s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 172/400 [10:39<23:15,  6.12s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1504.27644
Train_Epoch_Reward                    13519.67774
Running_Training_Average_Rewards      1271.08695
Explore_Time                          0.00310
Train___Time                          6.02849
Eval____Time                          0.00592
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.32373
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.19668
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -32.27887
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.18999
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.53612
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.12978
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.50123
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13583.49801
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.18739
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.34104
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.44791      0.56406    6.57685     4.81416
alpha_0                               0.64537      0.00057    0.64626     0.64449
alpha_1                               0.60203      0.00050    0.60282     0.60125
alpha_2                               0.60361      0.00044    0.60430     0.60291
alpha_3                               0.60180      0.00049    0.60258     0.60103
alpha_4                               0.60624      0.00052    0.60706     0.60542
alpha_5                               0.60658      0.00052    0.60739     0.60576
alpha_6                               0.60863      0.00056    0.60950     0.60776
alpha_7                               0.61155      0.00051    0.61235     0.61075
alpha_8                               0.60658      0.00052    0.60739     0.60577
alpha_9                               0.61153      0.00052    0.61234     0.61072
Alpha_loss                            -2.96942     0.01011    -2.95874    -2.98818
Training/policy_loss                  -32.93676    0.12840    -32.70122   -33.12519
Training/qf1_loss                     431.08025    288.76372  970.38977   181.75873
Training/qf2_loss                     457.27546    295.06801  1012.09314  201.77298
Training/pf_norm                      0.27859      0.02441    0.30545     0.22977
Training/qf1_norm                     234.78120    93.17730   430.79727   124.52558
Training/qf2_norm                     295.53322    93.44326   492.92114   181.58759
log_std/mean                          -0.24372     0.00093    -0.24185    -0.24455
log_std/std                           0.10179      0.00096    0.10350     0.10057
log_std/max                           -0.11635     0.00137    -0.11356    -0.11787
log_std/min                           -0.56230     0.00671    -0.55422    -0.57449
log_probs/mean                        -2.00450     0.01978    -1.96538    -2.03479
log_probs/std                         1.11287      0.01851    1.15465     1.08645
log_probs/max                         1.04623      0.12921    1.32071     0.90184
log_probs/min                         -6.54144     0.60180    -6.03270    -7.86778
mean/mean                             -0.21848     0.00418    -0.21178    -0.22475
mean/std                              0.44986      0.00153    0.45255     0.44760
mean/max                              0.87124      0.00553    0.88050     0.86335
mean/min                              -1.56262     0.01856    -1.53641    -1.59455
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 4, 2, 7, 1, 6, 8, 5, 9, 3]
replay_buffer._size: [26100 26100 26100 26100 26100 26100 26100 26100 26100 26100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.849820613861084 0.0019419193267822266
train_time 5.852983474731445
2023-09-06 14:04:05,383 MainThread INFO: EPOCH:172
2023-09-06 14:04:05,383 MainThread INFO: Time Consumed:5.8640220165252686s
2023-09-06 14:04:05,383 MainThread INFO: Total Frames:259500s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 173/400 [10:45<22:59,  6.08s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1267.06463
Train_Epoch_Reward                    13979.37542
Running_Training_Average_Rewards      1273.11288
Explore_Time                          0.00372
Train___Time                          5.85298
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.96105
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.16994
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -37.52064
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.78113
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.56346
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.61972
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.38202
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9651.35248
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.65053
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.37537
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.22179      0.59092    6.16788    4.17469
alpha_0                               0.64341      0.00056    0.64429    0.64253
alpha_1                               0.60028      0.00050    0.60107    0.59950
alpha_2                               0.60207      0.00044    0.60276    0.60139
alpha_3                               0.60008      0.00049    0.60086    0.59931
alpha_4                               0.60443      0.00052    0.60524    0.60362
alpha_5                               0.60478      0.00051    0.60558    0.60397
alpha_6                               0.60670      0.00055    0.60756    0.60583
alpha_7                               0.60977      0.00051    0.61057    0.60897
alpha_8                               0.60478      0.00051    0.60559    0.60398
alpha_9                               0.60973      0.00052    0.61054    0.60892
Alpha_loss                            -2.97818     0.01996    -2.94465   -3.01016
Training/policy_loss                  -33.25449    0.09626    -33.11137  -33.41879
Training/qf1_loss                     358.47520    222.61164  745.58752  145.88258
Training/qf2_loss                     381.78920    229.48033  785.85834  154.81235
Training/pf_norm                      0.25780      0.02058    0.29917    0.21915
Training/qf1_norm                     191.40578    95.31696   354.75705  30.45441
Training/qf2_norm                     250.66038    99.66261   416.74652  74.26781
log_std/mean                          -0.24492     0.00096    -0.24395   -0.24697
log_std/std                           0.10481      0.00049    0.10537    0.10377
log_std/max                           -0.11715     0.00161    -0.11509   -0.12110
log_std/min                           -0.57659     0.00663    -0.56428   -0.58965
log_probs/mean                        -1.98578     0.04009    -1.92539   -2.05786
log_probs/std                         1.13806      0.03313    1.19059    1.07451
log_probs/max                         1.07328      0.10082    1.24749    0.89984
log_probs/min                         -7.05679     0.67188    -5.88823   -8.14761
mean/mean                             -0.22739     0.00100    -0.22561   -0.22865
mean/std                              0.45473      0.00145    0.45694    0.45262
mean/max                              0.85983      0.00399    0.87083    0.85478
mean/min                              -1.60894     0.01829    -1.58642   -1.64598
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 2, 7, 3, 5, 9, 4, 0, 8, 1]
replay_buffer._size: [26250 26250 26250 26250 26250 26250 26250 26250 26250 26250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.97692346572876 0.0020127296447753906
train_time 5.9801344871521
2023-09-06 14:04:11,487 MainThread INFO: EPOCH:173
2023-09-06 14:04:11,487 MainThread INFO: Time Consumed:5.992615461349487s
2023-09-06 14:04:11,488 MainThread INFO: Total Frames:261000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 174/400 [10:51<22:57,  6.09s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               958.78774
Train_Epoch_Reward                    15422.27052
Running_Training_Average_Rewards      1430.71079
Explore_Time                          0.00272
Train___Time                          5.98013
Eval____Time                          0.00584
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.67404
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.43853
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -40.71939
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.12438
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.27656
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.40000
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.55762
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7010.67717
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.02530
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.97081
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.24154      0.50773    6.21257    4.10995
alpha_0                               0.64146      0.00056    0.64233    0.64059
alpha_1                               0.59854      0.00050    0.59932    0.59775
alpha_2                               0.60055      0.00044    0.60123    0.59986
alpha_3                               0.59836      0.00049    0.59914    0.59759
alpha_4                               0.60263      0.00051    0.60344    0.60183
alpha_5                               0.60299      0.00051    0.60379    0.60220
alpha_6                               0.60478      0.00055    0.60564    0.60392
alpha_7                               0.60801      0.00050    0.60879    0.60722
alpha_8                               0.60300      0.00051    0.60380    0.60220
alpha_9                               0.60793      0.00051    0.60874    0.60712
Alpha_loss                            -2.98246     0.01903    -2.95948   -3.00781
Training/policy_loss                  -33.48559    0.09218    -33.34850  -33.65168
Training/qf1_loss                     338.77323    219.07683  889.07422  185.03017
Training/qf2_loss                     360.78865    223.94429  920.73846  205.57559
Training/pf_norm                      0.31313      0.04802    0.38997    0.23025
Training/qf1_norm                     200.64083    80.46945   358.26566  32.50756
Training/qf2_norm                     256.60456    84.24739   408.16571  66.69503
log_std/mean                          -0.24926     0.00113    -0.24730   -0.25099
log_std/std                           0.10402      0.00079    0.10512    0.10311
log_std/max                           -0.12813     0.00341    -0.12233   -0.13221
log_std/min                           -0.57474     0.00739    -0.56651   -0.59289
log_probs/mean                        -1.95894     0.04028    -1.89781   -2.02665
log_probs/std                         1.13474      0.01518    1.16893    1.11246
log_probs/max                         1.09004      0.11343    1.27450    0.85123
log_probs/min                         -6.57104     0.48445    -5.65771   -7.29351
mean/mean                             -0.23100     0.00104    -0.22902   -0.23241
mean/std                              0.45698      0.00028    0.45734    0.45647
mean/max                              0.86788      0.01168    0.89284    0.85216
mean/min                              -1.60137     0.02044    -1.57830   -1.64815
------------------------------------  -----------  ---------  ---------  ---------
sample: [5, 4, 7, 1, 3, 8, 9, 2, 6, 0]
replay_buffer._size: [26400 26400 26400 26400 26400 26400 26400 26400 26400 26400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.325213670730591 0.0019979476928710938
train_time 3.3292734622955322
2023-09-06 14:04:17,699 MainThread INFO: EPOCH:174
2023-09-06 14:04:17,699 MainThread INFO: Time Consumed:3.34222412109375s
2023-09-06 14:04:17,699 MainThread INFO: Total Frames:262500s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 175/400 [10:57<22:57,  6.12s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               703.05158
Train_Epoch_Reward                    7681.31812
Running_Training_Average_Rewards      1236.09880
Explore_Time                          0.00391
Train___Time                          3.32927
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.24176
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.07260
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.80264
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.04128
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.50934
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.04757
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.74067
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5936.21589
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.06481
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.96700
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.39120     0.84331    6.78648     4.20856
alpha_0                               0.63952     0.00056    0.64039     0.63865
alpha_1                               0.59679     0.00050    0.59757     0.59601
alpha_2                               0.59903     0.00044    0.59971     0.59835
alpha_3                               0.59665     0.00049    0.59742     0.59588
alpha_4                               0.60085     0.00051    0.60165     0.60005
alpha_5                               0.60123     0.00050    0.60202     0.60045
alpha_6                               0.60287     0.00055    0.60373     0.60201
alpha_7                               0.60625     0.00050    0.60704     0.60547
alpha_8                               0.60122     0.00051    0.60202     0.60042
alpha_9                               0.60614     0.00051    0.60694     0.60534
Alpha_loss                            -2.99746    0.01371    -2.97212    -3.01455
Training/policy_loss                  -33.77478   0.09960    -33.62566   -33.90171
Training/qf1_loss                     453.17629   395.81473  1290.01086  150.36060
Training/qf2_loss                     477.52944   406.63821  1338.67822  160.46310
Training/pf_norm                      0.28339     0.03733    0.37860     0.24328
Training/qf1_norm                     223.59717   140.78320  487.26160   37.86405
Training/qf2_norm                     278.73612   142.77716  539.16077   85.38434
log_std/mean                          -0.25078    0.00041    -0.25023    -0.25165
log_std/std                           0.10236     0.00034    0.10303     0.10186
log_std/max                           -0.12982    0.00058    -0.12913    -0.13107
log_std/min                           -0.56642    0.00732    -0.55590    -0.57905
log_probs/mean                        -1.95529    0.02730    -1.90486    -2.00024
log_probs/std                         1.13132     0.02675    1.15664     1.07671
log_probs/max                         1.10714     0.10425    1.32150     0.95303
log_probs/min                         -6.76656    0.67168    -5.82630    -8.05136
mean/mean                             -0.23415    0.00120    -0.23272    -0.23626
mean/std                              0.45593     0.00026    0.45633     0.45562
mean/max                              0.89730     0.00892    0.90966     0.88148
mean/min                              -1.57068    0.01872    -1.54329    -1.59799
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 5, 7, 0, 1, 3, 2, 8, 9, 4]
replay_buffer._size: [26550 26550 26550 26550 26550 26550 26550 26550 26550 26550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.877847194671631 0.002309560775756836
train_time 5.881448268890381
2023-09-06 14:04:23,697 MainThread INFO: EPOCH:175
2023-09-06 14:04:23,697 MainThread INFO: Time Consumed:5.892400503158569s
2023-09-06 14:04:23,698 MainThread INFO: Total Frames:264000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 176/400 [11:03<22:44,  6.09s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               522.45405
Train_Epoch_Reward                    9253.14337
Running_Training_Average_Rewards      1078.55773
Explore_Time                          0.00309
Train___Time                          5.88145
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.18652
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.42649
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -46.18841
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.80983
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.61850
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.17000
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.73072
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4263.85632
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.16917
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.15380
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.99054     0.37472   5.47739    4.10240
alpha_0                               0.63758     0.00055   0.63845    0.63671
alpha_1                               0.59507     0.00049   0.59584    0.59429
alpha_2                               0.59752     0.00043   0.59819    0.59684
alpha_3                               0.59493     0.00049   0.59570    0.59417
alpha_4                               0.59907     0.00051   0.59987    0.59827
alpha_5                               0.59950     0.00049   0.60028    0.59873
alpha_6                               0.60097     0.00054   0.60182    0.60012
alpha_7                               0.60450     0.00050   0.60529    0.60371
alpha_8                               0.59945     0.00051   0.60024    0.59865
alpha_9                               0.60436     0.00051   0.60516    0.60355
Alpha_loss                            -3.00600    0.01470   -2.98236   -3.03274
Training/policy_loss                  -34.08914   0.10731   -33.87331  -34.20665
Training/qf1_loss                     204.74448   32.05673  258.07800  158.81467
Training/qf2_loss                     222.91808   33.22862  274.64813  176.36543
Training/pf_norm                      0.27562     0.03850   0.35998    0.22739
Training/qf1_norm                     150.28077   53.36119  224.78969  38.05965
Training/qf2_norm                     204.77751   60.56090  284.82153  65.19917
log_std/mean                          -0.25124    0.00076   -0.24947   -0.25192
log_std/std                           0.10473     0.00084   0.10555    0.10302
log_std/max                           -0.12570    0.00227   -0.12272   -0.12986
log_std/min                           -0.57611    0.00736   -0.56174   -0.58887
log_probs/mean                        -1.93764    0.02972   -1.90410   -1.98965
log_probs/std                         1.12997     0.02098   1.16477    1.09324
log_probs/max                         1.15652     0.13044   1.38417    0.88133
log_probs/min                         -6.66581    0.70453   -5.65321   -7.85469
mean/mean                             -0.23860    0.00119   -0.23671   -0.24023
mean/std                              0.45604     0.00029   0.45646    0.45564
mean/max                              0.91495     0.00514   0.92386    0.90627
mean/min                              -1.58097    0.01853   -1.55006   -1.60923
------------------------------------  ----------  --------  ---------  ---------
sample: [8, 9, 3, 5, 7, 2, 1, 6, 0, 4]
replay_buffer._size: [26700 26700 26700 26700 26700 26700 26700 26700 26700 26700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.021833419799805 0.00196075439453125
train_time 6.025029182434082
2023-09-06 14:04:29,868 MainThread INFO: EPOCH:176
2023-09-06 14:04:29,868 MainThread INFO: Time Consumed:6.035428047180176s
2023-09-06 14:04:29,869 MainThread INFO: Total Frames:265500s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 177/400 [11:09<22:42,  6.11s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               383.88832
Train_Epoch_Reward                    3989.70946
Running_Training_Average_Rewards      697.47236
Explore_Time                          0.00274
Train___Time                          6.02503
Eval____Time                          0.00297
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.27714
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.78190
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.46651
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.39024
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.30091
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.44877
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.36186
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2882.20509
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.96634
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.69292
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.20259     0.48098    6.10960    4.52223
alpha_0                               0.63566     0.00055    0.63652    0.63480
alpha_1                               0.59335     0.00049    0.59412    0.59257
alpha_2                               0.59601     0.00043    0.59669    0.59533
alpha_3                               0.59322     0.00049    0.59399    0.59245
alpha_4                               0.59729     0.00051    0.59809    0.59649
alpha_5                               0.59779     0.00049    0.59856    0.59703
alpha_6                               0.59909     0.00054    0.59993    0.59824
alpha_7                               0.60276     0.00050    0.60354    0.60197
alpha_8                               0.59768     0.00051    0.59847    0.59689
alpha_9                               0.60256     0.00052    0.60337    0.60175
Alpha_loss                            -3.03315    0.01533    -3.00878   -3.05192
Training/policy_loss                  -34.29275   0.10071    -34.15535  -34.42294
Training/qf1_loss                     386.77843   244.83797  897.40515  147.88942
Training/qf2_loss                     408.02122   251.12617  930.92432  161.24460
Training/pf_norm                      0.30773     0.04935    0.42080    0.25287
Training/qf1_norm                     182.84110   84.57801   351.98834  75.31995
Training/qf2_norm                     237.50826   82.88630   398.40323  127.03083
log_std/mean                          -0.24794    0.00064    -0.24704   -0.24901
log_std/std                           0.10531     0.00040    0.10617    0.10488
log_std/max                           -0.12146    0.00104    -0.12023   -0.12369
log_std/min                           -0.57346    0.00464    -0.56790   -0.58414
log_probs/mean                        -1.95571    0.03406    -1.90563   -2.00619
log_probs/std                         1.15997     0.01646    1.19483    1.12793
log_probs/max                         1.09760     0.07115    1.26422    0.99264
log_probs/min                         -6.96524    0.61848    -6.06472   -8.23200
mean/mean                             -0.24348    0.00193    -0.24054   -0.24656
mean/std                              0.45695     0.00089    0.45836    0.45586
mean/max                              0.92490     0.00537    0.93415    0.91814
mean/min                              -1.59665    0.00834    -1.58390   -1.61416
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 7, 9, 6, 0, 1, 8, 3, 2, 5]
replay_buffer._size: [26850 26850 26850 26850 26850 26850 26850 26850 26850 26850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.416597604751587 0.0020341873168945312
train_time 6.419817924499512
2023-09-06 14:04:36,408 MainThread INFO: EPOCH:177
2023-09-06 14:04:36,408 MainThread INFO: Time Consumed:6.428971767425537s
2023-09-06 14:04:36,408 MainThread INFO: Total Frames:267000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 178/400 [11:16<23:05,  6.24s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               266.17673
Train_Epoch_Reward                    2554.15132
Running_Training_Average_Rewards      526.56681
Explore_Time                          0.00265
Train___Time                          6.41982
Eval____Time                          0.00271
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.85856
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.15089
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.81903
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.37851
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.31349
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.51131
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.20998
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2429.45457
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.35720
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.47508
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           5.00230     0.32873   5.69952    4.56822
alpha_0                               0.63376     0.00054   0.63461    0.63291
alpha_1                               0.59163     0.00049   0.59240    0.59086
alpha_2                               0.59451     0.00043   0.59518    0.59384
alpha_3                               0.59151     0.00049   0.59228    0.59074
alpha_4                               0.59552     0.00051   0.59631    0.59473
alpha_5                               0.59609     0.00049   0.59686    0.59533
alpha_6                               0.59721     0.00054   0.59806    0.59637
alpha_7                               0.60101     0.00050   0.60180    0.60022
alpha_8                               0.59593     0.00051   0.59672    0.59513
alpha_9                               0.60076     0.00052   0.60157    0.59995
Alpha_loss                            -3.03415    0.01327   -3.01598   -3.06034
Training/policy_loss                  -34.62521   0.10159   -34.45589  -34.78020
Training/qf1_loss                     226.56826   67.33244  356.62933  133.29053
Training/qf2_loss                     243.69565   69.27042  370.77881  148.74629
Training/pf_norm                      0.28733     0.03818   0.33765    0.22826
Training/qf1_norm                     140.68434   56.50654  262.02072  65.77934
Training/qf2_norm                     200.63354   57.43934  330.60428  129.01666
log_std/mean                          -0.25109    0.00097   -0.24927   -0.25210
log_std/std                           0.10557     0.00087   0.10641    0.10400
log_std/max                           -0.12344    0.00250   -0.11999   -0.12783
log_std/min                           -0.58059    0.00556   -0.57337   -0.59301
log_probs/mean                        -1.92426    0.02800   -1.89155   -1.99060
log_probs/std                         1.16798     0.02429   1.20681    1.11682
log_probs/max                         1.16952     0.13273   1.38921    0.93980
log_probs/min                         -6.78199    0.89772   -5.76764   -9.07427
mean/mean                             -0.24751    0.00059   -0.24642   -0.24833
mean/std                              0.45859     0.00044   0.45911    0.45784
mean/max                              0.94717     0.00532   0.95910    0.94049
mean/min                              -1.57339    0.02311   -1.54062   -1.62996
------------------------------------  ----------  --------  ---------  ---------
sample: [7, 5, 0, 3, 4, 1, 2, 6, 8, 9]
replay_buffer._size: [27000 27000 27000 27000 27000 27000 27000 27000 27000 27000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.250439882278442 0.002012968063354492
train_time 6.253659248352051
2023-09-06 14:04:42,794 MainThread INFO: EPOCH:178
2023-09-06 14:04:42,795 MainThread INFO: Time Consumed:6.263628721237183s
2023-09-06 14:04:42,795 MainThread INFO: Total Frames:268500s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 179/400 [11:22<23:07,  6.28s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               186.96087
Train_Epoch_Reward                    978.43002
Running_Training_Average_Rewards      250.74303
Explore_Time                          0.00303
Train___Time                          6.25366
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.02482
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.84588
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.80929
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.44752
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.51277
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.67414
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.54528
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1907.50603
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.87297
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.84614
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.10259     0.41474    5.57655    4.29610
alpha_0                               0.63188     0.00054    0.63273    0.63103
alpha_1                               0.58992     0.00049    0.59069    0.58916
alpha_2                               0.59302     0.00043    0.59369    0.59235
alpha_3                               0.58980     0.00049    0.59057    0.58903
alpha_4                               0.59376     0.00051    0.59455    0.59297
alpha_5                               0.59441     0.00048    0.59516    0.59366
alpha_6                               0.59535     0.00053    0.59619    0.59451
alpha_7                               0.59926     0.00050    0.60005    0.59848
alpha_8                               0.59416     0.00051    0.59496    0.59337
alpha_9                               0.59898     0.00051    0.59978    0.59818
Alpha_loss                            -3.05156    0.01504    -3.02932   -3.07948
Training/policy_loss                  -34.94071   0.08897    -34.82259  -35.13695
Training/qf1_loss                     372.33809   196.09839  720.68408  176.30952
Training/qf2_loss                     391.30559   200.17188  744.96094  190.50784
Training/pf_norm                      0.29637     0.03788    0.37169    0.24255
Training/qf1_norm                     157.62080   67.68445   246.25508  36.49664
Training/qf2_norm                     215.05205   70.44646   306.02481  86.30554
log_std/mean                          -0.25382    0.00068    -0.25250   -0.25457
log_std/std                           0.10261     0.00058    0.10357    0.10160
log_std/max                           -0.13292    0.00195    -0.12941   -0.13564
log_std/min                           -0.58320    0.00647    -0.57245   -0.59451
log_probs/mean                        -1.92444    0.02980    -1.87579   -1.98436
log_probs/std                         1.15868     0.02919    1.19927    1.10563
log_probs/max                         1.09767     0.07990    1.20005    0.94359
log_probs/min                         -6.68046    0.84009    -5.86849   -8.82911
mean/mean                             -0.24414    0.00099    -0.24249   -0.24602
mean/std                              0.45791     0.00038    0.45843    0.45735
mean/max                              0.95547     0.00517    0.96671    0.94954
mean/min                              -1.55397    0.01735    -1.53483   -1.59014
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 9, 3, 2, 5, 0, 8, 4, 1, 7]
replay_buffer._size: [27150 27150 27150 27150 27150 27150 27150 27150 27150 27150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.083866834640503 0.0022857189178466797
train_time 6.087603807449341
2023-09-06 14:04:49,004 MainThread INFO: EPOCH:179
2023-09-06 14:04:49,005 MainThread INFO: Time Consumed:6.0997467041015625s
2023-09-06 14:04:49,005 MainThread INFO: Total Frames:270000s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 180/400 [11:28<22:57,  6.26s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               143.18613
Train_Epoch_Reward                    4037.38240
Running_Training_Average_Rewards      252.33212
Explore_Time                          0.00358
Train___Time                          6.08760
Eval____Time                          0.00381
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.32184
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.96500
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.20962
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.71250
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.84414
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.64074
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.13008
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1575.34422
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.66822
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.57594
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.11857     0.57727    6.36885     4.47940
alpha_0                               0.62999     0.00054    0.63084     0.62915
alpha_1                               0.58822     0.00049    0.58899     0.58746
alpha_2                               0.59153     0.00043    0.59220     0.59085
alpha_3                               0.58809     0.00049    0.58885     0.58732
alpha_4                               0.59200     0.00050    0.59279     0.59121
alpha_5                               0.59274     0.00048    0.59349     0.59200
alpha_6                               0.59350     0.00053    0.59433     0.59266
alpha_7                               0.59752     0.00050    0.59830     0.59674
alpha_8                               0.59240     0.00051    0.59319     0.59161
alpha_9                               0.59721     0.00051    0.59801     0.59642
Alpha_loss                            -3.07668    0.01527    -3.05058    -3.10140
Training/policy_loss                  -35.25275   0.12788    -35.04142   -35.42686
Training/qf1_loss                     430.54105   321.21244  1205.52612  182.51755
Training/qf2_loss                     450.56627   330.17661  1249.90735  191.72385
Training/pf_norm                      0.31073     0.04744    0.41048     0.24328
Training/qf1_norm                     162.16658   107.54167  393.00089   45.74942
Training/qf2_norm                     220.64922   104.39851  442.36487   105.69937
log_std/mean                          -0.25362    0.00106    -0.25230    -0.25494
log_std/std                           0.10180     0.00044    0.10274     0.10129
log_std/max                           -0.12774    0.00257    -0.12470    -0.13182
log_std/min                           -0.58252    0.00488    -0.57520    -0.58987
log_probs/mean                        -1.93958    0.02474    -1.89825    -1.97163
log_probs/std                         1.15634     0.02851    1.18455     1.08869
log_probs/max                         1.12698     0.11298    1.28443     0.93727
log_probs/min                         -6.91354    0.64432    -6.26187    -8.70061
mean/mean                             -0.24130    0.00071    -0.24017    -0.24209
mean/std                              0.45891     0.00079    0.46025     0.45765
mean/max                              0.96998     0.00569    0.97815     0.95878
mean/min                              -1.52033    0.01526    -1.50090    -1.54579
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 2, 7, 9, 8, 6, 5, 0, 1, 3]
replay_buffer._size: [27300 27300 27300 27300 27300 27300 27300 27300 27300 27300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.5778844356536865 0.0023641586303710938
train_time 6.5817320346832275
2023-09-06 14:04:55,737 MainThread INFO: EPOCH:180
2023-09-06 14:04:55,738 MainThread INFO: Time Consumed:6.618831157684326s
2023-09-06 14:04:55,738 MainThread INFO: Total Frames:271500s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 181/400 [11:35<23:23,  6.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               107.71206
Train_Epoch_Reward                    2257.75314
Running_Training_Average_Rewards      242.45219
Explore_Time                          0.00530
Train___Time                          6.58173
Eval____Time                          0.02597
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.12753
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.54684
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.48512
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.28345
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.70516
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.81423
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.88872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1378.98800
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.97228
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.00631
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.06951     0.55506    5.86999    4.26749
alpha_0                               0.62812     0.00054    0.62896    0.62727
alpha_1                               0.58653     0.00049    0.58729    0.58577
alpha_2                               0.59003     0.00043    0.59070    0.58937
alpha_3                               0.58638     0.00049    0.58715    0.58561
alpha_4                               0.59025     0.00050    0.59104    0.58946
alpha_5                               0.59109     0.00047    0.59183    0.59036
alpha_6                               0.59165     0.00053    0.59248    0.59082
alpha_7                               0.59578     0.00050    0.59656    0.59499
alpha_8                               0.59064     0.00051    0.59143    0.58985
alpha_9                               0.59545     0.00051    0.59624    0.59465
Alpha_loss                            -3.07943    0.01043    -3.06025   -3.09823
Training/policy_loss                  -35.49779   0.11295    -35.26615  -35.63885
Training/qf1_loss                     311.06714   209.64440  864.36243  160.52187
Training/qf2_loss                     327.61291   213.62192  884.92499  170.82709
Training/pf_norm                      0.31416     0.02472    0.36046    0.28226
Training/qf1_norm                     149.35190   88.63899   278.64822  33.31134
Training/qf2_norm                     203.68268   94.82346   345.83353  64.11031
log_std/mean                          -0.25385    0.00065    -0.25236   -0.25445
log_std/std                           0.10516     0.00111    0.10696    0.10322
log_std/max                           -0.12109    0.00245    -0.11718   -0.12431
log_std/min                           -0.59710    0.00756    -0.58778   -0.61501
log_probs/mean                        -1.91295    0.01709    -1.89266   -1.94431
log_probs/std                         1.16716     0.02654    1.20493    1.13581
log_probs/max                         1.27977     0.13419    1.43760    1.02391
log_probs/min                         -7.05843    0.93236    -6.02189   -9.13730
mean/mean                             -0.23978    0.00036    -0.23911   -0.24036
mean/std                              0.46336     0.00169    0.46583    0.46061
mean/max                              0.98072     0.00802    0.99402    0.96975
mean/min                              -1.51804    0.01391    -1.50117   -1.54978
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 5, 2, 4, 6, 8, 0, 3, 9, 1]
replay_buffer._size: [27450 27450 27450 27450 27450 27450 27450 27450 27450 27450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.611950397491455 0.0018868446350097656
train_time 3.615074872970581
2023-09-06 14:05:02,650 MainThread INFO: EPOCH:181
2023-09-06 14:05:02,651 MainThread INFO: Time Consumed:3.631096363067627s
2023-09-06 14:05:02,652 MainThread INFO: Total Frames:273000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 182/400 [11:42<23:52,  6.57s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               80.09411
Train_Epoch_Reward                    2482.73247
Running_Training_Average_Rewards      292.59560
Explore_Time                          0.00438
Train___Time                          3.61507
Eval____Time                          0.00553
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.60860
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.12375
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.79346
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.71957
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.09204
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.70341
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.27228
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1084.71514
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.72378
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.28956
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.17984     0.56898    6.31868    4.16586
alpha_0                               0.62623     0.00054    0.62708    0.62538
alpha_1                               0.58484     0.00048    0.58560    0.58409
alpha_2                               0.58856     0.00042    0.58922    0.58789
alpha_3                               0.58467     0.00049    0.58544    0.58390
alpha_4                               0.58851     0.00050    0.58929    0.58773
alpha_5                               0.58946     0.00047    0.59019    0.58872
alpha_6                               0.58981     0.00053    0.59064    0.58899
alpha_7                               0.59404     0.00050    0.59482    0.59326
alpha_8                               0.58888     0.00051    0.58967    0.58808
alpha_9                               0.59369     0.00050    0.59448    0.59290
Alpha_loss                            -3.09411    0.01141    -3.06830   -3.10371
Training/policy_loss                  -35.77650   0.13225    -35.54815  -36.03410
Training/qf1_loss                     331.57157   188.33199  774.73828  166.19223
Training/qf2_loss                     351.22534   193.99175  805.33411  173.76910
Training/pf_norm                      0.34378     0.05168    0.42369    0.23447
Training/qf1_norm                     165.99793   86.24254   325.00711  28.45736
Training/qf2_norm                     215.21411   88.24479   375.00287  58.90549
log_std/mean                          -0.25807    0.00218    -0.25479   -0.26165
log_std/std                           0.10986     0.00139    0.11188    0.10751
log_std/max                           -0.11399    0.00202    -0.11084   -0.11707
log_std/min                           -0.62137    0.01134    -0.60502   -0.64542
log_probs/mean                        -1.90744    0.02824    -1.85179   -1.94132
log_probs/std                         1.18292     0.02375    1.21463    1.14120
log_probs/max                         1.29963     0.11123    1.54345    1.16744
log_probs/min                         -6.85751    0.88808    -5.61218   -8.47606
mean/mean                             -0.24022    0.00100    -0.23889   -0.24234
mean/std                              0.47016     0.00247    0.47396    0.46605
mean/max                              0.99069     0.00673    0.99799    0.97648
mean/min                              -1.52342    0.01772    -1.50114   -1.56475
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 9, 1, 4, 3, 7, 0, 5, 8, 2]
replay_buffer._size: [27600 27600 27600 27600 27600 27600 27600 27600 27600 27600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.429168224334717 0.003299236297607422
train_time 3.4350671768188477
2023-09-06 14:05:09,205 MainThread INFO: EPOCH:182
2023-09-06 14:05:09,206 MainThread INFO: Time Consumed:3.4542922973632812s
2023-09-06 14:05:09,207 MainThread INFO: Total Frames:274500s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 183/400 [11:48<23:42,  6.56s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               56.44633
Train_Epoch_Reward                    2309.05991
Running_Training_Average_Rewards      234.98485
Explore_Time                          0.00435
Train___Time                          3.43507
Eval____Time                          0.00635
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.50619
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.28284
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.60379
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.74528
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.28870
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.39813
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.86822
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 876.50459
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.51912
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.44955
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.26032     0.63657    6.50314    4.27554
alpha_0                               0.62436     0.00053    0.62520    0.62353
alpha_1                               0.58318     0.00047    0.58392    0.58244
alpha_2                               0.58708     0.00042    0.58775    0.58642
alpha_3                               0.58296     0.00049    0.58373    0.58219
alpha_4                               0.58677     0.00050    0.58755    0.58600
alpha_5                               0.58783     0.00046    0.58856    0.58711
alpha_6                               0.58799     0.00052    0.58881    0.58718
alpha_7                               0.59232     0.00049    0.59309    0.59156
alpha_8                               0.58711     0.00051    0.58791    0.58631
alpha_9                               0.59194     0.00050    0.59273    0.59116
Alpha_loss                            -3.08481    0.01321    -3.06190   -3.10700
Training/policy_loss                  -36.11200   0.10267    -35.89980  -36.23283
Training/qf1_loss                     384.73576   220.03432  812.28210  144.77815
Training/qf2_loss                     403.52827   226.52946  842.03601  152.24123
Training/pf_norm                      0.34654     0.05765    0.44032    0.26851
Training/qf1_norm                     187.06146   109.76657  404.73920  23.03074
Training/qf2_norm                     234.91667   113.56594  463.92459  62.70851
log_std/mean                          -0.26478    0.00118    -0.26242   -0.26644
log_std/std                           0.11179     0.00032    0.11218    0.11117
log_std/max                           -0.10913    0.00106    -0.10738   -0.11051
log_std/min                           -0.63313    0.00589    -0.62541   -0.64654
log_probs/mean                        -1.85637    0.02590    -1.80095   -1.88874
log_probs/std                         1.19379     0.03344    1.24626    1.14559
log_probs/max                         1.53230     0.18681    1.97993    1.35134
log_probs/min                         -6.91628    0.70133    -5.97610   -8.44964
mean/mean                             -0.24495    0.00136    -0.24290   -0.24761
mean/std                              0.47733     0.00166    0.47963    0.47421
mean/max                              1.01567     0.00883    1.02963    1.00085
mean/min                              -1.50646    0.01373    -1.48363   -1.53552
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 9, 5, 3, 2, 7, 0, 4, 1, 8]
replay_buffer._size: [27750 27750 27750 27750 27750 27750 27750 27750 27750 27750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.123319864273071 0.0021011829376220703
train_time 6.126667737960815
2023-09-06 14:05:16,052 MainThread INFO: EPOCH:183
2023-09-06 14:05:16,053 MainThread INFO: Time Consumed:6.708248853683472s
2023-09-06 14:05:16,053 MainThread INFO: Total Frames:276000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 184/400 [11:55<23:55,  6.64s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               36.02129
Train_Epoch_Reward                    458.40971
Running_Training_Average_Rewards      175.00674
Explore_Time                          0.57358
Train___Time                          6.12667
Eval____Time                          0.00394
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.81933
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.56496
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.54204
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.34128
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.52028
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.19667
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.70504
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 772.46017
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.81664
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.54662
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           5.00358    0.38572   5.69376    4.24949
alpha_0                               0.62253    0.00052   0.62335    0.62172
alpha_1                               0.58153    0.00047   0.58227    0.58080
alpha_2                               0.58560    0.00043   0.58627    0.58494
alpha_3                               0.58125    0.00049   0.58202    0.58049
alpha_4                               0.58505    0.00050   0.58582    0.58427
alpha_5                               0.58624    0.00045   0.58695    0.58553
alpha_6                               0.58619    0.00051   0.58700    0.58539
alpha_7                               0.59061    0.00049   0.59138    0.58984
alpha_8                               0.58534    0.00051   0.58614    0.58455
alpha_9                               0.59021    0.00050   0.59098    0.58943
Alpha_loss                            -3.09310   0.01607   -3.06748   -3.11961
Training/policy_loss                  -36.42059  0.12101   -36.17493  -36.55940
Training/qf1_loss                     276.93479  97.03626  531.71716  191.09801
Training/qf2_loss                     291.99505  99.62501  552.50000  200.01895
Training/pf_norm                      0.31953    0.06043   0.42420    0.23206
Training/qf1_norm                     141.37524  62.35147  264.17181  42.57101
Training/qf2_norm                     184.12836  72.34152  312.76465  39.51756
log_std/mean                          -0.26530   0.00100   -0.26379   -0.26652
log_std/std                           0.10910    0.00132   0.11090    0.10697
log_std/max                           -0.10733   0.00070   -0.10601   -0.10835
log_std/min                           -0.62349   0.01052   -0.60776   -0.64347
log_probs/mean                        -1.83909   0.02818   -1.79856   -1.88520
log_probs/std                         1.20881    0.01232   1.23249    1.18854
log_probs/max                         1.80097    0.18901   2.12981    1.55430
log_probs/min                         -6.75061   0.70250   -6.11800   -8.66228
mean/mean                             -0.25003   0.00070   -0.24821   -0.25059
mean/std                              0.48192    0.00110   0.48352    0.47977
mean/max                              1.02248    0.00369   1.02750    1.01574
mean/min                              -1.48566   0.02070   -1.46125   -1.52583
------------------------------------  ---------  --------  ---------  ---------
sample: [4, 6, 2, 7, 0, 3, 8, 1, 9, 5]
replay_buffer._size: [27900 27900 27900 27900 27900 27900 27900 27900 27900 27900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.5131208896636963 0.002107858657836914
train_time 3.5164411067962646
2023-09-06 14:05:22,590 MainThread INFO: EPOCH:184
2023-09-06 14:05:22,590 MainThread INFO: Time Consumed:3.8509531021118164s
2023-09-06 14:05:22,591 MainThread INFO: Total Frames:277500s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 185/400 [12:02<23:39,  6.60s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               22.70215
Train_Epoch_Reward                    163.91962
Running_Training_Average_Rewards      97.71297
Explore_Time                          0.32394
Train___Time                          3.51644
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.84274
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.98648
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.42494
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.30051
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.12391
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.36495
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.94614
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 693.21328
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.19204
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.21710
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           4.56739    0.55580   5.71457    3.93240
alpha_0                               0.62074    0.00051   0.62154    0.61994
alpha_1                               0.57990    0.00047   0.58064    0.57917
alpha_2                               0.58412    0.00043   0.58479    0.58345
alpha_3                               0.57955    0.00049   0.58032    0.57878
alpha_4                               0.58332    0.00050   0.58410    0.58254
alpha_5                               0.58467    0.00045   0.58538    0.58397
alpha_6                               0.58441    0.00051   0.58521    0.58362
alpha_7                               0.58890    0.00049   0.58967    0.58812
alpha_8                               0.58358    0.00051   0.58437    0.58279
alpha_9                               0.58849    0.00049   0.58926    0.58772
Alpha_loss                            -3.10634   0.01601   -3.08221   -3.13433
Training/policy_loss                  -36.58686  0.03634   -36.55241  -36.65800
Training/qf1_loss                     224.74298  91.31530  465.48248  147.79091
Training/qf2_loss                     234.36903  94.01020  477.98233  157.46619
Training/pf_norm                      0.34502    0.03574   0.40642    0.29297
Training/qf1_norm                     83.58235   86.10839  279.03851  23.36518
Training/qf2_norm                     116.01749  94.35578  321.05435  34.98867
log_std/mean                          -0.26315   0.00051   -0.26240   -0.26402
log_std/std                           0.10524    0.00059   0.10642    0.10468
log_std/max                           -0.11119   0.00160   -0.10892   -0.11389
log_std/min                           -0.60565   0.00576   -0.59890   -0.62088
log_probs/mean                        -1.83152   0.03166   -1.78488   -1.88464
log_probs/std                         1.25226    0.02104   1.29550    1.21749
log_probs/max                         2.06741    0.17139   2.34574    1.82691
log_probs/min                         -7.78205   1.51768   -6.25987   -11.07736
mean/mean                             -0.24822   0.00104   -0.24694   -0.24999
mean/std                              0.48843    0.00310   0.49403    0.48457
mean/max                              1.04267    0.00929   1.05714    1.03075
mean/min                              -1.46001   0.01173   -1.44540   -1.48279
------------------------------------  ---------  --------  ---------  ---------
sample: [3, 0, 6, 9, 2, 7, 5, 8, 1, 4]
replay_buffer._size: [28050 28050 28050 28050 28050 28050 28050 28050 28050 28050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.7492451667785645 0.0019102096557617188
train_time 6.7524285316467285
2023-09-06 14:05:29,467 MainThread INFO: EPOCH:185
2023-09-06 14:05:29,468 MainThread INFO: Time Consumed:6.775524616241455s
2023-09-06 14:05:29,468 MainThread INFO: Total Frames:279000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 186/400 [12:09<23:52,  6.70s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               13.83109
Train_Epoch_Reward                    868.12351
Running_Training_Average_Rewards      49.68176
Explore_Time                          0.00250
Train___Time                          6.75243
Eval____Time                          0.01666
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.89266
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.14323
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.81960
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.51718
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.61449
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.30538
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.06162
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 622.34768
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.51739
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.76536
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           4.82056    0.37532   5.36056    4.02370
alpha_0                               0.61898    0.00050   0.61977    0.61820
alpha_1                               0.57828    0.00047   0.57901    0.57755
alpha_2                               0.58263    0.00042   0.58330    0.58197
alpha_3                               0.57785    0.00049   0.57861    0.57708
alpha_4                               0.58159    0.00050   0.58237    0.58082
alpha_5                               0.58312    0.00044   0.58382    0.58243
alpha_6                               0.58265    0.00050   0.58344    0.58186
alpha_7                               0.58717    0.00049   0.58795    0.58640
alpha_8                               0.58182    0.00051   0.58261    0.58103
alpha_9                               0.58678    0.00049   0.58755    0.58602
Alpha_loss                            -3.10265   0.02028   -3.07829   -3.14177
Training/policy_loss                  -36.71424  0.11173   -36.58274  -36.98037
Training/qf1_loss                     246.61478  87.53698  468.68829  182.43631
Training/qf2_loss                     257.44748  88.83387  481.39493  188.83968
Training/pf_norm                      0.43412    0.06319   0.58683    0.33721
Training/qf1_norm                     130.91305  54.95790  226.99741  41.95971
Training/qf2_norm                     165.00991  65.48332  263.53311  32.36673
log_std/mean                          -0.26785   0.00279   -0.26424   -0.27252
log_std/std                           0.10586    0.00063   0.10662    0.10479
log_std/max                           -0.11838   0.00236   -0.11455   -0.12213
log_std/min                           -0.61721   0.00849   -0.60575   -0.63415
log_probs/mean                        -1.79256   0.04339   -1.74415   -1.86832
log_probs/std                         1.27654    0.01817   1.29730    1.23838
log_probs/max                         2.33055    0.25035   2.84146    1.94407
log_probs/min                         -7.11057   0.76392   -5.94586   -8.38182
mean/mean                             -0.24896   0.00166   -0.24706   -0.25239
mean/std                              0.50343    0.00627   0.51380    0.49432
mean/max                              1.07393    0.00634   1.08323    1.06398
mean/min                              -1.42531   0.02617   -1.38307   -1.46419
------------------------------------  ---------  --------  ---------  ---------
sample: [9, 4, 3, 2, 8, 1, 6, 0, 5, 7]
replay_buffer._size: [28200 28200 28200 28200 28200 28200 28200 28200 28200 28200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.736673831939697 0.002037525177001953
train_time 4.739994287490845
2023-09-06 14:05:36,160 MainThread INFO: EPOCH:186
2023-09-06 14:05:36,161 MainThread INFO: Time Consumed:6.553203582763672s
2023-09-06 14:05:36,161 MainThread INFO: Total Frames:280500s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 187/400 [12:15<23:45,  6.69s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               6.17791
Train_Epoch_Reward                    380.91915
Running_Training_Average_Rewards      47.09874
Explore_Time                          1.80552
Train___Time                          4.73999
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.78265
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.81983
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.85587
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.54232
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.92696
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.31223
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.96690
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 559.36207
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.03098
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.31234
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           4.62633    0.27762   5.00022    4.11861
alpha_0                               0.61728    0.00047   0.61803    0.61655
alpha_1                               0.57667    0.00046   0.57739    0.57596
alpha_2                               0.58117    0.00042   0.58182    0.58051
alpha_3                               0.57615    0.00049   0.57691    0.57539
alpha_4                               0.57987    0.00050   0.58065    0.57909
alpha_5                               0.58160    0.00043   0.58228    0.58092
alpha_6                               0.58092    0.00049   0.58169    0.58014
alpha_7                               0.58546    0.00049   0.58623    0.58469
alpha_8                               0.58006    0.00051   0.58085    0.57927
alpha_9                               0.58509    0.00049   0.58585    0.58433
Alpha_loss                            -3.07713   0.01909   -3.04799   -3.11213
Training/policy_loss                  -37.04541  0.11443   -36.89106  -37.21006
Training/qf1_loss                     187.86361  29.58110  261.78180  153.49174
Training/qf2_loss                     193.33260  30.82124  268.27850  159.45683
Training/pf_norm                      0.38201    0.04481   0.49317    0.34413
Training/qf1_norm                     89.42808   43.20866  156.17986  24.78848
Training/qf2_norm                     123.50126  47.41707  191.52269  39.58529
log_std/mean                          -0.27795   0.00288   -0.27334   -0.28155
log_std/std                           0.10721    0.00040   0.10790    0.10663
log_std/max                           -0.12256   0.00112   -0.12059   -0.12406
log_std/min                           -0.62196   0.00444   -0.61517   -0.63153
log_probs/mean                        -1.71128   0.03890   -1.65301   -1.78186
log_probs/std                         1.35722    0.04475   1.41378    1.28935
log_probs/max                         2.84164    0.22734   3.26337    2.51373
log_probs/min                         -7.47925   0.84198   -6.43453   -8.88486
mean/mean                             -0.26154   0.00481   -0.25370   -0.26767
mean/std                              0.52332    0.00417   0.52802    0.51559
mean/max                              1.07994    0.00925   1.10227    1.06694
mean/min                              -1.37321   0.01448   -1.35305   -1.39575
------------------------------------  ---------  --------  ---------  ---------
sample: [9, 3, 0, 6, 5, 1, 8, 7, 4, 2]
replay_buffer._size: [28350 28350 28350 28350 28350 28350 28350 28350 28350 28350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.61238169670105 0.002835988998413086
train_time 3.616909980773926
2023-09-06 14:05:42,759 MainThread INFO: EPOCH:187
2023-09-06 14:05:42,760 MainThread INFO: Time Consumed:3.737431764602661s
2023-09-06 14:05:42,760 MainThread INFO: Total Frames:282000s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 188/400 [12:22<23:33,  6.67s/it]------------------------------------  ---------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -0.74995
Train_Epoch_Reward                    117.45591
Running_Training_Average_Rewards      45.54995
Explore_Time                          0.11022
Train___Time                          3.61691
Eval____Time                          0.00543
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.36641
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.88483
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.16989
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -34.28079
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.06062
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.63955
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.10246
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 501.22043
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.69560
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.04154
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std        Max        Min
Reward_Mean                           4.93082    0.67001    6.00210    3.90342
alpha_0                               0.61569    0.00044    0.61639    0.61500
alpha_1                               0.57509    0.00045    0.57580    0.57437
alpha_2                               0.57970    0.00043    0.58037    0.57903
alpha_3                               0.57446    0.00049    0.57522    0.57370
alpha_4                               0.57814    0.00050    0.57892    0.57737
alpha_5                               0.58011    0.00042    0.58077    0.57944
alpha_6                               0.57922    0.00048    0.57998    0.57846
alpha_7                               0.58376    0.00049    0.58452    0.58299
alpha_8                               0.57831    0.00050    0.57909    0.57752
alpha_9                               0.58341    0.00048    0.58416    0.58266
Alpha_loss                            -3.07989   0.02606    -3.02806   -3.13534
Training/policy_loss                  -37.33471  0.11815    -37.09978  -37.48018
Training/qf1_loss                     426.80469  231.34039  901.10754  154.05957
Training/qf2_loss                     436.92545  235.35164  917.04364  161.85262
Training/pf_norm                      0.38326    0.03708    0.42372    0.29382
Training/qf1_norm                     157.99940  110.75164  337.55984  20.06381
Training/qf2_norm                     183.66660  118.84487  375.86481  40.25794
log_std/mean                          -0.27828   0.00300    -0.27282   -0.28178
log_std/std                           0.10782    0.00019    0.10806    0.10746
log_std/max                           -0.11655   0.00405    -0.10879   -0.12254
log_std/min                           -0.61539   0.00724    -0.60575   -0.62589
log_probs/mean                        -1.68284   0.04290    -1.59691   -1.77696
log_probs/std                         1.39815    0.03408    1.44353    1.32614
log_probs/max                         3.37352    0.15571    3.57859    3.04517
log_probs/min                         -6.85154   0.54074    -6.13666   -7.88124
mean/mean                             -0.26138   0.00563    -0.25047   -0.26786
mean/std                              0.52596    0.00250    0.52880    0.52128
mean/max                              1.04336    0.01508    1.07498    1.02434
mean/min                              -1.37978   0.01524    -1.36172   -1.40804
------------------------------------  ---------  ---------  ---------  ---------
sample: [8, 7, 6, 4, 9, 2, 5, 3, 0, 1]
replay_buffer._size: [28500 28500 28500 28500 28500 28500 28500 28500 28500 28500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.434238910675049 0.0025196075439453125
train_time 3.4383702278137207
2023-09-06 14:05:49,546 MainThread INFO: EPOCH:188
2023-09-06 14:05:49,547 MainThread INFO: Time Consumed:3.4542415142059326s
2023-09-06 14:05:49,548 MainThread INFO: Total Frames:283500s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 189/400 [12:29<23:32,  6.70s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -6.17075
Train_Epoch_Reward                    11.93213
Running_Training_Average_Rewards      17.01024
Explore_Time                          0.00462
Train___Time                          3.43837
Eval____Time                          0.00505
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.62419
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.66467
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.59055
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.96766
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.86818
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.44048
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.76714
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 467.78308
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.30333
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.47016
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           4.88555    0.42831   5.56598    4.10666
alpha_0                               0.61418    0.00043   0.61485    0.61351
alpha_1                               0.57350    0.00045   0.57422    0.57279
alpha_2                               0.57820    0.00043   0.57888    0.57752
alpha_3                               0.57276    0.00049   0.57353    0.57200
alpha_4                               0.57642    0.00050   0.57719    0.57564
alpha_5                               0.57863    0.00042   0.57930    0.57797
alpha_6                               0.57754    0.00048   0.57830    0.57679
alpha_7                               0.58205    0.00049   0.58282    0.58128
alpha_8                               0.57656    0.00050   0.57735    0.57577
alpha_9                               0.58174    0.00048   0.58249    0.58097
Alpha_loss                            -3.14425   0.02958   -3.09057   -3.19470
Training/policy_loss                  -37.67741  0.08752   -37.54878  -37.84032
Training/qf1_loss                     250.26294  54.84163  378.57272  194.25378
Training/qf2_loss                     258.12597  54.76259  388.08438  202.33282
Training/pf_norm                      0.36637    0.02138   0.41735    0.33782
Training/qf1_norm                     141.52278  67.17598  243.49757  26.21399
Training/qf2_norm                     168.64063  73.45746  278.03583  38.20361
log_std/mean                          -0.26510   0.00416   -0.25905   -0.27171
log_std/std                           0.10596    0.00128   0.10745    0.10361
log_std/max                           -0.10710   0.00158   -0.10422   -0.10992
log_std/min                           -0.58644   0.00766   -0.57468   -0.59980
log_probs/mean                        -1.77195   0.04632   -1.68703   -1.85256
log_probs/std                         1.34892    0.03090   1.41619    1.29714
log_probs/max                         3.30318    0.22016   3.52801    2.83122
log_probs/min                         -7.02472   0.55010   -6.23542   -7.91718
mean/mean                             -0.22945   0.01154   -0.21156   -0.24752
mean/std                              0.51459    0.00362   0.52028    0.50914
mean/max                              1.00554    0.01095   1.03026    0.99168
mean/min                              -1.37189   0.01553   -1.35641   -1.40041
------------------------------------  ---------  --------  ---------  ---------
sample: [4, 0, 9, 3, 5, 1, 6, 7, 2, 8]
replay_buffer._size: [28650 28650 28650 28650 28650 28650 28650 28650 28650 28650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.911819934844971 0.0019915103912353516
train_time 6.9150307178497314
2023-09-06 14:05:56,588 MainThread INFO: EPOCH:189
2023-09-06 14:05:56,589 MainThread INFO: Time Consumed:6.927545785903931s
2023-09-06 14:05:56,589 MainThread INFO: Total Frames:285000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 190/400 [12:36<23:47,  6.80s/it]------------------------------------  ---------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -9.61084
Train_Epoch_Reward                    -63.89424
Running_Training_Average_Rewards      2.18313
Explore_Time                          0.00298
Train___Time                          6.91503
Eval____Time                          0.00550
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.33075
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.53080
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.29947
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.31928
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.89353
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.36900
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.27685
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 465.00702
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.81749
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.56047
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean       Std        Max        Min
Reward_Mean                           4.94938    0.69327    6.45691    4.07895
alpha_0                               0.61269    0.00043    0.61336    0.61202
alpha_1                               0.57192    0.00046    0.57263    0.57120
alpha_2                               0.57667    0.00044    0.57737    0.57597
alpha_3                               0.57106    0.00049    0.57183    0.57030
alpha_4                               0.57469    0.00050    0.57547    0.57391
alpha_5                               0.57714    0.00043    0.57782    0.57646
alpha_6                               0.57586    0.00048    0.57662    0.57511
alpha_7                               0.58033    0.00050    0.58111    0.57954
alpha_8                               0.57481    0.00051    0.57560    0.57401
alpha_9                               0.58003    0.00049    0.58080    0.57926
Alpha_loss                            -3.21134   0.02234    -3.17499   -3.24782
Training/policy_loss                  -37.87013  0.09442    -37.74610  -38.05186
Training/qf1_loss                     283.35316  191.69549  816.10876  128.01656
Training/qf2_loss                     290.16987  195.17001  832.24207  130.12802
Training/pf_norm                      0.36268    0.05398    0.49147    0.28087
Training/qf1_norm                     161.33754  124.15104  452.43201  24.12141
Training/qf2_norm                     185.68793  127.70337  471.83508  23.58397
log_std/mean                          -0.25630   0.00073    -0.25538   -0.25792
log_std/std                           0.10104    0.00103    0.10289    0.09977
log_std/max                           -0.11402   0.00307    -0.10868   -0.11752
log_std/min                           -0.56085   0.00544    -0.55140   -0.57130
log_probs/mean                        -1.86483   0.03492    -1.81275   -1.91809
log_probs/std                         1.33516    0.01674    1.36067    1.30620
log_probs/max                         3.04284    0.16774    3.36490    2.77814
log_probs/min                         -6.94355   0.65238    -5.95836   -8.02262
mean/mean                             -0.18884   0.01124    -0.17183   -0.20717
mean/std                              0.50571    0.00139    0.50814    0.50378
mean/max                              0.99712    0.00718    1.00948    0.98561
mean/min                              -1.34481   0.01600    -1.31701   -1.37466
------------------------------------  ---------  ---------  ---------  ---------
sample: [8, 7, 9, 6, 5, 3, 0, 4, 1, 2]
replay_buffer._size: [28800 28800 28800 28800 28800 28800 28800 28800 28800 28800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.729906797409058 0.002527475357055664
train_time 6.733987331390381
2023-09-06 14:06:03,440 MainThread INFO: EPOCH:190
2023-09-06 14:06:03,441 MainThread INFO: Time Consumed:6.748904705047607s
2023-09-06 14:06:03,441 MainThread INFO: Total Frames:286500s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 191/400 [12:43<23:43,  6.81s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -10.12172
Train_Epoch_Reward                    -54.90493
Running_Training_Average_Rewards      -3.56223
Explore_Time                          0.00531
Train___Time                          6.73399
Eval____Time                          0.00546
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.72583
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.06556
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.79079
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.39006
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.47265
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.51235
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.57986
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 470.42116
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.60850
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.62311
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           5.00666     0.50594    5.80327    4.40130
alpha_0                               0.61119     0.00044    0.61188    0.61051
alpha_1                               0.57032     0.00046    0.57104    0.56961
alpha_2                               0.57512     0.00045    0.57582    0.57441
alpha_3                               0.56936     0.00049    0.57013    0.56859
alpha_4                               0.57296     0.00050    0.57374    0.57218
alpha_5                               0.57562     0.00044    0.57631    0.57493
alpha_6                               0.57417     0.00049    0.57494    0.57341
alpha_7                               0.57857     0.00051    0.57937    0.57778
alpha_8                               0.57304     0.00051    0.57384    0.57225
alpha_9                               0.57830     0.00050    0.57908    0.57752
Alpha_loss                            -3.24552    0.01895    -3.20425   -3.26935
Training/policy_loss                  -38.15426   0.15789    -37.83607  -38.42433
Training/qf1_loss                     294.46469   186.52515  781.56512  139.90997
Training/qf2_loss                     301.82159   189.44354  793.15344  141.37085
Training/pf_norm                      0.35630     0.05052    0.47712    0.30691
Training/qf1_norm                     162.74360   98.55248   325.38834  36.41195
Training/qf2_norm                     189.39901   98.92135   348.73590  64.19241
log_std/mean                          -0.25927    0.00163    -0.25660   -0.26146
log_std/std                           0.09907     0.00045    0.09968    0.09846
log_std/max                           -0.11555    0.00070    -0.11459   -0.11657
log_std/min                           -0.55951    0.00457    -0.55313   -0.56903
log_probs/mean                        -1.89778    0.03566    -1.81069   -1.93519
log_probs/std                         1.29636     0.03626    1.36529    1.25475
log_probs/max                         3.08199     0.17004    3.40099    2.77063
log_probs/min                         -7.37366    0.73512    -6.02544   -8.54036
mean/mean                             -0.15730    0.00644    -0.14785   -0.16806
mean/std                              0.50361     0.00026    0.50406    0.50307
mean/max                              0.99766     0.00639    1.01056    0.98964
mean/min                              -1.30960    0.01655    -1.28658   -1.33785
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 3, 5, 1, 8, 7, 4, 2, 9, 0]
replay_buffer._size: [28950 28950 28950 28950 28950 28950 28950 28950 28950 28950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.759566307067871 0.0019648075103759766
train_time 6.762737989425659
2023-09-06 14:06:10,318 MainThread INFO: EPOCH:191
2023-09-06 14:06:10,319 MainThread INFO: Time Consumed:6.775675296783447s
2023-09-06 14:06:10,319 MainThread INFO: Total Frames:288000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 192/400 [12:49<23:42,  6.84s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -9.02964
Train_Epoch_Reward                    19.61293
Running_Training_Average_Rewards      -3.30621
Explore_Time                          0.00295
Train___Time                          6.76274
Eval____Time                          0.00475
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.12348
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.88573
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.64522
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.94999
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.18711
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.54179
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.46267
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 482.14317
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.13815
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.35994
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.77805     0.28289    5.49817    4.41896
alpha_0                               0.60967     0.00044    0.61036    0.60898
alpha_1                               0.56873     0.00046    0.56945    0.56802
alpha_2                               0.57354     0.00045    0.57425    0.57283
alpha_3                               0.56765     0.00049    0.56842    0.56688
alpha_4                               0.57123     0.00050    0.57201    0.57045
alpha_5                               0.57409     0.00044    0.57478    0.57339
alpha_6                               0.57248     0.00049    0.57324    0.57171
alpha_7                               0.57680     0.00051    0.57760    0.57600
alpha_8                               0.57128     0.00051    0.57207    0.57048
alpha_9                               0.57656     0.00050    0.57735    0.57578
Alpha_loss                            -3.27479    0.00949    -3.25894   -3.29234
Training/policy_loss                  -38.52400   0.12825    -38.32914  -38.72309
Training/qf1_loss                     292.01292   111.57777  488.24017  174.70467
Training/qf2_loss                     299.28137   113.77498  501.58197  179.61028
Training/pf_norm                      0.33496     0.03256    0.38809    0.27894
Training/qf1_norm                     108.79304   61.22461   266.52051  53.29905
Training/qf2_norm                     134.67418   59.09624   285.47388  76.17822
log_std/mean                          -0.26246    0.00042    -0.26156   -0.26290
log_std/std                           0.09853     0.00022    0.09888    0.09820
log_std/max                           -0.12078    0.00336    -0.11642   -0.12580
log_std/min                           -0.54770    0.00347    -0.54453   -0.55616
log_probs/mean                        -1.91947    0.02222    -1.88285   -1.96204
log_probs/std                         1.27062     0.02180    1.30230    1.22670
log_probs/max                         3.07362     0.15443    3.29595    2.77832
log_probs/min                         -7.23986    1.36598    -5.49948   -9.64455
mean/mean                             -0.13594    0.00623    -0.12643   -0.14550
mean/std                              0.50202     0.00040    0.50263    0.50145
mean/max                              0.99428     0.00637    1.00112    0.98394
mean/min                              -1.30347    0.01524    -1.27905   -1.33707
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 7, 2, 8, 3, 5, 6, 9, 0, 4]
replay_buffer._size: [29100 29100 29100 29100 29100 29100 29100 29100 29100 29100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.0309977531433105 0.0019421577453613281
train_time 7.03415322303772
2023-09-06 14:06:17,480 MainThread INFO: EPOCH:192
2023-09-06 14:06:17,481 MainThread INFO: Time Consumed:7.0431458950042725s
2023-09-06 14:06:17,481 MainThread INFO: Total Frames:289500s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 193/400 [13:11<39:17, 11.39s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -7.07245
Train_Epoch_Reward                    -5.85428
Running_Training_Average_Rewards      -1.37154
Explore_Time                          0.00314
Train___Time                          7.03415
Eval____Time                          0.00203
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.84732
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.87559
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.43096
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.21979
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.45161
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.85948
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.04293
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 497.35418
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.52121
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.78046
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.63130     0.28254    5.19022    4.22122
alpha_0                               0.60814     0.00044    0.60883    0.60745
alpha_1                               0.56715     0.00046    0.56786    0.56643
alpha_2                               0.57196     0.00045    0.57267    0.57125
alpha_3                               0.56594     0.00049    0.56671    0.56518
alpha_4                               0.56951     0.00049    0.57028    0.56874
alpha_5                               0.57253     0.00045    0.57323    0.57182
alpha_6                               0.57079     0.00048    0.57155    0.57003
alpha_7                               0.57501     0.00051    0.57582    0.57421
alpha_8                               0.56951     0.00051    0.57030    0.56871
alpha_9                               0.57483     0.00050    0.57561    0.57404
Alpha_loss                            -3.30222    0.02064    -3.27193   -3.34171
Training/policy_loss                  -38.84625   0.08957    -38.66773  -38.95409
Training/qf1_loss                     236.81255   147.61607  669.32690  162.46103
Training/qf2_loss                     242.23073   150.76670  682.99054  165.47847
Training/pf_norm                      0.39363     0.06102    0.50689    0.30164
Training/qf1_norm                     78.83066    52.62852   173.19774  23.17231
Training/qf2_norm                     105.61395   54.56159   202.48199  42.39635
log_std/mean                          -0.26226    0.00029    -0.26152   -0.26261
log_std/std                           0.09851     0.00023    0.09891    0.09806
log_std/max                           -0.12647    0.00092    -0.12540   -0.12828
log_std/min                           -0.54348    0.00451    -0.53663   -0.55288
log_probs/mean                        -1.93829    0.03585    -1.89562   -2.00811
log_probs/std                         1.25547     0.02364    1.29981    1.22519
log_probs/max                         3.02135     0.20697    3.30779    2.69228
log_probs/min                         -6.09033    0.52383    -5.41706   -6.99517
mean/mean                             -0.11190    0.00789    -0.09852   -0.12386
mean/std                              0.50118     0.00039    0.50167    0.50034
mean/max                              0.99064     0.00525    0.99794    0.98033
mean/min                              -1.31133    0.01996    -1.28607   -1.34298
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 3, 4, 8, 0, 6, 5, 2, 7, 1]
replay_buffer._size: [29250 29250 29250 29250 29250 29250 29250 29250 29250 29250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.6659469604492188 0.002366304397583008
train_time 3.669557571411133
2023-09-06 14:06:36,138 MainThread INFO: EPOCH:193
2023-09-06 14:06:36,138 MainThread INFO: Time Consumed:3.6798512935638428s
2023-09-06 14:06:36,139 MainThread INFO: Total Frames:291000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 194/400 [13:15<31:17,  9.11s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -4.96923
Train_Epoch_Reward                    276.84599
Running_Training_Average_Rewards      9.68682
Explore_Time                          0.00321
Train___Time                          3.66956
Eval____Time                          0.00263
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.35111
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.07206
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.02217
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.47701
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.79403
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.46922
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.45503
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 513.65715
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.33363
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.93370
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.81811     0.56103    5.58191    3.92054
alpha_0                               0.60659     0.00045    0.60729    0.60588
alpha_1                               0.56556     0.00045    0.56627    0.56485
alpha_2                               0.57037     0.00046    0.57109    0.56965
alpha_3                               0.56425     0.00049    0.56501    0.56348
alpha_4                               0.56779     0.00050    0.56856    0.56701
alpha_5                               0.57096     0.00045    0.57166    0.57025
alpha_6                               0.56911     0.00048    0.56986    0.56835
alpha_7                               0.57322     0.00052    0.57403    0.57241
alpha_8                               0.56775     0.00050    0.56854    0.56696
alpha_9                               0.57308     0.00050    0.57387    0.57229
Alpha_loss                            -3.34121    0.01198    -3.32871   -3.36866
Training/policy_loss                  -39.01964   0.08589    -38.89425  -39.15723
Training/qf1_loss                     282.30304   141.51579  565.99396  147.11731
Training/qf2_loss                     288.60420   144.43191  576.72131  149.55107
Training/pf_norm                      0.39320     0.04455    0.48256    0.33153
Training/qf1_norm                     140.66190   79.43440   261.95584  51.25722
Training/qf2_norm                     155.43560   90.93247   291.44806  49.01415
log_std/mean                          -0.25959    0.00096    -0.25805   -0.26091
log_std/std                           0.09802     0.00011    0.09818    0.09774
log_std/max                           -0.12430    0.00071    -0.12267   -0.12550
log_std/min                           -0.54072    0.00346    -0.53377   -0.54416
log_probs/mean                        -1.97936    0.01716    -1.95593   -2.01710
log_probs/std                         1.22044     0.02436    1.26063    1.18811
log_probs/max                         2.92991     0.28092    3.42540    2.54968
log_probs/min                         -6.50737    0.54094    -5.60742   -7.44406
mean/mean                             -0.07334    0.01427    -0.05018   -0.09462
mean/std                              0.49939     0.00051    0.50002    0.49846
mean/max                              1.00129     0.01108    1.01643    0.98410
mean/min                              -1.23140    0.02442    -1.19347   -1.26820
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 7, 2, 4, 0, 3, 5, 8, 1, 6]
replay_buffer._size: [29400 29400 29400 29400 29400 29400 29400 29400 29400 29400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.988983869552612 0.002119302749633789
train_time 6.992371320724487
2023-09-06 14:06:43,255 MainThread INFO: EPOCH:194
2023-09-06 14:06:43,256 MainThread INFO: Time Consumed:7.00177264213562s
2023-09-06 14:06:43,256 MainThread INFO: Total Frames:292500s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 195/400 [13:22<29:05,  8.51s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -3.04070
Train_Epoch_Reward                    279.69727
Running_Training_Average_Rewards      18.35630
Explore_Time                          0.00309
Train___Time                          6.99237
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.36308
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.90922
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.61372
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.06449
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.01757
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.23730
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.92969
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 519.17742
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.98496
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.35225
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.65694     0.43291    5.32913    3.86868
alpha_0                               0.60498     0.00047    0.60572    0.60424
alpha_1                               0.56399     0.00045    0.56470    0.56329
alpha_2                               0.56878     0.00046    0.56949    0.56806
alpha_3                               0.56256     0.00048    0.56331    0.56180
alpha_4                               0.56606     0.00050    0.56684    0.56528
alpha_5                               0.56938     0.00045    0.57009    0.56867
alpha_6                               0.56744     0.00048    0.56819    0.56669
alpha_7                               0.57141     0.00052    0.57223    0.57060
alpha_8                               0.56599     0.00050    0.56678    0.56520
alpha_9                               0.57132     0.00050    0.57211    0.57053
Alpha_loss                            -3.35450    0.01239    -3.33694   -3.37565
Training/policy_loss                  -39.16017   0.08255    -38.99944  -39.30180
Training/qf1_loss                     285.34406   142.06509  595.77301  148.51080
Training/qf2_loss                     289.53546   143.64033  601.33185  148.47098
Training/pf_norm                      0.34490     0.01343    0.37124    0.31917
Training/qf1_norm                     114.33018   51.48926   200.19594  48.69046
Training/qf2_norm                     131.22877   64.08772   233.12842  20.34289
log_std/mean                          -0.25874    0.00049    -0.25795   -0.25939
log_std/std                           0.09777     0.00021    0.09807    0.09743
log_std/max                           -0.12461    0.00111    -0.12305   -0.12581
log_std/min                           -0.53746    0.00425    -0.52778   -0.54364
log_probs/mean                        -1.97422    0.02197    -1.93673   -2.00268
log_probs/std                         1.17544     0.02097    1.21926    1.14393
log_probs/max                         2.49668     0.27531    2.93745    2.13319
log_probs/min                         -6.17053    0.58814    -5.38575   -7.52896
mean/mean                             -0.02186    0.01424    -0.00061   -0.04541
mean/std                              0.49905     0.00031    0.49964    0.49864
mean/max                              1.03987     0.00772    1.05372    1.03184
mean/min                              -1.14936    0.02700    -1.11759   -1.20273
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 9, 6, 1, 8, 2, 0, 7, 3, 5]
replay_buffer._size: [29550 29550 29550 29550 29550 29550 29550 29550 29550 29550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.156934976577759 0.0022537708282470703
train_time 7.160438776016235
2023-09-06 14:06:50,539 MainThread INFO: EPOCH:195
2023-09-06 14:06:50,540 MainThread INFO: Time Consumed:7.1741554737091064s
2023-09-06 14:06:50,540 MainThread INFO: Total Frames:294000s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 196/400 [13:30<27:42,  8.15s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               -0.18254
Train_Epoch_Reward                    735.90379
Running_Training_Average_Rewards      43.08157
Explore_Time                          0.00366
Train___Time                          7.16044
Eval____Time                          0.00586
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.89044
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.59126
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.80679
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           25.09087
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.46557
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.48056
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.45927
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 528.94999
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.83229
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.44523
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.64642     0.21808    5.03072    4.32640
alpha_0                               0.60330     0.00049    0.60407    0.60253
alpha_1                               0.56245     0.00044    0.56314    0.56177
alpha_2                               0.56719     0.00046    0.56791    0.56648
alpha_3                               0.56089     0.00048    0.56164    0.56014
alpha_4                               0.56433     0.00050    0.56511    0.56355
alpha_5                               0.56781     0.00045    0.56851    0.56710
alpha_6                               0.56578     0.00047    0.56652    0.56505
alpha_7                               0.56961     0.00052    0.57042    0.56880
alpha_8                               0.56424     0.00050    0.56502    0.56345
alpha_9                               0.56957     0.00050    0.57036    0.56879
Alpha_loss                            -3.36633    0.02118    -3.32939   -3.39428
Training/policy_loss                  -39.38766   0.11074    -39.23961  -39.61053
Training/qf1_loss                     352.80731   157.00426  653.72131  157.78085
Training/qf2_loss                     358.20955   157.09912  660.75671  162.29898
Training/pf_norm                      0.33274     0.04142    0.40543    0.24086
Training/qf1_norm                     93.91455    43.42447   183.10326  42.36031
Training/qf2_norm                     125.16155   44.30784   213.71658  72.62037
log_std/mean                          -0.25559    0.00171    -0.25292   -0.25824
log_std/std                           0.09732     0.00017    0.09758    0.09703
log_std/max                           -0.12124    0.00230    -0.11764   -0.12456
log_std/min                           -0.51711    0.00689    -0.50669   -0.52808
log_probs/mean                        -1.96627    0.03778    -1.91154   -2.01906
log_probs/std                         1.18022     0.02398    1.21853    1.13967
log_probs/max                         2.35926     0.19883    2.64833    2.03903
log_probs/min                         -7.00850    0.85831    -6.04819   -8.98037
mean/mean                             0.01875     0.00878    0.03130    0.00364
mean/std                              0.50053     0.00065    0.50147    0.49967
mean/max                              1.07294     0.01078    1.09478    1.05662
mean/min                              -1.06427    0.03422    -1.01164   -1.12653
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 1, 7, 0, 2, 5, 8, 3, 6, 4]
replay_buffer._size: [29700 29700 29700 29700 29700 29700 29700 29700 29700 29700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.104040861129761 0.0035736560821533203
train_time 7.109585285186768
2023-09-06 14:06:57,794 MainThread INFO: EPOCH:196
2023-09-06 14:06:57,794 MainThread INFO: Time Consumed:7.122136354446411s
2023-09-06 14:06:57,795 MainThread INFO: Total Frames:295500s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 197/400 [13:37<26:38,  7.88s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               68.54266
Train_Epoch_Reward                    179.94726
Running_Training_Average_Rewards      39.85161
Explore_Time                          0.00324
Train___Time                          7.10959
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.69390
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.62115
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.21639
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2013.26253
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.80062
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.15518
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.01286
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 543.06324
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.49836
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.82211
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.69927     0.41031    5.60383    4.17791
alpha_0                               0.60155     0.00051    0.60235    0.60075
alpha_1                               0.56094     0.00043    0.56161    0.56027
alpha_2                               0.56561     0.00045    0.56632    0.56490
alpha_3                               0.55922     0.00048    0.55997    0.55847
alpha_4                               0.56259     0.00050    0.56338    0.56181
alpha_5                               0.56624     0.00045    0.56694    0.56554
alpha_6                               0.56415     0.00047    0.56488    0.56341
alpha_7                               0.56781     0.00052    0.56862    0.56700
alpha_8                               0.56249     0.00050    0.56328    0.56172
alpha_9                               0.56783     0.00050    0.56861    0.56705
Alpha_loss                            -3.38867    0.01409    -3.36921   -3.42478
Training/policy_loss                  -39.71306   0.15160    -39.50000  -39.99133
Training/qf1_loss                     290.75610   126.98385  613.00214  175.36720
Training/qf2_loss                     294.20475   127.00399  617.95251  179.47812
Training/pf_norm                      0.34502     0.03002    0.39978    0.28988
Training/qf1_norm                     102.59563   73.44567   275.47287  26.36523
Training/qf2_norm                     129.46211   77.46652   299.61227  33.29967
log_std/mean                          -0.25123    0.00060    -0.25033   -0.25211
log_std/std                           0.09641     0.00084    0.09749    0.09489
log_std/max                           -0.11447    0.00228    -0.11005   -0.11717
log_std/min                           -0.49302    0.00658    -0.48646   -0.50306
log_probs/mean                        -1.97705    0.02600    -1.94026   -2.04081
log_probs/std                         1.14849     0.02762    1.18268    1.09986
log_probs/max                         2.12155     0.19336    2.32949    1.77059
log_probs/min                         -6.99248    0.91407    -5.52741   -8.27354
mean/mean                             0.03980     0.00334    0.04339    0.03328
mean/std                              0.50000     0.00042    0.50056    0.49925
mean/max                              1.09296     0.00518    1.10507    1.08716
mean/min                              -0.97959    0.02042    -0.94811   -1.00647
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 4, 5, 9, 6, 8, 2, 1, 7, 3]
replay_buffer._size: [29850 29850 29850 29850 29850 29850 29850 29850 29850 29850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.40235447883606 0.002533435821533203
train_time 7.406370401382446
2023-09-06 14:07:05,327 MainThread INFO: EPOCH:197
2023-09-06 14:07:05,328 MainThread INFO: Time Consumed:7.4209089279174805s
2023-09-06 14:07:05,328 MainThread INFO: Total Frames:297000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 198/400 [13:44<26:09,  7.77s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               140.65858
Train_Epoch_Reward                    141.23931
Running_Training_Average_Rewards      35.23635
Explore_Time                          0.00311
Train___Time                          7.40637
Eval____Time                          0.00714
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.73418
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.93425
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.96667
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2097.85092
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.96353
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.66310
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.27517
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 567.79186
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.15427
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.76880
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.77854     0.55799    5.38821    3.93558
alpha_0                               0.59975     0.00052    0.60056    0.59893
alpha_1                               0.55944     0.00043    0.56012    0.55877
alpha_2                               0.56404     0.00045    0.56475    0.56334
alpha_3                               0.55756     0.00048    0.55831    0.55682
alpha_4                               0.56086     0.00050    0.56164    0.56008
alpha_5                               0.56468     0.00045    0.56538    0.56397
alpha_6                               0.56252     0.00047    0.56325    0.56179
alpha_7                               0.56601     0.00052    0.56682    0.56520
alpha_8                               0.56077     0.00049    0.56154    0.56000
alpha_9                               0.56611     0.00049    0.56688    0.56533
Alpha_loss                            -3.40771    0.01685    -3.37962   -3.44399
Training/policy_loss                  -40.02074   0.09226    -39.87171  -40.18784
Training/qf1_loss                     349.10672   175.12051  601.53473  171.91765
Training/qf2_loss                     353.87449   176.28936  609.22137  174.04959
Training/pf_norm                      0.34347     0.03078    0.40388    0.28836
Training/qf1_norm                     145.20044   77.62535   238.86568  35.56799
Training/qf2_norm                     159.87176   93.86607   270.98981  23.64921
log_std/mean                          -0.25531    0.00166    -0.25227   -0.25701
log_std/std                           0.09244     0.00099    0.09436    0.09149
log_std/max                           -0.11697    0.00376    -0.11159   -0.12261
log_std/min                           -0.48667    0.00438    -0.48011   -0.49543
log_probs/mean                        -1.97947    0.03001    -1.92901   -2.03415
log_probs/std                         1.15806     0.02959    1.20224    1.10290
log_probs/max                         1.93100     0.22734    2.38732    1.56205
log_probs/min                         -6.77835    0.92393    -5.70476   -8.39720
mean/mean                             0.04693     0.00227    0.05073    0.04400
mean/std                              0.49877     0.00056    0.49969    0.49775
mean/max                              1.08951     0.00547    1.09959    1.08359
mean/min                              -0.91763    0.01631    -0.89513   -0.94433
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 6, 4, 9, 3, 2, 0, 5, 8, 1]
replay_buffer._size: [30000 30000 30000 30000 30000 30000 30000 30000 30000 30000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.677879810333252 0.0021169185638427734
train_time 7.681399345397949
2023-09-06 14:07:13,127 MainThread INFO: EPOCH:198
2023-09-06 14:07:13,128 MainThread INFO: Time Consumed:7.696077823638916s
2023-09-06 14:07:13,128 MainThread INFO: Total Frames:298500s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 199/400 [13:52<26:04,  7.78s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               214.52733
Train_Epoch_Reward                    43.23061
Running_Training_Average_Rewards      12.14724
Explore_Time                          0.00335
Train___Time                          7.68140
Eval____Time                          0.00691
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.97965
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.75230
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.49982
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2153.89972
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.72203
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.28883
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.79703
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 600.86302
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.57566
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.01540
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.50510     0.38238    5.20922    3.86168
alpha_0                               0.59793     0.00052    0.59875    0.59710
alpha_1                               0.55795     0.00043    0.55862    0.55727
alpha_2                               0.56247     0.00045    0.56318    0.56177
alpha_3                               0.55591     0.00047    0.55665    0.55517
alpha_4                               0.55913     0.00050    0.55991    0.55836
alpha_5                               0.56311     0.00045    0.56381    0.56240
alpha_6                               0.56090     0.00046    0.56163    0.56018
alpha_7                               0.56422     0.00051    0.56502    0.56341
alpha_8                               0.55906     0.00049    0.55983    0.55830
alpha_9                               0.56439     0.00049    0.56516    0.56362
Alpha_loss                            -3.42498    0.01757    -3.40009   -3.45823
Training/policy_loss                  -40.09053   0.10047    -39.90232  -40.21651
Training/qf1_loss                     347.69757   206.92606  731.31543  162.82695
Training/qf2_loss                     351.46173   209.55234  739.92645  162.36353
Training/pf_norm                      0.31749     0.04664    0.40956    0.21618
Training/qf1_norm                     104.67804   51.26073   228.54013  29.40511
Training/qf2_norm                     116.81834   60.69985   251.27766  38.92002
log_std/mean                          -0.25574    0.00055    -0.25499   -0.25659
log_std/std                           0.09161     0.00028    0.09200    0.09118
log_std/max                           -0.12516    0.00064    -0.12378   -0.12613
log_std/min                           -0.49258    0.00379    -0.48454   -0.49708
log_probs/mean                        -1.97933    0.02512    -1.94032   -2.02479
log_probs/std                         1.15734     0.01875    1.17912    1.10901
log_probs/max                         1.92244     0.26125    2.34625    1.45632
log_probs/min                         -6.77976    0.82168    -5.46090   -8.14937
mean/mean                             0.05730     0.00435    0.06505    0.05169
mean/std                              0.49859     0.00060    0.49958    0.49764
mean/max                              1.10611     0.00848    1.11967    1.09277
mean/min                              -0.85124    0.01538    -0.82965   -0.87998
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 1, 6, 3, 4, 5, 2, 0, 9, 8]
replay_buffer._size: [30150 30150 30150 30150 30150 30150 30150 30150 30150 30150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.477075576782227 0.0026252269744873047
train_time 7.481349229812622
2023-09-06 14:07:20,746 MainThread INFO: EPOCH:199
2023-09-06 14:07:20,746 MainThread INFO: Time Consumed:7.497237682342529s
2023-09-06 14:07:20,747 MainThread INFO: Total Frames:300000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 200/400 [14:00<25:46,  7.73s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               222.39825
Train_Epoch_Reward                    33.56752
Running_Training_Average_Rewards      7.26791
Explore_Time                          0.00581
Train___Time                          7.48135
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.01697
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.02116
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.81615
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2172.54557
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.32254
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.39059
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.60745
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 607.48249
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.18223
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.03843
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.52090     0.35825    4.95061    3.81073
alpha_0                               0.59608     0.00054    0.59692    0.59523
alpha_1                               0.55645     0.00043    0.55712    0.55578
alpha_2                               0.56091     0.00045    0.56161    0.56020
alpha_3                               0.55426     0.00047    0.55500    0.55352
alpha_4                               0.55741     0.00049    0.55818    0.55663
alpha_5                               0.56154     0.00045    0.56224    0.56084
alpha_6                               0.55930     0.00046    0.56002    0.55858
alpha_7                               0.56243     0.00051    0.56323    0.56162
alpha_8                               0.55737     0.00048    0.55813    0.55661
alpha_9                               0.56269     0.00049    0.56345    0.56193
Alpha_loss                            -3.43996    0.01406    -3.41489   -3.45774
Training/policy_loss                  -40.30427   0.08790    -40.21017  -40.44829
Training/qf1_loss                     277.71727   101.27233  477.05402  147.90379
Training/qf2_loss                     281.31774   103.84463  487.81622  146.33601
Training/pf_norm                      0.36665     0.02890    0.43545    0.31708
Training/qf1_norm                     103.90464   45.47373   181.87616  26.20204
Training/qf2_norm                     120.47792   54.27547   203.12117  22.59100
log_std/mean                          -0.25612    0.00096    -0.25481   -0.25763
log_std/std                           0.09166     0.00016    0.09187    0.09132
log_std/max                           -0.12695    0.00143    -0.12491   -0.12904
log_std/min                           -0.48968    0.00425    -0.48428   -0.49716
log_probs/mean                        -1.97685    0.02783    -1.92667   -2.01083
log_probs/std                         1.14177     0.01841    1.17379    1.11184
log_probs/max                         1.85458     0.14490    2.06493    1.62487
log_probs/min                         -6.88298    0.83779    -5.84213   -8.88498
mean/mean                             0.08044     0.00906    0.09577    0.06724
mean/std                              0.50062     0.00071    0.50128    0.49929
mean/max                              1.14314     0.01267    1.16255    1.12334
mean/min                              -0.82291    0.00847    -0.80995   -0.83739
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 4, 0, 1, 5, 9, 6, 7, 3, 8]
replay_buffer._size: [30300 30300 30300 30300 30300 30300 30300 30300 30300 30300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.55225944519043 0.004094362258911133
train_time 7.559798955917358
2023-09-06 14:07:28,440 MainThread INFO: EPOCH:200
2023-09-06 14:07:28,441 MainThread INFO: Time Consumed:7.586281061172485s
2023-09-06 14:07:28,442 MainThread INFO: Total Frames:301500s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 201/400 [14:08<26:26,  7.97s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               224.33474
Train_Epoch_Reward                    524.19141
Running_Training_Average_Rewards      20.03298
Explore_Time                          0.00293
Train___Time                          7.55980
Eval____Time                          0.01296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.96181
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.26168
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.24475
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2115.90643
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.90354
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.31161
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.19867
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 598.98871
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.06507
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.67047
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.72346     0.42092    5.45375    4.07649
alpha_0                               0.59417     0.00056    0.59504    0.59330
alpha_1                               0.55497     0.00042    0.55563    0.55431
alpha_2                               0.55934     0.00045    0.56004    0.55863
alpha_3                               0.55261     0.00047    0.55335    0.55187
alpha_4                               0.55569     0.00049    0.55646    0.55492
alpha_5                               0.55998     0.00045    0.56068    0.55928
alpha_6                               0.55771     0.00045    0.55842    0.55700
alpha_7                               0.56065     0.00051    0.56145    0.55985
alpha_8                               0.55569     0.00048    0.55644    0.55495
alpha_9                               0.56101     0.00048    0.56176    0.56026
Alpha_loss                            -3.45012    0.01492    -3.42343   -3.48167
Training/policy_loss                  -40.54508   0.10836    -40.31393  -40.69569
Training/qf1_loss                     285.64126   100.61565  445.97821  176.12012
Training/qf2_loss                     289.12005   102.54656  450.69952  175.47020
Training/pf_norm                      0.35218     0.03276    0.40312    0.29887
Training/qf1_norm                     129.42204   77.36875   277.45895  25.70767
Training/qf2_norm                     146.93814   83.10942   298.86337  30.44130
log_std/mean                          -0.25685    0.00082    -0.25548   -0.25797
log_std/std                           0.09072     0.00018    0.09106    0.09043
log_std/max                           -0.13157    0.00085    -0.13009   -0.13308
log_std/min                           -0.50119    0.00364    -0.49627   -0.50754
log_probs/mean                        -1.96731    0.02410    -1.93148   -2.01941
log_probs/std                         1.13823     0.01203    1.15725    1.11830
log_probs/max                         1.61506     0.13800    1.93584    1.40181
log_probs/min                         -6.84903    0.73883    -6.02168   -8.16425
mean/mean                             0.11857     0.01186    0.13731    0.10015
mean/std                              0.49750     0.00249    0.50058    0.49295
mean/max                              1.17453     0.00903    1.18631    1.15304
mean/min                              -0.79720    0.01348    -0.78035   -0.82518
------------------------------------  ----------  ---------  ---------  ---------
snapshot at 200
history save at ./log/testing_must_mtsac/mt10/18/model
sample: [2, 8, 9, 0, 3, 4, 7, 5, 1, 6]
replay_buffer._size: [30450 30450 30450 30450 30450 30450 30450 30450 30450 30450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.8657288551330566 0.0021369457244873047
train_time 3.8691742420196533
2023-09-06 14:07:35,679 MainThread INFO: EPOCH:201
2023-09-06 14:07:35,680 MainThread INFO: Time Consumed:3.8841552734375s
2023-09-06 14:07:35,680 MainThread INFO: Total Frames:303000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 202/400 [14:15<24:45,  7.50s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               152.27073
Train_Epoch_Reward                    724.53755
Running_Training_Average_Rewards      42.74322
Explore_Time                          0.00501
Train___Time                          3.86917
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.55894
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.83785
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.16843
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.79164
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.58074
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.15825
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.47413
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 605.85355
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.69648
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.37535
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.41753     0.37616    4.95473    3.73794
alpha_0                               0.59220     0.00057    0.59310    0.59130
alpha_1                               0.55352     0.00041    0.55417    0.55287
alpha_2                               0.55778     0.00045    0.55848    0.55708
alpha_3                               0.55097     0.00047    0.55171    0.55024
alpha_4                               0.55398     0.00049    0.55475    0.55320
alpha_5                               0.55842     0.00045    0.55912    0.55772
alpha_6                               0.55613     0.00045    0.55684    0.55542
alpha_7                               0.55888     0.00050    0.55967    0.55809
alpha_8                               0.55404     0.00047    0.55478    0.55330
alpha_9                               0.55935     0.00047    0.56009    0.55861
Alpha_loss                            -3.45638    0.01721    -3.41996   -3.47796
Training/policy_loss                  -40.82812   0.07672    -40.70385  -40.92362
Training/qf1_loss                     297.40439   187.68265  654.61951  155.32042
Training/qf2_loss                     299.38451   189.37194  662.57867  155.40378
Training/pf_norm                      0.39650     0.04317    0.44972    0.32556
Training/qf1_norm                     90.62434    45.71946   163.16029  29.05547
Training/qf2_norm                     100.08364   51.37169   182.29086  28.45420
log_std/mean                          -0.25339    0.00170    -0.25073   -0.25567
log_std/std                           0.09093     0.00018    0.09118    0.09064
log_std/max                           -0.13189    0.00072    -0.13053   -0.13337
log_std/min                           -0.50428    0.00242    -0.49986   -0.50843
log_probs/mean                        -1.94937    0.02622    -1.88999   -1.97962
log_probs/std                         1.12879     0.01388    1.16429    1.11420
log_probs/max                         1.26473     0.17429    1.55441    0.96473
log_probs/min                         -6.85730    0.59331    -6.12275   -8.38537
mean/mean                             0.15963     0.01077    0.17612    0.14197
mean/std                              0.48474     0.00521    0.49265    0.47682
mean/max                              1.19584     0.00330    1.19942    1.18850
mean/min                              -0.74305    0.01450    -0.71797   -0.77010
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 3, 0, 1, 2, 8, 4, 9, 6, 7]
replay_buffer._size: [30600 30600 30600 30600 30600 30600 30600 30600 30600 30600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.3028905391693115 0.0020444393157958984
train_time 7.306210279464722
2023-09-06 14:07:43,102 MainThread INFO: EPOCH:202
2023-09-06 14:07:43,103 MainThread INFO: Time Consumed:7.3175084590911865s
2023-09-06 14:07:43,103 MainThread INFO: Total Frames:304500s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 203/400 [14:22<24:33,  7.48s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               79.97709
Train_Epoch_Reward                    3437.31784
Running_Training_Average_Rewards      156.20156
Explore_Time                          0.00274
Train___Time                          7.30621
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.09938
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.32754
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.46348
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.56437
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.49674
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.12316
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.11161
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 642.07683
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.76481
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.30217
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.28862     0.39021    4.89709    3.47870
alpha_0                               0.59017     0.00060    0.59110    0.58923
alpha_1                               0.55209     0.00041    0.55273    0.55145
alpha_2                               0.55622     0.00045    0.55692    0.55552
alpha_3                               0.54934     0.00047    0.55007    0.54861
alpha_4                               0.55227     0.00049    0.55303    0.55150
alpha_5                               0.55686     0.00045    0.55757    0.55616
alpha_6                               0.55456     0.00045    0.55527    0.55385
alpha_7                               0.55714     0.00050    0.55792    0.55636
alpha_8                               0.55241     0.00046    0.55314    0.55169
alpha_9                               0.55771     0.00047    0.55844    0.55697
Alpha_loss                            -3.49126    0.01610    -3.47584   -3.53079
Training/policy_loss                  -40.97779   0.07666    -40.82763  -41.09290
Training/qf1_loss                     253.02182   109.20481  530.58478  160.72627
Training/qf2_loss                     254.17255   110.39503  534.40924  161.22229
Training/pf_norm                      0.38873     0.03665    0.43379    0.29842
Training/qf1_norm                     81.00707    49.56381   175.26553  22.74877
Training/qf2_norm                     85.78114    51.93794   183.16788  14.49973
log_std/mean                          -0.25169    0.00115    -0.25016   -0.25332
log_std/std                           0.09250     0.00094    0.09407    0.09115
log_std/max                           -0.13540    0.00204    -0.13168   -0.13795
log_std/min                           -0.51539    0.00604    -0.50570   -0.52296
log_probs/mean                        -1.98208    0.03001    -1.94725   -2.05330
log_probs/std                         1.13297     0.03070    1.16662    1.07180
log_probs/max                         1.35132     0.25131    1.71966    0.98532
log_probs/min                         -6.77409    0.80743    -5.33699   -8.17039
mean/mean                             0.19813     0.01160    0.21668    0.18025
mean/std                              0.46791     0.00453    0.47550    0.46092
mean/max                              1.20783     0.00685    1.21836    1.19747
mean/min                              -0.69682    0.01426    -0.67403   -0.72424
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 3, 8, 6, 0, 4, 1, 5, 2, 9]
replay_buffer._size: [30750 30750 30750 30750 30750 30750 30750 30750 30750 30750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.47502326965332 0.0020165443420410156
train_time 7.47827935218811
2023-09-06 14:07:50,715 MainThread INFO: EPOCH:203
2023-09-06 14:07:50,716 MainThread INFO: Time Consumed:7.496629476547241s
2023-09-06 14:07:50,716 MainThread INFO: Total Frames:306000s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 204/400 [14:30<24:33,  7.52s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               11.40982
Train_Epoch_Reward                    153.71189
Running_Training_Average_Rewards      143.85224
Explore_Time                          0.00622
Train___Time                          7.47828
Eval____Time                          0.00682
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -90.51995
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.77293
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.93609
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.05084
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.94082
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.80489
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.35673
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 696.29242
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.66558
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.98537
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.72936     0.47597    5.68096    4.13194
alpha_0                               0.58806     0.00062    0.58902    0.58709
alpha_1                               0.55067     0.00040    0.55131    0.55004
alpha_2                               0.55466     0.00045    0.55536    0.55396
alpha_3                               0.54772     0.00046    0.54845    0.54699
alpha_4                               0.55057     0.00049    0.55133    0.54980
alpha_5                               0.55530     0.00045    0.55600    0.55460
alpha_6                               0.55298     0.00045    0.55369    0.55227
alpha_7                               0.55541     0.00049    0.55619    0.55465
alpha_8                               0.55081     0.00045    0.55153    0.55010
alpha_9                               0.55607     0.00047    0.55681    0.55535
Alpha_loss                            -3.49137    0.00933    -3.47359   -3.50446
Training/policy_loss                  -41.07334   0.08796    -40.93289  -41.24425
Training/qf1_loss                     346.13286   140.98045  651.40027  194.22406
Training/qf2_loss                     348.57605   142.28934  654.16882  195.44458
Training/pf_norm                      0.41884     0.06646    0.53004    0.30991
Training/qf1_norm                     145.96972   95.36656   331.19562  31.59080
Training/qf2_norm                     158.25746   95.42957   342.02219  39.43927
log_std/mean                          -0.25395    0.00051    -0.25336   -0.25492
log_std/std                           0.09611     0.00113    0.09823    0.09454
log_std/max                           -0.13662    0.00068    -0.13551   -0.13771
log_std/min                           -0.54007    0.00900    -0.52496   -0.55127
log_probs/mean                        -1.95453    0.01154    -1.93622   -1.97224
log_probs/std                         1.14145     0.01671    1.16964    1.12089
log_probs/max                         1.44818     0.19895    1.84086    1.11701
log_probs/min                         -6.82778    0.73404    -5.80661   -8.63178
mean/mean                             0.23613     0.01016    0.25222    0.22036
mean/std                              0.45222     0.00480    0.46011    0.44470
mean/max                              1.22802     0.00884    1.24389    1.21100
mean/min                              -0.64781    0.01495    -0.62270   -0.66960
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 4, 6, 0, 8, 7, 3, 5, 1, 9]
replay_buffer._size: [30900 30900 30900 30900 30900 30900 30900 30900 30900 30900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.372143745422363 0.0023193359375
train_time 7.376508712768555
2023-09-06 14:07:58,215 MainThread INFO: EPOCH:204
2023-09-06 14:07:58,216 MainThread INFO: Time Consumed:7.391016006469727s
2023-09-06 14:07:58,216 MainThread INFO: Total Frames:307500s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 205/400 [14:37<24:25,  7.51s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               15.71569
Train_Epoch_Reward                    164.72314
Running_Training_Average_Rewards      125.19176
Explore_Time                          0.00637
Train___Time                          7.37651
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.06495
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.96124
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.65693
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.67539
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.48490
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.33406
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.06035
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 769.53645
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.70094
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20993
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.96828     0.65552    6.04083     3.94323
alpha_0                               0.58588     0.00064    0.58687     0.58488
alpha_1                               0.54928     0.00040    0.54990     0.54866
alpha_2                               0.55309     0.00045    0.55380     0.55239
alpha_3                               0.54611     0.00046    0.54683     0.54538
alpha_4                               0.54887     0.00048    0.54964     0.54812
alpha_5                               0.55376     0.00044    0.55445     0.55306
alpha_6                               0.55140     0.00045    0.55211     0.55069
alpha_7                               0.55371     0.00049    0.55448     0.55295
alpha_8                               0.54924     0.00045    0.54994     0.54854
alpha_9                               0.55446     0.00046    0.55518     0.55373
Alpha_loss                            -3.51825    0.01909    -3.47739    -3.54293
Training/policy_loss                  -41.45553   0.17390    -41.13909   -41.63413
Training/qf1_loss                     498.30418   333.67900  1190.53198  193.30666
Training/qf2_loss                     502.60889   336.59417  1199.83862  192.18900
Training/pf_norm                      0.44861     0.05037    0.57260     0.40199
Training/qf1_norm                     196.81987   130.22289  408.41669   41.83887
Training/qf2_norm                     203.18921   131.49905  418.24057   34.14812
log_std/mean                          -0.25591    0.00029    -0.25526    -0.25627
log_std/std                           0.10247     0.00211    0.10554     0.09884
log_std/max                           -0.13195    0.00179    -0.12896    -0.13517
log_std/min                           -0.56971    0.00992    -0.55225    -0.58510
log_probs/mean                        -1.97244    0.03276    -1.91115    -2.02365
log_probs/std                         1.15114     0.02214    1.19802     1.12882
log_probs/max                         1.54493     0.16698    1.75744     1.18228
log_probs/min                         -7.47037    1.55523    -6.02431    -11.16189
mean/mean                             0.27378     0.01106    0.29099     0.25644
mean/std                              0.43593     0.00422    0.44253     0.42951
mean/max                              1.25409     0.01001    1.27634     1.24223
mean/min                              -0.58802    0.01874    -0.55327    -0.61468
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 5, 0, 9, 2, 8, 4, 7, 1, 6]
replay_buffer._size: [31050 31050 31050 31050 31050 31050 31050 31050 31050 31050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.288613796234131 0.0020530223846435547
train_time 7.291921615600586
2023-09-06 14:08:05,639 MainThread INFO: EPOCH:205
2023-09-06 14:08:05,639 MainThread INFO: Time Consumed:7.303868770599365s
2023-09-06 14:08:05,639 MainThread INFO: Total Frames:309000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 206/400 [14:45<24:12,  7.49s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               22.69473
Train_Epoch_Reward                    449.23274
Running_Training_Average_Rewards      25.58893
Explore_Time                          0.00331
Train___Time                          7.29192
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -90.89938
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.66006
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.35968
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.50203
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.53989
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.47188
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.18117
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 879.62600
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.78975
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.02732
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.55926     0.47045    5.29587    3.88897
alpha_0                               0.58364     0.00065    0.58465    0.58262
alpha_1                               0.54791     0.00039    0.54852    0.54730
alpha_2                               0.55153     0.00045    0.55223    0.55082
alpha_3                               0.54451     0.00046    0.54522    0.54379
alpha_4                               0.54720     0.00048    0.54795    0.54645
alpha_5                               0.55222     0.00044    0.55291    0.55153
alpha_6                               0.54981     0.00046    0.55053    0.54910
alpha_7                               0.55203     0.00048    0.55278    0.55127
alpha_8                               0.54769     0.00044    0.54838    0.54701
alpha_9                               0.55285     0.00046    0.55357    0.55212
Alpha_loss                            -3.50286    0.01942    -3.46889   -3.53250
Training/policy_loss                  -41.76453   0.07445    -41.59064  -41.89066
Training/qf1_loss                     329.37047   173.48548  642.43567  150.17213
Training/qf2_loss                     330.97277   174.85686  647.57751  150.79439
Training/pf_norm                      0.41734     0.03870    0.49747    0.35620
Training/qf1_norm                     106.44045   85.83201   238.12637  24.68804
Training/qf2_norm                     111.99888   89.51558   244.59633  26.37595
log_std/mean                          -0.25650    0.00045    -0.25596   -0.25722
log_std/std                           0.10736     0.00057    0.10786    0.10602
log_std/max                           -0.12899    0.00089    -0.12784   -0.13087
log_std/min                           -0.59961    0.00682    -0.58597   -0.61258
log_probs/mean                        -1.91814    0.03191    -1.86322   -1.96667
log_probs/std                         1.16683     0.01740    1.19160    1.13774
log_probs/max                         1.51923     0.22152    1.91079    1.23523
log_probs/min                         -7.06070    1.01867    -5.94566   -9.89179
mean/mean                             0.30725     0.00705    0.31645    0.29432
mean/std                              0.42470     0.00222    0.42857    0.42147
mean/max                              1.29587     0.01463    1.31505    1.27054
mean/min                              -0.54397    0.01404    -0.52362   -0.56862
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 9, 8, 2, 7, 3, 1, 4, 0, 5]
replay_buffer._size: [31200 31200 31200 31200 31200 31200 31200 31200 31200 31200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.09248948097229 0.0020589828491210938
train_time 7.095769643783569
2023-09-06 14:08:12,879 MainThread INFO: EPOCH:206
2023-09-06 14:08:12,880 MainThread INFO: Time Consumed:7.112943410873413s
2023-09-06 14:08:12,880 MainThread INFO: Total Frames:310500s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 207/400 [14:52<23:52,  7.42s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               36.05452
Train_Epoch_Reward                    1553.70854
Running_Training_Average_Rewards      72.25548
Explore_Time                          0.00369
Train___Time                          7.09577
Eval____Time                          0.00721
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.37263
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.10990
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.40435
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.18161
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.03811
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.39124
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.06165
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1123.70335
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.21476
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.87602
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.56454     0.43243    5.45339    3.96537
alpha_0                               0.58138     0.00065    0.58240    0.58036
alpha_1                               0.54655     0.00039    0.54716    0.54594
alpha_2                               0.54997     0.00045    0.55067    0.54927
alpha_3                               0.54292     0.00046    0.54363    0.54221
alpha_4                               0.54553     0.00048    0.54628    0.54479
alpha_5                               0.55070     0.00043    0.55138    0.55003
alpha_6                               0.54823     0.00045    0.54894    0.54752
alpha_7                               0.55036     0.00048    0.55111    0.54961
alpha_8                               0.54618     0.00043    0.54686    0.54551
alpha_9                               0.55124     0.00046    0.55196    0.55051
Alpha_loss                            -3.51900    0.01262    -3.50279   -3.54672
Training/policy_loss                  -42.00395   0.09458    -41.88242  -42.16568
Training/qf1_loss                     310.02592   185.24067  689.15961  175.04819
Training/qf2_loss                     312.23372   188.24777  700.35461  173.74213
Training/pf_norm                      0.37876     0.02350    0.41134    0.33521
Training/qf1_norm                     106.45462   76.70981   279.56735  34.35977
Training/qf2_norm                     111.77602   79.62149   286.20847  24.97683
log_std/mean                          -0.25872    0.00053    -0.25787   -0.25949
log_std/std                           0.10757     0.00014    0.10777    0.10721
log_std/max                           -0.13012    0.00156    -0.12742   -0.13209
log_std/min                           -0.61589    0.00639    -0.60540   -0.62676
log_probs/mean                        -1.91586    0.01816    -1.89329   -1.94956
log_probs/std                         1.18008     0.02359    1.21670    1.13099
log_probs/max                         1.68051     0.22127    2.02486    1.37622
log_probs/min                         -6.43200    0.59229    -5.48828   -7.61632
mean/mean                             0.32403     0.00337    0.32797    0.31854
mean/std                              0.41921     0.00121    0.42110    0.41747
mean/max                              1.33854     0.01290    1.35963    1.31483
mean/min                              -0.52444    0.00403    -0.52001   -0.53340
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 7, 2, 4, 6, 5, 3, 9, 0, 8]
replay_buffer._size: [31350 31350 31350 31350 31350 31350 31350 31350 31350 31350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.240333080291748 0.0020134449005126953
train_time 4.243562936782837
2023-09-06 14:08:20,304 MainThread INFO: EPOCH:207
2023-09-06 14:08:20,305 MainThread INFO: Time Consumed:4.455526113510132s
2023-09-06 14:08:20,305 MainThread INFO: Total Frames:312000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 208/400 [14:59<23:43,  7.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               56.82659
Train_Epoch_Reward                    515.05299
Running_Training_Average_Rewards      83.93314
Explore_Time                          0.20542
Train___Time                          4.24356
Eval____Time                          0.00239
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.21933
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.31265
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -67.09662
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.90069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.90757
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.85400
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.75819
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1403.24014
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.90461
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.73655
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.46553     0.48997    5.40265    3.62031
alpha_0                               0.57912     0.00065    0.58013    0.57810
alpha_1                               0.54520     0.00039    0.54581    0.54459
alpha_2                               0.54841     0.00045    0.54911    0.54771
alpha_3                               0.54133     0.00045    0.54205    0.54062
alpha_4                               0.54388     0.00047    0.54462    0.54314
alpha_5                               0.54922     0.00043    0.54988    0.54855
alpha_6                               0.54666     0.00045    0.54736    0.54596
alpha_7                               0.54870     0.00048    0.54944    0.54795
alpha_8                               0.54470     0.00042    0.54537    0.54403
alpha_9                               0.54963     0.00046    0.55035    0.54892
Alpha_loss                            -3.52529    0.01624    -3.49602   -3.55286
Training/policy_loss                  -42.24434   0.10956    -42.01709  -42.35524
Training/qf1_loss                     320.17978   224.63032  884.98956  150.98480
Training/qf2_loss                     320.83253   226.05743  889.67560  149.58981
Training/pf_norm                      0.41076     0.01393    0.44498    0.39291
Training/qf1_norm                     109.36221   67.91517   277.01413  30.71814
Training/qf2_norm                     113.54430   69.58362   282.05255  35.14327
log_std/mean                          -0.25814    0.00024    -0.25788   -0.25876
log_std/std                           0.10631     0.00048    0.10730    0.10569
log_std/max                           -0.12455    0.00167    -0.12208   -0.12749
log_std/min                           -0.62794    0.00522    -0.61977   -0.63803
log_probs/mean                        -1.89679    0.02576    -1.85916   -1.94978
log_probs/std                         1.18581     0.01901    1.20957    1.14243
log_probs/max                         1.60440     0.16059    1.80246    1.27828
log_probs/min                         -6.70175    0.53772    -5.74830   -7.86905
mean/mean                             0.32969     0.00128    0.33206    0.32828
mean/std                              0.41636     0.00080    0.41770    0.41500
mean/max                              1.37098     0.01337    1.39290    1.34570
mean/min                              -0.53849    0.01059    -0.52502   -0.55418
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 9, 7, 8, 1, 6, 0, 4, 3, 2]
replay_buffer._size: [31500 31500 31500 31500 31500 31500 31500 31500 31500 31500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.359171390533447 0.0019330978393554688
train_time 7.362303733825684
2023-09-06 14:08:27,788 MainThread INFO: EPOCH:208
2023-09-06 14:08:27,789 MainThread INFO: Time Consumed:7.37368369102478s
2023-09-06 14:08:27,789 MainThread INFO: Total Frames:313500s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 209/400 [15:07<23:41,  7.44s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               79.89756
Train_Epoch_Reward                    3486.81596
Running_Training_Average_Rewards      185.18592
Explore_Time                          0.00314
Train___Time                          7.36230
Eval____Time                          0.00223
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.69055
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.35761
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -68.67840
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.39376
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.84375
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.25414
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.24691
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1564.31287
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.81620
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.70773
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.34318     0.59104    5.70257    3.58307
alpha_0                               0.57687     0.00064    0.57788    0.57587
alpha_1                               0.54384     0.00039    0.54445    0.54322
alpha_2                               0.54685     0.00045    0.54756    0.54615
alpha_3                               0.53975     0.00045    0.54046    0.53904
alpha_4                               0.54223     0.00047    0.54297    0.54149
alpha_5                               0.54775     0.00042    0.54840    0.54710
alpha_6                               0.54510     0.00045    0.54580    0.54439
alpha_7                               0.54704     0.00047    0.54779    0.54631
alpha_8                               0.54323     0.00042    0.54389    0.54257
alpha_9                               0.54804     0.00046    0.54876    0.54733
Alpha_loss                            -3.54017    0.02234    -3.50612   -3.57268
Training/policy_loss                  -42.41208   0.06444    -42.32592  -42.49749
Training/qf1_loss                     232.74459   117.27112  573.76288  143.81667
Training/qf2_loss                     233.45273   117.94663  575.89172  141.65190
Training/pf_norm                      0.40767     0.02933    0.46761    0.36751
Training/qf1_norm                     111.42633   83.06514   345.86957  41.03801
Training/qf2_norm                     115.54730   86.64981   358.67587  49.18983
log_std/mean                          -0.25913    0.00029    -0.25867   -0.25969
log_std/std                           0.10717     0.00113    0.10949    0.10590
log_std/max                           -0.12227    0.00068    -0.12134   -0.12333
log_std/min                           -0.63911    0.00938    -0.62467   -0.65416
log_probs/mean                        -1.89229    0.03663    -1.83721   -1.94177
log_probs/std                         1.18678     0.02298    1.20874    1.14771
log_probs/max                         1.59552     0.19538    1.89472    1.17588
log_probs/min                         -6.68911    0.53851    -5.81802   -7.75966
mean/mean                             0.33651     0.00193    0.33926    0.33332
mean/std                              0.41207     0.00150    0.41443    0.41032
mean/max                              1.38183     0.01507    1.40116    1.35131
mean/min                              -0.54966    0.00744    -0.53937   -0.56528
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 1, 6, 2, 5, 7, 4, 3, 0, 8]
replay_buffer._size: [31650 31650 31650 31650 31650 31650 31650 31650 31650 31650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 3.8867084980010986 0.002808809280395508
train_time 3.8912787437438965
2023-09-06 14:08:35,279 MainThread INFO: EPOCH:209
2023-09-06 14:08:35,280 MainThread INFO: Time Consumed:3.9050021171569824s
2023-09-06 14:08:35,280 MainThread INFO: Total Frames:315000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 210/400 [15:14<23:36,  7.46s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               96.67931
Train_Epoch_Reward                    2671.60045
Running_Training_Average_Rewards      222.44898
Explore_Time                          0.00412
Train___Time                          3.89128
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.07080
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.44716
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.09904
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.55380
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.38446
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.13039
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.93050
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1621.17963
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.96701
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.09099
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.32587     0.19548    4.59829    3.98245
alpha_0                               0.57465     0.00063    0.57565    0.57367
alpha_1                               0.54247     0.00039    0.54308    0.54186
alpha_2                               0.54529     0.00045    0.54600    0.54459
alpha_3                               0.53818     0.00045    0.53888    0.53747
alpha_4                               0.54058     0.00047    0.54132    0.53984
alpha_5                               0.54631     0.00041    0.54696    0.54567
alpha_6                               0.54353     0.00045    0.54423    0.54283
alpha_7                               0.54541     0.00047    0.54614    0.54467
alpha_8                               0.54176     0.00042    0.54242    0.54110
alpha_9                               0.54646     0.00046    0.54717    0.54574
Alpha_loss                            -3.54776    0.02159    -3.52459   -3.58530
Training/policy_loss                  -42.55676   0.09909    -42.42585  -42.75186
Training/qf1_loss                     242.08785   118.31131  557.96619  143.64066
Training/qf2_loss                     242.52150   119.57439  561.54590  143.62268
Training/pf_norm                      0.38374     0.01687    0.40565    0.35299
Training/qf1_norm                     64.06880    41.76666   130.68246  21.07564
Training/qf2_norm                     72.06336    43.51887   135.10336  18.44218
log_std/mean                          -0.25943    0.00028    -0.25884   -0.25984
log_std/std                           0.11190     0.00094    0.11334    0.11016
log_std/max                           -0.12088    0.00064    -0.11969   -0.12194
log_std/min                           -0.66304    0.00927    -0.64404   -0.67521
log_probs/mean                        -1.87554    0.03696    -1.83335   -1.95086
log_probs/std                         1.18668     0.02237    1.23178    1.15898
log_probs/max                         1.53328     0.25206    1.91515    1.25178
log_probs/min                         -6.75997    0.38171    -6.11430   -7.33470
mean/mean                             0.33997     0.00054    0.34081    0.33899
mean/std                              0.40998     0.00037    0.41041    0.40909
mean/max                              1.37900     0.01295    1.39844    1.35575
mean/min                              -0.54878    0.00825    -0.53936   -0.56169
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 0, 2, 5, 9, 7, 1, 3, 8, 4]
replay_buffer._size: [31800 31800 31800 31800 31800 31800 31800 31800 31800 31800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.631958246231079 0.0024843215942382812
train_time 7.636004209518433
2023-09-06 14:08:43,064 MainThread INFO: EPOCH:210
2023-09-06 14:08:43,065 MainThread INFO: Time Consumed:7.653612852096558s
2023-09-06 14:08:43,065 MainThread INFO: Total Frames:316500s
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 211/400 [15:22<23:48,  7.56s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               106.65263
Train_Epoch_Reward                    3912.66648
Running_Training_Average_Rewards      335.70276
Explore_Time                          0.00366
Train___Time                          7.63600
Eval____Time                          0.00855
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.54438
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.43096
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.99738
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.31620
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.91943
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.66926
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.54279
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1701.29669
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.80842
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.31818
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.32031     0.28232    4.78372    3.88692
alpha_0                               0.57248     0.00062    0.57345    0.57151
alpha_1                               0.54110     0.00040    0.54172    0.54048
alpha_2                               0.54372     0.00045    0.54443    0.54302
alpha_3                               0.53661     0.00045    0.53731    0.53590
alpha_4                               0.53894     0.00047    0.53968    0.53820
alpha_5                               0.54489     0.00041    0.54553    0.54425
alpha_6                               0.54197     0.00045    0.54268    0.54127
alpha_7                               0.54378     0.00047    0.54451    0.54304
alpha_8                               0.54031     0.00042    0.54096    0.53965
alpha_9                               0.54487     0.00045    0.54559    0.54416
Alpha_loss                            -3.57889    0.01533    -3.55327   -3.60786
Training/policy_loss                  -42.90698   0.11388    -42.72404  -43.05856
Training/qf1_loss                     290.02735   112.20711  489.52271  176.41711
Training/qf2_loss                     291.19272   112.94891  492.17023  173.90584
Training/pf_norm                      0.35362     0.03026    0.39945    0.31313
Training/qf1_norm                     76.76088    45.04052   172.45616  31.65096
Training/qf2_norm                     84.56910    47.52504   178.92714  27.76045
log_std/mean                          -0.25791    0.00044    -0.25735   -0.25863
log_std/std                           0.11537     0.00093    0.11701    0.11410
log_std/max                           -0.11721    0.00139    -0.11448   -0.11939
log_std/min                           -0.67183    0.00597    -0.66491   -0.68668
log_probs/mean                        -1.89662    0.02251    -1.86472   -1.93926
log_probs/std                         1.17143     0.02871    1.21730    1.13310
log_probs/max                         1.40025     0.22257    1.66317    0.92548
log_probs/min                         -6.85849    0.61028    -5.97834   -7.94253
mean/mean                             0.33803     0.00034    0.33869    0.33753
mean/std                              0.40865     0.00053    0.40957    0.40785
mean/max                              1.37883     0.00935    1.38900    1.36490
mean/min                              -0.54576    0.00595    -0.53613   -0.55562
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 2, 3, 9, 4, 8, 6, 0, 5, 7]
replay_buffer._size: [31950 31950 31950 31950 31950 31950 31950 31950 31950 31950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.093688011169434 0.002001047134399414
train_time 4.096903085708618
2023-09-06 14:08:50,622 MainThread INFO: EPOCH:211
2023-09-06 14:08:50,623 MainThread INFO: Time Consumed:4.228849172592163s
2023-09-06 14:08:50,623 MainThread INFO: Total Frames:318000s
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 212/400 [15:30<23:39,  7.55s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               111.78365
Train_Epoch_Reward                    1002.17501
Running_Training_Average_Rewards      252.88140
Explore_Time                          0.12363
Train___Time                          4.09690
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.45049
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.55017
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.22486
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.79794
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.71965
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.96696
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.55611
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1715.35897
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.07976
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.75862
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.53650     0.33696    4.98616    3.80989
alpha_0                               0.57036     0.00060    0.57130    0.56942
alpha_1                               0.53972     0.00039    0.54034    0.53910
alpha_2                               0.54215     0.00045    0.54286    0.54144
alpha_3                               0.53503     0.00045    0.53574    0.53432
alpha_4                               0.53729     0.00047    0.53803    0.53656
alpha_5                               0.54347     0.00041    0.54410    0.54283
alpha_6                               0.54041     0.00045    0.54111    0.53971
alpha_7                               0.54215     0.00047    0.54288    0.54142
alpha_8                               0.53885     0.00042    0.53951    0.53820
alpha_9                               0.54329     0.00046    0.54400    0.54257
Alpha_loss                            -3.58174    0.01836    -3.54832   -3.61698
Training/policy_loss                  -43.17851   0.13138    -42.98561  -43.41845
Training/qf1_loss                     292.10782   135.66210  569.35242  151.66830
Training/qf2_loss                     293.15717   135.10496  567.38007  150.99347
Training/pf_norm                      0.34751     0.03928    0.41115    0.29732
Training/qf1_norm                     122.58932   52.25287   217.81914  50.41220
Training/qf2_norm                     130.93520   54.46823   226.16441  58.94402
log_std/mean                          -0.25903    0.00042    -0.25831   -0.25958
log_std/std                           0.11911     0.00131    0.12084    0.11716
log_std/max                           -0.11319    0.00107    -0.11171   -0.11533
log_std/min                           -0.68125    0.00801    -0.67191   -0.69755
log_probs/mean                        -1.87164    0.03194    -1.81499   -1.93552
log_probs/std                         1.16810     0.01461    1.18527    1.14216
log_probs/max                         1.40160     0.15615    1.64735    1.11953
log_probs/min                         -6.94007    0.48923    -6.21043   -7.70966
mean/mean                             0.34018     0.00099    0.34156    0.33864
mean/std                              0.41015     0.00053    0.41094    0.40921
mean/max                              1.38139     0.00973    1.39388    1.35985
mean/min                              -0.53525    0.00816    -0.52519   -0.55110
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 8, 3, 4, 1, 0, 2, 7, 9, 5]
replay_buffer._size: [32100 32100 32100 32100 32100 32100 32100 32100 32100 32100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.4230101108551025 0.003045320510864258
train_time 7.427901983261108
2023-09-06 14:08:58,182 MainThread INFO: EPOCH:212
2023-09-06 14:08:58,183 MainThread INFO: Time Consumed:7.4406774044036865s
2023-09-06 14:08:58,183 MainThread INFO: Total Frames:319500s
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 213/400 [15:37<23:33,  7.56s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               120.83847
Train_Epoch_Reward                    2178.97389
Running_Training_Average_Rewards      236.46051
Explore_Time                          0.00281
Train___Time                          7.42790
Eval____Time                          0.00474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.89182
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.90273
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.38235
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.75905
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.28842
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.07134
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.38862
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1859.37135
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.67053
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.86656
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.24237     0.30079    4.63614    3.66216
alpha_0                               0.56830     0.00059    0.56922    0.56738
alpha_1                               0.53834     0.00040    0.53897    0.53772
alpha_2                               0.54058     0.00045    0.54128    0.53988
alpha_3                               0.53345     0.00045    0.53416    0.53274
alpha_4                               0.53566     0.00047    0.53639    0.53493
alpha_5                               0.54206     0.00040    0.54269    0.54143
alpha_6                               0.53885     0.00045    0.53956    0.53815
alpha_7                               0.54053     0.00047    0.54126    0.53980
alpha_8                               0.53740     0.00042    0.53805    0.53674
alpha_9                               0.54170     0.00046    0.54242    0.54099
Alpha_loss                            -3.59442    0.01746    -3.56822   -3.61795
Training/policy_loss                  -43.42691   0.07071    -43.33419  -43.56246
Training/qf1_loss                     334.44283   162.27184  614.58960  151.85410
Training/qf2_loss                     335.50903   163.78345  617.73047  149.91458
Training/pf_norm                      0.35090     0.04187    0.41089    0.29324
Training/qf1_norm                     80.43314    25.33797   128.22954  57.21052
Training/qf2_norm                     86.88860    31.33230   142.62550  47.11607
log_std/mean                          -0.25861    0.00030    -0.25807   -0.25910
log_std/std                           0.12233     0.00061    0.12301    0.12117
log_std/max                           -0.10816    0.00129    -0.10672   -0.11060
log_std/min                           -0.69344    0.00725    -0.68513   -0.70770
log_probs/mean                        -1.86365    0.03134    -1.82195   -1.91502
log_probs/std                         1.16009     0.02127    1.19884    1.13235
log_probs/max                         1.48579     0.15820    1.69161    1.23501
log_probs/min                         -6.76816    0.50827    -5.84035   -7.61557
mean/mean                             0.33780     0.00220    0.34076    0.33377
mean/std                              0.41260     0.00119    0.41430    0.41081
mean/max                              1.37796     0.00742    1.39023    1.36552
mean/min                              -0.53807    0.00785    -0.52730   -0.54924
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 4, 2, 1, 7, 3, 5, 6, 0, 9]
replay_buffer._size: [32250 32250 32250 32250 32250 32250 32250 32250 32250 32250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.020413637161255 0.001947641372680664
train_time 4.023589849472046
2023-09-06 14:09:05,882 MainThread INFO: EPOCH:213
2023-09-06 14:09:05,883 MainThread INFO: Time Consumed:4.830615997314453s
2023-09-06 14:09:05,883 MainThread INFO: Total Frames:321000s
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 214/400 [15:45<23:32,  7.59s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               133.74036
Train_Epoch_Reward                    2091.85536
Running_Training_Average_Rewards      175.76681
Explore_Time                          0.79870
Train___Time                          4.02359
Eval____Time                          0.00373
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.94105
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.51301
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.57427
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.20213
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.09356
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.18284
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.33498
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2044.78099
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.65019
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.48252
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.77204     0.58595    5.57401    3.89629
alpha_0                               0.56628     0.00057    0.56718    0.56539
alpha_1                               0.53696     0.00040    0.53759    0.53634
alpha_2                               0.53902     0.00045    0.53972    0.53831
alpha_3                               0.53187     0.00045    0.53258    0.53116
alpha_4                               0.53404     0.00047    0.53477    0.53331
alpha_5                               0.54066     0.00040    0.54129    0.54004
alpha_6                               0.53730     0.00045    0.53800    0.53660
alpha_7                               0.53890     0.00047    0.53963    0.53817
alpha_8                               0.53594     0.00042    0.53660    0.53529
alpha_9                               0.54011     0.00046    0.54083    0.53940
Alpha_loss                            -3.62069    0.02752    -3.57733   -3.67738
Training/policy_loss                  -43.74458   0.12737    -43.51089  -43.90211
Training/qf1_loss                     406.43373   225.03041  916.86865  150.60121
Training/qf2_loss                     407.90468   225.83940  919.16394  150.59641
Training/pf_norm                      0.41194     0.04482    0.48706    0.33434
Training/qf1_norm                     175.99243   106.34617  337.48224  31.35131
Training/qf2_norm                     183.41136   111.58416  349.33478  29.20907
log_std/mean                          -0.25953    0.00014    -0.25927   -0.25974
log_std/std                           0.12406     0.00066    0.12491    0.12310
log_std/max                           -0.10713    0.00059    -0.10645   -0.10836
log_std/min                           -0.70429    0.00727    -0.69530   -0.71861
log_probs/mean                        -1.87743    0.04720    -1.80605   -1.98199
log_probs/std                         1.16246     0.01700    1.19386    1.13716
log_probs/max                         1.20881     0.16915    1.52841    0.91620
log_probs/min                         -6.73422    0.99639    -5.88592   -9.56442
mean/mean                             0.33292     0.00064    0.33413    0.33211
mean/std                              0.41608     0.00106    0.41779    0.41438
mean/max                              1.37987     0.00495    1.38656    1.36867
mean/min                              -0.55106    0.00722    -0.54070   -0.55951
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 7, 6, 9, 5, 3, 0, 2, 1, 4]
replay_buffer._size: [32400 32400 32400 32400 32400 32400 32400 32400 32400 32400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.927474737167358 0.002427339553833008
train_time 7.9312357902526855
2023-09-06 14:09:13,942 MainThread INFO: EPOCH:214
2023-09-06 14:09:13,943 MainThread INFO: Time Consumed:7.944442272186279s
2023-09-06 14:09:13,943 MainThread INFO: Total Frames:322500s
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 215/400 [15:53<23:51,  7.74s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               146.75652
Train_Epoch_Reward                    1858.95318
Running_Training_Average_Rewards      204.32608
Explore_Time                          0.00339
Train___Time                          7.93124
Eval____Time                          0.00453
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -90.93800
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.53544
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -72.00592
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.47168
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.21556
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.25556
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.63094
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2077.36360
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.71115
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.86020
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.67009     0.31404    5.20738    4.21051
alpha_0                               0.56432     0.00056    0.56519    0.56345
alpha_1                               0.53557     0.00040    0.53620    0.53494
alpha_2                               0.53746     0.00045    0.53816    0.53675
alpha_3                               0.53030     0.00045    0.53101    0.52959
alpha_4                               0.53242     0.00046    0.53315    0.53169
alpha_5                               0.53927     0.00040    0.53990    0.53865
alpha_6                               0.53575     0.00044    0.53645    0.53506
alpha_7                               0.53728     0.00046    0.53801    0.53655
alpha_8                               0.53448     0.00042    0.53514    0.53383
alpha_9                               0.53852     0.00046    0.53924    0.53781
Alpha_loss                            -3.62206    0.01851    -3.58246   -3.64640
Training/policy_loss                  -44.09493   0.14339    -43.87566  -44.34083
Training/qf1_loss                     359.88509   160.74099  660.55957  204.38345
Training/qf2_loss                     360.41439   161.76935  661.25671  202.88057
Training/pf_norm                      0.38380     0.04438    0.47314    0.31258
Training/qf1_norm                     136.76581   71.00578   252.30016  38.49550
Training/qf2_norm                     147.56364   71.69249   268.24652  48.74388
log_std/mean                          -0.26230    0.00164    -0.25979   -0.26485
log_std/std                           0.12548     0.00041    0.12603    0.12494
log_std/max                           -0.11023    0.00153    -0.10804   -0.11252
log_std/min                           -0.71455    0.00492    -0.70779   -0.72546
log_probs/mean                        -1.85058    0.02704    -1.79452   -1.89519
log_probs/std                         1.18641     0.02201    1.21954    1.14862
log_probs/max                         1.22047     0.17251    1.46808    1.04521
log_probs/min                         -6.72065    0.48369    -5.96005   -7.56143
mean/mean                             0.33797     0.00219    0.34170    0.33479
mean/std                              0.41957     0.00110    0.42105    0.41767
mean/max                              1.38236     0.00208    1.38564    1.37829
mean/min                              -0.56464    0.00681    -0.55216   -0.57475
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 9, 8, 1, 7, 4, 6, 0, 5, 2]
replay_buffer._size: [32550 32550 32550 32550 32550 32550 32550 32550 32550 32550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.546544075012207 0.0020797252655029297
train_time 7.549858331680298
2023-09-06 14:09:21,636 MainThread INFO: EPOCH:215
2023-09-06 14:09:21,636 MainThread INFO: Time Consumed:7.562716245651245s
2023-09-06 14:09:21,637 MainThread INFO: Total Frames:324000s
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 216/400 [16:01<23:40,  7.72s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               151.06763
Train_Epoch_Reward                    1927.11992
Running_Training_Average_Rewards      195.93095
Explore_Time                          0.00317
Train___Time                          7.54986
Eval____Time                          0.00475
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.65655
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.34245
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -73.19058
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.53433
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.99395
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.09036
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.83419
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1991.45120
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.94137
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.38398
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.43356     0.57014   5.31924    3.56213
alpha_0                               0.56241     0.00054   0.56326    0.56157
alpha_1                               0.53417     0.00040   0.53480    0.53354
alpha_2                               0.53589     0.00045   0.53660    0.53519
alpha_3                               0.52873     0.00045   0.52943    0.52802
alpha_4                               0.53081     0.00046   0.53153    0.53008
alpha_5                               0.53790     0.00039   0.53852    0.53729
alpha_6                               0.53421     0.00044   0.53490    0.53353
alpha_7                               0.53567     0.00046   0.53639    0.53495
alpha_8                               0.53302     0.00042   0.53368    0.53236
alpha_9                               0.53694     0.00045   0.53765    0.53623
Alpha_loss                            -3.61360    0.01851   -3.59431   -3.64840
Training/policy_loss                  -44.45515   0.12938   -44.11386  -44.60411
Training/qf1_loss                     224.55826   67.16774  395.28024  158.71909
Training/qf2_loss                     223.58152   68.32982  397.88239  155.83318
Training/pf_norm                      0.33919     0.03353   0.38470    0.27977
Training/qf1_norm                     118.76472   83.08947  289.87198  22.92867
Training/qf2_norm                     121.87041   87.76123  293.90808  30.43613
log_std/mean                          -0.26799    0.00137   -0.26545   -0.26957
log_std/std                           0.12391     0.00068   0.12475    0.12268
log_std/max                           -0.11356    0.00089   -0.11243   -0.11558
log_std/min                           -0.72420    0.00398   -0.71920   -0.73073
log_probs/mean                        -1.80835    0.02986   -1.77420   -1.87256
log_probs/std                         1.20516     0.03062   1.25994    1.16625
log_probs/max                         1.31682     0.10831   1.46157    1.12903
log_probs/min                         -6.72518    0.75545   -5.83779   -8.30803
mean/mean                             0.34779     0.00317   0.35233    0.34254
mean/std                              0.42276     0.00083   0.42398    0.42131
mean/max                              1.37407     0.00875   1.38217    1.35606
mean/min                              -0.57725    0.00522   -0.56890   -0.58711
------------------------------------  ----------  --------  ---------  ---------
sample: [4, 1, 8, 9, 3, 7, 0, 5, 2, 6]
replay_buffer._size: [32700 32700 32700 32700 32700 32700 32700 32700 32700 32700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.650747060775757 0.0019683837890625
train_time 7.653912544250488
2023-09-06 14:09:29,416 MainThread INFO: EPOCH:216
2023-09-06 14:09:29,416 MainThread INFO: Time Consumed:7.6725664138793945s
2023-09-06 14:09:29,417 MainThread INFO: Total Frames:325500s
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 217/400 [16:09<23:37,  7.75s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               142.53792
Train_Epoch_Reward                    3598.48417
Running_Training_Average_Rewards      246.15191
Explore_Time                          0.00310
Train___Time                          7.65391
Eval____Time                          0.01148
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.72829
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -26.86914
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.00000
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.81494
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.11219
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.09367
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.47911
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1812.62458
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.63618
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.97605
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.40810     0.37065    4.92670    3.65968
alpha_0                               0.56057     0.00052    0.56139    0.55975
alpha_1                               0.53277     0.00040    0.53340    0.53214
alpha_2                               0.53434     0.00045    0.53504    0.53364
alpha_3                               0.52715     0.00045    0.52786    0.52645
alpha_4                               0.52919     0.00046    0.52992    0.52847
alpha_5                               0.53654     0.00039    0.53715    0.53593
alpha_6                               0.53269     0.00044    0.53337    0.53200
alpha_7                               0.53407     0.00046    0.53479    0.53336
alpha_8                               0.53156     0.00042    0.53222    0.53090
alpha_9                               0.53536     0.00045    0.53607    0.53465
Alpha_loss                            -3.64001    0.01305    -3.61661   -3.66240
Training/policy_loss                  -44.49283   0.07608    -44.31605  -44.62017
Training/qf1_loss                     306.88334   155.95162  670.49402  139.24867
Training/qf2_loss                     306.52341   156.34598  669.84186  137.73509
Training/pf_norm                      0.36659     0.03172    0.41150    0.32129
Training/qf1_norm                     97.80587    47.56559   188.22083  29.93916
Training/qf2_norm                     105.27907   51.81713   201.41855  23.73083
log_std/mean                          -0.26984    0.00042    -0.26936   -0.27072
log_std/std                           0.12160     0.00044    0.12246    0.12100
log_std/max                           -0.11166    0.00065    -0.11053   -0.11243
log_std/min                           -0.72837    0.00695    -0.72114   -0.74111
log_probs/mean                        -1.82264    0.01650    -1.78934   -1.85025
log_probs/std                         1.21558     0.02633    1.25085    1.16552
log_probs/max                         1.30060     0.09766    1.45950    1.12128
log_probs/min                         -7.02734    0.82303    -5.60646   -8.74580
mean/mean                             0.35385     0.00050    0.35452    0.35274
mean/std                              0.42483     0.00088    0.42658    0.42377
mean/max                              1.35244     0.00913    1.36863    1.33893
mean/min                              -0.59520    0.01038    -0.57714   -0.61260
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 4, 8, 3, 0, 2, 1, 5, 7, 6]
replay_buffer._size: [32850 32850 32850 32850 32850 32850 32850 32850 32850 32850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.028525829315186 0.002045869827270508
train_time 8.03180193901062
2023-09-06 14:09:37,602 MainThread INFO: EPOCH:217
2023-09-06 14:09:37,603 MainThread INFO: Time Consumed:8.046053171157837s
2023-09-06 14:09:37,603 MainThread INFO: Total Frames:327000s
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 218/400 [16:17<23:53,  7.87s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               127.11027
Train_Epoch_Reward                    3636.03426
Running_Training_Average_Rewards      305.38795
Explore_Time                          0.00585
Train___Time                          8.03180
Eval____Time                          0.00445
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.22462
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -20.14474
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.54913
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.44459
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.93659
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.82671
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.90647
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1638.06473
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.62205
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.50016
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.29908     0.48729    5.07871    3.63411
alpha_0                               0.55877     0.00051    0.55957    0.55797
alpha_1                               0.53136     0.00041    0.53200    0.53072
alpha_2                               0.53279     0.00044    0.53349    0.53210
alpha_3                               0.52559     0.00045    0.52629    0.52488
alpha_4                               0.52759     0.00046    0.52831    0.52686
alpha_5                               0.53518     0.00039    0.53579    0.53456
alpha_6                               0.53116     0.00044    0.53184    0.53047
alpha_7                               0.53249     0.00045    0.53320    0.53178
alpha_8                               0.53010     0.00042    0.53076    0.52944
alpha_9                               0.53378     0.00045    0.53449    0.53307
Alpha_loss                            -3.64991    0.01507    -3.62548   -3.68548
Training/policy_loss                  -44.59224   0.08444    -44.44225  -44.72118
Training/qf1_loss                     313.88589   224.59979  896.42542  175.94830
Training/qf2_loss                     312.96570   226.34090  899.82098  173.80602
Training/pf_norm                      0.32884     0.02347    0.37907    0.30151
Training/qf1_norm                     110.02199   76.12677   256.62119  23.15797
Training/qf2_norm                     116.67206   79.30764   268.43042  19.39806
log_std/mean                          -0.26962    0.00110    -0.26770   -0.27082
log_std/std                           0.12050     0.00040    0.12096    0.11975
log_std/max                           -0.11064    0.00119    -0.10891   -0.11315
log_std/min                           -0.72627    0.00413    -0.71908   -0.73127
log_probs/mean                        -1.81083    0.02150    -1.77543   -1.85523
log_probs/std                         1.21486     0.02577    1.26721    1.17142
log_probs/max                         1.30975     0.16646    1.51628    0.98323
log_probs/min                         -6.87384    1.04084    -5.94592   -9.73662
mean/mean                             0.34657     0.00409    0.35221    0.33977
mean/std                              0.42895     0.00137    0.43103    0.42665
mean/max                              1.31602     0.01203    1.33649    1.29440
mean/min                              -0.63466    0.01437    -0.61281   -0.66231
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 5, 7, 3, 1, 9, 0, 4, 6, 8]
replay_buffer._size: [33000 33000 33000 33000 33000 33000 33000 33000 33000 33000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.817908525466919 0.0021533966064453125
train_time 7.821314334869385
2023-09-06 14:09:45,592 MainThread INFO: EPOCH:218
2023-09-06 14:09:45,592 MainThread INFO: Time Consumed:7.837026834487915s
2023-09-06 14:09:45,593 MainThread INFO: Total Frames:328500s
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 219/400 [16:25<23:51,  7.91s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               109.48124
Train_Epoch_Reward                    1239.70159
Running_Training_Average_Rewards      282.47400
Explore_Time                          0.00393
Train___Time                          7.82131
Eval____Time                          0.00604
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -101.54251
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -20.06366
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.40899
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.47678
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.33577
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.24742
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.74198
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1480.89250
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.13196
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.33103
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.23838     0.25989    4.65641     3.76542
alpha_0                               0.55702     0.00050    0.55780     0.55624
alpha_1                               0.52994     0.00041    0.53058     0.52930
alpha_2                               0.53124     0.00045    0.53194     0.53054
alpha_3                               0.52402     0.00045    0.52472     0.52331
alpha_4                               0.52599     0.00046    0.52670     0.52527
alpha_5                               0.53381     0.00040    0.53443     0.53319
alpha_6                               0.52963     0.00044    0.53032     0.52894
alpha_7                               0.53093     0.00045    0.53163     0.53022
alpha_8                               0.52863     0.00043    0.52929     0.52796
alpha_9                               0.53221     0.00045    0.53292     0.53150
Alpha_loss                            -3.68649    0.02415    -3.63637    -3.71243
Training/policy_loss                  -44.76042   0.10567    -44.55876   -44.90116
Training/qf1_loss                     360.13863   267.75357  1053.21204  168.07518
Training/qf2_loss                     360.25696   268.92972  1056.96265  166.73782
Training/pf_norm                      0.32589     0.02554    0.38013     0.29582
Training/qf1_norm                     78.13712    48.29783   189.29767   32.35628
Training/qf2_norm                     87.39351    51.49210   199.75804   26.82229
log_std/mean                          -0.26614    0.00096    -0.26445    -0.26762
log_std/std                           0.11848     0.00042    0.11939     0.11796
log_std/max                           -0.10952    0.00059    -0.10855    -0.11050
log_std/min                           -0.72150    0.00421    -0.71566    -0.72980
log_probs/mean                        -1.84081    0.03495    -1.77386    -1.88672
log_probs/std                         1.20341     0.02528    1.24560     1.16581
log_probs/max                         1.37987     0.13198    1.54247     1.13641
log_probs/min                         -6.60467    0.78057    -5.50023    -8.43040
mean/mean                             0.32936     0.00583    0.33805     0.31971
mean/std                              0.43253     0.00076    0.43385     0.43134
mean/max                              1.28241     0.01287    1.29891     1.26297
mean/min                              -0.67549    0.01166    -0.65853    -0.69154
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 9, 7, 3, 5, 6, 8, 1, 2, 0]
replay_buffer._size: [33150 33150 33150 33150 33150 33150 33150 33150 33150 33150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.573965787887573 0.002041339874267578
train_time 7.577210903167725
2023-09-06 14:09:53,318 MainThread INFO: EPOCH:219
2023-09-06 14:09:53,319 MainThread INFO: Time Consumed:7.591627597808838s
2023-09-06 14:09:53,319 MainThread INFO: Total Frames:330000s
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 220/400 [16:32<23:34,  7.86s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               94.70802
Train_Epoch_Reward                    927.89885
Running_Training_Average_Rewards      193.45449
Explore_Time                          0.00385
Train___Time                          7.57721
Eval____Time                          0.00647
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.86543
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -20.69007
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.72132
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.37456
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.40685
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.44064
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.83721
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1372.25835
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.05489
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.14896
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.32723     0.36887    4.82921    3.67364
alpha_0                               0.55531     0.00049    0.55607    0.55454
alpha_1                               0.52851     0.00041    0.52916    0.52786
alpha_2                               0.52968     0.00045    0.53039    0.52898
alpha_3                               0.52245     0.00045    0.52316    0.52175
alpha_4                               0.52439     0.00046    0.52511    0.52367
alpha_5                               0.53242     0.00040    0.53305    0.53178
alpha_6                               0.52810     0.00044    0.52879    0.52741
alpha_7                               0.52937     0.00044    0.53007    0.52867
alpha_8                               0.52714     0.00043    0.52781    0.52647
alpha_9                               0.53064     0.00045    0.53135    0.52994
Alpha_loss                            -3.72260    0.01719    -3.69785   -3.75998
Training/policy_loss                  -45.07295   0.06033    -44.98769  -45.15989
Training/qf1_loss                     415.15150   160.65303  677.18933  167.66661
Training/qf2_loss                     413.77609   161.22555  679.18860  167.83188
Training/pf_norm                      0.39291     0.03785    0.45463    0.33559
Training/qf1_norm                     113.72833   52.95105   211.68756  53.97612
Training/qf2_norm                     120.31245   56.66810   223.38719  44.69640
log_std/mean                          -0.26207    0.00115    -0.26024   -0.26373
log_std/std                           0.11990     0.00101    0.12170    0.11843
log_std/max                           -0.10700    0.00113    -0.10564   -0.10901
log_std/min                           -0.72626    0.00585    -0.71980   -0.73749
log_probs/mean                        -1.87101    0.02170    -1.83734   -1.91886
log_probs/std                         1.17231     0.02220    1.21019    1.13591
log_probs/max                         1.20336     0.17592    1.49390    0.93300
log_probs/min                         -6.81757    0.47542    -5.93756   -7.70492
mean/mean                             0.30602     0.00712    0.31724    0.29498
mean/std                              0.43400     0.00036    0.43471    0.43341
mean/max                              1.25072     0.00901    1.26197    1.23382
mean/min                              -0.69765    0.00954    -0.67925   -0.70911
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 4, 8, 0, 7, 2, 3, 9, 5, 1]
replay_buffer._size: [33300 33300 33300 33300 33300 33300 33300 33300 33300 33300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.711118459701538 0.0021114349365234375
train_time 4.714574337005615
2023-09-06 14:10:01,016 MainThread INFO: EPOCH:220
2023-09-06 14:10:01,017 MainThread INFO: Time Consumed:7.557439565658569s
2023-09-06 14:10:01,017 MainThread INFO: Total Frames:331500s
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 221/400 [16:40<23:18,  7.81s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               84.22227
Train_Epoch_Reward                    3183.40242
Running_Training_Average_Rewards      178.36676
Explore_Time                          2.83433
Train___Time                          4.71457
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.65513
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -18.87593
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.54011
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.24870
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.03669
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.28849
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.18876
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1315.78733
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.97665
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.63956
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.42895     0.36924    5.15583    3.97406
alpha_0                               0.55362     0.00049    0.55438    0.55285
alpha_1                               0.52705     0.00042    0.52771    0.52639
alpha_2                               0.52812     0.00045    0.52882    0.52741
alpha_3                               0.52088     0.00045    0.52159    0.52018
alpha_4                               0.52279     0.00046    0.52351    0.52208
alpha_5                               0.53100     0.00041    0.53164    0.53036
alpha_6                               0.52657     0.00044    0.52726    0.52589
alpha_7                               0.52782     0.00044    0.52852    0.52712
alpha_8                               0.52565     0.00043    0.52632    0.52499
alpha_9                               0.52908     0.00045    0.52978    0.52837
Alpha_loss                            -3.76860    0.02382    -3.72223   -3.81082
Training/policy_loss                  -45.27713   0.09866    -45.14349  -45.41558
Training/qf1_loss                     384.48887   237.65677  744.92993  149.46036
Training/qf2_loss                     383.49050   238.22418  743.60144  148.84949
Training/pf_norm                      0.35416     0.03297    0.42402    0.29420
Training/qf1_norm                     118.62710   81.59288   287.25595  32.18962
Training/qf2_norm                     130.41504   82.86986   300.80792  38.47563
log_std/mean                          -0.25850    0.00060    -0.25772   -0.25953
log_std/std                           0.12391     0.00092    0.12532    0.12236
log_std/max                           -0.10472    0.00088    -0.10330   -0.10603
log_std/min                           -0.73076    0.00567    -0.72250   -0.74115
log_probs/mean                        -1.91684    0.03453    -1.84991   -1.98112
log_probs/std                         1.16308     0.02630    1.21141    1.12462
log_probs/max                         1.08619     0.11595    1.23663    0.80621
log_probs/min                         -6.82960    0.67316    -5.87710   -8.05307
mean/mean                             0.28253     0.00615    0.29246    0.27309
mean/std                              0.43453     0.00064    0.43574    0.43355
mean/max                              1.24433     0.00513    1.25169    1.23690
mean/min                              -0.72982    0.01328    -0.71094   -0.75566
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 6, 9, 1, 4, 8, 2, 5, 7, 3]
replay_buffer._size: [33450 33450 33450 33450 33450 33450 33450 33450 33450 33450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.32742714881897 0.0019998550415039062
train_time 4.330694198608398
2023-09-06 14:10:08,889 MainThread INFO: EPOCH:221
2023-09-06 14:10:08,890 MainThread INFO: Time Consumed:4.345470190048218s
2023-09-06 14:10:08,891 MainThread INFO: Total Frames:333000s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 222/400 [16:48<23:13,  7.83s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               78.71112
Train_Epoch_Reward                    1496.84498
Running_Training_Average_Rewards      186.93821
Explore_Time                          0.00521
Train___Time                          4.33069
Eval____Time                          0.00498
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.12237
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -23.67011
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.66794
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.72242
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.79251
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.15471
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.72215
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1288.68173
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.25633
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.29531
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.54585     0.32724    5.36507    4.11970
alpha_0                               0.55192     0.00049    0.55268    0.55115
alpha_1                               0.52558     0.00042    0.52624    0.52492
alpha_2                               0.52654     0.00045    0.52725    0.52583
alpha_3                               0.51931     0.00045    0.52002    0.51860
alpha_4                               0.52120     0.00046    0.52192    0.52047
alpha_5                               0.52957     0.00041    0.53021    0.52892
alpha_6                               0.52505     0.00044    0.52574    0.52436
alpha_7                               0.52627     0.00045    0.52697    0.52557
alpha_8                               0.52417     0.00042    0.52484    0.52351
alpha_9                               0.52751     0.00045    0.52821    0.52680
Alpha_loss                            -3.80281    0.01917    -3.76658   -3.82844
Training/policy_loss                  -45.66695   0.15929    -45.44876  -45.92094
Training/qf1_loss                     267.87226   126.45252  620.81256  193.64262
Training/qf2_loss                     266.16643   126.64283  620.06818  190.73184
Training/pf_norm                      0.32184     0.04394    0.44142    0.28231
Training/qf1_norm                     117.77375   78.23677   323.89441  22.50454
Training/qf2_norm                     128.68163   79.86927   335.45728  30.05147
log_std/mean                          -0.25961    0.00071    -0.25853   -0.26065
log_std/std                           0.12675     0.00038    0.12713    0.12590
log_std/max                           -0.10483    0.00067    -0.10382   -0.10582
log_std/min                           -0.74277    0.00462    -0.73253   -0.74730
log_probs/mean                        -1.94326    0.02830    -1.89954   -1.99327
log_probs/std                         1.14403     0.02364    1.18686    1.10961
log_probs/max                         0.98865     0.08850    1.19461    0.89631
log_probs/min                         -7.25403    0.78986    -5.95760   -8.48418
mean/mean                             0.26330     0.00489    0.27138    0.25603
mean/std                              0.43844     0.00155    0.44049    0.43598
mean/max                              1.25578     0.00846    1.26788    1.23943
mean/min                              -0.75952    0.00797    -0.74394   -0.77346
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 6, 5, 1, 9, 0, 4, 7, 8, 2]
replay_buffer._size: [33600 33600 33600 33600 33600 33600 33600 33600 33600 33600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.198957920074463 0.0019807815551757812
train_time 4.202229022979736
2023-09-06 14:10:16,747 MainThread INFO: EPOCH:222
2023-09-06 14:10:16,747 MainThread INFO: Time Consumed:4.219678640365601s
2023-09-06 14:10:16,748 MainThread INFO: Total Frames:334500s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 223/400 [16:56<23:05,  7.83s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               151.07177
Train_Epoch_Reward                    221.39567
Running_Training_Average_Rewards      163.38810
Explore_Time                          0.00575
Train___Time                          4.20223
Eval____Time                          0.00754
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.51884
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -25.46941
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.56240
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2203.40608
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.99208
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.67715
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.16382
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1282.75657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.40100
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.84002
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.09471     0.31974   4.79241    3.70346
alpha_0                               0.55022     0.00049   0.55098    0.54946
alpha_1                               0.52410     0.00043   0.52477    0.52343
alpha_2                               0.52496     0.00045   0.52567    0.52425
alpha_3                               0.51773     0.00045   0.51844    0.51703
alpha_4                               0.51959     0.00046   0.52031    0.51888
alpha_5                               0.52813     0.00041   0.52878    0.52748
alpha_6                               0.52352     0.00044   0.52421    0.52283
alpha_7                               0.52471     0.00045   0.52541    0.52401
alpha_8                               0.52270     0.00042   0.52336    0.52204
alpha_9                               0.52595     0.00045   0.52665    0.52524
Alpha_loss                            -3.82252    0.01833   -3.79835   -3.85146
Training/policy_loss                  -45.88809   0.09541   -45.69640  -46.00315
Training/qf1_loss                     240.41157   91.32307  446.97665  143.08029
Training/qf2_loss                     237.79395   91.29481  443.71680  139.64761
Training/pf_norm                      0.37899     0.04149   0.45318    0.32268
Training/qf1_norm                     71.48598    35.81239  154.47910  34.29746
Training/qf2_norm                     69.77635    38.44481  161.79298  31.47369
log_std/mean                          -0.26167    0.00050   -0.26092   -0.26241
log_std/std                           0.12673     0.00022   0.12706    0.12629
log_std/max                           -0.10367    0.00097   -0.10197   -0.10521
log_std/min                           -0.74947    0.00709   -0.74072   -0.75919
log_probs/mean                        -1.94631    0.02202   -1.91865   -1.98684
log_probs/std                         1.12877     0.02102   1.16273    1.10019
log_probs/max                         0.90367     0.12090   1.11551    0.72507
log_probs/min                         -6.96216    0.66225   -5.97251   -8.29626
mean/mean                             0.24344     0.00714   0.25418    0.23190
mean/std                              0.44067     0.00036   0.44128    0.44000
mean/max                              1.24549     0.01442   1.26751    1.22283
mean/min                              -0.77016    0.00836   -0.75997   -0.78688
------------------------------------  ----------  --------  ---------  ---------
sample: [1, 6, 9, 0, 8, 4, 7, 3, 5, 2]
replay_buffer._size: [33750 33750 33750 33750 33750 33750 33750 33750 33750 33750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.8987321853637695 0.001994609832763672
train_time 7.901989698410034
2023-09-06 14:10:24,765 MainThread INFO: EPOCH:223
2023-09-06 14:10:24,766 MainThread INFO: Time Consumed:7.912362098693848s
2023-09-06 14:10:24,766 MainThread INFO: Total Frames:336000s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 224/400 [17:04<23:08,  7.89s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               226.87278
Train_Epoch_Reward                    1856.57850
Running_Training_Average_Rewards      119.16064
Explore_Time                          0.00272
Train___Time                          7.90199
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.23571
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.02724
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.57816
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2222.08674
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.43960
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.53398
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.06989
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1293.23682
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.11923
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.95208
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.19696     0.29914   4.86360    3.73929
alpha_0                               0.54852     0.00049   0.54929    0.54775
alpha_1                               0.52261     0.00043   0.52328    0.52194
alpha_2                               0.52338     0.00046   0.52409    0.52266
alpha_3                               0.51616     0.00045   0.51687    0.51546
alpha_4                               0.51800     0.00046   0.51872    0.51728
alpha_5                               0.52668     0.00042   0.52734    0.52602
alpha_6                               0.52198     0.00044   0.52267    0.52129
alpha_7                               0.52316     0.00044   0.52386    0.52247
alpha_8                               0.52124     0.00042   0.52189    0.52058
alpha_9                               0.52438     0.00045   0.52509    0.52368
Alpha_loss                            -3.85912    0.01824   -3.82538   -3.88621
Training/policy_loss                  -45.79858   0.10346   -45.67503  -46.00973
Training/qf1_loss                     247.69417   70.11866  392.54114  173.91602
Training/qf2_loss                     244.61880   70.79955  390.05829  171.95599
Training/pf_norm                      0.33552     0.03020   0.37845    0.28140
Training/qf1_norm                     73.25045    60.22061  221.94821  11.65326
Training/qf2_norm                     78.05954    61.18316  223.68779  21.20337
log_std/mean                          -0.26233    0.00062   -0.26111   -0.26301
log_std/std                           0.12745     0.00016   0.12772    0.12722
log_std/max                           -0.10069    0.00120   -0.09902   -0.10242
log_std/min                           -0.76144    0.00495   -0.75341   -0.76678
log_probs/mean                        -1.97720    0.02644   -1.92874   -2.01892
log_probs/std                         1.09762     0.02436   1.14435    1.06267
log_probs/max                         0.80077     0.13076   0.96345    0.58307
log_probs/min                         -7.32491    1.11572   -5.85577   -10.16624
mean/mean                             0.21838     0.00704   0.22953    0.20763
mean/std                              0.44222     0.00056   0.44312    0.44133
mean/max                              1.19499     0.01572   1.22011    1.16841
mean/min                              -0.83286    0.02658   -0.79293   -0.88296
------------------------------------  ----------  --------  ---------  ---------
sample: [2, 7, 1, 8, 0, 4, 3, 9, 5, 6]
replay_buffer._size: [33900 33900 33900 33900 33900 33900 33900 33900 33900 33900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.414584159851074 0.002058267593383789
train_time 4.417932748794556
2023-09-06 14:10:32,571 MainThread INFO: EPOCH:224
2023-09-06 14:10:32,572 MainThread INFO: Time Consumed:7.673714876174927s
2023-09-06 14:10:32,572 MainThread INFO: Total Frames:337500s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 225/400 [17:12<22:57,  7.87s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               306.26791
Train_Epoch_Reward                    1308.31908
Running_Training_Average_Rewards      112.87644
Explore_Time                          3.24636
Train___Time                          4.41793
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.63272
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.94551
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -73.46525
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2238.12530
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.14540
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -58.23938
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.18556
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1368.62069
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.39948
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.60092
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.14765     0.27124   4.66804    3.84972
alpha_0                               0.54680     0.00050   0.54758    0.54602
alpha_1                               0.52112     0.00043   0.52179    0.52044
alpha_2                               0.52179     0.00046   0.52250    0.52107
alpha_3                               0.51460     0.00045   0.51530    0.51390
alpha_4                               0.51642     0.00045   0.51713    0.51570
alpha_5                               0.52521     0.00042   0.52588    0.52455
alpha_6                               0.52043     0.00045   0.52113    0.51972
alpha_7                               0.52162     0.00044   0.52231    0.52094
alpha_8                               0.51978     0.00042   0.52043    0.51912
alpha_9                               0.52281     0.00045   0.52352    0.52211
Alpha_loss                            -3.89366    0.02238   -3.85991   -3.93226
Training/policy_loss                  -45.94637   0.11677   -45.71909  -46.10361
Training/qf1_loss                     237.92149   68.94271  392.97693  168.56256
Training/qf2_loss                     235.81350   69.44131  392.35220  169.72299
Training/pf_norm                      0.33356     0.03416   0.40454    0.28250
Training/qf1_norm                     70.49850    52.22330  175.16194  20.58617
Training/qf2_norm                     74.48068    55.21959  180.55939  16.48068
log_std/mean                          -0.25849    0.00155   -0.25592   -0.26077
log_std/std                           0.12631     0.00078   0.12734    0.12511
log_std/max                           -0.09923    0.00063   -0.09798   -0.10017
log_std/min                           -0.76386    0.00466   -0.75747   -0.77360
log_probs/mean                        -2.00374    0.03050   -1.96004   -2.05337
log_probs/std                         1.08234     0.02039   1.12709    1.05470
log_probs/max                         0.84521     0.13515   1.10385    0.64093
log_probs/min                         -6.70233    0.94824   -5.53076   -8.76974
mean/mean                             0.19461     0.00682   0.20525    0.18397
mean/std                              0.44244     0.00030   0.44297    0.44204
mean/max                              1.14285     0.01682   1.16559    1.11417
mean/min                              -0.91502    0.02578   -0.87370   -0.94760
------------------------------------  ----------  --------  ---------  ---------
sample: [1, 7, 8, 2, 3, 5, 9, 0, 6, 4]
replay_buffer._size: [34050 34050 34050 34050 34050 34050 34050 34050 34050 34050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.133164644241333 0.0019221305847167969
train_time 4.136284351348877
2023-09-06 14:10:40,529 MainThread INFO: EPOCH:225
2023-09-06 14:10:40,530 MainThread INFO: Time Consumed:4.254626274108887s
2023-09-06 14:10:40,530 MainThread INFO: Total Frames:339000s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 226/400 [17:20<22:53,  7.89s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               313.37701
Train_Epoch_Reward                    3311.17442
Running_Training_Average_Rewards      215.86907
Explore_Time                          0.10593
Train___Time                          4.13628
Eval____Time                          0.00576
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -90.83431
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.77874
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -72.52106
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2205.46651
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.00133
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.23568
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.64344
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1463.89660
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.55057
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.98698
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.49391     0.39906    5.06282     3.64723
alpha_0                               0.54506     0.00050    0.54585     0.54427
alpha_1                               0.51962     0.00043    0.52029     0.51894
alpha_2                               0.52020     0.00046    0.52091     0.51948
alpha_3                               0.51305     0.00044    0.51375     0.51236
alpha_4                               0.51484     0.00045    0.51555     0.51413
alpha_5                               0.52373     0.00043    0.52440     0.52306
alpha_6                               0.51885     0.00046    0.51957     0.51814
alpha_7                               0.52011     0.00043    0.52079     0.51943
alpha_8                               0.51833     0.00041    0.51898     0.51768
alpha_9                               0.52125     0.00045    0.52195     0.52054
Alpha_loss                            -3.92897    0.02865    -3.88153    -3.97298
Training/policy_loss                  -46.28769   0.12105    -46.07300   -46.47912
Training/qf1_loss                     413.60394   295.26616  1191.09131  181.02469
Training/qf2_loss                     411.55876   295.69709  1188.36475  179.43364
Training/pf_norm                      0.32920     0.03995    0.42566     0.28074
Training/qf1_norm                     153.03587   75.00060   273.45627   53.06514
Training/qf2_norm                     159.71070   77.41721   278.86676   61.56667
log_std/mean                          -0.25287    0.00173    -0.24994    -0.25537
log_std/std                           0.12352     0.00102    0.12489     0.12159
log_std/max                           -0.09743    0.00102    -0.09593    -0.09911
log_std/min                           -0.75468    0.00626    -0.74386    -0.76199
log_probs/mean                        -2.03118    0.04137    -1.95849    -2.09323
log_probs/std                         1.06343     0.01801    1.09593     1.03801
log_probs/max                         0.80429     0.12375    1.01494     0.61393
log_probs/min                         -6.64296    0.85269    -5.48770    -8.67817
mean/mean                             0.17042     0.00705    0.18154     0.15967
mean/std                              0.44143     0.00054    0.44212     0.44030
mean/max                              1.08286     0.01507    1.10828     1.06139
mean/min                              -0.99126    0.02496    -0.95038    -1.02416
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 8, 3, 9, 5, 1, 2, 4, 7, 6]
replay_buffer._size: [34200 34200 34200 34200 34200 34200 34200 34200 34200 34200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.554362773895264 0.0020127296447753906
train_time 5.557640075683594
2023-09-06 14:10:49,671 MainThread INFO: EPOCH:226
2023-09-06 14:10:49,672 MainThread INFO: Time Consumed:5.575008153915405s
2023-09-06 14:10:49,672 MainThread INFO: Total Frames:340500s
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 227/400 [17:29<23:51,  8.28s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               252.58295
Train_Epoch_Reward                    3168.46789
Running_Training_Average_Rewards      259.59871
Explore_Time                          0.00628
Train___Time                          5.55764
Eval____Time                          0.00488
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.51164
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.41485
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.64162
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           99.99769
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.70879
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.13736
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.20664
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1582.32898
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.46281
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.69729
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.40686     0.39797    5.18810    3.87187
alpha_0                               0.54330     0.00051    0.54410    0.54249
alpha_1                               0.51810     0.00044    0.51879    0.51742
alpha_2                               0.51859     0.00046    0.51932    0.51787
alpha_3                               0.51151     0.00044    0.51220    0.51082
alpha_4                               0.51327     0.00045    0.51397    0.51257
alpha_5                               0.52224     0.00043    0.52291    0.52157
alpha_6                               0.51726     0.00046    0.51798    0.51654
alpha_7                               0.51860     0.00043    0.51928    0.51793
alpha_8                               0.51689     0.00041    0.51753    0.51624
alpha_9                               0.51968     0.00045    0.52039    0.51897
Alpha_loss                            -3.96352    0.01369    -3.93708   -3.98209
Training/policy_loss                  -46.62186   0.10219    -46.45871  -46.82467
Training/qf1_loss                     308.17352   171.87347  717.53992  188.34328
Training/qf2_loss                     306.08731   171.76353  715.88391  187.04312
Training/pf_norm                      0.30528     0.04191    0.38215    0.23211
Training/qf1_norm                     121.37489   88.69063   303.83383  29.85160
Training/qf2_norm                     124.95167   87.54684   310.22031  31.36676
log_std/mean                          -0.24609    0.00172    -0.24390   -0.24912
log_std/std                           0.11920     0.00130    0.12107    0.11708
log_std/max                           -0.09332    0.00108    -0.09180   -0.09497
log_std/min                           -0.73168    0.00659    -0.72046   -0.74021
log_probs/mean                        -2.05761    0.02006    -2.02560   -2.09380
log_probs/std                         1.04005     0.01678    1.07272    1.01887
log_probs/max                         0.85225     0.25683    1.36196    0.50042
log_probs/min                         -6.93749    1.20808    -5.74851   -10.37821
mean/mean                             0.14733     0.00651    0.15758    0.13733
mean/std                              0.43849     0.00120    0.44046    0.43664
mean/max                              1.04294     0.00873    1.05845    1.02810
mean/min                              -1.04243    0.01240    -1.01996   -1.06048
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 3, 0, 5, 1, 6, 2, 9, 4, 7]
replay_buffer._size: [34350 34350 34350 34350 34350 34350 34350 34350 34350 34350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.069082975387573 0.0019795894622802734
train_time 4.072300672531128
2023-09-06 14:10:57,554 MainThread INFO: EPOCH:227
2023-09-06 14:10:57,554 MainThread INFO: Time Consumed:4.084670543670654s
2023-09-06 14:10:57,555 MainThread INFO: Total Frames:342000s
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 228/400 [17:37<23:20,  8.14s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               190.12682
Train_Epoch_Reward                    1878.36976
Running_Training_Average_Rewards      278.60040
Explore_Time                          0.00399
Train___Time                          4.07230
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.23915
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.77631
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.77132
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.80337
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.42192
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.83591
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.92215
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1742.65353
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.87141
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.56398
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.20192     0.30106    4.46281    3.43106
alpha_0                               0.54150     0.00052    0.54231    0.54069
alpha_1                               0.51657     0.00044    0.51726    0.51588
alpha_2                               0.51698     0.00047    0.51771    0.51625
alpha_3                               0.50998     0.00044    0.51067    0.50930
alpha_4                               0.51171     0.00045    0.51241    0.51101
alpha_5                               0.52074     0.00043    0.52142    0.52006
alpha_6                               0.51566     0.00046    0.51638    0.51494
alpha_7                               0.51711     0.00043    0.51778    0.51645
alpha_8                               0.51545     0.00042    0.51610    0.51480
alpha_9                               0.51811     0.00045    0.51882    0.51740
Alpha_loss                            -4.00560    0.02333    -3.97034   -4.05016
Training/policy_loss                  -46.72278   0.08613    -46.53228  -46.81382
Training/qf1_loss                     277.52137   160.88920  646.17566  155.91911
Training/qf2_loss                     274.93207   162.04506  645.69495  152.75273
Training/pf_norm                      0.29447     0.03398    0.34245    0.23386
Training/qf1_norm                     92.28847    40.85179   135.74718  23.25106
Training/qf2_norm                     98.13500    41.98207   144.56044  22.99452
log_std/mean                          -0.24269    0.00072    -0.24180   -0.24392
log_std/std                           0.11561     0.00057    0.11671    0.11500
log_std/max                           -0.09083    0.00071    -0.09003   -0.09225
log_std/min                           -0.71261    0.00842    -0.70245   -0.73229
log_probs/mean                        -2.09375    0.03112    -2.05342   -2.15203
log_probs/std                         1.02659     0.02740    1.07281    0.98473
log_probs/max                         0.61832     0.18790    1.01360    0.40064
log_probs/min                         -7.49480    1.07142    -5.78542   -9.05385
mean/mean                             0.12703     0.00535    0.13524    0.11862
mean/std                              0.43501     0.00088    0.43664    0.43394
mean/max                              1.02045     0.00476    1.02796    1.01185
mean/min                              -1.06163    0.01296    -1.03767   -1.08117
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 5, 3, 1, 0, 2, 9, 6, 4, 7]
replay_buffer._size: [34500 34500 34500 34500 34500 34500 34500 34500 34500 34500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.09593152999878 0.0020308494567871094
train_time 8.099209308624268
2023-09-06 14:11:05,775 MainThread INFO: EPOCH:228
2023-09-06 14:11:05,775 MainThread INFO: Time Consumed:8.109273195266724s
2023-09-06 14:11:05,775 MainThread INFO: Total Frames:343500s
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 229/400 [17:45<23:16,  8.17s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               129.66723
Train_Epoch_Reward                    2610.28620
Running_Training_Average_Rewards      255.23746
Explore_Time                          0.00366
Train___Time                          8.09921
Eval____Time                          0.00251
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.12685
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.12281
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.14173
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.74028
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.32587
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.21898
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.01762
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1864.86081
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.01563
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.12773
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.29214     0.69189    5.68815     3.49415
alpha_0                               0.53971     0.00051    0.54051     0.53890
alpha_1                               0.51504     0.00044    0.51573     0.51435
alpha_2                               0.51536     0.00046    0.51608     0.51463
alpha_3                               0.50846     0.00044    0.50915     0.50778
alpha_4                               0.51016     0.00044    0.51086     0.50947
alpha_5                               0.51923     0.00044    0.51991     0.51854
alpha_6                               0.51406     0.00046    0.51478     0.51334
alpha_7                               0.51562     0.00043    0.51630     0.51496
alpha_8                               0.51399     0.00042    0.51465     0.51333
alpha_9                               0.51654     0.00045    0.51725     0.51583
Alpha_loss                            -4.04027    0.01090    -4.02636    -4.06427
Training/policy_loss                  -46.94972   0.11685    -46.80503   -47.20795
Training/qf1_loss                     306.92640   284.90180  1104.38733  139.12694
Training/qf2_loss                     304.64287   286.80625  1107.03809  135.47960
Training/pf_norm                      0.24904     0.02292    0.28063     0.20040
Training/qf1_norm                     141.53165   128.82295  437.05609   21.70015
Training/qf2_norm                     140.40783   131.46978  436.24622   16.18815
log_std/mean                          -0.24201    0.00046    -0.24142    -0.24280
log_std/std                           0.11580     0.00038    0.11647     0.11535
log_std/max                           -0.09252    0.00153    -0.09048    -0.09460
log_std/min                           -0.70697    0.00497    -0.70216    -0.71924
log_probs/mean                        -2.11810    0.01794    -2.09776    -2.15266
log_probs/std                         1.02038     0.02693    1.09110     0.97980
log_probs/max                         0.63374     0.16172    0.94915     0.40715
log_probs/min                         -6.83682    1.19992    -5.61391    -9.94498
mean/mean                             0.10970     0.00430    0.11719     0.10335
mean/std                              0.43513     0.00086    0.43631     0.43397
mean/max                              1.01408     0.00789    1.02500     1.00236
mean/min                              -1.09277    0.01274    -1.06670    -1.11169
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 0, 3, 2, 9, 1, 4, 8, 6, 5]
replay_buffer._size: [34650 34650 34650 34650 34650 34650 34650 34650 34650 34650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.7844672203063965 0.0020313262939453125
train_time 7.787757158279419
2023-09-06 14:11:13,697 MainThread INFO: EPOCH:229
2023-09-06 14:11:13,697 MainThread INFO: Time Consumed:7.812368392944336s
2023-09-06 14:11:13,698 MainThread INFO: Total Frames:345000s
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 230/400 [17:53<22:56,  8.10s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               137.42526
Train_Epoch_Reward                    3045.39286
Running_Training_Average_Rewards      251.13496
Explore_Time                          0.00601
Train___Time                          7.78776
Eval____Time                          0.01423
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.47071
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.10174
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.71465
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.91554
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.76845
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.29004
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.06504
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1930.37859
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.47882
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.28698
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.95116     0.48980   4.81129    3.13623
alpha_0                               0.53792     0.00051   0.53873    0.53712
alpha_1                               0.51350     0.00044   0.51419    0.51280
alpha_2                               0.51374     0.00046   0.51447    0.51301
alpha_3                               0.50695     0.00043   0.50763    0.50628
alpha_4                               0.50862     0.00044   0.50931    0.50793
alpha_5                               0.51770     0.00044   0.51839    0.51701
alpha_6                               0.51246     0.00046   0.51318    0.51174
alpha_7                               0.51414     0.00042   0.51481    0.51348
alpha_8                               0.51253     0.00042   0.51319    0.51186
alpha_9                               0.51496     0.00045   0.51567    0.51425
Alpha_loss                            -4.05501    0.01685   -4.03523   -4.08177
Training/policy_loss                  -46.97887   0.09668   -46.81544  -47.15911
Training/qf1_loss                     243.76333   77.40466  376.06070  142.08931
Training/qf2_loss                     240.65611   76.77608  371.67047  139.91655
Training/pf_norm                      0.27353     0.03578   0.36844    0.23766
Training/qf1_norm                     99.08431    62.35320  195.95569  23.81908
Training/qf2_norm                     100.37624   63.12851  203.44496  29.42875
log_std/mean                          -0.24401    0.00074   -0.24308   -0.24534
log_std/std                           0.11712     0.00025   0.11740    0.11671
log_std/max                           -0.09735    0.00153   -0.09519   -0.09949
log_std/min                           -0.71180    0.00254   -0.70902   -0.71631
log_probs/mean                        -2.11293    0.02085   -2.08698   -2.14551
log_probs/std                         1.00839     0.02586   1.04042    0.96816
log_probs/max                         0.69089     0.16176   0.99801    0.47003
log_probs/min                         -7.10793    1.12526   -6.05085   -9.30103
mean/mean                             0.09748     0.00250   0.10205    0.09429
mean/std                              0.43764     0.00061   0.43895    0.43694
mean/max                              0.99971     0.00591   1.01185    0.99243
mean/min                              -1.11699    0.00993   -1.10066   -1.13222
------------------------------------  ----------  --------  ---------  ---------
sample: [5, 9, 0, 6, 8, 7, 1, 3, 4, 2]
replay_buffer._size: [34800 34800 34800 34800 34800 34800 34800 34800 34800 34800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.123125314712524 0.0020041465759277344
train_time 8.126362085342407
2023-09-06 14:11:21,973 MainThread INFO: EPOCH:230
2023-09-06 14:11:21,973 MainThread INFO: Time Consumed:8.144448280334473s
2023-09-06 14:11:21,974 MainThread INFO: Total Frames:346500s
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 231/400 [18:01<22:56,  8.15s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               143.50489
Train_Epoch_Reward                    3648.22880
Running_Training_Average_Rewards      310.13026
Explore_Time                          0.00302
Train___Time                          8.12636
Eval____Time                          0.01042
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.51269
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.60680
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.45164
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.52118
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.66172
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.44102
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.46577
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1916.89769
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.08085
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.31912
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.29787     0.38896    4.76279    3.33847
alpha_0                               0.53614     0.00051    0.53694    0.53534
alpha_1                               0.51195     0.00044    0.51265    0.51126
alpha_2                               0.51213     0.00046    0.51285    0.51140
alpha_3                               0.50546     0.00043    0.50613    0.50479
alpha_4                               0.50709     0.00044    0.50777    0.50640
alpha_5                               0.51617     0.00044    0.51686    0.51548
alpha_6                               0.51086     0.00046    0.51158    0.51014
alpha_7                               0.51267     0.00042    0.51333    0.51201
alpha_8                               0.51106     0.00042    0.51172    0.51040
alpha_9                               0.51338     0.00045    0.51409    0.51268
Alpha_loss                            -4.06275    0.02251    -4.02096   -4.10590
Training/policy_loss                  -47.09324   0.12955    -46.82016  -47.22726
Training/qf1_loss                     333.51357   163.59986  603.59216  131.95383
Training/qf2_loss                     330.51920   163.02385  598.53558  129.39761
Training/pf_norm                      0.29792     0.03612    0.36276    0.24331
Training/qf1_norm                     151.70223   50.75563   239.44539  100.10863
Training/qf2_norm                     158.49000   54.50550   253.76263  94.28381
log_std/mean                          -0.24881    0.00188    -0.24574   -0.25156
log_std/std                           0.11705     0.00044    0.11753    0.11633
log_std/max                           -0.10206    0.00106    -0.09994   -0.10318
log_std/min                           -0.71806    0.00399    -0.71243   -0.72654
log_probs/mean                        -2.09641    0.03399    -2.04382   -2.17398
log_probs/std                         1.00801     0.02006    1.04661    0.97992
log_probs/max                         0.58575     0.11528    0.78508    0.40705
log_probs/min                         -6.70319    0.73311    -5.65424   -8.29120
mean/mean                             0.09647     0.00188    0.09996    0.09425
mean/std                              0.43927     0.00057    0.44004    0.43819
mean/max                              0.98358     0.00657    0.99416    0.97063
mean/min                              -1.14498    0.00825    -1.13302   -1.16380
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 5, 1, 0, 3, 6, 7, 4, 8, 9]
replay_buffer._size: [34950 34950 34950 34950 34950 34950 34950 34950 34950 34950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.670360326766968 0.0020058155059814453
train_time 7.6736085414886475
2023-09-06 14:11:29,792 MainThread INFO: EPOCH:231
2023-09-06 14:11:29,792 MainThread INFO: Time Consumed:7.694786787033081s
2023-09-06 14:11:29,792 MainThread INFO: Total Frames:348000s
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 232/400 [18:09<22:31,  8.05s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               144.55073
Train_Epoch_Reward                    1820.14701
Running_Training_Average_Rewards      283.79229
Explore_Time                          0.00870
Train___Time                          7.67361
Eval____Time                          0.00579
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.73562
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.56812
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.29637
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.65455
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.14746
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.99780
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.40394
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1901.49819
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.06736
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.22875
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.25457     0.43027    4.70917    3.41680
alpha_0                               0.53437     0.00051    0.53516    0.53357
alpha_1                               0.51041     0.00044    0.51110    0.50972
alpha_2                               0.51052     0.00046    0.51124    0.50980
alpha_3                               0.50398     0.00042    0.50464    0.50331
alpha_4                               0.50556     0.00044    0.50625    0.50488
alpha_5                               0.51464     0.00044    0.51533    0.51395
alpha_6                               0.50926     0.00046    0.50998    0.50854
alpha_7                               0.51121     0.00042    0.51186    0.51055
alpha_8                               0.50959     0.00042    0.51025    0.50893
alpha_9                               0.51182     0.00045    0.51252    0.51111
Alpha_loss                            -4.07937    0.01556    -4.06171   -4.11217
Training/policy_loss                  -47.43274   0.14997    -47.25312  -47.65753
Training/qf1_loss                     330.54472   162.40143  614.21625  184.92326
Training/qf2_loss                     328.70945   163.59343  615.59241  179.70958
Training/pf_norm                      0.31059     0.04785    0.39730    0.22102
Training/qf1_norm                     143.77738   73.33023   233.15469  21.85994
Training/qf2_norm                     147.16130   76.91610   236.52150  18.21435
log_std/mean                          -0.25182    0.00019    -0.25148   -0.25213
log_std/std                           0.11614     0.00032    0.11650    0.11542
log_std/max                           -0.10383    0.00030    -0.10332   -0.10422
log_std/min                           -0.71779    0.00547    -0.70938   -0.72992
log_probs/mean                        -2.09409    0.02701    -2.06352   -2.14824
log_probs/std                         1.01684     0.02199    1.05426    0.99308
log_probs/max                         0.78391     0.08654    0.95340    0.61586
log_probs/min                         -7.01256    1.59918    -5.46168   -11.19700
mean/mean                             0.10365     0.00200    0.10689    0.10060
mean/std                              0.44107     0.00091    0.44256    0.43959
mean/max                              0.96895     0.00800    0.98099    0.95423
mean/min                              -1.15517    0.01022    -1.14050   -1.17451
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 5, 2, 4, 9, 8, 7, 6, 0, 3]
replay_buffer._size: [35100 35100 35100 35100 35100 35100 35100 35100 35100 35100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.293941736221313 0.002341032028198242
train_time 8.297795057296753
2023-09-06 14:11:38,213 MainThread INFO: EPOCH:232
2023-09-06 14:11:38,214 MainThread INFO: Time Consumed:8.309986352920532s
2023-09-06 14:11:38,214 MainThread INFO: Total Frames:349500s
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 233/400 [18:17<22:42,  8.16s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               145.68118
Train_Epoch_Reward                    1479.78343
Running_Training_Average_Rewards      231.60531
Explore_Time                          0.00279
Train___Time                          8.29780
Eval____Time                          0.00467
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.02711
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.14744
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.28304
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.44606
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.93925
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.06990
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.48698
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1951.14424
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.35603
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.18817
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.96014     0.44254    4.74384    3.26909
alpha_0                               0.53260     0.00051    0.53339    0.53181
alpha_1                               0.50888     0.00044    0.50957    0.50819
alpha_2                               0.50892     0.00046    0.50964    0.50819
alpha_3                               0.50250     0.00042    0.50316    0.50183
alpha_4                               0.50404     0.00043    0.50473    0.50337
alpha_5                               0.51311     0.00044    0.51380    0.51242
alpha_6                               0.50766     0.00046    0.50838    0.50694
alpha_7                               0.50976     0.00041    0.51041    0.50911
alpha_8                               0.50813     0.00042    0.50879    0.50747
alpha_9                               0.51026     0.00045    0.51096    0.50956
Alpha_loss                            -4.09117    0.01998    -4.06101   -4.13198
Training/policy_loss                  -47.59695   0.13272    -47.37414  -47.80665
Training/qf1_loss                     251.59466   118.06195  565.62415  152.69363
Training/qf2_loss                     248.09153   117.54268  560.61292  148.06659
Training/pf_norm                      0.26908     0.03166    0.31527    0.20406
Training/qf1_norm                     90.68124    76.26969   230.92757  13.09875
Training/qf2_norm                     94.13900    78.53732   242.44562  19.73101
log_std/mean                          -0.24983    0.00056    -0.24920   -0.25102
log_std/std                           0.11390     0.00073    0.11510    0.11289
log_std/max                           -0.10296    0.00058    -0.10221   -0.10425
log_std/min                           -0.70491    0.00585    -0.69350   -0.71690
log_probs/mean                        -2.08400    0.02929    -2.03468   -2.14432
log_probs/std                         1.03969     0.02054    1.08028    0.99687
log_probs/max                         0.85363     0.18214    1.13641    0.58547
log_probs/min                         -6.49543    0.56589    -5.89219   -7.80078
mean/mean                             0.11028     0.00193    0.11313    0.10714
mean/std                              0.44327     0.00086    0.44446    0.44208
mean/max                              0.94840     0.00511    0.95408    0.93994
mean/min                              -1.16703    0.01028    -1.14794   -1.18697
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 1, 6, 8, 5, 9, 3, 4, 0, 7]
replay_buffer._size: [35250 35250 35250 35250 35250 35250 35250 35250 35250 35250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.507893085479736 0.0020089149475097656
train_time 8.511130571365356
2023-09-06 14:11:46,863 MainThread INFO: EPOCH:233
2023-09-06 14:11:46,863 MainThread INFO: Time Consumed:8.536924839019775s
2023-09-06 14:11:46,864 MainThread INFO: Total Frames:351000s
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 234/400 [18:26<23:00,  8.32s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               150.45118
Train_Epoch_Reward                    1478.27090
Running_Training_Average_Rewards      159.27338
Explore_Time                          0.00317
Train___Time                          8.51113
Eval____Time                          0.01642
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.92153
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.25293
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.13254
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.47013
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.16770
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.25182
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.25032
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2054.56892
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.85303
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.33198
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.35023     0.49164    5.71089     3.97338
alpha_0                               0.53085     0.00050    0.53164     0.53007
alpha_1                               0.50736     0.00044    0.50804     0.50668
alpha_2                               0.50731     0.00046    0.50803     0.50659
alpha_3                               0.50103     0.00042    0.50169     0.50037
alpha_4                               0.50254     0.00043    0.50322     0.50186
alpha_5                               0.51158     0.00044    0.51227     0.51089
alpha_6                               0.50607     0.00046    0.50679     0.50535
alpha_7                               0.50832     0.00041    0.50897     0.50768
alpha_8                               0.50668     0.00042    0.50733     0.50602
alpha_9                               0.50871     0.00044    0.50941     0.50802
Alpha_loss                            -4.10900    0.02136    -4.07004    -4.13212
Training/policy_loss                  -47.74639   0.13436    -47.57584   -48.01445
Training/qf1_loss                     289.64314   281.90729  1132.99365  158.97366
Training/qf2_loss                     286.00864   282.12703  1130.22095  156.69144
Training/pf_norm                      0.25632     0.02431    0.31607     0.21585
Training/qf1_norm                     149.79622   127.46056  514.85474   68.98103
Training/qf2_norm                     154.38066   125.81551  515.02051   72.07079
log_std/mean                          -0.24728    0.00122    -0.24550    -0.24911
log_std/std                           0.11194     0.00043    0.11262     0.11149
log_std/max                           -0.10302    0.00047    -0.10238    -0.10367
log_std/min                           -0.69028    0.00572    -0.67957    -0.69957
log_probs/mean                        -2.08262    0.02731    -2.03494    -2.11291
log_probs/std                         1.03398     0.02205    1.06833     1.00403
log_probs/max                         0.97068     0.10614    1.08555     0.77332
log_probs/min                         -6.64144    0.85536    -5.77419    -8.91985
mean/mean                             0.11507     0.00080    0.11602     0.11356
mean/std                              0.44492     0.00049    0.44529     0.44356
mean/max                              0.93952     0.00572    0.95144     0.93301
mean/min                              -1.17343    0.01083    -1.15419    -1.18967
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 4, 1, 3, 9, 5, 7, 0, 8, 6]
replay_buffer._size: [35400 35400 35400 35400 35400 35400 35400 35400 35400 35400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.222564220428467 0.002107381820678711
train_time 8.225939273834229
2023-09-06 14:11:55,251 MainThread INFO: EPOCH:234
2023-09-06 14:11:55,252 MainThread INFO: Time Consumed:8.248705387115479s
2023-09-06 14:11:55,252 MainThread INFO: Total Frames:352500s
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 235/400 [18:34<22:54,  8.33s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               158.47263
Train_Epoch_Reward                    1996.68964
Running_Training_Average_Rewards      165.15813
Explore_Time                          0.00313
Train___Time                          8.22594
Eval____Time                          0.00819
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.76900
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.06054
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.02828
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.31687
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.77614
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.57686
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.66201
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2119.27822
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.51456
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.53240
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.14288     0.46569    4.99531    3.34982
alpha_0                               0.52912     0.00049    0.52989    0.52835
alpha_1                               0.50584     0.00044    0.50653    0.50516
alpha_2                               0.50571     0.00046    0.50643    0.50499
alpha_3                               0.49957     0.00042    0.50022    0.49891
alpha_4                               0.50102     0.00043    0.50170    0.50034
alpha_5                               0.51005     0.00044    0.51074    0.50936
alpha_6                               0.50447     0.00046    0.50519    0.50375
alpha_7                               0.50690     0.00041    0.50754    0.50625
alpha_8                               0.50522     0.00042    0.50588    0.50457
alpha_9                               0.50718     0.00044    0.50787    0.50649
Alpha_loss                            -4.13287    0.02145    -4.10398   -4.17990
Training/policy_loss                  -48.09849   0.12275    -47.92017  -48.30483
Training/qf1_loss                     272.72000   108.21158  541.27130  155.46645
Training/qf2_loss                     268.94924   107.64623  536.36572  151.68785
Training/pf_norm                      0.26285     0.03574    0.34896    0.20042
Training/qf1_norm                     114.51694   88.70873   289.37469  26.93735
Training/qf2_norm                     116.72398   87.78193   287.53827  23.38575
log_std/mean                          -0.24477    0.00024    -0.24426   -0.24515
log_std/std                           0.11190     0.00015    0.11206    0.11154
log_std/max                           -0.10167    0.00061    -0.10079   -0.10281
log_std/min                           -0.68719    0.00271    -0.68243   -0.69168
log_probs/mean                        -2.09035    0.03033    -2.05180   -2.15774
log_probs/std                         1.05603     0.02863    1.12001    1.00711
log_probs/max                         0.98093     0.16500    1.25651    0.78836
log_probs/min                         -6.73895    0.54737    -5.48956   -7.57528
mean/mean                             0.11573     0.00024    0.11606    0.11514
mean/std                              0.44552     0.00041    0.44602    0.44489
mean/max                              0.95335     0.00575    0.96383    0.94254
mean/min                              -1.16379    0.00879    -1.15664   -1.18719
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 0, 3, 9, 4, 8, 5, 1, 6, 2]
replay_buffer._size: [35550 35550 35550 35550 35550 35550 35550 35550 35550 35550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.451713800430298 0.0025200843811035156
train_time 8.455911636352539
2023-09-06 14:12:03,841 MainThread INFO: EPOCH:235
2023-09-06 14:12:03,842 MainThread INFO: Time Consumed:8.477628946304321s
2023-09-06 14:12:03,842 MainThread INFO: Total Frames:354000s
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 236/400 [18:43<22:58,  8.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               162.57926
Train_Epoch_Reward                    1495.10937
Running_Training_Average_Rewards      165.66900
Explore_Time                          0.00311
Train___Time                          8.45591
Eval____Time                          0.01408
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.58702
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.42187
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.10807
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.80085
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.97112
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.29043
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.56894
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2066.79928
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.28332
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.36824
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.26770     0.57157    5.12982    3.32608
alpha_0                               0.52742     0.00048    0.52818    0.52666
alpha_1                               0.50433     0.00044    0.50501    0.50364
alpha_2                               0.50411     0.00046    0.50483    0.50339
alpha_3                               0.49811     0.00042    0.49876    0.49746
alpha_4                               0.49951     0.00043    0.50019    0.49884
alpha_5                               0.50851     0.00044    0.50921    0.50782
alpha_6                               0.50288     0.00046    0.50359    0.50216
alpha_7                               0.50547     0.00041    0.50611    0.50484
alpha_8                               0.50377     0.00042    0.50443    0.50312
alpha_9                               0.50565     0.00044    0.50633    0.50496
Alpha_loss                            -4.14271    0.01985    -4.10788   -4.18076
Training/policy_loss                  -48.34115   0.08133    -48.21706  -48.49134
Training/qf1_loss                     393.04437   215.20122  872.04590  166.28688
Training/qf2_loss                     390.02438   215.36612  870.61749  162.44084
Training/pf_norm                      0.25971     0.02380    0.29659    0.22089
Training/qf1_norm                     152.64838   114.21230  339.74652  17.07346
Training/qf2_norm                     153.96692   115.37101  348.40756  17.55021
log_std/mean                          -0.24596    0.00065    -0.24499   -0.24691
log_std/std                           0.11174     0.00046    0.11225    0.11074
log_std/max                           -0.10433    0.00124    -0.10209   -0.10651
log_std/min                           -0.68379    0.00455    -0.67532   -0.68955
log_probs/mean                        -2.07733    0.03050    -2.03806   -2.14022
log_probs/std                         1.05825     0.02427    1.10492    1.02974
log_probs/max                         1.17024     0.21657    1.47748    0.71586
log_probs/min                         -6.50166    0.55884    -5.65639   -7.72820
mean/mean                             0.11262     0.00144    0.11490    0.11041
mean/std                              0.44652     0.00027    0.44699    0.44613
mean/max                              0.94928     0.00671    0.95994    0.94115
mean/min                              -1.17216    0.00711    -1.16184   -1.18621
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 3, 4, 9, 5, 0, 6, 8, 7, 1]
replay_buffer._size: [35700 35700 35700 35700 35700 35700 35700 35700 35700 35700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.113254070281982 0.001973867416381836
train_time 8.116445302963257
2023-09-06 14:12:12,081 MainThread INFO: EPOCH:236
2023-09-06 14:12:12,082 MainThread INFO: Time Consumed:8.128997087478638s
2023-09-06 14:12:12,082 MainThread INFO: Total Frames:355500s
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 237/400 [18:51<22:42,  8.36s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               161.44736
Train_Epoch_Reward                    3006.86679
Running_Training_Average_Rewards      216.62219
Explore_Time                          0.00335
Train___Time                          8.11645
Eval____Time                          0.00427
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.27069
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.60226
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.20617
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           7.46293
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.14505
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -55.31599
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.48607
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1979.90233
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.19163
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.16772
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.36652     0.46144    5.19849    3.85123
alpha_0                               0.52574     0.00048    0.52649    0.52498
alpha_1                               0.50281     0.00044    0.50349    0.50212
alpha_2                               0.50252     0.00046    0.50323    0.50181
alpha_3                               0.49667     0.00041    0.49732    0.49602
alpha_4                               0.49801     0.00043    0.49869    0.49734
alpha_5                               0.50697     0.00044    0.50767    0.50628
alpha_6                               0.50129     0.00045    0.50200    0.50058
alpha_7                               0.50406     0.00041    0.50470    0.50342
alpha_8                               0.50231     0.00042    0.50297    0.50166
alpha_9                               0.50412     0.00044    0.50481    0.50343
Alpha_loss                            -4.17476    0.01520    -4.14993   -4.20110
Training/policy_loss                  -48.48605   0.13457    -48.25742  -48.72514
Training/qf1_loss                     370.01129   201.66917  764.53650  159.64311
Training/qf2_loss                     366.52473   200.29277  759.08563  156.08707
Training/pf_norm                      0.24169     0.02381    0.27787    0.20383
Training/qf1_norm                     146.39473   110.62341  346.93512  37.15178
Training/qf2_norm                     152.75502   111.74887  350.97015  38.33653
log_std/mean                          -0.24692    0.00027    -0.24642   -0.24719
log_std/std                           0.10913     0.00073    0.11012    0.10800
log_std/max                           -0.10672    0.00036    -0.10642   -0.10766
log_std/min                           -0.66827    0.00469    -0.65967   -0.67828
log_probs/mean                        -2.09767    0.02693    -2.05357   -2.14855
log_probs/std                         1.05916     0.02550    1.09356    1.01459
log_probs/max                         1.23653     0.30308    1.85665    0.84013
log_probs/min                         -6.76343    0.68687    -5.74733   -7.93737
mean/mean                             0.10805     0.00090    0.10962    0.10687
mean/std                              0.44539     0.00038    0.44616    0.44467
mean/max                              0.93404     0.00347    0.93891    0.92895
mean/min                              -1.17161    0.01093    -1.15128   -1.18450
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 9, 0, 4, 2, 5, 8, 1, 7, 3]
replay_buffer._size: [35850 35850 35850 35850 35850 35850 35850 35850 35850 35850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.412713289260864 0.001957416534423828
train_time 8.415883779525757
2023-09-06 14:12:20,625 MainThread INFO: EPOCH:237
2023-09-06 14:12:20,625 MainThread INFO: Time Consumed:8.43541431427002s
2023-09-06 14:12:20,626 MainThread INFO: Total Frames:357000s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 238/400 [19:00<22:43,  8.41s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               155.99525
Train_Epoch_Reward                    1826.21925
Running_Training_Average_Rewards      210.93985
Explore_Time                          0.01330
Train___Time                          8.41588
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.26967
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.89042
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.28613
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           7.71506
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.16934
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -55.29779
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.24549
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1923.17245
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.42142
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.82890
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.02095     0.44901    4.70825    3.44211
alpha_0                               0.52407     0.00048    0.52482    0.52333
alpha_1                               0.50128     0.00044    0.50197    0.50060
alpha_2                               0.50094     0.00045    0.50165    0.50022
alpha_3                               0.49523     0.00041    0.49587    0.49459
alpha_4                               0.49652     0.00043    0.49719    0.49585
alpha_5                               0.50543     0.00044    0.50612    0.50474
alpha_6                               0.49972     0.00045    0.50043    0.49902
alpha_7                               0.50265     0.00040    0.50328    0.50202
alpha_8                               0.50085     0.00042    0.50151    0.50019
alpha_9                               0.50259     0.00044    0.50328    0.50190
Alpha_loss                            -4.18153    0.01739    -4.14728   -4.20684
Training/policy_loss                  -48.84756   0.09611    -48.67057  -49.00451
Training/qf1_loss                     253.28158   108.47012  556.30042  170.79965
Training/qf2_loss                     248.66173   107.91611  550.40228  168.62338
Training/pf_norm                      0.23462     0.03311    0.30059    0.17979
Training/qf1_norm                     102.52830   63.50214   213.06522  32.34720
Training/qf2_norm                     103.77143   66.28096   215.24565  38.65671
log_std/mean                          -0.24745    0.00020    -0.24710   -0.24780
log_std/std                           0.10659     0.00079    0.10778    0.10534
log_std/max                           -0.10813    0.00064    -0.10688   -0.10912
log_std/min                           -0.65271    0.00433    -0.64443   -0.65714
log_probs/mean                        -2.08036    0.02736    -2.02322   -2.12562
log_probs/std                         1.03511     0.02240    1.06140    0.97818
log_probs/max                         1.25810     0.17167    1.53052    0.93650
log_probs/min                         -6.63740    0.79886    -5.12560   -7.66517
mean/mean                             0.10735     0.00051    0.10806    0.10627
mean/std                              0.44459     0.00065    0.44571    0.44318
mean/max                              0.94999     0.00933    0.96374    0.93590
mean/min                              -1.16078    0.01398    -1.13429   -1.18313
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 2, 8, 0, 3, 1, 7, 4, 5, 9]
replay_buffer._size: [36000 36000 36000 36000 36000 36000 36000 36000 36000 36000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.148457050323486 0.0019462108612060547
train_time 8.151688814163208
2023-09-06 14:12:28,911 MainThread INFO: EPOCH:238
2023-09-06 14:12:28,912 MainThread INFO: Time Consumed:8.172534942626953s
2023-09-06 14:12:28,912 MainThread INFO: Total Frames:358500s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 239/400 [19:08<22:28,  8.38s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               151.51151
Train_Epoch_Reward                    3318.17991
Running_Training_Average_Rewards      271.70887
Explore_Time                          0.00705
Train___Time                          8.15169
Eval____Time                          0.00712
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.18584
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.19669
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.41819
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           26.02188
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.04824
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -55.43433
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.52788
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1874.62589
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.87582
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.07361
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.35673     0.40172    4.95695    3.68459
alpha_0                               0.52243     0.00047    0.52316    0.52169
alpha_1                               0.49976     0.00044    0.50045    0.49908
alpha_2                               0.49936     0.00045    0.50007    0.49865
alpha_3                               0.49380     0.00041    0.49444    0.49315
alpha_4                               0.49503     0.00043    0.49570    0.49437
alpha_5                               0.50389     0.00044    0.50458    0.50320
alpha_6                               0.49816     0.00045    0.49886    0.49745
alpha_7                               0.50125     0.00040    0.50188    0.50062
alpha_8                               0.49938     0.00042    0.50004    0.49871
alpha_9                               0.50106     0.00044    0.50175    0.50038
Alpha_loss                            -4.21777    0.02728    -4.17539   -4.27024
Training/policy_loss                  -49.02780   0.15374    -48.77896  -49.27074
Training/qf1_loss                     389.29918   180.10076  701.87952  195.94974
Training/qf2_loss                     385.43158   180.21940  699.36682  192.69907
Training/pf_norm                      0.27336     0.03818    0.37295    0.23106
Training/qf1_norm                     147.12346   86.44398   312.28806  33.68758
Training/qf2_norm                     153.59102   85.58627   315.42841  46.32889
log_std/mean                          -0.24647    0.00052    -0.24585   -0.24733
log_std/std                           0.10492     0.00025    0.10540    0.10455
log_std/max                           -0.11125    0.00133    -0.10938   -0.11372
log_std/min                           -0.64174    0.00365    -0.63739   -0.64944
log_probs/mean                        -2.10561    0.03394    -2.05316   -2.17235
log_probs/std                         1.04535     0.01939    1.07603    1.01771
log_probs/max                         1.47311     0.27431    2.04224    1.09936
log_probs/min                         -7.12494    1.04176    -5.87436   -9.22850
mean/mean                             0.10666     0.00157    0.10820    0.10337
mean/std                              0.44267     0.00064    0.44383    0.44174
mean/max                              0.98648     0.01202    1.00409    0.96272
mean/min                              -1.14161    0.00936    -1.12937   -1.16182
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 2, 9, 3, 6, 0, 4, 7, 5, 1]
replay_buffer._size: [36150 36150 36150 36150 36150 36150 36150 36150 36150 36150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.214208841323853 0.001972198486328125
train_time 8.217434406280518
2023-09-06 14:12:37,260 MainThread INFO: EPOCH:239
2023-09-06 14:12:37,260 MainThread INFO: Time Consumed:8.232647895812988s
2023-09-06 14:12:37,260 MainThread INFO: Total Frames:360000s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 240/400 [19:16<22:18,  8.37s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               146.79044
Train_Epoch_Reward                    1698.31749
Running_Training_Average_Rewards      228.09055
Explore_Time                          0.00584
Train___Time                          8.21743
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.49464
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.08558
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.57687
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           26.04841
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.44942
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -61.01886
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.04396
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1818.26618
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.55514
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.74242
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.99499     0.50892    4.64001    3.22485
alpha_0                               0.52080     0.00046    0.52153    0.52008
alpha_1                               0.49824     0.00044    0.49893    0.49756
alpha_2                               0.49779     0.00045    0.49849    0.49708
alpha_3                               0.49236     0.00041    0.49301    0.49172
alpha_4                               0.49355     0.00043    0.49422    0.49288
alpha_5                               0.50236     0.00044    0.50305    0.50167
alpha_6                               0.49660     0.00045    0.49730    0.49590
alpha_7                               0.49985     0.00040    0.50048    0.49921
alpha_8                               0.49790     0.00043    0.49857    0.49723
alpha_9                               0.49954     0.00044    0.50022    0.49885
Alpha_loss                            -4.23703    0.02099    -4.18883   -4.27125
Training/policy_loss                  -49.17977   0.12051    -49.01674  -49.38839
Training/qf1_loss                     275.07321   128.55085  556.57312  154.73531
Training/qf2_loss                     271.12301   128.55438  550.25537  152.43384
Training/pf_norm                      0.29659     0.03842    0.37192    0.24825
Training/qf1_norm                     121.66474   61.54878   209.36189  23.96643
Training/qf2_norm                     122.60109   64.91745   216.48465  26.91947
log_std/mean                          -0.24663    0.00020    -0.24625   -0.24695
log_std/std                           0.10718     0.00086    0.10844    0.10583
log_std/max                           -0.11333    0.00107    -0.11161   -0.11557
log_std/min                           -0.64394    0.00544    -0.63585   -0.65367
log_probs/mean                        -2.10632    0.02650    -2.04960   -2.14346
log_probs/std                         1.03496     0.01820    1.05975    1.00960
log_probs/max                         1.47228     0.26422    1.88697    1.07070
log_probs/min                         -6.91333    0.66115    -6.02331   -7.92213
mean/mean                             0.09352     0.00552    0.10170    0.08420
mean/std                              0.44326     0.00045    0.44392    0.44238
mean/max                              0.99812     0.00599    1.00945    0.98987
mean/min                              -1.14830    0.00677    -1.13929   -1.16125
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 4, 7, 5, 3, 6, 8, 9, 0, 1]
replay_buffer._size: [36300 36300 36300 36300 36300 36300 36300 36300 36300 36300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.4471755027771 0.0021398067474365234
train_time 8.450538635253906
2023-09-06 14:12:45,834 MainThread INFO: EPOCH:240
2023-09-06 14:12:45,835 MainThread INFO: Time Consumed:8.467930555343628s
2023-09-06 14:12:45,835 MainThread INFO: Total Frames:361500s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 241/400 [19:25<22:20,  8.43s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               141.65965
Train_Epoch_Reward                    2214.21645
Running_Training_Average_Rewards      241.02379
Explore_Time                          0.00613
Train___Time                          8.45054
Eval____Time                          0.00743
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.79227
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.69453
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.34953
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           7.74194
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.60446
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.51260
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.20955
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1773.55552
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.61540
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.96448
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.87318     0.59470    4.72790    3.02482
alpha_0                               0.51919     0.00046    0.51992    0.51847
alpha_1                               0.49672     0.00044    0.49741    0.49603
alpha_2                               0.49622     0.00045    0.49692    0.49551
alpha_3                               0.49094     0.00041    0.49158    0.49030
alpha_4                               0.49206     0.00043    0.49273    0.49138
alpha_5                               0.50082     0.00044    0.50151    0.50013
alpha_6                               0.49505     0.00044    0.49575    0.49436
alpha_7                               0.49844     0.00040    0.49907    0.49781
alpha_8                               0.49641     0.00043    0.49708    0.49574
alpha_9                               0.49802     0.00043    0.49870    0.49734
Alpha_loss                            -4.26206    0.01356    -4.23674   -4.28193
Training/policy_loss                  -49.17126   0.05742    -49.06848  -49.26772
Training/qf1_loss                     252.06918   116.26545  494.82391  145.61218
Training/qf2_loss                     248.41654   116.40003  492.25311  141.63670
Training/pf_norm                      0.29098     0.03783    0.35953    0.23843
Training/qf1_norm                     140.51472   88.59840   278.34998  20.51560
Training/qf2_norm                     141.14172   89.42800   283.97934  23.73897
log_std/mean                          -0.24686    0.00030    -0.24647   -0.24742
log_std/std                           0.10987     0.00081    0.11121    0.10856
log_std/max                           -0.11364    0.00204    -0.11064   -0.11712
log_std/min                           -0.65310    0.00481    -0.64550   -0.66111
log_probs/mean                        -2.11670    0.01339    -2.08652   -2.13460
log_probs/std                         1.02430     0.03166    1.07851    0.98799
log_probs/max                         1.43477     0.12135    1.60034    1.20886
log_probs/min                         -6.65720    0.85495    -5.63783   -8.45501
mean/mean                             0.07130     0.00642    0.08164    0.06173
mean/std                              0.44325     0.00027    0.44358    0.44260
mean/max                              0.98476     0.00331    0.99131    0.98141
mean/min                              -1.15787    0.00981    -1.14147   -1.17098
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 7, 9, 3, 1, 4, 2, 5, 8, 6]
replay_buffer._size: [36450 36450 36450 36450 36450 36450 36450 36450 36450 36450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.778591632843018 0.002062559127807617
train_time 4.781898021697998
2023-09-06 14:12:54,118 MainThread INFO: EPOCH:241
2023-09-06 14:12:54,118 MainThread INFO: Time Consumed:7.871110677719116s
2023-09-06 14:12:54,119 MainThread INFO: Total Frames:363000s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 242/400 [19:33<22:05,  8.39s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               137.37600
Train_Epoch_Reward                    1626.48847
Running_Training_Average_Rewards      184.63408
Explore_Time                          3.07880
Train___Time                          4.78190
Eval____Time                          0.00609
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.84117
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.22256
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -68.50714
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           7.36839
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.35680
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.14308
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.50382
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1775.10470
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.43668
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.08422
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.93704     0.44058   4.55683    3.12339
alpha_0                               0.51757     0.00047   0.51830    0.51684
alpha_1                               0.49520     0.00044   0.49588    0.49451
alpha_2                               0.49466     0.00045   0.49536    0.49395
alpha_3                               0.48952     0.00041   0.49016    0.48889
alpha_4                               0.49057     0.00043   0.49124    0.48990
alpha_5                               0.49928     0.00044   0.49998    0.49859
alpha_6                               0.49352     0.00044   0.49421    0.49283
alpha_7                               0.49703     0.00041   0.49766    0.49639
alpha_8                               0.49493     0.00042   0.49559    0.49426
alpha_9                               0.49651     0.00043   0.49719    0.49583
Alpha_loss                            -4.28443    0.01286   -4.26573   -4.30974
Training/policy_loss                  -49.22026   0.13617   -48.99018  -49.49139
Training/qf1_loss                     208.30449   65.54633  366.01920  149.98216
Training/qf2_loss                     204.38728   65.03307  361.18179  146.05313
Training/pf_norm                      0.31880     0.02677   0.35501    0.27923
Training/qf1_norm                     114.41291   84.49295  257.06912  21.49376
Training/qf2_norm                     116.18419   83.77844  255.16800  25.36888
log_std/mean                          -0.24710    0.00030   -0.24657   -0.24748
log_std/std                           0.11151     0.00015   0.11175    0.11123
log_std/max                           -0.11783    0.00086   -0.11600   -0.11903
log_std/min                           -0.66178    0.00393   -0.65637   -0.66835
log_probs/mean                        -2.12244    0.01586   -2.10021   -2.14967
log_probs/std                         1.00659     0.01955   1.03105    0.96551
log_probs/max                         1.21247     0.12054   1.40145    0.97836
log_probs/min                         -6.51218    0.70985   -5.41334   -7.29874
mean/mean                             0.05050     0.00603   0.06005    0.04111
mean/std                              0.44314     0.00034   0.44357    0.44265
mean/max                              0.99413     0.00556   1.00276    0.98687
mean/min                              -1.15709    0.00942   -1.13743   -1.16487
------------------------------------  ----------  --------  ---------  ---------
sample: [0, 9, 7, 2, 3, 8, 4, 6, 1, 5]
replay_buffer._size: [36600 36600 36600 36600 36600 36600 36600 36600 36600 36600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.345432281494141 0.002527952194213867
train_time 4.349563121795654
2023-09-06 14:13:02,200 MainThread INFO: EPOCH:242
2023-09-06 14:13:02,200 MainThread INFO: Time Consumed:4.727353572845459s
2023-09-06 14:13:02,201 MainThread INFO: Total Frames:364500s
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 243/400 [19:41<21:41,  8.29s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               135.10359
Train_Epoch_Reward                    1675.13690
Running_Training_Average_Rewards      183.86139
Explore_Time                          0.36590
Train___Time                          4.34956
Eval____Time                          0.00675
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.01382
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.74016
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -67.30612
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.77770
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.52854
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.03968
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.91215
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1813.06403
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.25182
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.31853
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.35834     0.41473    5.27030     3.66883
alpha_0                               0.51594     0.00047    0.51668     0.51520
alpha_1                               0.49369     0.00043    0.49436     0.49301
alpha_2                               0.49310     0.00045    0.49380     0.49240
alpha_3                               0.48811     0.00041    0.48875     0.48747
alpha_4                               0.48908     0.00043    0.48975     0.48841
alpha_5                               0.49774     0.00045    0.49843     0.49704
alpha_6                               0.49199     0.00044    0.49267     0.49131
alpha_7                               0.49561     0.00041    0.49625     0.49497
alpha_8                               0.49346     0.00042    0.49412     0.49280
alpha_9                               0.49501     0.00043    0.49568     0.49434
Alpha_loss                            -4.31223    0.02274    -4.27364    -4.35454
Training/policy_loss                  -49.65507   0.20421    -49.33820   -49.97512
Training/qf1_loss                     394.69899   261.08842  1068.29907  172.19009
Training/qf2_loss                     390.38658   260.07273  1059.80359  167.33778
Training/pf_norm                      0.30696     0.03438    0.36589     0.23953
Training/qf1_norm                     185.81978   98.87127   420.16693   31.86942
Training/qf2_norm                     189.90489   99.26001   425.00204   33.33061
log_std/mean                          -0.24585    0.00026    -0.24548    -0.24638
log_std/std                           0.10981     0.00091    0.11126     0.10840
log_std/max                           -0.11986    0.00050    -0.11908    -0.12067
log_std/min                           -0.65842    0.00399    -0.65151    -0.66366
log_probs/mean                        -2.13611    0.02873    -2.09266    -2.19299
log_probs/std                         1.00351     0.01960    1.02763     0.96425
log_probs/max                         0.93804     0.23472    1.18740     0.41816
log_probs/min                         -6.46755    0.46751    -5.93322    -7.35161
mean/mean                             0.03076     0.00513    0.03926     0.02304
mean/std                              0.44318     0.00068    0.44421     0.44219
mean/max                              0.99917     0.00582    1.01060     0.99113
mean/min                              -1.15283    0.00914    -1.14023    -1.16716
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 9, 4, 6, 0, 3, 8, 2, 1, 7]
replay_buffer._size: [36750 36750 36750 36750 36750 36750 36750 36750 36750 36750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.315997838973999 0.002081632614135742
train_time 8.31932544708252
2023-09-06 14:13:10,639 MainThread INFO: EPOCH:243
2023-09-06 14:13:10,640 MainThread INFO: Time Consumed:8.332454204559326s
2023-09-06 14:13:10,640 MainThread INFO: Total Frames:366000s
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 244/400 [19:50<21:40,  8.34s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               137.96282
Train_Epoch_Reward                    2907.13526
Running_Training_Average_Rewards      206.95869
Explore_Time                          0.00284
Train___Time                          8.31933
Eval____Time                          0.00612
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.20068
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.35392
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -65.91037
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.96034
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.38485
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.00018
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.84172
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1903.66727
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.35389
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.32974
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.87204     0.45097    4.61251    3.29411
alpha_0                               0.51430     0.00047    0.51504    0.51356
alpha_1                               0.49218     0.00043    0.49286    0.49151
alpha_2                               0.49154     0.00045    0.49224    0.49085
alpha_3                               0.48670     0.00041    0.48733    0.48606
alpha_4                               0.48760     0.00043    0.48826    0.48693
alpha_5                               0.49617     0.00045    0.49688    0.49547
alpha_6                               0.49048     0.00043    0.49115    0.48980
alpha_7                               0.49419     0.00041    0.49483    0.49354
alpha_8                               0.49199     0.00042    0.49265    0.49134
alpha_9                               0.49353     0.00042    0.49420    0.49287
Alpha_loss                            -4.32824    0.01596    -4.29936   -4.35720
Training/policy_loss                  -50.01702   0.15629    -49.59518  -50.14181
Training/qf1_loss                     320.43242   162.59989  596.23694  156.80998
Training/qf2_loss                     316.45945   162.47439  593.52380  153.12094
Training/pf_norm                      0.26376     0.03369    0.31073    0.21554
Training/qf1_norm                     104.13793   57.42638   229.93973  40.71111
Training/qf2_norm                     104.74379   58.36996   231.43715  44.07380
log_std/mean                          -0.24515    0.00025    -0.24455   -0.24542
log_std/std                           0.10810     0.00009    0.10820    0.10795
log_std/max                           -0.12080    0.00057    -0.11936   -0.12143
log_std/min                           -0.65856    0.00567    -0.64591   -0.66625
log_probs/mean                        -2.13261    0.02354    -2.09924   -2.17624
log_probs/std                         1.00849     0.02831    1.07818    0.97808
log_probs/max                         1.02068     0.21069    1.26834    0.72782
log_probs/min                         -6.70448    0.75885    -6.00984   -8.19401
mean/mean                             0.01309     0.00508    0.02077    0.00543
mean/std                              0.44659     0.00164    0.44904    0.44346
mean/max                              0.97030     0.01301    0.98725    0.94774
mean/min                              -1.18783    0.01386    -1.16700   -1.20992
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 2, 5, 7, 3, 4, 0, 9, 1, 6]
replay_buffer._size: [36900 36900 36900 36900 36900 36900 36900 36900 36900 36900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.064061880111694 0.0032863616943359375
train_time 8.068632125854492
2023-09-06 14:13:18,836 MainThread INFO: EPOCH:244
2023-09-06 14:13:18,836 MainThread INFO: Time Consumed:8.085334539413452s
2023-09-06 14:13:18,837 MainThread INFO: Total Frames:367500s
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 245/400 [19:58<21:26,  8.30s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               144.67487
Train_Epoch_Reward                    1360.34023
Running_Training_Average_Rewards      198.08708
Explore_Time                          0.00313
Train___Time                          8.06863
Eval____Time                          0.00925
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.28368
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.93750
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.54889
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.68030
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.31598
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.13393
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.21155
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2044.09059
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.85267
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.38696
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.41137     0.57073    5.85829     3.77259
alpha_0                               0.51264     0.00048    0.51339     0.51190
alpha_1                               0.49069     0.00043    0.49136     0.49002
alpha_2                               0.49000     0.00044    0.49069     0.48930
alpha_3                               0.48529     0.00040    0.48592     0.48465
alpha_4                               0.48612     0.00042    0.48678     0.48546
alpha_5                               0.49461     0.00045    0.49531     0.49390
alpha_6                               0.48897     0.00043    0.48965     0.48830
alpha_7                               0.49277     0.00041    0.49340     0.49213
alpha_8                               0.49054     0.00042    0.49119     0.48989
alpha_9                               0.49206     0.00042    0.49272     0.49141
Alpha_loss                            -4.33453    0.02140    -4.30775    -4.36681
Training/policy_loss                  -50.13508   0.12456    -49.88792   -50.27264
Training/qf1_loss                     451.16397   305.68817  1141.19958  166.48576
Training/qf2_loss                     446.25164   305.64455  1136.74744  163.19133
Training/pf_norm                      0.23582     0.02247    0.27308     0.18646
Training/qf1_norm                     189.62649   141.17793  547.96802   49.90686
Training/qf2_norm                     196.88754   140.37390  549.26917   53.91673
log_std/mean                          -0.24250    0.00120    -0.24064    -0.24427
log_std/std                           0.10781     0.00042    0.10832     0.10699
log_std/max                           -0.12041    0.00045    -0.11928    -0.12100
log_std/min                           -0.66139    0.00845    -0.64542    -0.67247
log_probs/mean                        -2.11578    0.02815    -2.07346    -2.15942
log_probs/std                         0.99449     0.02668    1.03435     0.94809
log_probs/max                         0.86988     0.12185    1.11512     0.73934
log_probs/min                         -6.35368    0.80256    -5.37909    -8.04475
mean/mean                             -0.00155    0.00350    0.00424     -0.00693
mean/std                              0.44972     0.00043    0.45036     0.44892
mean/max                              0.93908     0.00499    0.95043     0.93433
mean/min                              -1.21420    0.01224    -1.18822    -1.22470
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 2, 0, 4, 9, 5, 6, 7, 8, 1]
replay_buffer._size: [37050 37050 37050 37050 37050 37050 37050 37050 37050 37050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.013627052307129 0.002101421356201172
train_time 5.017094850540161
2023-09-06 14:13:27,475 MainThread INFO: EPOCH:245
2023-09-06 14:13:27,476 MainThread INFO: Time Consumed:5.278154134750366s
2023-09-06 14:13:27,476 MainThread INFO: Total Frames:369000s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 246/400 [20:07<21:33,  8.40s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               157.59000
Train_Epoch_Reward                    4033.19907
Running_Training_Average_Rewards      276.68915
Explore_Time                          0.24741
Train___Time                          5.01709
Eval____Time                          0.00808
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.62280
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.64443
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.41551
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.01783
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.75538
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.40120
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.35188
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2250.46348
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.48084
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.14426
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.00069     0.36507   4.72798    3.34016
alpha_0                               0.51098     0.00048   0.51173    0.51023
alpha_1                               0.48921     0.00042   0.48987    0.48854
alpha_2                               0.48845     0.00044   0.48915    0.48776
alpha_3                               0.48388     0.00040   0.48451    0.48325
alpha_4                               0.48465     0.00042   0.48531    0.48399
alpha_5                               0.49304     0.00045   0.49375    0.49233
alpha_6                               0.48747     0.00043   0.48815    0.48680
alpha_7                               0.49136     0.00040   0.49199    0.49074
alpha_8                               0.48910     0.00041   0.48975    0.48846
alpha_9                               0.49061     0.00042   0.49126    0.48996
Alpha_loss                            -4.35469    0.01311   -4.32865   -4.37122
Training/policy_loss                  -50.38811   0.11651   -50.24645  -50.58073
Training/qf1_loss                     227.84416   74.41829  425.98300  157.79825
Training/qf2_loss                     223.32486   74.27752  421.45084  155.34674
Training/pf_norm                      0.24225     0.03968   0.32340    0.18884
Training/qf1_norm                     95.26571    54.04469  229.31973  34.10094
Training/qf2_norm                     100.04608   56.06474  233.99681  29.40500
log_std/mean                          -0.23856    0.00123   -0.23642   -0.24029
log_std/std                           0.10563     0.00047   0.10659    0.10484
log_std/max                           -0.11762    0.00152   -0.11428   -0.11956
log_std/min                           -0.65089    0.00578   -0.64249   -0.66210
log_probs/mean                        -2.11799    0.01842   -2.08192   -2.14117
log_probs/std                         1.00417     0.01888   1.02985    0.97493
log_probs/max                         0.66709     0.17755   0.93661    0.33530
log_probs/min                         -6.96617    0.73455   -6.23106   -8.81254
mean/mean                             -0.01396    0.00359   -0.00846   -0.01915
mean/std                              0.44659     0.00200   0.44931    0.44284
mean/max                              0.92948     0.00401   0.93930    0.92500
mean/min                              -1.21309    0.00549   -1.20570   -1.22185
------------------------------------  ----------  --------  ---------  ---------
sample: [6, 4, 0, 8, 7, 3, 2, 9, 1, 5]
replay_buffer._size: [37200 37200 37200 37200 37200 37200 37200 37200 37200 37200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.906918048858643 0.007718086242675781
train_time 8.916155099868774
2023-09-06 14:13:36,532 MainThread INFO: EPOCH:246
2023-09-06 14:13:36,533 MainThread INFO: Time Consumed:8.937777757644653s
2023-09-06 14:13:36,533 MainThread INFO: Total Frames:370500s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 247/400 [20:16<21:56,  8.60s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               170.01811
Train_Epoch_Reward                    2677.32265
Running_Training_Average_Rewards      269.02873
Explore_Time                          0.00338
Train___Time                          8.91616
Eval____Time                          0.01393
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.01243
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.61659
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.51683
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.90088
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.01770
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.25060
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.94690
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2326.76553
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.61918
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.70968
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.95513     0.44003    4.73805    3.23693
alpha_0                               0.50931     0.00048    0.51007    0.50856
alpha_1                               0.48773     0.00043    0.48839    0.48706
alpha_2                               0.48691     0.00044    0.48760    0.48622
alpha_3                               0.48248     0.00040    0.48311    0.48185
alpha_4                               0.48318     0.00042    0.48384    0.48252
alpha_5                               0.49147     0.00045    0.49218    0.49076
alpha_6                               0.48598     0.00043    0.48665    0.48531
alpha_7                               0.48997     0.00040    0.49060    0.48934
alpha_8                               0.48767     0.00041    0.48831    0.48702
alpha_9                               0.48917     0.00041    0.48982    0.48852
Alpha_loss                            -4.40500    0.01575    -4.37311   -4.42307
Training/policy_loss                  -50.52534   0.14315    -50.31749  -50.80590
Training/qf1_loss                     300.20193   209.23966  891.92664  167.31242
Training/qf2_loss                     295.35449   209.22859  886.97675  162.66547
Training/pf_norm                      0.26361     0.02849    0.31440    0.21453
Training/qf1_norm                     104.56434   81.15463   275.81854  15.68710
Training/qf2_norm                     108.06937   84.80584   289.98566  21.21113
log_std/mean                          -0.23514    0.00038    -0.23475   -0.23596
log_std/std                           0.10495     0.00048    0.10608    0.10448
log_std/max                           -0.11453    0.00124    -0.11216   -0.11620
log_std/min                           -0.64016    0.00781    -0.63076   -0.65344
log_probs/mean                        -2.16317    0.02094    -2.12013   -2.18582
log_probs/std                         0.99069     0.02355    1.02085    0.93286
log_probs/max                         0.51463     0.13916    0.69685    0.27658
log_probs/min                         -6.41768    0.49881    -5.69690   -7.21895
mean/mean                             -0.02563    0.00365    -0.02024   -0.03156
mean/std                              0.43851     0.00215    0.44184    0.43525
mean/max                              0.91682     0.00839    0.92743    0.90096
mean/min                              -1.20362    0.00460    -1.19365   -1.21021
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 5, 9, 4, 7, 1, 3, 6, 0, 2]
replay_buffer._size: [37350 37350 37350 37350 37350 37350 37350 37350 37350 37350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.661209583282471 0.002270221710205078
train_time 4.664723873138428
2023-09-06 14:13:45,758 MainThread INFO: EPOCH:247
2023-09-06 14:13:45,758 MainThread INFO: Time Consumed:4.913928985595703s
2023-09-06 14:13:45,759 MainThread INFO: Total Frames:372000s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 248/400 [20:25<22:15,  8.78s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               178.01348
Train_Epoch_Reward                    2347.49041
Running_Training_Average_Rewards      301.93374
Explore_Time                          0.23151
Train___Time                          4.66472
Eval____Time                          0.00588
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.67278
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.87366
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.54458
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.24750
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.64145
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.96519
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.99085
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2312.15559
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.15680
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.46256
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.01978     0.40076    4.71170    3.41945
alpha_0                               0.50762     0.00049    0.50839    0.50686
alpha_1                               0.48624     0.00042    0.48691    0.48558
alpha_2                               0.48538     0.00044    0.48607    0.48469
alpha_3                               0.48109     0.00040    0.48171    0.48047
alpha_4                               0.48171     0.00042    0.48237    0.48105
alpha_5                               0.48990     0.00045    0.49060    0.48919
alpha_6                               0.48449     0.00043    0.48516    0.48382
alpha_7                               0.48857     0.00040    0.48920    0.48794
alpha_8                               0.48623     0.00041    0.48688    0.48558
alpha_9                               0.48772     0.00042    0.48837    0.48706
Alpha_loss                            -4.43237    0.02165    -4.38402   -4.45643
Training/policy_loss                  -50.63887   0.08421    -50.50167  -50.76956
Training/qf1_loss                     280.68863   154.58265  707.36066  159.95297
Training/qf2_loss                     275.97158   154.33731  701.43146  156.49216
Training/pf_norm                      0.27137     0.02573    0.31634    0.22585
Training/qf1_norm                     109.18471   72.26394   259.97235  28.02461
Training/qf2_norm                     113.54009   74.06053   264.55563  27.76928
log_std/mean                          -0.23633    0.00060    -0.23535   -0.23733
log_std/std                           0.10787     0.00090    0.10926    0.10639
log_std/max                           -0.11131    0.00076    -0.10969   -0.11227
log_std/min                           -0.64846    0.00818    -0.63727   -0.66472
log_probs/mean                        -2.17557    0.02771    -2.10999   -2.20753
log_probs/std                         0.97502     0.02739    1.01979    0.91783
log_probs/max                         0.34251     0.10361    0.53634    0.13194
log_probs/min                         -6.48399    0.47141    -5.65328   -7.32343
mean/mean                             -0.04050    0.00537    -0.03268   -0.04941
mean/std                              0.43154     0.00196    0.43524    0.42894
mean/max                              0.87671     0.01524    0.90290    0.85486
mean/min                              -1.22160    0.00944    -1.20793   -1.23671
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 8, 3, 7, 5, 2, 6, 1, 0, 4]
replay_buffer._size: [37500 37500 37500 37500 37500 37500 37500 37500 37500 37500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.927450180053711 0.0025146007537841797
train_time 8.931416034698486
2023-09-06 14:13:54,827 MainThread INFO: EPOCH:248
2023-09-06 14:13:54,827 MainThread INFO: Time Consumed:8.946325302124023s
2023-09-06 14:13:54,828 MainThread INFO: Total Frames:373500s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 249/400 [20:34<22:18,  8.87s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               184.02169
Train_Epoch_Reward                    2523.08702
Running_Training_Average_Rewards      251.59667
Explore_Time                          0.00276
Train___Time                          8.93142
Eval____Time                          0.00687
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.08351
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.30915
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.82480
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.45578
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.80035
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.06632
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.20829
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2435.81833
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.82749
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.36700
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.08626     0.29787    4.54236    3.55669
alpha_0                               0.50592     0.00049    0.50669    0.50515
alpha_1                               0.48477     0.00042    0.48543    0.48410
alpha_2                               0.48386     0.00044    0.48454    0.48317
alpha_3                               0.47971     0.00040    0.48033    0.47909
alpha_4                               0.48025     0.00042    0.48091    0.47960
alpha_5                               0.48833     0.00045    0.48904    0.48762
alpha_6                               0.48301     0.00042    0.48367    0.48234
alpha_7                               0.48718     0.00040    0.48781    0.48656
alpha_8                               0.48479     0.00041    0.48543    0.48414
alpha_9                               0.48626     0.00042    0.48692    0.48560
Alpha_loss                            -4.44511    0.02474    -4.39436   -4.49260
Training/policy_loss                  -50.78396   0.13430    -50.50802  -50.94591
Training/qf1_loss                     272.31165   142.47056  639.54968  152.79758
Training/qf2_loss                     267.93665   143.14638  636.75903  149.02725
Training/pf_norm                      0.23675     0.02184    0.26659    0.18529
Training/qf1_norm                     109.73132   66.03310   214.73657  21.84797
Training/qf2_norm                     112.38500   66.83203   219.30945  23.41927
log_std/mean                          -0.23713    0.00028    -0.23647   -0.23757
log_std/std                           0.11040     0.00055    0.11098    0.10926
log_std/max                           -0.11054    0.00045    -0.10989   -0.11116
log_std/min                           -0.66024    0.00854    -0.65042   -0.67618
log_probs/mean                        -2.16759    0.02975    -2.10595   -2.22127
log_probs/std                         0.97074     0.01488    0.99781    0.94937
log_probs/max                         0.31582     0.15335    0.57907    0.09159
log_probs/min                         -7.51966    1.12181    -6.25947   -10.32194
mean/mean                             -0.05944    0.00493    -0.05103   -0.06625
mean/std                              0.42514     0.00183    0.42790    0.42214
mean/max                              0.82414     0.01458    0.84765    0.80005
mean/min                              -1.25656    0.00976    -1.23960   -1.27128
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 2, 6, 9, 5, 8, 0, 7, 3, 4]
replay_buffer._size: [37650 37650 37650 37650 37650 37650 37650 37650 37650 37650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.023610353469849 0.0023026466369628906
train_time 9.027179479598999
2023-09-06 14:14:03,984 MainThread INFO: EPOCH:249
2023-09-06 14:14:03,984 MainThread INFO: Time Consumed:9.042293310165405s
2023-09-06 14:14:03,985 MainThread INFO: Total Frames:375000s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 250/400 [20:43<22:22,  8.95s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               196.82486
Train_Epoch_Reward                    2356.30045
Running_Training_Average_Rewards      240.89593
Explore_Time                          0.00308
Train___Time                          9.02718
Eval____Time                          0.00776
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.95860
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.74716
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.91862
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.14459
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.35779
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.95459
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.69163
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2705.48538
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.12322
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.31907
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.94701     0.57339   4.93691    3.08136
alpha_0                               0.50420     0.00050   0.50498    0.50342
alpha_1                               0.48329     0.00042   0.48396    0.48263
alpha_2                               0.48233     0.00044   0.48302    0.48165
alpha_3                               0.47833     0.00039   0.47895    0.47772
alpha_4                               0.47881     0.00041   0.47946    0.47816
alpha_5                               0.48675     0.00045   0.48746    0.48604
alpha_6                               0.48153     0.00042   0.48220    0.48087
alpha_7                               0.48580     0.00039   0.48642    0.48519
alpha_8                               0.48335     0.00041   0.48400    0.48271
alpha_9                               0.48480     0.00042   0.48545    0.48414
Alpha_loss                            -4.46842    0.02488   -4.43900   -4.51075
Training/policy_loss                  -51.08280   0.06301   -50.96430  -51.19135
Training/qf1_loss                     238.33365   90.80242  479.70206  156.55519
Training/qf2_loss                     233.22173   91.02618  475.69720  152.22293
Training/pf_norm                      0.22866     0.02532   0.28105    0.19406
Training/qf1_norm                     141.47809   84.01366  327.78815  30.69181
Training/qf2_norm                     142.56299   84.94597  332.35211  33.00409
log_std/mean                          -0.23625    0.00007   -0.23614   -0.23637
log_std/std                           0.11015     0.00073   0.11094    0.10874
log_std/max                           -0.11415    0.00225   -0.11113   -0.11846
log_std/min                           -0.65977    0.00580   -0.64903   -0.66803
log_probs/mean                        -2.17446    0.03042   -2.13511   -2.22731
log_probs/std                         0.95286     0.02236   0.98650    0.91221
log_probs/max                         0.43493     0.11991   0.63476    0.27359
log_probs/min                         -7.25384    0.89241   -5.69924   -8.78821
mean/mean                             -0.06991    0.00109   -0.06744   -0.07100
mean/std                              0.41880     0.00175   0.42175    0.41644
mean/max                              0.77840     0.00987   0.79545    0.76589
mean/min                              -1.26982    0.00566   -1.26373   -1.28053
------------------------------------  ----------  --------  ---------  ---------
sample: [6, 1, 3, 9, 0, 4, 5, 8, 2, 7]
replay_buffer._size: [37800 37800 37800 37800 37800 37800 37800 37800 37800 37800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.954514741897583 0.0020885467529296875
train_time 8.957832336425781
2023-09-06 14:14:13,070 MainThread INFO: EPOCH:250
2023-09-06 14:14:13,071 MainThread INFO: Time Consumed:8.973751068115234s
2023-09-06 14:14:13,071 MainThread INFO: Total Frames:376500s
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 251/400 [20:52<22:19,  8.99s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               224.35376
Train_Epoch_Reward                    3382.60693
Running_Training_Average_Rewards      275.39981
Explore_Time                          0.00519
Train___Time                          8.95783
Eval____Time                          0.00660
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.41783
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.06755
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.09652
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.00718
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.74082
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.30660
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.05908
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3132.13271
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.73369
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.23648
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.92149     0.40678    4.61215    3.10613
alpha_0                               0.50247     0.00050    0.50325    0.50169
alpha_1                               0.48182     0.00042    0.48248    0.48116
alpha_2                               0.48081     0.00044    0.48149    0.48012
alpha_3                               0.47697     0.00039    0.47758    0.47636
alpha_4                               0.47737     0.00041    0.47802    0.47673
alpha_5                               0.48518     0.00045    0.48589    0.48447
alpha_6                               0.48006     0.00042    0.48072    0.47940
alpha_7                               0.48443     0.00039    0.48505    0.48382
alpha_8                               0.48192     0.00041    0.48256    0.48128
alpha_9                               0.48334     0.00042    0.48399    0.48268
Alpha_loss                            -4.49648    0.01800    -4.45999   -4.52887
Training/policy_loss                  -51.32979   0.04028    -51.27754  -51.41881
Training/qf1_loss                     237.05776   147.85927  670.89941  134.53293
Training/qf2_loss                     232.54368   147.33583  664.89240  131.66620
Training/pf_norm                      0.22886     0.04569    0.36396    0.20115
Training/qf1_norm                     99.29778    65.82448   235.15692  21.11201
Training/qf2_norm                     101.68742   63.28681   232.19739  26.70509
log_std/mean                          -0.23503    0.00059    -0.23439   -0.23604
log_std/std                           0.10662     0.00100    0.10830    0.10521
log_std/max                           -0.12153    0.00180    -0.11901   -0.12425
log_std/min                           -0.65130    0.00860    -0.63478   -0.67056
log_probs/mean                        -2.18717    0.02371    -2.13648   -2.23315
log_probs/std                         0.95502     0.01861    0.99152    0.93050
log_probs/max                         0.35725     0.15519    0.71974    0.18290
log_probs/min                         -6.65284    0.67794    -5.44090   -7.58794
mean/mean                             -0.06809    0.00144    -0.06608   -0.07017
mean/std                              0.41357     0.00140    0.41605    0.41195
mean/max                              0.75600     0.00507    0.76403    0.74809
mean/min                              -1.26793    0.00728    -1.25788   -1.27808
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 1, 9, 7, 2, 3, 8, 5, 4, 0]
replay_buffer._size: [37950 37950 37950 37950 37950 37950 37950 37950 37950 37950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.577508211135864 0.0019845962524414062
train_time 8.580702304840088
2023-09-06 14:14:21,769 MainThread INFO: EPOCH:251
2023-09-06 14:14:21,769 MainThread INFO: Time Consumed:8.592032432556152s
2023-09-06 14:14:21,770 MainThread INFO: Total Frames:378000s
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 252/400 [21:01<21:57,  8.90s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               261.92004
Train_Epoch_Reward                    6017.89925
Running_Training_Average_Rewards      391.89355
Explore_Time                          0.00304
Train___Time                          8.58070
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.16099
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.24957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.70778
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.20660
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.34641
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.51354
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.62040
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3541.96890
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.89466
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.40483
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.91929     0.45688   4.46271    2.80646
alpha_0                               0.50073     0.00050   0.50151    0.49996
alpha_1                               0.48034     0.00042   0.48101    0.47968
alpha_2                               0.47929     0.00044   0.47997    0.47860
alpha_3                               0.47562     0.00039   0.47623    0.47501
alpha_4                               0.47595     0.00041   0.47659    0.47531
alpha_5                               0.48360     0.00045   0.48431    0.48289
alpha_6                               0.47858     0.00043   0.47925    0.47791
alpha_7                               0.48307     0.00039   0.48368    0.48245
alpha_8                               0.48050     0.00041   0.48114    0.47985
alpha_9                               0.48188     0.00042   0.48254    0.48122
Alpha_loss                            -4.53572    0.01516   -4.50495   -4.55887
Training/policy_loss                  -51.39181   0.10917   -51.23573  -51.63589
Training/qf1_loss                     269.07344   97.16416  483.08804  136.89409
Training/qf2_loss                     263.56437   97.66260  478.64932  131.49994
Training/pf_norm                      0.23494     0.02685   0.28084    0.19014
Training/qf1_norm                     118.07497   73.76774  236.05247  18.63733
Training/qf2_norm                     122.23379   71.66152  229.77959  27.00625
log_std/mean                          -0.23370    0.00028   -0.23338   -0.23414
log_std/std                           0.10368     0.00080   0.10494    0.10261
log_std/max                           -0.12653    0.00093   -0.12505   -0.12776
log_std/min                           -0.64128    0.00699   -0.62923   -0.65067
log_probs/mean                        -2.21456    0.02135   -2.17858   -2.24209
log_probs/std                         0.94214     0.01494   0.97514    0.92390
log_probs/max                         0.38496     0.12007   0.59458    0.20052
log_probs/min                         -6.51447    0.55368   -5.90794   -7.70858
mean/mean                             -0.06291    0.00116   -0.06145   -0.06485
mean/std                              0.40917     0.00126   0.41103    0.40723
mean/max                              0.73153     0.01097   0.74596    0.71432
mean/min                              -1.26795    0.00532   -1.26230   -1.28149
------------------------------------  ----------  --------  ---------  ---------
sample: [7, 8, 6, 3, 9, 5, 2, 0, 4, 1]
replay_buffer._size: [38100 38100 38100 38100 38100 38100 38100 38100 38100 38100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.17053771018982 0.0021114349365234375
train_time 9.173900127410889
2023-09-06 14:14:31,078 MainThread INFO: EPOCH:252
2023-09-06 14:14:31,078 MainThread INFO: Time Consumed:9.200244903564453s
2023-09-06 14:14:31,078 MainThread INFO: Total Frames:379500s
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 253/400 [21:10<22:07,  9.03s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               317.01527
Train_Epoch_Reward                    7640.85850
Running_Training_Average_Rewards      568.04549
Explore_Time                          0.00299
Train___Time                          9.17390
Eval____Time                          0.01873
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.58801
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.39825
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.39675
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.23911
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.86002
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.32600
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.57966
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4318.68984
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.15359
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.02157
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.93187     0.33068    4.54798    3.41958
alpha_0                               0.49900     0.00050    0.49978    0.49821
alpha_1                               0.47887     0.00042    0.47953    0.47821
alpha_2                               0.47777     0.00044    0.47845    0.47709
alpha_3                               0.47426     0.00039    0.47487    0.47365
alpha_4                               0.47453     0.00041    0.47517    0.47390
alpha_5                               0.48202     0.00045    0.48273    0.48131
alpha_6                               0.47710     0.00043    0.47776    0.47643
alpha_7                               0.48171     0.00039    0.48232    0.48110
alpha_8                               0.47907     0.00041    0.47971    0.47843
alpha_9                               0.48041     0.00042    0.48107    0.47975
Alpha_loss                            -4.56444    0.01550    -4.53729   -4.58898
Training/policy_loss                  -51.67608   0.10885    -51.53765  -51.92149
Training/qf1_loss                     234.97594   144.76645  662.52747  146.44748
Training/qf2_loss                     230.21184   143.98145  655.42407  142.24142
Training/pf_norm                      0.23750     0.03395    0.31374    0.19235
Training/qf1_norm                     91.23711    67.37743   238.10927  23.79387
Training/qf2_norm                     92.59473    68.65896   244.70706  26.04184
log_std/mean                          -0.23342    0.00013    -0.23312   -0.23357
log_std/std                           0.10171     0.00034    0.10241    0.10133
log_std/max                           -0.12676    0.00044    -0.12596   -0.12743
log_std/min                           -0.63070    0.00912    -0.61707   -0.64409
log_probs/mean                        -2.22879    0.01813    -2.20350   -2.26386
log_probs/std                         0.93499     0.01900    0.96799    0.91164
log_probs/max                         0.40129     0.10120    0.58546    0.27879
log_probs/min                         -6.36891    0.52274    -5.49398   -7.45710
mean/mean                             -0.06256    0.00092    -0.06142   -0.06387
mean/std                              0.40565     0.00076    0.40702    0.40460
mean/max                              0.69981     0.00396    0.70866    0.69410
mean/min                              -1.28206    0.01369    -1.25780   -1.30462
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 6, 2, 5, 1, 4, 9, 3, 0, 8]
replay_buffer._size: [38250 38250 38250 38250 38250 38250 38250 38250 38250 38250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.57670521736145 0.0019588470458984375
train_time 9.579992771148682
2023-09-06 14:14:40,795 MainThread INFO: EPOCH:253
2023-09-06 14:14:40,796 MainThread INFO: Time Consumed:9.599788904190063s
2023-09-06 14:14:40,796 MainThread INFO: Total Frames:381000s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 254/400 [21:20<22:27,  9.23s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               398.22103
Train_Epoch_Reward                    8403.44126
Running_Training_Average_Rewards      735.40663
Explore_Time                          0.00297
Train___Time                          9.57999
Eval____Time                          0.01189
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.65936
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.16636
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.85469
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.61937
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.52525
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.38661
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.43027
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5524.39335
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.15987
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.95182
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.07774     0.39935    4.66259    3.47403
alpha_0                               0.49725     0.00050    0.49804    0.49646
alpha_1                               0.47741     0.00042    0.47807    0.47675
alpha_2                               0.47625     0.00043    0.47694    0.47557
alpha_3                               0.47292     0.00038    0.47352    0.47231
alpha_4                               0.47312     0.00040    0.47376    0.47249
alpha_5                               0.48044     0.00045    0.48115    0.47974
alpha_6                               0.47561     0.00043    0.47628    0.47495
alpha_7                               0.48035     0.00039    0.48096    0.47975
alpha_8                               0.47765     0.00041    0.47829    0.47700
alpha_9                               0.47894     0.00042    0.47961    0.47829
Alpha_loss                            -4.57884    0.01456    -4.55325   -4.60651
Training/policy_loss                  -51.84231   0.12343    -51.58379  -51.97398
Training/qf1_loss                     274.80464   115.12387  489.88983  142.41214
Training/qf2_loss                     269.85851   114.76884  483.37909  137.15109
Training/pf_norm                      0.29349     0.03184    0.35299    0.23823
Training/qf1_norm                     127.34948   78.53407   264.76566  20.60320
Training/qf2_norm                     129.02313   78.56934   268.31442  23.92427
log_std/mean                          -0.23382    0.00019    -0.23347   -0.23417
log_std/std                           0.10163     0.00012    0.10180    0.10142
log_std/max                           -0.12390    0.00119    -0.12238   -0.12597
log_std/min                           -0.63007    0.00778    -0.61793   -0.64336
log_probs/mean                        -2.22238    0.02043    -2.19580   -2.26449
log_probs/std                         0.94651     0.02138    0.98157    0.91844
log_probs/max                         0.56319     0.11089    0.82822    0.44575
log_probs/min                         -6.34239    0.38712    -5.60803   -7.03497
mean/mean                             -0.06321    0.00109    -0.06068   -0.06420
mean/std                              0.40474     0.00030    0.40517    0.40410
mean/max                              0.69057     0.00356    0.69480    0.68297
mean/min                              -1.31232    0.01154    -1.28998   -1.32778
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 0, 6, 8, 4, 3, 5, 2, 7, 1]
replay_buffer._size: [38400 38400 38400 38400 38400 38400 38400 38400 38400 38400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.097826957702637 0.0019762516021728516
train_time 9.10103988647461
2023-09-06 14:14:50,021 MainThread INFO: EPOCH:254
2023-09-06 14:14:50,021 MainThread INFO: Time Consumed:9.120014190673828s
2023-09-06 14:14:50,022 MainThread INFO: Total Frames:382500s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 255/400 [21:29<22:18,  9.23s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               535.83220
Train_Epoch_Reward                    6020.09172
Running_Training_Average_Rewards      735.47972
Explore_Time                          0.00327
Train___Time                          9.10104
Eval____Time                          0.01143
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.78750
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.08173
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.14789
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.90228
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.54095
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.51181
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.49119
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7618.93863
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.90727
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.36852
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.97016     0.46516    5.00800    3.17959
alpha_0                               0.49549     0.00051    0.49628    0.49470
alpha_1                               0.47594     0.00042    0.47660    0.47528
alpha_2                               0.47475     0.00043    0.47542    0.47407
alpha_3                               0.47158     0.00038    0.47218    0.47098
alpha_4                               0.47172     0.00040    0.47235    0.47110
alpha_5                               0.47887     0.00045    0.47958    0.47817
alpha_6                               0.47413     0.00043    0.47480    0.47346
alpha_7                               0.47902     0.00038    0.47961    0.47842
alpha_8                               0.47622     0.00041    0.47686    0.47558
alpha_9                               0.47748     0.00042    0.47814    0.47682
Alpha_loss                            -4.60562    0.01310    -4.58676   -4.62247
Training/policy_loss                  -51.98819   0.12610    -51.83290  -52.25084
Training/qf1_loss                     302.22103   158.22975  672.85364  156.25710
Training/qf2_loss                     297.25871   158.15540  667.24933  151.25716
Training/pf_norm                      0.25011     0.02629    0.29629    0.20811
Training/qf1_norm                     128.56293   91.46098   369.05591  21.88961
Training/qf2_norm                     130.38371   90.21962   365.07581  23.63550
log_std/mean                          -0.23290    0.00059    -0.23223   -0.23409
log_std/std                           0.10021     0.00078    0.10134    0.09890
log_std/max                           -0.12191    0.00035    -0.12133   -0.12244
log_std/min                           -0.62142    0.00830    -0.60347   -0.63332
log_probs/mean                        -2.23283    0.01602    -2.20061   -2.25898
log_probs/std                         0.94817     0.01724    0.97074    0.91563
log_probs/max                         0.60439     0.13198    0.85868    0.36803
log_probs/min                         -7.21942    0.86243    -6.26773   -9.20831
mean/mean                             -0.05335    0.00417    -0.04679   -0.05983
mean/std                              0.40272     0.00107    0.40465    0.40124
mean/max                              0.68380     0.00360    0.68984    0.67878
mean/min                              -1.31168    0.01089    -1.29429   -1.32838
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 8, 4, 9, 1, 0, 2, 3, 6, 7]
replay_buffer._size: [38550 38550 38550 38550 38550 38550 38550 38550 38550 38550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.103259801864624 0.002056121826171875
train_time 9.106664419174194
2023-09-06 14:14:59,267 MainThread INFO: EPOCH:255
2023-09-06 14:14:59,268 MainThread INFO: Time Consumed:9.133243083953857s
2023-09-06 14:14:59,268 MainThread INFO: Total Frames:384000s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 256/400 [21:38<22:09,  9.23s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               741.30932
Train_Epoch_Reward                    4503.99227
Running_Training_Average_Rewards      630.91751
Explore_Time                          0.00385
Train___Time                          9.10666
Eval____Time                          0.01767
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.50024
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.21487
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.96778
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.83319
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.70849
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -58.87142
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.72435
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10450.45400
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.16412
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.02915
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.36052      0.22056    4.70968    4.05754
alpha_0                               0.49373      0.00050    0.49452    0.49294
alpha_1                               0.47448      0.00042    0.47513    0.47382
alpha_2                               0.47325      0.00043    0.47392    0.47257
alpha_3                               0.47024      0.00038    0.47085    0.46964
alpha_4                               0.47034      0.00040    0.47096    0.46972
alpha_5                               0.47730      0.00045    0.47801    0.47660
alpha_6                               0.47265      0.00043    0.47332    0.47198
alpha_7                               0.47769      0.00038    0.47829    0.47710
alpha_8                               0.47479      0.00041    0.47543    0.47415
alpha_9                               0.47601      0.00042    0.47667    0.47535
Alpha_loss                            -4.63303     0.02254    -4.59257   -4.66353
Training/policy_loss                  -52.38732    0.17047    -52.10276  -52.67312
Training/qf1_loss                     352.67231    148.50694  583.28717  200.36887
Training/qf2_loss                     347.27023    147.68372  575.05725  196.41919
Training/pf_norm                      0.20563      0.02018    0.24635    0.17967
Training/qf1_norm                     169.37822    61.79535   254.11766  86.09032
Training/qf2_norm                     174.75374    62.83960   263.87036  94.18589
log_std/mean                          -0.23153     0.00048    -0.23093   -0.23227
log_std/std                           0.09771      0.00053    0.09868    0.09703
log_std/max                           -0.11947     0.00149    -0.11729   -0.12116
log_std/min                           -0.60969     0.00594    -0.60315   -0.62226
log_probs/mean                        -2.24377     0.02661    -2.19513   -2.28893
log_probs/std                         0.92788      0.01277    0.94513    0.90349
log_probs/max                         0.65146      0.10523    0.82216    0.48284
log_probs/min                         -6.39339     0.43232    -5.75373   -7.26636
mean/mean                             -0.03994     0.00307    -0.03554   -0.04535
mean/std                              0.40026      0.00091    0.40193    0.39919
mean/max                              0.67908      0.00218    0.68316    0.67540
mean/min                              -1.29434     0.01144    -1.27684   -1.31571
------------------------------------  -----------  ---------  ---------  ---------
sample: [5, 1, 3, 2, 4, 8, 7, 6, 9, 0]
replay_buffer._size: [38700 38700 38700 38700 38700 38700 38700 38700 38700 38700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.953911304473877 0.0021932125091552734
train_time 8.957502365112305
2023-09-06 14:15:08,359 MainThread INFO: EPOCH:256
2023-09-06 14:15:08,360 MainThread INFO: Time Consumed:8.983163356781006s
2023-09-06 14:15:08,360 MainThread INFO: Total Frames:385500s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 257/400 [21:47<21:54,  9.19s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               985.27314
Train_Epoch_Reward                    11203.62850
Running_Training_Average_Rewards      724.25708
Explore_Time                          0.01273
Train___Time                          8.95750
Eval____Time                          0.00870
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.77086
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.14978
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.56890
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.78765
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.92136
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.52257
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.00211
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12814.62795
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.10998
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.24050
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           3.94036      0.60020    5.25965    2.99900
alpha_0                               0.49197      0.00050    0.49276    0.49119
alpha_1                               0.47302      0.00042    0.47367    0.47236
alpha_2                               0.47175      0.00043    0.47242    0.47108
alpha_3                               0.46891      0.00038    0.46951    0.46830
alpha_4                               0.46896      0.00040    0.46958    0.46834
alpha_5                               0.47574      0.00045    0.47644    0.47504
alpha_6                               0.47117      0.00042    0.47184    0.47051
alpha_7                               0.47637      0.00038    0.47697    0.47578
alpha_8                               0.47336      0.00041    0.47401    0.47272
alpha_9                               0.47454      0.00042    0.47520    0.47387
Alpha_loss                            -4.65798     0.01768    -4.63280   -4.69460
Training/policy_loss                  -52.70652    0.08808    -52.55851  -52.90099
Training/qf1_loss                     251.67881    150.49110  678.48865  149.08273
Training/qf2_loss                     246.24967    150.18481  672.22528  144.16438
Training/pf_norm                      0.22603      0.01819    0.25683    0.19665
Training/qf1_norm                     125.94815    117.14955  414.38693  21.79835
Training/qf2_norm                     126.15435    116.82114  418.02341  27.19003
log_std/mean                          -0.23200     0.00089    -0.23095   -0.23344
log_std/std                           0.09680      0.00016    0.09707    0.09651
log_std/max                           -0.11682     0.00032    -0.11636   -0.11728
log_std/min                           -0.60410     0.00878    -0.59417   -0.61751
log_probs/mean                        -2.25117     0.01979    -2.22306   -2.28878
log_probs/std                         0.93598      0.02014    0.98446    0.90764
log_probs/max                         0.60094      0.19080    0.85110    0.12536
log_probs/min                         -6.59805     0.65833    -5.76113   -7.85484
mean/mean                             -0.03356     0.00089    -0.03272   -0.03549
mean/std                              0.39986      0.00063    0.40075    0.39866
mean/max                              0.69090      0.00646    0.70205    0.68218
mean/min                              -1.27576     0.00795    -1.26565   -1.28822
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 2, 8, 9, 7, 4, 5, 0, 1, 3]
replay_buffer._size: [38850 38850 38850 38850 38850 38850 38850 38850 38850 38850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.039828777313232 0.0019664764404296875
train_time 9.043015480041504
2023-09-06 14:15:17,531 MainThread INFO: EPOCH:257
2023-09-06 14:15:17,531 MainThread INFO: Time Consumed:9.058486938476562s
2023-09-06 14:15:17,531 MainThread INFO: Total Frames:387000s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 258/400 [21:57<21:45,  9.19s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1238.20926
Train_Epoch_Reward                    8208.68750
Running_Training_Average_Rewards      797.21028
Explore_Time                          0.00331
Train___Time                          9.04302
Eval____Time                          0.00811
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.45604
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.46920
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.07026
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.07188
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.39096
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.09006
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.28995
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15201.68153
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.31238
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.24763
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.00929      0.51385    5.04504    3.31422
alpha_0                               0.49023      0.00050    0.49101    0.48945
alpha_1                               0.47156      0.00042    0.47222    0.47091
alpha_2                               0.47026      0.00043    0.47093    0.46959
alpha_3                               0.46757      0.00038    0.46817    0.46697
alpha_4                               0.46758      0.00040    0.46820    0.46696
alpha_5                               0.47419      0.00045    0.47489    0.47349
alpha_6                               0.46970      0.00042    0.47036    0.46904
alpha_7                               0.47505      0.00038    0.47565    0.47445
alpha_8                               0.47193      0.00041    0.47258    0.47129
alpha_9                               0.47307      0.00042    0.47373    0.47241
Alpha_loss                            -4.67372     0.01301    -4.65484   -4.69634
Training/policy_loss                  -52.59103    0.12129    -52.44592  -52.82346
Training/qf1_loss                     307.86768    126.48782  558.81903  179.87842
Training/qf2_loss                     303.06694    126.44006  555.11475  176.31046
Training/pf_norm                      0.24524      0.02844    0.29160    0.20458
Training/qf1_norm                     127.42695    97.91585   358.39987  37.34293
Training/qf2_norm                     128.37452    98.60921   361.63715  39.50853
log_std/mean                          -0.23431     0.00034    -0.23359   -0.23471
log_std/std                           0.09748      0.00021    0.09789    0.09714
log_std/max                           -0.11729     0.00086    -0.11647   -0.11893
log_std/min                           -0.60903     0.00554    -0.59665   -0.61543
log_probs/mean                        -2.24618     0.02002    -2.22260   -2.28828
log_probs/std                         0.93556      0.01591    0.97213    0.91300
log_probs/max                         0.60728      0.11839    0.80475    0.41047
log_probs/min                         -6.67892     1.10278    -5.76686   -9.66051
mean/mean                             -0.03470     0.00105    -0.03332   -0.03630
mean/std                              0.40208      0.00046    0.40272    0.40126
mean/max                              0.70979      0.00808    0.72372    0.69498
mean/min                              -1.28370     0.00748    -1.27092   -1.29547
------------------------------------  -----------  ---------  ---------  ---------
sample: [7, 5, 0, 1, 6, 2, 4, 9, 8, 3]
replay_buffer._size: [39000 39000 39000 39000 39000 39000 39000 39000 39000 39000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.657598495483398 0.002178192138671875
train_time 8.661013126373291
snapshot at best
2023-09-06 14:15:27,034 MainThread INFO: EPOCH:258
2023-09-06 14:15:27,035 MainThread INFO: Time Consumed:9.375694513320923s
2023-09-06 14:15:27,035 MainThread INFO: Total Frames:388500s
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 259/400 [22:06<21:48,  9.28s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1510.78837
Train_Epoch_Reward                    8595.40108
Running_Training_Average_Rewards      933.59057
Explore_Time                          0.00311
Train___Time                          8.66101
Eval____Time                          0.00816
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.84045
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.51161
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.17165
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.22820
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.19635
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.94348
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.60639
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18628.78928
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.85618
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.62139
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           4.07829      0.31848   4.65937    3.51749
alpha_0                               0.48851      0.00049   0.48928    0.48774
alpha_1                               0.47011      0.00041   0.47076    0.46947
alpha_2                               0.46877      0.00043   0.46944    0.46811
alpha_3                               0.46624      0.00038   0.46684    0.46564
alpha_4                               0.46620      0.00040   0.46682    0.46558
alpha_5                               0.47264      0.00044   0.47334    0.47195
alpha_6                               0.46823      0.00042   0.46889    0.46757
alpha_7                               0.47372      0.00038   0.47431    0.47312
alpha_8                               0.47051      0.00041   0.47115    0.46987
alpha_9                               0.47160      0.00042   0.47226    0.47094
Alpha_loss                            -4.68459     0.01419   -4.65248   -4.70547
Training/policy_loss                  -52.89468    0.22974   -52.54261  -53.29136
Training/qf1_loss                     273.56212    77.57980  469.34668  185.83694
Training/qf2_loss                     268.83648    77.27829  464.82599  180.41328
Training/pf_norm                      0.23307      0.03038   0.28815    0.19611
Training/qf1_norm                     123.50404    66.95017  261.21024  39.77424
Training/qf2_norm                     126.19805    66.48407  263.71228  44.46342
log_std/mean                          -0.23433     0.00046   -0.23351   -0.23480
log_std/std                           0.09818      0.00025   0.09849    0.09774
log_std/max                           -0.11872     0.00027   -0.11829   -0.11901
log_std/min                           -0.60897     0.00800   -0.59827   -0.62590
log_probs/mean                        -2.23466     0.02005   -2.18531   -2.25949
log_probs/std                         0.94635      0.02076   0.99888    0.92223
log_probs/max                         0.50368      0.09829   0.65101    0.34839
log_probs/min                         -7.10021     1.07978   -5.65927   -9.00141
mean/mean                             -0.03918     0.00159   -0.03648   -0.04157
mean/std                              0.40411      0.00062   0.40558    0.40301
mean/max                              0.73856      0.00654   0.74786    0.72870
mean/min                              -1.28445     0.00946   -1.26974   -1.30471
------------------------------------  -----------  --------  ---------  ---------
sample: [6, 8, 2, 4, 9, 3, 0, 1, 7, 5]
replay_buffer._size: [39150 39150 39150 39150 39150 39150 39150 39150 39150 39150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.176670551300049 0.0019533634185791016
train_time 5.179853200912476
snapshot at best
2023-09-06 14:15:35,484 MainThread INFO: EPOCH:259
2023-09-06 14:15:35,484 MainThread INFO: Time Consumed:5.705103397369385s
2023-09-06 14:15:35,485 MainThread INFO: Total Frames:390000s
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 260/400 [22:15<21:04,  9.03s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1778.78927
Train_Epoch_Reward                    41591.36465
Running_Training_Average_Rewards      1946.51511
Explore_Time                          0.00295
Train___Time                          5.17985
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.71190
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -38.61297
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.82340
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.67745
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.83479
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.98840
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.17596
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20861.77297
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.15949
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.20737
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.57701      0.53784    5.76006     3.78419
alpha_0                               0.48680      0.00049    0.48757     0.48604
alpha_1                               0.46868      0.00041    0.46932     0.46804
alpha_2                               0.46730      0.00042    0.46796     0.46663
alpha_3                               0.46490      0.00039    0.46550     0.46429
alpha_4                               0.46482      0.00040    0.46544     0.46420
alpha_5                               0.47110      0.00044    0.47179     0.47041
alpha_6                               0.46676      0.00042    0.46742     0.46611
alpha_7                               0.47239      0.00038    0.47299     0.47180
alpha_8                               0.46910      0.00040    0.46973     0.46847
alpha_9                               0.47014      0.00042    0.47080     0.46949
Alpha_loss                            -4.70584     0.01992    -4.67624    -4.74004
Training/policy_loss                  -53.36937    0.12525    -53.15186   -53.61723
Training/qf1_loss                     430.07198    249.22304  1029.02075  183.41719
Training/qf2_loss                     424.87250    248.46389  1022.20764  180.05547
Training/pf_norm                      0.21947      0.03056    0.27640     0.17686
Training/qf1_norm                     213.14661    146.70225  552.81964   21.17207
Training/qf2_norm                     218.94532    147.20472  560.08215   23.26048
log_std/mean                          -0.23245     0.00052    -0.23181    -0.23356
log_std/std                           0.09663      0.00047    0.09752     0.09608
log_std/max                           -0.11925     0.00041    -0.11882    -0.12006
log_std/min                           -0.60160     0.00691    -0.59422    -0.61418
log_probs/mean                        -2.23706     0.02274    -2.20900    -2.28076
log_probs/std                         0.93463      0.02375    0.98622     0.89949
log_probs/max                         0.45007      0.10669    0.57529     0.18823
log_probs/min                         -6.37360     0.59927    -5.43585    -7.40024
mean/mean                             -0.04270     0.00063    -0.04160    -0.04375
mean/std                              0.40233      0.00108    0.40416     0.40067
mean/max                              0.75102      0.00434    0.75943     0.74495
mean/min                              -1.26695     0.00653    -1.25830    -1.28208
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 3, 9, 0, 4, 5, 2, 7, 8, 6]
replay_buffer._size: [39300 39300 39300 39300 39300 39300 39300 39300 39300 39300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 4.642341136932373 0.0020017623901367188
train_time 4.64556884765625
2023-09-06 14:15:43,987 MainThread INFO: EPOCH:260
2023-09-06 14:15:43,987 MainThread INFO: Time Consumed:4.661346435546875s
2023-09-06 14:15:43,988 MainThread INFO: Total Frames:391500s
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 261/400 [22:23<20:33,  8.87s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1938.33273
Train_Epoch_Reward                    20827.00614
Running_Training_Average_Rewards      2367.12573
Explore_Time                          0.00722
Train___Time                          4.64557
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.39266
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.01223
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.41657
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.98658
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.20882
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.66804
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.32090
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20003.96361
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.37898
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.99173
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.29987      0.49283    5.10854    3.49485
alpha_0                               0.48512      0.00048    0.48587    0.48437
alpha_1                               0.46726      0.00041    0.46790    0.46662
alpha_2                               0.46583      0.00042    0.46649    0.46517
alpha_3                               0.46355      0.00039    0.46416    0.46295
alpha_4                               0.46344      0.00040    0.46406    0.46282
alpha_5                               0.46956      0.00044    0.47025    0.46887
alpha_6                               0.46530      0.00042    0.46596    0.46465
alpha_7                               0.47107      0.00038    0.47167    0.47048
alpha_8                               0.46770      0.00040    0.46833    0.46707
alpha_9                               0.46869      0.00041    0.46934    0.46804
Alpha_loss                            -4.72957     0.02232    -4.69044   -4.76469
Training/policy_loss                  -53.61669    0.13225    -53.38533  -53.87244
Training/qf1_loss                     318.91016    131.42430  560.05560  185.54512
Training/qf2_loss                     314.12684    130.66516  553.73389  181.12901
Training/pf_norm                      0.19666      0.01342    0.21581    0.17793
Training/qf1_norm                     153.21328    100.84442  326.98395  30.78989
Training/qf2_norm                     156.84270    101.84823  327.54312  27.43671
log_std/mean                          -0.23269     0.00042    -0.23222   -0.23371
log_std/std                           0.09633      0.00023    0.09683    0.09609
log_std/max                           -0.12129     0.00090    -0.12026   -0.12311
log_std/min                           -0.59103     0.00421    -0.58232   -0.59668
log_probs/mean                        -2.24223     0.02433    -2.19668   -2.27677
log_probs/std                         0.93147      0.02129    0.96051    0.89016
log_probs/max                         0.45799      0.07607    0.59006    0.28618
log_probs/min                         -6.85698     0.93026    -5.51983   -8.98771
mean/mean                             -0.04353     0.00027    -0.04312   -0.04410
mean/std                              0.40036      0.00050    0.40100    0.39974
mean/max                              0.75526      0.00296    0.76013    0.74888
mean/min                              -1.23968     0.00780    -1.22882   -1.25508
------------------------------------  -----------  ---------  ---------  ---------
sample: [8, 6, 2, 7, 3, 5, 4, 9, 0, 1]
replay_buffer._size: [39450 39450 39450 39450 39450 39450 39450 39450 39450 39450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.73674988746643 0.0020143985748291016
train_time 8.739988088607788
2023-09-06 14:15:52,846 MainThread INFO: EPOCH:261
2023-09-06 14:15:52,846 MainThread INFO: Time Consumed:8.74953317642212s
2023-09-06 14:15:52,847 MainThread INFO: Total Frames:393000s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 262/400 [22:32<20:23,  8.87s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1896.35273
Train_Epoch_Reward                    33308.04929
Running_Training_Average_Rewards      3190.88067
Explore_Time                          0.00265
Train___Time                          8.73999
Eval____Time                          0.00296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.83103
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.07901
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.35246
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.30131
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.45813
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.46272
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.90865
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17384.87256
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.80729
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.25851
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.19211      0.55605    5.43974    3.52177
alpha_0                               0.48346      0.00048    0.48420    0.48271
alpha_1                               0.46584      0.00041    0.46648    0.46520
alpha_2                               0.46436      0.00042    0.46502    0.46371
alpha_3                               0.46221      0.00039    0.46281    0.46160
alpha_4                               0.46206      0.00040    0.46268    0.46144
alpha_5                               0.46803      0.00044    0.46872    0.46735
alpha_6                               0.46385      0.00042    0.46450    0.46320
alpha_7                               0.46974      0.00038    0.47034    0.46914
alpha_8                               0.46629      0.00040    0.46693    0.46566
alpha_9                               0.46725      0.00041    0.46790    0.46661
Alpha_loss                            -4.74209     0.01609    -4.70347   -4.76313
Training/policy_loss                  -53.70344    0.14639    -53.46924  -53.87601
Training/qf1_loss                     312.41698    133.26750  632.76385  170.27306
Training/qf2_loss                     307.62610    132.74430  626.47577  166.58188
Training/pf_norm                      0.27755      0.03811    0.33968    0.21508
Training/qf1_norm                     140.75325    116.82395  431.00766  39.30672
Training/qf2_norm                     143.05140    118.76821  432.41644  31.26848
log_std/mean                          -0.23482     0.00071    -0.23374   -0.23599
log_std/std                           0.09805      0.00044    0.09847    0.09711
log_std/max                           -0.12250     0.00070    -0.12140   -0.12411
log_std/min                           -0.59692     0.00963    -0.57904   -0.60819
log_probs/mean                        -2.23395     0.02620    -2.17413   -2.27327
log_probs/std                         0.92450      0.02316    0.95147    0.88167
log_probs/max                         0.37562      0.07509    0.51278    0.22638
log_probs/min                         -6.52147     0.42211    -5.73943   -7.28094
mean/mean                             -0.04251     0.00099    -0.04049   -0.04370
mean/std                              0.40284      0.00174    0.40592    0.40076
mean/max                              0.76617      0.00753    0.77910    0.75716
mean/min                              -1.22162     0.01184    -1.20418   -1.24349
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 1, 8, 5, 4, 3, 7, 0, 9, 2]
replay_buffer._size: [39600 39600 39600 39600 39600 39600 39600 39600 39600 39600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.96962308883667 0.002051115036010742
train_time 8.972864151000977
2023-09-06 14:16:01,945 MainThread INFO: EPOCH:262
2023-09-06 14:16:01,946 MainThread INFO: Time Consumed:8.993844509124756s
2023-09-06 14:16:01,946 MainThread INFO: Total Frames:394500s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 263/400 [22:41<20:24,  8.94s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1702.43587
Train_Epoch_Reward                    24460.16798
Running_Training_Average_Rewards      2619.84078
Explore_Time                          0.00635
Train___Time                          8.97286
Eval____Time                          0.00803
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.00890
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.57132
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.48408
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.41780
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.25741
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.27119
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.14138
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15047.31908
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.83429
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.25720
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.36934      0.58819    5.84437    3.78336
alpha_0                               0.48182      0.00047    0.48255    0.48109
alpha_1                               0.46443      0.00040    0.46506    0.46379
alpha_2                               0.46291      0.00042    0.46357    0.46226
alpha_3                               0.46087      0.00038    0.46147    0.46026
alpha_4                               0.46068      0.00039    0.46130    0.46006
alpha_5                               0.46651      0.00044    0.46719    0.46583
alpha_6                               0.46240      0.00041    0.46305    0.46175
alpha_7                               0.46841      0.00038    0.46901    0.46782
alpha_8                               0.46489      0.00040    0.46552    0.46426
alpha_9                               0.46582      0.00041    0.46646    0.46518
Alpha_loss                            -4.74071     0.01265    -4.71676   -4.75874
Training/policy_loss                  -53.94403    0.16206    -53.72300  -54.15424
Training/qf1_loss                     338.88317    213.69278  870.28552  193.80124
Training/qf2_loss                     333.88025    213.88893  865.66388  188.46121
Training/pf_norm                      0.25505      0.03418    0.31546    0.19154
Training/qf1_norm                     151.15697    141.61247  515.97156  27.07903
Training/qf2_norm                     153.31181    140.41770  514.60156  26.91953
log_std/mean                          -0.23876     0.00148    -0.23640   -0.24118
log_std/std                           0.09831      0.00007    0.09842    0.09821
log_std/max                           -0.12243     0.00086    -0.12125   -0.12384
log_std/min                           -0.59627     0.00963    -0.58400   -0.60919
log_probs/mean                        -2.20610     0.01372    -2.17662   -2.22461
log_probs/std                         0.95664      0.02637    0.99216    0.91188
log_probs/max                         0.58354      0.18985    0.93897    0.31554
log_probs/min                         -6.74252     0.90538    -5.45866   -8.26715
mean/mean                             -0.03502     0.00307    -0.02987   -0.03936
mean/std                              0.41146      0.00306    0.41616    0.40642
mean/max                              0.81040      0.02406    0.85095    0.77833
mean/min                              -1.22724     0.00651    -1.21729   -1.23666
------------------------------------  -----------  ---------  ---------  ---------
sample: [5, 7, 2, 9, 8, 6, 3, 0, 4, 1]
replay_buffer._size: [39750 39750 39750 39750 39750 39750 39750 39750 39750 39750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.040749549865723 0.0019593238830566406
train_time 9.043901205062866
2023-09-06 14:16:11,101 MainThread INFO: EPOCH:263
2023-09-06 14:16:11,101 MainThread INFO: Time Consumed:9.054078340530396s
2023-09-06 14:16:11,101 MainThread INFO: Total Frames:396000s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 264/400 [22:50<20:24,  9.00s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1490.92775
Train_Epoch_Reward                    28616.86733
Running_Training_Average_Rewards      2879.50282
Explore_Time                          0.00372
Train___Time                          9.04390
Eval____Time                          0.00247
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.71104
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.17029
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.91270
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.29866
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.92024
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.09943
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.42666
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13664.97755
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.83837
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.25668
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.56742      0.43982    5.48916    3.88299
alpha_0                               0.48021      0.00045    0.48092    0.47951
alpha_1                               0.46303      0.00040    0.46366    0.46241
alpha_2                               0.46147      0.00041    0.46212    0.46082
alpha_3                               0.45952      0.00039    0.46013    0.45892
alpha_4                               0.45931      0.00040    0.45993    0.45869
alpha_5                               0.46500      0.00043    0.46568    0.46432
alpha_6                               0.46096      0.00042    0.46161    0.46031
alpha_7                               0.46708      0.00038    0.46768    0.46649
alpha_8                               0.46349      0.00040    0.46412    0.46286
alpha_9                               0.46440      0.00041    0.46504    0.46376
Alpha_loss                            -4.74147     0.01786    -4.71158   -4.76853
Training/policy_loss                  -54.44315    0.19491    -54.09593  -54.81233
Training/qf1_loss                     481.24806    226.27478  930.07776  160.07642
Training/qf2_loss                     476.21434    225.26446  924.10370  156.43062
Training/pf_norm                      0.24825      0.03734    0.33814    0.19083
Training/qf1_norm                     184.04079    117.22445  433.07468  25.02321
Training/qf2_norm                     188.96273    117.97384  440.50494  28.05670
log_std/mean                          -0.24476     0.00173    -0.24175   -0.24710
log_std/std                           0.09984      0.00090    0.10124    0.09849
log_std/max                           -0.12670     0.00131    -0.12445   -0.12795
log_std/min                           -0.60164     0.00526    -0.59476   -0.61288
log_probs/mean                        -2.18104     0.02792    -2.13836   -2.22328
log_probs/std                         0.98273      0.01543    1.00735    0.95862
log_probs/max                         0.74765      0.13682    0.96779    0.54216
log_probs/min                         -6.59389     0.47852    -5.47355   -7.14767
mean/mean                             -0.02718     0.00104    -0.02595   -0.02935
mean/std                              0.42415      0.00405    0.43017    0.41794
mean/max                              0.90203      0.02560    0.93819    0.86018
mean/min                              -1.24638     0.01118    -1.23138   -1.26533
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 2, 5, 8, 4, 9, 3, 6, 7, 1]
replay_buffer._size: [39900 39900 39900 39900 39900 39900 39900 39900 39900 39900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.327961921691895 0.0019309520721435547
train_time 9.331095695495605
2023-09-06 14:16:20,549 MainThread INFO: EPOCH:264
2023-09-06 14:16:20,549 MainThread INFO: Time Consumed:9.346259117126465s
2023-09-06 14:16:20,550 MainThread INFO: Total Frames:397500s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 265/400 [23:00<20:33,  9.14s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1343.73968
Train_Epoch_Reward                    10494.67606
Running_Training_Average_Rewards      2119.05705
Explore_Time                          0.00277
Train___Time                          9.33110
Eval____Time                          0.00831
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.78402
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.62395
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.80058
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.83144
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.76216
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.72384
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.09211
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12962.87737
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.28569
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.20207
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.67390      0.58157    5.73726    3.92524
alpha_0                               0.47867      0.00044    0.47936    0.47799
alpha_1                               0.46165      0.00039    0.46227    0.46104
alpha_2                               0.46004      0.00041    0.46068    0.45939
alpha_3                               0.45818      0.00039    0.45878    0.45757
alpha_4                               0.45793      0.00039    0.45855    0.45732
alpha_5                               0.46349      0.00043    0.46417    0.46282
alpha_6                               0.45951      0.00041    0.46016    0.45886
alpha_7                               0.46576      0.00038    0.46635    0.46517
alpha_8                               0.46210      0.00040    0.46273    0.46148
alpha_9                               0.46298      0.00040    0.46362    0.46235
Alpha_loss                            -4.71896     0.01942    -4.67697   -4.74904
Training/policy_loss                  -54.71733    0.13945    -54.44720  -54.88848
Training/qf1_loss                     524.76381    192.73931  809.51685  240.64436
Training/qf2_loss                     519.96313    192.11741  803.95068  237.04642
Training/pf_norm                      0.25725      0.03404    0.30970    0.19464
Training/qf1_norm                     195.13787    137.48202  464.75803  49.62238
Training/qf2_norm                     195.70602    138.79302  463.59155  50.16875
log_std/mean                          -0.24922     0.00092    -0.24748   -0.25047
log_std/std                           0.10248      0.00043    0.10294    0.10156
log_std/max                           -0.12622     0.00064    -0.12540   -0.12748
log_std/min                           -0.61226     0.01022    -0.60141   -0.62733
log_probs/mean                        -2.12679     0.02825    -2.06857   -2.16076
log_probs/std                         1.01086      0.02346    1.05365    0.97773
log_probs/max                         0.95781      0.17578    1.19747    0.58979
log_probs/min                         -6.75540     0.44864    -6.19863   -7.51594
mean/mean                             -0.02496     0.00096    -0.02301   -0.02597
mean/std                              0.43845      0.00415    0.44444    0.43155
mean/max                              0.98675      0.02694    1.02740    0.94598
mean/min                              -1.28494     0.01332    -1.25427   -1.30417
------------------------------------  -----------  ---------  ---------  ---------
sample: [9, 4, 5, 7, 2, 6, 0, 3, 1, 8]
replay_buffer._size: [40050 40050 40050 40050 40050 40050 40050 40050 40050 40050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.17572283744812 0.0019674301147460938
train_time 9.178917646408081
2023-09-06 14:16:29,854 MainThread INFO: EPOCH:265
2023-09-06 14:16:29,855 MainThread INFO: Time Consumed:9.195466995239258s
2023-09-06 14:16:29,855 MainThread INFO: Total Frames:399000s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 266/400 [23:09<20:31,  9.19s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1293.92206
Train_Epoch_Reward                    25248.26083
Running_Training_Average_Rewards      2145.32681
Explore_Time                          0.00335
Train___Time                          9.17892
Eval____Time                          0.00918
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.62008
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.72655
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.12804
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.55475
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.99363
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.65319
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.08178
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13561.95988
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.41280
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.24229
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.71527      0.53580    5.76470     3.99207
alpha_0                               0.47717      0.00042    0.47784     0.47651
alpha_1                               0.46029      0.00039    0.46090     0.45969
alpha_2                               0.45861      0.00041    0.45925     0.45797
alpha_3                               0.45683      0.00039    0.45744     0.45623
alpha_4                               0.45657      0.00039    0.45718     0.45596
alpha_5                               0.46200      0.00043    0.46267     0.46133
alpha_6                               0.45807      0.00041    0.45872     0.45742
alpha_7                               0.46446      0.00037    0.46504     0.46388
alpha_8                               0.46073      0.00039    0.46135     0.46012
alpha_9                               0.46158      0.00040    0.46221     0.46095
Alpha_loss                            -4.72644     0.02262    -4.69075    -4.75830
Training/policy_loss                  -55.02198    0.18922    -54.74726   -55.36289
Training/qf1_loss                     502.55545    266.66396  1048.09106  196.51349
Training/qf2_loss                     497.55727    266.47697  1043.60986  193.34190
Training/pf_norm                      0.26804      0.02096    0.30691     0.24382
Training/qf1_norm                     170.42605    129.84685  401.55594   32.03588
Training/qf2_norm                     175.75006    129.90058  406.03787   33.22990
log_std/mean                          -0.25086     0.00031    -0.25026    -0.25126
log_std/std                           0.10331      0.00017    0.10352     0.10295
log_std/max                           -0.12783     0.00065    -0.12689    -0.12889
log_std/min                           -0.61217     0.00784    -0.59775    -0.62569
log_probs/mean                        -2.11148     0.02735    -2.06479    -2.14698
log_probs/std                         1.04961      0.01819    1.08169     1.01642
log_probs/max                         1.31495      0.19622    1.59010     1.03023
log_probs/min                         -6.98496     0.93766    -5.82739    -9.19778
mean/mean                             -0.01469     0.00496    -0.00614    -0.02189
mean/std                              0.44992      0.00256    0.45356     0.44571
mean/max                              1.06849      0.02478    1.11268     1.02716
mean/min                              -1.29484     0.01374    -1.25977    -1.31385
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 9, 8, 7, 3, 0, 2, 5, 6, 1]
replay_buffer._size: [40200 40200 40200 40200 40200 40200 40200 40200 40200 40200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.037778615951538 0.0020112991333007812
train_time 9.041002035140991
2023-09-06 14:16:39,014 MainThread INFO: EPOCH:266
2023-09-06 14:16:39,015 MainThread INFO: Time Consumed:9.053290605545044s
2023-09-06 14:16:39,015 MainThread INFO: Total Frames:400500s
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 267/400 [23:18<20:22,  9.19s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1318.18538
Train_Epoch_Reward                    15039.19302
Running_Training_Average_Rewards      1692.73766
Explore_Time                          0.00318
Train___Time                          9.04100
Eval____Time                          0.00473
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.55831
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.62088
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.24935
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.69094
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.29765
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.59185
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.86094
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14405.44049
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.08637
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.24108
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.52871      0.38786    5.21921    3.88293
alpha_0                               0.47573      0.00041    0.47637    0.47510
alpha_1                               0.45894      0.00039    0.45955    0.45834
alpha_2                               0.45719      0.00041    0.45783    0.45655
alpha_3                               0.45549      0.00039    0.45610    0.45489
alpha_4                               0.45521      0.00039    0.45582    0.45459
alpha_5                               0.46051      0.00043    0.46118    0.45984
alpha_6                               0.45663      0.00041    0.45728    0.45598
alpha_7                               0.46316      0.00037    0.46375    0.46258
alpha_8                               0.45937      0.00039    0.45998    0.45876
alpha_9                               0.46019      0.00040    0.46082    0.45956
Alpha_loss                            -4.73746     0.02477    -4.70325   -4.77762
Training/policy_loss                  -55.21955    0.17696    -54.90710  -55.47386
Training/qf1_loss                     513.43979    243.70909  884.49823  186.32559
Training/qf2_loss                     508.34211    243.74866  877.39612  180.58379
Training/pf_norm                      0.24936      0.02855    0.29102    0.19411
Training/qf1_norm                     131.64213    80.45854   306.07858  41.29498
Training/qf2_norm                     138.88929    81.87505   314.14246  45.53256
log_std/mean                          -0.25027     0.00049    -0.24943   -0.25105
log_std/std                           0.10339      0.00012    0.10358    0.10316
log_std/max                           -0.12923     0.00086    -0.12767   -0.13089
log_std/min                           -0.60693     0.00736    -0.59644   -0.62172
log_probs/mean                        -2.10119     0.03007    -2.05298   -2.14451
log_probs/std                         1.06486      0.02109    1.10383    1.02514
log_probs/max                         1.48622      0.21732    1.89909    1.20017
log_probs/min                         -6.98222     1.05808    -5.90507   -9.51482
mean/mean                             0.00476      0.00540    0.01305    -0.00410
mean/std                              0.45331      0.00070    0.45476    0.45238
mean/max                              1.14013      0.01520    1.15848    1.11090
mean/min                              -1.25026     0.01578    -1.22821   -1.27466
------------------------------------  -----------  ---------  ---------  ---------
sample: [4, 9, 8, 5, 3, 1, 2, 6, 7, 0]
replay_buffer._size: [40350 40350 40350 40350 40350 40350 40350 40350 40350 40350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.199803352355957 0.0027549266815185547
train_time 5.204364538192749
2023-09-06 14:16:48,477 MainThread INFO: EPOCH:267
2023-09-06 14:16:48,478 MainThread INFO: Time Consumed:5.616841077804565s
2023-09-06 14:16:48,478 MainThread INFO: Total Frames:402000s
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 268/400 [23:28<20:22,  9.26s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1374.63842
Train_Epoch_Reward                    13032.40124
Running_Training_Average_Rewards      1777.32850
Explore_Time                          0.40118
Train___Time                          5.20436
Eval____Time                          0.00544
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.84841
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.10090
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.09794
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.23077
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.41339
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.91387
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -45.65165
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14666.63673
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.10875
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.90826
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.43856      0.51319    5.40090    3.66814
alpha_0                               0.47433      0.00040    0.47496    0.47371
alpha_1                               0.45760      0.00039    0.45820    0.45699
alpha_2                               0.45577      0.00040    0.45641    0.45514
alpha_3                               0.45415      0.00039    0.45475    0.45354
alpha_4                               0.45384      0.00039    0.45446    0.45323
alpha_5                               0.45903      0.00042    0.45969    0.45837
alpha_6                               0.45519      0.00041    0.45584    0.45455
alpha_7                               0.46186      0.00037    0.46245    0.46127
alpha_8                               0.45802      0.00039    0.45863    0.45741
alpha_9                               0.45880      0.00040    0.45943    0.45817
Alpha_loss                            -4.76785     0.01471    -4.73705   -4.78505
Training/policy_loss                  -55.53656    0.18048    -55.15450  -55.80991
Training/qf1_loss                     441.42541    267.82964  946.48779  185.77686
Training/qf2_loss                     436.26038    267.48755  941.99445  181.43491
Training/pf_norm                      0.29031      0.04165    0.36678    0.22811
Training/qf1_norm                     132.87253    98.82465   340.02878  43.28021
Training/qf2_norm                     137.59209    104.79272  352.38245  47.73728
log_std/mean                          -0.24826     0.00070    -0.24706   -0.24932
log_std/std                           0.10355      0.00015    0.10387    0.10340
log_std/max                           -0.12651     0.00166    -0.12419   -0.13004
log_std/min                           -0.58936     0.00538    -0.57756   -0.59502
log_probs/mean                        -2.11636     0.01775    -2.08250   -2.13722
log_probs/std                         1.05551      0.02083    1.10168    1.03303
log_probs/max                         1.70060      0.26222    2.06067    1.25688
log_probs/min                         -7.13117     1.13259    -6.03579   -9.49926
mean/mean                             0.02093      0.00365    0.02624    0.01447
mean/std                              0.44746      0.00251    0.45078    0.44356
mean/max                              1.15166      0.01061    1.16296    1.13780
mean/min                              -1.18049     0.01841    -1.14549   -1.20640
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 7, 1, 5, 9, 2, 0, 4, 6, 8]
replay_buffer._size: [40500 40500 40500 40500 40500 40500 40500 40500 40500 40500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.844213724136353 0.001986980438232422
train_time 8.847425937652588
2023-09-06 14:16:57,448 MainThread INFO: EPOCH:268
2023-09-06 14:16:57,448 MainThread INFO: Time Consumed:8.859583616256714s
2023-09-06 14:16:57,449 MainThread INFO: Total Frames:403500s
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 269/400 [23:37<20:01,  9.17s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1393.34783
Train_Epoch_Reward                    11475.23040
Running_Training_Average_Rewards      1318.22749
Explore_Time                          0.00285
Train___Time                          8.84743
Eval____Time                          0.00534
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.95194
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.18995
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.80364
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.61628
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.98299
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.44901
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -45.49649
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14134.24726
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.83144
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.09656
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.48320      0.39239    5.38930    4.06903
alpha_0                               0.47296      0.00039    0.47357    0.47235
alpha_1                               0.45625      0.00039    0.45686    0.45565
alpha_2                               0.45438      0.00040    0.45500    0.45375
alpha_3                               0.45280      0.00039    0.45340    0.45219
alpha_4                               0.45248      0.00039    0.45310    0.45187
alpha_5                               0.45756      0.00042    0.45822    0.45690
alpha_6                               0.45376      0.00041    0.45440    0.45312
alpha_7                               0.46055      0.00038    0.46114    0.45996
alpha_8                               0.45666      0.00039    0.45727    0.45604
alpha_9                               0.45741      0.00040    0.45803    0.45678
Alpha_loss                            -4.79223     0.01685    -4.75966   -4.82387
Training/policy_loss                  -55.66156    0.14298    -55.49443  -55.96969
Training/qf1_loss                     374.97903    137.52249  684.55426  227.66562
Training/qf2_loss                     370.10828    137.45363  679.79541  223.98369
Training/pf_norm                      0.23840      0.03047    0.29281    0.19741
Training/qf1_norm                     122.91771    100.84807  369.21194  32.73193
Training/qf2_norm                     129.02677    102.69820  379.37991  32.35784
log_std/mean                          -0.24542     0.00059    -0.24473   -0.24665
log_std/std                           0.10492      0.00077    0.10634    0.10395
log_std/max                           -0.12162     0.00106    -0.12040   -0.12351
log_std/min                           -0.59568     0.00545    -0.58891   -0.60523
log_probs/mean                        -2.12336     0.01676    -2.08997   -2.15326
log_probs/std                         1.05750      0.01951    1.09390    1.02568
log_probs/max                         1.90191      0.22864    2.20091    1.45775
log_probs/min                         -6.69780     1.02035    -5.59055   -8.96398
mean/mean                             0.03008      0.00193    0.03327    0.02669
mean/std                              0.44126      0.00092    0.44324    0.44006
mean/max                              1.14481      0.00926    1.15931    1.13667
mean/min                              -1.11722     0.01728    -1.08719   -1.14026
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 5, 4, 0, 1, 7, 3, 9, 8, 6]
replay_buffer._size: [40650 40650 40650 40650 40650 40650 40650 40650 40650 40650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.627299547195435 0.0019881725311279297
train_time 9.630542993545532
2023-09-06 14:17:07,204 MainThread INFO: EPOCH:269
2023-09-06 14:17:07,204 MainThread INFO: Time Consumed:9.647007942199707s
2023-09-06 14:17:07,205 MainThread INFO: Total Frames:405000s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 270/400 [23:46<20:15,  9.35s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1332.92487
Train_Epoch_Reward                    7790.49717
Running_Training_Average_Rewards      1076.60429
Explore_Time                          0.00276
Train___Time                          9.63054
Eval____Time                          0.00973
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.55709
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.38922
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.04046
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.85666
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.75930
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.58845
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.87460
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12594.31491
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.62047
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.07442
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.46287      0.45520    5.58087     3.76602
alpha_0                               0.47162      0.00038    0.47222     0.47103
alpha_1                               0.45491      0.00039    0.45552     0.45430
alpha_2                               0.45299      0.00039    0.45361     0.45238
alpha_3                               0.45145      0.00039    0.45205     0.45084
alpha_4                               0.45112      0.00039    0.45173     0.45051
alpha_5                               0.45609      0.00042    0.45675     0.45544
alpha_6                               0.45234      0.00041    0.45297     0.45170
alpha_7                               0.45924      0.00038    0.45983     0.45864
alpha_8                               0.45529      0.00039    0.45591     0.45467
alpha_9                               0.45601      0.00040    0.45664     0.45538
Alpha_loss                            -4.79967     0.01773    -4.75973    -4.83371
Training/policy_loss                  -55.99521    0.12231    -55.74977   -56.12363
Training/qf1_loss                     365.44383    320.40689  1307.26611  172.50854
Training/qf2_loss                     360.53084    319.42526  1299.35901  168.70871
Training/pf_norm                      0.26046      0.02524    0.32411     0.23707
Training/qf1_norm                     122.34379    114.81629  441.95789   35.18043
Training/qf2_norm                     126.83686    117.22888  454.72119   36.82187
log_std/mean                          -0.24756     0.00150    -0.24535    -0.24980
log_std/std                           0.10861      0.00110    0.10999     0.10675
log_std/max                           -0.12099     0.00075    -0.11980    -0.12249
log_std/min                           -0.60673     0.01193    -0.58477    -0.62657
log_probs/mean                        -2.10881     0.02321    -2.05565    -2.14347
log_probs/std                         1.07763      0.03198    1.15816     1.04544
log_probs/max                         2.15435      0.25612    2.50318     1.70210
log_probs/min                         -6.59643     1.10993    -5.33371    -8.84082
mean/mean                             0.03622      0.00136    0.03806     0.03377
mean/std                              0.44489      0.00213    0.44760     0.44162
mean/max                              1.16646      0.01118    1.18066     1.14487
mean/min                              -1.08040     0.00927    -1.06047    -1.09199
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 2, 4, 1, 6, 5, 7, 0, 9, 3]
replay_buffer._size: [40800 40800 40800 40800 40800 40800 40800 40800 40800 40800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.581192255020142 0.002080678939819336
train_time 9.584590435028076
2023-09-06 14:17:16,921 MainThread INFO: EPOCH:270
2023-09-06 14:17:16,922 MainThread INFO: Time Consumed:9.610384702682495s
2023-09-06 14:17:16,922 MainThread INFO: Total Frames:406500s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 271/400 [23:56<20:20,  9.46s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1202.55258
Train_Epoch_Reward                    19335.81678
Running_Training_Average_Rewards      1286.71814
Explore_Time                          0.00704
Train___Time                          9.58459
Eval____Time                          0.01448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.97584
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.24267
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.42912
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.79470
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.22433
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.58218
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -45.33963
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10757.83487
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.46571
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.58657
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.72898      0.66682    5.53209     3.50989
alpha_0                               0.47033      0.00037    0.47090     0.46976
alpha_1                               0.45356      0.00039    0.45416     0.45295
alpha_2                               0.45163      0.00039    0.45224     0.45102
alpha_3                               0.45009      0.00039    0.45070     0.44948
alpha_4                               0.44976      0.00039    0.45037     0.44915
alpha_5                               0.45464      0.00042    0.45529     0.45399
alpha_6                               0.45093      0.00040    0.45156     0.45030
alpha_7                               0.45791      0.00038    0.45851     0.45731
alpha_8                               0.45392      0.00039    0.45453     0.45330
alpha_9                               0.45460      0.00040    0.45524     0.45397
Alpha_loss                            -4.81010     0.01722    -4.78145    -4.83545
Training/policy_loss                  -56.31768    0.19683    -55.95105   -56.63556
Training/qf1_loss                     583.74329    318.83570  1174.95435  159.37057
Training/qf2_loss                     577.95867    317.73437  1168.51660  155.05864
Training/pf_norm                      0.28536      0.03586    0.33539     0.23183
Training/qf1_norm                     224.90711    126.37119  410.38452   42.83352
Training/qf2_norm                     228.42185    129.57359  416.37021   49.83028
log_std/mean                          -0.25352     0.00169    -0.25086    -0.25582
log_std/std                           0.11307      0.00158    0.11571     0.11070
log_std/max                           -0.12195     0.00099    -0.12041    -0.12394
log_std/min                           -0.62592     0.00858    -0.61168    -0.63788
log_probs/mean                        -2.09774     0.02734    -2.05657    -2.14201
log_probs/std                         1.11249      0.03422    1.15921     1.03431
log_probs/max                         2.75991      0.29212    3.14637     2.23829
log_probs/min                         -6.81040     0.81442    -5.91082    -8.36819
mean/mean                             0.04097      0.00146    0.04307     0.03877
mean/std                              0.45449      0.00341    0.46020     0.44949
mean/max                              1.18957      0.01155    1.20410     1.16752
mean/min                              -1.05181     0.00721    -1.04237    -1.06483
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 5, 6, 8, 0, 4, 3, 9, 2, 1]
replay_buffer._size: [40950 40950 40950 40950 40950 40950 40950 40950 40950 40950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.98559284210205 0.002398252487182617
train_time 9.98947548866272
2023-09-06 14:17:27,044 MainThread INFO: EPOCH:271
2023-09-06 14:17:27,045 MainThread INFO: Time Consumed:10.001298666000366s
2023-09-06 14:17:27,045 MainThread INFO: Total Frames:408000s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 272/400 [24:06<20:36,  9.66s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1037.55564
Train_Epoch_Reward                    13101.62199
Running_Training_Average_Rewards      1340.93120
Explore_Time                          0.00344
Train___Time                          9.98948
Eval____Time                          0.00263
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.62551
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.58519
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.11834
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.09732
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.36737
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.79770
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -47.23296
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9185.21993
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.11330
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.36125
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.37272      0.43809    4.76630    3.25713
alpha_0                               0.46909      0.00034    0.46963    0.46856
alpha_1                               0.45220      0.00039    0.45281    0.45159
alpha_2                               0.45027      0.00039    0.45088    0.44967
alpha_3                               0.44873      0.00039    0.44934    0.44812
alpha_4                               0.44840      0.00039    0.44901    0.44779
alpha_5                               0.45320      0.00041    0.45385    0.45256
alpha_6                               0.44953      0.00040    0.45016    0.44891
alpha_7                               0.45657      0.00038    0.45718    0.45597
alpha_8                               0.45254      0.00040    0.45316    0.45192
alpha_9                               0.45320      0.00040    0.45383    0.45257
Alpha_loss                            -4.80308     0.01916    -4.77177   -4.83873
Training/policy_loss                  -56.56119    0.19947    -56.22327  -56.78281
Training/qf1_loss                     377.90558    162.12002  678.24646  185.35721
Training/qf2_loss                     372.99417    161.39660  673.28583  180.10706
Training/pf_norm                      0.25238      0.03014    0.33049    0.21814
Training/qf1_norm                     139.29936    49.05411   239.64311  66.62786
Training/qf2_norm                     144.54776    47.58466   223.80408  72.39198
log_std/mean                          -0.25773     0.00085    -0.25604   -0.25882
log_std/std                           0.11869      0.00134    0.12045    0.11618
log_std/max                           -0.11926     0.00053    -0.11838   -0.12008
log_std/min                           -0.64993     0.01181    -0.62814   -0.67089
log_probs/mean                        -2.06428     0.02028    -2.02995   -2.09863
log_probs/std                         1.16638      0.03113    1.20550    1.10264
log_probs/max                         2.73066      0.25464    3.10837    2.24163
log_probs/min                         -7.37084     0.95113    -5.95661   -8.82622
mean/mean                             0.04412      0.00089    0.04571    0.04287
mean/std                              0.46487      0.00289    0.46933    0.45962
mean/max                              1.19970      0.00658    1.20562    1.18118
mean/min                              -1.05668     0.01519    -1.03639   -1.08651
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 0, 7, 9, 3, 8, 1, 4, 5, 2]
replay_buffer._size: [41100 41100 41100 41100 41100 41100 41100 41100 41100 41100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.713380575180054 0.002140045166015625
train_time 9.716833353042603
2023-09-06 14:17:36,899 MainThread INFO: EPOCH:272
2023-09-06 14:17:36,899 MainThread INFO: Time Consumed:9.730799198150635s
2023-09-06 14:17:36,900 MainThread INFO: Total Frames:409500s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 273/400 [24:16<20:34,  9.72s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               884.09108
Train_Epoch_Reward                    10537.35623
Running_Training_Average_Rewards      1432.49317
Explore_Time                          0.00376
Train___Time                          9.71683
Eval____Time                          0.00278
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.16353
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.00653
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.84308
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.90709
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.27350
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.38115
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.62430
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7994.15935
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.03062
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.31232
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.67111      0.65690    5.89259    3.83355
alpha_0                               0.46793      0.00033    0.46844    0.46742
alpha_1                               0.45085      0.00039    0.45146    0.45024
alpha_2                               0.44893      0.00038    0.44954    0.44834
alpha_3                               0.44737      0.00039    0.44798    0.44676
alpha_4                               0.44705      0.00039    0.44766    0.44644
alpha_5                               0.45178      0.00041    0.45242    0.45114
alpha_6                               0.44815      0.00039    0.44877    0.44754
alpha_7                               0.45523      0.00039    0.45584    0.45463
alpha_8                               0.45117      0.00039    0.45178    0.45055
alpha_9                               0.45180      0.00040    0.45243    0.45117
Alpha_loss                            -4.78981     0.01869    -4.75346   -4.81097
Training/policy_loss                  -56.78150    0.16417    -56.45173  -57.07354
Training/qf1_loss                     464.21817    266.74155  980.77069  196.67285
Training/qf2_loss                     459.32716    266.80346  974.82355  192.04900
Training/pf_norm                      0.24456      0.03004    0.29658    0.18597
Training/qf1_norm                     191.61583    149.11080  499.07318  25.57568
Training/qf2_norm                     194.23175    151.46160  510.66080  24.49746
log_std/mean                          -0.25937     0.00040    -0.25893   -0.26031
log_std/std                           0.12226      0.00071    0.12324    0.12095
log_std/max                           -0.11768     0.00097    -0.11651   -0.11949
log_std/min                           -0.66850     0.00920    -0.65118   -0.68602
log_probs/mean                        -2.02424     0.02226    -1.97622   -2.04591
log_probs/std                         1.20223      0.02149    1.23545    1.16528
log_probs/max                         3.18315      0.21023    3.51170    2.82084
log_probs/min                         -6.58810     1.13232    -5.31655   -8.98830
mean/mean                             0.04579      0.00053    0.04651    0.04490
mean/std                              0.47504      0.00277    0.47974    0.47078
mean/max                              1.19305      0.00465    1.19839    1.18354
mean/min                              -1.12298     0.01841    -1.09439   -1.15541
------------------------------------  -----------  ---------  ---------  ---------
sample: [8, 5, 0, 4, 2, 7, 9, 3, 1, 6]
replay_buffer._size: [41250 41250 41250 41250 41250 41250 41250 41250 41250 41250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.109927892684937 0.001958131790161133
train_time 9.113831758499146
2023-09-06 14:17:46,154 MainThread INFO: EPOCH:273
2023-09-06 14:17:46,155 MainThread INFO: Time Consumed:9.125079870223999s
2023-09-06 14:17:46,155 MainThread INFO: Total Frames:411000s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 274/400 [24:25<20:06,  9.58s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               767.18039
Train_Epoch_Reward                    9370.51029
Running_Training_Average_Rewards      1100.31628
Explore_Time                          0.00361
Train___Time                          9.11383
Eval____Time                          0.00309
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.97985
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.22027
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.44100
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.26706
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.18225
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.04833
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.95070
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7276.51688
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.76586
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.78798
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.55449     0.50186    5.53093    3.76770
alpha_0                               0.46680     0.00032    0.46730    0.46631
alpha_1                               0.44950     0.00039    0.45011    0.44890
alpha_2                               0.44761     0.00038    0.44820    0.44701
alpha_3                               0.44602     0.00039    0.44662    0.44541
alpha_4                               0.44570     0.00039    0.44630    0.44509
alpha_5                               0.45037     0.00040    0.45100    0.44973
alpha_6                               0.44679     0.00039    0.44740    0.44618
alpha_7                               0.45390     0.00038    0.45450    0.45330
alpha_8                               0.44980     0.00039    0.45041    0.44918
alpha_9                               0.45040     0.00040    0.45103    0.44978
Alpha_loss                            -4.78958    0.01744    -4.76467   -4.82954
Training/policy_loss                  -56.97024   0.14934    -56.69048  -57.19186
Training/qf1_loss                     400.72047   163.11405  735.92902  219.38257
Training/qf2_loss                     395.33665   162.73962  729.86493  216.49356
Training/pf_norm                      0.21968     0.02169    0.25972    0.19399
Training/qf1_norm                     158.91402   118.95517  426.36398  29.41281
Training/qf2_norm                     162.52380   120.89634  430.40234  27.02783
log_std/mean                          -0.26169    0.00058    -0.26062   -0.26235
log_std/std                           0.12382     0.00023    0.12426    0.12335
log_std/max                           -0.12070    0.00186    -0.11737   -0.12306
log_std/min                           -0.67406    0.00884    -0.66068   -0.68382
log_probs/mean                        -2.00061    0.02253    -1.96848   -2.04080
log_probs/std                         1.23310     0.03430    1.29304    1.17759
log_probs/max                         3.53278     0.24666    3.95108    3.08588
log_probs/min                         -6.84619    0.83801    -5.18577   -8.17382
mean/mean                             0.04409     0.00027    0.04478    0.04374
mean/std                              0.48600     0.00324    0.49028    0.48024
mean/max                              1.18690     0.01153    1.19956    1.16740
mean/min                              -1.19030    0.02487    -1.14417   -1.22539
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 1, 9, 6, 4, 5, 8, 0, 7, 2]
replay_buffer._size: [41400 41400 41400 41400 41400 41400 41400 41400 41400 41400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.78669786453247 0.002603292465209961
train_time 9.790940761566162
2023-09-06 14:17:56,071 MainThread INFO: EPOCH:274
2023-09-06 14:17:56,072 MainThread INFO: Time Consumed:9.801506996154785s
2023-09-06 14:17:56,072 MainThread INFO: Total Frames:412500s
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 275/400 [24:35<20:10,  9.68s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               698.41253
Train_Epoch_Reward                    7250.70544
Running_Training_Average_Rewards      905.28573
Explore_Time                          0.00345
Train___Time                          9.79094
Eval____Time                          0.00274
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.41268
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.29104
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.09459
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.62700
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.15607
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.88447
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.65512
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7132.71860
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.82145
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.89110
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.35506     0.53426    5.23640    3.43571
alpha_0                               0.46573     0.00030    0.46620    0.46526
alpha_1                               0.44816     0.00038    0.44876    0.44756
alpha_2                               0.44628     0.00038    0.44688    0.44568
alpha_3                               0.44467     0.00039    0.44527    0.44406
alpha_4                               0.44435     0.00039    0.44495    0.44374
alpha_5                               0.44896     0.00040    0.44959    0.44834
alpha_6                               0.44543     0.00039    0.44604    0.44483
alpha_7                               0.45258     0.00038    0.45317    0.45198
alpha_8                               0.44844     0.00039    0.44905    0.44782
alpha_9                               0.44901     0.00040    0.44964    0.44838
Alpha_loss                            -4.79655    0.02926    -4.72748   -4.83380
Training/policy_loss                  -57.14584   0.12181    -56.97952  -57.36449
Training/qf1_loss                     395.85105   154.57193  798.06976  200.57724
Training/qf2_loss                     391.32941   154.42843  793.24243  197.46194
Training/pf_norm                      0.22909     0.03361    0.29372    0.17617
Training/qf1_norm                     152.36853   93.91547   337.27835  42.19742
Training/qf2_norm                     152.92167   94.95646   338.30322  42.76129
log_std/mean                          -0.26307    0.00026    -0.26262   -0.26348
log_std/std                           0.12359     0.00020    0.12387    0.12325
log_std/max                           -0.12320    0.00082    -0.12160   -0.12463
log_std/min                           -0.68193    0.00728    -0.67051   -0.69563
log_probs/mean                        -1.98593    0.03593    -1.90777   -2.03067
log_probs/std                         1.29268     0.02761    1.33367    1.25467
log_probs/max                         3.62487     0.20362    4.00593    3.42487
log_probs/min                         -7.45265    1.25948    -5.94904   -10.41582
mean/mean                             0.04455     0.00037    0.04523    0.04397
mean/std                              0.49437     0.00140    0.49596    0.49203
mean/max                              1.20363     0.00689    1.20808    1.18380
mean/min                              -1.24165    0.00899    -1.22513   -1.25345
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 8, 9, 4, 1, 7, 0, 3, 2, 5]
replay_buffer._size: [41550 41550 41550 41550 41550 41550 41550 41550 41550 41550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.81615924835205 0.002760648727416992
train_time 9.820615768432617
2023-09-06 14:18:06,035 MainThread INFO: EPOCH:275
2023-09-06 14:18:06,036 MainThread INFO: Time Consumed:9.842602014541626s
2023-09-06 14:18:06,037 MainThread INFO: Total Frames:414000s
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 276/400 [24:45<20:10,  9.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               666.78484
Train_Epoch_Reward                    9630.55770
Running_Training_Average_Rewards      875.05911
Explore_Time                          0.00322
Train___Time                          9.82062
Eval____Time                          0.01436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.02318
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.75007
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.51640
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.61777
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.07527
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.37692
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.29459
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7056.75106
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.88280
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.42763
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.47618     0.41709    5.31401     4.07741
alpha_0                               0.46470     0.00029    0.46516     0.46425
alpha_1                               0.44682     0.00039    0.44742     0.44622
alpha_2                               0.44496     0.00038    0.44555     0.44436
alpha_3                               0.44331     0.00039    0.44392     0.44271
alpha_4                               0.44301     0.00038    0.44361     0.44241
alpha_5                               0.44757     0.00040    0.44820     0.44694
alpha_6                               0.44409     0.00039    0.44469     0.44349
alpha_7                               0.45125     0.00038    0.45185     0.45066
alpha_8                               0.44708     0.00039    0.44769     0.44647
alpha_9                               0.44762     0.00040    0.44825     0.44700
Alpha_loss                            -4.79362    0.02201    -4.74891    -4.82865
Training/policy_loss                  -57.32098   0.18931    -57.04787   -57.70934
Training/qf1_loss                     465.42119   281.33398  1178.78638  167.23355
Training/qf2_loss                     460.24647   280.44464  1170.13110  162.60616
Training/pf_norm                      0.22155     0.02358    0.25704     0.18867
Training/qf1_norm                     138.38909   118.15254  384.44135   30.26372
Training/qf2_norm                     142.53026   116.99020  386.88138   33.21023
log_std/mean                          -0.26202    0.00028    -0.26169    -0.26268
log_std/std                           0.12310     0.00014    0.12341     0.12293
log_std/max                           -0.12213    0.00103    -0.12066    -0.12342
log_std/min                           -0.67845    0.01123    -0.65912    -0.69594
log_probs/mean                        -1.95964    0.02865    -1.90195    -2.00990
log_probs/std                         1.30457     0.02495    1.35230     1.25860
log_probs/max                         3.82859     0.21742    4.15353     3.34764
log_probs/min                         -6.57687    0.84327    -5.55417    -8.28497
mean/mean                             0.04246     0.00071    0.04365     0.04144
mean/std                              0.49842     0.00125    0.50030     0.49642
mean/max                              1.21512     0.00703    1.22664     1.20402
mean/min                              -1.26584    0.00724    -1.25174    -1.27634
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 9, 6, 5, 4, 3, 7, 0, 1, 8]
replay_buffer._size: [41700 41700 41700 41700 41700 41700 41700 41700 41700 41700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.505104780197144 0.0020067691802978516
train_time 9.50835108757019
2023-09-06 14:18:15,673 MainThread INFO: EPOCH:276
2023-09-06 14:18:15,673 MainThread INFO: Time Consumed:9.518229246139526s
2023-09-06 14:18:15,674 MainThread INFO: Total Frames:415500s
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 277/400 [24:55<19:56,  9.73s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               652.52119
Train_Epoch_Reward                    10004.67578
Running_Training_Average_Rewards      896.19796
Explore_Time                          0.00348
Train___Time                          9.50835
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.16274
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.20788
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.23214
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.18482
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.56039
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.53496
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.20101
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6845.09832
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.27925
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.77107
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.62903      0.35621    5.32331    4.03838
alpha_0                               0.46372      0.00028    0.46415    0.46328
alpha_1                               0.44548      0.00038    0.44608    0.44488
alpha_2                               0.44364      0.00038    0.44423    0.44304
alpha_3                               0.44197      0.00038    0.44257    0.44137
alpha_4                               0.44168      0.00038    0.44227    0.44108
alpha_5                               0.44618      0.00040    0.44681    0.44556
alpha_6                               0.44275      0.00038    0.44335    0.44215
alpha_7                               0.44994      0.00038    0.45053    0.44935
alpha_8                               0.44572      0.00039    0.44633    0.44511
alpha_9                               0.44624      0.00040    0.44686    0.44562
Alpha_loss                            -4.80220     0.01751    -4.77641   -4.84006
Training/policy_loss                  -57.87851    0.22070    -57.38039  -58.07903
Training/qf1_loss                     396.97904    166.65399  809.08795  194.27072
Training/qf2_loss                     391.71223    165.76557  801.13605  189.12727
Training/pf_norm                      0.21296      0.02169    0.25062    0.16817
Training/qf1_norm                     162.95251    90.45382   368.85577  55.97058
Training/qf2_norm                     162.15919    89.28417   365.41605  51.10581
log_std/mean                          -0.26404     0.00143    -0.26184   -0.26621
log_std/std                           0.12325      0.00016    0.12350    0.12288
log_std/max                           -0.12210     0.00192    -0.11995   -0.12463
log_std/min                           -0.68288     0.00985    -0.66398   -0.69721
log_probs/mean                        -1.94786     0.02615    -1.91126   -2.00569
log_probs/std                         1.33433      0.03213    1.37395    1.28108
log_probs/max                         4.08641      0.17027    4.35549    3.72259
log_probs/min                         -6.57381     0.71423    -5.74592   -7.69951
mean/mean                             0.04087      0.00036    0.04166    0.04045
mean/std                              0.50468      0.00246    0.50848    0.50020
mean/max                              1.25370      0.01759    1.27667    1.21356
mean/min                              -1.30636     0.01925    -1.26783   -1.33507
------------------------------------  -----------  ---------  ---------  ---------
sample: [1, 9, 8, 0, 6, 3, 5, 2, 4, 7]
replay_buffer._size: [41850 41850 41850 41850 41850 41850 41850 41850 41850 41850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.807964324951172 0.0020508766174316406
train_time 9.81135368347168
2023-09-06 14:18:25,613 MainThread INFO: EPOCH:277
2023-09-06 14:18:25,613 MainThread INFO: Time Consumed:9.823248624801636s
2023-09-06 14:18:25,614 MainThread INFO: Total Frames:417000s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 278/400 [25:05<19:54,  9.79s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               633.77430
Train_Epoch_Reward                    7881.20629
Running_Training_Average_Rewards      917.21466
Explore_Time                          0.00309
Train___Time                          9.81135
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.80420
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.47445
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.78595
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.17102
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.00929
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.35776
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -54.67761
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6582.81943
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.99982
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.06082
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.13212     0.39868    5.08815    3.58085
alpha_0                               0.46277     0.00027    0.46319    0.46235
alpha_1                               0.44415     0.00038    0.44474    0.44355
alpha_2                               0.44232     0.00038    0.44291    0.44173
alpha_3                               0.44063     0.00038    0.44124    0.44003
alpha_4                               0.44035     0.00038    0.44095    0.43975
alpha_5                               0.44480     0.00040    0.44542    0.44418
alpha_6                               0.44142     0.00038    0.44202    0.44082
alpha_7                               0.44863     0.00037    0.44922    0.44805
alpha_8                               0.44437     0.00039    0.44498    0.44376
alpha_9                               0.44487     0.00039    0.44548    0.44426
Alpha_loss                            -4.79021    0.02291    -4.74669   -4.82395
Training/policy_loss                  -58.08800   0.19793    -57.80331  -58.43678
Training/qf1_loss                     353.80579   141.73989  662.96014  180.91739
Training/qf2_loss                     349.18414   141.81451  659.12689  176.17661
Training/pf_norm                      0.19544     0.02887    0.24389    0.15416
Training/qf1_norm                     110.58299   64.92850   270.62885  39.26031
Training/qf2_norm                     110.50027   64.43436   273.04657  39.51606
log_std/mean                          -0.26716    0.00052    -0.26615   -0.26781
log_std/std                           0.12370     0.00028    0.12404    0.12311
log_std/max                           -0.12951    0.00199    -0.12587   -0.13127
log_std/min                           -0.68606    0.01001    -0.66800   -0.70041
log_probs/mean                        -1.90981    0.03089    -1.86159   -1.95838
log_probs/std                         1.37248     0.02976    1.43375    1.32560
log_probs/max                         4.05779     0.24786    4.50910    3.60437
log_probs/min                         -6.62470    0.71790    -5.35627   -8.00287
mean/mean                             0.03943     0.00047    0.04015    0.03855
mean/std                              0.51182     0.00178    0.51404    0.50854
mean/max                              1.29932     0.01533    1.31869    1.26390
mean/min                              -1.35973    0.01486    -1.32430   -1.37674
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 8, 0, 4, 7, 1, 3, 6, 5, 2]
replay_buffer._size: [42000 42000 42000 42000 42000 42000 42000 42000 42000 42000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.79289197921753 0.0020627975463867188
train_time 9.796231508255005
2023-09-06 14:18:35,535 MainThread INFO: EPOCH:278
2023-09-06 14:18:35,535 MainThread INFO: Time Consumed:9.805711030960083s
2023-09-06 14:18:35,536 MainThread INFO: Total Frames:418500s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 279/400 [25:15<19:49,  9.83s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               614.00123
Train_Epoch_Reward                    7455.86961
Running_Training_Average_Rewards      844.72506
Explore_Time                          0.00311
Train___Time                          9.79623
Eval____Time                          0.00244
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.40504
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.53298
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.80196
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.52831
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.22487
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.46444
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.35951
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6472.08941
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.11108
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.06685
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.09626     0.50376    5.07646    3.31463
alpha_0                               0.46187     0.00025    0.46227    0.46147
alpha_1                               0.44282     0.00038    0.44342    0.44223
alpha_2                               0.44101     0.00038    0.44160    0.44042
alpha_3                               0.43930     0.00038    0.43990    0.43870
alpha_4                               0.43901     0.00038    0.43961    0.43841
alpha_5                               0.44342     0.00040    0.44404    0.44280
alpha_6                               0.44008     0.00038    0.44068    0.43948
alpha_7                               0.44734     0.00037    0.44792    0.44676
alpha_8                               0.44303     0.00038    0.44363    0.44243
alpha_9                               0.44351     0.00039    0.44412    0.44290
Alpha_loss                            -4.80599    0.02297    -4.77061   -4.85349
Training/policy_loss                  -57.85432   0.17041    -57.64060  -58.12721
Training/qf1_loss                     358.27770   163.46027  729.89929  194.58286
Training/qf2_loss                     353.06111   162.98065  724.71222  190.39844
Training/pf_norm                      0.20906     0.03644    0.27731    0.15029
Training/qf1_norm                     127.95458   97.55693   288.13614  32.33501
Training/qf2_norm                     128.14468   97.63402   291.83255  34.72491
log_std/mean                          -0.26707    0.00060    -0.26594   -0.26777
log_std/std                           0.12375     0.00015    0.12400    0.12352
log_std/max                           -0.13039    0.00096    -0.12901   -0.13155
log_std/min                           -0.69006    0.00868    -0.67575   -0.70759
log_probs/mean                        -1.90714    0.03232    -1.86638   -1.97528
log_probs/std                         1.41551     0.02478    1.45639    1.36359
log_probs/max                         4.25650     0.19793    4.50052    3.91111
log_probs/min                         -6.91108    0.87150    -5.96177   -8.88148
mean/mean                             0.03849     0.00086    0.04026    0.03759
mean/std                              0.51553     0.00043    0.51596    0.51471
mean/max                              1.33139     0.00887    1.34372    1.31333
mean/min                              -1.38706    0.00792    -1.36860   -1.39606
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 5, 9, 8, 3, 0, 4, 1, 2, 6]
replay_buffer._size: [42150 42150 42150 42150 42150 42150 42150 42150 42150 42150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.77304458618164 0.0019631385803222656
train_time 9.776216983795166
2023-09-06 14:18:45,450 MainThread INFO: EPOCH:279
2023-09-06 14:18:45,451 MainThread INFO: Time Consumed:9.786484956741333s
2023-09-06 14:18:45,451 MainThread INFO: Total Frames:420000s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 280/400 [25:25<19:43,  9.87s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               602.77413
Train_Epoch_Reward                    5381.62655
Running_Training_Average_Rewards      690.62341
Explore_Time                          0.00334
Train___Time                          9.77622
Eval____Time                          0.00256
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.41059
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.05238
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.70540
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.83220
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.63694
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.36289
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.51234
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6529.83131
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.24587
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.92174
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.55715     0.41646    5.39585    4.03487
alpha_0                               0.46100     0.00024    0.46139    0.46062
alpha_1                               0.44150     0.00038    0.44210    0.44091
alpha_2                               0.43969     0.00038    0.44028    0.43911
alpha_3                               0.43797     0.00038    0.43857    0.43737
alpha_4                               0.43769     0.00038    0.43828    0.43709
alpha_5                               0.44205     0.00039    0.44266    0.44143
alpha_6                               0.43875     0.00038    0.43935    0.43815
alpha_7                               0.44606     0.00037    0.44663    0.44548
alpha_8                               0.44169     0.00038    0.44229    0.44109
alpha_9                               0.44215     0.00039    0.44276    0.44154
Alpha_loss                            -4.82286    0.02930    -4.77757   -4.87234
Training/policy_loss                  -58.24855   0.23572    -57.88273  -58.67846
Training/qf1_loss                     479.86420   182.48498  893.30194  293.48965
Training/qf2_loss                     474.17901   181.92548  885.70374  289.78748
Training/pf_norm                      0.26669     0.05900    0.39028    0.20703
Training/qf1_norm                     197.61656   128.67460  437.13855  46.84292
Training/qf2_norm                     204.45701   126.70694  444.14255  51.44756
log_std/mean                          -0.26353    0.00099    -0.26215   -0.26538
log_std/std                           0.12381     0.00023    0.12424    0.12361
log_std/max                           -0.12435    0.00232    -0.12113   -0.12845
log_std/min                           -0.69111    0.00930    -0.67635   -0.70250
log_probs/mean                        -1.90613    0.03431    -1.84698   -1.95786
log_probs/std                         1.42260     0.03170    1.48368    1.36954
log_probs/max                         4.58510     0.28701    5.13251    3.95870
log_probs/min                         -6.92169    0.74480    -5.72873   -8.03909
mean/mean                             0.04801     0.00474    0.05590    0.04160
mean/std                              0.51670     0.00059    0.51783    0.51588
mean/max                              1.35280     0.00540    1.36237    1.34527
mean/min                              -1.39597    0.00197    -1.39177   -1.39763
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 2, 3, 0, 6, 4, 9, 5, 7, 8]
replay_buffer._size: [42300 42300 42300 42300 42300 42300 42300 42300 42300 42300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.038094520568848 0.0019845962524414062
train_time 5.041299343109131
2023-09-06 14:18:55,395 MainThread INFO: EPOCH:280
2023-09-06 14:18:55,395 MainThread INFO: Time Consumed:5.054508686065674s
2023-09-06 14:18:55,396 MainThread INFO: Total Frames:421500s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 281/400 [25:35<19:35,  9.88s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               603.37179
Train_Epoch_Reward                    6515.94843
Running_Training_Average_Rewards      645.11482
Explore_Time                          0.00412
Train___Time                          5.04130
Eval____Time                          0.00498
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.68367
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.96987
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.77471
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.78453
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.86835
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.56500
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.75429
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6598.28279
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.53719
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.93668
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.44440     0.73286    5.87896     3.38652
alpha_0                               0.46015     0.00024    0.46053     0.45977
alpha_1                               0.44019     0.00038    0.44078     0.43960
alpha_2                               0.43839     0.00037    0.43898     0.43780
alpha_3                               0.43664     0.00038    0.43723     0.43604
alpha_4                               0.43636     0.00038    0.43696     0.43576
alpha_5                               0.44068     0.00039    0.44129     0.44006
alpha_6                               0.43742     0.00038    0.43802     0.43681
alpha_7                               0.44478     0.00036    0.44536     0.44421
alpha_8                               0.44036     0.00038    0.44096     0.43976
alpha_9                               0.44080     0.00039    0.44141     0.44019
Alpha_loss                            -4.84381    0.01939    -4.80209    -4.88436
Training/policy_loss                  -58.74124   0.13032    -58.58555   -59.00471
Training/qf1_loss                     482.03159   248.39417  1048.10522  229.47153
Training/qf2_loss                     476.41851   248.50942  1044.10376  224.48300
Training/pf_norm                      0.26342     0.03650    0.31888     0.18383
Training/qf1_norm                     214.10739   156.17072  563.71039   25.76385
Training/qf2_norm                     213.44920   154.58592  560.42828   25.43053
log_std/mean                          -0.26359    0.00105    -0.26226    -0.26537
log_std/std                           0.12551     0.00100    0.12716     0.12409
log_std/max                           -0.12103    0.00083    -0.11978    -0.12219
log_std/min                           -0.68550    0.01014    -0.67350    -0.70531
log_probs/mean                        -1.91034    0.02572    -1.86671    -1.96541
log_probs/std                         1.43638     0.03966    1.49349     1.37165
log_probs/max                         4.52571     0.25981    5.05020     4.12209
log_probs/min                         -7.02132    0.85551    -6.07681    -8.97869
mean/mean                             0.06676     0.00541    0.07459     0.05784
mean/std                              0.52132     0.00285    0.52606     0.51774
mean/max                              1.39695     0.02154    1.43326     1.36667
mean/min                              -1.40140    0.01001    -1.39116    -1.41995
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 5, 0, 8, 2, 7, 9, 6, 4, 1]
replay_buffer._size: [42450 42450 42450 42450 42450 42450 42450 42450 42450 42450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.879266500473022 0.0019021034240722656
train_time 9.883349418640137
2023-09-06 14:19:05,411 MainThread INFO: EPOCH:281
2023-09-06 14:19:05,412 MainThread INFO: Time Consumed:9.897137641906738s
2023-09-06 14:19:05,412 MainThread INFO: Total Frames:423000s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 282/400 [25:45<19:31,  9.92s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               612.28999
Train_Epoch_Reward                    5311.34825
Running_Training_Average_Rewards      573.63077
Explore_Time                          0.00290
Train___Time                          9.88335
Eval____Time                          0.00678
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.07984
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.82396
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.10386
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.21437
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.25134
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.85182
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.36929
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6734.04468
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.54588
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.66411
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.20981     0.60231    5.36284    3.46758
alpha_0                               0.45933     0.00023    0.45969    0.45897
alpha_1                               0.43889     0.00037    0.43947    0.43831
alpha_2                               0.43709     0.00037    0.43767    0.43650
alpha_3                               0.43531     0.00038    0.43590    0.43471
alpha_4                               0.43504     0.00038    0.43563    0.43444
alpha_5                               0.43932     0.00039    0.43993    0.43871
alpha_6                               0.43608     0.00039    0.43668    0.43547
alpha_7                               0.44351     0.00036    0.44409    0.44294
alpha_8                               0.43903     0.00038    0.43962    0.43843
alpha_9                               0.43944     0.00039    0.44005    0.43883
Alpha_loss                            -4.81595    0.01374    -4.79624   -4.83975
Training/policy_loss                  -58.81264   0.11255    -58.65480  -59.02968
Training/qf1_loss                     417.97194   237.71176  869.25848  222.47543
Training/qf2_loss                     412.59535   237.39612  864.40753  218.42578
Training/pf_norm                      0.20805     0.02953    0.25273    0.16223
Training/qf1_norm                     152.92496   153.59082  466.23416  21.20213
Training/qf2_norm                     154.42588   154.65589  470.29645  23.23605
log_std/mean                          -0.26840    0.00149    -0.26628   -0.27084
log_std/std                           0.12966     0.00110    0.13137    0.12802
log_std/max                           -0.12140    0.00126    -0.11922   -0.12309
log_std/min                           -0.70343    0.00783    -0.68894   -0.71475
log_probs/mean                        -1.85322    0.02000    -1.82519   -1.88577
log_probs/std                         1.51666     0.02656    1.57779    1.46595
log_probs/max                         4.97252     0.24962    5.36251    4.51619
log_probs/min                         -6.45472    0.54766    -5.94945   -7.48229
mean/mean                             0.08235     0.00339    0.08755    0.07686
mean/std                              0.53401     0.00342    0.53962    0.52882
mean/max                              1.47426     0.01945    1.50516    1.44228
mean/min                              -1.45128    0.01711    -1.42523   -1.47817
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 4, 3, 9, 8, 5, 0, 1, 2, 6]
replay_buffer._size: [42600 42600 42600 42600 42600 42600 42600 42600 42600 42600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.73538064956665 0.003497600555419922
train_time 9.740783214569092
2023-09-06 14:19:15,297 MainThread INFO: EPOCH:282
2023-09-06 14:19:15,298 MainThread INFO: Time Consumed:9.755844354629517s
2023-09-06 14:19:15,298 MainThread INFO: Total Frames:424500s
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 283/400 [25:54<19:19,  9.91s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               626.85340
Train_Epoch_Reward                    7193.93507
Running_Training_Average_Rewards      634.04106
Explore_Time                          0.00334
Train___Time                          9.74078
Eval____Time                          0.00676
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.56099
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48469
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.85467
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.82951
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.69468
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.76904
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.67114
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6950.01645
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.13802
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.96042
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.44362     0.53306    5.25341    3.51374
alpha_0                               0.45857     0.00021    0.45890    0.45825
alpha_1                               0.43760     0.00037    0.43818    0.43703
alpha_2                               0.43580     0.00037    0.43637    0.43522
alpha_3                               0.43398     0.00038    0.43458    0.43339
alpha_4                               0.43372     0.00038    0.43431    0.43313
alpha_5                               0.43797     0.00039    0.43857    0.43736
alpha_6                               0.43474     0.00038    0.43534    0.43413
alpha_7                               0.44225     0.00036    0.44282    0.44168
alpha_8                               0.43771     0.00038    0.43830    0.43711
alpha_9                               0.43809     0.00039    0.43870    0.43749
Alpha_loss                            -4.79000    0.02019    -4.76330   -4.82605
Training/policy_loss                  -58.68802   0.24293    -58.31550  -59.14685
Training/qf1_loss                     472.58449   208.19831  834.38318  181.60226
Training/qf2_loss                     466.26309   207.28091  827.55548  176.76744
Training/pf_norm                      0.25200     0.04544    0.32521    0.16981
Training/qf1_norm                     220.21281   123.32839  416.41025  44.35975
Training/qf2_norm                     221.40351   123.14365  415.11075  47.93678
log_std/mean                          -0.27108    0.00068    -0.26961   -0.27198
log_std/std                           0.13156     0.00023    0.13203    0.13124
log_std/max                           -0.12287    0.00049    -0.12201   -0.12340
log_std/min                           -0.70655    0.00663    -0.69385   -0.71653
log_probs/mean                        -1.79887    0.02372    -1.76490   -1.85095
log_probs/std                         1.58551     0.02906    1.61979    1.53081
log_probs/max                         5.30926     0.32863    6.07147    4.85981
log_probs/min                         -6.55207    1.01873    -5.70144   -8.90765
mean/mean                             0.09338     0.00280    0.09781    0.08892
mean/std                              0.54260     0.00137    0.54506    0.53985
mean/max                              1.52242     0.00526    1.52803    1.51079
mean/min                              -1.49976    0.00806    -1.48343   -1.50738
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 5, 7, 0, 9, 3, 8, 6, 1, 2]
replay_buffer._size: [42750 42750 42750 42750 42750 42750 42750 42750 42750 42750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.03901481628418 0.0020089149475097656
train_time 10.042313814163208
2023-09-06 14:19:25,475 MainThread INFO: EPOCH:283
2023-09-06 14:19:25,475 MainThread INFO: Time Consumed:10.053698301315308s
2023-09-06 14:19:25,476 MainThread INFO: Total Frames:426000s
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 284/400 [26:05<19:18,  9.98s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               644.47096
Train_Epoch_Reward                    6971.66737
Running_Training_Average_Rewards      649.23169
Explore_Time                          0.00271
Train___Time                          10.04231
Eval____Time                          0.00492
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.63065
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.57813
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -65.56144
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.47176
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.72178
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.76435
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.17493
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7128.62481
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.13185
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.65453
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           3.94491     0.41604    4.67431    3.38306
alpha_0                               0.45789     0.00019    0.45819    0.45760
alpha_1                               0.43632     0.00037    0.43690    0.43574
alpha_2                               0.43452     0.00036    0.43509    0.43395
alpha_3                               0.43266     0.00038    0.43326    0.43207
alpha_4                               0.43241     0.00038    0.43300    0.43182
alpha_5                               0.43663     0.00038    0.43723    0.43603
alpha_6                               0.43340     0.00038    0.43400    0.43280
alpha_7                               0.44098     0.00036    0.44155    0.44041
alpha_8                               0.43639     0.00038    0.43698    0.43579
alpha_9                               0.43675     0.00039    0.43735    0.43614
Alpha_loss                            -4.82061    0.02281    -4.78198   -4.85537
Training/policy_loss                  -59.08428   0.21947    -58.77719  -59.45396
Training/qf1_loss                     388.01898   175.61377  731.16260  195.05956
Training/qf2_loss                     383.07590   175.49621  724.90735  190.41539
Training/pf_norm                      0.21204     0.03771    0.27239    0.16111
Training/qf1_norm                     117.53727   68.79904   248.57367  27.46339
Training/qf2_norm                     117.25565   71.85524   258.82095  29.21591
log_std/mean                          -0.26768    0.00090    -0.26663   -0.26921
log_std/std                           0.13148     0.00020    0.13185    0.13118
log_std/max                           -0.11939    0.00066    -0.11819   -0.12045
log_std/min                           -0.69603    0.00946    -0.68236   -0.71291
log_probs/mean                        -1.81464    0.02657    -1.77492   -1.85685
log_probs/std                         1.62254     0.03149    1.66180    1.54780
log_probs/max                         5.44553     0.23794    5.91546    5.06484
log_probs/min                         -6.69215    0.78886    -5.41984   -7.96587
mean/mean                             0.10236     0.00205    0.10500    0.09893
mean/std                              0.54287     0.00081    0.54410    0.54166
mean/max                              1.50639     0.01085    1.52258    1.48799
mean/min                              -1.50833    0.00037    -1.50782   -1.50878
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 5, 2, 4, 1, 0, 8, 6, 3, 7]
replay_buffer._size: [42900 42900 42900 42900 42900 42900 42900 42900 42900 42900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.335603475570679 0.002053976058959961
train_time 10.338905572891235
2023-09-06 14:19:35,931 MainThread INFO: EPOCH:284
2023-09-06 14:19:35,932 MainThread INFO: Time Consumed:10.356454610824585s
2023-09-06 14:19:35,932 MainThread INFO: Total Frames:427500s
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 285/400 [26:15<19:24, 10.13s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               655.00611
Train_Epoch_Reward                    7030.74235
Running_Training_Average_Rewards      706.54483
Explore_Time                          0.00315
Train___Time                          10.33891
Eval____Time                          0.01024
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.79387
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.46127
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -66.03700
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.35585
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.45382
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.73643
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.35771
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7048.85731
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.64099
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.82581
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.37917     0.44734    4.85184    3.45964
alpha_0                               0.45725     0.00018    0.45753    0.45696
alpha_1                               0.43503     0.00037    0.43561    0.43445
alpha_2                               0.43326     0.00036    0.43382    0.43269
alpha_3                               0.43134     0.00038    0.43193    0.43074
alpha_4                               0.43110     0.00037    0.43169    0.43051
alpha_5                               0.43530     0.00038    0.43589    0.43470
alpha_6                               0.43207     0.00038    0.43266    0.43147
alpha_7                               0.43971     0.00037    0.44029    0.43914
alpha_8                               0.43507     0.00038    0.43566    0.43447
alpha_9                               0.43540     0.00039    0.43601    0.43479
Alpha_loss                            -4.84563    0.01626    -4.81793   -4.87394
Training/policy_loss                  -59.22273   0.11156    -59.07262  -59.43015
Training/qf1_loss                     463.76780   211.33940  849.25439  182.42551
Training/qf2_loss                     458.34776   210.41026  842.22443  177.55014
Training/pf_norm                      0.23561     0.04099    0.32465    0.19013
Training/qf1_norm                     228.92566   93.24410   370.17560  50.68575
Training/qf2_norm                     229.44830   93.87833   370.37619  51.39477
log_std/mean                          -0.26708    0.00014    -0.26690   -0.26736
log_std/std                           0.13150     0.00023    0.13185    0.13122
log_std/max                           -0.11842    0.00061    -0.11755   -0.11935
log_std/min                           -0.70321    0.00932    -0.68532   -0.71473
log_probs/mean                        -1.82423    0.01961    -1.78689   -1.84922
log_probs/std                         1.62910     0.03376    1.69564    1.59428
log_probs/max                         5.52548     0.25924    5.91688    5.21036
log_probs/min                         -6.69605    0.53085    -5.80952   -7.40038
mean/mean                             0.10403     0.00115    0.10566    0.10190
mean/std                              0.54102     0.00138    0.54333    0.53902
mean/max                              1.46046     0.01519    1.48368    1.43628
mean/min                              -1.50890    0.00273    -1.50308   -1.51195
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 2, 1, 4, 6, 9, 7, 8, 3, 5]
replay_buffer._size: [43050 43050 43050 43050 43050 43050 43050 43050 43050 43050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.770232439041138 0.0019855499267578125
train_time 9.773442029953003
2023-09-06 14:19:45,836 MainThread INFO: EPOCH:285
2023-09-06 14:19:45,837 MainThread INFO: Time Consumed:9.788411617279053s
2023-09-06 14:19:45,837 MainThread INFO: Total Frames:429000s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 286/400 [26:25<19:07, 10.07s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               677.44162
Train_Epoch_Reward                    6379.85746
Running_Training_Average_Rewards      679.40891
Explore_Time                          0.00325
Train___Time                          9.77344
Eval____Time                          0.00504
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -94.05891
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.29808
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -66.49447
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           653.34671
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.26024
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.54633
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.86493
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6974.39424
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.97908
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.12019
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.42372     0.38866    5.14482    3.81855
alpha_0                               0.45661     0.00019    0.45690    0.45631
alpha_1                               0.43375     0.00037    0.43433    0.43317
alpha_2                               0.43200     0.00036    0.43257    0.43144
alpha_3                               0.43002     0.00038    0.43061    0.42942
alpha_4                               0.42980     0.00037    0.43038    0.42922
alpha_5                               0.43397     0.00038    0.43457    0.43338
alpha_6                               0.43074     0.00038    0.43134    0.43015
alpha_7                               0.43844     0.00037    0.43901    0.43787
alpha_8                               0.43375     0.00038    0.43434    0.43315
alpha_9                               0.43405     0.00039    0.43465    0.43344
Alpha_loss                            -4.87400    0.01447    -4.84058   -4.89507
Training/policy_loss                  -59.56116   0.26155    -59.25499  -59.96675
Training/qf1_loss                     418.28192   169.91956  717.05157  212.56734
Training/qf2_loss                     412.74484   169.83244  709.43634  205.41377
Training/pf_norm                      0.25479     0.03887    0.34141    0.20389
Training/qf1_norm                     201.02476   107.32358  394.48865  48.30958
Training/qf2_norm                     203.17268   109.12981  402.19684  48.62949
log_std/mean                          -0.26707    0.00061    -0.26637   -0.26829
log_std/std                           0.13159     0.00028    0.13205    0.13118
log_std/max                           -0.11816    0.00050    -0.11749   -0.11894
log_std/min                           -0.69660    0.00830    -0.68848   -0.71724
log_probs/mean                        -1.83889    0.02116    -1.79152   -1.87077
log_probs/std                         1.58655     0.03998    1.65258    1.51076
log_probs/max                         5.20656     0.23942    5.70479    4.80086
log_probs/min                         -6.71599    0.58286    -6.02961   -8.07559
mean/mean                             0.09664     0.00300    0.10140    0.09186
mean/std                              0.53680     0.00143    0.53942    0.53521
mean/max                              1.41367     0.01006    1.43100    1.39917
mean/min                              -1.48687    0.00958    -1.47000   -1.50054
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 3, 1, 2, 6, 7, 0, 8, 4, 9]
replay_buffer._size: [43200 43200 43200 43200 43200 43200 43200 43200 43200 43200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.865960597991943 0.0020554065704345703
train_time 9.869264602661133
2023-09-06 14:19:55,852 MainThread INFO: EPOCH:286
2023-09-06 14:19:55,853 MainThread INFO: Time Consumed:9.884222984313965s
2023-09-06 14:19:55,853 MainThread INFO: Total Frames:430500s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 287/400 [26:35<18:56, 10.05s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               719.48584
Train_Epoch_Reward                    7835.32967
Running_Training_Average_Rewards      708.19765
Explore_Time                          0.00316
Train___Time                          9.86926
Eval____Time                          0.00507
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.18032
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.84639
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -66.46714
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1291.02925
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.39574
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.44091
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.36786
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7094.45998
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.14143
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.38763
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.40316     0.67999    5.35491    3.40724
alpha_0                               0.45594     0.00020    0.45625    0.45563
alpha_1                               0.43246     0.00037    0.43304    0.43188
alpha_2                               0.43075     0.00036    0.43131    0.43018
alpha_3                               0.42870     0.00038    0.42929    0.42811
alpha_4                               0.42851     0.00037    0.42909    0.42792
alpha_5                               0.43265     0.00038    0.43324    0.43206
alpha_6                               0.42943     0.00038    0.43002    0.42884
alpha_7                               0.43717     0.00036    0.43774    0.43661
alpha_8                               0.43243     0.00038    0.43302    0.43183
alpha_9                               0.43270     0.00039    0.43330    0.43209
Alpha_loss                            -4.91136    0.03940    -4.83063   -4.95979
Training/policy_loss                  -59.92559   0.24130    -59.49165  -60.27171
Training/qf1_loss                     448.99286   175.96984  725.20532  197.82832
Training/qf2_loss                     443.37122   175.09179  719.82239  191.88077
Training/pf_norm                      0.22264     0.02769    0.25849    0.16588
Training/qf1_norm                     222.12094   136.69131  439.26123  51.41858
Training/qf2_norm                     222.62249   141.33685  448.22012  56.24323
log_std/mean                          -0.26916    0.00040    -0.26844   -0.26995
log_std/std                           0.13103     0.00040    0.13163    0.13048
log_std/max                           -0.12074    0.00051    -0.11973   -0.12167
log_std/min                           -0.69673    0.00973    -0.67871   -0.71308
log_probs/mean                        -1.86421    0.04583    -1.77359   -1.92041
log_probs/std                         1.52137     0.06122    1.62211    1.41624
log_probs/max                         5.40585     0.46513    6.01660    4.38999
log_probs/min                         -6.64734    0.55759    -5.60357   -7.36765
mean/mean                             0.08736     0.00197    0.09105    0.08504
mean/std                              0.53170     0.00143    0.53379    0.52953
mean/max                              1.39732     0.00316    1.40434    1.39386
mean/min                              -1.44285    0.01372    -1.42445   -1.46514
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 6, 2, 7, 5, 0, 1, 4, 9, 3]
replay_buffer._size: [43350 43350 43350 43350 43350 43350 43350 43350 43350 43350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.307706356048584 0.0020241737365722656
train_time 5.311038255691528
2023-09-06 14:20:05,508 MainThread INFO: EPOCH:287
2023-09-06 14:20:05,509 MainThread INFO: Time Consumed:5.568102598190308s
2023-09-06 14:20:05,510 MainThread INFO: Total Frames:432000s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 288/400 [26:45<18:32,  9.93s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               753.68367
Train_Epoch_Reward                    5904.26437
Running_Training_Average_Rewards      670.64838
Explore_Time                          0.24365
Train___Time                          5.31104
Eval____Time                          0.00667
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.79937
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.55279
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -65.84572
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           717.70422
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.82785
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.24715
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.09668
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7345.21793
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.70129
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.72177
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.52887     0.51382    5.26422    3.75081
alpha_0                               0.45524     0.00020    0.45556    0.45492
alpha_1                               0.43116     0.00037    0.43175    0.43058
alpha_2                               0.42948     0.00036    0.43005    0.42891
alpha_3                               0.42739     0.00038    0.42798    0.42680
alpha_4                               0.42722     0.00037    0.42780    0.42664
alpha_5                               0.43134     0.00038    0.43193    0.43074
alpha_6                               0.42812     0.00038    0.42871    0.42754
alpha_7                               0.43592     0.00036    0.43648    0.43537
alpha_8                               0.43111     0.00038    0.43170    0.43051
alpha_9                               0.43135     0.00039    0.43196    0.43075
Alpha_loss                            -4.91328    0.02540    -4.87535   -4.95038
Training/policy_loss                  -60.26792   0.21811    -59.79349  -60.58375
Training/qf1_loss                     444.43995   179.47868  856.42834  229.97209
Training/qf2_loss                     439.17817   178.46576  849.02185  226.23367
Training/pf_norm                      0.21365     0.02382    0.26573    0.18395
Training/qf1_norm                     215.46690   143.06054  451.88193  39.71900
Training/qf2_norm                     218.90198   147.48610  453.22458  28.32199
log_std/mean                          -0.27150    0.00069    -0.27004   -0.27219
log_std/std                           0.13084     0.00023    0.13112    0.13046
log_std/max                           -0.12197    0.00083    -0.12083   -0.12339
log_std/min                           -0.69655    0.01191    -0.68136   -0.71369
log_probs/mean                        -1.84441    0.03390    -1.79106   -1.89690
log_probs/std                         1.58500     0.03716    1.65892    1.53914
log_probs/max                         5.50026     0.21409    5.80431    5.24515
log_probs/min                         -7.03286    0.79943    -5.96043   -8.94571
mean/mean                             0.08476     0.00040    0.08548    0.08409
mean/std                              0.53293     0.00143    0.53512    0.53019
mean/max                              1.42602     0.01206    1.44610    1.40710
mean/min                              -1.42999    0.00455    -1.42426   -1.43823
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 0, 3, 5, 7, 1, 2, 9, 8, 4]
replay_buffer._size: [43500 43500 43500 43500 43500 43500 43500 43500 43500 43500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.994263887405396 0.002573251724243164
train_time 9.998392343521118
2023-09-06 14:20:15,654 MainThread INFO: EPOCH:288
2023-09-06 14:20:15,655 MainThread INFO: Time Consumed:10.017745971679688s
2023-09-06 14:20:15,656 MainThread INFO: Total Frames:433500s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 289/400 [26:55<18:28,  9.99s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               813.42360
Train_Epoch_Reward                    10364.14616
Running_Training_Average_Rewards      803.45801
Explore_Time                          0.00283
Train___Time                          9.99839
Eval____Time                          0.01222
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.33138
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.59658
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.82675
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1901.71750
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.64761
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.49083
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.56423
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7506.72822
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.01357
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.65813
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.54590      0.58576    5.44760    3.63199
alpha_0                               0.45455      0.00019    0.45485    0.45425
alpha_1                               0.42987      0.00037    0.43045    0.42929
alpha_2                               0.42822      0.00036    0.42879    0.42765
alpha_3                               0.42608      0.00037    0.42667    0.42550
alpha_4                               0.42593      0.00037    0.42651    0.42535
alpha_5                               0.43002      0.00038    0.43061    0.42943
alpha_6                               0.42682      0.00037    0.42740    0.42623
alpha_7                               0.43470      0.00035    0.43525    0.43415
alpha_8                               0.42979      0.00038    0.43038    0.42920
alpha_9                               0.43002      0.00038    0.43062    0.42942
Alpha_loss                            -4.91520     0.01894    -4.89231   -4.94678
Training/policy_loss                  -60.39122    0.23182    -60.12142  -60.88812
Training/qf1_loss                     497.73978    199.00192  909.88147  209.02246
Training/qf2_loss                     492.96210    198.57700  904.85809  204.34348
Training/pf_norm                      0.25137      0.06864    0.40352    0.15407
Training/qf1_norm                     219.50078    152.96706  480.35904  28.71688
Training/qf2_norm                     223.54156    154.83417  486.66068  32.45480
log_std/mean                          -0.27186     0.00025    -0.27160   -0.27241
log_std/std                           0.13124      0.00063    0.13263    0.13054
log_std/max                           -0.12433     0.00127    -0.12227   -0.12667
log_std/min                           -0.69230     0.00778    -0.67876   -0.70961
log_probs/mean                        -1.82501     0.02446    -1.79437   -1.86497
log_probs/std                         1.60969      0.05441    1.72065    1.54616
log_probs/max                         5.51799      0.28897    6.06908    5.01635
log_probs/min                         -6.82746     0.39998    -6.26298   -7.53325
mean/mean                             0.08587      0.00067    0.08737    0.08502
mean/std                              0.53778      0.00316    0.54441    0.53415
mean/max                              1.47767      0.02130    1.51306    1.44787
mean/min                              -1.46553     0.02219    -1.43970   -1.50589
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 6, 1, 5, 9, 2, 7, 4, 0, 8]
replay_buffer._size: [43650 43650 43650 43650 43650 43650 43650 43650 43650 43650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.155702352523804 0.0019555091857910156
train_time 10.158867120742798
2023-09-06 14:20:25,935 MainThread INFO: EPOCH:289
2023-09-06 14:20:25,966 MainThread INFO: Time Consumed:10.174518585205078s
2023-09-06 14:20:25,967 MainThread INFO: Total Frames:435000s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 290/400 [27:05<18:30, 10.10s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               854.03253
Train_Epoch_Reward                    9506.59009
Running_Training_Average_Rewards      859.16669
Explore_Time                          0.00299
Train___Time                          10.15887
Eval____Time                          0.00849
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.86599
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.96507
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.20110
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2076.80284
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.21529
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.58098
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.09530
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7521.04139
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.03697
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.35388
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.26909     0.37749    4.80030    3.63347
alpha_0                               0.45390     0.00017    0.45418    0.45363
alpha_1                               0.42858     0.00037    0.42916    0.42801
alpha_2                               0.42696     0.00036    0.42752    0.42640
alpha_3                               0.42478     0.00037    0.42537    0.42420
alpha_4                               0.42464     0.00037    0.42522    0.42406
alpha_5                               0.42870     0.00038    0.42929    0.42810
alpha_6                               0.42552     0.00037    0.42610    0.42493
alpha_7                               0.43348     0.00035    0.43403    0.43293
alpha_8                               0.42847     0.00038    0.42907    0.42788
alpha_9                               0.42869     0.00038    0.42928    0.42809
Alpha_loss                            -4.90884    0.03138    -4.87385   -4.97298
Training/policy_loss                  -60.78417   0.16692    -60.41545  -60.99206
Training/qf1_loss                     394.92659   159.67352  713.74866  173.44650
Training/qf2_loss                     389.69178   159.20901  707.69800  169.09146
Training/pf_norm                      0.25873     0.03967    0.32515    0.18881
Training/qf1_norm                     127.58031   59.04892   235.92059  27.34460
Training/qf2_norm                     131.46503   62.43529   245.80994  26.33944
log_std/mean                          -0.27176    0.00054    -0.27053   -0.27237
log_std/std                           0.13340     0.00064    0.13427    0.13249
log_std/max                           -0.12727    0.00100    -0.12489   -0.12869
log_std/min                           -0.69162    0.01050    -0.67517   -0.71119
log_probs/mean                        -1.79524    0.03766    -1.74695   -1.86517
log_probs/std                         1.68153     0.05547    1.78590    1.60353
log_probs/max                         5.81887     0.39141    6.65378    5.27463
log_probs/min                         -6.27598    0.62054    -5.13460   -7.47024
mean/mean                             0.08531     0.00114    0.08701    0.08327
mean/std                              0.54946     0.00317    0.55402    0.54455
mean/max                              1.54381     0.01547    1.56680    1.51905
mean/min                              -1.56472    0.02905    -1.51723   -1.60645
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 6, 7, 5, 9, 0, 2, 1, 4, 3]
replay_buffer._size: [43800 43800 43800 43800 43800 43800 43800 43800 43800 43800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.21544075012207 0.0020895004272460938
train_time 5.218736171722412
2023-09-06 14:20:35,702 MainThread INFO: EPOCH:290
2023-09-06 14:20:35,702 MainThread INFO: Time Consumed:5.235052108764648s
2023-09-06 14:20:35,702 MainThread INFO: Total Frames:436500s
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 291/400 [27:15<18:07,  9.98s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               897.77743
Train_Epoch_Reward                    6525.97937
Running_Training_Average_Rewards      879.89052
Explore_Time                          0.00671
Train___Time                          5.21874
Eval____Time                          0.00527
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.04026
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.69640
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.21021
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1984.88354
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.98529
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.72969
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.68522
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7389.16176
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.91861
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.30287
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.47134     0.60248    5.36764    3.47513
alpha_0                               0.45332     0.00016    0.45358    0.45307
alpha_1                               0.42731     0.00037    0.42788    0.42673
alpha_2                               0.42571     0.00036    0.42627    0.42514
alpha_3                               0.42349     0.00037    0.42407    0.42291
alpha_4                               0.42336     0.00037    0.42394    0.42279
alpha_5                               0.42737     0.00038    0.42797    0.42678
alpha_6                               0.42421     0.00037    0.42480    0.42363
alpha_7                               0.43226     0.00035    0.43281    0.43171
alpha_8                               0.42717     0.00037    0.42775    0.42658
alpha_9                               0.42736     0.00038    0.42796    0.42677
Alpha_loss                            -4.91667    0.02711    -4.87671   -4.96568
Training/policy_loss                  -60.94664   0.17364    -60.58965  -61.17903
Training/qf1_loss                     481.60327   221.87386  909.30353  188.71306
Training/qf2_loss                     476.51732   221.61026  905.32361  184.93054
Training/pf_norm                      0.21925     0.02951    0.27078    0.17709
Training/qf1_norm                     218.00462   121.67313  459.93283  53.74104
Training/qf2_norm                     221.55697   123.22715  461.09589  53.45512
log_std/mean                          -0.26959    0.00063    -0.26844   -0.27042
log_std/std                           0.13490     0.00037    0.13543    0.13433
log_std/max                           -0.12370    0.00083    -0.12189   -0.12472
log_std/min                           -0.69975    0.00829    -0.68782   -0.71794
log_probs/mean                        -1.78365    0.03029    -1.73793   -1.83392
log_probs/std                         1.70542     0.03085    1.74607    1.64423
log_probs/max                         5.88816     0.43310    6.66465    5.17694
log_probs/min                         -6.77850    1.14560    -5.60573   -8.97072
mean/mean                             0.07829     0.00361    0.08299    0.07178
mean/std                              0.55799     0.00151    0.56004    0.55492
mean/max                              1.59085     0.00843    1.60081    1.57296
mean/min                              -1.64255    0.01464    -1.61539   -1.66209
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 2, 8, 9, 7, 4, 3, 1, 5, 6]
replay_buffer._size: [43950 43950 43950 43950 43950 43950 43950 43950 43950 43950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.287268877029419 0.0019347667694091797
train_time 10.290401458740234
2023-09-06 14:20:46,118 MainThread INFO: EPOCH:291
2023-09-06 14:20:46,118 MainThread INFO: Time Consumed:10.308050870895386s
2023-09-06 14:20:46,119 MainThread INFO: Total Frames:438000s
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 292/400 [27:25<18:12, 10.11s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               824.40909
Train_Epoch_Reward                    6648.29965
Running_Training_Average_Rewards      756.02897
Explore_Time                          0.00294
Train___Time                          10.29040
Eval____Time                          0.01040
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.28145
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.31114
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.84950
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.46755
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.19176
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.38055
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.99481
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7215.00208
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.72842
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.53048
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.72931     0.75615    5.88707     3.16009
alpha_0                               0.45277     0.00016    0.45302     0.45253
alpha_1                               0.42603     0.00037    0.42661     0.42546
alpha_2                               0.42446     0.00036    0.42502     0.42389
alpha_3                               0.42220     0.00037    0.42278     0.42162
alpha_4                               0.42209     0.00037    0.42266     0.42151
alpha_5                               0.42606     0.00038    0.42665     0.42546
alpha_6                               0.42292     0.00037    0.42350     0.42234
alpha_7                               0.43103     0.00035    0.43158     0.43047
alpha_8                               0.42587     0.00037    0.42645     0.42529
alpha_9                               0.42605     0.00038    0.42663     0.42546
Alpha_loss                            -4.92880    0.02271    -4.88629    -4.95886
Training/policy_loss                  -61.20945   0.29998    -60.69681   -61.66113
Training/qf1_loss                     517.66872   239.93287  1057.97205  228.45743
Training/qf2_loss                     512.80991   239.81634  1053.91455  224.47595
Training/pf_norm                      0.21262     0.02973    0.27717     0.17948
Training/qf1_norm                     288.26442   170.53848  616.66632   47.83677
Training/qf2_norm                     293.31308   173.05843  622.67822   44.01561
log_std/mean                          -0.26839    0.00016    -0.26811    -0.26866
log_std/std                           0.13383     0.00065    0.13474     0.13254
log_std/max                           -0.12326    0.00056    -0.12224    -0.12433
log_std/min                           -0.70913    0.01012    -0.68938    -0.71995
log_probs/mean                        -1.77765    0.02760    -1.73147    -1.81495
log_probs/std                         1.70580     0.03078    1.74962     1.63677
log_probs/max                         5.92338     0.19249    6.29120     5.64496
log_probs/min                         -6.73385    1.03883    -5.24449    -8.46669
mean/mean                             0.06363     0.00440    0.07051     0.05708
mean/std                              0.55942     0.00100    0.56134     0.55771
mean/max                              1.59436     0.00559    1.60327     1.58526
mean/min                              -1.67088    0.00322    -1.66427    -1.67499
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 1, 7, 2, 8, 6, 9, 3, 4, 5]
replay_buffer._size: [44100 44100 44100 44100 44100 44100 44100 44100 44100 44100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.489644527435303 0.001967191696166992
train_time 10.492843627929688
2023-09-06 14:20:56,744 MainThread INFO: EPOCH:292
2023-09-06 14:20:56,744 MainThread INFO: Time Consumed:10.502652168273926s
2023-09-06 14:20:56,745 MainThread INFO: Total Frames:439500s
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 293/400 [27:36<18:18, 10.27s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               740.97543
Train_Epoch_Reward                    8427.78916
Running_Training_Average_Rewards      720.06894
Explore_Time                          0.00323
Train___Time                          10.49284
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.78042
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.59558
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.97375
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.03427
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.31136
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.37405
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.34024
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7116.60404
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.42029
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.25428
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.71726     0.65350    6.09473     3.88916
alpha_0                               0.45223     0.00016    0.45248     0.45198
alpha_1                               0.42476     0.00037    0.42533     0.42418
alpha_2                               0.42320     0.00036    0.42377     0.42264
alpha_3                               0.42091     0.00037    0.42149     0.42033
alpha_4                               0.42081     0.00037    0.42139     0.42024
alpha_5                               0.42474     0.00038    0.42533     0.42415
alpha_6                               0.42163     0.00037    0.42221     0.42105
alpha_7                               0.42980     0.00035    0.43035     0.42924
alpha_8                               0.42458     0.00037    0.42516     0.42400
alpha_9                               0.42474     0.00037    0.42533     0.42416
Alpha_loss                            -4.96628    0.01720    -4.94166    -4.99775
Training/policy_loss                  -61.56461   0.23223    -61.20638   -61.91560
Training/qf1_loss                     571.24838   290.97054  1043.32422  233.09383
Training/qf2_loss                     565.75050   290.33209  1035.12415  227.91211
Training/pf_norm                      0.18961     0.02275    0.23913     0.15562
Training/qf1_norm                     231.65415   192.49604  655.28381   32.23307
Training/qf2_norm                     235.96500   195.70634  664.51208   29.01898
log_std/mean                          -0.26737    0.00059    -0.26659    -0.26817
log_std/std                           0.13174     0.00063    0.13261     0.13091
log_std/max                           -0.12335    0.00041    -0.12262    -0.12393
log_std/min                           -0.69459    0.01034    -0.68356    -0.71570
log_probs/mean                        -1.80262    0.01774    -1.77776    -1.83474
log_probs/std                         1.67150     0.03415    1.72604     1.60388
log_probs/max                         5.82090     0.39047    6.42450     5.05782
log_probs/min                         -6.72979    0.95969    -5.89140    -9.26487
mean/mean                             0.04920     0.00390    0.05530     0.04326
mean/std                              0.55662     0.00183    0.55893     0.55382
mean/max                              1.57193     0.00621    1.58057     1.56237
mean/min                              -1.66680    0.00596    -1.65578    -1.67324
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 8, 0, 4, 9, 3, 6, 7, 2, 1]
replay_buffer._size: [44250 44250 44250 44250 44250 44250 44250 44250 44250 44250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.331889867782593 0.0031795501708984375
train_time 10.336933851242065
2023-09-06 14:21:07,220 MainThread INFO: EPOCH:293
2023-09-06 14:21:07,221 MainThread INFO: Time Consumed:10.354893445968628s
2023-09-06 14:21:07,221 MainThread INFO: Total Frames:441000s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 294/400 [27:46<18:14, 10.33s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               665.45518
Train_Epoch_Reward                    5823.09659
Running_Training_Average_Rewards      696.63951
Explore_Time                          0.00368
Train___Time                          10.33693
Eval____Time                          0.00985
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.80767
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.37375
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.70396
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.19359
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.89011
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.37742
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.88617
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7146.52040
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.10050
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.31813
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.37766     0.58993    5.47193    3.60164
alpha_0                               0.45167     0.00017    0.45193    0.45141
alpha_1                               0.42348     0.00037    0.42406    0.42290
alpha_2                               0.42195     0.00036    0.42252    0.42139
alpha_3                               0.41963     0.00037    0.42020    0.41905
alpha_4                               0.41954     0.00036    0.42011    0.41898
alpha_5                               0.42343     0.00038    0.42402    0.42284
alpha_6                               0.42035     0.00037    0.42093    0.41978
alpha_7                               0.42857     0.00035    0.42912    0.42802
alpha_8                               0.42329     0.00037    0.42387    0.42272
alpha_9                               0.42344     0.00037    0.42403    0.42286
Alpha_loss                            -4.98997    0.02947    -4.94447   -5.06206
Training/policy_loss                  -61.82007   0.20502    -61.45004  -62.18739
Training/qf1_loss                     450.75285   189.83714  757.57361  252.26860
Training/qf2_loss                     445.34950   189.83172  754.39862  245.61679
Training/pf_norm                      0.23014     0.05340    0.37111    0.17346
Training/qf1_norm                     177.89793   129.33952  451.34436  34.74081
Training/qf2_norm                     176.53945   132.20445  461.45367  28.86689
log_std/mean                          -0.26563    0.00051    -0.26510   -0.26646
log_std/std                           0.13049     0.00042    0.13120    0.12991
log_std/max                           -0.12408    0.00052    -0.12314   -0.12475
log_std/min                           -0.70310    0.00825    -0.69001   -0.71473
log_probs/mean                        -1.81099    0.03354    -1.76169   -1.88970
log_probs/std                         1.65023     0.03939    1.70657    1.56443
log_probs/max                         5.61051     0.34933    6.31620    5.12267
log_probs/min                         -6.67536    1.02759    -5.61614   -8.80602
mean/mean                             0.03821     0.00292    0.04284    0.03344
mean/std                              0.55239     0.00179    0.55509    0.54935
mean/max                              1.55398     0.00567    1.56245    1.54530
mean/min                              -1.64378    0.00589    -1.63521   -1.65350
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 3, 0, 1, 7, 8, 9, 2, 6, 5]
replay_buffer._size: [44400 44400 44400 44400 44400 44400 44400 44400 44400 44400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.761605262756348 0.001954317092895508
train_time 9.764759302139282
2023-09-06 14:21:17,102 MainThread INFO: EPOCH:294
2023-09-06 14:21:17,102 MainThread INFO: Time Consumed:9.773432970046997s
2023-09-06 14:21:17,102 MainThread INFO: Total Frames:442500s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 295/400 [27:56<17:50, 10.19s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               665.04695
Train_Epoch_Reward                    9138.36857
Running_Training_Average_Rewards      779.64181
Explore_Time                          0.00249
Train___Time                          9.76476
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.66416
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.78204
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.22404
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.58208
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.81475
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.62321
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.83358
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7221.74989
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.71496
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.49160
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.56706     0.83529    6.25276     3.29498
alpha_0                               0.45107     0.00018    0.45135     0.45079
alpha_1                               0.42220     0.00037    0.42278     0.42162
alpha_2                               0.42070     0.00036    0.42126     0.42014
alpha_3                               0.41835     0.00037    0.41892     0.41778
alpha_4                               0.41828     0.00036    0.41885     0.41772
alpha_5                               0.42212     0.00038    0.42271     0.42153
alpha_6                               0.41907     0.00037    0.41965     0.41850
alpha_7                               0.42736     0.00035    0.42790     0.42681
alpha_8                               0.42202     0.00037    0.42259     0.42144
alpha_9                               0.42214     0.00037    0.42273     0.42156
Alpha_loss                            -5.02096    0.02545    -4.98793    -5.05918
Training/policy_loss                  -61.78158   0.28175    -61.36882   -62.17730
Training/qf1_loss                     567.38999   352.42799  1392.79285  187.98526
Training/qf2_loss                     560.95003   351.05125  1382.30945  183.25659
Training/pf_norm                      0.24425     0.02827    0.29412     0.20832
Training/qf1_norm                     270.49964   179.33453  750.25488   89.02321
Training/qf2_norm                     274.18659   183.60208  760.06696   79.29665
log_std/mean                          -0.26602    0.00032    -0.26548    -0.26638
log_std/std                           0.12975     0.00033    0.13049     0.12927
log_std/max                           -0.12682    0.00113    -0.12467    -0.12825
log_std/min                           -0.69895    0.01166    -0.68349    -0.71430
log_probs/mean                        -1.82836    0.02686    -1.79043    -1.86772
log_probs/std                         1.60584     0.02944    1.65043     1.56543
log_probs/max                         5.42079     0.31018    6.00760     4.92685
log_probs/min                         -6.49217    0.72640    -5.43646    -7.98761
mean/mean                             0.03212     0.00053    0.03306     0.03117
mean/std                              0.54756     0.00161    0.55083     0.54494
mean/max                              1.54179     0.00136    1.54416     1.53979
mean/min                              -1.61800    0.00997    -1.60245    -1.63298
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 2, 1, 6, 4, 3, 8, 7, 5, 0]
replay_buffer._size: [44550 44550 44550 44550 44550 44550 44550 44550 44550 44550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.31666088104248 0.001978635787963867
train_time 10.319858312606812
2023-09-06 14:21:27,543 MainThread INFO: EPOCH:295
2023-09-06 14:21:27,543 MainThread INFO: Time Consumed:10.330368280410767s
2023-09-06 14:21:27,543 MainThread INFO: Total Frames:444000s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 296/400 [28:07<17:47, 10.27s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               677.16097
Train_Epoch_Reward                    6303.09235
Running_Training_Average_Rewards      708.81858
Explore_Time                          0.00388
Train___Time                          10.31986
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.38859
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.20750
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -63.48757
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.63901
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.08826
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.64339
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.91352
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7478.77908
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.38052
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.09023
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.48584     0.47600    5.28978    3.71615
alpha_0                               0.45044     0.00019    0.45073    0.45015
alpha_1                               0.42092     0.00037    0.42150    0.42035
alpha_2                               0.41945     0.00036    0.42001    0.41888
alpha_3                               0.41708     0.00036    0.41765    0.41651
alpha_4                               0.41703     0.00036    0.41759    0.41647
alpha_5                               0.42081     0.00038    0.42140    0.42022
alpha_6                               0.41779     0.00037    0.41837    0.41721
alpha_7                               0.42616     0.00034    0.42669    0.42562
alpha_8                               0.42074     0.00037    0.42131    0.42017
alpha_9                               0.42085     0.00037    0.42143    0.42026
Alpha_loss                            -5.05693    0.01816    -5.03169   -5.08171
Training/policy_loss                  -61.99881   0.22425    -61.69080  -62.40925
Training/qf1_loss                     443.45836   94.03081   605.63293  289.84155
Training/qf2_loss                     437.58287   93.82207   599.45038  283.96378
Training/pf_norm                      0.22617     0.03059    0.27099    0.16870
Training/qf1_norm                     183.64045   117.97758  429.98978  42.64260
Training/qf2_norm                     189.29374   117.65184  437.24515  41.86967
log_std/mean                          -0.26456    0.00077    -0.26313   -0.26570
log_std/std                           0.12995     0.00048    0.13064    0.12927
log_std/max                           -0.12534    0.00172    -0.12179   -0.12773
log_std/min                           -0.69423    0.00936    -0.67572   -0.70694
log_probs/mean                        -1.85031    0.01945    -1.82623   -1.88341
log_probs/std                         1.60178     0.02722    1.63985    1.54435
log_probs/max                         5.25092     0.36900    5.98996    4.67678
log_probs/min                         -6.64638    0.68946    -5.53547   -8.10597
mean/mean                             0.03610     0.00195    0.03855    0.03278
mean/std                              0.54498     0.00074    0.54593    0.54327
mean/max                              1.55534     0.00636    1.56341    1.54619
mean/min                              -1.58299    0.00981    -1.56736   -1.59891
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 4, 5, 7, 6, 3, 9, 0, 1, 2]
replay_buffer._size: [44700 44700 44700 44700 44700 44700 44700 44700 44700 44700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.125168800354004 0.0019297599792480469
train_time 10.12829065322876
2023-09-06 14:21:37,795 MainThread INFO: EPOCH:296
2023-09-06 14:21:37,795 MainThread INFO: Time Consumed:10.137993335723877s
2023-09-06 14:21:37,795 MainThread INFO: Total Frames:445500s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 297/400 [28:17<17:37, 10.26s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               706.25139
Train_Epoch_Reward                    7591.52330
Running_Training_Average_Rewards      767.76614
Explore_Time                          0.00310
Train___Time                          10.12829
Eval____Time                          0.00282
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.97403
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.14906
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.91612
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.25717
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.70044
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.50297
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.02065
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8005.55870
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.15694
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.29964
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.73082     0.66060    5.77547    3.62042
alpha_0                               0.44979     0.00019    0.45008    0.44949
alpha_1                               0.41964     0.00037    0.42022    0.41907
alpha_2                               0.41819     0.00036    0.41876    0.41762
alpha_3                               0.41582     0.00036    0.41639    0.41525
alpha_4                               0.41579     0.00036    0.41634    0.41523
alpha_5                               0.41950     0.00038    0.42009    0.41891
alpha_6                               0.41650     0.00037    0.41708    0.41592
alpha_7                               0.42497     0.00034    0.42550    0.42444
alpha_8                               0.41946     0.00037    0.42004    0.41889
alpha_9                               0.41954     0.00037    0.42013    0.41896
Alpha_loss                            -5.09299    0.02349    -5.04499   -5.13018
Training/policy_loss                  -62.47637   0.17795    -62.05003  -62.73712
Training/qf1_loss                     600.22263   210.02342  911.42981  248.20227
Training/qf2_loss                     594.91836   209.30129  905.97784  244.84624
Training/pf_norm                      0.20566     0.01619    0.22547    0.17172
Training/qf1_norm                     288.12406   129.10101  554.14642  133.86438
Training/qf2_norm                     294.99288   132.61910  559.81866  125.52181
log_std/mean                          -0.26255    0.00043    -0.26198   -0.26340
log_std/std                           0.13166     0.00044    0.13257    0.13112
log_std/max                           -0.12035    0.00125    -0.11886   -0.12260
log_std/min                           -0.69608    0.00682    -0.68544   -0.70677
log_probs/mean                        -1.87203    0.02705    -1.81420   -1.91215
log_probs/std                         1.60359     0.03453    1.67835    1.55306
log_probs/max                         5.51363     0.35488    6.04338    4.85919
log_probs/min                         -6.91666    0.71418    -5.82355   -8.09769
mean/mean                             0.03879     0.00053    0.03938    0.03791
mean/std                              0.54367     0.00125    0.54554    0.54170
mean/max                              1.56559     0.00294    1.57093    1.56267
mean/min                              -1.55745    0.00552    -1.55103   -1.56577
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 0, 4, 5, 3, 1, 2, 7, 8, 6]
replay_buffer._size: [44850 44850 44850 44850 44850 44850 44850 44850 44850 44850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.120297193527222 0.0019307136535644531
train_time 10.12342119216919
2023-09-06 14:21:48,048 MainThread INFO: EPOCH:297
2023-09-06 14:21:48,048 MainThread INFO: Time Consumed:10.1364905834198s
2023-09-06 14:21:48,048 MainThread INFO: Total Frames:447000s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 298/400 [28:27<17:26, 10.26s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.89042
Train_Epoch_Reward                    6960.50170
Running_Training_Average_Rewards      695.17058
Explore_Time                          0.00281
Train___Time                          10.12342
Eval____Time                          0.00622
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.68168
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.61231
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.56683
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.58938
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.44211
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.00146
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.21927
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8421.93528
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.55874
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.07322
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.55793     0.64976    5.56888     3.35746
alpha_0                               0.44913     0.00019    0.44942     0.44883
alpha_1                               0.41837     0.00037    0.41894     0.41780
alpha_2                               0.41693     0.00036    0.41750     0.41636
alpha_3                               0.41456     0.00036    0.41513     0.41400
alpha_4                               0.41455     0.00035    0.41510     0.41400
alpha_5                               0.41818     0.00038    0.41877     0.41759
alpha_6                               0.41522     0.00037    0.41580     0.41464
alpha_7                               0.42379     0.00034    0.42432     0.42326
alpha_8                               0.41819     0.00037    0.41876     0.41762
alpha_9                               0.41825     0.00037    0.41883     0.41766
Alpha_loss                            -5.06851    0.01854    -5.03874    -5.10518
Training/policy_loss                  -62.84727   0.21101    -62.49552   -63.23046
Training/qf1_loss                     499.79603   264.30869  1178.16040  217.88802
Training/qf2_loss                     493.84467   263.74453  1171.12231  213.19478
Training/pf_norm                      0.19643     0.02708    0.26394     0.17382
Training/qf1_norm                     228.49429   109.92021  436.53320   37.51352
Training/qf2_norm                     230.78706   110.60661  440.86322   37.68992
log_std/mean                          -0.26303    0.00018    -0.26276    -0.26327
log_std/std                           0.13310     0.00032    0.13377     0.13266
log_std/max                           -0.11839    0.00083    -0.11706    -0.11938
log_std/min                           -0.68792    0.00867    -0.67373    -0.70520
log_probs/mean                        -1.82283    0.02236    -1.78758    -1.86044
log_probs/std                         1.61821     0.04859    1.67370     1.49185
log_probs/max                         5.62622     0.26034    6.06596     5.24895
log_probs/min                         -6.87598    0.67943    -5.93431    -8.04811
mean/mean                             0.03654     0.00080    0.03781     0.03536
mean/std                              0.54245     0.00093    0.54391     0.54115
mean/max                              1.56798     0.00176    1.57197     1.56473
mean/min                              -1.55203    0.00085    -1.55045    -1.55289
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 1, 6, 7, 0, 2, 8, 4, 5, 3]
replay_buffer._size: [45000 45000 45000 45000 45000 45000 45000 45000 45000 45000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.827405452728271 0.002002716064453125
train_time 9.830649375915527
2023-09-06 14:21:57,989 MainThread INFO: EPOCH:298
2023-09-06 14:21:57,990 MainThread INFO: Time Consumed:9.840887069702148s
2023-09-06 14:21:57,990 MainThread INFO: Total Frames:448500s
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 299/400 [28:37<17:07, 10.17s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               784.97116
Train_Epoch_Reward                    8522.86238
Running_Training_Average_Rewards      769.16291
Explore_Time                          0.00304
Train___Time                          9.83065
Eval____Time                          0.00267
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.26743
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.98931
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.88171
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.36315
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.08710
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.90404
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -54.14628
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8609.22062
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.45129
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.76749
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.83057     0.54172    5.59988    4.06333
alpha_0                               0.44847     0.00019    0.44877    0.44818
alpha_1                               0.41710     0.00036    0.41767    0.41653
alpha_2                               0.41567     0.00036    0.41624    0.41510
alpha_3                               0.41332     0.00036    0.41388    0.41276
alpha_4                               0.41332     0.00035    0.41387    0.41276
alpha_5                               0.41687     0.00038    0.41746    0.41628
alpha_6                               0.41393     0.00037    0.41451    0.41336
alpha_7                               0.42262     0.00033    0.42314    0.42209
alpha_8                               0.41692     0.00037    0.41749    0.41635
alpha_9                               0.41695     0.00037    0.41753    0.41637
Alpha_loss                            -5.11217    0.02116    -5.08817   -5.15185
Training/policy_loss                  -62.92173   0.27887    -62.46424  -63.28323
Training/qf1_loss                     566.05973   218.83454  960.28894  283.76120
Training/qf2_loss                     560.67151   218.94623  955.11133  279.39920
Training/pf_norm                      0.23576     0.02803    0.30500    0.19501
Training/qf1_norm                     239.14359   163.68760  484.38757  37.46741
Training/qf2_norm                     245.37980   165.56417  489.49088  44.54807
log_std/mean                          -0.26349    0.00050    -0.26233   -0.26409
log_std/std                           0.13231     0.00029    0.13276    0.13168
log_std/max                           -0.12011    0.00110    -0.11777   -0.12195
log_std/min                           -0.67629    0.00817    -0.66265   -0.69112
log_probs/mean                        -1.85382    0.02741    -1.81562   -1.90726
log_probs/std                         1.60255     0.03022    1.65861    1.56598
log_probs/max                         5.45690     0.25603    5.96590    5.16972
log_probs/min                         -7.07228    0.83638    -6.15994   -8.97821
mean/mean                             0.03584     0.00028    0.03626    0.03532
mean/std                              0.53980     0.00085    0.54076    0.53833
mean/max                              1.58029     0.01116    1.60359    1.56725
mean/min                              -1.55598    0.00399    -1.55070   -1.56401
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 0, 5, 4, 9, 6, 3, 7, 1, 2]
replay_buffer._size: [45150 45150 45150 45150 45150 45150 45150 45150 45150 45150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.3242223262786865 0.0020911693572998047
train_time 6.327574014663696
2023-09-06 14:22:08,386 MainThread INFO: EPOCH:299
2023-09-06 14:22:08,387 MainThread INFO: Time Consumed:9.733397006988525s
2023-09-06 14:22:08,387 MainThread INFO: Total Frames:450000s
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 300/400 [28:48<17:04, 10.24s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               798.48337
Train_Epoch_Reward                    10198.16412
Running_Training_Average_Rewards      856.05094
Explore_Time                          3.39850
Train___Time                          6.32757
Eval____Time                          0.00255
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.04774
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.62940
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.97215
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.57424
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.36549
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.09919
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.30493
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8396.95167
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.67655
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.33406
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.23493      0.68434    5.76304    3.28142
alpha_0                               0.44781      0.00019    0.44811    0.44751
alpha_1                               0.41583      0.00036    0.41640    0.41526
alpha_2                               0.41442      0.00036    0.41498    0.41385
alpha_3                               0.41207      0.00036    0.41263    0.41151
alpha_4                               0.41209      0.00035    0.41264    0.41153
alpha_5                               0.41556      0.00038    0.41615    0.41497
alpha_6                               0.41265      0.00037    0.41323    0.41208
alpha_7                               0.42145      0.00033    0.42198    0.42093
alpha_8                               0.41565      0.00037    0.41622    0.41507
alpha_9                               0.41566      0.00037    0.41624    0.41508
Alpha_loss                            -5.14309     0.01606    -5.10939   -5.16644
Training/policy_loss                  -63.07688    0.16038    -62.74459  -63.27926
Training/qf1_loss                     357.50920    170.16685  743.96216  168.28419
Training/qf2_loss                     351.91583    169.57102  736.78381  162.84692
Training/pf_norm                      0.24991      0.03260    0.31287    0.19773
Training/qf1_norm                     177.58337    122.50569  476.98621  34.31742
Training/qf2_norm                     177.53525    121.69624  485.93826  41.76371
log_std/mean                          -0.26483     0.00062    -0.26396   -0.26582
log_std/std                           0.13220      0.00034    0.13289    0.13181
log_std/max                           -0.11959     0.00079    -0.11800   -0.12054
log_std/min                           -0.67248     0.00675    -0.66162   -0.68234
log_probs/mean                        -1.86920     0.02148    -1.82434   -1.90713
log_probs/std                         1.60892      0.04379    1.69806    1.54014
log_probs/max                         5.58598      0.35877    6.17797    5.00812
log_probs/min                         -6.13644     0.44950    -5.14486   -6.64361
mean/mean                             0.03406      0.00188    0.03634    0.03072
mean/std                              0.54215      0.00151    0.54456    0.54011
mean/max                              1.61978      0.01342    1.63990    1.59871
mean/min                              -1.57790     0.00901    -1.56331   -1.59113
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 5, 7, 4, 6, 1, 9, 8, 2, 3]
replay_buffer._size: [45300 45300 45300 45300 45300 45300 45300 45300 45300 45300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.354098320007324 0.0019578933715820312
train_time 5.357259035110474
2023-09-06 14:22:25,521 MainThread INFO: EPOCH:300
2023-09-06 14:22:25,522 MainThread INFO: Time Consumed:5.627312183380127s
2023-09-06 14:22:25,522 MainThread INFO: Total Frames:451500s
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 301/400 [29:05<20:42, 12.55s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               778.93838
Train_Epoch_Reward                    10181.03264
Running_Training_Average_Rewards      963.40197
Explore_Time                          0.26186
Train___Time                          5.35726
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.90488
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.32258
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.28560
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.88856
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.50658
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.75825
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.06805
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7838.13047
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.78031
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.77510
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.59043      0.56211    5.56544     3.58170
alpha_0                               0.44715      0.00019    0.44745     0.44686
alpha_1                               0.41456      0.00036    0.41513     0.41400
alpha_2                               0.41317      0.00036    0.41373     0.41261
alpha_3                               0.41083      0.00036    0.41139     0.41027
alpha_4                               0.41085      0.00035    0.41141     0.41030
alpha_5                               0.41425      0.00038    0.41484     0.41366
alpha_6                               0.41139      0.00036    0.41196     0.41082
alpha_7                               0.42029      0.00033    0.42081     0.41977
alpha_8                               0.41437      0.00037    0.41495     0.41380
alpha_9                               0.41438      0.00037    0.41495     0.41381
Alpha_loss                            -5.13428     0.02283    -5.10207    -5.16609
Training/policy_loss                  -63.21523    0.23094    -62.95419   -63.70961
Training/qf1_loss                     481.33357    209.74709  1060.76575  277.70917
Training/qf2_loss                     474.85985    210.02786  1053.43103  269.82803
Training/pf_norm                      0.24398      0.02536    0.30009     0.21275
Training/qf1_norm                     204.41330    148.29857  485.43918   43.91703
Training/qf2_norm                     211.66767    148.92363  488.14096   39.58426
log_std/mean                          -0.26495     0.00088    -0.26383    -0.26630
log_std/std                           0.13221      0.00051    0.13315     0.13154
log_std/max                           -0.11995     0.00105    -0.11823    -0.12168
log_std/min                           -0.67793     0.00869    -0.66227    -0.69071
log_probs/mean                        -1.83869     0.02664    -1.80027    -1.87954
log_probs/std                         1.61623      0.03266    1.68129     1.57196
log_probs/max                         5.65254      0.30339    6.20371     5.21238
log_probs/min                         -7.08122     1.04651    -5.97079    -9.99884
mean/mean                             0.02650      0.00237    0.03024     0.02321
mean/std                              0.54405      0.00112    0.54573     0.54238
mean/max                              1.65440      0.00729    1.66520     1.64337
mean/min                              -1.59011     0.00618    -1.57722    -1.59614
------------------------------------  -----------  ---------  ----------  ---------
snapshot at 300
history save at ./log/testing_must_mtsac/mt10/18/model
sample: [2, 7, 1, 6, 9, 0, 4, 8, 5, 3]
replay_buffer._size: [45450 45450 45450 45450 45450 45450 45450 45450 45450 45450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.289801120758057 0.0019893646240234375
train_time 5.29303765296936
2023-09-06 14:22:35,910 MainThread INFO: EPOCH:301
2023-09-06 14:22:35,910 MainThread INFO: Time Consumed:5.31225848197937s
2023-09-06 14:22:35,911 MainThread INFO: Total Frames:453000s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 302/400 [29:15<19:02, 11.65s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               735.28871
Train_Epoch_Reward                    10886.66915
Running_Training_Average_Rewards      1042.19553
Explore_Time                          0.00522
Train___Time                          5.29304
Eval____Time                          0.00838
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.59805
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.94576
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.24736
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.19866
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.86089
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.47671
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.60449
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7311.11478
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.66649
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.64352
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.77310      0.46712    5.30183    3.88757
alpha_0                               0.44650      0.00019    0.44680    0.44620
alpha_1                               0.41330      0.00036    0.41387    0.41273
alpha_2                               0.41193      0.00035    0.41248    0.41137
alpha_3                               0.40959      0.00035    0.41015    0.40904
alpha_4                               0.40962      0.00035    0.41017    0.40906
alpha_5                               0.41294      0.00037    0.41353    0.41235
alpha_6                               0.41013      0.00036    0.41069    0.40957
alpha_7                               0.41913      0.00033    0.41965    0.41861
alpha_8                               0.41310      0.00036    0.41368    0.41253
alpha_9                               0.41311      0.00036    0.41368    0.41255
Alpha_loss                            -5.15105     0.03242    -5.10250   -5.20532
Training/policy_loss                  -63.87055    0.27974    -63.59031  -64.44370
Training/qf1_loss                     529.98202    133.63375  913.49530  431.23306
Training/qf2_loss                     524.50011    133.93877  909.11639  427.73853
Training/pf_norm                      0.21678      0.03623    0.27346    0.14595
Training/qf1_norm                     221.69238    111.07544  357.89978  49.24218
Training/qf2_norm                     226.45945    117.46291  365.46832  42.62814
log_std/mean                          -0.26258     0.00061    -0.26184   -0.26372
log_std/std                           0.13136      0.00035    0.13205    0.13095
log_std/max                           -0.11939     0.00076    -0.11829   -0.12067
log_std/min                           -0.66615     0.01185    -0.65409   -0.68722
log_probs/mean                        -1.83900     0.03535    -1.78519   -1.89947
log_probs/std                         1.58769      0.03156    1.64728    1.54169
log_probs/max                         5.37651      0.25334    5.78603    5.00367
log_probs/min                         -7.43400     0.84793    -6.22919   -9.19038
mean/mean                             0.01746      0.00246    0.02177    0.01405
mean/std                              0.54094      0.00151    0.54392    0.53931
mean/max                              1.66792      0.00248    1.67279    1.66484
mean/min                              -1.55955     0.00734    -1.55266   -1.57393
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 1, 0, 8, 7, 4, 9, 5, 2, 6]
replay_buffer._size: [45600 45600 45600 45600 45600 45600 45600 45600 45600 45600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.006715536117554 0.0020563602447509766
train_time 10.010136604309082
2023-09-06 14:22:46,057 MainThread INFO: EPOCH:302
2023-09-06 14:22:46,058 MainThread INFO: Time Consumed:10.022313356399536s
2023-09-06 14:22:46,058 MainThread INFO: Total Frames:454500s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 303/400 [29:25<18:06, 11.20s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               686.48333
Train_Epoch_Reward                    5438.89513
Running_Training_Average_Rewards      883.55323
Explore_Time                          0.00328
Train___Time                          10.01014
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.08552
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.57050
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.72626
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.95760
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.83869
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.37265
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -50.39654
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6951.29464
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.52474
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.03551
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.34791     0.56436    5.16256    3.14743
alpha_0                               0.44583     0.00020    0.44614    0.44552
alpha_1                               0.41204     0.00036    0.41261    0.41148
alpha_2                               0.41070     0.00035    0.41125    0.41014
alpha_3                               0.40836     0.00035    0.40892    0.40781
alpha_4                               0.40838     0.00035    0.40894    0.40783
alpha_5                               0.41163     0.00037    0.41222    0.41105
alpha_6                               0.40888     0.00036    0.40944    0.40831
alpha_7                               0.41798     0.00033    0.41850    0.41747
alpha_8                               0.41184     0.00036    0.41241    0.41127
alpha_9                               0.41186     0.00036    0.41242    0.41130
Alpha_loss                            -5.16846    0.02401    -5.13693   -5.21695
Training/policy_loss                  -64.02686   0.25737    -63.44752  -64.53752
Training/qf1_loss                     482.04613   170.95901  720.15735  234.06168
Training/qf2_loss                     476.25915   170.28539  711.21399  227.85197
Training/pf_norm                      0.23078     0.04982    0.33575    0.16343
Training/qf1_norm                     157.42687   95.76551   338.73569  25.19124
Training/qf2_norm                     159.66140   92.81394   321.02625  34.87654
log_std/mean                          -0.26318    0.00064    -0.26228   -0.26433
log_std/std                           0.13179     0.00053    0.13254    0.13079
log_std/max                           -0.12095    0.00149    -0.11837   -0.12336
log_std/min                           -0.67101    0.01243    -0.65519   -0.68642
log_probs/mean                        -1.83901    0.03061    -1.80343   -1.89739
log_probs/std                         1.58196     0.03967    1.63112    1.49653
log_probs/max                         5.22647     0.27519    5.58164    4.77966
log_probs/min                         -7.02018    0.86916    -5.93776   -8.94417
mean/mean                             0.01291     0.00048    0.01369    0.01227
mean/std                              0.54057     0.00165    0.54366    0.53788
mean/max                              1.68510     0.00875    1.69805    1.67294
mean/min                              -1.57039    0.01254    -1.55607   -1.59404
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 2, 4, 7, 5, 9, 8, 0, 1, 6]
replay_buffer._size: [45750 45750 45750 45750 45750 45750 45750 45750 45750 45750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.350680589675903 0.001983642578125
train_time 10.353885173797607
2023-09-06 14:22:56,532 MainThread INFO: EPOCH:303
2023-09-06 14:22:56,533 MainThread INFO: Time Consumed:10.365071535110474s
2023-09-06 14:22:56,533 MainThread INFO: Total Frames:456000s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 304/400 [29:36<17:34, 10.98s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               654.96977
Train_Epoch_Reward                    5900.19697
Running_Training_Average_Rewards      740.85871
Explore_Time                          0.00287
Train___Time                          10.35389
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.79276
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.84904
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.54148
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.43377
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.53582
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.10126
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.10007
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6924.41296
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.32098
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.30424
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.93520     0.37475    5.43556    4.20118
alpha_0                               0.44516     0.00019    0.44545    0.44486
alpha_1                               0.41079     0.00036    0.41135    0.41022
alpha_2                               0.40947     0.00035    0.41002    0.40892
alpha_3                               0.40713     0.00035    0.40769    0.40658
alpha_4                               0.40715     0.00035    0.40770    0.40659
alpha_5                               0.41033     0.00037    0.41092    0.40975
alpha_6                               0.40763     0.00036    0.40819    0.40707
alpha_7                               0.41683     0.00033    0.41735    0.41632
alpha_8                               0.41058     0.00036    0.41114    0.41001
alpha_9                               0.41061     0.00036    0.41117    0.41005
Alpha_loss                            -5.18793    0.02432    -5.14702   -5.22387
Training/policy_loss                  -64.20600   0.30125    -63.71694  -64.62602
Training/qf1_loss                     573.55554   161.15573  789.81689  336.92514
Training/qf2_loss                     568.34959   161.09708  785.94012  332.61734
Training/pf_norm                      0.21357     0.03004    0.24651    0.14399
Training/qf1_norm                     250.87984   111.69913  414.38959  59.76727
Training/qf2_norm                     254.88202   114.12905  414.88190  54.91005
log_std/mean                          -0.26419    0.00025    -0.26381   -0.26462
log_std/std                           0.13177     0.00041    0.13257    0.13129
log_std/max                           -0.12673    0.00107    -0.12484   -0.12827
log_std/min                           -0.66986    0.00545    -0.66322   -0.68239
log_probs/mean                        -1.84066    0.02418    -1.79858   -1.87193
log_probs/std                         1.60452     0.04367    1.67261    1.49656
log_probs/max                         5.39378     0.34037    6.10610    4.84459
log_probs/min                         -6.63695    0.95841    -5.42769   -8.75038
mean/mean                             0.01663     0.00171    0.01947    0.01410
mean/std                              0.54357     0.00078    0.54490    0.54208
mean/max                              1.70629     0.00235    1.71140    1.70297
mean/min                              -1.61869    0.01032    -1.60163   -1.63518
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 1, 3, 0, 7, 9, 4, 2, 5, 8]
replay_buffer._size: [45900 45900 45900 45900 45900 45900 45900 45900 45900 45900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.249398946762085 0.0021479129791259766
train_time 10.252910375595093
2023-09-06 14:23:06,923 MainThread INFO: EPOCH:304
2023-09-06 14:23:06,923 MainThread INFO: Time Consumed:10.26949405670166s
2023-09-06 14:23:06,924 MainThread INFO: Total Frames:457500s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 305/400 [29:46<17:06, 10.81s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               646.50806
Train_Epoch_Reward                    4065.38497
Running_Training_Average_Rewards      513.48257
Explore_Time                          0.00346
Train___Time                          10.25291
Eval____Time                          0.00845
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.55141
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.11282
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.36643
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.29285
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.09725
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.80904
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.82974
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7068.71371
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.45032
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.18220
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.43527     0.23443    4.82004    3.91652
alpha_0                               0.44450     0.00019    0.44480    0.44420
alpha_1                               0.40954     0.00036    0.41010    0.40898
alpha_2                               0.40824     0.00035    0.40880    0.40769
alpha_3                               0.40591     0.00035    0.40646    0.40536
alpha_4                               0.40592     0.00035    0.40647    0.40536
alpha_5                               0.40903     0.00037    0.40962    0.40845
alpha_6                               0.40638     0.00036    0.40694    0.40582
alpha_7                               0.41568     0.00033    0.41620    0.41516
alpha_8                               0.40932     0.00036    0.40989    0.40876
alpha_9                               0.40937     0.00036    0.40993    0.40881
Alpha_loss                            -5.22037    0.01886    -5.19525   -5.25914
Training/policy_loss                  -64.50230   0.21063    -64.03436  -64.75880
Training/qf1_loss                     470.47378   139.12397  674.85284  317.74869
Training/qf2_loss                     464.77582   138.86539  669.75061  313.45737
Training/pf_norm                      0.19652     0.02140    0.22332    0.14963
Training/qf1_norm                     94.17031    42.86526   176.92053  37.07672
Training/qf2_norm                     101.28092   43.08191   182.40863  46.40399
log_std/mean                          -0.26567    0.00066    -0.26477   -0.26663
log_std/std                           0.13104     0.00033    0.13148    0.13053
log_std/max                           -0.12866    0.00093    -0.12645   -0.13008
log_std/min                           -0.67070    0.01072    -0.65420   -0.68479
log_probs/mean                        -1.85798    0.01898    -1.82675   -1.89474
log_probs/std                         1.59392     0.03296    1.62910    1.52680
log_probs/max                         5.48549     0.27955    5.98080    5.08535
log_probs/min                         -6.88394    0.80035    -5.58722   -8.10672
mean/mean                             0.02286     0.00150    0.02515    0.02052
mean/std                              0.54503     0.00088    0.54624    0.54367
mean/max                              1.72035     0.00523    1.72884    1.71259
mean/min                              -1.64626    0.00406    -1.63832   -1.65057
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 7, 8, 2, 9, 5, 4, 1, 0, 6]
replay_buffer._size: [46050 46050 46050 46050 46050 46050 46050 46050 46050 46050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 15.476130962371826 0.0020112991333007812
train_time 15.47938060760498
2023-09-06 14:23:22,534 MainThread INFO: EPOCH:305
2023-09-06 14:23:22,535 MainThread INFO: Time Consumed:15.494146347045898s
2023-09-06 14:23:22,535 MainThread INFO: Total Frames:459000s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 306/400 [30:02<19:11, 12.25s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               658.17222
Train_Epoch_Reward                    7735.70325
Running_Training_Average_Rewards      590.04284
Explore_Time                          0.00307
Train___Time                          15.47938
Eval____Time                          0.00751
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.86880
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.70268
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.70278
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.36788
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.24092
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.00135
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -50.75477
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7293.95833
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.20383
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.40393
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.58137     0.46440    5.27717    4.03012
alpha_0                               0.44385     0.00018    0.44414    0.44357
alpha_1                               0.40829     0.00036    0.40885    0.40773
alpha_2                               0.40702     0.00035    0.40757    0.40647
alpha_3                               0.40469     0.00035    0.40524    0.40414
alpha_4                               0.40469     0.00035    0.40524    0.40414
alpha_5                               0.40774     0.00037    0.40832    0.40716
alpha_6                               0.40514     0.00036    0.40570    0.40458
alpha_7                               0.41452     0.00033    0.41504    0.41400
alpha_8                               0.40807     0.00036    0.40863    0.40750
alpha_9                               0.40813     0.00036    0.40869    0.40757
Alpha_loss                            -5.21750    0.03490    -5.14937   -5.25847
Training/policy_loss                  -64.64315   0.23060    -64.25969  -64.90865
Training/qf1_loss                     502.44015   124.37011  664.83667  286.48566
Training/qf2_loss                     496.51760   124.61194  659.44226  280.88434
Training/pf_norm                      0.21741     0.03373    0.30174    0.16431
Training/qf1_norm                     159.82609   107.71142  345.12601  36.21463
Training/qf2_norm                     162.11841   109.90569  347.49350  37.70704
log_std/mean                          -0.26598    0.00085    -0.26459   -0.26706
log_std/std                           0.13187     0.00019    0.13212    0.13145
log_std/max                           -0.12428    0.00211    -0.12104   -0.12688
log_std/min                           -0.68000    0.00848    -0.66580   -0.69239
log_probs/mean                        -1.83350    0.03882    -1.75690   -1.87287
log_probs/std                         1.64241     0.03798    1.68652    1.55617
log_probs/max                         5.59949     0.21678    5.96591    5.29142
log_probs/min                         -7.02838    1.38030    -5.61564   -9.74175
mean/mean                             0.02935     0.00192    0.03217    0.02630
mean/std                              0.54443     0.00154    0.54646    0.54183
mean/max                              1.73154     0.00582    1.74119    1.71915
mean/min                              -1.63375    0.01050    -1.61565   -1.64710
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 7, 8, 0, 9, 1, 4, 2, 3, 5]
replay_buffer._size: [46200 46200 46200 46200 46200 46200 46200 46200 46200 46200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.300424098968506 0.00228118896484375
train_time 5.303972482681274
2023-09-06 14:23:32,795 MainThread INFO: EPOCH:306
2023-09-06 14:23:32,796 MainThread INFO: Time Consumed:5.316553354263306s
2023-09-06 14:23:32,796 MainThread INFO: Total Frames:460500s
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 307/400 [30:12<18:03, 11.65s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               676.52860
Train_Epoch_Reward                    10368.44212
Running_Training_Average_Rewards      738.98434
Explore_Time                          0.00356
Train___Time                          5.30397
Eval____Time                          0.00486
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.01722
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.99925
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.88966
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.07236
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.93804
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.85534
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.98488
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7456.87375
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.28416
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.70782
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.62278      0.60421    5.36248    3.26902
alpha_0                               0.44322      0.00018    0.44350    0.44293
alpha_1                               0.40705      0.00036    0.40761    0.40649
alpha_2                               0.40581      0.00035    0.40635    0.40526
alpha_3                               0.40346      0.00035    0.40401    0.40291
alpha_4                               0.40348      0.00035    0.40402    0.40293
alpha_5                               0.40645      0.00037    0.40703    0.40587
alpha_6                               0.40390      0.00036    0.40446    0.40334
alpha_7                               0.41336      0.00033    0.41388    0.41285
alpha_8                               0.40682      0.00036    0.40738    0.40625
alpha_9                               0.40689      0.00036    0.40744    0.40633
Alpha_loss                            -5.24300     0.03383    -5.19329   -5.29068
Training/policy_loss                  -64.90949    0.29794    -64.55942  -65.47197
Training/qf1_loss                     564.74083    201.18249  866.65692  269.73444
Training/qf2_loss                     559.26831    200.88538  859.45734  265.08203
Training/pf_norm                      0.19970      0.03796    0.28204    0.14393
Training/qf1_norm                     211.18018    87.44470   365.43039  70.11549
Training/qf2_norm                     216.20853    87.34963   373.12506  74.07986
log_std/mean                          -0.26381     0.00053    -0.26287   -0.26444
log_std/std                           0.13219      0.00024    0.13255    0.13182
log_std/max                           -0.11923     0.00150    -0.11747   -0.12201
log_std/min                           -0.67742     0.00879    -0.66378   -0.69453
log_probs/mean                        -1.84394     0.03928    -1.78915   -1.90121
log_probs/std                         1.60353      0.03655    1.68868    1.53694
log_probs/max                         5.38564      0.39958    5.96394    4.66686
log_probs/min                         -6.41671     0.97616    -5.45364   -8.62954
mean/mean                             0.03667      0.00271    0.04115    0.03282
mean/std                              0.54018      0.00093    0.54163    0.53833
mean/max                              1.71506      0.00432    1.72146    1.70988
mean/min                              -1.60173     0.00636    -1.59426   -1.61314
------------------------------------  -----------  ---------  ---------  ---------
sample: [8, 1, 3, 9, 5, 7, 0, 6, 2, 4]
replay_buffer._size: [46350 46350 46350 46350 46350 46350 46350 46350 46350 46350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.159011125564575 0.0020024776458740234
train_time 10.162256717681885
2023-09-06 14:23:43,086 MainThread INFO: EPOCH:307
2023-09-06 14:23:43,087 MainThread INFO: Time Consumed:10.177666664123535s
2023-09-06 14:23:43,087 MainThread INFO: Total Frames:462000s
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 308/400 [30:22<17:14, 11.24s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               691.97657
Train_Epoch_Reward                    6383.69218
Running_Training_Average_Rewards      816.26125
Explore_Time                          0.00270
Train___Time                          10.16226
Eval____Time                          0.00856
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.48883
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.95751
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.61879
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.84236
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.17197
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.70879
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.28990
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7516.30009
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.82908
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.93216
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.89563     0.69484    6.66218     4.16914
alpha_0                               0.44257     0.00019    0.44286     0.44228
alpha_1                               0.40581     0.00036    0.40636     0.40525
alpha_2                               0.40460     0.00035    0.40514     0.40405
alpha_3                               0.40224     0.00035    0.40279     0.40170
alpha_4                               0.40227     0.00035    0.40281     0.40173
alpha_5                               0.40516     0.00037    0.40574     0.40458
alpha_6                               0.40266     0.00036    0.40322     0.40211
alpha_7                               0.41222     0.00033    0.41273     0.41170
alpha_8                               0.40557     0.00036    0.40613     0.40500
alpha_9                               0.40564     0.00036    0.40620     0.40508
Alpha_loss                            -5.27166    0.02190    -5.24582    -5.31464
Training/policy_loss                  -65.19312   0.34385    -64.64285   -65.70366
Training/qf1_loss                     629.69108   261.18729  1362.97388  395.40234
Training/qf2_loss                     623.42189   260.88268  1355.73889  386.65018
Training/pf_norm                      0.21806     0.02970    0.27492     0.17260
Training/qf1_norm                     223.09390   202.58074  753.07141   30.87792
Training/qf2_norm                     229.15826   202.32136  756.39868   35.67376
log_std/mean                          -0.26217    0.00062    -0.26139    -0.26336
log_std/std                           0.13233     0.00051    0.13315     0.13139
log_std/max                           -0.11599    0.00080    -0.11487    -0.11705
log_std/min                           -0.67916    0.01082    -0.65955    -0.69373
log_probs/mean                        -1.85630    0.02676    -1.82327    -1.90794
log_probs/std                         1.63246     0.03288    1.68559     1.58951
log_probs/max                         5.62106     0.31395    6.01820     5.17884
log_probs/min                         -7.31235    1.08687    -5.78410    -9.23488
mean/mean                             0.04550     0.00253    0.04917     0.04167
mean/std                              0.54144     0.00249    0.54545     0.53696
mean/max                              1.73232     0.00965    1.74828     1.71950
mean/min                              -1.59712    0.00636    -1.59065    -1.60920
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 4, 5, 1, 2, 0, 6, 3, 9, 8]
replay_buffer._size: [46500 46500 46500 46500 46500 46500 46500 46500 46500 46500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.875185012817383 0.0019822120666503906
train_time 9.878371238708496
2023-09-06 14:23:53,096 MainThread INFO: EPOCH:308
2023-09-06 14:23:53,097 MainThread INFO: Time Consumed:9.887566089630127s
2023-09-06 14:23:53,097 MainThread INFO: Total Frames:463500s
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 309/400 [30:32<16:29, 10.87s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               701.63541
Train_Epoch_Reward                    7412.64517
Running_Training_Average_Rewards      805.49265
Explore_Time                          0.00290
Train___Time                          9.87837
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.09720
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.89943
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.69193
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.46968
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.26082
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.66249
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.96459
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7586.78327
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.57415
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.68650
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.53661     0.46092    5.13041    3.75317
alpha_0                               0.44194     0.00017    0.44222    0.44167
alpha_1                               0.40457     0.00035    0.40513    0.40402
alpha_2                               0.40339     0.00034    0.40393    0.40286
alpha_3                               0.40103     0.00035    0.40157    0.40048
alpha_4                               0.40106     0.00035    0.40160    0.40052
alpha_5                               0.40388     0.00037    0.40445    0.40330
alpha_6                               0.40143     0.00035    0.40198    0.40087
alpha_7                               0.41106     0.00033    0.41158    0.41054
alpha_8                               0.40432     0.00036    0.40488    0.40376
alpha_9                               0.40440     0.00036    0.40496    0.40384
Alpha_loss                            -5.25418    0.03443    -5.18604   -5.32253
Training/policy_loss                  -65.62725   0.31944    -65.19830  -66.24068
Training/qf1_loss                     478.67807   176.68115  901.99768  278.48758
Training/qf2_loss                     472.79413   176.27074  895.01172  272.45541
Training/pf_norm                      0.26521     0.03528    0.34029    0.20330
Training/qf1_norm                     147.49815   77.74443   253.96042  33.34719
Training/qf2_norm                     149.59983   75.04198   241.74309  37.47937
log_std/mean                          -0.26484    0.00072    -0.26368   -0.26571
log_std/std                           0.13379     0.00048    0.13460    0.13303
log_std/max                           -0.11628    0.00157    -0.11400   -0.11988
log_std/min                           -0.67594    0.00940    -0.66263   -0.69146
log_probs/mean                        -1.81422    0.04373    -1.72621   -1.90012
log_probs/std                         1.69792     0.05110    1.78259    1.65330
log_probs/max                         5.95523     0.22068    6.37780    5.69977
log_probs/min                         -6.17907    1.03358    -5.20063   -8.64478
mean/mean                             0.05347     0.00239    0.05745    0.05017
mean/std                              0.55025     0.00326    0.55537    0.54550
mean/max                              1.76451     0.00760    1.77452    1.75064
mean/min                              -1.63998    0.01849    -1.61308   -1.66846
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 0, 2, 1, 8, 9, 5, 3, 6, 7]
replay_buffer._size: [46650 46650 46650 46650 46650 46650 46650 46650 46650 46650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 9.98111605644226 0.0019383430480957031
train_time 9.984253406524658
2023-09-06 14:24:03,201 MainThread INFO: EPOCH:309
2023-09-06 14:24:03,201 MainThread INFO: Time Consumed:9.99620509147644s
2023-09-06 14:24:03,201 MainThread INFO: Total Frames:465000s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 310/400 [30:42<15:57, 10.64s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               701.55366
Train_Epoch_Reward                    5446.62409
Running_Training_Average_Rewards      641.43205
Explore_Time                          0.00328
Train___Time                          9.98425
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.50662
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.28521
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.35457
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.98440
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.17654
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.65249
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -54.43216
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7446.67640
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.07359
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.53811
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.36925     0.51714    5.21737    3.58819
alpha_0                               0.44137     0.00016    0.44161    0.44113
alpha_1                               0.40334     0.00035    0.40389    0.40279
alpha_2                               0.40220     0.00034    0.40274    0.40167
alpha_3                               0.39981     0.00035    0.40036    0.39926
alpha_4                               0.39986     0.00034    0.40040    0.39932
alpha_5                               0.40261     0.00036    0.40318    0.40204
alpha_6                               0.40020     0.00035    0.40075    0.39964
alpha_7                               0.40990     0.00033    0.41042    0.40938
alpha_8                               0.40308     0.00036    0.40363    0.40252
alpha_9                               0.40315     0.00036    0.40371    0.40259
Alpha_loss                            -5.26064    0.01903    -5.22881   -5.29896
Training/policy_loss                  -65.75746   0.31465    -65.26618  -66.17610
Training/qf1_loss                     458.10473   208.58604  856.30353  224.95938
Training/qf2_loss                     452.65576   208.92065  851.02423  219.73862
Training/pf_norm                      0.21140     0.02285    0.25824    0.17921
Training/qf1_norm                     166.09085   86.28236   294.09225  61.12624
Training/qf2_norm                     162.47177   83.62671   291.05682  59.00520
log_std/mean                          -0.26492    0.00026    -0.26452   -0.26545
log_std/std                           0.13418     0.00032    0.13461    0.13356
log_std/max                           -0.11389    0.00198    -0.10944   -0.11641
log_std/min                           -0.67327    0.01061    -0.65955   -0.68958
log_probs/mean                        -1.80141    0.02234    -1.76298   -1.84172
log_probs/std                         1.72861     0.03424    1.79961    1.67102
log_probs/max                         6.27346     0.20953    6.51159    5.94791
log_probs/min                         -6.42273    0.94136    -4.96561   -8.05787
mean/mean                             0.05882     0.00076    0.05970    0.05729
mean/std                              0.55679     0.00137    0.55887    0.55480
mean/max                              1.76635     0.00407    1.77338    1.75979
mean/min                              -1.68027    0.00408    -1.67200   -1.68434
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 4, 8, 3, 9, 2, 0, 1, 5, 6]
replay_buffer._size: [46800 46800 46800 46800 46800 46800 46800 46800 46800 46800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.96153712272644 0.001971721649169922
train_time 10.964790105819702
2023-09-06 14:24:14,290 MainThread INFO: EPOCH:310
2023-09-06 14:24:14,291 MainThread INFO: Time Consumed:10.975232124328613s
2023-09-06 14:24:14,291 MainThread INFO: Total Frames:466500s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 311/400 [30:53<15:59, 10.78s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               689.03635
Train_Epoch_Reward                    7650.85628
Running_Training_Average_Rewards      683.67085
Explore_Time                          0.00308
Train___Time                          10.96479
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.73243
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.10282
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.53439
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.90844
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.92623
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.73643
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.85941
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7146.53377
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.23912
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.55321
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.54647     0.41360    5.40151    3.78501
alpha_0                               0.44084     0.00015    0.44107    0.44060
alpha_1                               0.40212     0.00035    0.40267    0.40157
alpha_2                               0.40102     0.00034    0.40155    0.40049
alpha_3                               0.39860     0.00035    0.39914    0.39805
alpha_4                               0.39866     0.00034    0.39920    0.39812
alpha_5                               0.40134     0.00036    0.40191    0.40078
alpha_6                               0.39897     0.00035    0.39952    0.39842
alpha_7                               0.40875     0.00033    0.40927    0.40822
alpha_8                               0.40183     0.00036    0.40239    0.40128
alpha_9                               0.40191     0.00036    0.40247    0.40135
Alpha_loss                            -5.28153    0.03225    -5.21526   -5.33418
Training/policy_loss                  -65.67049   0.27552    -65.08037  -66.13201
Training/qf1_loss                     529.55922   188.26405  852.39618  255.33963
Training/qf2_loss                     523.62279   188.21634  847.43750  249.43973
Training/pf_norm                      0.22805     0.03152    0.29857    0.19471
Training/qf1_norm                     170.16002   104.79603  432.37396  55.15372
Training/qf2_norm                     175.86297   106.56657  440.88913  55.42822
log_std/mean                          -0.26430    0.00024    -0.26394   -0.26472
log_std/std                           0.13457     0.00033    0.13512    0.13384
log_std/max                           -0.10879    0.00069    -0.10780   -0.10983
log_std/min                           -0.67039    0.00823    -0.65751   -0.68430
log_probs/mean                        -1.80556    0.03331    -1.73630   -1.85670
log_probs/std                         1.73022     0.05882    1.83597    1.62366
log_probs/max                         6.19558     0.30575    6.78752    5.69211
log_probs/min                         -6.65598    0.87490    -5.54875   -9.00073
mean/mean                             0.05691     0.00162    0.05897    0.05399
mean/std                              0.55565     0.00174    0.55852    0.55338
mean/max                              1.73981     0.01013    1.75661    1.72481
mean/min                              -1.66955    0.00816    -1.65603   -1.68252
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 4, 5, 9, 3, 6, 1, 0, 7, 2]
replay_buffer._size: [46950 46950 46950 46950 46950 46950 46950 46950 46950 46950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.692494630813599 0.0021622180938720703
train_time 10.695932388305664
2023-09-06 14:24:25,131 MainThread INFO: EPOCH:311
2023-09-06 14:24:25,131 MainThread INFO: Time Consumed:10.706987857818604s
2023-09-06 14:24:25,131 MainThread INFO: Total Frames:468000s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 312/400 [31:04<15:49, 10.79s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               667.49125
Train_Epoch_Reward                    5178.96575
Running_Training_Average_Rewards      609.21487
Explore_Time                          0.00308
Train___Time                          10.69593
Eval____Time                          0.00344
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.79022
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.70589
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.84067
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.12895
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.71096
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.71503
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.30263
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6947.79445
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.79344
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.68312
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.56246     0.70572    5.50449    3.37367
alpha_0                               0.44030     0.00016    0.44055    0.44006
alpha_1                               0.40089     0.00035    0.40144    0.40035
alpha_2                               0.39985     0.00034    0.40037    0.39932
alpha_3                               0.39739     0.00035    0.39793    0.39684
alpha_4                               0.39747     0.00034    0.39800    0.39693
alpha_5                               0.40009     0.00036    0.40065    0.39952
alpha_6                               0.39775     0.00035    0.39830    0.39721
alpha_7                               0.40758     0.00034    0.40811    0.40705
alpha_8                               0.40059     0.00036    0.40115    0.40004
alpha_9                               0.40067     0.00035    0.40123    0.40012
Alpha_loss                            -5.30685    0.03125    -5.25145   -5.35709
Training/policy_loss                  -66.11215   0.20854    -65.78557  -66.48738
Training/qf1_loss                     532.30607   199.60240  917.83850  259.79840
Training/qf2_loss                     526.18179   198.85606  911.17383  254.63078
Training/pf_norm                      0.22734     0.03349    0.28411    0.18056
Training/qf1_norm                     267.34582   103.56941  456.35526  130.04779
Training/qf2_norm                     271.59596   109.14514  470.27560  138.77777
log_std/mean                          -0.26620    0.00101    -0.26465   -0.26746
log_std/std                           0.13579     0.00039    0.13630    0.13502
log_std/max                           -0.10920    0.00162    -0.10681   -0.11153
log_std/min                           -0.67837    0.00920    -0.66674   -0.69506
log_probs/mean                        -1.81586    0.03674    -1.75474   -1.87972
log_probs/std                         1.68845     0.02127    1.71882    1.63706
log_probs/max                         6.05155     0.39987    6.75414    5.42358
log_probs/min                         -6.69759    0.51727    -5.85680   -7.62203
mean/mean                             0.05126     0.00206    0.05442    0.04791
mean/std                              0.55270     0.00132    0.55409    0.55031
mean/max                              1.71525     0.00569    1.72244    1.70688
mean/min                              -1.64239    0.00768    -1.62879   -1.65308
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 6, 8, 3, 0, 4, 2, 5, 1, 7]
replay_buffer._size: [47100 47100 47100 47100 47100 47100 47100 47100 47100 47100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.69128155708313 0.0020325183868408203
train_time 10.694527864456177
2023-09-06 14:24:35,965 MainThread INFO: EPOCH:312
2023-09-06 14:24:35,965 MainThread INFO: Time Consumed:10.710732698440552s
2023-09-06 14:24:35,965 MainThread INFO: Total Frames:469500s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 313/400 [31:15<15:39, 10.80s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               644.72991
Train_Epoch_Reward                    10728.40731
Running_Training_Average_Rewards      785.27431
Explore_Time                          0.00870
Train___Time                          10.69453
Eval____Time                          0.00288
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.02306
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.66636
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.15386
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.75489
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.88117
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.04224
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.37307
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6778.59713
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.21192
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.65811
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.94511      0.76846    6.28311     3.86565
alpha_0                               0.43975      0.00016    0.44000     0.43950
alpha_1                               0.39968      0.00035    0.40022     0.39913
alpha_2                               0.39867      0.00034    0.39920     0.39814
alpha_3                               0.39618      0.00035    0.39672     0.39564
alpha_4                               0.39627      0.00034    0.39681     0.39574
alpha_5                               0.39883      0.00036    0.39940     0.39827
alpha_6                               0.39655      0.00035    0.39709     0.39601
alpha_7                               0.40642      0.00033    0.40694     0.40590
alpha_8                               0.39936      0.00036    0.39991     0.39880
alpha_9                               0.39944      0.00035    0.39999     0.39889
Alpha_loss                            -5.33515     0.02431    -5.29532    -5.36638
Training/policy_loss                  -66.30285    0.26056    -65.90993   -66.76558
Training/qf1_loss                     625.76058    258.16862  1161.35583  322.13150
Training/qf2_loss                     618.97804    257.51267  1155.57849  315.58524
Training/pf_norm                      0.21639      0.03899    0.31090     0.16812
Training/qf1_norm                     317.48378    225.93672  744.75824   65.92810
Training/qf2_norm                     321.83743    226.07498  743.05420   63.46933
log_std/mean                          -0.26787     0.00015    -0.26761    -0.26819
log_std/std                           0.13580      0.00017    0.13601     0.13537
log_std/max                           -0.11175     0.00093    -0.11034    -0.11339
log_std/min                           -0.67792     0.01077    -0.66672    -0.69715
log_probs/mean                        -1.82886     0.02451    -1.78721    -1.85786
log_probs/std                         1.67766      0.04148    1.72940     1.59320
log_probs/max                         5.85328      0.25528    6.46661     5.58736
log_probs/min                         -6.69197     0.65648    -5.73204    -7.67572
mean/mean                             0.04420      0.00181    0.04717     0.04204
mean/std                              0.54876      0.00086    0.55015     0.54699
mean/max                              1.70517      0.00117    1.70750     1.70379
mean/min                              -1.60758     0.01089    -1.59317    -1.62507
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 8, 2, 6, 3, 4, 7, 1, 0, 9]
replay_buffer._size: [47250 47250 47250 47250 47250 47250 47250 47250 47250 47250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.562165975570679 0.0020258426666259766
train_time 10.565388917922974
2023-09-06 14:24:46,668 MainThread INFO: EPOCH:313
2023-09-06 14:24:46,670 MainThread INFO: Time Consumed:10.601198196411133s
2023-09-06 14:24:46,671 MainThread INFO: Total Frames:471000s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 314/400 [31:26<15:27, 10.78s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               626.50086
Train_Epoch_Reward                    7240.09952
Running_Training_Average_Rewards      771.58242
Explore_Time                          0.00305
Train___Time                          10.56539
Eval____Time                          0.02699
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.89743
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.70256
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.33037
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.92054
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.59436
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.66720
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.60826
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6605.09342
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.85657
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.44622
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.45570     0.44978    5.22294    3.92155
alpha_0                               0.43918     0.00017    0.43944    0.43891
alpha_1                               0.39846     0.00035    0.39901    0.39791
alpha_2                               0.39750     0.00034    0.39803    0.39697
alpha_3                               0.39498     0.00034    0.39552    0.39444
alpha_4                               0.39509     0.00034    0.39562    0.39455
alpha_5                               0.39758     0.00036    0.39815    0.39702
alpha_6                               0.39535     0.00034    0.39589    0.39481
alpha_7                               0.40527     0.00033    0.40578    0.40476
alpha_8                               0.39812     0.00035    0.39868    0.39756
alpha_9                               0.39822     0.00035    0.39877    0.39768
Alpha_loss                            -5.33903    0.03317    -5.26335   -5.37879
Training/policy_loss                  -66.70176   0.18359    -66.42062  -67.04316
Training/qf1_loss                     525.53915   216.49696  931.77509  280.08063
Training/qf2_loss                     520.28436   216.04418  923.04755  275.41187
Training/pf_norm                      0.20918     0.02474    0.23745    0.15887
Training/qf1_norm                     154.46480   102.90146  351.05237  48.86632
Training/qf2_norm                     154.44785   104.82210  351.75058  41.09584
log_std/mean                          -0.26851    0.00032    -0.26813   -0.26915
log_std/std                           0.13503     0.00041    0.13582    0.13445
log_std/max                           -0.10803    0.00149    -0.10521   -0.11062
log_std/min                           -0.67856    0.00786    -0.66937   -0.69393
log_probs/mean                        -1.81458    0.03286    -1.73767   -1.85188
log_probs/std                         1.65472     0.02897    1.69667    1.61724
log_probs/max                         5.60241     0.32700    6.46055    5.30407
log_probs/min                         -6.62347    0.81463    -5.76131   -8.47321
mean/mean                             0.04162     0.00051    0.04239    0.04060
mean/std                              0.54755     0.00078    0.54892    0.54649
mean/max                              1.71491     0.00446    1.72182    1.70816
mean/min                              -1.58569    0.00387    -1.58151   -1.59206
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 5, 7, 0, 1, 8, 6, 2, 9, 4]
replay_buffer._size: [47400 47400 47400 47400 47400 47400 47400 47400 47400 47400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.665900707244873 0.0019638538360595703
train_time 10.669078588485718
2023-09-06 14:24:57,481 MainThread INFO: EPOCH:314
2023-09-06 14:24:57,481 MainThread INFO: Time Consumed:10.68425178527832s
2023-09-06 14:24:57,481 MainThread INFO: Total Frames:472500s
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 315/400 [31:37<15:17, 10.79s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               611.87495
Train_Epoch_Reward                    4926.32083
Running_Training_Average_Rewards      763.16092
Explore_Time                          0.00260
Train___Time                          10.66908
Eval____Time                          0.00797
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.53350
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.36223
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.49210
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.84517
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.45386
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.67212
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.50181
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6510.57655
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.59269
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.77693
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.64915     0.46092    5.41739    3.49017
alpha_0                               0.43857     0.00018    0.43885    0.43830
alpha_1                               0.39724     0.00035    0.39779    0.39669
alpha_2                               0.39632     0.00034    0.39685    0.39579
alpha_3                               0.39378     0.00034    0.39432    0.39324
alpha_4                               0.39390     0.00034    0.39443    0.39336
alpha_5                               0.39634     0.00036    0.39690    0.39578
alpha_6                               0.39416     0.00034    0.39469    0.39362
alpha_7                               0.40413     0.00033    0.40464    0.40362
alpha_8                               0.39689     0.00035    0.39744    0.39633
alpha_9                               0.39701     0.00035    0.39756    0.39647
Alpha_loss                            -5.37233    0.01870    -5.33795   -5.40672
Training/policy_loss                  -66.82162   0.19746    -66.54490  -67.26767
Training/qf1_loss                     534.60811   182.70576  962.82556  297.36832
Training/qf2_loss                     529.53837   182.17378  956.37714  292.81699
Training/pf_norm                      0.20984     0.02601    0.24366    0.16731
Training/qf1_norm                     210.96649   76.59028   394.97916  123.67285
Training/qf2_norm                     210.62943   73.55566   388.24719  126.52555
log_std/mean                          -0.26931    0.00020    -0.26911   -0.26980
log_std/std                           0.13501     0.00021    0.13553    0.13477
log_std/max                           -0.10589    0.00116    -0.10403   -0.10727
log_std/min                           -0.67232    0.00917    -0.65443   -0.69017
log_probs/mean                        -1.83230    0.02053    -1.79791   -1.86875
log_probs/std                         1.66550     0.02404    1.70486    1.63757
log_probs/max                         5.60754     0.32563    6.20746    5.07572
log_probs/min                         -6.89034    0.71624    -5.90586   -8.08856
mean/mean                             0.04138     0.00141    0.04302    0.03862
mean/std                              0.54783     0.00098    0.54994    0.54617
mean/max                              1.71313     0.00846    1.72292    1.69700
mean/min                              -1.58234    0.00069    -1.58172   -1.58373
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 1, 3, 4, 7, 5, 0, 8, 2, 9]
replay_buffer._size: [47550 47550 47550 47550 47550 47550 47550 47550 47550 47550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.459148406982422 0.0019614696502685547
train_time 10.462330102920532
2023-09-06 14:25:08,088 MainThread INFO: EPOCH:315
2023-09-06 14:25:08,088 MainThread INFO: Time Consumed:10.472694396972656s
2023-09-06 14:25:08,088 MainThread INFO: Total Frames:474000s
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 316/400 [31:47<15:01, 10.73s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               603.13660
Train_Epoch_Reward                    4949.67279
Running_Training_Average_Rewards      570.53644
Explore_Time                          0.00458
Train___Time                          10.46233
Eval____Time                          0.00205
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.94336
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.36154
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.07780
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.80861
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.79173
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.03907
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.25907
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6521.66245
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.65401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.04518
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.35850     0.42913    5.24951    3.64919
alpha_0                               0.43796     0.00018    0.43824    0.43767
alpha_1                               0.39602     0.00035    0.39657    0.39548
alpha_2                               0.39515     0.00034    0.39568    0.39462
alpha_3                               0.39259     0.00034    0.39312    0.39205
alpha_4                               0.39271     0.00034    0.39325    0.39219
alpha_5                               0.39509     0.00036    0.39565    0.39453
alpha_6                               0.39297     0.00034    0.39350    0.39244
alpha_7                               0.40301     0.00032    0.40351    0.40250
alpha_8                               0.39566     0.00035    0.39621    0.39510
alpha_9                               0.39580     0.00035    0.39635    0.39526
Alpha_loss                            -5.37873    0.02074    -5.34989   -5.41298
Training/policy_loss                  -67.21687   0.35220    -66.45494  -67.74414
Training/qf1_loss                     492.07311   113.76161  720.02747  342.00131
Training/qf2_loss                     485.72915   112.49045  710.32129  336.38818
Training/pf_norm                      0.22094     0.04164    0.27252    0.12812
Training/qf1_norm                     134.38508   99.71894   385.05215  57.22006
Training/qf2_norm                     135.14641   100.74745  388.85803  55.39314
log_std/mean                          -0.26994    0.00044    -0.26908   -0.27074
log_std/std                           0.13552     0.00032    0.13606    0.13499
log_std/max                           -0.10787    0.00138    -0.10478   -0.10933
log_std/min                           -0.67425    0.01134    -0.65180   -0.69137
log_probs/mean                        -1.82115    0.02565    -1.78246   -1.86407
log_probs/std                         1.64415     0.04575    1.73943    1.55936
log_probs/max                         5.52132     0.40285    6.17678    4.82716
log_probs/min                         -6.44356    0.66227    -5.66760   -7.86440
mean/mean                             0.03207     0.00349    0.03798    0.02670
mean/std                              0.54547     0.00157    0.54892    0.54362
mean/max                              1.67669     0.01061    1.69303    1.66155
mean/min                              -1.58615    0.00120    -1.58429   -1.58805
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 2, 3, 4, 1, 5, 9, 0, 7, 6]
replay_buffer._size: [47700 47700 47700 47700 47700 47700 47700 47700 47700 47700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 10.722805500030518 0.0019845962524414062
train_time 10.72612738609314
2023-09-06 14:25:18,927 MainThread INFO: EPOCH:316
2023-09-06 14:25:18,928 MainThread INFO: Time Consumed:10.736641645431519s
2023-09-06 14:25:18,928 MainThread INFO: Total Frames:475500s
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 317/400 [31:58<14:53, 10.77s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               599.78947
Train_Epoch_Reward                    8355.24459
Running_Training_Average_Rewards      607.70794
Explore_Time                          0.00395
Train___Time                          10.72613
Eval____Time                          0.00266
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.44603
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.27348
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.72874
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.71953
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.89323
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.76048
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.30409
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6511.10672
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.17231
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.15288
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.48653     0.53117    5.54104    3.76487
alpha_0                               0.43732     0.00019    0.43761    0.43703
alpha_1                               0.39480     0.00035    0.39535    0.39425
alpha_2                               0.39398     0.00034    0.39450    0.39345
alpha_3                               0.39140     0.00034    0.39193    0.39086
alpha_4                               0.39154     0.00034    0.39207    0.39101
alpha_5                               0.39385     0.00036    0.39441    0.39329
alpha_6                               0.39179     0.00034    0.39232    0.39126
alpha_7                               0.40190     0.00032    0.40239    0.40140
alpha_8                               0.39443     0.00035    0.39498    0.39388
alpha_9                               0.39460     0.00034    0.39514    0.39406
Alpha_loss                            -5.41286    0.02674    -5.37273   -5.47076
Training/policy_loss                  -66.95787   0.39729    -66.51676  -67.70332
Training/qf1_loss                     461.50063   166.89712  878.85901  294.63614
Training/qf2_loss                     455.77073   166.69213  873.50165  288.08978
Training/pf_norm                      0.20088     0.02636    0.26141    0.15836
Training/qf1_norm                     202.10601   129.78621  517.51813  50.44622
Training/qf2_norm                     202.86342   130.82887  516.45441  52.26717
log_std/mean                          -0.26984    0.00049    -0.26933   -0.27095
log_std/std                           0.13499     0.00043    0.13594    0.13451
log_std/max                           -0.10823    0.00085    -0.10669   -0.10980
log_std/min                           -0.67553    0.00607    -0.66127   -0.68363
log_probs/mean                        -1.84028    0.03049    -1.80255   -1.90591
log_probs/std                         1.61345     0.03470    1.64780    1.53625
log_probs/max                         5.24870     0.36998    6.12930    4.86089
log_probs/min                         -6.29328    0.64166    -5.30855   -7.57115
mean/mean                             0.02067     0.00307    0.02585    0.01617
mean/std                              0.54227     0.00124    0.54496    0.54087
mean/max                              1.65487     0.00316    1.66030    1.65162
mean/min                              -1.59495    0.00444    -1.58934   -1.60111
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 7, 5, 1, 8, 9, 2, 3, 0, 6]
replay_buffer._size: [47850 47850 47850 47850 47850 47850 47850 47850 47850 47850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.01758074760437 0.0019562244415283203
train_time 11.020720481872559
2023-09-06 14:25:30,076 MainThread INFO: EPOCH:317
2023-09-06 14:25:30,077 MainThread INFO: Time Consumed:11.033019781112671s
2023-09-06 14:25:30,077 MainThread INFO: Total Frames:477000s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 318/400 [32:09<14:52, 10.88s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               595.86087
Train_Epoch_Reward                    9956.50318
Running_Training_Average_Rewards      775.38069
Explore_Time                          0.00330
Train___Time                          11.02072
Eval____Time                          0.00321
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.04388
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.63529
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.03396
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.58038
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.05682
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.60595
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.97231
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6392.75594
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.01489
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.32434
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.75218     0.58937    5.66482    3.87990
alpha_0                               0.43666     0.00019    0.43696    0.43636
alpha_1                               0.39358     0.00035    0.39413    0.39303
alpha_2                               0.39281     0.00033    0.39333    0.39229
alpha_3                               0.39021     0.00034    0.39074    0.38968
alpha_4                               0.39037     0.00034    0.39090    0.38984
alpha_5                               0.39260     0.00036    0.39316    0.39204
alpha_6                               0.39061     0.00034    0.39114    0.39008
alpha_7                               0.40079     0.00032    0.40129    0.40029
alpha_8                               0.39321     0.00035    0.39376    0.39266
alpha_9                               0.39340     0.00034    0.39394    0.39287
Alpha_loss                            -5.43969    0.02163    -5.38953   -5.47027
Training/policy_loss                  -67.07734   0.28176    -66.57081  -67.56217
Training/qf1_loss                     540.95858   184.40625  878.20947  288.18320
Training/qf2_loss                     535.55734   184.09772  872.79083  284.13477
Training/pf_norm                      0.20314     0.01872    0.23732    0.17483
Training/qf1_norm                     275.06128   169.63963  529.59442  47.09404
Training/qf2_norm                     276.40604   171.67065  527.22644  42.01664
log_std/mean                          -0.26731    0.00087    -0.26584   -0.26871
log_std/std                           0.13380     0.00048    0.13448    0.13284
log_std/max                           -0.11158    0.00195    -0.10829   -0.11462
log_std/min                           -0.67676    0.00953    -0.65949   -0.68771
log_probs/mean                        -1.85146    0.02583    -1.78793   -1.89012
log_probs/std                         1.59475     0.04291    1.69107    1.54308
log_probs/max                         5.35082     0.21946    5.83816    5.08192
log_probs/min                         -7.12960    1.72037    -5.39665   -11.53285
mean/mean                             0.01121     0.00243    0.01471    0.00721
mean/std                              0.53977     0.00093    0.54104    0.53789
mean/max                              1.65705     0.00450    1.66525    1.65259
mean/min                              -1.59991    0.00142    -1.59761   -1.60244
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 5, 2, 9, 8, 1, 6, 3, 7, 4]
replay_buffer._size: [48000 48000 48000 48000 48000 48000 48000 48000 48000 48000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.12571907043457 0.0022957324981689453
train_time 11.129510641098022
2023-09-06 14:25:41,347 MainThread INFO: EPOCH:318
2023-09-06 14:25:41,348 MainThread INFO: Time Consumed:11.140052318572998s
2023-09-06 14:25:41,348 MainThread INFO: Total Frames:478500s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 319/400 [32:20<14:50, 11.00s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               585.91955
Train_Epoch_Reward                    6104.40993
Running_Training_Average_Rewards      813.87192
Explore_Time                          0.00329
Train___Time                          11.12951
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.69290
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.98062
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.38092
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.43155
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.08526
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.25471
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.87638
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6223.77067
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.24027
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.38556
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.49630     0.64867    6.06966     3.32528
alpha_0                               0.43598     0.00020    0.43629     0.43567
alpha_1                               0.39236     0.00035    0.39291     0.39182
alpha_2                               0.39164     0.00034    0.39217     0.39112
alpha_3                               0.38903     0.00034    0.38956     0.38850
alpha_4                               0.38920     0.00033    0.38973     0.38868
alpha_5                               0.39136     0.00036    0.39192     0.39081
alpha_6                               0.38944     0.00034    0.38997     0.38891
alpha_7                               0.39968     0.00032    0.40018     0.39918
alpha_8                               0.39199     0.00035    0.39254     0.39145
alpha_9                               0.39221     0.00034    0.39275     0.39168
Alpha_loss                            -5.46011    0.03245    -5.38952    -5.50501
Training/policy_loss                  -67.72738   0.37056    -67.37041   -68.55058
Training/qf1_loss                     589.24451   229.67399  1079.70190  332.11719
Training/qf2_loss                     583.26641   228.90539  1073.18921  326.08765
Training/pf_norm                      0.20618     0.02669    0.24066     0.15065
Training/qf1_norm                     191.98701   177.91640  693.59332   48.80005
Training/qf2_norm                     199.23740   177.03753  698.58002   42.73167
log_std/mean                          -0.26465    0.00068    -0.26386    -0.26612
log_std/std                           0.13134     0.00100    0.13330     0.12981
log_std/max                           -0.11549    0.00134    -0.11256    -0.11709
log_std/min                           -0.66641    0.01228    -0.64520    -0.68415
log_probs/mean                        -1.85523    0.03561    -1.77242    -1.89616
log_probs/std                         1.59182     0.04324    1.67307     1.51857
log_probs/max                         5.20943     0.25545    5.69646     4.87948
log_probs/min                         -6.70359    0.48292    -6.02034    -7.38726
mean/mean                             0.00412     0.00160    0.00683     0.00197
mean/std                              0.53662     0.00184    0.54062     0.53391
mean/max                              1.64776     0.00252    1.65141     1.64270
mean/min                              -1.58961    0.00181    -1.58735    -1.59366
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 7, 8, 0, 3, 9, 4, 6, 1, 2]
replay_buffer._size: [48150 48150 48150 48150 48150 48150 48150 48150 48150 48150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.12973141670227 0.0019919872283935547
train_time 11.132972002029419
2023-09-06 14:25:52,605 MainThread INFO: EPOCH:319
2023-09-06 14:25:52,605 MainThread INFO: Time Consumed:11.142827272415161s
2023-09-06 14:25:52,605 MainThread INFO: Total Frames:480000s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 320/400 [32:32<14:45, 11.07s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               575.15434
Train_Epoch_Reward                    6210.35254
Running_Training_Average_Rewards      742.37552
Explore_Time                          0.00276
Train___Time                          11.13297
Eval____Time                          0.00300
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.62046
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.12863
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.82143
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.21730
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.05318
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.91214
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.66745
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6193.48026
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.62232
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.73775
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.55496     0.46011    5.24818    3.90752
alpha_0                               0.43528     0.00021    0.43560    0.43495
alpha_1                               0.39115     0.00035    0.39170    0.39061
alpha_2                               0.39047     0.00034    0.39100    0.38995
alpha_3                               0.38785     0.00034    0.38838    0.38732
alpha_4                               0.38804     0.00033    0.38857    0.38752
alpha_5                               0.39013     0.00035    0.39068    0.38957
alpha_6                               0.38827     0.00034    0.38880    0.38774
alpha_7                               0.39857     0.00032    0.39907    0.39807
alpha_8                               0.39078     0.00035    0.39133    0.39024
alpha_9                               0.39103     0.00034    0.39156    0.39049
Alpha_loss                            -5.49606    0.01355    -5.47676   -5.51528
Training/policy_loss                  -67.76689   0.24248    -67.37876  -68.24529
Training/qf1_loss                     467.93746   140.33711  704.11304  279.20160
Training/qf2_loss                     462.39408   139.84909  696.60327  274.00629
Training/pf_norm                      0.22968     0.02322    0.26798    0.19022
Training/qf1_norm                     181.02675   105.51562  370.72934  68.39011
Training/qf2_norm                     182.54983   108.77695  375.67975  58.96660
log_std/mean                          -0.26580    0.00103    -0.26454   -0.26741
log_std/std                           0.13030     0.00036    0.13077    0.12984
log_std/max                           -0.11843    0.00116    -0.11632   -0.11984
log_std/min                           -0.66647    0.00940    -0.65101   -0.68357
log_probs/mean                        -1.87706    0.01255    -1.85640   -1.89090
log_probs/std                         1.54822     0.03354    1.58348    1.49070
log_probs/max                         5.17411     0.30774    5.52748    4.63795
log_probs/min                         -6.41254    0.41860    -5.83858   -7.17399
mean/mean                             0.00275     0.00089    0.00465    0.00167
mean/std                              0.53488     0.00106    0.53665    0.53312
mean/max                              1.65017     0.00452    1.65887    1.64368
mean/min                              -1.59237    0.00593    -1.58668   -1.60442
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 6, 2, 9, 5, 3, 0, 4, 8, 1]
replay_buffer._size: [48300 48300 48300 48300 48300 48300 48300 48300 48300 48300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.161635637283325 0.001928091049194336
train_time 11.16478967666626
2023-09-06 14:26:03,894 MainThread INFO: EPOCH:320
2023-09-06 14:26:03,895 MainThread INFO: Time Consumed:11.174620389938354s
2023-09-06 14:26:03,895 MainThread INFO: Total Frames:481500s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 321/400 [32:43<14:39, 11.14s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               571.23278
Train_Epoch_Reward                    6603.06007
Running_Training_Average_Rewards      630.59408
Explore_Time                          0.00295
Train___Time                          11.16479
Eval____Time                          0.00272
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.00756
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.78079
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.63113
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.18377
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.61209
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.87748
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.96864
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6278.48573
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.13388
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.44920
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.36967     0.53928    5.12998    3.21103
alpha_0                               0.43455     0.00021    0.43487    0.43422
alpha_1                               0.38995     0.00034    0.39049    0.38941
alpha_2                               0.38930     0.00034    0.38983    0.38878
alpha_3                               0.38668     0.00034    0.38721    0.38615
alpha_4                               0.38689     0.00033    0.38741    0.38638
alpha_5                               0.38890     0.00035    0.38945    0.38834
alpha_6                               0.38709     0.00034    0.38762    0.38656
alpha_7                               0.39746     0.00032    0.39796    0.39696
alpha_8                               0.38958     0.00034    0.39012    0.38905
alpha_9                               0.38983     0.00034    0.39037    0.38930
Alpha_loss                            -5.49976    0.03262    -5.44097   -5.54646
Training/policy_loss                  -68.06055   0.14727    -67.85513  -68.33291
Training/qf1_loss                     505.33388   173.88840  757.84674  211.90808
Training/qf2_loss                     499.19131   173.65386  750.60321  204.80774
Training/pf_norm                      0.20168     0.03305    0.25793    0.14310
Training/qf1_norm                     170.33973   110.99604  360.53305  45.19183
Training/qf2_norm                     171.56214   109.80429  341.70688  40.04362
log_std/mean                          -0.26957    0.00096    -0.26796   -0.27058
log_std/std                           0.13180     0.00063    0.13275    0.13075
log_std/max                           -0.11923    0.00099    -0.11723   -0.12101
log_std/min                           -0.67391    0.01080    -0.65872   -0.69225
log_probs/mean                        -1.85999    0.03721    -1.79729   -1.91918
log_probs/std                         1.59122     0.04007    1.64958    1.53525
log_probs/max                         5.36319     0.28522    5.79460    4.94672
log_probs/min                         -6.95775    0.87474    -6.24081   -8.70823
mean/mean                             0.00724     0.00122    0.00876    0.00532
mean/std                              0.54002     0.00210    0.54244    0.53606
mean/max                              1.68106     0.01223    1.70083    1.66216
mean/min                              -1.62242    0.00838    -1.60802   -1.63315
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 0, 9, 6, 3, 4, 5, 1, 8, 2]
replay_buffer._size: [48450 48450 48450 48450 48450 48450 48450 48450 48450 48450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.592242240905762 0.0027899742126464844
train_time 11.596826553344727
2023-09-06 14:26:15,620 MainThread INFO: EPOCH:321
2023-09-06 14:26:15,621 MainThread INFO: Time Consumed:11.616928815841675s
2023-09-06 14:26:15,621 MainThread INFO: Total Frames:483000s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 322/400 [32:55<14:42, 11.32s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               582.47139
Train_Epoch_Reward                    5012.99178
Running_Training_Average_Rewards      594.21348
Explore_Time                          0.01075
Train___Time                          11.59683
Eval____Time                          0.00366
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.42820
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.71082
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.93957
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.40937
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.71450
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.83657
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.25873
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6550.67394
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.76077
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.01444
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.49033     0.38941    4.93987    3.84905
alpha_0                               0.43384     0.00020    0.43415    0.43353
alpha_1                               0.38875     0.00034    0.38929    0.38822
alpha_2                               0.38814     0.00034    0.38866    0.38761
alpha_3                               0.38551     0.00034    0.38604    0.38498
alpha_4                               0.38575     0.00033    0.38626    0.38523
alpha_5                               0.38767     0.00035    0.38822    0.38712
alpha_6                               0.38592     0.00034    0.38645    0.38539
alpha_7                               0.39636     0.00032    0.39685    0.39586
alpha_8                               0.38839     0.00034    0.38893    0.38785
alpha_9                               0.38864     0.00034    0.38918    0.38811
Alpha_loss                            -5.50820    0.02279    -5.46476   -5.55356
Training/policy_loss                  -68.19382   0.37284    -67.48748  -68.72958
Training/qf1_loss                     552.33819   160.31665  821.12714  360.74780
Training/qf2_loss                     546.20610   160.01834  814.30652  356.23746
Training/pf_norm                      0.18798     0.03624    0.25165    0.13487
Training/qf1_norm                     163.26101   85.06144   294.63007  48.92457
Training/qf2_norm                     166.54963   87.56673   300.02899  58.65224
log_std/mean                          -0.26965    0.00044    -0.26911   -0.27056
log_std/std                           0.13236     0.00030    0.13281    0.13181
log_std/max                           -0.12131    0.00131    -0.11918   -0.12299
log_std/min                           -0.67866    0.00930    -0.66546   -0.69536
log_probs/mean                        -1.85010    0.02521    -1.80420   -1.89466
log_probs/std                         1.60549     0.03280    1.66085    1.54621
log_probs/max                         5.38964     0.35270    5.93012    4.80760
log_probs/min                         -6.59329    0.56441    -5.56491   -7.43957
mean/mean                             0.00840     0.00029    0.00915    0.00795
mean/std                              0.54205     0.00120    0.54371    0.53967
mean/max                              1.69791     0.00214    1.70394    1.69644
mean/min                              -1.62618    0.00748    -1.61429   -1.63435
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 9, 6, 1, 3, 5, 7, 2, 0, 4]
replay_buffer._size: [48600 48600 48600 48600 48600 48600 48600 48600 48600 48600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.223915338516235 0.0019752979278564453
train_time 11.227081775665283
2023-09-06 14:26:26,987 MainThread INFO: EPOCH:322
2023-09-06 14:26:26,988 MainThread INFO: Time Consumed:11.245141983032227s
2023-09-06 14:26:26,988 MainThread INFO: Total Frames:484500s
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 323/400 [33:06<14:32, 11.33s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               609.90576
Train_Epoch_Reward                    7038.84249
Running_Training_Average_Rewards      621.82981
Explore_Time                          0.00301
Train___Time                          11.22708
Eval____Time                          0.01089
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.41485
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.11254
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.27681
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.17717
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.99962
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.96057
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.57728
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7002.83277
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.88073
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.70242
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.70148     1.10022    7.41173     3.41086
alpha_0                               0.43314     0.00020    0.43346     0.43282
alpha_1                               0.38756     0.00034    0.38810     0.38703
alpha_2                               0.38696     0.00034    0.38749     0.38644
alpha_3                               0.38434     0.00034    0.38487     0.38382
alpha_4                               0.38461     0.00033    0.38512     0.38410
alpha_5                               0.38645     0.00035    0.38700     0.38590
alpha_6                               0.38475     0.00034    0.38527     0.38422
alpha_7                               0.39526     0.00032    0.39575     0.39476
alpha_8                               0.38720     0.00034    0.38773     0.38666
alpha_9                               0.38745     0.00034    0.38799     0.38692
Alpha_loss                            -5.54207    0.03289    -5.50081    -5.59836
Training/policy_loss                  -68.43198   0.25236    -68.10609   -68.83818
Training/qf1_loss                     608.57467   454.34920  1778.17969  277.07401
Training/qf2_loss                     602.26575   454.00571  1771.59241  272.48605
Training/pf_norm                      0.23362     0.03823    0.31080     0.18010
Training/qf1_norm                     302.87240   299.85806  1085.35046  77.33014
Training/qf2_norm                     302.54360   301.76501  1085.17139  69.88368
log_std/mean                          -0.26882    0.00034    -0.26831    -0.26931
log_std/std                           0.13221     0.00020    0.13246     0.13182
log_std/max                           -0.12274    0.00097    -0.12131    -0.12477
log_std/min                           -0.68482    0.01225    -0.66628    -0.70137
log_probs/mean                        -1.86896    0.03610    -1.81642    -1.92843
log_probs/std                         1.57714     0.04815    1.63913     1.49339
log_probs/max                         5.12267     0.16876    5.34512     4.83900
log_probs/min                         -6.71737    0.88866    -5.50714    -8.09521
mean/mean                             0.00927     0.00117    0.01161     0.00794
mean/std                              0.53948     0.00091    0.54125     0.53833
mean/max                              1.70251     0.00631    1.71444     1.69552
mean/min                              -1.60855    0.00366    -1.60305    -1.61337
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 0, 9, 1, 2, 7, 3, 4, 8, 5]
replay_buffer._size: [48750 48750 48750 48750 48750 48750 48750 48750 48750 48750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.067901372909546 0.0018579959869384766
train_time 11.07089114189148
2023-09-06 14:26:38,175 MainThread INFO: EPOCH:323
2023-09-06 14:26:38,175 MainThread INFO: Time Consumed:11.083757400512695s
2023-09-06 14:26:38,176 MainThread INFO: Total Frames:486000s
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 324/400 [33:17<14:18, 11.30s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               644.44885
Train_Epoch_Reward                    4816.37324
Running_Training_Average_Rewards      562.27358
Explore_Time                          0.00334
Train___Time                          11.07089
Eval____Time                          0.00570
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.29603
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.48155
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.10779
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.36332
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.65459
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.98900
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.09308
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7307.04657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.47984
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.44760
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.47464     0.86447    5.87344    3.05367
alpha_0                               0.43243     0.00020    0.43275    0.43211
alpha_1                               0.38638     0.00034    0.38691    0.38585
alpha_2                               0.38580     0.00033    0.38632    0.38528
alpha_3                               0.38317     0.00034    0.38370    0.38265
alpha_4                               0.38348     0.00033    0.38399    0.38297
alpha_5                               0.38522     0.00035    0.38577    0.38467
alpha_6                               0.38358     0.00034    0.38411    0.38306
alpha_7                               0.39416     0.00032    0.39465    0.39366
alpha_8                               0.38601     0.00034    0.38655    0.38549
alpha_9                               0.38626     0.00034    0.38680    0.38573
Alpha_loss                            -5.55746    0.02048    -5.51668   -5.58433
Training/policy_loss                  -68.45688   0.22030    -67.97929  -68.71370
Training/qf1_loss                     461.08849   193.89928  929.47424  191.55618
Training/qf2_loss                     455.04185   193.96177  926.39636  187.83125
Training/pf_norm                      0.22096     0.04067    0.27770    0.15158
Training/qf1_norm                     283.55941   182.51682  637.63147  34.89494
Training/qf2_norm                     282.83719   181.48106  638.16901  33.99445
log_std/mean                          -0.26696    0.00118    -0.26454   -0.26822
log_std/std                           0.13139     0.00072    0.13235    0.12981
log_std/max                           -0.12483    0.00077    -0.12354   -0.12605
log_std/min                           -0.67614    0.00895    -0.66165   -0.69468
log_probs/mean                        -1.86539    0.02151    -1.81748   -1.89444
log_probs/std                         1.60966     0.04482    1.71494    1.54685
log_probs/max                         5.23842     0.25994    5.79721    4.96608
log_probs/min                         -6.62836    0.96801    -5.72294   -8.38064
mean/mean                             0.01624     0.00231    0.01967    0.01250
mean/std                              0.53837     0.00096    0.53980    0.53632
mean/max                              1.73004     0.00573    1.73913    1.71889
mean/min                              -1.60053    0.00443    -1.59277   -1.60619
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 1, 3, 9, 8, 0, 5, 4, 2, 7]
replay_buffer._size: [48900 48900 48900 48900 48900 48900 48900 48900 48900 48900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.669934034347534 0.003205537796020508
train_time 5.674405813217163
2023-09-06 14:26:49,404 MainThread INFO: EPOCH:324
2023-09-06 14:26:49,405 MainThread INFO: Time Consumed:5.6852428913116455s
2023-09-06 14:26:49,405 MainThread INFO: Total Frames:487500s
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 325/400 [33:29<14:06, 11.28s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               664.77050
Train_Epoch_Reward                    6497.64351
Running_Training_Average_Rewards      611.76197
Explore_Time                          0.00338
Train___Time                          5.67441
Eval____Time                          0.00272
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.08763
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.17170
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.96253
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.96125
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.39191
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.68498
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.79377
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7159.22918
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.56057
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.36438
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.56673     0.38277    5.12463     3.92655
alpha_0                               0.43173     0.00020    0.43204     0.43142
alpha_1                               0.38520     0.00034    0.38573     0.38467
alpha_2                               0.38464     0.00033    0.38516     0.38412
alpha_3                               0.38201     0.00033    0.38253     0.38148
alpha_4                               0.38234     0.00033    0.38285     0.38183
alpha_5                               0.38400     0.00035    0.38455     0.38346
alpha_6                               0.38242     0.00033    0.38294     0.38189
alpha_7                               0.39305     0.00032    0.39355     0.39255
alpha_8                               0.38484     0.00034    0.38537     0.38431
alpha_9                               0.38508     0.00034    0.38561     0.38455
Alpha_loss                            -5.56813    0.02401    -5.53523    -5.61508
Training/policy_loss                  -68.80233   0.40190    -68.24493   -69.45885
Training/qf1_loss                     529.87563   225.95412  1095.33960  256.45557
Training/qf2_loss                     523.78071   225.35739  1086.16492  250.25211
Training/pf_norm                      0.20052     0.03077    0.23726     0.12908
Training/qf1_norm                     214.16741   100.42331  377.64316   77.60122
Training/qf2_norm                     215.73367   104.35689  390.26474   68.38963
log_std/mean                          -0.26317    0.00078    -0.26188    -0.26455
log_std/std                           0.12919     0.00034    0.12967     0.12853
log_std/max                           -0.12280    0.00065    -0.12132    -0.12367
log_std/min                           -0.66673    0.01036    -0.64882    -0.68192
log_probs/mean                        -1.85776    0.02558    -1.82511    -1.91128
log_probs/std                         1.60819     0.02743    1.64990     1.56397
log_probs/max                         5.30693     0.32073    5.77884     4.70546
log_probs/min                         -6.99512    0.92216    -5.62122    -8.79359
mean/mean                             0.02120     0.00025    0.02160     0.02084
mean/std                              0.53504     0.00145    0.53761     0.53269
mean/max                              1.71803     0.00612    1.72804     1.70605
mean/min                              -1.58063    0.00630    -1.56992    -1.59113
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 8, 9, 0, 7, 1, 3, 5, 2, 4]
replay_buffer._size: [49050 49050 49050 49050 49050 49050 49050 49050 49050 49050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.787204742431641 0.002936840057373047
train_time 5.791933536529541
2023-09-06 14:27:00,683 MainThread INFO: EPOCH:325
2023-09-06 14:27:00,684 MainThread INFO: Time Consumed:5.811177968978882s
2023-09-06 14:27:00,684 MainThread INFO: Total Frames:489000s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 326/400 [33:40<13:54, 11.28s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               654.58571
Train_Epoch_Reward                    5792.49795
Running_Training_Average_Rewards      570.21716
Explore_Time                          0.00764
Train___Time                          5.79193
Eval____Time                          0.00710
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.59854
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.12667
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.98352
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.90310
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.36978
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.93260
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.62978
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6700.16135
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.32401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.10640
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.50885     0.36905    4.98892    3.74855
alpha_0                               0.43103     0.00021    0.43135    0.43071
alpha_1                               0.38403     0.00034    0.38456    0.38350
alpha_2                               0.38349     0.00033    0.38401    0.38297
alpha_3                               0.38084     0.00033    0.38137    0.38032
alpha_4                               0.38121     0.00033    0.38172    0.38069
alpha_5                               0.38279     0.00035    0.38333    0.38225
alpha_6                               0.38125     0.00033    0.38178    0.38073
alpha_7                               0.39194     0.00032    0.39244    0.39143
alpha_8                               0.38366     0.00034    0.38419    0.38313
alpha_9                               0.38390     0.00034    0.38443    0.38337
Alpha_loss                            -5.62129    0.02834    -5.56783   -5.67439
Training/policy_loss                  -68.93390   0.31434    -68.49587  -69.48940
Training/qf1_loss                     433.21441   96.36388   601.65411  256.15683
Training/qf2_loss                     427.19211   95.89512   594.67236  250.87509
Training/pf_norm                      0.19517     0.02485    0.22721    0.15170
Training/qf1_norm                     198.26311   101.38128  362.91650  38.90065
Training/qf2_norm                     203.38819   104.13151  372.68356  48.32581
log_std/mean                          -0.26225    0.00081    -0.26159   -0.26396
log_std/std                           0.12873     0.00036    0.12949    0.12813
log_std/max                           -0.12014    0.00087    -0.11890   -0.12215
log_std/min                           -0.66406    0.00783    -0.65174   -0.67643
log_probs/mean                        -1.89850    0.03196    -1.84260   -1.95677
log_probs/std                         1.55221     0.05731    1.64729    1.47838
log_probs/max                         5.06916     0.34572    5.84497    4.48018
log_probs/min                         -6.39237    0.69299    -5.42213   -7.82307
mean/mean                             0.02124     0.00087    0.02299    0.02015
mean/std                              0.52972     0.00119    0.53124    0.52759
mean/max                              1.69773     0.00615    1.70828    1.69124
mean/min                              -1.55396    0.00658    -1.54558   -1.56643
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 5, 1, 4, 2, 0, 7, 3, 9, 8]
replay_buffer._size: [49200 49200 49200 49200 49200 49200 49200 49200 49200 49200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.714308738708496 0.0020093917846679688
train_time 5.71760368347168
2023-09-06 14:27:11,580 MainThread INFO: EPOCH:326
2023-09-06 14:27:11,581 MainThread INFO: Time Consumed:5.731537342071533s
2023-09-06 14:27:11,581 MainThread INFO: Total Frames:490500s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 327/400 [33:51<13:34, 11.16s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               618.76629
Train_Epoch_Reward                    7776.89846
Running_Training_Average_Rewards      668.90133
Explore_Time                          0.00529
Train___Time                          5.71760
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.59671
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.34376
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.46526
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.73414
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.69264
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.71964
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.88397
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6237.92859
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.02539
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.91588
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.24704     0.61524    5.48844    3.56166
alpha_0                               0.43030     0.00021    0.43063    0.42996
alpha_1                               0.38286     0.00033    0.38339    0.38234
alpha_2                               0.38234     0.00033    0.38286    0.38183
alpha_3                               0.37968     0.00033    0.38020    0.37916
alpha_4                               0.38007     0.00033    0.38058    0.37956
alpha_5                               0.38158     0.00035    0.38213    0.38104
alpha_6                               0.38010     0.00033    0.38062    0.37958
alpha_7                               0.39082     0.00032    0.39132    0.39032
alpha_8                               0.38248     0.00034    0.38301    0.38195
alpha_9                               0.38273     0.00034    0.38326    0.38220
Alpha_loss                            -5.63137    0.02470    -5.57846   -5.65913
Training/policy_loss                  -69.37417   0.29903    -68.99530  -69.91026
Training/qf1_loss                     451.95849   134.01236  615.18719  241.62166
Training/qf2_loss                     446.32053   134.37916  609.99896  234.27966
Training/pf_norm                      0.19615     0.02853    0.24563    0.15728
Training/qf1_norm                     193.99495   124.78713  506.00354  30.42574
Training/qf2_norm                     192.86294   123.08675  504.38516  33.38787
log_std/mean                          -0.26655    0.00146    -0.26432   -0.26843
log_std/std                           0.13008     0.00063    0.13099    0.12931
log_std/max                           -0.12045    0.00112    -0.11804   -0.12165
log_std/min                           -0.66006    0.00565    -0.65064   -0.67000
log_probs/mean                        -1.89079    0.02671    -1.84061   -1.92237
log_probs/std                         1.53750     0.02394    1.57082    1.48834
log_probs/max                         4.89504     0.18249    5.18473    4.63925
log_probs/min                         -6.31814    0.62746    -5.52001   -7.39544
mean/mean                             0.02336     0.00034    0.02380    0.02288
mean/std                              0.52909     0.00071    0.52996    0.52771
mean/max                              1.70778     0.00616    1.71656    1.69967
mean/min                              -1.53352    0.00458    -1.52557   -1.54230
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 5, 4, 6, 0, 2, 7, 8, 9, 3]
replay_buffer._size: [49350 49350 49350 49350 49350 49350 49350 49350 49350 49350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 5.896174669265747 0.002683877944946289
train_time 5.900472164154053
2023-09-06 14:27:22,701 MainThread INFO: EPOCH:327
2023-09-06 14:27:22,702 MainThread INFO: Time Consumed:5.914024829864502s
2023-09-06 14:27:22,702 MainThread INFO: Total Frames:492000s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 328/400 [34:02<13:22, 11.14s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               580.09104
Train_Epoch_Reward                    9040.78584
Running_Training_Average_Rewards      753.67274
Explore_Time                          0.00375
Train___Time                          5.90047
Eval____Time                          0.00474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.26652
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.77978
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.02013
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.50565
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.20031
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.28668
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.90530
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6009.66609
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.29168
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.41713
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.81363     0.52533    5.74078     3.91383
alpha_0                               0.42954     0.00022    0.42988     0.42919
alpha_1                               0.38171     0.00033    0.38223     0.38119
alpha_2                               0.38120     0.00033    0.38171     0.38069
alpha_3                               0.37852     0.00033    0.37904     0.37800
alpha_4                               0.37894     0.00032    0.37945     0.37843
alpha_5                               0.38038     0.00034    0.38092     0.37985
alpha_6                               0.37894     0.00033    0.37946     0.37842
alpha_7                               0.38971     0.00032    0.39021     0.38921
alpha_8                               0.38130     0.00034    0.38183     0.38077
alpha_9                               0.38156     0.00034    0.38208     0.38103
Alpha_loss                            -5.65005    0.02239    -5.60576    -5.69115
Training/policy_loss                  -69.40446   0.35054    -68.92751   -70.14502
Training/qf1_loss                     637.52714   261.82772  1200.97485  277.71387
Training/qf2_loss                     632.18544   262.01886  1196.74072  272.37802
Training/pf_norm                      0.17543     0.02783    0.21573     0.12475
Training/qf1_norm                     278.35698   171.76829  600.13153   37.59951
Training/qf2_norm                     281.74062   172.97651  606.43854   42.21727
log_std/mean                          -0.26889    0.00028    -0.26846    -0.26930
log_std/std                           0.13201     0.00067    0.13300     0.13125
log_std/max                           -0.11781    0.00084    -0.11624    -0.11921
log_std/min                           -0.66641    0.01011    -0.64680    -0.68188
log_probs/mean                        -1.89330    0.02065    -1.85035    -1.93344
log_probs/std                         1.52795     0.03342    1.57447     1.45931
log_probs/max                         5.07048     0.24062    5.43354     4.62994
log_probs/min                         -6.77433    0.44618    -5.91271    -7.49295
mean/mean                             0.02055     0.00128    0.02238     0.01867
mean/std                              0.52815     0.00103    0.52982     0.52613
mean/max                              1.72399     0.00556    1.73791     1.71676
mean/min                              -1.51348    0.00536    -1.50788    -1.52463
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 8, 6, 2, 5, 0, 9, 1, 3, 7]
replay_buffer._size: [49500 49500 49500 49500 49500 49500 49500 49500 49500 49500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.564833164215088 0.0019609928131103516
train_time 11.568030834197998
2023-09-06 14:27:34,417 MainThread INFO: EPOCH:328
2023-09-06 14:27:34,418 MainThread INFO: Time Consumed:11.588694095611572s
2023-09-06 14:27:34,418 MainThread INFO: Total Frames:493500s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 329/400 [34:14<13:23, 11.31s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               560.44497
Train_Epoch_Reward                    4335.36794
Running_Training_Average_Rewards      705.10174
Explore_Time                          0.00411
Train___Time                          11.56803
Eval____Time                          0.01168
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.63406
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.79243
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.22470
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.81169
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.62719
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.74317
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.69485
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6109.85834
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.44932
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.07589
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.38087     0.45350    5.11994    3.74680
alpha_0                               0.42876     0.00023    0.42911    0.42840
alpha_1                               0.38055     0.00033    0.38107    0.38003
alpha_2                               0.38007     0.00032    0.38058    0.37956
alpha_3                               0.37737     0.00033    0.37789    0.37685
alpha_4                               0.37781     0.00032    0.37832    0.37730
alpha_5                               0.37919     0.00034    0.37973    0.37865
alpha_6                               0.37779     0.00033    0.37831    0.37727
alpha_7                               0.38861     0.00032    0.38910    0.38811
alpha_8                               0.38013     0.00034    0.38065    0.37960
alpha_9                               0.38039     0.00033    0.38092    0.37987
Alpha_loss                            -5.65457    0.02719    -5.62269   -5.70626
Training/policy_loss                  -69.70182   0.30562    -69.21330  -70.32545
Training/qf1_loss                     465.80210   128.20146  682.38318  306.38803
Training/qf2_loss                     459.71699   128.43767  675.64905  299.68298
Training/pf_norm                      0.18933     0.02292    0.24296    0.15523
Training/qf1_norm                     148.75427   118.94155  349.00858  34.25865
Training/qf2_norm                     147.40070   117.20989  345.16592  38.53643
log_std/mean                          -0.26988    0.00032    -0.26929   -0.27029
log_std/std                           0.13317     0.00027    0.13364    0.13279
log_std/max                           -0.11783    0.00111    -0.11603   -0.11957
log_std/min                           -0.67167    0.01012    -0.65676   -0.68617
log_probs/mean                        -1.87927    0.02972    -1.84124   -1.93300
log_probs/std                         1.51701     0.04004    1.58265    1.45430
log_probs/max                         4.77313     0.18271    5.03249    4.47264
log_probs/min                         -6.54332    0.57792    -5.58861   -7.46228
mean/mean                             0.01664     0.00131    0.01833    0.01446
mean/std                              0.52747     0.00085    0.52819    0.52518
mean/max                              1.73522     0.00591    1.74577    1.72746
mean/min                              -1.50737    0.00137    -1.50541   -1.51009
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 5, 1, 3, 4, 7, 2, 0, 9, 6]
replay_buffer._size: [49650 49650 49650 49650 49650 49650 49650 49650 49650 49650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.365137577056885 0.0020759105682373047
train_time 11.36847972869873
2023-09-06 14:27:45,917 MainThread INFO: EPOCH:329
2023-09-06 14:27:45,918 MainThread INFO: Time Consumed:11.385162591934204s
2023-09-06 14:27:45,918 MainThread INFO: Total Frames:495000s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 330/400 [34:25<13:15, 11.37s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               561.31506
Train_Epoch_Reward                    5808.79240
Running_Training_Average_Rewards      639.49821
Explore_Time                          0.00321
Train___Time                          11.36848
Eval____Time                          0.00820
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.35673
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.93347
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.20674
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.33107
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.96234
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.25705
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.45387
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6270.92990
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.21530
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.55965
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.74465     0.68176    5.81819     3.86114
alpha_0                               0.42796     0.00023    0.42832     0.42760
alpha_1                               0.37940     0.00033    0.37992     0.37889
alpha_2                               0.37894     0.00032    0.37945     0.37843
alpha_3                               0.37621     0.00033    0.37673     0.37569
alpha_4                               0.37668     0.00032    0.37719     0.37618
alpha_5                               0.37799     0.00034    0.37853     0.37746
alpha_6                               0.37664     0.00033    0.37716     0.37612
alpha_7                               0.38752     0.00031    0.38801     0.38703
alpha_8                               0.37896     0.00033    0.37948     0.37844
alpha_9                               0.37924     0.00033    0.37976     0.37872
Alpha_loss                            -5.68368    0.02155    -5.64519    -5.72122
Training/policy_loss                  -69.66434   0.24604    -69.27892   -70.07165
Training/qf1_loss                     584.42149   281.92024  1176.60449  202.81908
Training/qf2_loss                     578.62281   281.29105  1170.76624  198.03102
Training/pf_norm                      0.20158     0.03537    0.25493     0.15188
Training/qf1_norm                     282.07964   198.09091  612.76630   67.27232
Training/qf2_norm                     282.03635   194.92747  611.49652   67.82211
log_std/mean                          -0.26799    0.00078    -0.26693    -0.26931
log_std/std                           0.13255     0.00051    0.13318     0.13161
log_std/max                           -0.11914    0.00160    -0.11614    -0.12192
log_std/min                           -0.66343    0.01139    -0.64429    -0.68592
log_probs/mean                        -1.89282    0.02182    -1.85640    -1.93576
log_probs/std                         1.48721     0.03233    1.53779     1.42280
log_probs/max                         4.64250     0.28835    5.03624     3.98270
log_probs/min                         -6.69398    0.69552    -5.42796    -8.01086
mean/mean                             0.00995     0.00292    0.01409     0.00541
mean/std                              0.52411     0.00116    0.52568     0.52218
mean/max                              1.71445     0.00945    1.72633     1.69757
mean/min                              -1.52544    0.01044    -1.51133    -1.54243
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 6, 1, 2, 9, 8, 4, 7, 0, 3]
replay_buffer._size: [49800 49800 49800 49800 49800 49800 49800 49800 49800 49800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.219674587249756 0.001954793930053711
train_time 11.222840070724487
2023-09-06 14:27:57,277 MainThread INFO: EPOCH:330
2023-09-06 14:27:57,277 MainThread INFO: Time Consumed:11.234598636627197s
2023-09-06 14:27:57,277 MainThread INFO: Total Frames:496500s
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 331/400 [34:36<13:04, 11.37s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               572.42005
Train_Epoch_Reward                    2225.35784
Running_Training_Average_Rewards      412.31727
Explore_Time                          0.00305
Train___Time                          11.22284
Eval____Time                          0.00473
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.59512
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.03565
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.39630
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.07933
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.85495
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.41122
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.73817
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6336.09035
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.74783
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.08892
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.75753     0.75579    6.14348     3.83253
alpha_0                               0.42714     0.00024    0.42752     0.42677
alpha_1                               0.37826     0.00033    0.37877     0.37774
alpha_2                               0.37781     0.00032    0.37832     0.37731
alpha_3                               0.37506     0.00033    0.37558     0.37454
alpha_4                               0.37556     0.00032    0.37607     0.37506
alpha_5                               0.37680     0.00034    0.37734     0.37626
alpha_6                               0.37549     0.00033    0.37601     0.37498
alpha_7                               0.38643     0.00031    0.38692     0.38594
alpha_8                               0.37780     0.00033    0.37833     0.37728
alpha_9                               0.37809     0.00033    0.37860     0.37757
Alpha_loss                            -5.73310    0.02998    -5.66447    -5.77024
Training/policy_loss                  -70.04352   0.34364    -69.32014   -70.43081
Training/qf1_loss                     567.69273   229.89102  1018.22034  249.56064
Training/qf2_loss                     561.95648   229.49188  1010.93292  243.78568
Training/pf_norm                      0.17591     0.02934    0.22362     0.14107
Training/qf1_norm                     264.62377   229.43818  702.34760   48.40716
Training/qf2_norm                     264.15386   226.64943  704.07373   55.37777
log_std/mean                          -0.26591    0.00052    -0.26523    -0.26691
log_std/std                           0.13123     0.00023    0.13186     0.13100
log_std/max                           -0.12371    0.00089    -0.12245    -0.12552
log_std/min                           -0.66047    0.00670    -0.64427    -0.67213
log_probs/mean                        -1.92711    0.02952    -1.86214    -1.96260
log_probs/std                         1.46375     0.01984    1.50504     1.44066
log_probs/max                         4.45093     0.29635    5.03602     3.90898
log_probs/min                         -6.86076    0.74778    -5.73211    -8.00743
mean/mean                             0.00100     0.00174    0.00419     -0.00187
mean/std                              0.52067     0.00099    0.52327     0.51927
mean/max                              1.67774     0.00713    1.68960     1.66807
mean/min                              -1.55536    0.00609    -1.54530    -1.56457
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 6, 8, 0, 2, 5, 7, 4, 3, 1]
replay_buffer._size: [49950 49950 49950 49950 49950 49950 49950 49950 49950 49950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.067838668823242 0.0021026134490966797
train_time 7.071170330047607
2023-09-06 14:28:08,582 MainThread INFO: EPOCH:331
2023-09-06 14:28:08,582 MainThread INFO: Time Consumed:8.691314458847046s
2023-09-06 14:28:08,582 MainThread INFO: Total Frames:498000s
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 332/400 [34:48<12:51, 11.34s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               579.46312
Train_Epoch_Reward                    4116.36852
Running_Training_Average_Rewards      405.01729
Explore_Time                          1.61297
Train___Time                          7.07117
Eval____Time                          0.00261
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.26502
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.39015
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.46250
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.48438
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.49653
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.21731
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.21845
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6321.50400
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.37986
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.49263
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.39646     0.52434    5.26015    3.89189
alpha_0                               0.42630     0.00024    0.42668    0.42592
alpha_1                               0.37712     0.00033    0.37763    0.37660
alpha_2                               0.37669     0.00032    0.37720    0.37618
alpha_3                               0.37391     0.00033    0.37443    0.37340
alpha_4                               0.37444     0.00032    0.37494    0.37394
alpha_5                               0.37561     0.00034    0.37614    0.37507
alpha_6                               0.37435     0.00033    0.37487    0.37384
alpha_7                               0.38534     0.00031    0.38583    0.38484
alpha_8                               0.37665     0.00033    0.37717    0.37613
alpha_9                               0.37693     0.00033    0.37745    0.37642
Alpha_loss                            -5.74874    0.01971    -5.71670   -5.78293
Training/policy_loss                  -70.51316   0.25320    -70.09420  -70.95317
Training/qf1_loss                     451.65236   168.86221  790.61530  300.43405
Training/qf2_loss                     444.79960   168.75147  786.23822  294.88269
Training/pf_norm                      0.18682     0.03035    0.23921    0.14411
Training/qf1_norm                     172.30426   99.22479   349.92276  77.31813
Training/qf2_norm                     169.88918   100.69448  341.60730  73.19373
log_std/mean                          -0.26591    0.00016    -0.26563   -0.26613
log_std/std                           0.13213     0.00029    0.13272    0.13173
log_std/max                           -0.12243    0.00162    -0.11819   -0.12428
log_std/min                           -0.66027    0.00765    -0.65152   -0.67312
log_probs/mean                        -1.92467    0.02379    -1.89078   -1.96722
log_probs/std                         1.48468     0.04915    1.55975    1.41159
log_probs/max                         4.57443     0.13199    4.75830    4.39508
log_probs/min                         -7.28693    0.84391    -6.30482   -8.84947
mean/mean                             -0.00084    0.00124    0.00143    -0.00231
mean/std                              0.52142     0.00063    0.52276    0.52053
mean/max                              1.67008     0.00576    1.68117    1.66409
mean/min                              -1.57470    0.00410    -1.56689   -1.57858
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 5, 2, 7, 9, 4, 1, 6, 3, 0]
replay_buffer._size: [50100 50100 50100 50100 50100 50100 50100 50100 50100 50100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.47812819480896 0.0020227432250976562
train_time 11.48142671585083
2023-09-06 14:28:20,180 MainThread INFO: EPOCH:332
2023-09-06 14:28:20,181 MainThread INFO: Time Consumed:11.491750001907349s
2023-09-06 14:28:20,181 MainThread INFO: Total Frames:499500s
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 333/400 [34:59<12:45, 11.42s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               581.50691
Train_Epoch_Reward                    5248.14113
Running_Training_Average_Rewards      386.32892
Explore_Time                          0.00295
Train___Time                          11.48143
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.99007
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.44935
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -48.99826
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.11054
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.12203
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.48027
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.92274
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6321.30125
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.48081
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.77982
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.33584     0.61093    5.15019    3.16835
alpha_0                               0.42544     0.00025    0.42583    0.42505
alpha_1                               0.37598     0.00032    0.37649    0.37548
alpha_2                               0.37556     0.00032    0.37607    0.37505
alpha_3                               0.37277     0.00033    0.37328    0.37225
alpha_4                               0.37333     0.00032    0.37383    0.37283
alpha_5                               0.37442     0.00034    0.37495    0.37389
alpha_6                               0.37321     0.00033    0.37372    0.37270
alpha_7                               0.38424     0.00031    0.38473    0.38375
alpha_8                               0.37549     0.00033    0.37601    0.37497
alpha_9                               0.37578     0.00033    0.37630    0.37527
Alpha_loss                            -5.76092    0.03788    -5.70482   -5.82060
Training/policy_loss                  -70.26410   0.40641    -69.68114  -70.91875
Training/qf1_loss                     414.67817   112.01675  597.48621  285.88516
Training/qf2_loss                     409.04377   112.64915  592.61688  280.33441
Training/pf_norm                      0.21017     0.02568    0.24569    0.17291
Training/qf1_norm                     217.29967   139.82937  425.23199  51.80286
Training/qf2_norm                     217.36291   138.17743  429.27054  54.26108
log_std/mean                          -0.26547    0.00046    -0.26476   -0.26622
log_std/std                           0.13291     0.00034    0.13344    0.13231
log_std/max                           -0.11899    0.00150    -0.11623   -0.12116
log_std/min                           -0.66060    0.00958    -0.64766   -0.67409
log_probs/mean                        -1.92012    0.04163    -1.86481   -1.98866
log_probs/std                         1.45060     0.03843    1.50577    1.38968
log_probs/max                         4.45072     0.24181    4.94536    4.02041
log_probs/min                         -6.43700    0.67907    -5.46012   -7.86439
mean/mean                             0.00340     0.00072    0.00422    0.00214
mean/std                              0.52330     0.00108    0.52492    0.52154
mean/max                              1.70189     0.00827    1.71685    1.68829
mean/min                              -1.57438    0.00534    -1.56450   -1.57956
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 6, 9, 0, 1, 5, 2, 4, 7, 3]
replay_buffer._size: [50250 50250 50250 50250 50250 50250 50250 50250 50250 50250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.465680122375488 0.0021724700927734375
train_time 11.469163417816162
2023-09-06 14:28:31,793 MainThread INFO: EPOCH:333
2023-09-06 14:28:31,807 MainThread INFO: Time Consumed:11.484440326690674s
2023-09-06 14:28:31,807 MainThread INFO: Total Frames:501000s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 334/400 [35:11<12:37, 11.48s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               579.03294
Train_Epoch_Reward                    4648.72316
Running_Training_Average_Rewards      467.10776
Explore_Time                          0.00366
Train___Time                          11.46916
Eval____Time                          0.00523
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.65689
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.20710
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.26490
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.04881
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.80751
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.24673
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.97955
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6263.71111
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.55112
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.02477
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.47112     0.43466    5.26004    3.84392
alpha_0                               0.42457     0.00025    0.42496    0.42418
alpha_1                               0.37486     0.00032    0.37536    0.37435
alpha_2                               0.37444     0.00032    0.37494    0.37393
alpha_3                               0.37163     0.00033    0.37214    0.37111
alpha_4                               0.37222     0.00032    0.37272    0.37172
alpha_5                               0.37324     0.00034    0.37377    0.37270
alpha_6                               0.37208     0.00033    0.37259    0.37156
alpha_7                               0.38315     0.00031    0.38364    0.38266
alpha_8                               0.37435     0.00033    0.37486    0.37383
alpha_9                               0.37464     0.00033    0.37515    0.37412
Alpha_loss                            -5.78648    0.01685    -5.76021   -5.81828
Training/policy_loss                  -70.40411   0.24980    -69.85474  -70.72729
Training/qf1_loss                     511.99348   147.98217  734.18585  288.83374
Training/qf2_loss                     505.54716   148.36084  727.72150  281.91595
Training/pf_norm                      0.22164     0.03181    0.27544    0.16515
Training/qf1_norm                     210.50058   123.11206  469.91873  69.90286
Training/qf2_norm                     215.81695   124.64062  478.67178  66.73457
log_std/mean                          -0.26371    0.00052    -0.26319   -0.26480
log_std/std                           0.13137     0.00070    0.13262    0.13055
log_std/max                           -0.11618    0.00137    -0.11405   -0.11842
log_std/min                           -0.65691    0.00652    -0.63985   -0.66548
log_probs/mean                        -1.92889    0.01726    -1.89585   -1.96024
log_probs/std                         1.44537     0.03303    1.49798    1.38742
log_probs/max                         4.19760     0.27351    4.62208    3.80114
log_probs/min                         -6.70831    0.36310    -5.87402   -7.08321
mean/mean                             0.00102     0.00203    0.00373    -0.00277
mean/std                              0.51906     0.00224    0.52356    0.51638
mean/max                              1.69709     0.00874    1.70822    1.68223
mean/min                              -1.53638    0.01366    -1.51430   -1.55804
------------------------------------  ----------  ---------  ---------  ---------
sample: [2, 5, 8, 7, 3, 6, 1, 4, 0, 9]
replay_buffer._size: [50400 50400 50400 50400 50400 50400 50400 50400 50400 50400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.191452741622925 0.0019927024841308594
train_time 11.194692134857178
2023-09-06 14:28:43,145 MainThread INFO: EPOCH:334
2023-09-06 14:28:43,146 MainThread INFO: Time Consumed:11.22354769706726s
2023-09-06 14:28:43,146 MainThread INFO: Total Frames:502500s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 335/400 [35:22<12:23, 11.44s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               574.41970
Train_Epoch_Reward                    5556.35755
Running_Training_Average_Rewards      515.10739
Explore_Time                          0.00335
Train___Time                          11.19469
Eval____Time                          0.02139
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.35025
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.19292
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -48.86722
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.11695
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.95624
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.74455
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.05636
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6177.97349
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.18447
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.80456
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.20699     0.45163    5.02072    3.38948
alpha_0                               0.42368     0.00026    0.42409    0.42326
alpha_1                               0.37374     0.00032    0.37424    0.37323
alpha_2                               0.37332     0.00032    0.37382    0.37282
alpha_3                               0.37049     0.00033    0.37100    0.36997
alpha_4                               0.37111     0.00032    0.37161    0.37062
alpha_5                               0.37206     0.00034    0.37259    0.37153
alpha_6                               0.37094     0.00033    0.37145    0.37043
alpha_7                               0.38206     0.00031    0.38255    0.38157
alpha_8                               0.37320     0.00033    0.37372    0.37269
alpha_9                               0.37350     0.00033    0.37401    0.37298
Alpha_loss                            -5.81393    0.02584    -5.75578   -5.84567
Training/policy_loss                  -70.91337   0.23205    -70.60567  -71.42432
Training/qf1_loss                     423.36687   131.58282  681.50354  269.76920
Training/qf2_loss                     416.97181   130.88131  674.42371  264.35779
Training/pf_norm                      0.19293     0.03783    0.28302    0.14538
Training/qf1_norm                     131.81074   98.88437   307.76666  44.61130
Training/qf2_norm                     132.19236   97.06378   310.90057  38.61942
log_std/mean                          -0.26304    0.00022    -0.26271   -0.26333
log_std/std                           0.12923     0.00049    0.13019    0.12869
log_std/max                           -0.11698    0.00143    -0.11378   -0.11861
log_std/min                           -0.64629    0.00776    -0.63598   -0.66264
log_probs/mean                        -1.94163    0.02557    -1.88804   -1.97576
log_probs/std                         1.40341     0.02696    1.45138    1.34384
log_probs/max                         4.04891     0.16838    4.30573    3.71044
log_probs/min                         -7.43568    0.62293    -6.74056   -8.68414
mean/mean                             -0.00785    0.00244    -0.00340   -0.01096
mean/std                              0.51249     0.00162    0.51509    0.51020
mean/max                              1.66398     0.00984    1.68397    1.65320
mean/min                              -1.48692    0.01370    -1.46711   -1.51130
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 6, 0, 8, 1, 9, 2, 3, 7, 4]
replay_buffer._size: [50550 50550 50550 50550 50550 50550 50550 50550 50550 50550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.645047903060913 0.0020656585693359375
train_time 11.648341655731201
2023-09-06 14:28:54,913 MainThread INFO: EPOCH:335
2023-09-06 14:28:54,913 MainThread INFO: Time Consumed:11.657729387283325s
2023-09-06 14:28:54,914 MainThread INFO: Total Frames:504000s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 336/400 [35:34<12:18, 11.54s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               567.67061
Train_Epoch_Reward                    5529.15987
Running_Training_Average_Rewards      524.47469
Explore_Time                          0.00301
Train___Time                          11.64834
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.86893
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.36210
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.76026
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.81531
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.39272
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.38932
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.39589
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6121.05320
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.68106
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89309
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.60612     0.46112    5.46098    3.91966
alpha_0                               0.42273     0.00028    0.42316    0.42230
alpha_1                               0.37262     0.00032    0.37312    0.37211
alpha_2                               0.37221     0.00032    0.37271    0.37170
alpha_3                               0.36935     0.00033    0.36986    0.36884
alpha_4                               0.37002     0.00031    0.37051    0.36952
alpha_5                               0.37088     0.00034    0.37141    0.37036
alpha_6                               0.36981     0.00032    0.37032    0.36930
alpha_7                               0.38099     0.00031    0.38147    0.38051
alpha_8                               0.37206     0.00033    0.37258    0.37155
alpha_9                               0.37236     0.00033    0.37287    0.37185
Alpha_loss                            -5.82937    0.02509    -5.78392   -5.87086
Training/policy_loss                  -70.91379   0.34234    -70.22993  -71.38328
Training/qf1_loss                     472.59217   139.92610  708.07422  307.86798
Training/qf2_loss                     467.67964   140.36106  704.77747  302.29254
Training/pf_norm                      0.23086     0.03028    0.27761    0.18475
Training/qf1_norm                     216.94593   144.15196  500.19116  62.86682
Training/qf2_norm                     213.83605   141.77820  491.38998  63.30014
log_std/mean                          -0.26318    0.00023    -0.26263   -0.26348
log_std/std                           0.12812     0.00033    0.12866    0.12763
log_std/max                           -0.12131    0.00170    -0.11934   -0.12471
log_std/min                           -0.64915    0.00839    -0.63277   -0.66018
log_probs/mean                        -1.94052    0.02435    -1.90199   -1.97962
log_probs/std                         1.37210     0.02862    1.43106    1.32488
log_probs/max                         3.84930     0.15717    4.17829    3.65034
log_probs/min                         -6.21713    0.70816    -5.48068   -7.96765
mean/mean                             -0.01197    0.00038    -0.01124   -0.01276
mean/std                              0.50807     0.00114    0.50979    0.50611
mean/max                              1.64213     0.00471    1.64804    1.63489
mean/min                              -1.45378    0.00658    -1.44363   -1.46405
------------------------------------  ----------  ---------  ---------  ---------
sample: [3, 7, 8, 6, 9, 2, 4, 1, 5, 0]
replay_buffer._size: [50700 50700 50700 50700 50700 50700 50700 50700 50700 50700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.4555723667144775 0.0020246505737304688
train_time 7.4590442180633545
2023-09-06 14:29:06,552 MainThread INFO: EPOCH:336
2023-09-06 14:29:06,552 MainThread INFO: Time Consumed:11.507354497909546s
2023-09-06 14:29:06,553 MainThread INFO: Total Frames:505500s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 337/400 [35:46<12:09, 11.57s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               569.30249
Train_Epoch_Reward                    4800.22980
Running_Training_Average_Rewards      529.52491
Explore_Time                          4.02460
Train___Time                          7.45904
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.19492
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.35703
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -46.74172
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.87989
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.79488
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.81628
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.74793
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6307.23113
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.41397
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.40436
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.44866     0.47866    5.28196    3.54342
alpha_0                               0.42175     0.00029    0.42220    0.42129
alpha_1                               0.37149     0.00032    0.37200    0.37099
alpha_2                               0.37109     0.00032    0.37159    0.37059
alpha_3                               0.36822     0.00032    0.36873    0.36771
alpha_4                               0.36892     0.00031    0.36941    0.36843
alpha_5                               0.36971     0.00034    0.37024    0.36919
alpha_6                               0.36868     0.00032    0.36919    0.36818
alpha_7                               0.37993     0.00030    0.38040    0.37945
alpha_8                               0.37093     0.00032    0.37144    0.37042
alpha_9                               0.37123     0.00032    0.37174    0.37072
Alpha_loss                            -5.86005    0.02422    -5.82345   -5.89884
Training/policy_loss                  -71.39046   0.35530    -70.84987  -72.04868
Training/qf1_loss                     468.08414   119.01895  730.06482  267.20306
Training/qf2_loss                     461.79893   119.19047  722.92877  260.53851
Training/pf_norm                      0.23040     0.01874    0.25183    0.19610
Training/qf1_norm                     187.34739   87.76134   343.94562  85.63779
Training/qf2_norm                     186.74363   82.54180   340.14508  93.19775
log_std/mean                          -0.26324    0.00016    -0.26297   -0.26345
log_std/std                           0.12749     0.00020    0.12780    0.12707
log_std/max                           -0.12735    0.00184    -0.12318   -0.12957
log_std/min                           -0.63517    0.00678    -0.62361   -0.64789
log_probs/mean                        -1.95544    0.02495    -1.91644   -1.99707
log_probs/std                         1.35543     0.03377    1.39264    1.30279
log_probs/max                         3.61245     0.28015    4.12327    3.13380
log_probs/min                         -6.90778    0.57789    -5.83339   -7.83607
mean/mean                             -0.01203    0.00056    -0.01068   -0.01266
mean/std                              0.50582     0.00072    0.50663    0.50470
mean/max                              1.64819     0.00590    1.66029    1.64169
mean/min                              -1.43942    0.00164    -1.43712   -1.44252
------------------------------------  ----------  ---------  ---------  ---------
sample: [7, 0, 8, 6, 9, 2, 1, 3, 4, 5]
replay_buffer._size: [50850 50850 50850 50850 50850 50850 50850 50850 50850 50850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.0486109256744385 0.002129077911376953
train_time 7.052712440490723
2023-09-06 14:29:18,616 MainThread INFO: EPOCH:337
2023-09-06 14:29:18,617 MainThread INFO: Time Consumed:7.414343595504761s
2023-09-06 14:29:18,617 MainThread INFO: Total Frames:507000s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 338/400 [35:58<12:06, 11.72s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               589.69102
Train_Epoch_Reward                    5725.84513
Running_Training_Average_Rewards      535.17449
Explore_Time                          0.33918
Train___Time                          7.05271
Eval____Time                          0.00553
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.08986
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.96731
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -45.64028
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.70883
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.86939
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.18024
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.42587
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6784.52342
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.10238
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.18344
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.34689     0.66784    5.60019    3.46733
alpha_0                               0.42073     0.00029    0.42119    0.42027
alpha_1                               0.37037     0.00032    0.37088    0.36987
alpha_2                               0.36998     0.00032    0.37048    0.36947
alpha_3                               0.36710     0.00032    0.36760    0.36659
alpha_4                               0.36784     0.00031    0.36832    0.36735
alpha_5                               0.36855     0.00034    0.36907    0.36802
alpha_6                               0.36756     0.00032    0.36807    0.36705
alpha_7                               0.37888     0.00030    0.37935    0.37841
alpha_8                               0.36980     0.00032    0.37031    0.36930
alpha_9                               0.37010     0.00032    0.37061    0.36959
Alpha_loss                            -5.88540    0.02326    -5.84938   -5.90932
Training/policy_loss                  -71.56626   0.31543    -71.17936  -72.24566
Training/qf1_loss                     508.78284   178.29972  910.16620  245.99179
Training/qf2_loss                     502.92760   178.58242  906.01257  240.01045
Training/pf_norm                      0.24597     0.04008    0.35285    0.20395
Training/qf1_norm                     210.63521   146.68731  532.90149  41.89227
Training/qf2_norm                     207.88493   146.01204  533.33734  42.82962
log_std/mean                          -0.26294    0.00018    -0.26257   -0.26324
log_std/std                           0.12858     0.00073    0.12972    0.12762
log_std/max                           -0.12291    0.00248    -0.11910   -0.12653
log_std/min                           -0.63437    0.00445    -0.62722   -0.64057
log_probs/mean                        -1.96315    0.02089    -1.92545   -1.99087
log_probs/std                         1.34505     0.03273    1.39754    1.28215
log_probs/max                         3.50198     0.30550    4.05314    3.05174
log_probs/min                         -6.63911    0.83412    -5.42519   -8.29068
mean/mean                             -0.01054    0.00051    -0.00973   -0.01146
mean/std                              0.50760     0.00142    0.50985    0.50519
mean/max                              1.68111     0.01024    1.69686    1.66368
mean/min                              -1.45240    0.00800    -1.44152   -1.46789
------------------------------------  ----------  ---------  ---------  ---------
sample: [8, 1, 0, 2, 3, 4, 9, 7, 5, 6]
replay_buffer._size: [51000 51000 51000 51000 51000 51000 51000 51000 51000 51000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.597570896148682 0.0020034313201904297
train_time 11.600812435150146
2023-09-06 14:29:30,347 MainThread INFO: EPOCH:338
2023-09-06 14:29:30,347 MainThread INFO: Time Consumed:11.610548973083496s
2023-09-06 14:29:30,347 MainThread INFO: Total Frames:508500s
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 339/400 [36:09<11:54, 11.72s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               632.48487
Train_Epoch_Reward                    6328.99470
Running_Training_Average_Rewards      561.83565
Explore_Time                          0.00306
Train___Time                          11.60081
Eval____Time                          0.00275
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.81583
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.17802
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -44.40137
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.01149
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.65977
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.62988
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.46398
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7391.46321
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.50159
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.49120
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.48172     0.63789    5.55510    3.40127
alpha_0                               0.41971     0.00029    0.42017    0.41925
alpha_1                               0.36926     0.00032    0.36976    0.36877
alpha_2                               0.36886     0.00032    0.36936    0.36836
alpha_3                               0.36598     0.00032    0.36648    0.36548
alpha_4                               0.36676     0.00031    0.36724    0.36627
alpha_5                               0.36738     0.00033    0.36790    0.36686
alpha_6                               0.36643     0.00032    0.36694    0.36592
alpha_7                               0.37783     0.00030    0.37830    0.37736
alpha_8                               0.36868     0.00032    0.36919    0.36818
alpha_9                               0.36897     0.00032    0.36948    0.36847
Alpha_loss                            -5.88348    0.02978    -5.84834   -5.94902
Training/policy_loss                  -71.59177   0.35350    -70.99244  -72.07796
Training/qf1_loss                     483.42425   176.93880  758.69623  230.60873
Training/qf2_loss                     476.62405   176.80585  751.02295  223.11841
Training/pf_norm                      0.25893     0.04877    0.33966    0.20630
Training/qf1_norm                     222.98145   142.59918  551.93799  65.29535
Training/qf2_norm                     224.78722   142.08155  556.15839  74.46105
log_std/mean                          -0.26387    0.00024    -0.26340   -0.26419
log_std/std                           0.13052     0.00037    0.13104    0.12978
log_std/max                           -0.12029    0.00033    -0.11986   -0.12101
log_std/min                           -0.63617    0.00585    -0.62698   -0.64768
log_probs/mean                        -1.94197    0.02913    -1.91059   -2.01160
log_probs/std                         1.36734     0.02438    1.41906    1.32965
log_probs/max                         3.46831     0.21590    3.86606    3.12201
log_probs/min                         -6.65819    1.07064    -5.72129   -9.49719
mean/mean                             -0.01213    0.00104    -0.01089   -0.01406
mean/std                              0.51160     0.00110    0.51281    0.50934
mean/max                              1.70383     0.00328    1.70691    1.69767
mean/min                              -1.48660    0.01010    -1.46988   -1.50111
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 3, 2, 0, 4, 7, 5, 8, 6, 9]
replay_buffer._size: [51150 51150 51150 51150 51150 51150 51150 51150 51150 51150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.586658239364624 0.002158641815185547
train_time 11.590118408203125
2023-09-06 14:29:42,052 MainThread INFO: EPOCH:339
2023-09-06 14:29:42,052 MainThread INFO: Time Consumed:11.601105690002441s
2023-09-06 14:29:42,053 MainThread INFO: Total Frames:510000s
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 340/400 [36:21<11:43, 11.72s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               687.59530
Train_Epoch_Reward                    8876.97595
Running_Training_Average_Rewards      697.72719
Explore_Time                          0.00320
Train___Time                          11.59012
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.11384
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.87788
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.76123
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.97596
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.98660
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.56291
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.04482
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7948.88062
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.39282
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.97149
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.89718     0.32779    5.54788    4.43093
alpha_0                               0.41870     0.00028    0.41915    0.41826
alpha_1                               0.36816     0.00031    0.36866    0.36767
alpha_2                               0.36775     0.00032    0.36825    0.36725
alpha_3                               0.36486     0.00032    0.36536    0.36436
alpha_4                               0.36568     0.00031    0.36617    0.36520
alpha_5                               0.36622     0.00033    0.36674    0.36570
alpha_6                               0.36530     0.00032    0.36581    0.36479
alpha_7                               0.37679     0.00030    0.37726    0.37632
alpha_8                               0.36757     0.00032    0.36807    0.36707
alpha_9                               0.36785     0.00032    0.36835    0.36734
Alpha_loss                            -5.87995    0.02465    -5.84549   -5.92486
Training/policy_loss                  -71.90258   0.30442    -71.39236  -72.35695
Training/qf1_loss                     562.87730   174.14362  918.08167  324.60800
Training/qf2_loss                     556.94012   173.24052  909.49774  320.49969
Training/pf_norm                      0.21619     0.02757    0.28176    0.16752
Training/qf1_norm                     262.82277   127.13411  541.00439  98.62420
Training/qf2_norm                     264.86055   127.06390  545.24756  102.35176
log_std/mean                          -0.26454    0.00017    -0.26413   -0.26473
log_std/std                           0.13073     0.00034    0.13107    0.13003
log_std/max                           -0.12422    0.00173    -0.11999   -0.12640
log_std/min                           -0.63992    0.00691    -0.62475   -0.65040
log_probs/mean                        -1.91857    0.02582    -1.87893   -1.96288
log_probs/std                         1.38970     0.01882    1.42801    1.35358
log_probs/max                         3.39497     0.12485    3.58581    3.20838
log_probs/min                         -7.20868    0.69404    -6.33981   -8.54487
mean/mean                             -0.01979    0.00311    -0.01494   -0.02437
mean/std                              0.51229     0.00046    0.51294    0.51143
mean/max                              1.67275     0.01502    1.69152    1.64745
mean/min                              -1.50908    0.00308    -1.50444   -1.51395
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 4, 6, 3, 2, 1, 7, 9, 5, 8]
replay_buffer._size: [51300 51300 51300 51300 51300 51300 51300 51300 51300 51300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.296493530273438 0.001964569091796875
train_time 11.299663782119751
2023-09-06 14:29:53,493 MainThread INFO: EPOCH:340
2023-09-06 14:29:53,493 MainThread INFO: Time Consumed:11.310645341873169s
2023-09-06 14:29:53,494 MainThread INFO: Total Frames:511500s
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 341/400 [36:33<11:26, 11.64s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               742.78680
Train_Epoch_Reward                    9182.16334
Running_Training_Average_Rewards      812.93780
Explore_Time                          0.00415
Train___Time                          11.29966
Eval____Time                          0.00226
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.64249
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.18807
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.54126
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.73061
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.12634
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.96456
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.07478
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8428.00931
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.49725
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.14310
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.73547     0.56125    5.66621    3.94005
alpha_0                               0.41771     0.00029    0.41816    0.41726
alpha_1                               0.36707     0.00031    0.36756    0.36658
alpha_2                               0.36664     0.00032    0.36714    0.36614
alpha_3                               0.36375     0.00032    0.36425    0.36325
alpha_4                               0.36462     0.00030    0.36510    0.36414
alpha_5                               0.36506     0.00033    0.36558    0.36454
alpha_6                               0.36417     0.00032    0.36468    0.36367
alpha_7                               0.37575     0.00030    0.37622    0.37529
alpha_8                               0.36647     0.00032    0.36696    0.36597
alpha_9                               0.36672     0.00033    0.36723    0.36621
Alpha_loss                            -5.92949    0.02433    -5.87586   -5.95992
Training/policy_loss                  -72.38254   0.35563    -71.64933  -73.05207
Training/qf1_loss                     626.51331   167.99095  872.58771  308.19864
Training/qf2_loss                     619.19289   167.74065  860.06171  300.55157
Training/pf_norm                      0.22800     0.03503    0.29141    0.17953
Training/qf1_norm                     192.94669   175.55322  503.96643  41.74753
Training/qf2_norm                     194.50055   174.79634  502.32043  40.50126
log_std/mean                          -0.26256    0.00047    -0.26202   -0.26350
log_std/std                           0.12858     0.00052    0.12933    0.12779
log_std/max                           -0.12165    0.00091    -0.12030   -0.12359
log_std/min                           -0.63057    0.00595    -0.62044   -0.63967
log_probs/mean                        -1.95334    0.02473    -1.89872   -1.98167
log_probs/std                         1.35853     0.03048    1.39546    1.29539
log_probs/max                         3.43126     0.17848    3.68098    3.18564
log_probs/min                         -6.64303    0.69443    -5.29931   -7.62224
mean/mean                             -0.02676    0.00063    -0.02579   -0.02772
mean/std                              0.50934     0.00054    0.51026    0.50852
mean/max                              1.63311     0.00399    1.64230    1.62897
mean/min                              -1.50305    0.00179    -1.50046   -1.50529
------------------------------------  ----------  ---------  ---------  ---------
sample: [0, 9, 2, 5, 7, 4, 3, 1, 6, 8]
replay_buffer._size: [51450 51450 51450 51450 51450 51450 51450 51450 51450 51450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.571642875671387 0.0032444000244140625
train_time 6.576785326004028
2023-09-06 14:30:05,080 MainThread INFO: EPOCH:341
2023-09-06 14:30:05,081 MainThread INFO: Time Consumed:6.898977994918823s
2023-09-06 14:30:05,081 MainThread INFO: Total Frames:513000s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 342/400 [36:44<11:14, 11.63s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               776.54938
Train_Epoch_Reward                    5226.87137
Running_Training_Average_Rewards      776.20036
Explore_Time                          0.31140
Train___Time                          6.57679
Eval____Time                          0.00557
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.89133
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.22154
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.69370
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.81288
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.26894
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.40884
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.75561
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8386.00654
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.45680
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.30930
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.79205     0.46599    5.83767     4.09070
alpha_0                               0.41670     0.00029    0.41716     0.41625
alpha_1                               0.36598     0.00031    0.36647     0.36550
alpha_2                               0.36552     0.00032    0.36603     0.36502
alpha_3                               0.36264     0.00032    0.36314     0.36214
alpha_4                               0.36356     0.00030    0.36404     0.36309
alpha_5                               0.36391     0.00033    0.36443     0.36339
alpha_6                               0.36305     0.00032    0.36355     0.36255
alpha_7                               0.37471     0.00030    0.37518     0.37424
alpha_8                               0.36536     0.00032    0.36586     0.36487
alpha_9                               0.36558     0.00032    0.36609     0.36507
Alpha_loss                            -5.93590    0.03112    -5.89539    -5.97770
Training/policy_loss                  -72.46600   0.22302    -72.16242   -72.78857
Training/qf1_loss                     628.27703   251.78584  1169.16968  386.37531
Training/qf2_loss                     621.25474   251.04266  1162.50159  379.37146
Training/pf_norm                      0.23769     0.03636    0.29951     0.18058
Training/qf1_norm                     189.29941   149.26811  577.64178   62.63007
Training/qf2_norm                     193.04528   148.36025  576.42426   66.37288
log_std/mean                          -0.26323    0.00035    -0.26258    -0.26359
log_std/std                           0.12786     0.00032    0.12842     0.12733
log_std/max                           -0.12368    0.00114    -0.12146    -0.12487
log_std/min                           -0.62565    0.00842    -0.61176    -0.63969
log_probs/mean                        -1.94119    0.03519    -1.89660    -1.99362
log_probs/std                         1.36012     0.03207    1.41924     1.31819
log_probs/max                         3.57452     0.20937    3.86674     3.12047
log_probs/min                         -6.83390    0.63750    -5.79662    -7.78241
mean/mean                             -0.02221    0.00292    -0.01788    -0.02623
mean/std                              0.51057     0.00087    0.51187     0.50884
mean/max                              1.66561     0.01552    1.68931     1.64026
mean/min                              -1.51734    0.00366    -1.50835    -1.52072
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 6, 3, 5, 0, 2, 9, 4, 7, 8]
replay_buffer._size: [51600 51600 51600 51600 51600 51600 51600 51600 51600 51600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.202139377593994 0.0021784305572509766
train_time 6.205830335617065
2023-09-06 14:30:17,094 MainThread INFO: EPOCH:342
2023-09-06 14:30:17,094 MainThread INFO: Time Consumed:6.71460223197937s
2023-09-06 14:30:17,095 MainThread INFO: Total Frames:514500s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 343/400 [36:56<11:08, 11.73s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               787.72844
Train_Epoch_Reward                    9662.53155
Running_Training_Average_Rewards      802.38554
Explore_Time                          0.48964
Train___Time                          6.20583
Eval____Time                          0.00454
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.35793
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.89076
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.91740
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.38189
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.52347
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.25437
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.07100
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8263.99239
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.22217
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.80866
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.64736     0.32069    5.14605     4.08477
alpha_0                               0.41570     0.00029    0.41615     0.41525
alpha_1                               0.36491     0.00031    0.36539     0.36443
alpha_2                               0.36441     0.00032    0.36491     0.36392
alpha_3                               0.36153     0.00032    0.36203     0.36103
alpha_4                               0.36252     0.00030    0.36299     0.36205
alpha_5                               0.36276     0.00033    0.36328     0.36224
alpha_6                               0.36194     0.00032    0.36244     0.36144
alpha_7                               0.37366     0.00031    0.37414     0.37318
alpha_8                               0.36426     0.00032    0.36476     0.36376
alpha_9                               0.36445     0.00032    0.36496     0.36395
Alpha_loss                            -5.97468    0.01750    -5.93469    -6.00472
Training/policy_loss                  -72.88817   0.42698    -72.07622   -73.51115
Training/qf1_loss                     552.20451   244.82272  1210.36987  293.64838
Training/qf2_loss                     545.48103   244.41222  1202.66003  288.53363
Training/pf_norm                      0.23544     0.05397    0.36306     0.16634
Training/qf1_norm                     146.03194   65.71880   296.25769   68.34822
Training/qf2_norm                     150.54205   68.47871   306.85495   72.54318
log_std/mean                          -0.26257    0.00034    -0.26196    -0.26300
log_std/std                           0.12914     0.00046    0.12979     0.12839
log_std/max                           -0.12214    0.00157    -0.11881    -0.12411
log_std/min                           -0.62106    0.00576    -0.61573    -0.63634
log_probs/mean                        -1.96304    0.01691    -1.92603    -1.98229
log_probs/std                         1.35513     0.02830    1.41986     1.31937
log_probs/max                         3.49887     0.20008    3.87999     3.11752
log_probs/min                         -7.18248    1.13773    -5.38792    -9.27078
mean/mean                             -0.01151    0.00304    -0.00725    -0.01630
mean/std                              0.50812     0.00111    0.51001     0.50669
mean/max                              1.69996     0.01037    1.71551     1.68466
mean/min                              -1.50800    0.00465    -1.50163    -1.51573
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 5, 6, 7, 4, 2, 8, 9, 0, 1]
replay_buffer._size: [51750 51750 51750 51750 51750 51750 51750 51750 51750 51750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 16.38839316368103 0.0019903182983398438
train_time 16.39158868789673
2023-09-06 14:30:33,622 MainThread INFO: EPOCH:343
2023-09-06 14:30:33,623 MainThread INFO: Time Consumed:16.411163806915283s
2023-09-06 14:30:33,623 MainThread INFO: Total Frames:516000s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 344/400 [37:13<12:18, 13.18s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               785.84484
Train_Epoch_Reward                    7210.47866
Running_Training_Average_Rewards      736.66272
Explore_Time                          0.00282
Train___Time                          16.39159
Eval____Time                          0.01268
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.12370
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.17063
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.79692
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.65138
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.97678
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.88735
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.62758
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8363.36348
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.41018
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.12598
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.29499     0.40501    4.80300    3.61371
alpha_0                               0.41471     0.00028    0.41515    0.41426
alpha_1                               0.36384     0.00031    0.36432    0.36336
alpha_2                               0.36332     0.00031    0.36381    0.36283
alpha_3                               0.36042     0.00032    0.36092    0.35992
alpha_4                               0.36148     0.00030    0.36195    0.36101
alpha_5                               0.36161     0.00033    0.36213    0.36110
alpha_6                               0.36083     0.00032    0.36133    0.36033
alpha_7                               0.37259     0.00031    0.37307    0.37210
alpha_8                               0.36316     0.00032    0.36365    0.36266
alpha_9                               0.36332     0.00032    0.36383    0.36282
Alpha_loss                            -5.98281    0.02711    -5.94468   -6.03078
Training/policy_loss                  -73.20442   0.26767    -72.91167  -73.69244
Training/qf1_loss                     481.24551   156.55133  884.11603  311.85568
Training/qf2_loss                     474.28263   156.23765  875.51007  305.35846
Training/pf_norm                      0.21493     0.02811    0.26746    0.17528
Training/qf1_norm                     145.46380   78.38122   319.56958  62.07792
Training/qf2_norm                     141.32382   71.58723   302.16467  66.73804
log_std/mean                          -0.26398    0.00087    -0.26269   -0.26532
log_std/std                           0.13014     0.00032    0.13061    0.12976
log_std/max                           -0.12288    0.00090    -0.12125   -0.12425
log_std/min                           -0.62308    0.00490    -0.61741   -0.63372
log_probs/mean                        -1.95196    0.02678    -1.91759   -2.00051
log_probs/std                         1.37606     0.02918    1.44159    1.34291
log_probs/max                         3.52823     0.19182    3.79874    3.16650
log_probs/min                         -6.61833    0.83103    -5.32405   -7.96393
mean/mean                             -0.00361    0.00169    -0.00108   -0.00630
mean/std                              0.50753     0.00090    0.50917    0.50626
mean/max                              1.73127     0.00892    1.74543    1.71784
mean/min                              -1.50752    0.00537    -1.50134   -1.51787
------------------------------------  ----------  ---------  ---------  ---------
sample: [4, 0, 3, 7, 5, 9, 8, 2, 1, 6]
replay_buffer._size: [51900 51900 51900 51900 51900 51900 51900 51900 51900 51900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.766433238983154 0.0020914077758789062
train_time 12.769810676574707
2023-09-06 14:30:46,573 MainThread INFO: EPOCH:344
2023-09-06 14:30:46,573 MainThread INFO: Time Consumed:12.78719973564148s
2023-09-06 14:30:46,574 MainThread INFO: Total Frames:517500s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 345/400 [37:26<12:00, 13.10s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               856.58633
Train_Epoch_Reward                    7598.75834
Running_Training_Average_Rewards      815.72562
Explore_Time                          0.00516
Train___Time                          12.76981
Eval____Time                          0.00463
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.65751
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.06060
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -44.31379
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2128.14450
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.65014
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.24073
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.62006
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8368.01998
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.68479
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.50474
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.69953     0.52240    5.38383     3.64714
alpha_0                               0.41373     0.00028    0.41416     0.41329
alpha_1                               0.36277     0.00030    0.36325     0.36230
alpha_2                               0.36223     0.00031    0.36272     0.36174
alpha_3                               0.35931     0.00032    0.35981     0.35881
alpha_4                               0.36043     0.00030    0.36090     0.35996
alpha_5                               0.36047     0.00033    0.36099     0.35996
alpha_6                               0.35973     0.00032    0.36022     0.35924
alpha_7                               0.37150     0.00031    0.37199     0.37100
alpha_8                               0.36206     0.00031    0.36256     0.36157
alpha_9                               0.36220     0.00032    0.36271     0.36170
Alpha_loss                            -5.99380    0.03519    -5.92882    -6.03145
Training/policy_loss                  -73.14230   0.25374    -72.75349   -73.59241
Training/qf1_loss                     610.27136   228.71747  1090.68835  360.61710
Training/qf2_loss                     603.43730   227.99083  1083.06604  354.94888
Training/pf_norm                      0.22042     0.03135    0.26591     0.16024
Training/qf1_norm                     211.16926   94.59432   374.53760   67.70020
Training/qf2_norm                     214.04096   93.88882   383.91800   74.89469
log_std/mean                          -0.26581    0.00025    -0.26533    -0.26627
log_std/std                           0.13042     0.00020    0.13078     0.13003
log_std/max                           -0.12044    0.00113    -0.11869    -0.12226
log_std/min                           -0.62697    0.00826    -0.61662    -0.64003
log_probs/mean                        -1.94462    0.03538    -1.88225    -1.98099
log_probs/std                         1.37000     0.04370    1.44727     1.27219
log_probs/max                         3.46688     0.25792    3.91652     3.00918
log_probs/min                         -6.55008    0.56839    -5.43569    -7.39845
mean/mean                             -0.00112    0.00034    -0.00053    -0.00168
mean/std                              0.50820     0.00060    0.50916     0.50696
mean/max                              1.73354     0.00758    1.74330     1.72137
mean/min                              -1.52168    0.00219    -1.51801    -1.52474
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 8, 1, 6, 9, 4, 2, 0, 3, 5]
replay_buffer._size: [52050 52050 52050 52050 52050 52050 52050 52050 52050 52050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.965662717819214 0.002119779586791992
train_time 11.96907353401184
2023-09-06 14:30:58,678 MainThread INFO: EPOCH:345
2023-09-06 14:30:58,678 MainThread INFO: Time Consumed:11.9869065284729s
2023-09-06 14:30:58,678 MainThread INFO: Total Frames:519000s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 346/400 [37:38<11:31, 12.80s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               913.29929
Train_Epoch_Reward                    7663.11546
Running_Training_Average_Rewards      749.07842
Explore_Time                          0.00563
Train___Time                          11.96907
Eval____Time                          0.00655
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.69861
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.32072
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -45.20152
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1802.47379
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.06645
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.83048
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.66237
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8157.33025
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.65508
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.41518
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.54577     0.23411    4.95756    4.24097
alpha_0                               0.41276     0.00028    0.41320    0.41233
alpha_1                               0.36172     0.00030    0.36219    0.36125
alpha_2                               0.36115     0.00031    0.36164    0.36066
alpha_3                               0.35820     0.00032    0.35870    0.35770
alpha_4                               0.35939     0.00030    0.35986    0.35892
alpha_5                               0.35934     0.00032    0.35985    0.35883
alpha_6                               0.35863     0.00031    0.35913    0.35814
alpha_7                               0.37039     0.00032    0.37089    0.36990
alpha_8                               0.36097     0.00031    0.36146    0.36048
alpha_9                               0.36109     0.00032    0.36159    0.36059
Alpha_loss                            -6.02003    0.01541    -5.98539   -6.04353
Training/policy_loss                  -73.32901   0.38576    -72.69728  -73.92770
Training/qf1_loss                     540.07393   136.54913  811.39050  310.26447
Training/qf2_loss                     533.30836   136.69518  803.48859  302.05209
Training/pf_norm                      0.21081     0.01949    0.24988    0.17679
Training/qf1_norm                     119.45816   67.74133   278.51486  49.61668
Training/qf2_norm                     126.61828   69.66919   287.20972  57.46616
log_std/mean                          -0.26803    0.00104    -0.26639   -0.26949
log_std/std                           0.12982     0.00020    0.13006    0.12942
log_std/max                           -0.12359    0.00081    -0.12230   -0.12502
log_std/min                           -0.63234    0.00735    -0.62230   -0.64691
log_probs/mean                        -1.95334    0.01764    -1.91435   -1.97462
log_probs/std                         1.38269     0.03323    1.43710    1.34394
log_probs/max                         3.56534     0.27965    4.08490    3.18304
log_probs/min                         -6.89442    0.95602    -5.74688   -8.63869
mean/mean                             -0.00167    0.00036    -0.00113   -0.00225
mean/std                              0.50863     0.00109    0.51009    0.50662
mean/max                              1.72130     0.00462    1.72760    1.71101
mean/min                              -1.52958    0.00479    -1.52150   -1.53952
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 4, 6, 9, 7, 1, 0, 8, 2, 3]
replay_buffer._size: [52200 52200 52200 52200 52200 52200 52200 52200 52200 52200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.14145803451538 0.001953601837158203
train_time 12.144594430923462
2023-09-06 14:31:10,969 MainThread INFO: EPOCH:346
2023-09-06 14:31:10,970 MainThread INFO: Time Consumed:12.173305749893188s
2023-09-06 14:31:10,970 MainThread INFO: Total Frames:520500s
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 347/400 [37:50<11:10, 12.65s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               897.60493
Train_Epoch_Reward                    7114.41840
Running_Training_Average_Rewards      745.87641
Explore_Time                          0.00367
Train___Time                          12.14459
Eval____Time                          0.01796
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.39344
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.59176
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -45.69115
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.56170
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.72279
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.16244
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.66790
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7912.38329
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.58446
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.24554
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.63968     0.49805    5.91232    4.02737
alpha_0                               0.41180     0.00028    0.41223    0.41137
alpha_1                               0.36068     0.00030    0.36114    0.36021
alpha_2                               0.36007     0.00031    0.36055    0.35959
alpha_3                               0.35709     0.00032    0.35759    0.35659
alpha_4                               0.35834     0.00030    0.35881    0.35787
alpha_5                               0.35821     0.00032    0.35872    0.35770
alpha_6                               0.35754     0.00031    0.35803    0.35705
alpha_7                               0.36929     0.00032    0.36979    0.36879
alpha_8                               0.35987     0.00031    0.36037    0.35938
alpha_9                               0.35998     0.00032    0.36048    0.35948
Alpha_loss                            -6.01904    0.02392    -5.99149   -6.07899
Training/policy_loss                  -73.92486   0.31762    -73.53522  -74.39637
Training/qf1_loss                     511.50837   162.36920  933.81329  347.07666
Training/qf2_loss                     505.19960   162.56662  927.56311  339.69659
Training/pf_norm                      0.20284     0.03254    0.26239    0.15911
Training/qf1_norm                     164.38998   146.79583  587.39191  37.66038
Training/qf2_norm                     164.77882   144.84185  582.96924  44.55562
log_std/mean                          -0.27107    0.00084    -0.26992   -0.27254
log_std/std                           0.13119     0.00050    0.13208    0.13054
log_std/max                           -0.12408    0.00101    -0.12277   -0.12605
log_std/min                           -0.64367    0.00889    -0.62804   -0.65776
log_probs/mean                        -1.93477    0.02339    -1.90938   -1.99416
log_probs/std                         1.37875     0.03471    1.42572    1.32167
log_probs/max                         3.63383     0.24453    3.99278    3.16024
log_probs/min                         -6.45741    0.84671    -5.34651   -8.37944
mean/mean                             -0.00304    0.00060    -0.00221   -0.00375
mean/std                              0.51507     0.00252    0.51975    0.51170
mean/max                              1.72326     0.00506    1.73307    1.71644
mean/min                              -1.56240    0.01425    -1.54300   -1.58871
------------------------------------  ----------  ---------  ---------  ---------
sample: [5, 6, 1, 2, 9, 0, 3, 7, 4, 8]
replay_buffer._size: [52350 52350 52350 52350 52350 52350 52350 52350 52350 52350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.902294397354126 0.0026543140411376953
train_time 11.906578779220581
2023-09-06 14:31:23,005 MainThread INFO: EPOCH:347
2023-09-06 14:31:23,006 MainThread INFO: Time Consumed:11.918051481246948s
2023-09-06 14:31:23,006 MainThread INFO: Total Frames:522000s
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 348/400 [38:02<10:48, 12.47s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               801.30583
Train_Epoch_Reward                    11301.30269
Running_Training_Average_Rewards      869.29455
Explore_Time                          0.00459
Train___Time                          11.90658
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.02367
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.88251
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -46.28139
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.01000
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.47830
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.82136
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.68982
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7637.65456
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.98832
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.02004
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.82653      0.69996    5.86231     3.80678
alpha_0                               0.41085      0.00027    0.41127     0.41043
alpha_1                               0.35964      0.00030    0.36011     0.35918
alpha_2                               0.35900      0.00031    0.35948     0.35852
alpha_3                               0.35599      0.00032    0.35648     0.35549
alpha_4                               0.35730      0.00030    0.35777     0.35683
alpha_5                               0.35709      0.00032    0.35759     0.35659
alpha_6                               0.35646      0.00031    0.35694     0.35598
alpha_7                               0.36819      0.00032    0.36868     0.36769
alpha_8                               0.35879      0.00031    0.35927     0.35830
alpha_9                               0.35888      0.00032    0.35937     0.35838
Alpha_loss                            -6.00180     0.02001    -5.96440    -6.02716
Training/policy_loss                  -74.11298    0.37414    -73.45802   -74.84270
Training/qf1_loss                     663.35287    351.98761  1362.56177  325.64496
Training/qf2_loss                     656.54261    351.43345  1354.82141  322.35803
Training/pf_norm                      0.23055      0.03379    0.27490     0.15738
Training/qf1_norm                     236.00442    189.54035  542.98407   63.50653
Training/qf2_norm                     237.32168    188.28585  538.06409   62.07900
log_std/mean                          -0.27549     0.00150    -0.27312    -0.27764
log_std/std                           0.13339      0.00069    0.13431     0.13234
log_std/max                           -0.12518     0.00099    -0.12339    -0.12660
log_std/min                           -0.66533     0.00633    -0.65155    -0.67279
log_probs/mean                        -1.89860     0.02358    -1.85384    -1.92919
log_probs/std                         1.42181      0.04029    1.48596     1.35827
log_probs/max                         3.97899      0.21152    4.19473     3.58217
log_probs/min                         -7.11281     0.57894    -6.16307    -7.96805
mean/mean                             -0.00210     0.00130    0.00042     -0.00372
mean/std                              0.52666      0.00400    0.53224     0.52048
mean/max                              1.74293      0.00755    1.75373     1.72723
mean/min                              -1.62333     0.01826    -1.59023    -1.64786
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 4, 0, 1, 7, 9, 5, 3, 8, 6]
replay_buffer._size: [52500 52500 52500 52500 52500 52500 52500 52500 52500 52500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.488409519195557 0.002707958221435547
train_time 8.492807865142822
2023-09-06 14:31:35,297 MainThread INFO: EPOCH:348
2023-09-06 14:31:35,297 MainThread INFO: Time Consumed:12.150992631912231s
2023-09-06 14:31:35,297 MainThread INFO: Total Frames:523500s
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 349/400 [38:14<10:33, 12.41s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               715.06469
Train_Epoch_Reward                    8084.98461
Running_Training_Average_Rewards      883.35686
Explore_Time                          3.65180
Train___Time                          8.49281
Eval____Time                          0.00226
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.80020
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.93529
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.56886
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.94829
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.79873
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.54527
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.90584
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7407.06201
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.43571
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.40454
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.09559     0.55051    5.29772     3.26078
alpha_0                               0.40994     0.00025    0.41034     0.40955
alpha_1                               0.35862     0.00029    0.35908     0.35817
alpha_2                               0.35793     0.00031    0.35841     0.35745
alpha_3                               0.35488     0.00032    0.35538     0.35439
alpha_4                               0.35625     0.00030    0.35672     0.35578
alpha_5                               0.35598     0.00032    0.35647     0.35548
alpha_6                               0.35539     0.00031    0.35587     0.35491
alpha_7                               0.36708     0.00032    0.36758     0.36658
alpha_8                               0.35771     0.00031    0.35819     0.35723
alpha_9                               0.35778     0.00031    0.35827     0.35729
Alpha_loss                            -5.98386    0.02594    -5.93291    -6.01940
Training/policy_loss                  -74.21887   0.37953    -73.79065   -75.15457
Training/qf1_loss                     472.31396   203.05130  1017.00897  263.90372
Training/qf2_loss                     465.56873   203.16543  1010.56427  257.17963
Training/pf_norm                      0.18729     0.02343    0.24299     0.16136
Training/qf1_norm                     194.77790   133.40439  409.09790   39.47039
Training/qf2_norm                     186.87143   127.86024  386.12509   42.38509
log_std/mean                          -0.27929    0.00077    -0.27799    -0.28018
log_std/std                           0.13466     0.00027    0.13524     0.13419
log_std/max                           -0.12581    0.00153    -0.12360    -0.12900
log_std/min                           -0.67258    0.00747    -0.66226    -0.68911
log_probs/mean                        -1.86091    0.02604    -1.80478    -1.88553
log_probs/std                         1.47509     0.02690    1.52264     1.44235
log_probs/max                         4.30201     0.30140    4.74348     3.90220
log_probs/min                         -6.55664    0.82121    -5.71879    -8.71308
mean/mean                             0.00529     0.00293    0.00958     0.00109
mean/std                              0.53839     0.00290    0.54193     0.53403
mean/max                              1.77998     0.01148    1.79506     1.76202
mean/min                              -1.66653    0.00483    -1.65635    -1.67198
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 7, 6, 4, 8, 2, 3, 9, 1, 5]
replay_buffer._size: [52650 52650 52650 52650 52650 52650 52650 52650 52650 52650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.534584999084473 0.0020711421966552734
train_time 7.537935495376587
2023-09-06 14:31:47,289 MainThread INFO: EPOCH:349
2023-09-06 14:31:47,289 MainThread INFO: Time Consumed:11.86280369758606s
2023-09-06 14:31:47,290 MainThread INFO: Total Frames:525000s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 350/400 [38:26<10:14, 12.28s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               709.07238
Train_Epoch_Reward                    4451.83883
Running_Training_Average_Rewards      794.60420
Explore_Time                          4.30738
Train___Time                          7.53794
Eval____Time                          0.01273
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.95613
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.21245
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.49849
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.94714
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.99285
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.61177
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.16469
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7748.39797
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.48070
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.54075
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.84358     0.61459    6.16789    3.80012
alpha_0                               0.40907     0.00024    0.40946    0.40869
alpha_1                               0.35762     0.00029    0.35807    0.35716
alpha_2                               0.35687     0.00030    0.35735    0.35639
alpha_3                               0.35378     0.00032    0.35428    0.35329
alpha_4                               0.35521     0.00030    0.35568    0.35474
alpha_5                               0.35487     0.00032    0.35537    0.35437
alpha_6                               0.35432     0.00031    0.35480    0.35384
alpha_7                               0.36598     0.00031    0.36647    0.36549
alpha_8                               0.35664     0.00031    0.35712    0.35616
alpha_9                               0.35669     0.00031    0.35718    0.35619
Alpha_loss                            -5.99779    0.02633    -5.94849   -6.04637
Training/policy_loss                  -74.12778   0.25424    -73.60835  -74.49123
Training/qf1_loss                     535.12880   160.32048  927.95959  357.99518
Training/qf2_loss                     527.41544   159.10627  916.15759  352.71729
Training/pf_norm                      0.19993     0.03889    0.27927    0.13320
Training/qf1_norm                     278.71305   200.38607  760.07776  73.12765
Training/qf2_norm                     283.14902   198.64384  761.30591  77.84509
log_std/mean                          -0.27896    0.00120    -0.27696   -0.28021
log_std/std                           0.13377     0.00040    0.13446    0.13312
log_std/max                           -0.12901    0.00085    -0.12716   -0.13009
log_std/min                           -0.67225    0.00553    -0.66103   -0.67992
log_probs/mean                        -1.85801    0.02499    -1.80695   -1.89864
log_probs/std                         1.49210     0.02974    1.55062    1.43708
log_probs/max                         4.31713     0.12423    4.53452    4.15319
log_probs/min                         -7.02468    1.20619    -5.75875   -10.03135
mean/mean                             0.01227     0.00094    0.01355    0.01042
mean/std                              0.54271     0.00050    0.54352    0.54171
mean/max                              1.80008     0.00596    1.80754    1.79082
mean/min                              -1.65759    0.00777    -1.64435   -1.66869
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 3, 1, 2, 9, 7, 8, 4, 5, 0]
replay_buffer._size: [52800 52800 52800 52800 52800 52800 52800 52800 52800 52800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 16.038126707077026 0.002105236053466797
train_time 16.041611909866333
2023-09-06 14:32:03,461 MainThread INFO: EPOCH:350
2023-09-06 14:32:03,461 MainThread INFO: Time Consumed:16.056728839874268s
2023-09-06 14:32:03,462 MainThread INFO: Total Frames:526500s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 351/400 [38:43<10:59, 13.46s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               722.56059
Train_Epoch_Reward                    7947.18571
Running_Training_Average_Rewards      682.80031
Explore_Time                          0.00570
Train___Time                          16.04161
Eval____Time                          0.00349
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.04044
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.07019
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.78847
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.77612
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.90532
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.63513
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.69449
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8062.53262
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.55746
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.95956
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.45257     0.57899    5.31717    3.73202
alpha_0                               0.40822     0.00025    0.40861    0.40783
alpha_1                               0.35662     0.00028    0.35706    0.35617
alpha_2                               0.35581     0.00030    0.35629    0.35533
alpha_3                               0.35269     0.00031    0.35318    0.35219
alpha_4                               0.35417     0.00030    0.35464    0.35371
alpha_5                               0.35377     0.00032    0.35426    0.35327
alpha_6                               0.35326     0.00031    0.35373    0.35278
alpha_7                               0.36489     0.00031    0.36538    0.36440
alpha_8                               0.35558     0.00030    0.35606    0.35510
alpha_9                               0.35559     0.00031    0.35609    0.35510
Alpha_loss                            -6.01497    0.01724    -5.98959   -6.04145
Training/policy_loss                  -74.60521   0.23317    -74.27728  -75.05692
Training/qf1_loss                     551.12470   225.17753  936.48340  255.88997
Training/qf2_loss                     543.96169   224.46856  929.16193  250.57291
Training/pf_norm                      0.20428     0.04416    0.27931    0.13947
Training/qf1_norm                     207.13595   120.63676  446.26883  42.72688
Training/qf2_norm                     207.48204   120.70490  440.59787  40.23378
log_std/mean                          -0.27450    0.00125    -0.27281   -0.27652
log_std/std                           0.13295     0.00019    0.13329    0.13255
log_std/max                           -0.12619    0.00177    -0.12383   -0.12863
log_std/min                           -0.67729    0.00727    -0.66689   -0.68884
log_probs/mean                        -1.85884    0.01418    -1.84010   -1.88338
log_probs/std                         1.47458     0.03354    1.53944    1.42016
log_probs/max                         4.22756     0.22847    4.59287    3.78611
log_probs/min                         -6.90945    1.02470    -5.64117   -9.42809
mean/mean                             0.00656     0.00298    0.01110    0.00189
mean/std                              0.53937     0.00157    0.54157    0.53692
mean/max                              1.76353     0.01692    1.78977    1.73852
mean/min                              -1.63810    0.00334    -1.63296   -1.64407
------------------------------------  ----------  ---------  ---------  ---------
sample: [1, 9, 5, 6, 2, 7, 0, 4, 8, 3]
replay_buffer._size: [52950 52950 52950 52950 52950 52950 52950 52950 52950 52950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.991334915161133 0.0019805431365966797
train_time 11.994548797607422
2023-09-06 14:32:15,602 MainThread INFO: EPOCH:351
2023-09-06 14:32:15,603 MainThread INFO: Time Consumed:12.009191751480103s
2023-09-06 14:32:15,603 MainThread INFO: Total Frames:528000s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 352/400 [38:55<10:26, 13.05s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               749.10330
Train_Epoch_Reward                    7442.91561
Running_Training_Average_Rewards      661.39801
Explore_Time                          0.00737
Train___Time                          11.99455
Eval____Time                          0.00223
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.79676
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.25339
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.53127
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.43282
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.45803
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.35280
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.51568
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8211.87279
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.36026
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.17133
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.69391     0.39798    5.27752     3.99307
alpha_0                               0.40736     0.00025    0.40775     0.40697
alpha_1                               0.35563     0.00029    0.35607     0.35518
alpha_2                               0.35475     0.00030    0.35523     0.35427
alpha_3                               0.35159     0.00031    0.35208     0.35110
alpha_4                               0.35315     0.00030    0.35361     0.35268
alpha_5                               0.35267     0.00032    0.35316     0.35218
alpha_6                               0.35219     0.00031    0.35267     0.35171
alpha_7                               0.36380     0.00031    0.36429     0.36331
alpha_8                               0.35452     0.00030    0.35500     0.35405
alpha_9                               0.35450     0.00031    0.35499     0.35401
Alpha_loss                            -6.04732    0.02878    -6.00075    -6.11013
Training/policy_loss                  -74.59510   0.29313    -74.01003   -74.95487
Training/qf1_loss                     647.37458   265.84266  1231.11255  422.02017
Training/qf2_loss                     639.76603   264.87321  1221.63672  414.49130
Training/pf_norm                      0.20930     0.03673    0.27075     0.15993
Training/qf1_norm                     213.93395   116.60623  375.05859   63.36119
Training/qf2_norm                     219.11260   115.36000  381.51541   62.78686
log_std/mean                          -0.27293    0.00023    -0.27257    -0.27342
log_std/std                           0.13294     0.00025    0.13336     0.13253
log_std/max                           -0.12318    0.00024    -0.12268    -0.12344
log_std/min                           -0.67768    0.00673    -0.66653    -0.68860
log_probs/mean                        -1.87234    0.03121    -1.82516    -1.94102
log_probs/std                         1.48303     0.03220    1.53924     1.44252
log_probs/max                         4.17846     0.12744    4.41101     4.00720
log_probs/min                         -7.30142    0.97845    -6.30501    -9.52692
mean/mean                             -0.00013    0.00065    0.00122     -0.00065
mean/std                              0.53690     0.00057    0.53778     0.53580
mean/max                              1.70794     0.01523    1.73523     1.68769
mean/min                              -1.63982    0.00191    -1.63667    -1.64292
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 9, 4, 5, 7, 8, 1, 3, 6]
replay_buffer._size: [53100 53100 53100 53100 53100 53100 53100 53100 53100 53100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.281751155853271 0.002095937728881836
train_time 12.285090684890747
2023-09-06 14:32:28,024 MainThread INFO: EPOCH:352
2023-09-06 14:32:28,025 MainThread INFO: Time Consumed:12.304423570632935s
2023-09-06 14:32:28,025 MainThread INFO: Total Frames:529500s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 353/400 [39:07<10:04, 12.86s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               771.21534
Train_Epoch_Reward                    6384.05518
Running_Training_Average_Rewards      725.80522
Explore_Time                          0.00371
Train___Time                          12.28509
Eval____Time                          0.00983
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.58894
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.31880
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.36588
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.57323
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.78841
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.05632
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.31233
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8409.57803
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.92473
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.29498
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.84952     0.44414    5.69041    4.07967
alpha_0                               0.40649     0.00025    0.40689    0.40610
alpha_1                               0.35464     0.00028    0.35508    0.35419
alpha_2                               0.35369     0.00030    0.35417    0.35322
alpha_3                               0.35050     0.00031    0.35099    0.35001
alpha_4                               0.35212     0.00029    0.35258    0.35166
alpha_5                               0.35157     0.00031    0.35207    0.35108
alpha_6                               0.35113     0.00030    0.35160    0.35065
alpha_7                               0.36272     0.00031    0.36321    0.36223
alpha_8                               0.35347     0.00030    0.35394    0.35300
alpha_9                               0.35341     0.00031    0.35390    0.35292
Alpha_loss                            -6.06062    0.02455    -6.02830   -6.12013
Training/policy_loss                  -75.29283   0.29153    -74.97092  -75.92991
Training/qf1_loss                     698.83339   141.51741  928.59747  443.48227
Training/qf2_loss                     691.37192   141.15901  919.10516  436.36261
Training/pf_norm                      0.28742     0.03705    0.35226    0.23457
Training/qf1_norm                     225.02377   115.20800  469.93591  93.83705
Training/qf2_norm                     234.60821   113.06678  473.38690  112.37065
log_std/mean                          -0.27489    0.00152    -0.27312   -0.27740
log_std/std                           0.13315     0.00038    0.13389    0.13260
log_std/max                           -0.12295    0.00080    -0.12212   -0.12470
log_std/min                           -0.67304    0.00821    -0.66073   -0.68275
log_probs/mean                        -1.87027    0.02458    -1.84092   -1.92303
log_probs/std                         1.47974     0.02891    1.51301    1.41969
log_probs/max                         4.17909     0.21368    4.45616    3.79292
log_probs/min                         -6.95437    0.98865    -5.57600   -8.95929
mean/mean                             0.00832     0.00535    0.01775    0.00169
mean/std                              0.54104     0.00264    0.54576    0.53829
mean/max                              1.68974     0.00598    1.70427    1.68309
mean/min                              -1.64927    0.00558    -1.64259   -1.66083
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 6, 3, 1, 5, 4, 7, 0, 8, 2]
replay_buffer._size: [53250 53250 53250 53250 53250 53250 53250 53250 53250 53250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.720546245574951 0.0020477771759033203
train_time 11.7238187789917
2023-09-06 14:32:39,866 MainThread INFO: EPOCH:353
2023-09-06 14:32:39,866 MainThread INFO: Time Consumed:11.735202074050903s
2023-09-06 14:32:39,867 MainThread INFO: Total Frames:531000s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 354/400 [39:19<09:37, 12.56s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               802.47800
Train_Epoch_Reward                    4692.55631
Running_Training_Average_Rewards      617.31757
Explore_Time                          0.00311
Train___Time                          11.72382
Eval____Time                          0.00220
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.35854
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.37656
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.75319
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.36143
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.16758
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.61193
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.36919
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8983.83341
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.29739
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.55235
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.45067     0.53593    5.15855    3.69181
alpha_0                               0.40563     0.00024    0.40601    0.40526
alpha_1                               0.35365     0.00028    0.35409    0.35321
alpha_2                               0.35264     0.00030    0.35311    0.35216
alpha_3                               0.34942     0.00031    0.34991    0.34893
alpha_4                               0.35110     0.00029    0.35156    0.35064
alpha_5                               0.35048     0.00031    0.35097    0.34999
alpha_6                               0.35007     0.00030    0.35054    0.34959
alpha_7                               0.36164     0.00031    0.36213    0.36116
alpha_8                               0.35243     0.00030    0.35290    0.35196
alpha_9                               0.35232     0.00031    0.35281    0.35184
Alpha_loss                            -6.02306    0.01876    -5.99333   -6.04651
Training/policy_loss                  -75.62481   0.35220    -75.03194  -76.15524
Training/qf1_loss                     464.68284   169.83488  805.27118  257.06421
Training/qf2_loss                     457.89625   169.51030  798.28192  251.87912
Training/pf_norm                      0.25428     0.04011    0.31817    0.18991
Training/qf1_norm                     200.15217   107.58335  381.88861  51.20731
Training/qf2_norm                     198.70445   101.06658  356.51047  39.76338
log_std/mean                          -0.28139    0.00190    -0.27793   -0.28400
log_std/std                           0.13597     0.00107    0.13759    0.13411
log_std/max                           -0.12811    0.00183    -0.12562   -0.13129
log_std/min                           -0.68417    0.00888    -0.66725   -0.70031
log_probs/mean                        -1.81172    0.02316    -1.77766   -1.84221
log_probs/std                         1.56571     0.04378    1.66512    1.51939
log_probs/max                         4.60413     0.37824    5.14849    3.95212
log_probs/min                         -6.98290    0.89310    -5.82428   -8.56366
mean/mean                             0.03235     0.00766    0.04353    0.02006
mean/std                              0.55405     0.00440    0.56025    0.54649
mean/max                              1.72392     0.01139    1.73755    1.70060
mean/min                              -1.67724    0.00805    -1.66407   -1.68821
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 2, 3, 7, 4, 8, 0, 9, 1, 5]
replay_buffer._size: [53400 53400 53400 53400 53400 53400 53400 53400 53400 53400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.618416786193848 0.0019631385803222656
train_time 11.621582269668579
2023-09-06 14:32:51,603 MainThread INFO: EPOCH:354
2023-09-06 14:32:51,603 MainThread INFO: Time Consumed:11.632191181182861s
2023-09-06 14:32:51,604 MainThread INFO: Total Frames:532500s
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 355/400 [39:31<09:14, 12.31s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               855.74264
Train_Epoch_Reward                    6614.51314
Running_Training_Average_Rewards      589.70415
Explore_Time                          0.00255
Train___Time                          11.62158
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.63450
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.25794
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.33439
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.66729
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.69923
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.60969
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.85095
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9804.73542
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.80048
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.94144
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.10557     0.56253    5.11856    3.40195
alpha_0                               0.40484     0.00022    0.40519    0.40450
alpha_1                               0.35268     0.00027    0.35311    0.35225
alpha_2                               0.35159     0.00030    0.35206    0.35112
alpha_3                               0.34833     0.00031    0.34882    0.34784
alpha_4                               0.35009     0.00029    0.35054    0.34963
alpha_5                               0.34940     0.00031    0.34989    0.34891
alpha_6                               0.34901     0.00030    0.34949    0.34853
alpha_7                               0.36057     0.00031    0.36105    0.36009
alpha_8                               0.35139     0.00030    0.35186    0.35093
alpha_9                               0.35124     0.00031    0.35173    0.35075
Alpha_loss                            -5.98754    0.04216    -5.91380   -6.05631
Training/policy_loss                  -75.33405   0.33004    -74.84716  -76.10502
Training/qf1_loss                     545.77499   212.42873  948.59045  228.37996
Training/qf2_loss                     538.96657   212.28375  940.48572  221.94168
Training/pf_norm                      0.20309     0.04033    0.28739    0.16164
Training/qf1_norm                     213.29134   117.94314  392.44315  30.46522
Training/qf2_norm                     206.34257   111.80856  372.12033  34.53602
log_std/mean                          -0.28385    0.00052    -0.28277   -0.28454
log_std/std                           0.13834     0.00030    0.13880    0.13773
log_std/max                           -0.12583    0.00223    -0.12177   -0.12929
log_std/min                           -0.69529    0.00794    -0.68252   -0.70911
log_probs/mean                        -1.75927    0.04156    -1.69333   -1.82967
log_probs/std                         1.61750     0.02092    1.64685    1.57388
log_probs/max                         5.10460     0.18506    5.46854    4.83100
log_probs/min                         -7.00792    0.56057    -6.12713   -7.69235
mean/mean                             0.05350     0.00379    0.05806    0.04665
mean/std                              0.56562     0.00214    0.56801    0.56190
mean/max                              1.75087     0.00575    1.76040    1.73903
mean/min                              -1.68694    0.00288    -1.68173   -1.69004
------------------------------------  ----------  ---------  ---------  ---------
sample: [9, 7, 3, 2, 5, 6, 1, 8, 0, 4]
replay_buffer._size: [53550 53550 53550 53550 53550 53550 53550 53550 53550 53550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.382734060287476 0.002118349075317383
train_time 6.386137008666992
2023-09-06 14:33:03,216 MainThread INFO: EPOCH:355
2023-09-06 14:33:03,217 MainThread INFO: Time Consumed:11.507163524627686s
2023-09-06 14:33:03,217 MainThread INFO: Total Frames:534000s
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 356/400 [39:42<08:52, 12.10s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               946.97779
Train_Epoch_Reward                    7321.91067
Running_Training_Average_Rewards      620.96600
Explore_Time                          5.07997
Train___Time                          6.38614
Eval____Time                          0.00868
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.51840
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.87124
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.43629
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.04794
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.32900
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.31939
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.55479
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10575.82724
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.87047
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           530.52920
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.58100      0.46893    5.31994    3.73494
alpha_0                               0.40410      0.00021    0.40443    0.40378
alpha_1                               0.35173      0.00027    0.35215    0.35130
alpha_2                               0.35054      0.00030    0.35101    0.35007
alpha_3                               0.34725      0.00031    0.34774    0.34676
alpha_4                               0.34908      0.00029    0.34953    0.34864
alpha_5                               0.34832      0.00031    0.34881    0.34784
alpha_6                               0.34796      0.00030    0.34843    0.34748
alpha_7                               0.35950      0.00031    0.35998    0.35902
alpha_8                               0.35037      0.00029    0.35083    0.34991
alpha_9                               0.35015      0.00031    0.35064    0.34967
Alpha_loss                            -6.01074     0.03003    -5.97468   -6.07290
Training/policy_loss                  -75.60581    0.46168    -74.93213  -76.31622
Training/qf1_loss                     550.39184    181.32251  800.75574  325.12311
Training/qf2_loss                     543.09152    180.86871  793.32068  317.64886
Training/pf_norm                      0.27871      0.03295    0.33782    0.22988
Training/qf1_norm                     222.65625    108.92327  440.37463  58.38661
Training/qf2_norm                     222.21603    109.26225  438.93097  64.25700
log_std/mean                          -0.27866     0.00213    -0.27544   -0.28193
log_std/std                           0.13720      0.00073    0.13821    0.13601
log_std/max                           -0.12318     0.00305    -0.11881   -0.12759
log_std/min                           -0.68639     0.00612    -0.67679   -0.69384
log_probs/mean                        -1.76456     0.02648    -1.73672   -1.82196
log_probs/std                         1.63536      0.02879    1.68447    1.59056
log_probs/max                         5.10254      0.27844    5.59535    4.50152
log_probs/min                         -7.39760     0.82285    -6.36505   -8.89628
mean/mean                             0.05308      0.00392    0.05750    0.04579
mean/std                              0.56238      0.00369    0.56686    0.55562
mean/max                              1.72795      0.01760    1.75113    1.69483
mean/min                              -1.65300     0.01734    -1.62276   -1.67582
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 8, 2, 0, 3, 7, 5, 4, 9, 1]
replay_buffer._size: [53700 53700 53700 53700 53700 53700 53700 53700 53700 53700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.481598854064941 0.0019927024841308594
train_time 11.48481035232544
2023-09-06 14:33:14,819 MainThread INFO: EPOCH:356
2023-09-06 14:33:14,820 MainThread INFO: Time Consumed:11.494228601455688s
2023-09-06 14:33:14,820 MainThread INFO: Total Frames:535500s
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 357/400 [39:54<08:33, 11.95s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1030.12918
Train_Epoch_Reward                    11835.32523
Running_Training_Average_Rewards      859.05830
Explore_Time                          0.00267
Train___Time                          11.48481
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.03145
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.67702
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.26889
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.89129
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.22298
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.53406
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.64063
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10711.60795
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.74708
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           749.93256
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.87786      0.74714    6.18330     3.73359
alpha_0                               0.40337      0.00022    0.40371     0.40303
alpha_1                               0.35077      0.00028    0.35121     0.35033
alpha_2                               0.34950      0.00030    0.34997     0.34903
alpha_3                               0.34617      0.00031    0.34666     0.34569
alpha_4                               0.34809      0.00029    0.34854     0.34764
alpha_5                               0.34725      0.00031    0.34773     0.34677
alpha_6                               0.34691      0.00030    0.34738     0.34643
alpha_7                               0.35844      0.00030    0.35892     0.35796
alpha_8                               0.34934      0.00030    0.34980     0.34887
alpha_9                               0.34907      0.00031    0.34956     0.34859
Alpha_loss                            -6.09766     0.03273    -6.05700    -6.15426
Training/policy_loss                  -75.90139    0.34033    -75.33238   -76.45779
Training/qf1_loss                     707.70270    364.08849  1534.10291  312.32169
Training/qf2_loss                     699.88081    362.78071  1523.54663  304.93161
Training/pf_norm                      0.25835      0.02751    0.30480     0.19969
Training/qf1_norm                     311.45665    226.87675  756.96600   55.55408
Training/qf2_norm                     312.01112    227.13978  760.06885   53.38694
log_std/mean                          -0.27215     0.00141    -0.27037    -0.27451
log_std/std                           0.13514      0.00032    0.13585     0.13464
log_std/max                           -0.11544     0.00158    -0.11338    -0.11938
log_std/min                           -0.68434     0.00343    -0.67807    -0.68935
log_probs/mean                        -1.83609     0.03125    -1.79505    -1.89188
log_probs/std                         1.52637      0.03888    1.57787     1.43714
log_probs/max                         4.64165      0.19935    4.90022     4.22130
log_probs/min                         -6.49596     0.61558    -5.79854    -7.80307
mean/mean                             0.03363      0.00670    0.04418     0.02293
mean/std                              0.54744      0.00368    0.55344     0.54160
mean/max                              1.65673      0.02097    1.69790     1.62836
mean/min                              -1.59108     0.01488    -1.57431    -1.61689
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 8, 1, 9, 2, 5, 7, 3, 6, 0]
replay_buffer._size: [53850 53850 53850 53850 53850 53850 53850 53850 53850 53850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.754791021347046 0.002124786376953125
train_time 11.758125066757202
2023-09-06 14:33:26,692 MainThread INFO: EPOCH:357
2023-09-06 14:33:26,692 MainThread INFO: Time Consumed:11.769586086273193s
2023-09-06 14:33:26,693 MainThread INFO: Total Frames:537000s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 358/400 [40:06<08:21, 11.93s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1082.08930
Train_Epoch_Reward                    8959.37500
Running_Training_Average_Rewards      937.22036
Explore_Time                          0.00521
Train___Time                          11.75813
Eval____Time                          0.00220
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.80828
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.15545
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.83216
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.90950
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.93871
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.73621
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.42401
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10729.63460
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.21525
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           606.12790
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.66870      0.71252    5.62126     3.61379
alpha_0                               0.40258      0.00024    0.40295     0.40220
alpha_1                               0.34980      0.00028    0.35024     0.34935
alpha_2                               0.34846      0.00030    0.34893     0.34799
alpha_3                               0.34510      0.00031    0.34558     0.34462
alpha_4                               0.34709      0.00029    0.34754     0.34665
alpha_5                               0.34619      0.00031    0.34667     0.34571
alpha_6                               0.34586      0.00030    0.34633     0.34539
alpha_7                               0.35739      0.00030    0.35786     0.35692
alpha_8                               0.34830      0.00030    0.34877     0.34784
alpha_9                               0.34800      0.00031    0.34848     0.34752
Alpha_loss                            -6.13804     0.04306    -6.08119    -6.23103
Training/policy_loss                  -76.16846    0.33323    -75.62993   -76.68474
Training/qf1_loss                     551.10116    218.04325  1005.43030  243.80029
Training/qf2_loss                     544.29363    217.37224  996.11249   237.18875
Training/pf_norm                      0.23061      0.01831    0.25779     0.19639
Training/qf1_norm                     288.78780    135.32991  502.72339   79.01162
Training/qf2_norm                     287.34737    135.52680  497.96472   88.36944
log_std/mean                          -0.27100     0.00042    -0.27036    -0.27183
log_std/std                           0.13611      0.00060    0.13718     0.13540
log_std/max                           -0.11628     0.00109    -0.11369    -0.11795
log_std/min                           -0.68264     0.00677    -0.67393    -0.69747
log_probs/mean                        -1.86232     0.03990    -1.81402    -1.94781
log_probs/std                         1.46981      0.04278    1.53442     1.37495
log_probs/max                         4.26243      0.17874    4.52324     4.02757
log_probs/min                         -6.66788     0.60370    -5.52417    -7.75707
mean/mean                             0.01107      0.00578    0.02102     0.00245
mean/std                              0.53874      0.00154    0.54215     0.53699
mean/max                              1.60804      0.01366    1.62740     1.58828
mean/min                              -1.57273     0.00139    -1.57076    -1.57522
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 6, 7, 4, 9, 3, 1, 8, 5, 2]
replay_buffer._size: [54000 54000 54000 54000 54000 54000 54000 54000 54000 54000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.362401723861694 0.0020143985748291016
train_time 12.365651607513428
2023-09-06 14:33:39,179 MainThread INFO: EPOCH:358
2023-09-06 14:33:39,179 MainThread INFO: Time Consumed:12.3780837059021s
2023-09-06 14:33:39,179 MainThread INFO: Total Frames:538500s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 359/400 [40:18<08:16, 12.10s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1083.80806
Train_Epoch_Reward                    8892.99604
Running_Training_Average_Rewards      989.58988
Explore_Time                          0.00280
Train___Time                          12.36565
Eval____Time                          0.00564
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.70485
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.41060
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.59307
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.58464
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.99737
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.43215
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.88638
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10775.56020
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.12320
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           394.14389
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.74622      0.91011    6.80916    3.13571
alpha_0                               0.40172      0.00025    0.40211    0.40132
alpha_1                               0.34880      0.00029    0.34925    0.34835
alpha_2                               0.34741      0.00030    0.34788    0.34694
alpha_3                               0.34403      0.00031    0.34451    0.34355
alpha_4                               0.34610      0.00028    0.34655    0.34566
alpha_5                               0.34512      0.00031    0.34560    0.34465
alpha_6                               0.34482      0.00030    0.34529    0.34436
alpha_7                               0.35636      0.00029    0.35682    0.35590
alpha_8                               0.34727      0.00030    0.34773    0.34680
alpha_9                               0.34693      0.00030    0.34741    0.34646
Alpha_loss                            -6.14620     0.02483    -6.11231   -6.18771
Training/policy_loss                  -76.25195    0.36728    -75.70233  -76.80685
Training/qf1_loss                     601.01160    208.21355  961.03809  236.00986
Training/qf2_loss                     594.06303    208.16547  954.86072  229.60909
Training/pf_norm                      0.19487      0.03293    0.26700    0.14724
Training/qf1_norm                     303.08340    252.36637  935.78088  38.71217
Training/qf2_norm                     307.08440    248.57363  933.34888  49.72314
log_std/mean                          -0.27386     0.00103    -0.27206   -0.27557
log_std/std                           0.13813      0.00052    0.13929    0.13734
log_std/max                           -0.11784     0.00179    -0.11393   -0.12051
log_std/min                           -0.68316     0.00740    -0.67096   -0.69668
log_probs/mean                        -1.85303     0.02118    -1.82135   -1.88919
log_probs/std                         1.46731      0.04242    1.53086    1.39288
log_probs/max                         4.08954      0.27564    4.61145    3.74908
log_probs/min                         -6.66588     0.42712    -6.13231   -7.38255
mean/mean                             -0.00195     0.00178    0.00121    -0.00413
mean/std                              0.53746      0.00107    0.54002    0.53641
mean/max                              1.58629      0.00180    1.58921    1.58350
mean/min                              -1.58331     0.00572    -1.57332   -1.59209
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 9, 1, 4, 6, 8, 2, 5, 7, 3]
replay_buffer._size: [54150 54150 54150 54150 54150 54150 54150 54150 54150 54150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.973008155822754 0.0026361942291259766
train_time 11.977309465408325
2023-09-06 14:33:51,291 MainThread INFO: EPOCH:359
2023-09-06 14:33:51,291 MainThread INFO: Time Consumed:11.989927530288696s
2023-09-06 14:33:51,291 MainThread INFO: Total Frames:540000s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 360/400 [40:30<08:03, 12.10s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1065.64416
Train_Epoch_Reward                    13570.36532
Running_Training_Average_Rewards      1047.42455
Explore_Time                          0.00264
Train___Time                          11.97731
Eval____Time                          0.00276
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.34252
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.44358
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.59288
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.51970
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.13301
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.13478
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.62414
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10692.24684
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.21330
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           217.36714
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           4.58171      0.44500   5.26096    3.84100
alpha_0                               0.40083      0.00025   0.40123    0.40044
alpha_1                               0.34780      0.00029   0.34825    0.34735
alpha_2                               0.34636      0.00030   0.34683    0.34589
alpha_3                               0.34297      0.00031   0.34344    0.34249
alpha_4                               0.34511      0.00028   0.34556    0.34467
alpha_5                               0.34406      0.00030   0.34454    0.34359
alpha_6                               0.34379      0.00029   0.34425    0.34333
alpha_7                               0.35534      0.00029   0.35580    0.35488
alpha_8                               0.34622      0.00030   0.34669    0.34575
alpha_9                               0.34588      0.00030   0.34635    0.34540
Alpha_loss                            -6.15838     0.03172   -6.09867   -6.22313
Training/policy_loss                  -76.71643    0.35620   -75.81947  -77.08937
Training/qf1_loss                     522.65494    98.81954  681.72607  405.46957
Training/qf2_loss                     516.00617    98.31192  675.84583  401.01285
Training/pf_norm                      0.21017      0.04420   0.31793    0.15038
Training/qf1_norm                     184.77946    91.13353  356.24768  60.63887
Training/qf2_norm                     188.48402    92.61286  356.88925  59.74640
log_std/mean                          -0.27676     0.00075   -0.27571   -0.27774
log_std/std                           0.13946      0.00040   0.14002    0.13875
log_std/max                           -0.11799     0.00186   -0.11462   -0.12031
log_std/min                           -0.68048     0.00658   -0.67296   -0.69329
log_probs/mean                        -1.84685     0.03396   -1.78556   -1.91865
log_probs/std                         1.49317      0.02941   1.52796    1.42671
log_probs/max                         4.29492      0.24761   4.66400    3.91551
log_probs/min                         -6.54202     0.64877   -5.27096   -7.54135
mean/mean                             -0.00214     0.00159   0.00091    -0.00403
mean/std                              0.54326      0.00235   0.54659    0.53936
mean/max                              1.60814      0.01310   1.62705    1.59116
mean/min                              -1.61020     0.01058   -1.59362   -1.62624
------------------------------------  -----------  --------  ---------  ---------
sample: [4, 5, 7, 2, 3, 8, 6, 9, 0, 1]
replay_buffer._size: [54300 54300 54300 54300 54300 54300 54300 54300 54300 54300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.66149616241455 0.0019583702087402344
train_time 12.664687871932983
2023-09-06 14:34:04,088 MainThread INFO: EPOCH:360
2023-09-06 14:34:04,089 MainThread INFO: Time Consumed:12.688499689102173s
2023-09-06 14:34:04,089 MainThread INFO: Total Frames:541500s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 361/400 [40:43<08:00, 12.31s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1051.03946
Train_Epoch_Reward                    14463.74778
Running_Training_Average_Rewards      1230.90364
Explore_Time                          0.00822
Train___Time                          12.66469
Eval____Time                          0.00820
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.15797
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.62969
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -48.62934
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.39906
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.65128
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.06590
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.05039
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10602.23956
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.80329
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           303.74916
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.70259      0.98632    6.54214     3.17563
alpha_0                               0.39997      0.00024    0.40035     0.39960
alpha_1                               0.34679      0.00029    0.34724     0.34634
alpha_2                               0.34532      0.00030    0.34579     0.34485
alpha_3                               0.34190      0.00030    0.34238     0.34143
alpha_4                               0.34413      0.00028    0.34457     0.34369
alpha_5                               0.34301      0.00030    0.34348     0.34254
alpha_6                               0.34277      0.00029    0.34323     0.34231
alpha_7                               0.35432      0.00030    0.35478     0.35385
alpha_8                               0.34518      0.00030    0.34565     0.34471
alpha_9                               0.34483      0.00030    0.34530     0.34436
Alpha_loss                            -6.14145     0.02086    -6.11277    -6.17484
Training/policy_loss                  -76.89940    0.27299    -76.60777   -77.52592
Training/qf1_loss                     621.81816    231.67970  1011.45294  252.05698
Training/qf2_loss                     614.25706    230.62567  1002.96161  247.92065
Training/pf_norm                      0.20458      0.02966    0.24948     0.15901
Training/qf1_norm                     357.20406    180.03566  848.67310   163.71860
Training/qf2_norm                     357.92941    175.90244  844.92352   186.52756
log_std/mean                          -0.27850     0.00059    -0.27794    -0.27986
log_std/std                           0.14033      0.00014    0.14063     0.14009
log_std/max                           -0.11606     0.00212    -0.11347    -0.12043
log_std/min                           -0.68555     0.00725    -0.67513    -0.69709
log_probs/mean                        -1.81312     0.01929    -1.78730    -1.84228
log_probs/std                         1.53003      0.02873    1.57095     1.47150
log_probs/max                         4.68760      0.19624    4.98439     4.41144
log_probs/min                         -6.99275     1.13348    -5.70169    -9.96927
mean/mean                             0.00482      0.00226    0.00839     0.00138
mean/std                              0.55055      0.00211    0.55445     0.54762
mean/max                              1.65168      0.01134    1.66758     1.63248
mean/min                              -1.65080     0.01417    -1.63053    -1.67468
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 8, 3, 0, 2, 1, 6, 5, 4, 9]
replay_buffer._size: [54450 54450 54450 54450 54450 54450 54450 54450 54450 54450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.151537895202637 0.002203702926635742
train_time 12.15554165840149
2023-09-06 14:34:16,382 MainThread INFO: EPOCH:361
2023-09-06 14:34:16,383 MainThread INFO: Time Consumed:12.175520181655884s
2023-09-06 14:34:16,383 MainThread INFO: Total Frames:543000s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 362/400 [40:56<07:47, 12.31s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1034.84926
Train_Epoch_Reward                    7995.97152
Running_Training_Average_Rewards      1201.00282
Explore_Time                          0.00407
Train___Time                          12.15554
Eval____Time                          0.01114
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.93179
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.66168
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -48.82634
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.55207
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.68472
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.11849
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.19879
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10414.73182
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.57628
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           271.08438
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.50388      0.58269    5.59197    3.38872
alpha_0                               0.39915      0.00023    0.39951    0.39879
alpha_1                               0.34580      0.00028    0.34624    0.34535
alpha_2                               0.34428      0.00030    0.34474    0.34381
alpha_3                               0.34085      0.00030    0.34132    0.34037
alpha_4                               0.34315      0.00028    0.34360    0.34271
alpha_5                               0.34196      0.00030    0.34243    0.34149
alpha_6                               0.34175      0.00029    0.34221    0.34130
alpha_7                               0.35329      0.00030    0.35375    0.35282
alpha_8                               0.34414      0.00030    0.34460    0.34367
alpha_9                               0.34379      0.00030    0.34426    0.34332
Alpha_loss                            -6.14212     0.03679    -6.07829   -6.19506
Training/policy_loss                  -77.04167    0.28094    -76.60403  -77.50230
Training/qf1_loss                     492.99095    141.44976  807.30560  313.43243
Training/qf2_loss                     486.12754    140.33704  797.06415  308.58856
Training/pf_norm                      0.19963      0.04022    0.28450    0.16021
Training/qf1_norm                     199.61121    149.29457  504.96362  51.35526
Training/qf2_norm                     200.05302    150.88131  508.58597  51.88171
log_std/mean                          -0.28291     0.00146    -0.28021   -0.28491
log_std/std                           0.14048      0.00013    0.14069    0.14030
log_std/max                           -0.11988     0.00164    -0.11680   -0.12368
log_std/min                           -0.69781     0.00650    -0.68760   -0.70836
log_probs/mean                        -1.79368     0.03739    -1.73118   -1.85308
log_probs/std                         1.59040      0.05244    1.67713    1.50198
log_probs/max                         4.92642      0.31336    5.45567    4.25625
log_probs/min                         -6.64100     0.51076    -5.74722   -7.29914
mean/mean                             0.01280      0.00198    0.01534    0.00985
mean/std                              0.55920      0.00204    0.56241    0.55550
mean/max                              1.69325      0.01042    1.70963    1.67433
mean/min                              -1.70610     0.01488    -1.67564   -1.72356
------------------------------------  -----------  ---------  ---------  ---------
sample: [1, 5, 2, 6, 9, 7, 3, 8, 0, 4]
replay_buffer._size: [54600 54600 54600 54600 54600 54600 54600 54600 54600 54600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.68274211883545 0.0021169185638427734
train_time 12.686267375946045
2023-09-06 14:34:29,205 MainThread INFO: EPOCH:362
2023-09-06 14:34:29,205 MainThread INFO: Time Consumed:12.695843935012817s
2023-09-06 14:34:29,205 MainThread INFO: Total Frames:544500s
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 363/400 [41:08<07:41, 12.47s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1032.77206
Train_Epoch_Reward                    7726.23320
Running_Training_Average_Rewards      1006.19842
Explore_Time                          0.00270
Train___Time                          12.68627
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.83297
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.81211
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.43951
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           429.38789
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.17035
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.02242
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.58106
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10017.90316
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.76535
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           399.62676
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.60133      0.81961    6.32178     3.23755
alpha_0                               0.39838      0.00021    0.39872     0.39805
alpha_1                               0.34481      0.00028    0.34525     0.34437
alpha_2                               0.34324      0.00030    0.34371     0.34278
alpha_3                               0.33980      0.00030    0.34027     0.33932
alpha_4                               0.34217      0.00028    0.34261     0.34173
alpha_5                               0.34092      0.00030    0.34138     0.34045
alpha_6                               0.34074      0.00029    0.34120     0.34028
alpha_7                               0.35225      0.00030    0.35272     0.35178
alpha_8                               0.34310      0.00030    0.34357     0.34264
alpha_9                               0.34275      0.00030    0.34322     0.34228
Alpha_loss                            -6.16338     0.03340    -6.12037    -6.22387
Training/policy_loss                  -77.17458    0.38560    -76.64246   -77.87721
Training/qf1_loss                     641.29976    367.14170  1439.20374  214.53706
Training/qf2_loss                     633.27957    365.00154  1425.97534  208.84758
Training/pf_norm                      0.18588      0.03473    0.22912     0.14178
Training/qf1_norm                     287.35459    211.76427  824.12439   70.62389
Training/qf2_norm                     288.03555    210.57513  821.33167   70.63320
log_std/mean                          -0.28506     0.00025    -0.28467    -0.28549
log_std/std                           0.13965      0.00046    0.14018     0.13890
log_std/max                           -0.12020     0.00132    -0.11846    -0.12241
log_std/min                           -0.70923     0.00512    -0.70080    -0.71946
log_probs/mean                        -1.79705     0.03053    -1.76016    -1.85098
log_probs/std                         1.60566      0.01590    1.63145     1.57137
log_probs/max                         5.02931      0.15445    5.30465     4.77073
log_probs/min                         -6.78256     0.63312    -5.67269    -7.99679
mean/mean                             0.01481      0.00061    0.01540     0.01393
mean/std                              0.56291      0.00086    0.56440     0.56188
mean/max                              1.69073      0.00686    1.69997     1.67903
mean/min                              -1.72631     0.00311    -1.72098    -1.73074
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 5, 8, 6, 9, 0, 7, 1, 3, 4]
replay_buffer._size: [54750 54750 54750 54750 54750 54750 54750 54750 54750 54750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.339932680130005 0.0024499893188476562
train_time 6.343858480453491
2023-09-06 14:34:41,559 MainThread INFO: EPOCH:363
2023-09-06 14:34:41,559 MainThread INFO: Time Consumed:6.356701374053955s
2023-09-06 14:34:41,560 MainThread INFO: Total Frames:546000s
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 364/400 [41:21<07:27, 12.42s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1013.53038
Train_Epoch_Reward                    10831.86892
Running_Training_Average_Rewards      885.13579
Explore_Time                          0.00377
Train___Time                          6.34386
Eval____Time                          0.00293
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.24965
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.24701
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.47003
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.52986
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.44625
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.13831
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.26906
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9798.61245
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.60254
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           529.69154
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.61699      0.66178    5.86546     3.70773
alpha_0                               0.39764      0.00021    0.39798     0.39731
alpha_1                               0.34383      0.00028    0.34427     0.34339
alpha_2                               0.34222      0.00029    0.34268     0.34176
alpha_3                               0.33875      0.00030    0.33922     0.33827
alpha_4                               0.34119      0.00028    0.34163     0.34075
alpha_5                               0.33987      0.00030    0.34034     0.33941
alpha_6                               0.33973      0.00029    0.34018     0.33927
alpha_7                               0.35121      0.00030    0.35168     0.35074
alpha_8                               0.34207      0.00029    0.34253     0.34161
alpha_9                               0.34171      0.00030    0.34218     0.34125
Alpha_loss                            -6.14789     0.03706    -6.08014    -6.21422
Training/policy_loss                  -77.43303    0.32108    -76.93123   -77.93677
Training/qf1_loss                     585.80922    230.87585  1028.31104  325.50482
Training/qf2_loss                     579.03876    230.20420  1020.00427  319.73535
Training/pf_norm                      0.20985      0.03585    0.27261     0.14693
Training/qf1_norm                     235.92318    194.73871  657.37787   47.03786
Training/qf2_norm                     234.54924    195.81283  659.95654   48.23090
log_std/mean                          -0.28624     0.00063    -0.28531    -0.28708
log_std/std                           0.13868      0.00023    0.13896     0.13824
log_std/max                           -0.12028     0.00178    -0.11787    -0.12414
log_std/min                           -0.71923     0.00793    -0.70281    -0.73230
log_probs/mean                        -1.76775     0.03900    -1.70082    -1.83744
log_probs/std                         1.59932      0.01910    1.62044     1.54725
log_probs/max                         4.99915      0.34973    5.62889     4.33613
log_probs/min                         -6.88778     0.89961    -5.93442    -9.01996
mean/mean                             0.01160      0.00083    0.01331     0.01028
mean/std                              0.56387      0.00083    0.56553     0.56275
mean/max                              1.65811      0.00789    1.67161     1.64495
mean/min                              -1.72476     0.00310    -1.71821    -1.72982
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 5, 2, 0, 9, 7, 3, 6, 8, 1]
replay_buffer._size: [54900 54900 54900 54900 54900 54900 54900 54900 54900 54900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.644976377487183 0.002045154571533203
train_time 12.648220300674438
2023-09-06 14:34:54,336 MainThread INFO: EPOCH:364
2023-09-06 14:34:54,336 MainThread INFO: Time Consumed:12.660029172897339s
2023-09-06 14:34:54,337 MainThread INFO: Total Frames:547500s
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 365/400 [41:33<07:18, 12.54s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1007.53489
Train_Epoch_Reward                    13328.87706
Running_Training_Average_Rewards      1062.89931
Explore_Time                          0.00353
Train___Time                          12.64822
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.14179
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.08946
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.02099
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.37422
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.18045
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.07382
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.23440
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10021.27079
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.57487
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           493.82064
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.84942      0.70771    6.04768     3.94933
alpha_0                               0.39691      0.00021    0.39724     0.39658
alpha_1                               0.34286      0.00028    0.34330     0.34243
alpha_2                               0.34120      0.00029    0.34166     0.34074
alpha_3                               0.33770      0.00030    0.33817     0.33723
alpha_4                               0.34022      0.00028    0.34065     0.33978
alpha_5                               0.33884      0.00030    0.33931     0.33838
alpha_6                               0.33872      0.00029    0.33917     0.33826
alpha_7                               0.35017      0.00030    0.35064     0.34970
alpha_8                               0.34106      0.00029    0.34151     0.34060
alpha_9                               0.34068      0.00029    0.34115     0.34022
Alpha_loss                            -6.16659     0.02796    -6.11407    -6.21250
Training/policy_loss                  -77.70293    0.40321    -77.17243   -78.31007
Training/qf1_loss                     694.76219    337.68485  1260.70923  316.38260
Training/qf2_loss                     686.05335    335.91694  1249.91858  308.66711
Training/pf_norm                      0.21493      0.02760    0.25697     0.15640
Training/qf1_norm                     276.46828    237.01246  709.27032   62.62304
Training/qf2_norm                     279.50966    239.41243  709.58289   56.64707
log_std/mean                          -0.28757     0.00058    -0.28692    -0.28879
log_std/std                           0.13736      0.00035    0.13803     0.13696
log_std/max                           -0.12072     0.00138    -0.11801    -0.12262
log_std/min                           -0.72683     0.00866    -0.71246    -0.74059
log_probs/mean                        -1.76855     0.02441    -1.72164    -1.81515
log_probs/std                         1.62031      0.03566    1.67894     1.55977
log_probs/max                         5.18544      0.23293    5.51249     4.75287
log_probs/min                         -7.41854     1.16172    -5.67636    -9.29437
mean/mean                             0.02006      0.00477    0.02809     0.01338
mean/std                              0.56607      0.00146    0.56912     0.56453
mean/max                              1.64453      0.00506    1.65064     1.63209
mean/min                              -1.71420     0.00618    -1.70606    -1.72310
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 4, 7, 1, 9, 3, 2, 8, 5, 0]
replay_buffer._size: [55050 55050 55050 55050 55050 55050 55050 55050 55050 55050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.8889288902282715 0.002377033233642578
train_time 7.892672538757324
2023-09-06 14:35:07,122 MainThread INFO: EPOCH:365
2023-09-06 14:35:07,123 MainThread INFO: Time Consumed:12.655178308486938s
2023-09-06 14:35:07,123 MainThread INFO: Total Frames:549000s
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 366/400 [41:46<07:08, 12.62s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1008.48523
Train_Epoch_Reward                    11286.70467
Running_Training_Average_Rewards      1181.58169
Explore_Time                          4.75521
Train___Time                          7.89267
Eval____Time                          0.00332
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.11917
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.77964
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.67910
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.53623
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.09228
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.11194
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.95521
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10392.10802
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.37628
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           491.34595
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.76446      0.73388    6.52624     3.65066
alpha_0                               0.39618      0.00020    0.39650     0.39586
alpha_1                               0.34190      0.00027    0.34233     0.34147
alpha_2                               0.34018      0.00029    0.34064     0.33972
alpha_3                               0.33665      0.00030    0.33712     0.33618
alpha_4                               0.33925      0.00028    0.33968     0.33882
alpha_5                               0.33781      0.00030    0.33827     0.33735
alpha_6                               0.33771      0.00029    0.33816     0.33726
alpha_7                               0.34913      0.00030    0.34960     0.34866
alpha_8                               0.34004      0.00029    0.34050     0.33959
alpha_9                               0.33966      0.00029    0.34012     0.33920
Alpha_loss                            -6.17027     0.02249    -6.14415    -6.21778
Training/policy_loss                  -77.91190    0.52590    -76.90675   -78.55322
Training/qf1_loss                     743.41127    334.03428  1482.98376  405.20941
Training/qf2_loss                     735.87198    332.77164  1471.31763  399.77756
Training/pf_norm                      0.17118      0.01546    0.20659     0.15085
Training/qf1_norm                     290.27517    205.71925  863.31049   59.16344
Training/qf2_norm                     291.59227    204.13228  857.82440   60.22103
log_std/mean                          -0.28919     0.00036    -0.28870    -0.28985
log_std/std                           0.13726      0.00035    0.13781     0.13667
log_std/max                           -0.11946     0.00115    -0.11762    -0.12085
log_std/min                           -0.73304     0.00946    -0.71587    -0.74569
log_probs/mean                        -1.75490     0.02198    -1.72584    -1.79329
log_probs/std                         1.63309      0.02657    1.66503     1.58136
log_probs/max                         5.27247      0.24860    5.50744     4.77628
log_probs/min                         -6.76962     0.57801    -5.97239    -7.63986
mean/mean                             0.03502      0.00298    0.03925     0.02943
mean/std                              0.56892      0.00139    0.57117     0.56679
mean/max                              1.66066      0.00518    1.66875     1.65329
mean/min                              -1.69368     0.00670    -1.68334    -1.70562
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 0, 7, 3, 4, 2, 6, 5, 8, 1]
replay_buffer._size: [55200 55200 55200 55200 55200 55200 55200 55200 55200 55200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.762476682662964 0.002542257308959961
train_time 7.76628303527832
2023-09-06 14:35:20,197 MainThread INFO: EPOCH:366
2023-09-06 14:35:20,197 MainThread INFO: Time Consumed:8.184433698654175s
2023-09-06 14:35:20,198 MainThread INFO: Total Frames:550500s
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 367/400 [41:59<07:00, 12.76s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1040.37534
Train_Epoch_Reward                    9162.92538
Running_Training_Average_Rewards      1125.95024
Explore_Time                          0.36670
Train___Time                          7.76628
Eval____Time                          0.01843
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.44463
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.35957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.77838
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.87569
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.20569
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.92749
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.20822
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10448.72849
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.88226
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           838.00803
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.31196      0.56580    5.25545    3.72015
alpha_0                               0.39548      0.00020    0.39579    0.39516
alpha_1                               0.34095      0.00027    0.34138    0.34053
alpha_2                               0.33915      0.00029    0.33961    0.33870
alpha_3                               0.33561      0.00030    0.33608    0.33514
alpha_4                               0.33829      0.00027    0.33872    0.33786
alpha_5                               0.33678      0.00029    0.33724    0.33632
alpha_6                               0.33671      0.00029    0.33716    0.33625
alpha_7                               0.34809      0.00030    0.34856    0.34763
alpha_8                               0.33904      0.00029    0.33949    0.33859
alpha_9                               0.33863      0.00030    0.33909    0.33817
Alpha_loss                            -6.16347     0.02848    -6.11679   -6.19755
Training/policy_loss                  -77.95781    0.29220    -77.51021  -78.69835
Training/qf1_loss                     526.65242    160.23106  826.86200  304.52240
Training/qf2_loss                     519.27440    159.56967  817.56342  299.56168
Training/pf_norm                      0.20579      0.03683    0.29858    0.16458
Training/qf1_norm                     210.34960    96.59445   366.21057  55.69839
Training/qf2_norm                     210.10700    96.39645   373.00696  69.55637
log_std/mean                          -0.28868     0.00058    -0.28764   -0.28945
log_std/std                           0.13760      0.00024    0.13791    0.13725
log_std/max                           -0.11997     0.00163    -0.11728   -0.12182
log_std/min                           -0.74031     0.00660    -0.72724   -0.75131
log_probs/mean                        -1.73265     0.02834    -1.68651   -1.76791
log_probs/std                         1.64309      0.04633    1.70449    1.57864
log_probs/max                         5.47813      0.20065    5.95049    5.20249
log_probs/min                         -6.71803     0.88289    -5.53482   -8.58107
mean/mean                             0.04137      0.00194    0.04540    0.03863
mean/std                              0.56971      0.00088    0.57143    0.56895
mean/max                              1.65951      0.00355    1.66343    1.65339
mean/min                              -1.68028     0.00512    -1.67048   -1.68642
------------------------------------  -----------  ---------  ---------  ---------
sample: [6, 7, 5, 3, 9, 8, 1, 4, 0, 2]
replay_buffer._size: [55350 55350 55350 55350 55350 55350 55350 55350 55350 55350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.293721199035645 0.0020761489868164062
train_time 13.29701042175293
2023-09-06 14:35:33,778 MainThread INFO: EPOCH:367
2023-09-06 14:35:33,779 MainThread INFO: Time Consumed:13.416538000106812s
2023-09-06 14:35:33,779 MainThread INFO: Total Frames:552000s
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 368/400 [42:13<06:55, 13.00s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1066.51131
Train_Epoch_Reward                    12065.16583
Running_Training_Average_Rewards      1083.82653
Explore_Time                          0.00352
Train___Time                          13.29701
Eval____Time                          0.10489
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.84553
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.61668
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.50404
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.21046
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.25868
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.58458
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.25365
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10429.02417
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.02904
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           854.75897
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.06153      0.90280    6.97173     3.85383
alpha_0                               0.39478      0.00020    0.39509     0.39447
alpha_1                               0.34001      0.00027    0.34043     0.33958
alpha_2                               0.33814      0.00029    0.33859     0.33768
alpha_3                               0.33457      0.00030    0.33504     0.33411
alpha_4                               0.33733      0.00028    0.33776     0.33690
alpha_5                               0.33576      0.00029    0.33622     0.33530
alpha_6                               0.33570      0.00029    0.33615     0.33525
alpha_7                               0.34706      0.00030    0.34753     0.34660
alpha_8                               0.33805      0.00029    0.33849     0.33760
alpha_9                               0.33760      0.00029    0.33806     0.33714
Alpha_loss                            -6.19583     0.02883    -6.15821    -6.24638
Training/policy_loss                  -78.26624    0.24865    -77.85889   -78.71964
Training/qf1_loss                     733.56809    290.55356  1444.16663  417.37637
Training/qf2_loss                     726.32393    289.76565  1433.00549  410.14484
Training/pf_norm                      0.20400      0.04300    0.30568     0.14956
Training/qf1_norm                     369.85798    323.07246  1112.31567  83.73015
Training/qf2_norm                     374.05655    325.55142  1121.78613  71.33307
log_std/mean                          -0.28684     0.00032    -0.28640    -0.28739
log_std/std                           0.13967      0.00113    0.14188     0.13812
log_std/max                           -0.11741     0.00178    -0.11431    -0.12060
log_std/min                           -0.74728     0.00763    -0.73372    -0.75599
log_probs/mean                        -1.74610     0.02862    -1.70686    -1.79709
log_probs/std                         1.65641      0.04658    1.72352     1.58876
log_probs/max                         5.27122      0.34714    5.83144     4.71692
log_probs/min                         -6.62389     0.51240    -5.96560    -7.46633
mean/mean                             0.05283      0.00464    0.05985     0.04595
mean/std                              0.57121      0.00188    0.57555     0.56864
mean/max                              1.68423      0.01635    1.71180     1.66271
mean/min                              -1.67229     0.00424    -1.66631    -1.68019
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 7, 5, 9, 4, 8, 0, 1, 2, 3]
replay_buffer._size: [55500 55500 55500 55500 55500 55500 55500 55500 55500 55500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.253685474395752 0.0020749568939208984
train_time 12.256975889205933
2023-09-06 14:35:46,182 MainThread INFO: EPOCH:368
2023-09-06 14:35:46,182 MainThread INFO: Time Consumed:12.270414590835571s
2023-09-06 14:35:46,183 MainThread INFO: Total Frames:553500s
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 369/400 [42:25<06:37, 12.81s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1069.85875
Train_Epoch_Reward                    14609.36540
Running_Training_Average_Rewards      1194.58189
Explore_Time                          0.00345
Train___Time                          12.25698
Eval____Time                          0.00322
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.28821
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.75683
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.63945
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.85369
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.49494
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.36943
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.23565
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10146.69025
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.90131
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           838.07678
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.60812      0.72144    5.84413     3.34788
alpha_0                               0.39412      0.00018    0.39441     0.39383
alpha_1                               0.33907      0.00027    0.33949     0.33865
alpha_2                               0.33713      0.00029    0.33758     0.33668
alpha_3                               0.33354      0.00030    0.33400     0.33307
alpha_4                               0.33637      0.00028    0.33680     0.33594
alpha_5                               0.33475      0.00029    0.33520     0.33429
alpha_6                               0.33470      0.00029    0.33515     0.33424
alpha_7                               0.34603      0.00029    0.34650     0.34557
alpha_8                               0.33705      0.00028    0.33750     0.33661
alpha_9                               0.33658      0.00029    0.33704     0.33611
Alpha_loss                            -6.17632     0.03606    -6.09784    -6.21622
Training/policy_loss                  -78.81290    0.45530    -78.04317   -79.48012
Training/qf1_loss                     619.11168    215.55803  1075.90564  323.69647
Training/qf2_loss                     611.23495    215.57543  1068.20776  315.22098
Training/pf_norm                      0.20178      0.04130    0.28701     0.14261
Training/qf1_norm                     285.46341    161.92575  603.57349   102.76292
Training/qf2_norm                     283.61234    163.04763  605.80127   94.41554
log_std/mean                          -0.28961     0.00106    -0.28752    -0.29091
log_std/std                           0.14280      0.00073    0.14384     0.14139
log_std/max                           -0.12123     0.00187    -0.11727    -0.12348
log_std/min                           -0.75934     0.01010    -0.74429    -0.77440
log_probs/mean                        -1.70804     0.03655    -1.63197    -1.75213
log_probs/std                         1.74754      0.03059    1.80736     1.70063
log_probs/max                         5.82687      0.19374    6.26932     5.58442
log_probs/min                         -7.22596     1.60777    -5.49663    -11.06321
mean/mean                             0.06538      0.00263    0.06938     0.06072
mean/std                              0.58074      0.00327    0.58561     0.57459
mean/max                              1.73929      0.01460    1.75491     1.71381
mean/min                              -1.70618     0.01425    -1.68590    -1.72737
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 4, 7, 0, 9, 3, 1, 5, 6, 2]
replay_buffer._size: [55650 55650 55650 55650 55650 55650 55650 55650 55650 55650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.615885734558105 0.002064943313598633
train_time 12.619176387786865
2023-09-06 14:35:58,926 MainThread INFO: EPOCH:369
2023-09-06 14:35:58,926 MainThread INFO: Time Consumed:12.63181185722351s
2023-09-06 14:35:58,926 MainThread INFO: Total Frames:555000s
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 370/400 [42:38<06:23, 12.79s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1045.61910
Train_Epoch_Reward                    12202.24904
Running_Training_Average_Rewards      1295.89268
Explore_Time                          0.00317
Train___Time                          12.61918
Eval____Time                          0.00530
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.96182
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.89308
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.10227
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.62049
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.45551
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.58239
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.35480
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9700.20649
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.56288
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           857.19177
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.75295      0.74443    5.76137     3.18046
alpha_0                               0.39351      0.00017    0.39377     0.39325
alpha_1                               0.33814      0.00026    0.33855     0.33773
alpha_2                               0.33612      0.00029    0.33658     0.33567
alpha_3                               0.33251      0.00030    0.33297     0.33204
alpha_4                               0.33541      0.00028    0.33584     0.33498
alpha_5                               0.33374      0.00029    0.33419     0.33328
alpha_6                               0.33369      0.00029    0.33414     0.33323
alpha_7                               0.34501      0.00030    0.34547     0.34454
alpha_8                               0.33607      0.00028    0.33651     0.33563
alpha_9                               0.33555      0.00029    0.33601     0.33509
Alpha_loss                            -6.16651     0.02882    -6.10682    -6.20656
Training/policy_loss                  -78.77627    0.31413    -78.31936   -79.24969
Training/qf1_loss                     659.23229    282.01094  1148.57581  254.89558
Training/qf2_loss                     650.97277    281.40297  1138.17969  248.18547
Training/pf_norm                      0.21473      0.02037    0.25185     0.18700
Training/qf1_norm                     296.14890    201.94268  600.27441   69.35931
Training/qf2_norm                     302.61631    200.66392  610.11536   70.53304
log_std/mean                          -0.29024     0.00049    -0.28944    -0.29101
log_std/std                           0.14438      0.00026    0.14485     0.14393
log_std/max                           -0.12001     0.00214    -0.11663    -0.12360
log_std/min                           -0.77315     0.00553    -0.76604    -0.78645
log_probs/mean                        -1.68320     0.02739    -1.62706    -1.71939
log_probs/std                         1.75111      0.03239    1.79554     1.69511
log_probs/max                         6.01164      0.20082    6.39940     5.61393
log_probs/min                         -7.27545     0.88752    -5.54018    -8.57323
mean/mean                             0.06962      0.00060    0.07059     0.06887
mean/std                              0.58733      0.00115    0.58855     0.58493
mean/max                              1.75593      0.00596    1.76387     1.74720
mean/min                              -1.73594     0.00312    -1.72983    -1.74123
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 7, 2, 0, 3, 5, 9, 6, 1, 8]
replay_buffer._size: [55800 55800 55800 55800 55800 55800 55800 55800 55800 55800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.850393772125244 0.0026662349700927734
train_time 7.854349374771118
2023-09-06 14:36:11,523 MainThread INFO: EPOCH:370
2023-09-06 14:36:11,524 MainThread INFO: Time Consumed:12.468571186065674s
2023-09-06 14:36:11,524 MainThread INFO: Total Frames:556500s
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 371/400 [42:51<06:09, 12.74s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1018.42762
Train_Epoch_Reward                    10223.63277
Running_Training_Average_Rewards      1234.50824
Explore_Time                          4.58877
Train___Time                          7.85435
Eval____Time                          0.00926
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.95082
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.17323
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.01706
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.63657
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.62078
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.25756
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.09598
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9653.02203
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.64679
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           823.11293
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.27367      0.68777    5.34059    2.79865
alpha_0                               0.39293      0.00017    0.39319    0.39267
alpha_1                               0.33723      0.00026    0.33763    0.33682
alpha_2                               0.33513      0.00029    0.33557    0.33468
alpha_3                               0.33148      0.00029    0.33194    0.33102
alpha_4                               0.33445      0.00028    0.33488    0.33402
alpha_5                               0.33273      0.00029    0.33318    0.33228
alpha_6                               0.33268      0.00029    0.33313    0.33222
alpha_7                               0.34398      0.00029    0.34444    0.34353
alpha_8                               0.33510      0.00028    0.33554    0.33467
alpha_9                               0.33452      0.00029    0.33498    0.33406
Alpha_loss                            -6.18482     0.04930    -6.11978   -6.26357
Training/policy_loss                  -78.89351    0.37688    -78.33595  -79.76945
Training/qf1_loss                     541.01986    221.00193  850.16125  230.51347
Training/qf2_loss                     533.32334    220.31114  839.46484  223.47568
Training/pf_norm                      0.21621      0.03133    0.25242    0.15717
Training/qf1_norm                     241.62571    163.27105  658.39545  51.03603
Training/qf2_norm                     240.11783    158.35376  633.28857  47.38456
log_std/mean                          -0.28816     0.00092    -0.28643   -0.28922
log_std/std                           0.14370      0.00044    0.14431    0.14290
log_std/max                           -0.11535     0.00253    -0.11116   -0.11821
log_std/min                           -0.76395     0.00665    -0.75063   -0.77279
log_probs/mean                        -1.68571     0.04442    -1.62952   -1.75902
log_probs/std                         1.72920      0.04614    1.81125    1.63247
log_probs/max                         5.72695      0.32471    6.36230    5.30058
log_probs/min                         -6.70193     0.98895    -5.37881   -8.07665
mean/mean                             0.06610      0.00243    0.06914    0.06179
mean/std                              0.58429      0.00308    0.58793    0.57861
mean/max                              1.72807      0.01267    1.74266    1.70603
mean/min                              -1.71016     0.01820    -1.68009   -1.73332
------------------------------------  -----------  ---------  ---------  ---------
sample: [0, 5, 8, 6, 3, 9, 7, 1, 2, 4]
replay_buffer._size: [55950 55950 55950 55950 55950 55950 55950 55950 55950 55950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.240121603012085 0.002124786376953125
train_time 12.243510484695435
2023-09-06 14:36:23,908 MainThread INFO: EPOCH:371
2023-09-06 14:36:23,909 MainThread INFO: Time Consumed:12.256580114364624s
2023-09-06 14:36:23,909 MainThread INFO: Total Frames:558000s
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 372/400 [43:03<05:53, 12.63s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1014.67475
Train_Epoch_Reward                    10991.78209
Running_Training_Average_Rewards      1113.92213
Explore_Time                          0.00336
Train___Time                          12.24351
Eval____Time                          0.00313
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.93537
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.03358
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.31576
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.02973
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.99071
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.00237
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.94247
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10020.54685
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.06253
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           848.40707
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.59628      0.65210    5.73911    3.72407
alpha_0                               0.39233      0.00018    0.39261    0.39205
alpha_1                               0.33631      0.00026    0.33672    0.33590
alpha_2                               0.33413      0.00029    0.33458    0.33368
alpha_3                               0.33045      0.00029    0.33091    0.32999
alpha_4                               0.33349      0.00027    0.33392    0.33306
alpha_5                               0.33173      0.00029    0.33218    0.33127
alpha_6                               0.33167      0.00029    0.33212    0.33121
alpha_7                               0.34297      0.00029    0.34343    0.34252
alpha_8                               0.33414      0.00028    0.33457    0.33370
alpha_9                               0.33350      0.00029    0.33396    0.33305
Alpha_loss                            -6.25694     0.04251    -6.19537   -6.33355
Training/policy_loss                  -78.95743    0.26707    -78.49797  -79.41401
Training/qf1_loss                     590.34385    233.83669  889.46960  285.30304
Training/qf2_loss                     582.81347    232.98768  880.68585  278.92395
Training/pf_norm                      0.16964      0.02818    0.21068    0.12537
Training/qf1_norm                     253.75916    170.81642  606.17969  48.68116
Training/qf2_norm                     253.22237    171.68681  597.17279  42.47519
log_std/mean                          -0.28519     0.00053    -0.28460   -0.28640
log_std/std                           0.14283      0.00029    0.14330    0.14222
log_std/max                           -0.10941     0.00165    -0.10626   -0.11297
log_std/min                           -0.75862     0.00604    -0.74918   -0.76863
log_probs/mean                        -1.73979     0.03704    -1.68603   -1.80962
log_probs/std                         1.67481      0.02974    1.72032    1.63023
log_probs/max                         5.41158      0.26155    5.85736    4.93497
log_probs/min                         -6.86028     1.26752    -5.94747   -10.46374
mean/mean                             0.05682      0.00256    0.06082    0.05301
mean/std                              0.57529      0.00192    0.57859    0.57212
mean/max                              1.68732      0.00824    1.69910    1.67615
mean/min                              -1.65437     0.01067    -1.64101   -1.67464
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 8, 3, 7, 9, 1, 0, 6, 4, 5]
replay_buffer._size: [56100 56100 56100 56100 56100 56100 56100 56100 56100 56100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.608795642852783 0.0021965503692626953
train_time 12.612271547317505
2023-09-06 14:36:36,660 MainThread INFO: EPOCH:372
2023-09-06 14:36:36,661 MainThread INFO: Time Consumed:12.636547565460205s
2023-09-06 14:36:36,661 MainThread INFO: Total Frames:559500s
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 373/400 [43:16<05:41, 12.66s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1048.34602
Train_Epoch_Reward                    9662.58042
Running_Training_Average_Rewards      1029.26651
Explore_Time                          0.00320
Train___Time                          12.61227
Eval____Time                          0.01537
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.52508
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.76872
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.29512
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.02180
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.25813
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.73074
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.95016
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10637.28813
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.82388
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           921.08838
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.47533      0.72672    5.30048    3.07522
alpha_0                               0.39169      0.00018    0.39198    0.39140
alpha_1                               0.33539      0.00027    0.33581    0.33497
alpha_2                               0.33313      0.00029    0.33358    0.33269
alpha_3                               0.32943      0.00029    0.32989    0.32897
alpha_4                               0.33253      0.00027    0.33296    0.33210
alpha_5                               0.33072      0.00029    0.33117    0.33027
alpha_6                               0.33065      0.00029    0.33111    0.33020
alpha_7                               0.34197      0.00029    0.34242    0.34152
alpha_8                               0.33317      0.00028    0.33361    0.33273
alpha_9                               0.33249      0.00029    0.33295    0.33203
Alpha_loss                            -6.25974     0.02425    -6.22167   -6.29383
Training/policy_loss                  -79.49714    0.29893    -78.98146  -79.96315
Training/qf1_loss                     633.20936    234.49140  993.13037  249.38745
Training/qf2_loss                     625.23158    234.17601  984.10974  242.49576
Training/pf_norm                      0.22549      0.05549    0.31591    0.14146
Training/qf1_norm                     288.24510    116.62904  422.78217  58.17348
Training/qf2_norm                     288.48828    118.07253  433.14719  58.95395
log_std/mean                          -0.28611     0.00039    -0.28564   -0.28691
log_std/std                           0.14294      0.00024    0.14351    0.14253
log_std/max                           -0.11224     0.00150    -0.10977   -0.11498
log_std/min                           -0.75478     0.00640    -0.74365   -0.76320
log_probs/mean                        -1.72592     0.02428    -1.68563   -1.76461
log_probs/std                         1.68953      0.04846    1.76717    1.59832
log_probs/max                         5.36085      0.20173    5.72119    5.04608
log_probs/min                         -7.00467     1.16451    -6.10366   -9.93122
mean/mean                             0.05105      0.00110    0.05318    0.04936
mean/std                              0.57429      0.00088    0.57646    0.57303
mean/max                              1.68294      0.00433    1.68921    1.67652
mean/min                              -1.64522     0.00622    -1.63590   -1.65748
------------------------------------  -----------  ---------  ---------  ---------
sample: [9, 0, 8, 2, 4, 7, 3, 5, 1, 6]
replay_buffer._size: [56250 56250 56250 56250 56250 56250 56250 56250 56250 56250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.803655862808228 0.0023343563079833984
train_time 12.80734658241272
2023-09-06 14:36:49,586 MainThread INFO: EPOCH:373
2023-09-06 14:36:49,586 MainThread INFO: Time Consumed:12.821573734283447s
2023-09-06 14:36:49,587 MainThread INFO: Total Frames:561000s
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 374/400 [43:29<05:31, 12.74s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1097.17136
Train_Epoch_Reward                    12019.09895
Running_Training_Average_Rewards      1089.11538
Explore_Time                          0.00340
Train___Time                          12.80735
Eval____Time                          0.00639
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.75406
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.07020
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.07746
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.75577
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.77408
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.61101
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.35412
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10998.05423
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.63386
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           931.47299
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.84874      0.83243    6.51893     3.78340
alpha_0                               0.39106      0.00018    0.39134     0.39078
alpha_1                               0.33446      0.00027    0.33488     0.33405
alpha_2                               0.33214      0.00028    0.33259     0.33170
alpha_3                               0.32841      0.00029    0.32887     0.32795
alpha_4                               0.33158      0.00027    0.33201     0.33116
alpha_5                               0.32972      0.00029    0.33017     0.32927
alpha_6                               0.32965      0.00029    0.33010     0.32920
alpha_7                               0.34097      0.00029    0.34142     0.34052
alpha_8                               0.33220      0.00028    0.33264     0.33177
alpha_9                               0.33148      0.00029    0.33193     0.33102
Alpha_loss                            -6.24922     0.03185    -6.20922    -6.30918
Training/policy_loss                  -79.56414    0.35712    -79.13560   -80.34819
Training/qf1_loss                     601.45441    222.42818  1092.42017  341.91821
Training/qf2_loss                     594.44305    221.45478  1083.06738  336.99985
Training/pf_norm                      0.20664      0.03383    0.26447     0.15086
Training/qf1_norm                     338.56459    270.81778  976.89508   87.82557
Training/qf2_norm                     335.22367    270.91124  968.41071   87.17858
log_std/mean                          -0.28806     0.00102    -0.28690    -0.28994
log_std/std                           0.14308      0.00017    0.14328     0.14280
log_std/max                           -0.11516     0.00156    -0.11210    -0.11690
log_std/min                           -0.75925     0.00525    -0.74998    -0.77064
log_probs/mean                        -1.69872     0.02870    -1.65443    -1.74882
log_probs/std                         1.73059      0.01890    1.75950     1.69764
log_probs/max                         5.73968      0.33458    6.21332     5.19171
log_probs/min                         -6.75161     0.44312    -5.95570    -7.63354
mean/mean                             0.05428      0.00249    0.05885     0.05153
mean/std                              0.57855      0.00198    0.58228     0.57586
mean/max                              1.67782      0.00453    1.68336     1.67138
mean/min                              -1.67751     0.01250    -1.65472    -1.70123
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 1, 0, 7, 3, 5, 9, 6, 8, 4]
replay_buffer._size: [56400 56400 56400 56400 56400 56400 56400 56400 56400 56400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.917190551757812 0.002057790756225586
train_time 12.92046856880188
2023-09-06 14:37:02,651 MainThread INFO: EPOCH:374
2023-09-06 14:37:02,651 MainThread INFO: Time Consumed:12.947973489761353s
2023-09-06 14:37:02,652 MainThread INFO: Total Frames:562500s
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 375/400 [43:42<05:20, 12.84s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1126.79619
Train_Epoch_Reward                    11581.55361
Running_Training_Average_Rewards      1108.77443
Explore_Time                          0.00404
Train___Time                          12.92047
Eval____Time                          0.01745
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.45321
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.51874
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.10946
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.49600
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.70490
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.84686
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.31136
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10830.27311
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.52082
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           918.07445
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.66977      0.46698    5.37716    3.95766
alpha_0                               0.39046      0.00017    0.39072    0.39020
alpha_1                               0.33354      0.00026    0.33395    0.33312
alpha_2                               0.33115      0.00028    0.33160    0.33071
alpha_3                               0.32740      0.00029    0.32785    0.32694
alpha_4                               0.33064      0.00027    0.33106    0.33022
alpha_5                               0.32872      0.00029    0.32917    0.32827
alpha_6                               0.32865      0.00029    0.32910    0.32820
alpha_7                               0.33997      0.00029    0.34042    0.33951
alpha_8                               0.33124      0.00027    0.33167    0.33081
alpha_9                               0.33046      0.00029    0.33092    0.33001
Alpha_loss                            -6.23579     0.03116    -6.17641   -6.29564
Training/policy_loss                  -79.72863    0.27908    -79.34959  -80.21938
Training/qf1_loss                     627.87357    188.84507  910.55371  338.58643
Training/qf2_loss                     619.39729    188.00414  902.95831  331.43317
Training/pf_norm                      0.22958      0.03434    0.27665    0.17486
Training/qf1_norm                     234.54384    151.08799  518.38416  43.77888
Training/qf2_norm                     239.40341    150.64483  515.30408  53.97071
log_std/mean                          -0.29307     0.00177    -0.29052   -0.29591
log_std/std                           0.14437      0.00066    0.14530    0.14347
log_std/max                           -0.12184     0.00280    -0.11685   -0.12668
log_std/min                           -0.77034     0.00772    -0.75680   -0.78230
log_probs/mean                        -1.66916     0.03394    -1.60458   -1.73696
log_probs/std                         1.78732      0.04300    1.88594    1.73681
log_probs/max                         6.20548      0.20385    6.53581    5.85447
log_probs/min                         -7.01623     0.64696    -6.38314   -8.49741
mean/mean                             0.06732      0.00522    0.07560    0.05988
mean/std                              0.58917      0.00366    0.59419    0.58316
mean/max                              1.69405      0.00999    1.71389    1.68248
mean/min                              -1.73021     0.01351    -1.71020   -1.75349
------------------------------------  -----------  ---------  ---------  ---------
sample: [2, 8, 5, 9, 0, 6, 4, 1, 7, 3]
replay_buffer._size: [56550 56550 56550 56550 56550 56550 56550 56550 56550 56550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.750530004501343 0.0026607513427734375
train_time 12.754778385162354
2023-09-06 14:37:15,540 MainThread INFO: EPOCH:375
2023-09-06 14:37:15,540 MainThread INFO: Time Consumed:12.77700686454773s
2023-09-06 14:37:15,541 MainThread INFO: Total Frames:564000s
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 376/400 [43:55<05:08, 12.86s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1116.08783
Train_Epoch_Reward                    12649.37438
Running_Training_Average_Rewards      1208.33423
Explore_Time                          0.00404
Train___Time                          12.75478
Eval____Time                          0.01060
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.45435
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.80628
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.22951
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.71249
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.94351
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.63396
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.43968
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10235.51488
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.61249
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1009.06946
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.77205      0.93866    6.72613     3.57112
alpha_0                               0.38992      0.00014    0.39015     0.38971
alpha_1                               0.33263      0.00026    0.33303     0.33222
alpha_2                               0.33017      0.00028    0.33061     0.32973
alpha_3                               0.32638      0.00029    0.32684     0.32593
alpha_4                               0.32970      0.00027    0.33012     0.32928
alpha_5                               0.32772      0.00028    0.32817     0.32728
alpha_6                               0.32765      0.00028    0.32810     0.32721
alpha_7                               0.33896      0.00029    0.33941     0.33850
alpha_8                               0.33029      0.00027    0.33072     0.32986
alpha_9                               0.32946      0.00029    0.32991     0.32901
Alpha_loss                            -6.18508     0.03156    -6.13202    -6.24494
Training/policy_loss                  -80.19860    0.22461    -79.92991   -80.72371
Training/qf1_loss                     730.94483    282.19452  1244.23022  230.17709
Training/qf2_loss                     722.77406    281.41309  1235.14502  222.86580
Training/pf_norm                      0.20419      0.02982    0.26328     0.15585
Training/qf1_norm                     345.03354    256.92012  974.28558   93.86935
Training/qf2_norm                     343.89176    257.42389  970.92261   85.45759
log_std/mean                          -0.29933     0.00126    -0.29698    -0.30082
log_std/std                           0.14708      0.00057    0.14790     0.14615
log_std/max                           -0.12854     0.00186    -0.12620    -0.13183
log_std/min                           -0.78742     0.01008    -0.77408    -0.80322
log_probs/mean                        -1.60240     0.03182    -1.54688    -1.66636
log_probs/std                         1.87423      0.03357    1.91585     1.79527
log_probs/max                         6.55981      0.18361    6.97130     6.36463
log_probs/min                         -7.02934     0.86916    -5.96567    -8.70798
mean/mean                             0.08638      0.00490    0.09319     0.07808
mean/std                              0.60056      0.00178    0.60310     0.59771
mean/max                              1.72926      0.00799    1.73796     1.71408
mean/min                              -1.76024     0.00699    -1.74384    -1.76899
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 2, 1, 3, 0, 5, 9, 7, 4, 6]
replay_buffer._size: [56700 56700 56700 56700 56700 56700 56700 56700 56700 56700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.484983921051025 0.002058267593383789
train_time 12.488311529159546
2023-09-06 14:37:28,637 MainThread INFO: EPOCH:376
2023-09-06 14:37:28,637 MainThread INFO: Time Consumed:12.959310054779053s
2023-09-06 14:37:28,638 MainThread INFO: Total Frames:565500s
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 377/400 [44:08<04:57, 12.93s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1085.22000
Train_Epoch_Reward                    15657.45694
Running_Training_Average_Rewards      1329.61283
Explore_Time                          0.46167
Train___Time                          12.48831
Eval____Time                          0.00528
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.61657
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.45774
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.72786
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.12788
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.02251
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.38248
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.18791
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9586.12530
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.27105
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1427.13051
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.09094      0.65369    6.16677     4.04726
alpha_0                               0.38945      0.00013    0.38966     0.38924
alpha_1                               0.33173      0.00026    0.33213     0.33133
alpha_2                               0.32920      0.00028    0.32964     0.32876
alpha_3                               0.32538      0.00029    0.32583     0.32492
alpha_4                               0.32877      0.00027    0.32919     0.32835
alpha_5                               0.32674      0.00028    0.32718     0.32629
alpha_6                               0.32667      0.00028    0.32711     0.32623
alpha_7                               0.33793      0.00029    0.33839     0.33747
alpha_8                               0.32935      0.00027    0.32977     0.32893
alpha_9                               0.32845      0.00029    0.32891     0.32800
Alpha_loss                            -6.21583     0.03523    -6.15424    -6.26434
Training/policy_loss                  -80.30841    0.38460    -79.81679   -81.22768
Training/qf1_loss                     829.13397    245.88423  1212.72754  446.17743
Training/qf2_loss                     820.24077    245.96713  1205.77148  435.60370
Training/pf_norm                      0.18812      0.01877    0.21637     0.15704
Training/qf1_norm                     368.87758    213.97095  730.90845   83.32741
Training/qf2_norm                     374.60203    216.01088  730.27698   76.12998
log_std/mean                          -0.30211     0.00077    -0.30085    -0.30335
log_std/std                           0.14816      0.00043    0.14914     0.14741
log_std/max                           -0.13134     0.00213    -0.12783    -0.13401
log_std/min                           -0.80717     0.00924    -0.79324    -0.82198
log_probs/mean                        -1.61778     0.03477    -1.55287    -1.67187
log_probs/std                         1.85350      0.04234    1.92494     1.76926
log_probs/max                         6.51449      0.23644    7.04954     6.19612
log_probs/min                         -7.16044     0.90902    -6.20057    -9.00126
mean/mean                             0.09866      0.00268    0.10232     0.09429
mean/std                              0.60375      0.00127    0.60664     0.60198
mean/max                              1.75713      0.01589    1.78638     1.73346
mean/min                              -1.73351     0.00758    -1.72340    -1.74894
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 9, 0, 6, 3, 2, 7, 8, 4, 1]
replay_buffer._size: [56850 56850 56850 56850 56850 56850 56850 56850 56850 56850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.689022064208984 0.0020165443420410156
train_time 12.692280292510986
2023-09-06 14:37:41,469 MainThread INFO: EPOCH:377
2023-09-06 14:37:41,470 MainThread INFO: Time Consumed:12.708234786987305s
2023-09-06 14:37:41,470 MainThread INFO: Total Frames:567000s
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 378/400 [44:21<04:43, 12.89s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1055.27630
Train_Epoch_Reward                    9302.55051
Running_Training_Average_Rewards      1253.64606
Explore_Time                          0.00351
Train___Time                          12.69228
Eval____Time                          0.00752
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.59835
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.94945
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.99595
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.61519
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.53552
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.87657
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.77680
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9345.62059
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.07135
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1512.87369
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.96320     0.47672    5.75632     4.12369
alpha_0                               0.38900     0.00012    0.38920     0.38881
alpha_1                               0.33084     0.00025    0.33124     0.33044
alpha_2                               0.32823     0.00028    0.32866     0.32779
alpha_3                               0.32437     0.00029    0.32482     0.32392
alpha_4                               0.32784     0.00027    0.32826     0.32742
alpha_5                               0.32575     0.00028    0.32619     0.32531
alpha_6                               0.32569     0.00028    0.32613     0.32525
alpha_7                               0.33691     0.00029    0.33737     0.33646
alpha_8                               0.32842     0.00026    0.32884     0.32801
alpha_9                               0.32745     0.00029    0.32790     0.32700
Alpha_loss                            -6.20380    0.02067    -6.17605    -6.23600
Training/policy_loss                  -80.98843   0.27202    -80.44955   -81.39935
Training/qf1_loss                     708.48438   175.82686  1109.54285  485.27545
Training/qf2_loss                     700.78545   175.81419  1101.37988  478.11758
Training/pf_norm                      0.18123     0.03118    0.25157     0.14523
Training/qf1_norm                     267.31549   146.67540  541.08612   62.91869
Training/qf2_norm                     275.20558   149.38644  550.50464   60.90841
log_std/mean                          -0.30313    0.00026    -0.30261    -0.30349
log_std/std                           0.14872     0.00026    0.14916     0.14836
log_std/max                           -0.13616    0.00140    -0.13388    -0.13871
log_std/min                           -0.81717    0.01097    -0.80497    -0.83366
log_probs/mean                        -1.58957    0.02144    -1.55618    -1.61739
log_probs/std                         1.89749     0.03089    1.95636     1.83847
log_probs/max                         6.56359     0.30902    6.98689     6.00991
log_probs/min                         -6.93088    0.65410    -5.92901    -8.02878
mean/mean                             0.10276     0.00051    0.10364     0.10167
mean/std                              0.60587     0.00072    0.60725     0.60488
mean/max                              1.79376     0.00815    1.80500     1.77864
mean/min                              -1.71031    0.00710    -1.69607    -1.72012
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 6, 1, 7, 0, 4, 5, 8, 9, 2]
replay_buffer._size: [57000 57000 57000 57000 57000 57000 57000 57000 57000 57000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.904684782028198 0.0021631717681884766
train_time 12.90816330909729
2023-09-06 14:37:54,495 MainThread INFO: EPOCH:378
2023-09-06 14:37:54,495 MainThread INFO: Time Consumed:12.920854568481445s
2023-09-06 14:37:54,495 MainThread INFO: Total Frames:568500s
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 379/400 [44:34<04:31, 12.94s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1043.42814
Train_Epoch_Reward                    11657.70973
Running_Training_Average_Rewards      1220.59057
Explore_Time                          0.00289
Train___Time                          12.90816
Eval____Time                          0.00564
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.09619
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.37603
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.61429
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.24867
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.41700
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.87186
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.76614
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9377.14292
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.47442
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1515.02907
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.91033      0.85432    5.89651     3.22967
alpha_0                               0.38857      0.00012    0.38876     0.38839
alpha_1                               0.32996      0.00025    0.33036     0.32956
alpha_2                               0.32726      0.00028    0.32770     0.32683
alpha_3                               0.32337      0.00029    0.32382     0.32293
alpha_4                               0.32690      0.00027    0.32732     0.32648
alpha_5                               0.32477      0.00028    0.32521     0.32433
alpha_6                               0.32471      0.00028    0.32515     0.32426
alpha_7                               0.33590      0.00029    0.33636     0.33545
alpha_8                               0.32751      0.00026    0.32792     0.32710
alpha_9                               0.32644      0.00029    0.32689     0.32599
Alpha_loss                            -6.20816     0.02701    -6.15547    -6.24020
Training/policy_loss                  -81.08436    0.32800    -80.32953   -81.60808
Training/qf1_loss                     702.70492    277.92244  1187.65540  304.85318
Training/qf2_loss                     695.27752    278.07459  1178.33643  296.69818
Training/pf_norm                      0.19647      0.02543    0.24625     0.16320
Training/qf1_norm                     336.77166    190.99489  543.92316   60.37778
Training/qf2_norm                     333.68790    192.67536  550.19275   53.71059
log_std/mean                          -0.30178     0.00037    -0.30128    -0.30241
log_std/std                           0.14855      0.00032    0.14922     0.14808
log_std/max                           -0.13230     0.00239    -0.12948    -0.13641
log_std/min                           -0.81370     0.00887    -0.79761    -0.82881
log_probs/mean                        -1.57791     0.02658    -1.52949    -1.60921
log_probs/std                         1.90643      0.02581    1.94025     1.86193
log_probs/max                         6.60628      0.22167    6.93430     6.21261
log_probs/min                         -6.57578     0.55854    -5.72610    -7.55655
mean/mean                             0.10195      0.00049    0.10249     0.10080
mean/std                              0.60734      0.00209    0.61076     0.60388
mean/max                              1.80054      0.00429    1.80575     1.79235
mean/min                              -1.71074     0.00851    -1.69780    -1.72532
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 6, 5, 7, 4, 1, 9, 2, 3, 0]
replay_buffer._size: [57150 57150 57150 57150 57150 57150 57150 57150 57150 57150]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.379762887954712 0.002094745635986328
train_time 7.383261442184448
2023-09-06 14:38:07,284 MainThread INFO: EPOCH:379
2023-09-06 14:38:07,284 MainThread INFO: Time Consumed:12.658355474472046s
2023-09-06 14:38:07,285 MainThread INFO: Total Frames:570000s
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 380/400 [44:46<04:17, 12.89s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1042.69404
Train_Epoch_Reward                    11864.90643
Running_Training_Average_Rewards      1094.17222
Explore_Time                          5.26347
Train___Time                          7.38326
Eval____Time                          0.00665
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.11879
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.59772
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.92015
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.28458
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.56253
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.44308
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.50046
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9473.48408
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.77424
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1515.15610
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.92375      0.42482    5.74838     4.41174
alpha_0                               0.38818      0.00011    0.38835     0.38801
alpha_1                               0.32908      0.00025    0.32948     0.32869
alpha_2                               0.32630      0.00028    0.32674     0.32587
alpha_3                               0.32238      0.00029    0.32283     0.32193
alpha_4                               0.32598      0.00027    0.32639     0.32556
alpha_5                               0.32379      0.00028    0.32423     0.32335
alpha_6                               0.32372      0.00028    0.32416     0.32328
alpha_7                               0.33490      0.00029    0.33535     0.33445
alpha_8                               0.32660      0.00026    0.32701     0.32619
alpha_9                               0.32544      0.00029    0.32589     0.32499
Alpha_loss                            -6.19393     0.03753    -6.14442    -6.25365
Training/policy_loss                  -81.35686    0.37266    -80.52013   -81.84750
Training/qf1_loss                     657.04735    195.53240  1107.41565  373.73480
Training/qf2_loss                     649.61358    195.00086  1098.18372  366.26123
Training/pf_norm                      0.21555      0.04876    0.30748     0.16129
Training/qf1_norm                     191.91524    142.40708  480.83243   58.90258
Training/qf2_norm                     193.39984    141.58446  483.59497   55.92355
log_std/mean                          -0.30205     0.00048    -0.30120    -0.30259
log_std/std                           0.14952      0.00066    0.15071     0.14862
log_std/max                           -0.12952     0.00066    -0.12776    -0.13046
log_std/min                           -0.81441     0.00953    -0.80019    -0.83578
log_probs/mean                        -1.54731     0.03691    -1.49807    -1.60789
log_probs/std                         1.95738      0.03166    1.99519     1.88228
log_probs/max                         6.78391      0.29173    7.44811     6.35565
log_probs/min                         -6.70771     0.69106    -5.61771    -7.63251
mean/mean                             0.10256      0.00079    0.10350     0.10125
mean/std                              0.61748      0.00397    0.62334     0.61151
mean/max                              1.81390      0.01321    1.83818     1.78835
mean/min                              -1.75935     0.01983    -1.72304    -1.79006
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 0, 2, 5, 3, 1, 7, 8, 9, 4]
replay_buffer._size: [57300 57300 57300 57300 57300 57300 57300 57300 57300 57300]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.946522951126099 0.0026183128356933594
train_time 12.9506995677948
2023-09-06 14:38:20,363 MainThread INFO: EPOCH:380
2023-09-06 14:38:20,364 MainThread INFO: Time Consumed:12.974719047546387s
2023-09-06 14:38:20,364 MainThread INFO: Total Frames:571500s
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 381/400 [45:00<04:06, 12.95s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1050.13187
Train_Epoch_Reward                    13028.95135
Running_Training_Average_Rewards      1218.38558
Explore_Time                          0.00327
Train___Time                          12.95070
Eval____Time                          0.00944
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.79586
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.88986
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.42764
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.32083
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.15438
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.48207
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.60513
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9600.57587
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.89198
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1481.20187
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.97730      0.52006    5.70990     4.23607
alpha_0                               0.38783      0.00009    0.38798     0.38769
alpha_1                               0.32822      0.00025    0.32861     0.32783
alpha_2                               0.32535      0.00027    0.32578     0.32491
alpha_3                               0.32139      0.00028    0.32183     0.32094
alpha_4                               0.32505      0.00027    0.32546     0.32463
alpha_5                               0.32282      0.00028    0.32326     0.32238
alpha_6                               0.32274      0.00028    0.32318     0.32230
alpha_7                               0.33390      0.00029    0.33435     0.33345
alpha_8                               0.32570      0.00026    0.32610     0.32530
alpha_9                               0.32444      0.00029    0.32489     0.32399
Alpha_loss                            -6.19548     0.03842    -6.14151    -6.27313
Training/policy_loss                  -81.62907    0.41660    -81.08445   -82.37319
Training/qf1_loss                     724.90638    198.60373  1178.10510  411.84320
Training/qf2_loss                     717.51051    197.80306  1169.89160  407.39825
Training/pf_norm                      0.19047      0.02511    0.24111     0.15811
Training/qf1_norm                     245.12745    158.31365  519.36407   59.08817
Training/qf2_norm                     245.59706    159.93592  517.63776   60.51045
log_std/mean                          -0.30188     0.00052    -0.30096    -0.30252
log_std/std                           0.15123      0.00047    0.15195     0.15061
log_std/max                           -0.13192     0.00075    -0.13085    -0.13312
log_std/min                           -0.82522     0.00619    -0.81820    -0.83661
log_probs/mean                        -1.53209     0.03735    -1.47511    -1.61145
log_probs/std                         1.99807      0.02730    2.05152     1.95488
log_probs/max                         6.83345      0.31502    7.40830     6.21896
log_probs/min                         -6.65212     0.99680    -6.00579    -9.56919
mean/mean                             0.10391      0.00082    0.10503     0.10182
mean/std                              0.62603      0.00183    0.62821     0.62345
mean/max                              1.82532      0.00519    1.82957     1.81507
mean/min                              -1.80070     0.00751    -1.78603    -1.80969
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 8, 6, 1, 9, 3, 2, 5, 4, 0]
replay_buffer._size: [57450 57450 57450 57450 57450 57450 57450 57450 57450 57450]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.183167934417725 0.0020384788513183594
train_time 13.18644642829895
2023-09-06 14:38:33,689 MainThread INFO: EPOCH:381
2023-09-06 14:38:33,689 MainThread INFO: Time Consumed:13.207909345626831s
2023-09-06 14:38:33,689 MainThread INFO: Total Frames:573000s
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 382/400 [45:13<03:55, 13.06s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1056.11551
Train_Epoch_Reward                    12753.21451
Running_Training_Average_Rewards      1254.90241
Explore_Time                          0.01228
Train___Time                          13.18645
Eval____Time                          0.00509
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.53876
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.16326
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.71638
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.28214
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.95699
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.68399
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.82009
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9626.60980
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.02202
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1437.39063
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.87550      0.46714    5.72548     3.89760
alpha_0                               0.38754      0.00008    0.38766     0.38742
alpha_1                               0.32735      0.00025    0.32774     0.32696
alpha_2                               0.32439      0.00027    0.32482     0.32396
alpha_3                               0.32040      0.00028    0.32084     0.31995
alpha_4                               0.32412      0.00027    0.32454     0.32370
alpha_5                               0.32185      0.00028    0.32228     0.32141
alpha_6                               0.32176      0.00028    0.32220     0.32132
alpha_7                               0.33291      0.00029    0.33335     0.33246
alpha_8                               0.32481      0.00025    0.32521     0.32441
alpha_9                               0.32345      0.00029    0.32389     0.32300
Alpha_loss                            -6.20814     0.03060    -6.15429    -6.25194
Training/policy_loss                  -81.96886    0.24163    -81.61657   -82.51514
Training/qf1_loss                     717.05220    226.08787  1147.11169  340.87094
Training/qf2_loss                     707.85398    225.68351  1137.16821  332.47516
Training/pf_norm                      0.18624      0.03109    0.25877     0.15209
Training/qf1_norm                     217.06098    97.52293   423.60110   94.43402
Training/qf2_norm                     222.53685    92.28266   421.92020   111.70724
log_std/mean                          -0.30035     0.00054    -0.29958    -0.30129
log_std/std                           0.15193      0.00028    0.15227     0.15133
log_std/max                           -0.12765     0.00181    -0.12519    -0.13099
log_std/min                           -0.82620     0.00729    -0.81556    -0.83880
log_probs/mean                        -1.52724     0.02789    -1.47776    -1.57046
log_probs/std                         2.02653      0.02607    2.06823     1.98478
log_probs/max                         6.90826      0.21529    7.21861     6.61833
log_probs/min                         -7.01796     1.06750    -5.77865    -8.59115
mean/mean                             0.09926      0.00191    0.10262     0.09689
mean/std                              0.62739      0.00085    0.62880     0.62543
mean/max                              1.81182      0.01052    1.82693     1.79343
mean/min                              -1.80123     0.00476    -1.79451    -1.81021
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 2, 5, 1, 7, 8, 6, 9, 0, 4]
replay_buffer._size: [57600 57600 57600 57600 57600 57600 57600 57600 57600 57600]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.194246530532837 0.0020210742950439453
train_time 13.197490215301514
2023-09-06 14:38:47,000 MainThread INFO: EPOCH:382
2023-09-06 14:38:47,001 MainThread INFO: Time Consumed:13.20924711227417s
2023-09-06 14:38:47,001 MainThread INFO: Total Frames:574500s
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 383/400 [45:26<03:43, 13.18s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1054.17519
Train_Epoch_Reward                    11459.93929
Running_Training_Average_Rewards      1241.40351
Explore_Time                          0.00531
Train___Time                          13.19749
Eval____Time                          0.00255
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.26877
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.07237
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.60461
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.74437
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.88449
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.86472
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.05808
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9561.56111
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.66462
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1374.82983
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.37634      0.44011    4.88879    3.68128
alpha_0                               0.38726      0.00008    0.38739    0.38713
alpha_1                               0.32647      0.00025    0.32687    0.32608
alpha_2                               0.32344      0.00027    0.32386    0.32301
alpha_3                               0.31941      0.00028    0.31985    0.31897
alpha_4                               0.32320      0.00026    0.32361    0.32278
alpha_5                               0.32088      0.00028    0.32131    0.32044
alpha_6                               0.32078      0.00028    0.32122    0.32034
alpha_7                               0.33191      0.00029    0.33236    0.33146
alpha_8                               0.32393      0.00025    0.32433    0.32354
alpha_9                               0.32245      0.00028    0.32290    0.32201
Alpha_loss                            -6.24226     0.03694    -6.17703   -6.29688
Training/policy_loss                  -82.31114    0.30069    -81.95671  -82.88675
Training/qf1_loss                     528.98089    134.13076  713.51477  348.95493
Training/qf2_loss                     521.05068    134.72574  707.17755  341.70508
Training/pf_norm                      0.20868      0.03490    0.27908    0.16184
Training/qf1_norm                     176.52670    141.95080  418.50528  46.36116
Training/qf2_norm                     174.26274    134.48752  396.48706  51.65502
log_std/mean                          -0.29959     0.00086    -0.29874   -0.30134
log_std/std                           0.15150      0.00023    0.15180    0.15117
log_std/max                           -0.12561     0.00151    -0.12240   -0.12750
log_std/min                           -0.82418     0.00857    -0.81469   -0.84289
log_probs/mean                        -1.54652     0.03421    -1.49391   -1.60251
log_probs/std                         1.97972      0.04550    2.04456    1.91351
log_probs/max                         6.99701      0.33191    7.63454    6.47089
log_probs/min                         -6.48068     0.43925    -5.71086   -7.01632
mean/mean                             0.09552      0.00062    0.09679    0.09467
mean/std                              0.62922      0.00283    0.63469    0.62531
mean/max                              1.78359      0.00804    1.79425    1.77209
mean/min                              -1.79784     0.00837    -1.79058   -1.81467
------------------------------------  -----------  ---------  ---------  ---------
sample: [9, 7, 1, 3, 6, 8, 0, 5, 2, 4]
replay_buffer._size: [57750 57750 57750 57750 57750 57750 57750 57750 57750 57750]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 7.281566619873047 0.0020585060119628906
train_time 7.28484845161438
2023-09-06 14:39:00,813 MainThread INFO: EPOCH:383
2023-09-06 14:39:00,814 MainThread INFO: Time Consumed:7.337172269821167s
2023-09-06 14:39:00,814 MainThread INFO: Total Frames:576000s
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 384/400 [45:40<03:33, 13.33s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1050.28501
Train_Epoch_Reward                    9231.22956
Running_Training_Average_Rewards      1114.81278
Explore_Time                          0.04292
Train___Time                          7.28485
Eval____Time                          0.00538
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.12694
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.89912
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.17937
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85683
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.31532
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.09002
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.47802
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9601.65452
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.00627
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1372.80198
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.92147     0.63891    6.16054     3.86756
alpha_0                               0.38699     0.00007    0.38711     0.38688
alpha_1                               0.32560     0.00025    0.32599     0.32520
alpha_2                               0.32248     0.00027    0.32291     0.32205
alpha_3                               0.31843     0.00028    0.31887     0.31799
alpha_4                               0.32228     0.00026    0.32269     0.32187
alpha_5                               0.31991     0.00028    0.32034     0.31948
alpha_6                               0.31981     0.00028    0.32025     0.31937
alpha_7                               0.33091     0.00029    0.33136     0.33046
alpha_8                               0.32306     0.00025    0.32345     0.32266
alpha_9                               0.32146     0.00028    0.32191     0.32102
Alpha_loss                            -6.23067    0.03470    -6.17911    -6.29295
Training/policy_loss                  -82.15199   0.35378    -81.59325   -82.63315
Training/qf1_loss                     720.31099   266.23414  1188.12292  371.57562
Training/qf2_loss                     712.20362   265.83937  1180.76611  365.46622
Training/pf_norm                      0.22339     0.04834    0.31349     0.17273
Training/qf1_norm                     285.38523   212.94454  781.39917   61.84760
Training/qf2_norm                     285.91631   214.71975  778.82898   58.52681
log_std/mean                          -0.30263    0.00042    -0.30188    -0.30335
log_std/std                           0.15198     0.00033    0.15256     0.15148
log_std/max                           -0.13149    0.00218    -0.12816    -0.13549
log_std/min                           -0.82502    0.00978    -0.80911    -0.83994
log_probs/mean                        -1.51714    0.03020    -1.47275    -1.57124
log_probs/std                         2.07030     0.05404    2.13545     1.96409
log_probs/max                         7.20272     0.28838    7.59707     6.76443
log_probs/min                         -7.28740    0.67746    -6.02746    -8.09233
mean/mean                             0.09463     0.00113    0.09671     0.09267
mean/std                              0.63819     0.00159    0.64047     0.63556
mean/max                              1.80790     0.01427    1.82730     1.78725
mean/min                              -1.83098    0.01024    -1.81357    -1.84428
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 1, 0, 6, 7, 2, 8, 5, 9, 4]
replay_buffer._size: [57900 57900 57900 57900 57900 57900 57900 57900 57900 57900]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.689201593399048 0.002206087112426758
train_time 8.69351077079773
2023-09-06 14:39:14,292 MainThread INFO: EPOCH:384
2023-09-06 14:39:14,293 MainThread INFO: Time Consumed:13.35164999961853s
2023-09-06 14:39:14,293 MainThread INFO: Total Frames:577500s
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 385/400 [45:53<03:20, 13.38s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1043.22046
Train_Epoch_Reward                    13672.16087
Running_Training_Average_Rewards      1145.44432
Explore_Time                          4.48741
Train___Time                          8.69351
Eval____Time                          0.00544
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.44224
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.45333
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.06613
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.49987
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.86465
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.31838
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.75203
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9467.54044
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.69093
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1399.42727
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.53146      0.88305    6.68412     3.24249
alpha_0                               0.38676      0.00006    0.38686     0.38667
alpha_1                               0.32472      0.00025    0.32511     0.32433
alpha_2                               0.32153      0.00027    0.32196     0.32110
alpha_3                               0.31745      0.00028    0.31789     0.31701
alpha_4                               0.32137      0.00026    0.32178     0.32096
alpha_5                               0.31895      0.00028    0.31938     0.31852
alpha_6                               0.31884      0.00028    0.31928     0.31841
alpha_7                               0.32991      0.00029    0.33036     0.32947
alpha_8                               0.32218      0.00025    0.32257     0.32179
alpha_9                               0.32048      0.00028    0.32092     0.32003
Alpha_loss                            -6.22172     0.04294    -6.12670    -6.28343
Training/policy_loss                  -82.67403    0.33167    -82.05818   -83.20241
Training/qf1_loss                     632.35338    286.86429  1263.41345  296.26056
Training/qf2_loss                     624.67352    286.42680  1255.09717  289.50873
Training/pf_norm                      0.21664      0.02298    0.27046     0.18560
Training/qf1_norm                     260.00258    260.90684  920.01215   55.41150
Training/qf2_norm                     258.50527    255.46090  914.21185   57.58316
log_std/mean                          -0.30396     0.00031    -0.30325    -0.30447
log_std/std                           0.15364      0.00054    0.15446     0.15273
log_std/max                           -0.13367     0.00178    -0.13028    -0.13619
log_std/min                           -0.82763     0.00869    -0.81174    -0.83927
log_probs/mean                        -1.49246     0.03881    -1.40772    -1.54663
log_probs/std                         2.10784      0.02402    2.13971     2.06096
log_probs/max                         7.44608      0.15879    7.81561     7.25997
log_probs/min                         -7.13105     0.68776    -6.29345    -8.25217
mean/mean                             0.09123      0.00092    0.09292     0.08976
mean/std                              0.64203      0.00059    0.64289     0.64062
mean/max                              1.84134      0.01075    1.85198     1.81759
mean/min                              -1.85439     0.00625    -1.83838    -1.86073
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 0, 2, 6, 8, 3, 1, 4, 9, 5]
replay_buffer._size: [58050 58050 58050 58050 58050 58050 58050 58050 58050 58050]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.157914876937866 0.0023813247680664062
train_time 8.16158151626587
2023-09-06 14:39:26,945 MainThread INFO: EPOCH:385
2023-09-06 14:39:26,945 MainThread INFO: Time Consumed:12.521709442138672s
2023-09-06 14:39:26,946 MainThread INFO: Total Frames:579000s
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 386/400 [46:06<03:04, 13.15s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1033.33910
Train_Epoch_Reward                    10664.04369
Running_Training_Average_Rewards      1118.91447
Explore_Time                          4.21796
Train___Time                          8.16158
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.52712
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.50718
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.18629
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.12295
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.50889
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.49025
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.62004
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9320.39083
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.63572
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1323.99583
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.96240      0.74375    6.13516     3.75954
alpha_0                               0.38657      0.00005    0.38665     0.38649
alpha_1                               0.32384      0.00025    0.32424     0.32345
alpha_2                               0.32057      0.00027    0.32100     0.32015
alpha_3                               0.31647      0.00028    0.31691     0.31604
alpha_4                               0.32046      0.00026    0.32087     0.32005
alpha_5                               0.31799      0.00027    0.31842     0.31756
alpha_6                               0.31788      0.00027    0.31831     0.31745
alpha_7                               0.32892      0.00029    0.32937     0.32847
alpha_8                               0.32130      0.00025    0.32170     0.32091
alpha_9                               0.31949      0.00028    0.31994     0.31905
Alpha_loss                            -6.24532     0.03805    -6.18636    -6.29354
Training/policy_loss                  -82.81229    0.32026    -82.20335   -83.21116
Training/qf1_loss                     822.69535    230.92794  1093.49695  334.56436
Training/qf2_loss                     813.86819    230.19448  1084.40503  327.73819
Training/pf_norm                      0.20192      0.03401    0.26134     0.15337
Training/qf1_norm                     346.97578    163.16130  701.51038   67.52558
Training/qf2_norm                     344.22401    157.22218  693.79974   86.94453
log_std/mean                          -0.30171     0.00092    -0.30008    -0.30313
log_std/std                           0.15471      0.00037    0.15510     0.15383
log_std/max                           -0.12877     0.00148    -0.12599    -0.13060
log_std/min                           -0.82524     0.00978    -0.80845    -0.84488
log_probs/mean                        -1.49873     0.03753    -1.44023    -1.54351
log_probs/std                         2.10206      0.04877    2.19922     2.04958
log_probs/max                         7.49140      0.33562    7.99225     7.00356
log_probs/min                         -7.69816     1.40702    -5.75057    -11.08059
mean/mean                             0.08816      0.00188    0.09078     0.08474
mean/std                              0.63851      0.00175    0.64156     0.63500
mean/max                              1.84977      0.00773    1.85944     1.83665
mean/min                              -1.84364     0.00692    -1.83361    -1.85482
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 9, 2, 6, 1, 4, 0, 3, 8, 7]
replay_buffer._size: [58200 58200 58200 58200 58200 58200 58200 58200 58200 58200]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.137602090835571 0.0021979808807373047
train_time 13.141108274459839
2023-09-06 14:39:40,204 MainThread INFO: EPOCH:386
2023-09-06 14:39:40,205 MainThread INFO: Time Consumed:13.150559186935425s
2023-09-06 14:39:40,205 MainThread INFO: Total Frames:580500s
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 387/400 [46:19<02:51, 13.19s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1011.05477
Train_Epoch_Reward                    13485.37211
Running_Training_Average_Rewards      1260.71922
Explore_Time                          0.00283
Train___Time                          13.14111
Eval____Time                          0.00249
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.82357
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.92826
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.26343
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.55499
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.44862
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.49139
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.34176
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9072.97031
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.98794
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1224.84436
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.67944      0.49254    5.75173     4.03169
alpha_0                               0.38640      0.00005    0.38648     0.38633
alpha_1                               0.32296      0.00025    0.32336     0.32257
alpha_2                               0.31963      0.00027    0.32005     0.31920
alpha_3                               0.31550      0.00028    0.31594     0.31507
alpha_4                               0.31955      0.00026    0.31996     0.31914
alpha_5                               0.31703      0.00027    0.31746     0.31660
alpha_6                               0.31693      0.00027    0.31736     0.31650
alpha_7                               0.32793      0.00028    0.32837     0.32748
alpha_8                               0.32042      0.00025    0.32082     0.32003
alpha_9                               0.31852      0.00028    0.31896     0.31808
Alpha_loss                            -6.28030     0.02680    -6.22994    -6.32390
Training/policy_loss                  -82.83860    0.27453    -82.32030   -83.19414
Training/qf1_loss                     669.45941    207.95526  1015.97443  350.91351
Training/qf2_loss                     661.32202    207.40152  1007.25439  344.00952
Training/pf_norm                      0.20583      0.02344    0.24466     0.15162
Training/qf1_norm                     217.14739    165.87081  612.33569   68.64871
Training/qf2_norm                     217.60096    165.61843  610.36060   71.34012
log_std/mean                          -0.29858     0.00039    -0.29815    -0.29952
log_std/std                           0.15508      0.00019    0.15533     0.15464
log_std/max                           -0.12680     0.00056    -0.12591    -0.12772
log_std/min                           -0.82280     0.01002    -0.80736    -0.84310
log_probs/mean                        -1.51667     0.02566    -1.46280    -1.55576
log_probs/std                         2.08166      0.03366    2.12056     2.00583
log_probs/max                         7.45947      0.35076    7.89214     6.76912
log_probs/min                         -6.57965     0.77141    -5.67262    -8.53961
mean/mean                             0.08165      0.00176    0.08448     0.07875
mean/std                              0.63648      0.00101    0.63817     0.63448
mean/max                              1.82832      0.00733    1.83890     1.81469
mean/min                              -1.84535     0.00661    -1.83154    -1.85293
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 9, 6, 2, 5, 7, 1, 3, 8, 0]
replay_buffer._size: [58350 58350 58350 58350 58350 58350 58350 58350 58350 58350]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.630701065063477 0.0023446083068847656
train_time 13.634333610534668
2023-09-06 14:39:53,961 MainThread INFO: EPOCH:387
2023-09-06 14:39:53,962 MainThread INFO: Time Consumed:13.647300720214844s
2023-09-06 14:39:53,962 MainThread INFO: Total Frames:582000s
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 388/400 [46:33<02:40, 13.37s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               989.39024
Train_Epoch_Reward                    11169.01863
Running_Training_Average_Rewards      1177.28115
Explore_Time                          0.00283
Train___Time                          13.63433
Eval____Time                          0.00562
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.76992
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.56660
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.01333
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.26479
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.75758
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.69715
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.14033
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9044.21048
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.82760
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1177.77096
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.47188      0.59831    5.78333     3.59289
alpha_0                               0.38624      0.00005    0.38631     0.38616
alpha_1                               0.32208      0.00026    0.32248     0.32167
alpha_2                               0.31868      0.00027    0.31910     0.31825
alpha_3                               0.31453      0.00028    0.31497     0.31410
alpha_4                               0.31865      0.00026    0.31905     0.31824
alpha_5                               0.31608      0.00027    0.31651     0.31565
alpha_6                               0.31598      0.00027    0.31640     0.31555
alpha_7                               0.32694      0.00028    0.32738     0.32649
alpha_8                               0.31955      0.00025    0.31994     0.31915
alpha_9                               0.31755      0.00028    0.31798     0.31711
Alpha_loss                            -6.28448     0.03194    -6.21805    -6.32054
Training/policy_loss                  -83.10490    0.41649    -82.57272   -84.02840
Training/qf1_loss                     648.29029    287.56894  1243.64172  335.80200
Training/qf2_loss                     639.82296    285.96483  1230.64978  330.87778
Training/pf_norm                      0.22500      0.02884    0.27465     0.17338
Training/qf1_norm                     224.19681    164.39243  623.53217   67.82663
Training/qf2_norm                     224.28919    163.83182  631.22144   62.14936
log_std/mean                          -0.29867     0.00028    -0.29827    -0.29910
log_std/std                           0.15504      0.00026    0.15537     0.15462
log_std/max                           -0.12787     0.00129    -0.12619    -0.13019
log_std/min                           -0.82657     0.00825    -0.81141    -0.83842
log_probs/mean                        -1.50504     0.02622    -1.45009    -1.53753
log_probs/std                         2.09750      0.03519    2.15021     2.02715
log_probs/max                         7.53593      0.19220    7.94013     7.31004
log_probs/min                         -7.16167     0.88987    -6.09153    -9.34788
mean/mean                             0.07512      0.00259    0.07840     0.07091
mean/std                              0.64023      0.00150    0.64261     0.63720
mean/max                              1.81498      0.00610    1.82236     1.80116
mean/min                              -1.87327     0.00837    -1.85480    -1.88517
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 2, 7, 0, 6, 8, 9, 1, 5, 3]
replay_buffer._size: [58500 58500 58500 58500 58500 58500 58500 58500 58500 58500]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 8.358307123184204 0.0021064281463623047
train_time 8.36180329322815
2023-09-06 14:40:07,870 MainThread INFO: EPOCH:388
2023-09-06 14:40:07,870 MainThread INFO: Time Consumed:13.769065141677856s
2023-09-06 14:40:07,871 MainThread INFO: Total Frames:583500s
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 389/400 [46:47<02:28, 13.52s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               979.76540
Train_Epoch_Reward                    12597.69930
Running_Training_Average_Rewards      1241.73633
Explore_Time                          5.39577
Train___Time                          8.36180
Eval____Time                          0.00620
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.25378
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.97970
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.33644
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.74630
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.67173
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.07895
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.91589
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9147.08181
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.57273
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1209.51691
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.16987      0.46012    4.94403    3.57699
alpha_0                               0.38608      0.00004    0.38615    0.38601
alpha_1                               0.32118      0.00026    0.32158    0.32077
alpha_2                               0.31773      0.00027    0.31816    0.31731
alpha_3                               0.31357      0.00028    0.31400    0.31314
alpha_4                               0.31774      0.00026    0.31815    0.31734
alpha_5                               0.31513      0.00027    0.31556    0.31470
alpha_6                               0.31503      0.00027    0.31546    0.31461
alpha_7                               0.32595      0.00028    0.32640    0.32551
alpha_8                               0.31867      0.00025    0.31906    0.31827
alpha_9                               0.31658      0.00028    0.31701    0.31615
Alpha_loss                            -6.30013     0.02767    -6.24991   -6.35227
Training/policy_loss                  -82.92248    0.27281    -82.43981  -83.29060
Training/qf1_loss                     516.18251    143.37200  735.25671  234.06494
Training/qf2_loss                     507.96932    143.14673  726.21936  225.85904
Training/pf_norm                      0.26761      0.03828    0.32504    0.21625
Training/qf1_norm                     186.12457    86.68394   344.33884  64.42647
Training/qf2_norm                     181.07094    86.56268   344.81680  68.64050
log_std/mean                          -0.29789     0.00086    -0.29620   -0.29882
log_std/std                           0.15456      0.00038    0.15505    0.15393
log_std/max                           -0.11907     0.00306    -0.11444   -0.12343
log_std/min                           -0.81828     0.00712    -0.80894   -0.83281
log_probs/mean                        -1.50445     0.02488    -1.45519   -1.54920
log_probs/std                         2.08571      0.04145    2.16587    2.00917
log_probs/max                         7.46079      0.18862    7.72698    7.18615
log_probs/min                         -6.58976     0.52397    -5.47135   -7.35176
mean/mean                             0.05663      0.00773    0.06817    0.04407
mean/std                              0.63846      0.00162    0.64043    0.63587
mean/max                              1.77089      0.02213    1.80407    1.73602
mean/min                              -1.88256     0.00534    -1.86996   -1.88823
------------------------------------  -----------  ---------  ---------  ---------
sample: [3, 4, 9, 6, 5, 2, 7, 0, 1, 8]
replay_buffer._size: [58650 58650 58650 58650 58650 58650 58650 58650 58650 58650]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 12.94496464729309 0.0020287036895751953
train_time 12.94823169708252
2023-09-06 14:40:20,945 MainThread INFO: EPOCH:389
2023-09-06 14:40:20,946 MainThread INFO: Time Consumed:12.958428382873535s
2023-09-06 14:40:20,946 MainThread INFO: Total Frames:585000s
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 390/400 [47:00<02:13, 13.39s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               973.70308
Train_Epoch_Reward                    10489.23418
Running_Training_Average_Rewards      1141.86507
Explore_Time                          0.00303
Train___Time                          12.94823
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.22089
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.23988
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.42365
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.63436
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.06792
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.05193
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.93681
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9006.37176
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.82348
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1137.13219
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           4.47213      0.64252    5.40083    3.46134
alpha_0                               0.38591      0.00006    0.38600    0.38582
alpha_1                               0.32027      0.00026    0.32068    0.31986
alpha_2                               0.31678      0.00027    0.31721    0.31636
alpha_3                               0.31261      0.00028    0.31304    0.31218
alpha_4                               0.31685      0.00026    0.31725    0.31645
alpha_5                               0.31418      0.00027    0.31461    0.31376
alpha_6                               0.31410      0.00027    0.31452    0.31368
alpha_7                               0.32497      0.00028    0.32541    0.32452
alpha_8                               0.31778      0.00026    0.31818    0.31738
alpha_9                               0.31563      0.00027    0.31606    0.31520
Alpha_loss                            -6.35407     0.04360    -6.28380   -6.43298
Training/policy_loss                  -83.11249    0.36292    -82.67641  -83.75300
Training/qf1_loss                     558.23734    212.11560  904.89709  270.27374
Training/qf2_loss                     549.89458    211.22816  895.91797  262.99380
Training/pf_norm                      0.23016      0.05374    0.33422    0.13872
Training/qf1_norm                     300.02391    144.17860  557.17883  107.02071
Training/qf2_norm                     299.34778    143.56056  557.56329  107.46992
log_std/mean                          -0.29362     0.00085    -0.29285   -0.29536
log_std/std                           0.15266      0.00073    0.15399    0.15154
log_std/max                           -0.11014     0.00174    -0.10677   -0.11247
log_std/min                           -0.80644     0.00982    -0.78922   -0.81957
log_probs/mean                        -1.54252     0.04032    -1.48448   -1.62289
log_probs/std                         2.01395      0.03846    2.06775    1.92756
log_probs/max                         7.24726      0.27034    7.77226    6.86941
log_probs/min                         -6.80060     1.05074    -5.73063   -9.27424
mean/mean                             0.02845      0.00701    0.04008    0.01774
mean/std                              0.63306      0.00121    0.63533    0.63162
mean/max                              1.72766      0.00430    1.73421    1.71929
mean/min                              -1.87996     0.00712    -1.87093   -1.88999
------------------------------------  -----------  ---------  ---------  ---------
sample: [5, 0, 6, 1, 7, 3, 2, 9, 8, 4]
replay_buffer._size: [58800 58800 58800 58800 58800 58800 58800 58800 58800 58800]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.13482928276062 0.002011537551879883
train_time 13.138134717941284
2023-09-06 14:40:34,205 MainThread INFO: EPOCH:390
2023-09-06 14:40:34,206 MainThread INFO: Time Consumed:13.149945259094238s
2023-09-06 14:40:34,206 MainThread INFO: Total Frames:586500s
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 391/400 [47:13<02:00, 13.35s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               961.53800
Train_Epoch_Reward                    10135.83489
Running_Training_Average_Rewards      1107.42561
Explore_Time                          0.00338
Train___Time                          13.13813
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.74662
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.90052
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.57381
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.52024
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.97976
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.22995
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.61096
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8939.21683
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.33585
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           955.67251
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.69445      0.81975    6.13262     3.74211
alpha_0                               0.38570      0.00007    0.38580     0.38559
alpha_1                               0.31936      0.00026    0.31977     0.31894
alpha_2                               0.31584      0.00027    0.31626     0.31541
alpha_3                               0.31165      0.00027    0.31208     0.31122
alpha_4                               0.31596      0.00026    0.31636     0.31556
alpha_5                               0.31324      0.00027    0.31367     0.31282
alpha_6                               0.31317      0.00026    0.31359     0.31276
alpha_7                               0.32398      0.00028    0.32443     0.32354
alpha_8                               0.31689      0.00026    0.31729     0.31648
alpha_9                               0.31469      0.00027    0.31511     0.31427
Alpha_loss                            -6.38528     0.02559    -6.31973    -6.41721
Training/policy_loss                  -83.70344    0.32335    -83.10133   -84.13290
Training/qf1_loss                     690.19004    287.23526  1238.44312  354.01251
Training/qf2_loss                     682.44531    286.09477  1227.39221  347.17291
Training/pf_norm                      0.18326      0.03301    0.27051     0.14508
Training/qf1_norm                     310.30791    275.00279  824.66339   68.50358
Training/qf2_norm                     308.18899    269.04465  815.91284   77.56725
log_std/mean                          -0.29537     0.00124    -0.29349    -0.29710
log_std/std                           0.15085      0.00055    0.15162     0.14980
log_std/max                           -0.11927     0.00508    -0.11226    -0.12717
log_std/min                           -0.80018     0.00938    -0.78461    -0.81455
log_probs/mean                        -1.55586     0.02208    -1.50363    -1.58209
log_probs/std                         2.02476      0.03019    2.06947     1.97671
log_probs/max                         7.28877      0.35109    7.70722     6.54463
log_probs/min                         -7.03688     0.84638    -5.88628    -9.00230
mean/mean                             0.01315      0.00212    0.01703     0.00946
mean/std                              0.63528      0.00127    0.63722     0.63313
mean/max                              1.74837      0.01215    1.76732     1.72500
mean/min                              -1.90124     0.00633    -1.88858    -1.90868
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 6, 8, 9, 7, 2, 5, 4, 1, 3]
replay_buffer._size: [58950 58950 58950 58950 58950 58950 58950 58950 58950 58950]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.2529296875 0.0021390914916992188
train_time 13.256296634674072
2023-09-06 14:40:47,586 MainThread INFO: EPOCH:391
2023-09-06 14:40:47,587 MainThread INFO: Time Consumed:13.277002096176147s
2023-09-06 14:40:47,587 MainThread INFO: Total Frames:588000s
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 392/400 [47:27<01:46, 13.36s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               941.59550
Train_Epoch_Reward                    10109.76620
Running_Training_Average_Rewards      1024.49451
Explore_Time                          0.00288
Train___Time                          13.25630
Eval____Time                          0.01354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.37577
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.81769
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.92442
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.04327
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.24361
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.94188
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.30777
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8905.31065
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.11104
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           905.22312
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.89487      0.66931    6.09397     3.98032
alpha_0                               0.38547      0.00006    0.38557     0.38538
alpha_1                               0.31844      0.00026    0.31885     0.31802
alpha_2                               0.31489      0.00027    0.31531     0.31446
alpha_3                               0.31070      0.00027    0.31113     0.31027
alpha_4                               0.31507      0.00026    0.31547     0.31466
alpha_5                               0.31230      0.00027    0.31272     0.31188
alpha_6                               0.31225      0.00026    0.31266     0.31184
alpha_7                               0.32300      0.00028    0.32344     0.32256
alpha_8                               0.31599      0.00026    0.31639     0.31558
alpha_9                               0.31376      0.00027    0.31417     0.31334
Alpha_loss                            -6.37197     0.04459    -6.28786    -6.44383
Training/policy_loss                  -83.87996    0.47405    -83.14268   -84.72801
Training/qf1_loss                     800.32149    317.34254  1563.23511  464.35748
Training/qf2_loss                     791.38989    316.61649  1553.33960  455.27081
Training/pf_norm                      0.20763      0.04380    0.29607     0.15913
Training/qf1_norm                     358.23784    242.06465  800.98071   90.30556
Training/qf2_norm                     357.82299    240.32062  799.19086   86.47446
log_std/mean                          -0.29888     0.00045    -0.29797    -0.29943
log_std/std                           0.15000      0.00059    0.15104     0.14903
log_std/max                           -0.12925     0.00191    -0.12613    -0.13259
log_std/min                           -0.79906     0.00673    -0.79137    -0.81263
log_probs/mean                        -1.52721     0.04146    -1.45557    -1.59557
log_probs/std                         2.05890      0.04485    2.12868     1.97404
log_probs/max                         7.20657      0.27805    7.58336     6.74855
log_probs/min                         -6.63290     0.67768    -5.60631    -7.84117
mean/mean                             0.01030      0.00076    0.01125     0.00914
mean/std                              0.63573      0.00224    0.63903     0.63199
mean/max                              1.76988      0.00520    1.78277     1.76579
mean/min                              -1.88112     0.01585    -1.85235    -1.90327
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 6, 5, 7, 3, 2, 0, 4, 8, 9]
replay_buffer._size: [59100 59100 59100 59100 59100 59100 59100 59100 59100 59100]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.260355949401855 0.0028820037841796875
train_time 13.264589309692383
2023-09-06 14:41:00,980 MainThread INFO: EPOCH:392
2023-09-06 14:41:00,981 MainThread INFO: Time Consumed:13.284187316894531s
2023-09-06 14:41:00,982 MainThread INFO: Total Frames:589500s
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 393/400 [47:40<01:33, 13.37s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               929.76338
Train_Epoch_Reward                    11121.16712
Running_Training_Average_Rewards      1045.55894
Explore_Time                          0.00295
Train___Time                          13.26459
Eval____Time                          0.01248
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.05276
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.74494
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.00584
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.19707
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.87618
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.88279
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.02915
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8938.57934
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.29650
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           886.64749
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.17999      0.75773    6.67403     4.08679
alpha_0                               0.38525      0.00007    0.38536     0.38514
alpha_1                               0.31752      0.00027    0.31793     0.31710
alpha_2                               0.31394      0.00027    0.31436     0.31351
alpha_3                               0.30975      0.00027    0.31017     0.30932
alpha_4                               0.31417      0.00026    0.31457     0.31377
alpha_5                               0.31137      0.00027    0.31179     0.31095
alpha_6                               0.31134      0.00026    0.31175     0.31093
alpha_7                               0.32203      0.00028    0.32247     0.32159
alpha_8                               0.31509      0.00026    0.31549     0.31468
alpha_9                               0.31283      0.00027    0.31325     0.31241
Alpha_loss                            -6.43108     0.02011    -6.39040    -6.45699
Training/policy_loss                  -84.23277    0.36629    -83.62785   -84.78958
Training/qf1_loss                     843.71728    419.36280  1858.55591  382.24631
Training/qf2_loss                     834.63465    417.47928  1845.14771  375.80368
Training/pf_norm                      0.20948      0.03515    0.27421     0.16210
Training/qf1_norm                     397.18669    306.03748  1069.71851  82.69373
Training/qf2_norm                     399.54323    305.09017  1068.16016  84.70892
log_std/mean                          -0.29742     0.00058    -0.29665    -0.29861
log_std/std                           0.14962      0.00090    0.15124     0.14856
log_std/max                           -0.12762     0.00194    -0.12415    -0.13149
log_std/min                           -0.80542     0.01102    -0.78493    -0.82963
log_probs/mean                        -1.56901     0.01935    -1.52996    -1.59672
log_probs/std                         2.00062      0.02529    2.03180     1.95598
log_probs/max                         6.98803      0.29352    7.41006     6.34631
log_probs/min                         -6.99774     1.38610    -5.70719    -10.54900
mean/mean                             0.01257      0.00246    0.01669     0.00944
mean/std                              0.62889      0.00064    0.62997     0.62788
mean/max                              1.75455      0.00878    1.76649     1.73202
mean/min                              -1.82406     0.01241    -1.80621    -1.85310
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 2, 3, 5, 9, 6, 8, 7, 0, 1]
replay_buffer._size: [59250 59250 59250 59250 59250 59250 59250 59250 59250 59250]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.926809549331665 0.002098560333251953
train_time 13.930184602737427
2023-09-06 14:41:15,033 MainThread INFO: EPOCH:393
2023-09-06 14:41:15,033 MainThread INFO: Time Consumed:13.951256275177002s
2023-09-06 14:41:15,034 MainThread INFO: Total Frames:591000s
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 394/400 [47:54<01:21, 13.58s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               930.57435
Train_Epoch_Reward                    10035.19540
Running_Training_Average_Rewards      1042.20429
Explore_Time                          0.00812
Train___Time                          13.93018
Eval____Time                          0.00881
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.90754
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.52025
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.75229
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.97672
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.99244
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.18109
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.24782
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9000.46465
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.28401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           923.71812
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.50086      0.60042    5.58307     3.67466
alpha_0                               0.38501      0.00007    0.38511     0.38491
alpha_1                               0.31659      0.00027    0.31701     0.31617
alpha_2                               0.31299      0.00027    0.31342     0.31257
alpha_3                               0.30880      0.00027    0.30923     0.30837
alpha_4                               0.31328      0.00025    0.31368     0.31289
alpha_5                               0.31043      0.00027    0.31085     0.31001
alpha_6                               0.31042      0.00026    0.31083     0.31001
alpha_7                               0.32106      0.00028    0.32149     0.32063
alpha_8                               0.31419      0.00026    0.31459     0.31378
alpha_9                               0.31191      0.00026    0.31232     0.31149
Alpha_loss                            -6.39116     0.03427    -6.34182    -6.44931
Training/policy_loss                  -84.67058    0.36897    -84.12486   -85.32134
Training/qf1_loss                     697.54417    317.95898  1506.81274  347.55133
Training/qf2_loss                     689.36708    317.32549  1495.92712  338.64990
Training/pf_norm                      0.21422      0.02897    0.27490     0.18058
Training/qf1_norm                     233.95029    143.44412  476.25827   66.63519
Training/qf2_norm                     231.15656    142.52180  487.20169   68.08861
log_std/mean                          -0.30168     0.00150    -0.29938    -0.30380
log_std/std                           0.15305      0.00082    0.15429     0.15189
log_std/max                           -0.12781     0.00082    -0.12627    -0.12889
log_std/min                           -0.82064     0.01170    -0.80331    -0.83980
log_probs/mean                        -1.51468     0.03196    -1.47655    -1.57424
log_probs/std                         2.07461      0.05089    2.17719     1.99871
log_probs/max                         7.43318      0.13795    7.69121     7.15208
log_probs/min                         -7.42220     0.94542    -6.33270    -9.45999
mean/mean                             0.02623      0.00495    0.03351     0.01913
mean/std                              0.63533      0.00309    0.64006     0.63130
mean/max                              1.77800      0.01269    1.79855     1.76035
mean/min                              -1.83782     0.00980    -1.82490    -1.85522
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 6, 3, 1, 7, 0, 5, 9, 4, 2]
replay_buffer._size: [59400 59400 59400 59400 59400 59400 59400 59400 59400 59400]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.345077514648438 0.0028481483459472656
train_time 13.350091695785522
2023-09-06 14:41:28,528 MainThread INFO: EPOCH:394
2023-09-06 14:41:28,529 MainThread INFO: Time Consumed:13.367228269577026s
2023-09-06 14:41:28,529 MainThread INFO: Total Frames:592500s
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 395/400 [48:08<01:07, 13.55s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               936.15406
Train_Epoch_Reward                    9145.83694
Running_Training_Average_Rewards      1010.07332
Explore_Time                          0.00598
Train___Time                          13.35009
Eval____Time                          0.00591
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.14992
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.15078
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.00071
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.56912
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.38892
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.36647
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.76067
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9012.76350
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.32096
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           956.10355
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.73557     0.42878    5.54171     4.27993
alpha_0                               0.38481     0.00005    0.38489     0.38474
alpha_1                               0.31567     0.00026    0.31608     0.31525
alpha_2                               0.31205     0.00027    0.31248     0.31163
alpha_3                               0.30785     0.00027    0.30828     0.30743
alpha_4                               0.31240     0.00025    0.31280     0.31201
alpha_5                               0.30950     0.00027    0.30992     0.30909
alpha_6                               0.30951     0.00026    0.30992     0.30910
alpha_7                               0.32010     0.00028    0.32053     0.31966
alpha_8                               0.31329     0.00026    0.31369     0.31289
alpha_9                               0.31098     0.00027    0.31140     0.31057
Alpha_loss                            -6.39237    0.04652    -6.29858    -6.44452
Training/policy_loss                  -84.65113   0.58463    -83.27869   -85.66374
Training/qf1_loss                     747.29141   217.81869  1080.93872  401.51151
Training/qf2_loss                     738.32359   217.31531  1069.87988  393.11777
Training/pf_norm                      0.23517     0.03541    0.30548     0.17957
Training/qf1_norm                     196.46600   141.72237  513.59778   57.81910
Training/qf2_norm                     200.96760   141.60166  511.73462   73.20528
log_std/mean                          -0.30493    0.00050    -0.30414    -0.30565
log_std/std                           0.15455     0.00044    0.15542     0.15361
log_std/max                           -0.12543    0.00085    -0.12436    -0.12694
log_std/min                           -0.82955    0.00780    -0.81613    -0.84186
log_probs/mean                        -1.49886    0.04264    -1.40559    -1.54355
log_probs/std                         2.11658     0.05442    2.21091     2.04717
log_probs/max                         7.72193     0.28803    8.16612     7.25749
log_probs/min                         -6.84106    0.94668    -5.50966    -9.42766
mean/mean                             0.03936     0.00248    0.04199     0.03533
mean/std                              0.64449     0.00250    0.64792     0.64017
mean/max                              1.81234     0.00837    1.82473     1.79521
mean/min                              -1.87730    0.01020    -1.85899    -1.88881
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 4, 8, 0, 6, 1, 7, 2, 5, 9]
replay_buffer._size: [59550 59550 59550 59550 59550 59550 59550 59550 59550 59550]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.532135725021362 0.002351045608520508
train_time 13.535715341567993
2023-09-06 14:41:42,201 MainThread INFO: EPOCH:395
2023-09-06 14:41:42,201 MainThread INFO: Time Consumed:13.562721729278564s
2023-09-06 14:41:42,202 MainThread INFO: Total Frames:594000s
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 396/400 [48:21<00:54, 13.59s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               939.52912
Train_Epoch_Reward                    12622.57331
Running_Training_Average_Rewards      1060.12019
Explore_Time                          0.02003
Train___Time                          13.53572
Eval____Time                          0.00279
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.39325
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.49786
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.66519
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.60983
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.23414
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.14307
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.01881
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8941.96053
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.35153
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           984.34665
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.24678      0.79738    6.50658     4.25764
alpha_0                               0.38467      0.00004    0.38473     0.38461
alpha_1                               0.31475      0.00026    0.31516     0.31433
alpha_2                               0.31112      0.00027    0.31154     0.31070
alpha_3                               0.30691      0.00027    0.30734     0.30649
alpha_4                               0.31152      0.00025    0.31192     0.31113
alpha_5                               0.30858      0.00027    0.30899     0.30816
alpha_6                               0.30860      0.00026    0.30901     0.30819
alpha_7                               0.31914      0.00028    0.31957     0.31870
alpha_8                               0.31241      0.00025    0.31280     0.31201
alpha_9                               0.31006      0.00027    0.31047     0.30964
Alpha_loss                            -6.41883     0.02914    -6.37710    -6.47482
Training/policy_loss                  -85.01621    0.48256    -84.08848   -85.81172
Training/qf1_loss                     879.75692    356.37413  1411.79541  438.57950
Training/qf2_loss                     870.41227    355.11629  1399.81348  431.93408
Training/pf_norm                      0.23139      0.03347    0.28185     0.18695
Training/qf1_norm                     371.56142    298.58060  878.83301   60.24150
Training/qf2_norm                     372.27652    297.94706  869.16473   62.01239
log_std/mean                          -0.30341     0.00072    -0.30205    -0.30421
log_std/std                           0.15402      0.00037    0.15453     0.15339
log_std/max                           -0.12526     0.00078    -0.12429    -0.12677
log_std/min                           -0.83124     0.01204    -0.81472    -0.85133
log_probs/mean                        -1.50749     0.02625    -1.46946    -1.55853
log_probs/std                         2.11660      0.04183    2.16928     2.05533
log_probs/max                         7.50088      0.29502    7.90106     7.09516
log_probs/min                         -6.68780     1.01844    -5.55701    -8.44765
mean/mean                             0.03951      0.00135    0.04141     0.03726
mean/std                              0.64455      0.00167    0.64657     0.64122
mean/max                              1.80453      0.00995    1.82368     1.78780
mean/min                              -1.87955     0.00852    -1.86451    -1.89396
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 7, 2, 1, 4, 3, 0, 6, 5, 8]
replay_buffer._size: [59700 59700 59700 59700 59700 59700 59700 59700 59700 59700]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 13.54462718963623 0.002146482467651367
train_time 13.548173904418945
2023-09-06 14:41:55,878 MainThread INFO: EPOCH:396
2023-09-06 14:41:55,878 MainThread INFO: Time Consumed:13.566999197006226s
2023-09-06 14:41:55,879 MainThread INFO: Total Frames:595500s
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 397/400 [48:35<00:40, 13.62s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               950.66965
Train_Epoch_Reward                    10111.72717
Running_Training_Average_Rewards      1062.67125
Explore_Time                          0.00265
Train___Time                          13.54817
Eval____Time                          0.01094
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.56371
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.11889
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.37939
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -37.82792
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.62004
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.31737
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.22503
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9110.89697
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.63946
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1137.33126
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.89323      0.54700    5.84584     3.66839
alpha_0                               0.38452      0.00005    0.38460     0.38444
alpha_1                               0.31383      0.00027    0.31424     0.31341
alpha_2                               0.31018      0.00027    0.31060     0.30976
alpha_3                               0.30597      0.00027    0.30639     0.30555
alpha_4                               0.31065      0.00025    0.31104     0.31025
alpha_5                               0.30765      0.00026    0.30807     0.30724
alpha_6                               0.30769      0.00026    0.30810     0.30728
alpha_7                               0.31818      0.00027    0.31861     0.31776
alpha_8                               0.31153      0.00025    0.31192     0.31114
alpha_9                               0.30914      0.00026    0.30955     0.30872
Alpha_loss                            -6.45840     0.04117    -6.40517    -6.56926
Training/policy_loss                  -85.20043    0.53956    -84.28773   -86.16768
Training/qf1_loss                     641.91461    215.14752  1068.24707  307.80978
Training/qf2_loss                     633.35016    214.49898  1058.31543  300.90625
Training/pf_norm                      0.21825      0.03930    0.32530     0.18249
Training/qf1_norm                     245.93267    163.55422  611.94855   71.53742
Training/qf2_norm                     245.27460    160.04728  599.38831   74.47878
log_std/mean                          -0.29919     0.00132    -0.29759    -0.30126
log_std/std                           0.15169      0.00053    0.15256     0.15063
log_std/max                           -0.12157     0.00267    -0.11566    -0.12474
log_std/min                           -0.82738     0.01047    -0.81400    -0.84542
log_probs/mean                        -1.53369     0.03885    -1.48113    -1.63596
log_probs/std                         2.04232      0.06432    2.15651     1.92330
log_probs/max                         7.19345      0.25349    7.69698     6.82313
log_probs/min                         -6.78617     0.63128    -5.99565    -7.86265
mean/mean                             0.03801      0.00229    0.04353     0.03584
mean/std                              0.63390      0.00232    0.63812     0.63033
mean/max                              1.77660      0.00686    1.78977     1.76662
mean/min                              -1.82334     0.01691    -1.80163    -1.85268
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 3, 0, 5, 7, 1, 9, 2, 4, 6]
replay_buffer._size: [59850 59850 59850 59850 59850 59850 59850 59850 59850 59850]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 11.519171476364136 0.002195119857788086
train_time 11.522683382034302
2023-09-06 14:42:09,563 MainThread INFO: EPOCH:397
2023-09-06 14:42:09,563 MainThread INFO: Time Consumed:13.563335418701172s
2023-09-06 14:42:09,563 MainThread INFO: Total Frames:597000s
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 398/400 [48:49<00:27, 13.64s/it]first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               983.88806
Train_Epoch_Reward                    11735.04495
Running_Training_Average_Rewards      1148.97818
Explore_Time                          2.03339
Train___Time                          11.52268
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.96109
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.91641
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -59.68613
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.31000
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.13471
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.24590
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.31321
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9589.84183
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.91074
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1357.34836
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.60365      1.01401    6.85061     3.46585
alpha_0                               0.38433      0.00006    0.38442     0.38424
alpha_1                               0.31290      0.00026    0.31332     0.31249
alpha_2                               0.30925      0.00027    0.30967     0.30883
alpha_3                               0.30504      0.00027    0.30546     0.30461
alpha_4                               0.30977      0.00025    0.31017     0.30938
alpha_5                               0.30673      0.00027    0.30714     0.30631
alpha_6                               0.30678      0.00026    0.30719     0.30637
alpha_7                               0.31724      0.00027    0.31766     0.31682
alpha_8                               0.31066      0.00025    0.31105     0.31027
alpha_9                               0.30821      0.00027    0.30863     0.30779
Alpha_loss                            -6.48005     0.03155    -6.42675    -6.54640
Training/policy_loss                  -85.62508    0.38806    -84.99818   -86.14792
Training/qf1_loss                     676.42199    356.98251  1524.59375  302.22153
Training/qf2_loss                     668.22808    356.73817  1516.37183  293.29205
Training/pf_norm                      0.21859      0.03258    0.26234     0.16470
Training/qf1_norm                     350.52272    257.57195  1039.76965  62.80403
Training/qf2_norm                     343.71120    256.02770  1031.54919  66.13398
log_std/mean                          -0.29662     0.00035    -0.29609    -0.29722
log_std/std                           0.15227      0.00040    0.15297     0.15142
log_std/max                           -0.11489     0.00209    -0.11022    -0.11760
log_std/min                           -0.83127     0.00673    -0.82071    -0.84373
log_probs/mean                        -1.53557     0.02968    -1.48648    -1.59692
log_probs/std                         2.06186      0.03459    2.11043     1.97596
log_probs/max                         7.35182      0.25532    7.80021     7.00292
log_probs/min                         -6.50040     0.46959    -5.90446    -7.57115
mean/mean                             0.05258      0.00610    0.06155     0.04362
mean/std                              0.63423      0.00135    0.63634     0.63133
mean/max                              1.81573      0.01831    1.84876     1.78998
mean/min                              -1.81394     0.00603    -1.80416    -1.82440
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 2, 7, 4, 5, 1, 3, 6, 9, 8]
replay_buffer._size: [60000 60000 60000 60000 60000 60000 60000 60000 60000 60000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 6.80989933013916 0.002169370651245117
train_time 6.813409090042114
2023-09-06 14:42:16,502 MainThread INFO: EPOCH:398
2023-09-06 14:42:16,503 MainThread INFO: Time Consumed:6.823983192443848s
2023-09-06 14:42:16,503 MainThread INFO: Total Frames:598500s
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 399/400 [48:56<00:11, 11.63s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1030.02652
Train_Epoch_Reward                    11341.35573
Running_Training_Average_Rewards      1106.27093
Explore_Time                          0.00297
Train___Time                          6.81341
Eval____Time                          0.00343
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.59556
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.39029
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.59537
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.68512
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.30079
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.71400
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.19486
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9763.39136
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.93013
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1494.56202
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           4.82381      0.69887    5.98369     3.84687
alpha_0                               0.38415      0.00004    0.38423     0.38409
alpha_1                               0.31198      0.00026    0.31240     0.31157
alpha_2                               0.30832      0.00027    0.30873     0.30790
alpha_3                               0.30410      0.00027    0.30452     0.30368
alpha_4                               0.30890      0.00025    0.30929     0.30851
alpha_5                               0.30581      0.00026    0.30622     0.30539
alpha_6                               0.30587      0.00026    0.30628     0.30546
alpha_7                               0.31630      0.00027    0.31672     0.31588
alpha_8                               0.30979      0.00025    0.31018     0.30940
alpha_9                               0.30729      0.00027    0.30770     0.30687
Alpha_loss                            -6.47243     0.04425    -6.39328    -6.54122
Training/policy_loss                  -85.65591    0.46084    -84.82962   -86.36625
Training/qf1_loss                     803.63657    304.45384  1371.15344  488.83588
Training/qf2_loss                     795.18627    304.18637  1365.25269  481.37094
Training/pf_norm                      0.22568      0.04704    0.29536     0.15098
Training/qf1_norm                     311.98448    189.04768  734.53082   89.06478
Training/qf2_norm                     309.31685    192.55090  743.71008   84.37868
log_std/mean                          -0.29745     0.00043    -0.29678    -0.29813
log_std/std                           0.15339      0.00031    0.15376     0.15271
log_std/max                           -0.11256     0.00118    -0.11065    -0.11436
log_std/min                           -0.83005     0.00930    -0.81714    -0.84534
log_probs/mean                        -1.51135     0.04079    -1.44166    -1.57373
log_probs/std                         2.12331      0.04218    2.18778     2.04439
log_probs/max                         7.50148      0.28552    7.95905     6.90329
log_probs/min                         -6.76781     0.71714    -5.80395    -8.10702
mean/mean                             0.07219      0.00480    0.07878     0.06426
mean/std                              0.63671      0.00092    0.63802     0.63545
mean/max                              1.84735      0.00485    1.85754     1.84207
mean/min                              -1.82667     0.00432    -1.81874    -1.83376
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 8, 5, 0, 2, 9, 6, 3, 1, 7]
replay_buffer._size: [60000 60000 60000 60000 60000 60000 60000 60000 60000 60000]
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
obs.device cpu
policy_device_masks.device cpu
diff1,diff2 0.6532771587371826 0.001958608627319336
train_time 0.6564679145812988
2023-09-06 14:42:17,277 MainThread INFO: EPOCH:399
2023-09-06 14:42:17,277 MainThread INFO: Time Consumed:0.6643884181976318s
2023-09-06 14:42:17,277 MainThread INFO: Total Frames:600000s
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [48:56<00:00,  8.37s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [48:56<00:00,  7.34s/it]
------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1054.32073
Train_Epoch_Reward                    12247.93920
Running_Training_Average_Rewards      1177.47800
Explore_Time                          0.00212
Train___Time                          0.65647
Eval____Time                          0.00188
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.16721
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.89580
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.86086
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.84856
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.06510
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.36751
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.05352
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9467.89831
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.42881
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1473.15159
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.05717      0.87515    6.68814     3.78182
alpha_0                               0.38401      0.00004    0.38407     0.38395
alpha_1                               0.31107      0.00026    0.31148     0.31065
alpha_2                               0.30739      0.00026    0.30780     0.30697
alpha_3                               0.30317      0.00027    0.30359     0.30275
alpha_4                               0.30803      0.00025    0.30842     0.30764
alpha_5                               0.30489      0.00026    0.30530     0.30448
alpha_6                               0.30495      0.00026    0.30537     0.30454
alpha_7                               0.31536      0.00027    0.31578     0.31493
alpha_8                               0.30893      0.00025    0.30932     0.30854
alpha_9                               0.30636      0.00027    0.30678     0.30594
Alpha_loss                            -6.49341     0.02615    -6.45114    -6.55015
Training/policy_loss                  -85.88525    0.32114    -85.19977   -86.32138
Training/qf1_loss                     771.56643    255.68209  1183.70776  367.16876
Training/qf2_loss                     762.28705    255.27493  1172.84338  359.14383
Training/pf_norm                      0.21415      0.04070    0.30566     0.15699
Training/qf1_norm                     387.30407    308.83741  1041.67908  54.44348
Training/qf2_norm                     385.52983    307.18858  1030.94934  64.17877
log_std/mean                          -0.29982     0.00082    -0.29863    -0.30127
log_std/std                           0.15546      0.00077    0.15690     0.15420
log_std/max                           -0.11471     0.00109    -0.11273    -0.11660
log_std/min                           -0.84603     0.00871    -0.83260    -0.85795
log_probs/mean                        -1.51638     0.02345    -1.47718    -1.56857
log_probs/std                         2.11318      0.03435    2.16540     2.05415
log_probs/max                         7.55419      0.17547    7.89328     7.28947
log_probs/min                         -6.68958     0.45172    -5.94519    -7.43379
mean/mean                             0.08314      0.00119    0.08496     0.08106
mean/std                              0.63637      0.00091    0.63821     0.63527
mean/max                              1.83318      0.00834    1.85065     1.81978
mean/min                              -1.82801     0.00347    -1.82358    -1.83411
------------------------------------  -----------  ---------  ----------  ---------
snapshot at finish
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                    0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    8 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    9 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                           Alpha_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                         Eval____Time ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb:                         Explore_Time ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          Reward_Mean ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ
wandb:              Running_Average_Rewards ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
wandb:     Running_Training_Average_Rewards ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:                   Train_Epoch_Reward ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá
wandb:                         Train___Time ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÑ‚ñà‚ñà‚ñà‚ñÅ
wandb:                     Training/pf_norm ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ
wandb:                 Training/policy_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                    Training/qf1_loss ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:                    Training/qf1_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñá
wandb:                    Training/qf2_loss ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:                    Training/qf2_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñá
wandb:                              alpha_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_1 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_2 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_3 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_4 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_5 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_6 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_7 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_8 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_9 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: button-press-topdown-v1_eval_rewards ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: button-press-topdown-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 door-v1_eval_rewards ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:                 door-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         drawer-close-v1_eval_rewards ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb:         drawer-close-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          drawer-open-v1_eval_rewards ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          drawer-open-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        log_probs/max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:                       log_probs/mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                        log_probs/min ‚ñà‚ñÉ‚ñà‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ
wandb:                        log_probs/std ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:                          log_std/max ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:                         log_std/mean ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          log_std/min ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                          log_std/std ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                             mean/max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                            mean/mean ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                             mean/min ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                             mean/std ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                    mean_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      ped-insert-side-v1_eval_rewards ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      ped-insert-side-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           pick-place-v1_eval_rewards ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñà‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:           pick-place-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 push-v1_eval_rewards ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 push-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                reach-v1_eval_rewards ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                reach-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                    save_traj_mod_sum ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                   task_policy_mask_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_8 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_9 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         window-close-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ
wandb:         window-close-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          window-open-v1_eval_rewards ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:          window-open-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                    0 0.0
wandb:                                    1 0.0
wandb:                                    2 0.0
wandb:                                    3 0.0
wandb:                                    4 0.0
wandb:                                    5 0.0
wandb:                                    6 0.0
wandb:                                    7 0.0
wandb:                                    8 0.0
wandb:                                    9 0.0
wandb:                           Alpha_loss -6.45114
wandb:                         Eval____Time 0.00188
wandb:                         Explore_Time 0.00212
wandb:                          Reward_Mean 5.71856
wandb:              Running_Average_Rewards 1054.32073
wandb:     Running_Training_Average_Rewards 1177.478
wandb:                   Train_Epoch_Reward 12247.9392
wandb:                         Train___Time 0.65647
wandb:                     Training/pf_norm 0.21984
wandb:                 Training/policy_loss -86.0023
wandb:                    Training/qf1_loss 943.55927
wandb:                    Training/qf1_norm 625.21185
wandb:                    Training/qf2_loss 934.92169
wandb:                    Training/qf2_norm 620.03162
wandb:                              alpha_0 0.38395
wandb:                              alpha_1 0.31065
wandb:                              alpha_2 0.30697
wandb:                              alpha_3 0.30275
wandb:                              alpha_4 0.30764
wandb:                              alpha_5 0.30448
wandb:                              alpha_6 0.30454
wandb:                              alpha_7 0.31493
wandb:                              alpha_8 0.30854
wandb:                              alpha_9 0.30594
wandb: button-press-topdown-v1_eval_rewards -74.16721
wandb: button-press-topdown-v1_success_rate 0.0
wandb:                 door-v1_eval_rewards -60.8958
wandb:                 door-v1_success_rate 0.0
wandb:         drawer-close-v1_eval_rewards -58.86086
wandb:         drawer-close-v1_success_rate 0.0
wandb:          drawer-open-v1_eval_rewards -16.84856
wandb:          drawer-open-v1_success_rate 0.0
wandb:                        log_probs/max 7.48176
wandb:                       log_probs/mean -1.47718
wandb:                        log_probs/min -6.87576
wandb:                        log_probs/std 2.05415
wandb:                          log_std/max -0.11507
wandb:                         log_std/mean -0.30127
wandb:                          log_std/min -0.85595
wandb:                          log_std/std 0.1569
wandb:                             mean/max 1.82881
wandb:                            mean/mean 0.08334
wandb:                             mean/min -1.82656
wandb:                             mean/std 0.63682
wandb:                    mean_success_rate 0.0
wandb:      ped-insert-side-v1_eval_rewards -75.0651
wandb:      ped-insert-side-v1_success_rate 0.0
wandb:           pick-place-v1_eval_rewards -83.36751
wandb:           pick-place-v1_success_rate 0.0
wandb:                 push-v1_eval_rewards -71.05352
wandb:                 push-v1_success_rate 0.0
wandb:                reach-v1_eval_rewards 9467.89831
wandb:                reach-v1_success_rate 0.0
wandb:                    save_traj_mod_sum 1
wandb:                   task_policy_mask_0 64
wandb:                   task_policy_mask_1 67
wandb:                   task_policy_mask_2 78
wandb:                   task_policy_mask_3 77
wandb:                   task_policy_mask_4 76
wandb:                   task_policy_mask_5 53
wandb:                   task_policy_mask_6 59
wandb:                   task_policy_mask_7 93
wandb:                   task_policy_mask_8 62
wandb:                   task_policy_mask_9 70
wandb:         window-close-v1_eval_rewards -59.42881
wandb:         window-close-v1_success_rate 0.0
wandb:          window-open-v1_eval_rewards 1473.15159
wandb:          window-open-v1_success_rate 0.0
wandb: 
wandb: üöÄ View run azure-universe-366 at: https://wandb.ai/liqianxi/dst_mtrl/runs/4wwda43c
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20230906_135313-4wwda43c/logs
3172 seconds elapsed.
