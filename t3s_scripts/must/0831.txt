W&B enabled.
2023-08-31 20:37:14,827 MainThread INFO: Experiment Name:testing_must_mtsac
2023-08-31 20:37:14,827 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      20,
      20
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      20,
      20
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      20,
      20
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.9
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 50,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "success_traj_update_only": 1,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 2,
    "mask_update_interval": 3,
    "update_end_epoch": 50,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
wandb: Currently logged in as: liqianxi. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/qianxi/t3s/t3s_code/wandb/run-20230831_203902-zj56k7td
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-resonance-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/liqianxi/dst_mtrl
wandb: üöÄ View run at https://wandb.ai/liqianxi/dst_mtrl/runs/zj56k7td
2023-08-31 20:39:04,196 MainThread INFO: Finished Pretrain
  0%|          | 0/50 [00:00<?, ?it/s]sample: [6, 5, 0, 3, 9, 8, 4, 2, 1, 7]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
train_time 1.8560082912445068
eval_infos
eval time 10.709327936172485
snapshot at best
2023-08-31 20:39:17,719 MainThread INFO: EPOCH:0
2023-08-31 20:39:17,720 MainThread INFO: Time Consumed:13.277986526489258s
2023-08-31 20:39:17,720 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:374: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  2%|‚ñè         | 1/50 [00:14<11:51, 14.52s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1138.03990
Train_Epoch_Reward                    1879.33478
Running_Training_Average_Rewards      187.93348
Explore_Time                          0.05798
Train___Time                          1.85601
Eval____Time                          10.70933
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.30327
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.57344
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.64056
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.93069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14610
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89363
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.96914
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11629.43774
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.68584
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.89604
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.40781      0.17099   6.57880    6.23682
alpha_0                               0.99955      0.00015   0.99970    0.99940
alpha_1                               0.99955      0.00015   0.99970    0.99940
alpha_2                               0.99955      0.00015   0.99970    0.99940
alpha_3                               0.99955      0.00015   0.99970    0.99940
alpha_4                               0.99955      0.00015   0.99970    0.99940
alpha_5                               0.99955      0.00015   0.99970    0.99940
alpha_6                               0.99955      0.00015   0.99970    0.99940
alpha_7                               0.99955      0.00015   0.99970    0.99940
alpha_8                               0.99955      0.00015   0.99970    0.99940
alpha_9                               0.99955      0.00015   0.99970    0.99940
Alpha_loss                            -0.00100     0.00100   -0.00000   -0.00201
Training/policy_loss                  -2.68254     0.00129   -2.68126   -2.68383
Training/qf1_loss                     777.20078    61.62772  838.82849  715.57306
Training/qf2_loss                     777.23761    61.62842  838.86603  715.60919
Training/pf_norm                      0.42655      0.01480   0.44136    0.41175
Training/qf1_norm                     18.13519     0.33534   18.47053   17.79985
Training/qf2_norm                     18.18538     0.34067   18.52606   17.84471
log_std/mean                          0.00056      0.00018   0.00074    0.00038
log_std/std                           0.00210      0.00000   0.00210    0.00209
log_std/max                           0.00307      0.00021   0.00327    0.00286
log_std/min                           -0.00354     0.00021   -0.00333   -0.00375
log_probs/mean                        -2.68548     0.00151   -2.68397   -2.68698
log_probs/std                         0.43899      0.00642   0.44541    0.43256
log_probs/max                         -1.32551     0.06914   -1.25638   -1.39465
log_probs/min                         -5.34773     0.52718   -4.82054   -5.87491
mean/mean                             -0.00051     0.00000   -0.00051   -0.00051
mean/std                              0.00137      0.00013   0.00150    0.00124
mean/max                              0.00185      0.00018   0.00203    0.00167
mean/min                              -0.00262     0.00018   -0.00244   -0.00281
------------------------------------  -----------  --------  ---------  ---------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [0, 3, 4, 8, 5, 1, 6, 7, 2, 9]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
train_time 0.3228282928466797
eval_infos
eval time 0.0030546188354492188
2023-08-31 20:39:19,132 MainThread INFO: EPOCH:1
2023-08-31 20:39:19,133 MainThread INFO: Time Consumed:0.3383166790008545s
2023-08-31 20:39:19,133 MainThread INFO: Total Frames:3000s
  4%|‚ñç         | 2/50 [00:15<05:00,  6.26s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1137.88493
Train_Epoch_Reward                    17435.14585
Running_Training_Average_Rewards      965.72403
Explore_Time                          0.00438
Train___Time                          0.32283
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.40265
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.57344
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.64056
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.93069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14610
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89363
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.96914
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11629.43774
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.68584
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.89604
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.62046      0.54929   7.16976    6.07117
alpha_0                               0.99895      0.00015   0.99910    0.99880
alpha_1                               0.99895      0.00015   0.99910    0.99880
alpha_2                               0.99895      0.00015   0.99910    0.99880
alpha_3                               0.99895      0.00015   0.99910    0.99880
alpha_4                               0.99895      0.00015   0.99910    0.99880
alpha_5                               0.99895      0.00015   0.99910    0.99880
alpha_6                               0.99895      0.00015   0.99910    0.99880
alpha_7                               0.99895      0.00015   0.99910    0.99880
alpha_8                               0.99895      0.00015   0.99910    0.99880
alpha_9                               0.99895      0.00015   0.99910    0.99880
Alpha_loss                            -0.00501     0.00100   -0.00401   -0.00600
Training/policy_loss                  -2.67032     0.00256   -2.66776   -2.67288
Training/qf1_loss                     762.65909    58.20761  820.86670  704.45148
Training/qf2_loss                     762.69623    58.20972  820.90594  704.48651
Training/pf_norm                      0.46630      0.01224   0.47853    0.45406
Training/qf1_norm                     18.60753     1.09717   19.70470   17.51036
Training/qf2_norm                     18.66762     1.09991   19.76753   17.56771
log_std/mean                          -0.00016     0.00018   0.00002    -0.00034
log_std/std                           0.00210      0.00000   0.00210    0.00210
log_std/max                           0.00227      0.00020   0.00247    0.00208
log_std/min                           -0.00436     0.00020   -0.00416   -0.00456
log_probs/mean                        -2.67412     0.00234   -2.67178   -2.67647
log_probs/std                         0.43777      0.01266   0.45042    0.42511
log_probs/max                         -1.22528     0.06165   -1.16363   -1.28693
log_probs/min                         -3.78355     0.10236   -3.68118   -3.88591
mean/mean                             -0.00070     0.00007   -0.00063   -0.00077
mean/std                              0.00156      0.00001   0.00157    0.00154
mean/max                              0.00203      0.00006   0.00209    0.00197
mean/min                              -0.00300     0.00010   -0.00289   -0.00310
------------------------------------  -----------  --------  ---------  ---------
sample: [1, 0, 7, 6, 4, 9, 3, 8, 5, 2]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
train_time 0.2314167022705078
eval_infos
eval time 0.007009029388427734
2023-08-31 20:39:19,501 MainThread INFO: EPOCH:2
2023-08-31 20:39:19,502 MainThread INFO: Time Consumed:0.24884867668151855s
2023-08-31 20:39:19,503 MainThread INFO: Total Frames:4500s
  6%|‚ñå         | 3/50 [00:15<02:47,  3.57s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1137.85401
Train_Epoch_Reward                    10512.62719
Running_Training_Average_Rewards      994.23693
Explore_Time                          0.00319
Train___Time                          0.23142
Eval____Time                          0.00701
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.78073
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.57344
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.64056
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.93069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14610
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89363
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.96914
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11629.43774
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.68584
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.89604
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.27150      0.80788    8.07939     6.46362
alpha_0                               0.99835      0.00015    0.99850     0.99820
alpha_1                               0.99835      0.00015    0.99850     0.99820
alpha_2                               0.99835      0.00015    0.99850     0.99820
alpha_3                               0.99835      0.00015    0.99850     0.99820
alpha_4                               0.99835      0.00015    0.99850     0.99820
alpha_5                               0.99835      0.00015    0.99850     0.99820
alpha_6                               0.99835      0.00015    0.99850     0.99820
alpha_7                               0.99835      0.00015    0.99850     0.99820
alpha_8                               0.99835      0.00015    0.99850     0.99820
alpha_9                               0.99835      0.00015    0.99850     0.99820
Alpha_loss                            -0.00902     0.00099    -0.00803    -0.01001
Training/policy_loss                  -2.67828     0.01135    -2.66692    -2.68963
Training/qf1_loss                     1035.64032   274.02008  1309.66040  761.62024
Training/qf2_loss                     1035.67941   274.02322  1309.70264  761.65619
Training/pf_norm                      0.43365      0.00408    0.43773     0.42957
Training/qf1_norm                     19.93540     1.65402    21.58942    18.28139
Training/qf2_norm                     20.00575     1.65815    21.66390    18.34760
log_std/mean                          -0.00088     0.00018    -0.00070    -0.00106
log_std/std                           0.00210      0.00000    0.00210     0.00210
log_std/max                           0.00148      0.00020    0.00168     0.00128
log_std/min                           -0.00517     0.00021    -0.00497    -0.00538
log_probs/mean                        -2.68297     0.01115    -2.67182    -2.69412
log_probs/std                         0.43052      0.00303    0.43355     0.42748
log_probs/max                         -1.28741     0.12331    -1.16409    -1.41072
log_probs/min                         -3.85503     0.01370    -3.84134    -3.86873
mean/mean                             -0.00092     0.00004    -0.00087    -0.00096
mean/std                              0.00158      0.00002    0.00161     0.00156
mean/max                              0.00177      0.00005    0.00183     0.00172
mean/min                              -0.00313     0.00004    -0.00310    -0.00317
------------------------------------  -----------  ---------  ----------  ---------
start to update mask
sample: [5, 2, 0, 8, 6, 1, 9, 4, 7, 3]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
train_time 0.1409754753112793
eval_infos
eval time 0.004080533981323242
2023-08-31 20:39:24,850 MainThread INFO: EPOCH:3
2023-08-31 20:39:24,851 MainThread INFO: Time Consumed:0.15656781196594238s
2023-08-31 20:39:24,851 MainThread INFO: Total Frames:6000s
  8%|‚ñä         | 4/50 [00:20<03:16,  4.28s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1136.40945
Train_Epoch_Reward                    12487.40575
Running_Training_Average_Rewards      1347.83929
Explore_Time                          0.00595
Train___Time                          0.14098
Eval____Time                          0.00408
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.96893
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.64040
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.60946
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.98026
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.15727
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.90204
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97591
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11592.95379
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.74909
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.90820
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.98775      0.16175   9.14950     8.82599
alpha_0                               0.99775      0.00015   0.99790     0.99760
alpha_1                               0.99775      0.00015   0.99790     0.99760
alpha_2                               0.99775      0.00015   0.99790     0.99760
alpha_3                               0.99775      0.00015   0.99790     0.99760
alpha_4                               0.99775      0.00015   0.99790     0.99760
alpha_5                               0.99775      0.00015   0.99790     0.99760
alpha_6                               0.99775      0.00015   0.99790     0.99760
alpha_7                               0.99775      0.00015   0.99790     0.99760
alpha_8                               0.99775      0.00015   0.99790     0.99760
alpha_9                               0.99775      0.00015   0.99790     0.99760
Alpha_loss                            -0.01305     0.00101   -0.01203    -0.01406
Training/policy_loss                  -2.68415     0.00469   -2.67946    -2.68885
Training/qf1_loss                     1320.74603   17.13458  1337.88062  1303.61145
Training/qf2_loss                     1320.79114   17.13562  1337.92676  1303.65552
Training/pf_norm                      0.40689      0.00165   0.40854     0.40525
Training/qf1_norm                     23.36633     0.32146   23.68779    23.04488
Training/qf2_norm                     23.45524     0.31265   23.76789    23.14259
log_std/mean                          -0.00159     0.00018   -0.00142    -0.00177
log_std/std                           0.00210      0.00000   0.00211     0.00210
log_std/max                           0.00068      0.00020   0.00088     0.00048
log_std/min                           -0.00599     0.00021   -0.00578    -0.00619
log_probs/mean                        -2.68974     0.00493   -2.68482    -2.69467
log_probs/std                         0.43181      0.00903   0.44084     0.42278
log_probs/max                         -1.26978     0.06768   -1.20211    -1.33746
log_probs/min                         -4.13154     0.26082   -3.87071    -4.39236
mean/mean                             -0.00102     0.00003   -0.00099    -0.00105
mean/std                              0.00175      0.00004   0.00179     0.00171
mean/max                              0.00178      0.00001   0.00179     0.00177
mean/min                              -0.00329     0.00007   -0.00322    -0.00337
------------------------------------  -----------  --------  ----------  ----------
sample: [8, 3, 9, 0, 7, 2, 6, 1, 4, 5]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 894]
train_time 0.25981831550598145
eval_infos
eval time 0.003365039825439453
2023-08-31 20:39:25,272 MainThread INFO: EPOCH:4
2023-08-31 20:39:25,272 MainThread INFO: Time Consumed:0.2721061706542969s
2023-08-31 20:39:25,272 MainThread INFO: Total Frames:7500s
 10%|‚ñà         | 5/50 [00:21<02:09,  2.89s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1133.95724
Train_Epoch_Reward                    24931.83346
Running_Training_Average_Rewards      1597.72888
Explore_Time                          0.00325
Train___Time                          0.25982
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.67927
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.68559
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.58549
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04010
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19350
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93625
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.00839
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11553.60744
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.80516
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.94033
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           9.04187      0.19345   9.23532     8.84842
alpha_0                               0.99715      0.00015   0.99730     0.99700
alpha_1                               0.99715      0.00015   0.99730     0.99700
alpha_2                               0.99715      0.00015   0.99730     0.99700
alpha_3                               0.99715      0.00015   0.99730     0.99700
alpha_4                               0.99715      0.00015   0.99730     0.99700
alpha_5                               0.99715      0.00015   0.99730     0.99700
alpha_6                               0.99715      0.00015   0.99730     0.99700
alpha_7                               0.99715      0.00015   0.99730     0.99701
alpha_8                               0.99715      0.00015   0.99730     0.99700
alpha_9                               0.99715      0.00015   0.99730     0.99701
Alpha_loss                            -0.01702     0.00101   -0.01600    -0.01803
Training/policy_loss                  -2.66687     0.00462   -2.66225    -2.67148
Training/qf1_loss                     1269.71014   94.01227  1363.72241  1175.69788
Training/qf2_loss                     1269.75507   94.01288  1363.76794  1175.74219
Training/pf_norm                      0.43988      0.00768   0.44756     0.43219
Training/qf1_norm                     23.47586     0.38125   23.85711    23.09461
Training/qf2_norm                     23.55739     0.38348   23.94087    23.17392
log_std/mean                          -0.00231     0.00018   -0.00213    -0.00249
log_std/std                           0.00211      0.00000   0.00211     0.00211
log_std/max                           -0.00011     0.00019   0.00009     -0.00030
log_std/min                           -0.00678     0.00020   -0.00659    -0.00698
log_probs/mean                        -2.67329     0.00485   -2.66844    -2.67814
log_probs/std                         0.43380      0.01092   0.44472     0.42288
log_probs/max                         -1.24937     0.07307   -1.17630    -1.32244
log_probs/min                         -5.10385     1.24827   -3.85558    -6.35212
mean/mean                             -0.00109     0.00001   -0.00108    -0.00110
mean/std                              0.00195      0.00004   0.00199     0.00191
mean/max                              0.00197      0.00006   0.00203     0.00191
mean/min                              -0.00377     0.00014   -0.00362    -0.00391
------------------------------------  -----------  --------  ----------  ----------
sample: [1, 5, 9, 0, 3, 7, 2, 4, 8, 6]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
train_time 0.13104605674743652
eval_infos
eval time 0.0037004947662353516
2023-08-31 20:39:25,759 MainThread INFO: EPOCH:5
2023-08-31 20:39:25,760 MainThread INFO: Time Consumed:0.14491868019104004s
2023-08-31 20:39:25,760 MainThread INFO: Total Frames:9000s
 12%|‚ñà‚ñè        | 6/50 [00:21<01:31,  2.07s/it]------------------------------------  -----------  -------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1129.62989
Train_Epoch_Reward                    10806.46334
Running_Training_Average_Rewards      1607.52342
Explore_Time                          0.00358
Train___Time                          0.13105
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.55157
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.72083
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.55600
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.09552
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21697
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95467
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.02630
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11506.05072
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.84330
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.98432
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std      Max         Min
Reward_Mean                           9.96260      0.19084  10.15345    9.77176
alpha_0                               0.99656      0.00015  0.99671     0.99641
alpha_1                               0.99656      0.00015  0.99671     0.99641
alpha_2                               0.99656      0.00015  0.99670     0.99641
alpha_3                               0.99656      0.00015  0.99671     0.99641
alpha_4                               0.99656      0.00015  0.99671     0.99641
alpha_5                               0.99656      0.00015  0.99671     0.99641
alpha_6                               0.99656      0.00015  0.99671     0.99641
alpha_7                               0.99656      0.00015  0.99671     0.99641
alpha_8                               0.99656      0.00015  0.99671     0.99641
alpha_9                               0.99656      0.00015  0.99671     0.99641
Alpha_loss                            -0.02108     0.00100  -0.02008    -0.02209
Training/policy_loss                  -2.68542     0.00012  -2.68530    -2.68554
Training/qf1_loss                     1533.09796   0.01361  1533.11157  1533.08435
Training/qf2_loss                     1533.14563   0.01453  1533.16016  1533.13110
Training/pf_norm                      0.40187      0.01758  0.41944     0.38429
Training/qf1_norm                     25.31062     0.38532  25.69594    24.92530
Training/qf2_norm                     25.40706     0.38219  25.78926    25.02487
log_std/mean                          -0.00302     0.00018  -0.00284    -0.00320
log_std/std                           0.00210      0.00000  0.00210     0.00210
log_std/max                           -0.00089     0.00020  -0.00069    -0.00109
log_std/min                           -0.00757     0.00019  -0.00738    -0.00777
log_probs/mean                        -2.69278     0.00010  -2.69268    -2.69288
log_probs/std                         0.43712      0.01013  0.44725     0.42699
log_probs/max                         -1.20433     0.05202  -1.15231    -1.25635
log_probs/min                         -5.92024     1.39248  -4.52776    -7.31272
mean/mean                             -0.00115     0.00003  -0.00113    -0.00118
mean/std                              0.00210      0.00002  0.00213     0.00208
mean/max                              0.00222      0.00003  0.00225     0.00219
mean/min                              -0.00436     0.00013  -0.00423    -0.00449
------------------------------------  -----------  -------  ----------  ----------
start to update mask
sample: [5, 3, 9, 8, 0, 1, 2, 7, 6, 4]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
train_time 0.17737078666687012
eval_infos
eval time 0.003403186798095703
2023-08-31 20:39:33,776 MainThread INFO: EPOCH:6
2023-08-31 20:39:33,777 MainThread INFO: Time Consumed:0.20537376403808594s
2023-08-31 20:39:33,777 MainThread INFO: Total Frames:10500s
 14%|‚ñà‚ñç        | 7/50 [00:29<02:52,  4.01s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1124.55850
Train_Epoch_Reward                    23039.61849
Running_Training_Average_Rewards      1959.26384
Explore_Time                          0.00624
Train___Time                          0.17737
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.82609
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.74644
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.50796
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.14786
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21460
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94707
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01904
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11432.24491
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.87218
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.04337
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.42483     0.44876    10.87360    9.97607
alpha_0                               0.99596      0.00015    0.99611     0.99581
alpha_1                               0.99596      0.00015    0.99611     0.99581
alpha_2                               0.99596      0.00015    0.99611     0.99581
alpha_3                               0.99596      0.00015    0.99611     0.99581
alpha_4                               0.99596      0.00015    0.99611     0.99581
alpha_5                               0.99596      0.00015    0.99611     0.99581
alpha_6                               0.99596      0.00015    0.99611     0.99581
alpha_7                               0.99596      0.00015    0.99611     0.99581
alpha_8                               0.99596      0.00015    0.99611     0.99581
alpha_9                               0.99596      0.00015    0.99611     0.99581
Alpha_loss                            -0.02507     0.00100    -0.02407    -0.02607
Training/policy_loss                  -2.67713     0.00189    -2.67525    -2.67902
Training/qf1_loss                     1769.02747   140.21118  1909.23865  1628.81628
Training/qf2_loss                     1769.07544   140.21338  1909.28882  1628.86206
Training/pf_norm                      0.41338      0.00935    0.42273     0.40404
Training/qf1_norm                     26.26010     0.93732    27.19742    25.32278
Training/qf2_norm                     26.37440     0.93585    27.31024    25.43855
log_std/mean                          -0.00374     0.00018    -0.00356    -0.00392
log_std/std                           0.00210      0.00000    0.00210     0.00210
log_std/max                           -0.00168     0.00019    -0.00149    -0.00187
log_std/min                           -0.00836     0.00019    -0.00817    -0.00855
log_probs/mean                        -2.68535     0.00168    -2.68367    -2.68702
log_probs/std                         0.42921      0.00545    0.43467     0.42376
log_probs/max                         -1.22796     0.09086    -1.13710    -1.31883
log_probs/min                         -4.32451     0.56739    -3.75712    -4.89190
mean/mean                             -0.00125     0.00002    -0.00122    -0.00127
mean/std                              0.00218      0.00002    0.00220     0.00216
mean/max                              0.00218      0.00003    0.00221     0.00215
mean/min                              -0.00490     0.00014    -0.00476    -0.00505
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 6, 4, 5, 9, 0, 1, 2, 3, 8]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
train_time 0.6702213287353516
eval_infos
eval time 0.002986907958984375
2023-08-31 20:39:34,860 MainThread INFO: EPOCH:7
2023-08-31 20:39:34,861 MainThread INFO: Time Consumed:0.6821451187133789s
2023-08-31 20:39:34,861 MainThread INFO: Total Frames:12000s
 16%|‚ñà‚ñå        | 8/50 [00:30<02:09,  3.08s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1118.69599
Train_Epoch_Reward                    34435.66619
Running_Training_Average_Rewards      2276.05827
Explore_Time                          0.00376
Train___Time                          0.67022
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.58039
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.78569
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.46638
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.19112
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20445
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93065
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.00235
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11375.01565
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.91817
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.07818
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.53696      0.83614    10.37309    8.70082
alpha_0                               0.99536      0.00015    0.99551     0.99521
alpha_1                               0.99536      0.00015    0.99551     0.99521
alpha_2                               0.99536      0.00015    0.99551     0.99521
alpha_3                               0.99536      0.00015    0.99551     0.99521
alpha_4                               0.99536      0.00015    0.99551     0.99521
alpha_5                               0.99536      0.00015    0.99551     0.99521
alpha_6                               0.99536      0.00015    0.99551     0.99521
alpha_7                               0.99536      0.00015    0.99551     0.99521
alpha_8                               0.99536      0.00015    0.99551     0.99521
alpha_9                               0.99536      0.00015    0.99551     0.99521
Alpha_loss                            -0.02907     0.00096    -0.02812    -0.03003
Training/policy_loss                  -2.67439     0.01097    -2.66342    -2.68537
Training/qf1_loss                     1587.73724   263.61993  1851.35718  1324.11731
Training/qf2_loss                     1587.78119   263.62238  1851.40356  1324.15881
Training/pf_norm                      0.40911      0.01143    0.42055     0.39768
Training/qf1_norm                     24.45151     1.67805    26.12955    22.77346
Training/qf2_norm                     24.55799     1.69315    26.25113    22.86484
log_std/mean                          -0.00445     0.00018    -0.00427    -0.00463
log_std/std                           0.00210      0.00000    0.00210     0.00209
log_std/max                           -0.00243     0.00017    -0.00226    -0.00260
log_std/min                           -0.00914     0.00019    -0.00894    -0.00933
log_probs/mean                        -2.68348     0.01080    -2.67267    -2.69428
log_probs/std                         0.43181      0.00015    0.43196     0.43167
log_probs/max                         -1.37671     0.03902    -1.33769    -1.41573
log_probs/min                         -4.15842     0.17686    -3.98156    -4.33529
mean/mean                             -0.00132     0.00001    -0.00130    -0.00133
mean/std                              0.00226      0.00001    0.00227     0.00224
mean/max                              0.00214      0.00002    0.00216     0.00213
mean/min                              -0.00546     0.00013    -0.00533    -0.00559
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 9, 3, 5, 1, 4, 2, 0, 8, 6]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
train_time 0.49358510971069336
eval_infos
eval time 0.003471851348876953
2023-08-31 20:39:35,575 MainThread INFO: EPOCH:8
2023-08-31 20:39:35,576 MainThread INFO: Time Consumed:0.5095701217651367s
2023-08-31 20:39:35,576 MainThread INFO: Total Frames:13500s
 18%|‚ñà‚ñä        | 9/50 [00:31<01:35,  2.34s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1112.86953
Train_Epoch_Reward                    3942.72512
Running_Training_Average_Rewards      2047.26699
Explore_Time                          0.00305
Train___Time                          0.49359
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.29596
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.83863
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.42526
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.24111
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20444
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92250
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.99260
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11326.30748
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97597
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.10381
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.11037     0.21120    10.32157    9.89917
alpha_0                               0.99476      0.00015    0.99491     0.99461
alpha_1                               0.99476      0.00015    0.99491     0.99461
alpha_2                               0.99476      0.00015    0.99491     0.99461
alpha_3                               0.99477      0.00015    0.99491     0.99462
alpha_4                               0.99477      0.00015    0.99491     0.99462
alpha_5                               0.99477      0.00015    0.99491     0.99462
alpha_6                               0.99476      0.00015    0.99491     0.99462
alpha_7                               0.99476      0.00015    0.99491     0.99461
alpha_8                               0.99476      0.00015    0.99491     0.99461
alpha_9                               0.99476      0.00015    0.99491     0.99461
Alpha_loss                            -0.03307     0.00097    -0.03210    -0.03404
Training/policy_loss                  -2.67184     0.00676    -2.66508    -2.67861
Training/qf1_loss                     1790.35034   104.87354  1895.22388  1685.47681
Training/qf2_loss                     1790.39569   104.87555  1895.27124  1685.52014
Training/pf_norm                      0.43256      0.00684    0.43940     0.42573
Training/qf1_norm                     25.66521     0.38824    26.05345    25.27696
Training/qf2_norm                     25.78119     0.37514    26.15633    25.40605
log_std/mean                          -0.00517     0.00018    -0.00499    -0.00535
log_std/std                           0.00209      0.00000    0.00209     0.00209
log_std/max                           -0.00311     0.00017    -0.00294    -0.00327
log_std/min                           -0.00992     0.00019    -0.00973    -0.01012
log_probs/mean                        -2.68178     0.00658    -2.67520    -2.68837
log_probs/std                         0.42555      0.01084    0.43639     0.41471
log_probs/max                         -1.26842     0.13254    -1.13588    -1.40096
log_probs/min                         -4.35406     0.19869    -4.15537    -4.55275
mean/mean                             -0.00138     0.00002    -0.00136    -0.00140
mean/std                              0.00232      0.00002    0.00234     0.00231
mean/max                              0.00223      0.00001    0.00224     0.00222
mean/min                              -0.00596     0.00010    -0.00585    -0.00606
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [7, 8, 1, 6, 3, 2, 9, 4, 5, 0]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
train_time 0.14239072799682617
eval_infos
eval time 0.0030176639556884766
2023-08-31 20:39:45,681 MainThread INFO: EPOCH:9
2023-08-31 20:39:45,712 MainThread INFO: Time Consumed:0.16620874404907227s
2023-08-31 20:39:45,713 MainThread INFO: Total Frames:15000s
 20%|‚ñà‚ñà        | 10/50 [00:41<03:10,  4.75s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1108.37244
Train_Epoch_Reward                    6138.99919
Running_Training_Average_Rewards      1483.91302
Explore_Time                          0.00719
Train___Time                          0.14239
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.18638
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.89227
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.39809
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.28096
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20972
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92170
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98806
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11297.02702
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.02744
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.11463
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.05593     0.29235    10.34828    9.76359
alpha_0                               0.99417      0.00015    0.99431     0.99402
alpha_1                               0.99416      0.00015    0.99431     0.99401
alpha_2                               0.99416      0.00015    0.99431     0.99402
alpha_3                               0.99417      0.00015    0.99432     0.99402
alpha_4                               0.99417      0.00015    0.99432     0.99402
alpha_5                               0.99417      0.00015    0.99432     0.99402
alpha_6                               0.99417      0.00015    0.99432     0.99402
alpha_7                               0.99417      0.00015    0.99432     0.99402
alpha_8                               0.99417      0.00015    0.99432     0.99402
alpha_9                               0.99417      0.00015    0.99432     0.99402
Alpha_loss                            -0.03711     0.00103    -0.03608    -0.03814
Training/policy_loss                  -2.67502     0.00493    -2.67009    -2.67995
Training/qf1_loss                     1668.35632   109.17395  1777.53027  1559.18237
Training/qf2_loss                     1668.40167   109.17621  1777.57788  1559.22546
Training/pf_norm                      0.42247      0.02347    0.44594     0.39899
Training/qf1_norm                     25.54228     0.59321    26.13549    24.94908
Training/qf2_norm                     25.64801     0.57921    26.22722    25.06880
log_std/mean                          -0.00589     0.00018    -0.00571    -0.00608
log_std/std                           0.00209      0.00000    0.00209     0.00209
log_std/max                           -0.00379     0.00017    -0.00362    -0.00396
log_std/min                           -0.01072     0.00020    -0.01052    -0.01092
log_probs/mean                        -2.68585     0.00518    -2.68067    -2.69102
log_probs/std                         0.41309      0.00381    0.41690     0.40928
log_probs/max                         -1.36667     0.04369    -1.32298    -1.41036
log_probs/min                         -4.23202     0.18998    -4.04204    -4.42200
mean/mean                             -0.00143     0.00001    -0.00143    -0.00144
mean/std                              0.00239      0.00003    0.00242     0.00237
mean/max                              0.00226      0.00000    0.00226     0.00226
mean/min                              -0.00637     0.00011    -0.00626    -0.00648
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 1, 7, 0, 6, 2, 8, 5, 9, 4]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
train_time 1.7513535022735596
eval_infos
eval time 0.003937244415283203
2023-08-31 20:39:48,525 MainThread INFO: EPOCH:10
2023-08-31 20:39:48,525 MainThread INFO: Time Consumed:1.7914164066314697s
2023-08-31 20:39:48,525 MainThread INFO: Total Frames:16500s
 22%|‚ñà‚ñà‚ñè       | 11/50 [00:44<02:42,  4.16s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1104.95177
Train_Epoch_Reward                    10485.45681
Running_Training_Average_Rewards      685.57270
Explore_Time                          0.01582
Train___Time                          1.75135
Eval____Time                          0.00394
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.15964
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.94011
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.38198
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.31134
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21219
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91936
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98028
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11277.33707
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.07329
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.12087
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.61914      0.46653    10.08567    9.15260
alpha_0                               0.99357      0.00015    0.99372     0.99342
alpha_1                               0.99357      0.00015    0.99372     0.99342
alpha_2                               0.99357      0.00015    0.99372     0.99342
alpha_3                               0.99357      0.00015    0.99372     0.99343
alpha_4                               0.99357      0.00015    0.99372     0.99342
alpha_5                               0.99357      0.00015    0.99372     0.99342
alpha_6                               0.99357      0.00015    0.99372     0.99342
alpha_7                               0.99357      0.00015    0.99372     0.99342
alpha_8                               0.99357      0.00015    0.99372     0.99342
alpha_9                               0.99357      0.00015    0.99372     0.99342
Alpha_loss                            -0.04104     0.00097    -0.04007    -0.04200
Training/policy_loss                  -2.66081     0.00574    -2.65507    -2.66655
Training/qf1_loss                     1488.86884   106.07562  1594.94446  1382.79321
Training/qf2_loss                     1488.91119   106.07635  1594.98755  1382.83484
Training/pf_norm                      0.43602      0.01356    0.44958     0.42246
Training/qf1_norm                     24.61362     0.91926    25.53288    23.69435
Training/qf2_norm                     24.72232     0.92996    25.65228    23.79235
log_std/mean                          -0.00662     0.00018    -0.00644    -0.00680
log_std/std                           0.00208      0.00000    0.00209     0.00208
log_std/max                           -0.00447     0.00017    -0.00430    -0.00465
log_std/min                           -0.01150     0.00020    -0.01130    -0.01169
log_probs/mean                        -2.67242     0.00555    -2.66687    -2.67797
log_probs/std                         0.42254      0.00611    0.42865     0.41642
log_probs/max                         -1.33159     0.05386    -1.27773    -1.38545
log_probs/min                         -3.69846     0.03731    -3.66115    -3.73577
mean/mean                             -0.00151     0.00002    -0.00149    -0.00153
mean/std                              0.00250      0.00003    0.00254     0.00247
mean/max                              0.00218      0.00002    0.00220     0.00216
mean/min                              -0.00683     0.00011    -0.00672    -0.00694
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 7, 2, 9, 8, 3, 1, 0, 6, 4]
replay_buffer._size: [1907 1913 1902 1925 1918 1898 1924 1902 1906 1894]
train_time 1.1564710140228271
eval_infos
eval time 0.002828836441040039
2023-08-31 20:39:49,957 MainThread INFO: EPOCH:11
2023-08-31 20:39:49,957 MainThread INFO: Time Consumed:1.1759140491485596s
2023-08-31 20:39:49,957 MainThread INFO: Total Frames:18000s
 24%|‚ñà‚ñà‚ñç       | 12/50 [00:45<02:06,  3.33s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1102.24795
Train_Epoch_Reward                    18138.78991
Running_Training_Average_Rewards      1158.77486
Explore_Time                          0.00474
Train___Time                          1.15647
Eval____Time                          0.00283
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.42498
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.97908
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.35550
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34126
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20464
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.90488
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.96446
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11240.62444
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.10994
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.14697
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.69669      0.63526    10.33195    9.06142
alpha_0                               0.99297      0.00015    0.99312     0.99282
alpha_1                               0.99297      0.00015    0.99312     0.99282
alpha_2                               0.99297      0.00015    0.99312     0.99282
alpha_3                               0.99298      0.00015    0.99313     0.99283
alpha_4                               0.99298      0.00015    0.99313     0.99283
alpha_5                               0.99298      0.00015    0.99313     0.99283
alpha_6                               0.99298      0.00015    0.99313     0.99283
alpha_7                               0.99297      0.00015    0.99312     0.99282
alpha_8                               0.99298      0.00015    0.99312     0.99283
alpha_9                               0.99298      0.00015    0.99312     0.99283
Alpha_loss                            -0.04518     0.00096    -0.04422    -0.04614
Training/policy_loss                  -2.68055     0.00660    -2.67395    -2.68715
Training/qf1_loss                     1638.98706   156.23486  1795.22192  1482.75220
Training/qf2_loss                     1639.02881   156.23645  1795.26526  1482.79236
Training/pf_norm                      0.40394      0.02124    0.42518     0.38270
Training/qf1_norm                     24.80674     1.29333    26.10007    23.51342
Training/qf2_norm                     24.92142     1.30297    26.22439    23.61845
log_std/mean                          -0.00735     0.00018    -0.00717    -0.00753
log_std/std                           0.00209      0.00000    0.00209     0.00208
log_std/max                           -0.00516     0.00017    -0.00499    -0.00533
log_std/min                           -0.01235     0.00024    -0.01211    -0.01258
log_probs/mean                        -2.69317     0.00643    -2.68674    -2.69960
log_probs/std                         0.41487      0.00189    0.41676     0.41298
log_probs/max                         -1.45268     0.06761    -1.38507    -1.52029
log_probs/min                         -4.48354     0.01296    -4.47058    -4.49650
mean/mean                             -0.00154     0.00000    -0.00153    -0.00154
mean/std                              0.00266      0.00004    0.00270     0.00263
mean/max                              0.00219      0.00002    0.00222     0.00217
mean/min                              -0.00726     0.00009    -0.00717    -0.00735
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [3, 2, 1, 6, 9, 8, 0, 4, 5, 7]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
train_time 1.9478154182434082
eval_infos
eval time 0.011239290237426758
2023-08-31 20:40:01,415 MainThread INFO: EPOCH:12
2023-08-31 20:40:01,416 MainThread INFO: Time Consumed:1.9800896644592285s
2023-08-31 20:40:01,416 MainThread INFO: Total Frames:19500s
 26%|‚ñà‚ñà‚ñå       | 13/50 [00:57<03:35,  5.82s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1098.33502
Train_Epoch_Reward                    11240.89155
Running_Training_Average_Rewards      1328.83794
Explore_Time                          0.00550
Train___Time                          1.94782
Eval____Time                          0.01124
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.17933
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.99590
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32912
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.36887
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19640
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89462
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94650
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11190.84796
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12475
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.19270
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.68265      0.73967    10.42232    8.94298
alpha_0                               0.99238      0.00015    0.99253     0.99223
alpha_1                               0.99237      0.00015    0.99252     0.99223
alpha_2                               0.99238      0.00015    0.99253     0.99223
alpha_3                               0.99238      0.00015    0.99253     0.99223
alpha_4                               0.99238      0.00015    0.99253     0.99223
alpha_5                               0.99238      0.00015    0.99253     0.99223
alpha_6                               0.99238      0.00015    0.99253     0.99223
alpha_7                               0.99238      0.00015    0.99253     0.99223
alpha_8                               0.99238      0.00015    0.99253     0.99223
alpha_9                               0.99238      0.00015    0.99253     0.99223
Alpha_loss                            -0.04905     0.00105    -0.04800    -0.05010
Training/policy_loss                  -2.66033     0.00661    -2.65372    -2.66694
Training/qf1_loss                     1637.19940   380.45453  2017.65393  1256.74487
Training/qf2_loss                     1637.24121   380.45728  2017.69849  1256.78394
Training/pf_norm                      0.43620      0.02636    0.46256     0.40984
Training/qf1_norm                     24.78466     1.50915    26.29381    23.27551
Training/qf2_norm                     24.89429     1.51612    26.41041    23.37816
log_std/mean                          -0.00809     0.00018    -0.00790    -0.00827
log_std/std                           0.00209      0.00000    0.00210     0.00209
log_std/max                           -0.00584     0.00017    -0.00567    -0.00601
log_std/min                           -0.01324     0.00022    -0.01302    -0.01345
log_probs/mean                        -2.67366     0.00688    -2.66679    -2.68054
log_probs/std                         0.42810      0.00588    0.43398     0.42222
log_probs/max                         -1.32335     0.05010    -1.27326    -1.37345
log_probs/min                         -4.07793     0.01512    -4.06281    -4.09304
mean/mean                             -0.00153     0.00001    -0.00153    -0.00154
mean/std                              0.00277      0.00004    0.00281     0.00274
mean/max                              0.00222      0.00002    0.00224     0.00221
mean/min                              -0.00754     0.00009    -0.00745    -0.00763
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 5, 1, 7, 2, 9, 4, 8, 0, 3]
replay_buffer._size: [2223 2210 2211 2225 2209 2205 2204 2229 2192 2210]
train_time 1.9952454566955566
eval_infos
eval time 0.07035636901855469
2023-08-31 20:40:03,994 MainThread INFO: EPOCH:13
2023-08-31 20:40:03,994 MainThread INFO: Time Consumed:2.080869197845459s
2023-08-31 20:40:03,994 MainThread INFO: Total Frames:21000s
 28%|‚ñà‚ñà‚ñä       | 14/50 [00:59<02:53,  4.82s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1094.24531
Train_Epoch_Reward                    27508.89813
Running_Training_Average_Rewards      1896.28599
Explore_Time                          0.00332
Train___Time                          1.99525
Eval____Time                          0.07036
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.75522
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.99199
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32334
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.38095
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19496
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89331
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93743
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11154.37069
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11710
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.22945
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           9.54832      0.17157   9.71989     9.37675
alpha_0                               0.99178      0.00015   0.99193     0.99163
alpha_1                               0.99178      0.00015   0.99193     0.99163
alpha_2                               0.99178      0.00015   0.99193     0.99163
alpha_3                               0.99179      0.00015   0.99194     0.99164
alpha_4                               0.99179      0.00015   0.99193     0.99164
alpha_5                               0.99179      0.00015   0.99193     0.99164
alpha_6                               0.99178      0.00015   0.99193     0.99164
alpha_7                               0.99178      0.00015   0.99193     0.99163
alpha_8                               0.99179      0.00015   0.99194     0.99164
alpha_9                               0.99178      0.00015   0.99193     0.99164
Alpha_loss                            -0.05323     0.00097   -0.05225    -0.05420
Training/policy_loss                  -2.68085     0.00421   -2.67664    -2.68506
Training/qf1_loss                     1591.07904   41.50641  1632.58545  1549.57263
Training/qf2_loss                     1591.11884   41.50775  1632.62659  1549.61108
Training/pf_norm                      0.41128      0.00337   0.41464     0.40791
Training/qf1_norm                     24.48949     0.34773   24.83722    24.14176
Training/qf2_norm                     24.60425     0.34352   24.94777    24.26073
log_std/mean                          -0.00883     0.00019   -0.00864    -0.00901
log_std/std                           0.00211      0.00000   0.00211     0.00210
log_std/max                           -0.00654     0.00018   -0.00636    -0.00672
log_std/min                           -0.01412     0.00022   -0.01391    -0.01434
log_probs/mean                        -2.69520     0.00403   -2.69117    -2.69923
log_probs/std                         0.42418      0.00215   0.42633     0.42202
log_probs/max                         -1.28646     0.02405   -1.26241    -1.31051
log_probs/min                         -4.64031     0.52198   -4.11833    -5.16229
mean/mean                             -0.00155     0.00000   -0.00155    -0.00155
mean/std                              0.00289      0.00002   0.00292     0.00287
mean/max                              0.00230      0.00002   0.00232     0.00228
mean/min                              -0.00784     0.00006   -0.00778    -0.00790
------------------------------------  -----------  --------  ----------  ----------
sample: [4, 5, 9, 2, 3, 7, 8, 1, 0, 6]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
train_time 1.454688310623169
eval_infos
eval time 0.002913951873779297
2023-08-31 20:40:06,047 MainThread INFO: EPOCH:14
2023-08-31 20:40:06,047 MainThread INFO: Time Consumed:1.47613525390625s
2023-08-31 20:40:06,048 MainThread INFO: Total Frames:22500s
 30%|‚ñà‚ñà‚ñà       | 15/50 [01:01<02:19,  3.98s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1089.81013
Train_Epoch_Reward                    6067.24180
Running_Training_Average_Rewards      1493.90105
Explore_Time                          0.00474
Train___Time                          1.45469
Eval____Time                          0.00291
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.83451
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.00469
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.31540
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.40714
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20491
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.90569
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94154
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11119.13685
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12403
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.26175
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.31326     0.68487    10.99813    9.62838
alpha_0                               0.99119      0.00015    0.99133     0.99104
alpha_1                               0.99118      0.00015    0.99133     0.99103
alpha_2                               0.99119      0.00015    0.99134     0.99104
alpha_3                               0.99119      0.00015    0.99134     0.99104
alpha_4                               0.99119      0.00015    0.99134     0.99104
alpha_5                               0.99119      0.00015    0.99134     0.99104
alpha_6                               0.99119      0.00015    0.99134     0.99104
alpha_7                               0.99119      0.00015    0.99134     0.99104
alpha_8                               0.99119      0.00015    0.99134     0.99104
alpha_9                               0.99119      0.00015    0.99134     0.99104
Alpha_loss                            -0.05725     0.00096    -0.05629    -0.05822
Training/policy_loss                  -2.68104     0.00518    -2.67586    -2.68623
Training/qf1_loss                     1703.79376   182.10858  1885.90234  1521.68518
Training/qf2_loss                     1703.83447   182.11121  1885.94568  1521.72327
Training/pf_norm                      0.38050      0.01103    0.39153     0.36946
Training/qf1_norm                     26.02462     1.40727    27.43189    24.61736
Training/qf2_norm                     26.15963     1.40853    27.56816    24.75110
log_std/mean                          -0.00957     0.00019    -0.00938    -0.00975
log_std/std                           0.00212      0.00000    0.00212     0.00211
log_std/max                           -0.00723     0.00017    -0.00706    -0.00741
log_std/min                           -0.01499     0.00021    -0.01479    -0.01520
log_probs/mean                        -2.69627     0.00502    -2.69126    -2.70129
log_probs/std                         0.42193      0.00815    0.43008     0.41378
log_probs/max                         -1.35036     0.01248    -1.33789    -1.36284
log_probs/min                         -4.84546     0.20107    -4.64438    -5.04653
mean/mean                             -0.00157     0.00000    -0.00156    -0.00157
mean/std                              0.00299      0.00003    0.00302     0.00296
mean/max                              0.00239      0.00001    0.00240     0.00238
mean/min                              -0.00807     0.00006    -0.00801    -0.00814
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [5, 1, 0, 8, 4, 3, 7, 6, 2, 9]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
train_time 0.2067265510559082
eval_infos
eval time 0.0046613216400146484
2023-08-31 20:40:16,729 MainThread INFO: EPOCH:15
2023-08-31 20:40:16,730 MainThread INFO: Time Consumed:0.2346489429473877s
2023-08-31 20:40:16,730 MainThread INFO: Total Frames:24000s
 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [01:12<03:24,  6.00s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1086.93056
Train_Epoch_Reward                    14229.80616
Running_Training_Average_Rewards      1593.53154
Explore_Time                          0.00513
Train___Time                          0.20673
Eval____Time                          0.00466
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.09916
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.00941
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.31040
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.42308
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21330
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91623
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94663
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11092.55789
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12437
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.28267
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.43560     0.82939    11.26499    9.60621
alpha_0                               0.99059      0.00015    0.99074     0.99044
alpha_1                               0.99059      0.00015    0.99074     0.99044
alpha_2                               0.99059      0.00015    0.99074     0.99045
alpha_3                               0.99060      0.00015    0.99075     0.99045
alpha_4                               0.99060      0.00015    0.99074     0.99045
alpha_5                               0.99060      0.00015    0.99074     0.99045
alpha_6                               0.99059      0.00015    0.99074     0.99044
alpha_7                               0.99059      0.00015    0.99074     0.99044
alpha_8                               0.99060      0.00015    0.99075     0.99045
alpha_9                               0.99059      0.00015    0.99074     0.99045
Alpha_loss                            -0.06123     0.00098    -0.06025    -0.06221
Training/policy_loss                  -2.67520     0.00280    -2.67240    -2.67800
Training/qf1_loss                     1823.04340   246.28571  2069.32910  1576.75769
Training/qf2_loss                     1823.08325   246.28833  2069.37158  1576.79492
Training/pf_norm                      0.38509      0.01122    0.39631     0.37387
Training/qf1_norm                     26.26623     1.67658    27.94281    24.58964
Training/qf2_norm                     26.40539     1.68756    28.09296    24.71783
log_std/mean                          -0.01030     0.00018    -0.01012    -0.01049
log_std/std                           0.00213      0.00000    0.00213     0.00213
log_std/max                           -0.00792     0.00017    -0.00775    -0.00809
log_std/min                           -0.01587     0.00022    -0.01566    -0.01609
log_probs/mean                        -2.69124     0.00260    -2.68863    -2.69384
log_probs/std                         0.41320      0.00289    0.41609     0.41031
log_probs/max                         -1.31200     0.04399    -1.26801    -1.35599
log_probs/min                         -3.98835     0.02193    -3.96642    -4.01027
mean/mean                             -0.00160     0.00001    -0.00159    -0.00161
mean/std                              0.00306      0.00001    0.00307     0.00305
mean/max                              0.00249      0.00003    0.00252     0.00245
mean/min                              -0.00828     0.00004    -0.00824    -0.00833
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 4, 1, 6, 0, 8, 3, 9, 5, 7]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
train_time 0.10988116264343262
eval_infos
eval time 0.002921581268310547
2023-08-31 20:40:17,377 MainThread INFO: EPOCH:16
2023-08-31 20:40:17,377 MainThread INFO: Time Consumed:0.12154698371887207s
2023-08-31 20:40:17,378 MainThread INFO: Total Frames:25500s
 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:13<02:25,  4.39s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1084.14302
Train_Epoch_Reward                    15614.46300
Running_Training_Average_Rewards      1197.05037
Explore_Time                          0.00368
Train___Time                          0.10988
Eval____Time                          0.00292
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.19643
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.01724
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.30396
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.43756
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21853
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91912
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94671
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11068.38400
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12447
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.29919
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.72041      0.09935    9.81976     9.62107
alpha_0                               0.99000      0.00015    0.99014     0.98985
alpha_1                               0.98999      0.00015    0.99014     0.98984
alpha_2                               0.99000      0.00015    0.99015     0.98985
alpha_3                               0.99000      0.00015    0.99015     0.98986
alpha_4                               0.99000      0.00015    0.99015     0.98985
alpha_5                               0.99000      0.00015    0.99015     0.98985
alpha_6                               0.99000      0.00015    0.99015     0.98985
alpha_7                               0.99000      0.00015    0.99015     0.98985
alpha_8                               0.99000      0.00015    0.99015     0.98985
alpha_9                               0.99000      0.00015    0.99015     0.98985
Alpha_loss                            -0.06511     0.00096    -0.06415    -0.06607
Training/policy_loss                  -2.66109     0.00437    -2.65672    -2.66547
Training/qf1_loss                     1600.94745   133.85211  1734.79956  1467.09534
Training/qf2_loss                     1600.98517   133.85248  1734.83765  1467.13269
Training/pf_norm                      0.40754      0.01971    0.42726     0.38783
Training/qf1_norm                     24.81233     0.17344    24.98577    24.63889
Training/qf2_norm                     24.93719     0.17602    25.11320    24.76117
log_std/mean                          -0.01104     0.00018    -0.01085    -0.01122
log_std/std                           0.00213      0.00000    0.00214     0.00213
log_std/max                           -0.00861     0.00017    -0.00844    -0.00878
log_std/min                           -0.01672     0.00021    -0.01651    -0.01693
log_probs/mean                        -2.67784     0.00422    -2.67362    -2.68205
log_probs/std                         0.40903      0.00355    0.41258     0.40547
log_probs/max                         -1.37041     0.10490    -1.26551    -1.47531
log_probs/min                         -4.77598     0.32699    -4.44899    -5.10298
mean/mean                             -0.00164     0.00000    -0.00163    -0.00164
mean/std                              0.00305      0.00001    0.00306     0.00304
mean/max                              0.00251      0.00001    0.00252     0.00250
mean/min                              -0.00835     0.00000    -0.00835    -0.00835
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 2, 5, 1, 7, 3, 9, 6, 8, 4]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
train_time 2.351083993911743
eval_infos
eval time 0.19653034210205078
2023-08-31 20:40:20,800 MainThread INFO: EPOCH:17
2023-08-31 20:40:20,801 MainThread INFO: Time Consumed:2.577890157699585s
2023-08-31 20:40:20,801 MainThread INFO: Total Frames:27000s
 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:16<02:10,  4.09s/it]------------------------------------  -----------  -------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1082.15762
Train_Epoch_Reward                    1950.28845
Running_Training_Average_Rewards      1059.81859
Explore_Time                          0.00603
Train___Time                          2.35108
Eval____Time                          0.19653
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.69783
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02148
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.29844
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.43730
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21436
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91318
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94085
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11055.52276
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12162
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.30235
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std      Max         Min
Reward_Mean                           10.54673     0.26319  10.80991    10.28354
alpha_0                               0.98940      0.00015  0.98955     0.98925
alpha_1                               0.98940      0.00015  0.98955     0.98925
alpha_2                               0.98941      0.00015  0.98956     0.98926
alpha_3                               0.98941      0.00015  0.98956     0.98926
alpha_4                               0.98941      0.00015  0.98956     0.98926
alpha_5                               0.98941      0.00015  0.98956     0.98926
alpha_6                               0.98940      0.00015  0.98955     0.98925
alpha_7                               0.98940      0.00015  0.98955     0.98926
alpha_8                               0.98941      0.00015  0.98956     0.98926
alpha_9                               0.98941      0.00015  0.98955     0.98926
Alpha_loss                            -0.06927     0.00091  -0.06836    -0.07017
Training/policy_loss                  -2.67420     0.00923  -2.66497    -2.68343
Training/qf1_loss                     2006.21191   6.99438  2013.20630  1999.21753
Training/qf2_loss                     2006.24872   6.99518  2013.24390  1999.25354
Training/pf_norm                      0.36607      0.03099  0.39706     0.33509
Training/qf1_norm                     26.51847     0.50291  27.02138    26.01557
Training/qf2_norm                     26.67727     0.51881  27.19608    26.15846
log_std/mean                          -0.01177     0.00018  -0.01159    -0.01195
log_std/std                           0.00214      0.00000  0.00214     0.00214
log_std/max                           -0.00930     0.00017  -0.00913    -0.00947
log_std/min                           -0.01754     0.00021  -0.01733    -0.01775
log_probs/mean                        -2.69193     0.00912  -2.68281    -2.70106
log_probs/std                         0.40999      0.00532  0.41531     0.40467
log_probs/max                         -1.35526     0.04198  -1.31328    -1.39723
log_probs/min                         -4.03128     0.04222  -3.98905    -4.07350
mean/mean                             -0.00166     0.00000  -0.00165    -0.00166
mean/std                              0.00297      0.00003  0.00300     0.00294
mean/max                              0.00244      0.00002  0.00247     0.00242
mean/min                              -0.00825     0.00004  -0.00821    -0.00830
------------------------------------  -----------  -------  ----------  ----------
start to update mask
sample: [1, 6, 7, 5, 9, 0, 8, 4, 3, 2]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
train_time 0.15932488441467285
eval_infos
eval time 0.003945112228393555
2023-08-31 20:40:34,666 MainThread INFO: EPOCH:18
2023-08-31 20:40:34,666 MainThread INFO: Time Consumed:0.18205857276916504s
2023-08-31 20:40:34,666 MainThread INFO: Total Frames:28500s
 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:30<03:38,  7.03s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1081.08929
Train_Epoch_Reward                    37490.96403
Running_Training_Average_Rewards      1835.19052
Explore_Time                          0.00538
Train___Time                          0.15932
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.53506
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02293
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.30439
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.42232
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20942
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91063
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93416
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11063.92620
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11757
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.28705
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.90301      0.44689    10.34990    9.45611
alpha_0                               0.98881      0.00015    0.98895     0.98866
alpha_1                               0.98881      0.00015    0.98895     0.98866
alpha_2                               0.98881      0.00015    0.98896     0.98867
alpha_3                               0.98882      0.00015    0.98897     0.98867
alpha_4                               0.98882      0.00015    0.98896     0.98867
alpha_5                               0.98882      0.00015    0.98896     0.98867
alpha_6                               0.98881      0.00015    0.98896     0.98866
alpha_7                               0.98881      0.00015    0.98896     0.98866
alpha_8                               0.98881      0.00015    0.98896     0.98867
alpha_9                               0.98881      0.00015    0.98896     0.98866
Alpha_loss                            -0.07330     0.00096    -0.07235    -0.07426
Training/policy_loss                  -2.67539     0.00436    -2.67103    -2.67976
Training/qf1_loss                     1787.12714   180.04999  1967.17712  1607.07715
Training/qf2_loss                     1787.16528   180.05151  1967.21680  1607.11377
Training/pf_norm                      0.37275      0.01617    0.38892     0.35658
Training/qf1_norm                     25.20581     0.88221    26.08802    24.32360
Training/qf2_norm                     25.32946     0.88847    26.21794    24.44099
log_std/mean                          -0.01250     0.00018    -0.01232    -0.01269
log_std/std                           0.00215      0.00000    0.00215     0.00215
log_std/max                           -0.00999     0.00017    -0.00982    -0.01017
log_std/min                           -0.01835     0.00021    -0.01814    -0.01856
log_probs/mean                        -2.69400     0.00419    -2.68981    -2.69819
log_probs/std                         0.40839      0.00969    0.41808     0.39870
log_probs/max                         -1.32117     0.03862    -1.28255    -1.35979
log_probs/min                         -3.96517     0.01312    -3.95205    -3.97829
mean/mean                             -0.00167     0.00000    -0.00167    -0.00167
mean/std                              0.00284      0.00003    0.00287     0.00282
mean/max                              0.00243      0.00000    0.00244     0.00243
mean/min                              -0.00802     0.00005    -0.00797    -0.00807
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 9, 5, 2, 1, 4, 0, 8, 7, 3]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
train_time 0.11993694305419922
eval_infos
eval time 0.002982616424560547
2023-08-31 20:40:35,283 MainThread INFO: EPOCH:19
2023-08-31 20:40:35,283 MainThread INFO: Time Consumed:0.13089990615844727s
2023-08-31 20:40:35,284 MainThread INFO: Total Frames:30000s
 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:31<02:33,  5.10s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1081.93563
Train_Epoch_Reward                    17970.44119
Running_Training_Average_Rewards      1913.72312
Explore_Time                          0.00292
Train___Time                          0.11994
Eval____Time                          0.00298
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.55382
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02046
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32394
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.39712
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21014
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91337
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93219
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11093.02643
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11143
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.25306
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.89801     0.62535    12.52336    11.27267
alpha_0                               0.98821      0.00015    0.98836     0.98806
alpha_1                               0.98821      0.00015    0.98836     0.98806
alpha_2                               0.98822      0.00015    0.98837     0.98807
alpha_3                               0.98822      0.00015    0.98837     0.98808
alpha_4                               0.98822      0.00015    0.98837     0.98807
alpha_5                               0.98822      0.00015    0.98837     0.98807
alpha_6                               0.98822      0.00015    0.98836     0.98807
alpha_7                               0.98822      0.00015    0.98837     0.98807
alpha_8                               0.98822      0.00015    0.98837     0.98807
alpha_9                               0.98822      0.00015    0.98837     0.98807
Alpha_loss                            -0.07750     0.00099    -0.07650    -0.07849
Training/policy_loss                  -2.68955     0.00126    -2.68828    -2.69081
Training/qf1_loss                     2732.81885   298.25293  3031.07178  2434.56592
Training/qf2_loss                     2732.85767   298.25513  3031.11279  2434.60254
Training/pf_norm                      0.33769      0.02603    0.36371     0.31166
Training/qf1_norm                     29.23726     1.27548    30.51274    27.96177
Training/qf2_norm                     29.41292     1.28335    30.69627    28.12957
log_std/mean                          -0.01323     0.00018    -0.01305    -0.01341
log_std/std                           0.00215      0.00000    0.00215     0.00215
log_std/max                           -0.01068     0.00016    -0.01051    -0.01084
log_std/min                           -0.01915     0.00020    -0.01895    -0.01936
log_probs/mean                        -2.70916     0.00107    -2.70809    -2.71024
log_probs/std                         0.40554      0.00751    0.41305     0.39803
log_probs/max                         -1.35470     0.01624    -1.33845    -1.37094
log_probs/min                         -4.92109     0.15406    -4.76703    -5.07515
mean/mean                             -0.00168     0.00000    -0.00168    -0.00169
mean/std                              0.00274      0.00002    0.00277     0.00272
mean/max                              0.00243      0.00001    0.00244     0.00242
mean/min                              -0.00783     0.00004    -0.00779    -0.00787
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 5, 4, 1, 6, 7, 9, 8, 2, 0]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
train_time 0.12086248397827148
eval_infos
eval time 0.002709627151489258
2023-08-31 20:40:35,934 MainThread INFO: EPOCH:20
2023-08-31 20:40:35,934 MainThread INFO: Time Consumed:0.13291573524475098s
2023-08-31 20:40:35,934 MainThread INFO: Total Frames:31500s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:31<01:49,  3.77s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1084.12782
Train_Epoch_Reward                    55367.99191
Running_Training_Average_Rewards      3694.31324
Explore_Time                          0.00387
Train___Time                          0.12086
Eval____Time                          0.00271
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.08716
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.01984
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.33872
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.37497
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20796
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91545
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.92703
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11114.53882
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.10941
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.21734
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           10.72837     0.03283   10.76121    10.69554
alpha_0                               0.98762      0.00015   0.98777     0.98747
alpha_1                               0.98762      0.00015   0.98777     0.98747
alpha_2                               0.98763      0.00015   0.98778     0.98748
alpha_3                               0.98763      0.00015   0.98778     0.98748
alpha_4                               0.98763      0.00015   0.98778     0.98748
alpha_5                               0.98763      0.00015   0.98778     0.98748
alpha_6                               0.98762      0.00015   0.98777     0.98747
alpha_7                               0.98762      0.00015   0.98777     0.98748
alpha_8                               0.98763      0.00015   0.98778     0.98748
alpha_9                               0.98763      0.00015   0.98777     0.98748
Alpha_loss                            -0.08133     0.00091   -0.08043    -0.08224
Training/policy_loss                  -2.67308     0.00801   -2.66507    -2.68109
Training/qf1_loss                     2078.05707   65.71759  2143.77466  2012.33948
Training/qf2_loss                     2078.09497   65.71704  2143.81201  2012.37793
Training/pf_norm                      0.38733      0.01963   0.40696     0.36770
Training/qf1_norm                     26.87959     0.06508   26.94467    26.81450
Training/qf2_norm                     27.02192     0.06745   27.08937    26.95447
log_std/mean                          -0.01395     0.00018   -0.01377    -0.01413
log_std/std                           0.00216      0.00000   0.00217     0.00216
log_std/max                           -0.01136     0.00017   -0.01119    -0.01153
log_std/min                           -0.01996     0.00020   -0.01976    -0.02016
log_probs/mean                        -2.69336     0.00791   -2.68544    -2.70127
log_probs/std                         0.40637      0.00225   0.40862     0.40412
log_probs/max                         -1.37911     0.04952   -1.32959    -1.42863
log_probs/min                         -4.22705     0.23619   -3.99086    -4.46324
mean/mean                             -0.00173     0.00002   -0.00171    -0.00175
mean/std                              0.00267      0.00002   0.00269     0.00266
mean/max                              0.00235      0.00001   0.00236     0.00234
mean/min                              -0.00776     0.00001   -0.00774    -0.00777
------------------------------------  -----------  --------  ----------  ----------
start to update mask
sample: [4, 7, 0, 5, 8, 1, 6, 2, 3, 9]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
train_time 0.11252284049987793
eval_infos
eval time 0.0038559436798095703
2023-08-31 20:40:44,134 MainThread INFO: EPOCH:21
2023-08-31 20:40:44,135 MainThread INFO: Time Consumed:0.12598729133605957s
2023-08-31 20:40:44,135 MainThread INFO: Total Frames:33000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:40<02:22,  5.10s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1086.14072
Train_Epoch_Reward                    11985.53800
Running_Training_Average_Rewards      2844.13237
Explore_Time                          0.00331
Train___Time                          0.11252
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.63576
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02767
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.34344
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.36210
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20105
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91520
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.91775
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11127.27845
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11527
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.19046
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.32528     0.94775    11.27303    9.37753
alpha_0                               0.98702      0.00015    0.98717     0.98688
alpha_1                               0.98702      0.00015    0.98717     0.98688
alpha_2                               0.98703      0.00015    0.98718     0.98689
alpha_3                               0.98704      0.00015    0.98719     0.98689
alpha_4                               0.98704      0.00015    0.98719     0.98689
alpha_5                               0.98704      0.00015    0.98719     0.98689
alpha_6                               0.98703      0.00015    0.98718     0.98688
alpha_7                               0.98703      0.00015    0.98718     0.98688
alpha_8                               0.98703      0.00015    0.98718     0.98689
alpha_9                               0.98703      0.00015    0.98718     0.98688
Alpha_loss                            -0.08541     0.00092    -0.08449    -0.08633
Training/policy_loss                  -2.67648     0.00674    -2.66973    -2.68322
Training/qf1_loss                     2299.45844   539.07013  2838.52856  1760.38831
Training/qf2_loss                     2299.49396   539.07147  2838.56543  1760.42249
Training/pf_norm                      0.37065      0.00484    0.37549     0.36582
Training/qf1_norm                     26.03712     1.90527    27.94239    24.13185
Training/qf2_norm                     26.17610     1.92321    28.09930    24.25289
log_std/mean                          -0.01468     0.00018    -0.01449    -0.01486
log_std/std                           0.00218      0.00000    0.00218     0.00218
log_std/max                           -0.01206     0.00018    -0.01188    -0.01224
log_std/min                           -0.02073     0.00022    -0.02051    -0.02094
log_probs/mean                        -2.69761     0.00662    -2.69099    -2.70423
log_probs/std                         0.40688      0.00230    0.40918     0.40458
log_probs/max                         -1.32406     0.01907    -1.30499    -1.34313
log_probs/min                         -3.95829     0.37709    -3.58120    -4.33538
mean/mean                             -0.00179     0.00001    -0.00178    -0.00180
mean/std                              0.00259      0.00002    0.00261     0.00257
mean/max                              0.00236      0.00002    0.00237     0.00234
mean/min                              -0.00766     0.00003    -0.00762    -0.00769
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 4, 1, 7, 5, 2, 9, 6, 3, 8]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
train_time 0.11102080345153809
eval_infos
eval time 0.002655506134033203
2023-08-31 20:40:44,751 MainThread INFO: EPOCH:22
2023-08-31 20:40:44,752 MainThread INFO: Time Consumed:0.12273430824279785s
2023-08-31 20:40:44,752 MainThread INFO: Total Frames:34500s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:40<01:41,  3.76s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1087.96098
Train_Epoch_Reward                    4728.05417
Running_Training_Average_Rewards      2402.71947
Explore_Time                          0.00420
Train___Time                          0.11102
Eval____Time                          0.00266
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.92844
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.04751
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.34616
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.35417
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20155
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92179
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.91974
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11146.92785
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.13118
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.15849
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           12.00677     0.43137    12.43814    11.57540
alpha_0                               0.98643      0.00015    0.98658     0.98628
alpha_1                               0.98643      0.00015    0.98658     0.98628
alpha_2                               0.98644      0.00015    0.98659     0.98629
alpha_3                               0.98645      0.00015    0.98660     0.98630
alpha_4                               0.98645      0.00015    0.98659     0.98630
alpha_5                               0.98644      0.00015    0.98659     0.98630
alpha_6                               0.98643      0.00015    0.98658     0.98629
alpha_7                               0.98644      0.00015    0.98659     0.98629
alpha_8                               0.98644      0.00015    0.98659     0.98629
alpha_9                               0.98644      0.00015    0.98659     0.98629
Alpha_loss                            -0.08929     0.00097    -0.08832    -0.09026
Training/policy_loss                  -2.66522     0.00257    -2.66265    -2.66779
Training/qf1_loss                     2962.37854   199.87195  3162.25049  2762.50659
Training/qf2_loss                     2962.41248   199.87415  3162.28662  2762.53833
Training/pf_norm                      0.38481      0.00823    0.39304     0.37659
Training/qf1_norm                     29.44634     0.85356    30.29990    28.59279
Training/qf2_norm                     29.64359     0.85144    30.49502    28.79215
log_std/mean                          -0.01540     0.00018    -0.01522    -0.01559
log_std/std                           0.00220      0.00001    0.00220     0.00219
log_std/max                           -0.01278     0.00019    -0.01259    -0.01297
log_std/min                           -0.02158     0.00022    -0.02137    -0.02180
log_probs/mean                        -2.68704     0.00240    -2.68464    -2.68944
log_probs/std                         0.40482      0.00220    0.40702     0.40262
log_probs/max                         -1.47754     0.04911    -1.42843    -1.52664
log_probs/min                         -4.37738     0.66468    -3.71270    -5.04206
mean/mean                             -0.00183     0.00001    -0.00182    -0.00184
mean/std                              0.00254      0.00000    0.00254     0.00253
mean/max                              0.00249      0.00007    0.00256     0.00242
mean/min                              -0.00754     0.00002    -0.00752    -0.00756
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 2, 8, 6, 3, 4, 9, 1, 5, 7]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
train_time 0.11316990852355957
eval_infos
eval time 0.0027201175689697266
2023-08-31 20:40:45,378 MainThread INFO: EPOCH:23
2023-08-31 20:40:45,378 MainThread INFO: Time Consumed:0.12476515769958496s
2023-08-31 20:40:45,378 MainThread INFO: Total Frames:36000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:41<01:13,  2.81s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1089.80995
Train_Epoch_Reward                    27191.90885
Running_Training_Average_Rewards      1463.51670
Explore_Time                          0.00406
Train___Time                          0.11317
Eval____Time                          0.00272
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.25055
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.06161
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.35879
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34401
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21147
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93605
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93017
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11170.16554
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.14039
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.12264
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           12.27838     0.52501    12.80338    11.75337
alpha_0                               0.98584      0.00015    0.98599     0.98569
alpha_1                               0.98584      0.00015    0.98599     0.98569
alpha_2                               0.98585      0.00015    0.98600     0.98570
alpha_3                               0.98586      0.00015    0.98601     0.98571
alpha_4                               0.98586      0.00015    0.98600     0.98571
alpha_5                               0.98585      0.00015    0.98600     0.98570
alpha_6                               0.98584      0.00015    0.98599     0.98569
alpha_7                               0.98585      0.00015    0.98599     0.98570
alpha_8                               0.98585      0.00015    0.98600     0.98570
alpha_9                               0.98585      0.00015    0.98599     0.98570
Alpha_loss                            -0.09344     0.00103    -0.09241    -0.09447
Training/policy_loss                  -2.67382     0.00178    -2.67204    -2.67561
Training/qf1_loss                     2924.11169   345.24329  3269.35498  2578.86841
Training/qf2_loss                     2924.14624   345.24487  3269.39111  2578.90137
Training/pf_norm                      0.36365      0.00382    0.36747     0.35983
Training/qf1_norm                     30.03300     1.08202    31.11502    28.95098
Training/qf2_norm                     30.23302     1.08222    31.31524    29.15079
log_std/mean                          -0.01614     0.00018    -0.01595    -0.01632
log_std/std                           0.00222      0.00000    0.00222     0.00222
log_std/max                           -0.01351     0.00018    -0.01332    -0.01369
log_std/min                           -0.02248     0.00022    -0.02226    -0.02270
log_probs/mean                        -2.69661     0.00201    -2.69459    -2.69862
log_probs/std                         0.40146      0.00704    0.40850     0.39442
log_probs/max                         -1.38757     0.08798    -1.29959    -1.47555
log_probs/min                         -4.02299     0.12620    -3.89679    -4.14919
mean/mean                             -0.00183     0.00001    -0.00181    -0.00184
mean/std                              0.00251      0.00001    0.00252     0.00250
mean/max                              0.00278      0.00007    0.00285     0.00271
mean/min                              -0.00742     0.00006    -0.00737    -0.00748
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [3, 2, 8, 5, 7, 6, 0, 1, 4, 9]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
train_time 0.12287640571594238
eval_infos
eval time 0.008306264877319336
2023-08-31 20:40:53,742 MainThread INFO: EPOCH:24
2023-08-31 20:40:53,743 MainThread INFO: Time Consumed:0.14140748977661133s
2023-08-31 20:40:53,744 MainThread INFO: Total Frames:37500s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:49<01:52,  4.49s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1091.60309
Train_Epoch_Reward                    6481.51072
Running_Training_Average_Rewards      1280.04912
Explore_Time                          0.00446
Train___Time                          0.12288
Eval____Time                          0.00831
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.43660
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.07629
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.38197
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34139
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.23662
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95848
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.95441
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11185.99599
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.15125
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.09509
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           11.34054     0.20389   11.54442    11.13665
alpha_0                               0.98525      0.00015   0.98539     0.98510
alpha_1                               0.98525      0.00015   0.98540     0.98510
alpha_2                               0.98526      0.00015   0.98541     0.98511
alpha_3                               0.98527      0.00015   0.98541     0.98512
alpha_4                               0.98526      0.00015   0.98541     0.98512
alpha_5                               0.98526      0.00015   0.98541     0.98511
alpha_6                               0.98525      0.00015   0.98540     0.98510
alpha_7                               0.98526      0.00015   0.98540     0.98511
alpha_8                               0.98526      0.00015   0.98540     0.98511
alpha_9                               0.98525      0.00015   0.98540     0.98511
Alpha_loss                            -0.09742     0.00098   -0.09644    -0.09840
Training/policy_loss                  -2.67020     0.00201   -2.66819    -2.67222
Training/qf1_loss                     2456.88879   63.42151  2520.31030  2393.46729
Training/qf2_loss                     2456.92017   63.42358  2520.34375  2393.49658
Training/pf_norm                      0.39505      0.00438   0.39943     0.39068
Training/qf1_norm                     28.13892     0.42254   28.56146    27.71638
Training/qf2_norm                     28.32678     0.41759   28.74437    27.90919
log_std/mean                          -0.01688     0.00018   -0.01669    -0.01706
log_std/std                           0.00224      0.00001   0.00225     0.00224
log_std/max                           -0.01423     0.00019   -0.01404    -0.01442
log_std/min                           -0.02335     0.00020   -0.02314    -0.02355
log_probs/mean                        -2.69378     0.00181   -2.69197    -2.69560
log_probs/std                         0.41306      0.00830   0.42136     0.40475
log_probs/max                         -1.47292     0.10380   -1.36912    -1.57672
log_probs/min                         -4.67122     0.22303   -4.44818    -4.89425
mean/mean                             -0.00173     0.00003   -0.00171    -0.00176
mean/std                              0.00247      0.00001   0.00248     0.00246
mean/max                              0.00301      0.00004   0.00306     0.00297
mean/min                              -0.00717     0.00008   -0.00709    -0.00724
------------------------------------  -----------  --------  ----------  ----------
sample: [8, 1, 2, 0, 3, 4, 5, 6, 7, 9]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
train_time 0.13058686256408691
eval_infos
eval time 0.0031707286834716797
2023-08-31 20:40:54,462 MainThread INFO: EPOCH:25
2023-08-31 20:40:54,462 MainThread INFO: Time Consumed:0.1425929069519043s
2023-08-31 20:40:54,463 MainThread INFO: Total Frames:39000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [01:50<01:20,  3.35s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1093.76832
Train_Epoch_Reward                    4937.77872
Running_Training_Average_Rewards      1287.03994
Explore_Time                          0.00349
Train___Time                          0.13059
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.60734
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.07266
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.42276
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.32408
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26089
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.97928
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97558
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11213.72458
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.14225
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.06389
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.52782     0.57699    12.10480    10.95083
alpha_0                               0.98465      0.00015    0.98480     0.98451
alpha_1                               0.98466      0.00015    0.98480     0.98451
alpha_2                               0.98467      0.00015    0.98481     0.98452
alpha_3                               0.98468      0.00015    0.98483     0.98453
alpha_4                               0.98467      0.00015    0.98482     0.98453
alpha_5                               0.98467      0.00015    0.98482     0.98452
alpha_6                               0.98466      0.00015    0.98481     0.98451
alpha_7                               0.98466      0.00015    0.98481     0.98452
alpha_8                               0.98467      0.00015    0.98481     0.98452
alpha_9                               0.98466      0.00015    0.98481     0.98451
Alpha_loss                            -0.10142     0.00099    -0.10043    -0.10241
Training/policy_loss                  -2.66828     0.00095    -2.66733    -2.66923
Training/qf1_loss                     2877.61133   563.33545  3440.94678  2314.27588
Training/qf2_loss                     2877.63831   563.33752  3440.97583  2314.30078
Training/pf_norm                      0.36827      0.01342    0.38170     0.35485
Training/qf1_norm                     28.49697     1.18824    29.68521    27.30874
Training/qf2_norm                     28.71436     1.18712    29.90148    27.52724
log_std/mean                          -0.01762     0.00019    -0.01744    -0.01781
log_std/std                           0.00228      0.00001    0.00229     0.00227
log_std/max                           -0.01495     0.00018    -0.01477    -0.01514
log_std/min                           -0.02418     0.00024    -0.02395    -0.02442
log_probs/mean                        -2.69266     0.00076    -2.69190    -2.69341
log_probs/std                         0.39143      0.00603    0.39746     0.38541
log_probs/max                         -1.59559     0.01204    -1.58355    -1.60763
log_probs/min                         -4.18153     0.37462    -3.80691    -4.55615
mean/mean                             -0.00162     0.00002    -0.00159    -0.00164
mean/std                              0.00242      0.00002    0.00244     0.00240
mean/max                              0.00308      0.00000    0.00308     0.00308
mean/min                              -0.00687     0.00006    -0.00681    -0.00693
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 0, 6, 8, 7, 5, 1, 4, 9, 2]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
train_time 0.11952853202819824
eval_infos
eval time 0.0029783248901367188
2023-08-31 20:40:55,120 MainThread INFO: EPOCH:26
2023-08-31 20:40:55,120 MainThread INFO: Time Consumed:0.1319591999053955s
2023-08-31 20:40:55,121 MainThread INFO: Total Frames:40500s
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [01:51<00:58,  2.54s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1095.77510
Train_Epoch_Reward                    8125.24557
Running_Training_Average_Rewards      651.48450
Explore_Time                          0.00362
Train___Time                          0.11953
Eval____Time                          0.00298
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.91641
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.06022
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.45534
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.30494
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.27524
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.98917
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98526
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11232.16574
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12645
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.03954
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           9.98764      0.11420   10.10184    9.87344
alpha_0                               0.98406      0.00015   0.98421     0.98391
alpha_1                               0.98407      0.00015   0.98421     0.98392
alpha_2                               0.98408      0.00015   0.98422     0.98393
alpha_3                               0.98409      0.00015   0.98423     0.98394
alpha_4                               0.98408      0.00015   0.98423     0.98393
alpha_5                               0.98408      0.00015   0.98423     0.98393
alpha_6                               0.98407      0.00015   0.98421     0.98392
alpha_7                               0.98407      0.00015   0.98422     0.98392
alpha_8                               0.98407      0.00015   0.98422     0.98393
alpha_9                               0.98407      0.00015   0.98422     0.98392
Alpha_loss                            -0.10560     0.00082   -0.10478    -0.10642
Training/policy_loss                  -2.67755     0.01175   -2.66580    -2.68930
Training/qf1_loss                     2053.17096   41.96527  2095.13623  2011.20569
Training/qf2_loss                     2053.19958   41.96301  2095.16260  2011.23657
Training/pf_norm                      0.36406      0.04200   0.40606     0.32206
Training/qf1_norm                     25.39056     0.24966   25.64021    25.14090
Training/qf2_norm                     25.55108     0.24089   25.79197    25.31020
log_std/mean                          -0.01837     0.00019   -0.01818    -0.01856
log_std/std                           0.00232      0.00001   0.00233     0.00231
log_std/max                           -0.01569     0.00018   -0.01551    -0.01587
log_std/min                           -0.02524     0.00023   -0.02501    -0.02547
log_probs/mean                        -2.70289     0.01175   -2.69114    -2.71463
log_probs/std                         0.39968      0.00277   0.40245     0.39691
log_probs/max                         -1.52289     0.06208   -1.46081    -1.58498
log_probs/min                         -4.34406     0.36399   -3.98007    -4.70806
mean/mean                             -0.00147     0.00004   -0.00143    -0.00151
mean/std                              0.00235      0.00001   0.00236     0.00233
mean/max                              0.00319      0.00002   0.00321     0.00316
mean/min                              -0.00661     0.00006   -0.00654    -0.00667
------------------------------------  -----------  --------  ----------  ----------
start to update mask
sample: [1, 3, 4, 6, 7, 2, 9, 8, 5, 0]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
train_time 0.12281346321105957
eval_infos
eval time 0.006333589553833008
2023-08-31 20:41:03,086 MainThread INFO: EPOCH:27
2023-08-31 20:41:03,086 MainThread INFO: Time Consumed:0.13861989974975586s
2023-08-31 20:41:03,086 MainThread INFO: Total Frames:42000s
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [01:58<01:31,  4.16s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1097.89711
Train_Epoch_Reward                    1641.30294
Running_Training_Average_Rewards      490.14424
Explore_Time                          0.00427
Train___Time                          0.12281
Eval____Time                          0.00633
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.64786
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.04060
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.48099
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.27749
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.27542
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99011
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98071
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11250.83795
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.10396
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.01638
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.64723     0.96559    11.61283    9.68164
alpha_0                               0.98347      0.00015    0.98362     0.98332
alpha_1                               0.98348      0.00015    0.98362     0.98333
alpha_2                               0.98349      0.00015    0.98363     0.98334
alpha_3                               0.98350      0.00015    0.98364     0.98335
alpha_4                               0.98349      0.00015    0.98364     0.98334
alpha_5                               0.98349      0.00015    0.98363     0.98334
alpha_6                               0.98347      0.00015    0.98362     0.98333
alpha_7                               0.98348      0.00015    0.98363     0.98333
alpha_8                               0.98348      0.00015    0.98363     0.98334
alpha_9                               0.98348      0.00015    0.98363     0.98333
Alpha_loss                            -0.10946     0.00094    -0.10852    -0.11039
Training/policy_loss                  -2.66654     0.00420    -2.66235    -2.67074
Training/qf1_loss                     2407.95825   185.43628  2593.39453  2222.52197
Training/qf2_loss                     2407.98291   185.43726  2593.42017  2222.54565
Training/pf_norm                      0.35572      0.02227    0.37799     0.33345
Training/qf1_norm                     26.71299     1.94448    28.65746    24.76851
Training/qf2_norm                     26.90889     1.96532    28.87421    24.94357
log_std/mean                          -0.01912     0.00019    -0.01893    -0.01931
log_std/std                           0.00236      0.00001    0.00237     0.00235
log_std/max                           -0.01641     0.00018    -0.01623    -0.01659
log_std/min                           -0.02613     0.00031    -0.02582    -0.02643
log_probs/mean                        -2.69252     0.00406    -2.68846    -2.69658
log_probs/std                         0.39542      0.00576    0.40118     0.38966
log_probs/max                         -1.42110     0.02469    -1.39641    -1.44580
log_probs/min                         -3.77069     0.22651    -3.54418    -3.99719
mean/mean                             -0.00129     0.00005    -0.00124    -0.00134
mean/std                              0.00232      0.00001    0.00232     0.00231
mean/max                              0.00333      0.00008    0.00341     0.00325
mean/min                              -0.00640     0.00005    -0.00635    -0.00644
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 2, 3, 6, 0, 5, 4, 7, 9, 1]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
train_time 0.12484025955200195
eval_infos
eval time 0.0031883716583251953
2023-08-31 20:41:03,721 MainThread INFO: EPOCH:28
2023-08-31 20:41:03,722 MainThread INFO: Time Consumed:0.1369326114654541s
2023-08-31 20:41:03,722 MainThread INFO: Total Frames:43500s
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [01:59<01:05,  3.11s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1099.72787
Train_Epoch_Reward                    25820.71674
Running_Training_Average_Rewards      1186.24218
Explore_Time                          0.00350
Train___Time                          0.12484
Eval____Time                          0.00319
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.95940
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.01804
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.50743
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.25606
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28693
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.00284
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98813
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11266.90729
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.08424
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.00558
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.38110     1.02527    11.40637    9.35583
alpha_0                               0.98288      0.00015    0.98303     0.98273
alpha_1                               0.98288      0.00015    0.98303     0.98274
alpha_2                               0.98290      0.00015    0.98304     0.98275
alpha_3                               0.98291      0.00015    0.98305     0.98276
alpha_4                               0.98290      0.00015    0.98305     0.98275
alpha_5                               0.98290      0.00015    0.98304     0.98275
alpha_6                               0.98288      0.00015    0.98303     0.98274
alpha_7                               0.98289      0.00015    0.98304     0.98274
alpha_8                               0.98289      0.00015    0.98304     0.98275
alpha_9                               0.98289      0.00015    0.98304     0.98274
Alpha_loss                            -0.11321     0.00087    -0.11234    -0.11409
Training/policy_loss                  -2.65071     0.00759    -2.64312    -2.65830
Training/qf1_loss                     2261.92700   453.55469  2715.48169  1808.37231
Training/qf2_loss                     2261.94708   453.55023  2715.49731  1808.39685
Training/pf_norm                      0.39103      0.02663    0.41766     0.36440
Training/qf1_norm                     26.15947     2.06810    28.22757    24.09137
Training/qf2_norm                     26.37448     2.12546    28.49994    24.24902
log_std/mean                          -0.01987     0.00019    -0.01968    -0.02006
log_std/std                           0.00241      0.00001    0.00242     0.00240
log_std/max                           -0.01714     0.00018    -0.01695    -0.01732
log_std/min                           -0.02714     0.00025    -0.02689    -0.02739
log_probs/mean                        -2.67720     0.00753    -2.66967    -2.68473
log_probs/std                         0.39034      0.00405    0.39439     0.38629
log_probs/max                         -1.44432     0.00373    -1.44059    -1.44805
log_probs/min                         -3.81552     0.16518    -3.65034    -3.98071
mean/mean                             -0.00109     0.00005    -0.00103    -0.00114
mean/std                              0.00229      0.00000    0.00230     0.00229
mean/max                              0.00362      0.00007    0.00369     0.00355
mean/min                              -0.00618     0.00005    -0.00614    -0.00623
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 7, 3, 4, 0, 8, 1, 5, 2]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
train_time 0.10714340209960938
eval_infos
eval time 0.0025734901428222656
2023-08-31 20:41:04,328 MainThread INFO: EPOCH:29
2023-08-31 20:41:04,328 MainThread INFO: Time Consumed:0.1175229549407959s
2023-08-31 20:41:04,328 MainThread INFO: Total Frames:45000s
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [02:00<00:47,  2.36s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.65017
Train_Epoch_Reward                    5457.62988
Running_Training_Average_Rewards      1097.32165
Explore_Time                          0.00297
Train___Time                          0.10714
Eval____Time                          0.00257
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.02281
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.99091
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54876
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.23196
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31489
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.02580
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01167
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11296.87710
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.06007
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.98830
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.84495      0.60481    9.44976     8.24014
alpha_0                               0.98229      0.00015    0.98244     0.98214
alpha_1                               0.98230      0.00015    0.98244     0.98215
alpha_2                               0.98231      0.00015    0.98245     0.98216
alpha_3                               0.98232      0.00015    0.98246     0.98217
alpha_4                               0.98231      0.00015    0.98246     0.98217
alpha_5                               0.98231      0.00015    0.98245     0.98216
alpha_6                               0.98229      0.00015    0.98244     0.98215
alpha_7                               0.98230      0.00015    0.98245     0.98215
alpha_8                               0.98230      0.00015    0.98245     0.98216
alpha_9                               0.98230      0.00015    0.98245     0.98215
Alpha_loss                            -0.11761     0.00094    -0.11667    -0.11855
Training/policy_loss                  -2.67166     0.00378    -2.66789    -2.67544
Training/qf1_loss                     1769.17871   186.16565  1955.34436  1583.01306
Training/qf2_loss                     1769.20209   186.17035  1955.37244  1583.03174
Training/pf_norm                      0.35489      0.00268    0.35757     0.35221
Training/qf1_norm                     23.09180     1.22241    24.31421    21.86939
Training/qf2_norm                     23.24311     1.21002    24.45313    22.03309
log_std/mean                          -0.02063     0.00019    -0.02044    -0.02082
log_std/std                           0.00245      0.00001    0.00246     0.00244
log_std/max                           -0.01787     0.00018    -0.01769    -0.01805
log_std/min                           -0.02812     0.00024    -0.02788    -0.02835
log_probs/mean                        -2.69933     0.00366    -2.69567    -2.70298
log_probs/std                         0.39628      0.00222    0.39850     0.39405
log_probs/max                         -1.43810     0.01266    -1.42544    -1.45076
log_probs/min                         -4.15962     0.03443    -4.12518    -4.19405
mean/mean                             -0.00091     0.00004    -0.00086    -0.00095
mean/std                              0.00226      0.00002    0.00227     0.00224
mean/max                              0.00385      0.00004    0.00390     0.00381
mean/min                              -0.00590     0.00009    -0.00581    -0.00599
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [2, 6, 8, 4, 7, 3, 5, 0, 1, 9]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
train_time 0.16087961196899414
eval_infos
eval time 0.004829883575439453
2023-08-31 20:41:12,400 MainThread INFO: EPOCH:30
2023-08-31 20:41:12,401 MainThread INFO: Time Consumed:0.18010544776916504s
2023-08-31 20:41:12,401 MainThread INFO: Total Frames:46500s
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [02:08<01:17,  4.07s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1104.54758
Train_Epoch_Reward                    12645.06161
Running_Training_Average_Rewards      1464.11361
Explore_Time                          0.00553
Train___Time                          0.16088
Eval____Time                          0.00483
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.02508
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96344
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.59525
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.20682
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.34368
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.05093
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.03350
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11331.17283
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.03494
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.97237
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.31780     1.04313    12.36094    10.27467
alpha_0                               0.98170      0.00015    0.98185     0.98155
alpha_1                               0.98171      0.00015    0.98185     0.98156
alpha_2                               0.98172      0.00015    0.98187     0.98157
alpha_3                               0.98173      0.00015    0.98187     0.98158
alpha_4                               0.98172      0.00015    0.98187     0.98158
alpha_5                               0.98172      0.00015    0.98186     0.98157
alpha_6                               0.98170      0.00015    0.98185     0.98156
alpha_7                               0.98171      0.00015    0.98186     0.98156
alpha_8                               0.98172      0.00015    0.98186     0.98157
alpha_9                               0.98171      0.00015    0.98186     0.98156
Alpha_loss                            -0.12151     0.00103    -0.12049    -0.12254
Training/policy_loss                  -2.66426     0.00093    -2.66333    -2.66519
Training/qf1_loss                     2589.11682   366.62708  2955.74390  2222.48975
Training/qf2_loss                     2589.14111   366.62793  2955.76904  2222.51318
Training/pf_norm                      0.37467      0.00145    0.37612     0.37321
Training/qf1_norm                     28.09782     2.10244    30.20026    25.99539
Training/qf2_norm                     28.30284     2.12091    30.42375    26.18192
log_std/mean                          -0.02139     0.00019    -0.02120    -0.02158
log_std/std                           0.00250      0.00002    0.00252     0.00248
log_std/max                           -0.01859     0.00018    -0.01841    -0.01877
log_std/min                           -0.02896     0.00030    -0.02866    -0.02925
log_probs/mean                        -2.69256     0.00114    -2.69142    -2.69370
log_probs/std                         0.38720      0.00619    0.39339     0.38102
log_probs/max                         -1.37853     0.01138    -1.36715    -1.38991
log_probs/min                         -4.34011     0.28897    -4.05114    -4.62908
mean/mean                             -0.00075     0.00004    -0.00071    -0.00079
mean/std                              0.00220      0.00001    0.00221     0.00220
mean/max                              0.00404      0.00005    0.00409     0.00398
mean/min                              -0.00550     0.00008    -0.00542    -0.00558
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 0, 1, 6, 9, 2, 3, 5, 8, 4]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
train_time 0.1490767002105713
eval_infos
eval time 0.003714323043823242
2023-08-31 20:41:13,249 MainThread INFO: EPOCH:31
2023-08-31 20:41:13,249 MainThread INFO: Time Consumed:0.16392135620117188s
2023-08-31 20:41:13,250 MainThread INFO: Total Frames:48000s
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [02:09<00:55,  3.10s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1108.18569
Train_Epoch_Reward                    18824.86340
Running_Training_Average_Rewards      1230.91850
Explore_Time                          0.00426
Train___Time                          0.14908
Eval____Time                          0.00371
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.91106
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.94379
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.63244
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.18058
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36250
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.06132
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.04245
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11373.02750
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.01361
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.93783
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.17612     0.06174    11.23786    11.11438
alpha_0                               0.98111      0.00015    0.98126     0.98096
alpha_1                               0.98112      0.00015    0.98126     0.98097
alpha_2                               0.98113      0.00015    0.98128     0.98098
alpha_3                               0.98114      0.00015    0.98129     0.98099
alpha_4                               0.98114      0.00015    0.98128     0.98099
alpha_5                               0.98113      0.00015    0.98127     0.98098
alpha_6                               0.98111      0.00015    0.98126     0.98097
alpha_7                               0.98112      0.00015    0.98127     0.98097
alpha_8                               0.98113      0.00015    0.98127     0.98098
alpha_9                               0.98112      0.00015    0.98127     0.98097
Alpha_loss                            -0.12553     0.00117    -0.12436    -0.12670
Training/policy_loss                  -2.66345     0.00861    -2.65484    -2.67206
Training/qf1_loss                     2698.45532   195.19385  2893.64917  2503.26147
Training/qf2_loss                     2698.47656   195.19238  2893.66895  2503.28418
Training/pf_norm                      0.35619      0.01356    0.36975     0.34264
Training/qf1_norm                     27.80226     0.11905    27.92131    27.68321
Training/qf2_norm                     28.01437     0.11075    28.12511    27.90362
log_std/mean                          -0.02216     0.00019    -0.02197    -0.02235
log_std/std                           0.00256      0.00002    0.00258     0.00255
log_std/max                           -0.01929     0.00017    -0.01912    -0.01945
log_std/min                           -0.03003     0.00022    -0.02981    -0.03026
log_probs/mean                        -2.69253     0.00897    -2.68357    -2.70150
log_probs/std                         0.39177      0.00406    0.39583     0.38771
log_probs/max                         -1.49936     0.03462    -1.46474    -1.53398
log_probs/min                         -4.04613     0.13038    -3.91575    -4.17651
mean/mean                             -0.00065     0.00001    -0.00064    -0.00067
mean/std                              0.00219      0.00001    0.00220     0.00218
mean/max                              0.00424      0.00007    0.00431     0.00417
mean/min                              -0.00525     0.00006    -0.00520    -0.00531
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 3, 2, 0, 1, 9, 8, 7, 5, 4]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
train_time 0.1281452178955078
eval_infos
eval time 0.0038983821868896484
2023-08-31 20:41:13,946 MainThread INFO: EPOCH:32
2023-08-31 20:41:13,946 MainThread INFO: Time Consumed:0.14138364791870117s
2023-08-31 20:41:13,946 MainThread INFO: Total Frames:49500s
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [02:09<00:40,  2.38s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1111.64559
Train_Epoch_Reward                    32594.58554
Running_Training_Average_Rewards      2135.48368
Explore_Time                          0.00433
Train___Time                          0.12815
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.04526
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.93292
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.65254
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.16375
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.37611
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.06576
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.04691
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11400.66779
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.99560
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.91012
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.13302     0.53310    11.66613    10.59992
alpha_0                               0.98052      0.00015    0.98067     0.98038
alpha_1                               0.98053      0.00015    0.98067     0.98038
alpha_2                               0.98054      0.00015    0.98069     0.98039
alpha_3                               0.98055      0.00015    0.98070     0.98040
alpha_4                               0.98055      0.00015    0.98069     0.98040
alpha_5                               0.98054      0.00015    0.98069     0.98039
alpha_6                               0.98052      0.00015    0.98067     0.98038
alpha_7                               0.98053      0.00015    0.98068     0.98038
alpha_8                               0.98054      0.00015    0.98069     0.98039
alpha_9                               0.98053      0.00015    0.98068     0.98038
Alpha_loss                            -0.12962     0.00106    -0.12856    -0.13069
Training/policy_loss                  -2.66657     0.00282    -2.66375    -2.66939
Training/qf1_loss                     2620.75635   211.15039  2831.90674  2409.60596
Training/qf2_loss                     2620.77490   211.14771  2831.92261  2409.62720
Training/pf_norm                      0.33830      0.01002    0.34833     0.32828
Training/qf1_norm                     27.69056     1.09655    28.78710    26.59401
Training/qf2_norm                     27.91872     1.11307    29.03179    26.80565
log_std/mean                          -0.02292     0.00019    -0.02273    -0.02311
log_std/std                           0.00262      0.00001    0.00264     0.00261
log_std/max                           -0.01996     0.00017    -0.01980    -0.02013
log_std/min                           -0.03108     0.00023    -0.03084    -0.03131
log_probs/mean                        -2.69650     0.00305    -2.69345    -2.69955
log_probs/std                         0.39412      0.00162    0.39574     0.39250
log_probs/max                         -1.44964     0.03630    -1.41334    -1.48594
log_probs/min                         -4.24221     0.42336    -3.81885    -4.66557
mean/mean                             -0.00055     0.00003    -0.00052    -0.00058
mean/std                              0.00220      0.00000    0.00220     0.00219
mean/max                              0.00455      0.00006    0.00461     0.00448
mean/min                              -0.00499     0.00008    -0.00491    -0.00507
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [3, 9, 5, 0, 1, 6, 8, 7, 4, 2]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
train_time 0.1465911865234375
eval_infos
eval time 0.003554105758666992
2023-08-31 20:41:22,516 MainThread INFO: EPOCH:33
2023-08-31 20:41:22,517 MainThread INFO: Time Consumed:0.16260170936584473s
2023-08-31 20:41:22,518 MainThread INFO: Total Frames:51000s
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [02:18<01:07,  4.24s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1115.03756
Train_Epoch_Reward                    28504.84239
Running_Training_Average_Rewards      2664.14304
Explore_Time                          0.00396
Train___Time                          0.14659
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.30895
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.93068
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.68237
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.15270
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.40468
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.09096
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.06370
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11432.20173
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.98505
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.87649
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.27167     0.90011    12.17178    10.37156
alpha_0                               0.97993      0.00015    0.98008     0.97979
alpha_1                               0.97994      0.00015    0.98008     0.97979
alpha_2                               0.97995      0.00015    0.98010     0.97981
alpha_3                               0.97996      0.00015    0.98011     0.97981
alpha_4                               0.97996      0.00015    0.98011     0.97981
alpha_5                               0.97995      0.00015    0.98010     0.97980
alpha_6                               0.97994      0.00015    0.98008     0.97979
alpha_7                               0.97994      0.00015    0.98009     0.97979
alpha_8                               0.97995      0.00015    0.98010     0.97981
alpha_9                               0.97994      0.00015    0.98009     0.97979
Alpha_loss                            -0.13365     0.00101    -0.13264    -0.13466
Training/policy_loss                  -2.66619     0.00022    -2.66596    -2.66641
Training/qf1_loss                     2712.28589   534.20581  3246.49170  2178.08008
Training/qf2_loss                     2712.30212   534.20593  3246.50806  2178.09619
Training/pf_norm                      0.35114      0.00340    0.35454     0.34774
Training/qf1_norm                     28.01367     1.83251    29.84618    26.18115
Training/qf2_norm                     28.24777     1.85102    30.09879    26.39675
log_std/mean                          -0.02368     0.00019    -0.02349    -0.02387
log_std/std                           0.00268      0.00002    0.00270     0.00266
log_std/max                           -0.02064     0.00017    -0.02047    -0.02080
log_std/min                           -0.03203     0.00029    -0.03174    -0.03233
log_probs/mean                        -2.69687     0.00041    -2.69646    -2.69729
log_probs/std                         0.38706      0.00093    0.38799     0.38613
log_probs/max                         -1.41820     0.06535    -1.35285    -1.48355
log_probs/min                         -4.07727     0.19072    -3.88655    -4.26799
mean/mean                             -0.00046     0.00002    -0.00044    -0.00048
mean/std                              0.00217      0.00000    0.00217     0.00216
mean/max                              0.00473      0.00005    0.00478     0.00467
mean/min                              -0.00460     0.00008    -0.00452    -0.00468
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 9, 4, 6, 2, 1, 0, 8, 3, 5]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
train_time 0.12278223037719727
eval_infos
eval time 0.002811431884765625
2023-08-31 20:41:23,112 MainThread INFO: EPOCH:34
2023-08-31 20:41:23,113 MainThread INFO: Time Consumed:0.13505339622497559s
2023-08-31 20:41:23,113 MainThread INFO: Total Frames:52500s
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [02:19<00:47,  3.15s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1118.19258
Train_Epoch_Reward                    9565.53407
Running_Training_Average_Rewards      2355.49873
Explore_Time                          0.00426
Train___Time                          0.12278
Eval____Time                          0.00281
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.34488
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.92336
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.72748
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.12746
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42976
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.11204
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.08267
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11480.13294
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.96605
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.82671
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           10.14829     0.16030   10.30859    9.98799
alpha_0                               0.97935      0.00015   0.97949     0.97920
alpha_1                               0.97935      0.00015   0.97950     0.97920
alpha_2                               0.97937      0.00015   0.97951     0.97922
alpha_3                               0.97937      0.00015   0.97952     0.97923
alpha_4                               0.97937      0.00015   0.97952     0.97923
alpha_5                               0.97936      0.00015   0.97951     0.97921
alpha_6                               0.97935      0.00015   0.97949     0.97920
alpha_7                               0.97935      0.00015   0.97950     0.97921
alpha_8                               0.97936      0.00015   0.97951     0.97922
alpha_9                               0.97935      0.00015   0.97950     0.97921
Alpha_loss                            -0.13774     0.00135   -0.13639    -0.13908
Training/policy_loss                  -2.66858     0.01602   -2.65256    -2.68459
Training/qf1_loss                     2366.53064   97.50085  2464.03149  2269.02979
Training/qf2_loss                     2366.54797   97.49939  2464.04736  2269.04858
Training/pf_norm                      0.32013      0.05609   0.37622     0.26404
Training/qf1_norm                     25.69157     0.32693   26.01850    25.36464
Training/qf2_norm                     25.90316     0.33605   26.23921    25.56711
log_std/mean                          -0.02444     0.00019   -0.02425    -0.02463
log_std/std                           0.00274      0.00002   0.00276     0.00272
log_std/max                           -0.02128     0.00016   -0.02112    -0.02144
log_std/min                           -0.03300     0.00023   -0.03277    -0.03322
log_probs/mean                        -2.70006     0.01655   -2.68350    -2.71661
log_probs/std                         0.38327      0.00197   0.38523     0.38130
log_probs/max                         -1.44162     0.05486   -1.38676    -1.49649
log_probs/min                         -4.35276     0.22883   -4.12394    -4.58159
mean/mean                             -0.00034     0.00002   -0.00032    -0.00036
mean/std                              0.00215      0.00000   0.00215     0.00215
mean/max                              0.00494      0.00005   0.00499     0.00489
mean/min                              -0.00425     0.00005   -0.00421    -0.00430
------------------------------------  -----------  --------  ----------  ----------
sample: [8, 0, 9, 3, 2, 5, 4, 6, 7, 1]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
train_time 0.11527204513549805
eval_infos
eval time 0.0032041072845458984
2023-08-31 20:41:23,751 MainThread INFO: EPOCH:35
2023-08-31 20:41:23,752 MainThread INFO: Time Consumed:0.12657594680786133s
2023-08-31 20:41:23,752 MainThread INFO: Total Frames:54000s
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [02:19<00:33,  2.39s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1122.93994
Train_Epoch_Reward                    6101.33965
Running_Training_Average_Rewards      1472.39054
Explore_Time                          0.00317
Train___Time                          0.11527
Eval____Time                          0.00320
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.01978
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.91230
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.77554
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.09741
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45036
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13142
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.10028
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11538.10873
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.95014
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.77209
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.67347      0.89230    10.56577    8.78117
alpha_0                               0.97876      0.00015    0.97891     0.97861
alpha_1                               0.97876      0.00015    0.97891     0.97861
alpha_2                               0.97878      0.00015    0.97892     0.97863
alpha_3                               0.97878      0.00015    0.97893     0.97864
alpha_4                               0.97878      0.00015    0.97893     0.97864
alpha_5                               0.97877      0.00015    0.97892     0.97863
alpha_6                               0.97876      0.00015    0.97891     0.97861
alpha_7                               0.97877      0.00015    0.97891     0.97862
alpha_8                               0.97878      0.00015    0.97892     0.97863
alpha_9                               0.97876      0.00015    0.97891     0.97862
Alpha_loss                            -0.14163     0.00103    -0.14060    -0.14266
Training/policy_loss                  -2.66180     0.00078    -2.66103    -2.66258
Training/qf1_loss                     1906.44202   221.67468  2128.11670  1684.76733
Training/qf2_loss                     1906.45355   221.67560  2128.12915  1684.77795
Training/pf_norm                      0.35602      0.00059    0.35661     0.35544
Training/qf1_norm                     24.76727     1.79424    26.56151    22.97303
Training/qf2_norm                     24.98027     1.81050    26.79076    23.16977
log_std/mean                          -0.02519     0.00019    -0.02501    -0.02538
log_std/std                           0.00281      0.00001    0.00283     0.00280
log_std/max                           -0.02193     0.00017    -0.02176    -0.02209
log_std/min                           -0.03401     0.00020    -0.03381    -0.03421
log_probs/mean                        -2.69397     0.00098    -2.69299    -2.69496
log_probs/std                         0.38386      0.00362    0.38748     0.38024
log_probs/max                         -1.37663     0.07426    -1.30236    -1.45089
log_probs/min                         -3.91823     0.14099    -3.77724    -4.05921
mean/mean                             -0.00029     0.00000    -0.00029    -0.00030
mean/std                              0.00220      0.00002    0.00222     0.00218
mean/max                              0.00522      0.00006    0.00528     0.00516
mean/min                              -0.00418     0.00003    -0.00415    -0.00421
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [5, 9, 4, 8, 3, 0, 2, 7, 6, 1]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
train_time 0.12914013862609863
eval_infos
eval time 0.003502368927001953
2023-08-31 20:41:32,584 MainThread INFO: EPOCH:36
2023-08-31 20:41:32,585 MainThread INFO: Time Consumed:0.14312744140625s
2023-08-31 20:41:32,585 MainThread INFO: Total Frames:55500s
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [02:28<00:56,  4.32s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1127.91678
Train_Epoch_Reward                    11878.24349
Running_Training_Average_Rewards      918.17057
Explore_Time                          0.00482
Train___Time                          0.12914
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.39016
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.90828
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.81113
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.08851
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47483
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.15063
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.12317
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11575.64657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.94402
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74436
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.88271     0.47900    12.36171    11.40371
alpha_0                               0.97817      0.00015    0.97832     0.97802
alpha_1                               0.97817      0.00015    0.97832     0.97803
alpha_2                               0.97819      0.00015    0.97834     0.97804
alpha_3                               0.97820      0.00015    0.97834     0.97805
alpha_4                               0.97820      0.00015    0.97834     0.97805
alpha_5                               0.97818      0.00015    0.97833     0.97804
alpha_6                               0.97817      0.00015    0.97832     0.97803
alpha_7                               0.97818      0.00015    0.97833     0.97803
alpha_8                               0.97819      0.00015    0.97834     0.97804
alpha_9                               0.97818      0.00015    0.97832     0.97803
Alpha_loss                            -0.14571     0.00081    -0.14491    -0.14652
Training/policy_loss                  -2.66391     0.00920    -2.65472    -2.67311
Training/qf1_loss                     2826.54407   154.71570  2981.25977  2671.82837
Training/qf2_loss                     2826.55640   154.71655  2981.27295  2671.83984
Training/pf_norm                      0.34490      0.03030    0.37520     0.31461
Training/qf1_norm                     29.25043     1.00525    30.25568    28.24518
Training/qf2_norm                     29.50752     1.01366    30.52118    28.49386
log_std/mean                          -0.02594     0.00019    -0.02576    -0.02613
log_std/std                           0.00288      0.00001    0.00289     0.00286
log_std/max                           -0.02260     0.00017    -0.02243    -0.02277
log_std/min                           -0.03500     0.00028    -0.03472    -0.03528
log_probs/mean                        -2.69684     0.00921    -2.68763    -2.70605
log_probs/std                         0.38243      0.00101    0.38344     0.38143
log_probs/max                         -1.47171     0.04904    -1.42267    -1.52075
log_probs/min                         -4.44616     0.33003    -4.11614    -4.77619
mean/mean                             -0.00027     0.00000    -0.00027    -0.00028
mean/std                              0.00230      0.00003    0.00233     0.00227
mean/max                              0.00546      0.00008    0.00554     0.00538
mean/min                              -0.00429     0.00003    -0.00425    -0.00432
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 3, 4, 9, 5, 0, 8, 6, 2, 1]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
train_time 0.1304466724395752
eval_infos
eval time 0.0032601356506347656
2023-08-31 20:41:33,263 MainThread INFO: EPOCH:37
2023-08-31 20:41:33,264 MainThread INFO: Time Consumed:0.14274191856384277s
2023-08-31 20:41:33,264 MainThread INFO: Total Frames:57000s
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:29<00:38,  3.23s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1132.34006
Train_Epoch_Reward                    6312.47658
Running_Training_Average_Rewards      809.73532
Explore_Time                          0.00401
Train___Time                          0.13045
Eval____Time                          0.00326
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.17781
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.92326
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.83119
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.09668
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.49624
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16856
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14002
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11600.81094
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.96097
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.72536
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.33582     1.05630    11.39211    9.27952
alpha_0                               0.97758      0.00015    0.97773     0.97744
alpha_1                               0.97758      0.00015    0.97773     0.97744
alpha_2                               0.97760      0.00015    0.97775     0.97746
alpha_3                               0.97761      0.00015    0.97775     0.97746
alpha_4                               0.97761      0.00015    0.97776     0.97747
alpha_5                               0.97760      0.00015    0.97774     0.97745
alpha_6                               0.97759      0.00015    0.97773     0.97744
alpha_7                               0.97759      0.00015    0.97774     0.97745
alpha_8                               0.97760      0.00015    0.97775     0.97746
alpha_9                               0.97759      0.00015    0.97774     0.97744
Alpha_loss                            -0.14967     0.00138    -0.14829    -0.15104
Training/policy_loss                  -2.66012     0.01608    -2.64404    -2.67619
Training/qf1_loss                     2254.36096   649.06873  2903.42969  1605.29224
Training/qf2_loss                     2254.37561   649.07214  2903.44775  1605.30347
Training/pf_norm                      0.34571      0.05320    0.39891     0.29251
Training/qf1_norm                     26.08179     2.11397    28.19576    23.96782
Training/qf2_norm                     26.29927     2.13030    28.42957    24.16897
log_std/mean                          -0.02670     0.00019    -0.02651    -0.02690
log_std/std                           0.00294      0.00001    0.00295     0.00292
log_std/max                           -0.02329     0.00018    -0.02312    -0.02347
log_std/min                           -0.03590     0.00020    -0.03570    -0.03610
log_probs/mean                        -2.69371     0.01661    -2.67710    -2.71031
log_probs/std                         0.37327      0.00227    0.37553     0.37100
log_probs/max                         -1.51170     0.03451    -1.47719    -1.54622
log_probs/min                         -3.68744     0.15789    -3.52955    -3.84533
mean/mean                             -0.00027     0.00001    -0.00027    -0.00028
mean/std                              0.00240      0.00003    0.00242     0.00237
mean/max                              0.00557      0.00002    0.00559     0.00556
mean/min                              -0.00442     0.00004    -0.00438    -0.00446
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 1, 4, 5, 9, 8, 3, 2, 0, 7]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
train_time 0.15410923957824707
eval_infos
eval time 0.004533290863037109
2023-08-31 20:41:33,915 MainThread INFO: EPOCH:38
2023-08-31 20:41:33,915 MainThread INFO: Time Consumed:0.16923999786376953s
2023-08-31 20:41:33,916 MainThread INFO: Total Frames:58500s
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [02:29<00:27,  2.46s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1135.01738
Train_Epoch_Reward                    9593.36208
Running_Training_Average_Rewards      926.13607
Explore_Time                          0.00418
Train___Time                          0.15411
Eval____Time                          0.00453
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.19160
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.94141
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84096
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.10950
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.51209
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17967
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14710
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11619.83281
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.98280
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.70852
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.34795      0.84618    10.19413    8.50177
alpha_0                               0.97700      0.00015    0.97714     0.97685
alpha_1                               0.97700      0.00015    0.97714     0.97685
alpha_2                               0.97702      0.00015    0.97716     0.97687
alpha_3                               0.97702      0.00015    0.97717     0.97687
alpha_4                               0.97703      0.00015    0.97717     0.97688
alpha_5                               0.97701      0.00015    0.97716     0.97686
alpha_6                               0.97700      0.00015    0.97715     0.97685
alpha_7                               0.97701      0.00015    0.97715     0.97686
alpha_8                               0.97702      0.00015    0.97716     0.97687
alpha_9                               0.97700      0.00015    0.97715     0.97686
Alpha_loss                            -0.15391     0.00112    -0.15279    -0.15503
Training/policy_loss                  -2.66909     0.00481    -2.66427    -2.67390
Training/qf1_loss                     1576.43365   308.02557  1884.45923  1268.40808
Training/qf2_loss                     1576.44733   308.02863  1884.47595  1268.41870
Training/pf_norm                      0.36881      0.01343    0.38224     0.35539
Training/qf1_norm                     24.10538     1.72796    25.83334    22.37743
Training/qf2_norm                     24.29451     1.73245    26.02696    22.56205
log_std/mean                          -0.02746     0.00019    -0.02727    -0.02766
log_std/std                           0.00299      0.00001    0.00300     0.00297
log_std/max                           -0.02399     0.00017    -0.02382    -0.02416
log_std/min                           -0.03684     0.00032    -0.03651    -0.03716
log_probs/mean                        -2.70363     0.00509    -2.69853    -2.70872
log_probs/std                         0.38205      0.00672    0.38878     0.37533
log_probs/max                         -1.55787     0.01388    -1.54398    -1.57175
log_probs/min                         -4.22560     0.13389    -4.09171    -4.35949
mean/mean                             -0.00029     0.00001    -0.00028    -0.00029
mean/std                              0.00246      0.00001    0.00247     0.00245
mean/max                              0.00565      0.00004    0.00569     0.00561
mean/min                              -0.00471     0.00012    -0.00459    -0.00482
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [9, 4, 8, 3, 1, 0, 5, 2, 6, 7]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
train_time 0.16457891464233398
eval_infos
eval time 0.004409074783325195
snapshot at best
2023-08-31 20:41:43,368 MainThread INFO: EPOCH:39
2023-08-31 20:41:43,369 MainThread INFO: Time Consumed:0.7148537635803223s
2023-08-31 20:41:43,369 MainThread INFO: Total Frames:60000s
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [02:39<00:45,  4.56s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1136.87054
Train_Epoch_Reward                    10169.48447
Running_Training_Average_Rewards      869.17744
Explore_Time                          0.00447
Train___Time                          0.16458
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.84658
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96146
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84320
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.11945
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.51853
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18508
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14918
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11635.92553
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00184
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.69399
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.07099     0.00190    10.07289    10.06909
alpha_0                               0.97641      0.00015    0.97656     0.97626
alpha_1                               0.97641      0.00015    0.97656     0.97626
alpha_2                               0.97643      0.00015    0.97658     0.97628
alpha_3                               0.97643      0.00015    0.97658     0.97628
alpha_4                               0.97644      0.00015    0.97659     0.97629
alpha_5                               0.97642      0.00015    0.97657     0.97628
alpha_6                               0.97641      0.00015    0.97656     0.97627
alpha_7                               0.97642      0.00015    0.97657     0.97627
alpha_8                               0.97643      0.00015    0.97658     0.97628
alpha_9                               0.97642      0.00015    0.97656     0.97627
Alpha_loss                            -0.15772     0.00094    -0.15679    -0.15866
Training/policy_loss                  -2.65955     0.00299    -2.65656    -2.66253
Training/qf1_loss                     1947.95959   135.16858  2083.12817  1812.79102
Training/qf2_loss                     1947.96423   135.17444  2083.13867  1812.78979
Training/pf_norm                      0.35327      0.01520    0.36847     0.33807
Training/qf1_norm                     25.56066     0.01032    25.57098    25.55033
Training/qf2_norm                     25.80520     0.01732    25.82253    25.78788
log_std/mean                          -0.02823     0.00019    -0.02804    -0.02843
log_std/std                           0.00304      0.00001    0.00305     0.00302
log_std/max                           -0.02468     0.00016    -0.02451    -0.02484
log_std/min                           -0.03782     0.00021    -0.03761    -0.03802
log_probs/mean                        -2.69459     0.00290    -2.69170    -2.69749
log_probs/std                         0.38146      0.00380    0.38526     0.37766
log_probs/max                         -1.49324     0.02018    -1.47306    -1.51342
log_probs/min                         -3.85595     0.09280    -3.76315    -3.94875
mean/mean                             -0.00031     0.00001    -0.00030    -0.00032
mean/std                              0.00250      0.00000    0.00250     0.00250
mean/max                              0.00563      0.00003    0.00566     0.00561
mean/min                              -0.00505     0.00007    -0.00498    -0.00512
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 3, 1, 5, 9, 8, 6, 4, 2, 7]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
train_time 0.12020754814147949
eval_infos
eval time 0.0032205581665039062
snapshot at best
2023-08-31 20:41:44,133 MainThread INFO: EPOCH:40
2023-08-31 20:41:44,134 MainThread INFO: Time Consumed:0.6464195251464844s
2023-08-31 20:41:44,134 MainThread INFO: Total Frames:61500s
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [02:39<00:30,  3.42s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1137.97631
Train_Epoch_Reward                    3298.67609
Running_Training_Average_Rewards      768.71742
Explore_Time                          0.00377
Train___Time                          0.12021
Eval____Time                          0.00322
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.45224
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.97254
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84178
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.12691
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.51594
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18436
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14821
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11646.39870
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.01198
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.68087
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           10.09675     0.11072   10.20747    9.98603
alpha_0                               0.97582      0.00015   0.97597     0.97568
alpha_1                               0.97582      0.00015   0.97597     0.97568
alpha_2                               0.97584      0.00015   0.97599     0.97570
alpha_3                               0.97584      0.00015   0.97599     0.97570
alpha_4                               0.97586      0.00015   0.97600     0.97571
alpha_5                               0.97584      0.00015   0.97598     0.97569
alpha_6                               0.97583      0.00015   0.97597     0.97568
alpha_7                               0.97583      0.00015   0.97598     0.97569
alpha_8                               0.97584      0.00015   0.97599     0.97570
alpha_9                               0.97583      0.00015   0.97598     0.97569
Alpha_loss                            -0.16186     0.00096   -0.16090    -0.16282
Training/policy_loss                  -2.66352     0.00213   -2.66139    -2.66565
Training/qf1_loss                     2033.91919   88.20923  2122.12842  1945.70996
Training/qf2_loss                     2033.92651   88.21631  2122.14282  1945.71021
Training/pf_norm                      0.34641      0.02461   0.37103     0.32180
Training/qf1_norm                     25.64665     0.18439   25.83104    25.46226
Training/qf2_norm                     25.87651     0.15290   26.02942    25.72361
log_std/mean                          -0.02900     0.00019   -0.02881    -0.02920
log_std/std                           0.00309      0.00002   0.00310     0.00307
log_std/max                           -0.02533     0.00018   -0.02516    -0.02551
log_std/min                           -0.03863     0.00023   -0.03840    -0.03886
log_probs/mean                        -2.69940     0.00199   -2.69741    -2.70139
log_probs/std                         0.36561      0.00425   0.36986     0.36136
log_probs/max                         -1.50231     0.05015   -1.45215    -1.55246
log_probs/min                         -4.30883     0.01413   -4.29470    -4.32295
mean/mean                             -0.00032     0.00000   -0.00032    -0.00032
mean/std                              0.00246      0.00003   0.00250     0.00243
mean/max                              0.00550      0.00007   0.00558     0.00543
mean/min                              -0.00524     0.00003   -0.00521    -0.00527
------------------------------------  -----------  --------  ----------  ----------
sample: [7, 0, 9, 5, 1, 8, 2, 4, 3, 6]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
train_time 0.12387681007385254
eval_infos
eval time 0.0027654170989990234
snapshot at best
2023-08-31 20:41:44,919 MainThread INFO: EPOCH:41
2023-08-31 20:41:44,920 MainThread INFO: Time Consumed:0.6761388778686523s
2023-08-31 20:41:44,920 MainThread INFO: Total Frames:63000s
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [02:40<00:21,  2.63s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1139.94823
Train_Epoch_Reward                    15647.08200
Running_Training_Average_Rewards      970.50809
Explore_Time                          0.00392
Train___Time                          0.12388
Eval____Time                          0.00277
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.91070
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.97942
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84482
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.12097
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50520
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17357
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.13682
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11671.72765
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.01883
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.66063
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.99854     0.74334    11.74188    10.25520
alpha_0                               0.97524      0.00015    0.97538     0.97509
alpha_1                               0.97524      0.00015    0.97539     0.97509
alpha_2                               0.97526      0.00015    0.97541     0.97511
alpha_3                               0.97526      0.00015    0.97540     0.97511
alpha_4                               0.97527      0.00015    0.97542     0.97513
alpha_5                               0.97525      0.00015    0.97540     0.97510
alpha_6                               0.97524      0.00015    0.97539     0.97510
alpha_7                               0.97525      0.00015    0.97539     0.97510
alpha_8                               0.97526      0.00015    0.97540     0.97511
alpha_9                               0.97525      0.00015    0.97539     0.97510
Alpha_loss                            -0.16590     0.00128    -0.16462    -0.16717
Training/policy_loss                  -2.66333     0.01049    -2.65284    -2.67382
Training/qf1_loss                     2659.00330   234.62610  2893.62939  2424.37720
Training/qf2_loss                     2659.00793   234.62561  2893.63354  2424.38232
Training/pf_norm                      0.33126      0.03484    0.36609     0.29642
Training/qf1_norm                     27.43281     1.55547    28.98828    25.87733
Training/qf2_norm                     27.69933     1.56950    29.26883    26.12983
log_std/mean                          -0.02978     0.00020    -0.02959    -0.02998
log_std/std                           0.00315      0.00002    0.00317     0.00314
log_std/max                           -0.02603     0.00017    -0.02586    -0.02620
log_std/min                           -0.03974     0.00021    -0.03953    -0.03995
log_probs/mean                        -2.69994     0.01093    -2.68902    -2.71087
log_probs/std                         0.37300      0.00165    0.37465     0.37134
log_probs/max                         -1.51637     0.00571    -1.51067    -1.52208
log_probs/min                         -4.18849     0.33831    -3.85018    -4.52679
mean/mean                             -0.00033     0.00001    -0.00033    -0.00034
mean/std                              0.00237      0.00001    0.00238     0.00237
mean/max                              0.00530      0.00003    0.00533     0.00526
mean/min                              -0.00541     0.00003    -0.00538    -0.00544
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
sample: [4, 0, 8, 9, 3, 1, 2, 7, 6, 5]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
train_time 0.12385082244873047
eval_infos
eval time 0.004380702972412109
snapshot at best
2023-08-31 20:41:53,689 MainThread INFO: EPOCH:42
2023-08-31 20:41:53,689 MainThread INFO: Time Consumed:0.6820321083068848s
2023-08-31 20:41:53,690 MainThread INFO: Total Frames:64500s
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [02:49<00:31,  4.47s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1142.42095
Train_Epoch_Reward                    10970.56658
Running_Training_Average_Rewards      997.21082
Explore_Time                          0.00380
Train___Time                          0.12385
Eval____Time                          0.00438
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.41296
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96932
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85490
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.09370
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47775
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14589
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.10977
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11708.49010
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00608
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.63189
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.31637     1.80182     12.11819    8.51455
alpha_0                               0.97465      0.00015     0.97480     0.97451
alpha_1                               0.97465      0.00015     0.97480     0.97451
alpha_2                               0.97467      0.00015     0.97482     0.97453
alpha_3                               0.97467      0.00015     0.97482     0.97452
alpha_4                               0.97469      0.00015     0.97483     0.97454
alpha_5                               0.97466      0.00015     0.97481     0.97452
alpha_6                               0.97466      0.00015     0.97480     0.97451
alpha_7                               0.97466      0.00015     0.97481     0.97451
alpha_8                               0.97467      0.00015     0.97482     0.97452
alpha_9                               0.97466      0.00015     0.97481     0.97451
Alpha_loss                            -0.16999     0.00111     -0.16888    -0.17110
Training/policy_loss                  -2.66544     0.00386     -2.66158    -2.66931
Training/qf1_loss                     2486.84924   1066.14929  3552.99854  1420.69995
Training/qf2_loss                     2486.85413   1066.15369  3553.00781  1420.70044
Training/pf_norm                      0.34890      0.00389     0.35279     0.34501
Training/qf1_norm                     26.05306     3.60564     29.65871    22.44742
Training/qf2_norm                     26.30663     3.63903     29.94566    22.66760
log_std/mean                          -0.03056     0.00020     -0.03036    -0.03075
log_std/std                           0.00321      0.00002     0.00323     0.00319
log_std/max                           -0.02673     0.00018     -0.02656    -0.02691
log_std/min                           -0.04070     0.00034     -0.04036    -0.04104
log_probs/mean                        -2.70282     0.00413     -2.69869    -2.70696
log_probs/std                         0.37568      0.00090     0.37658     0.37478
log_probs/max                         -1.55819     0.05355     -1.50464    -1.61174
log_probs/min                         -4.27607     0.02486     -4.25121    -4.30093
mean/mean                             -0.00032     0.00000     -0.00031    -0.00032
mean/std                              0.00237      0.00001     0.00237     0.00236
mean/max                              0.00529      0.00003     0.00531     0.00526
mean/min                              -0.00562     0.00007     -0.00555    -0.00569
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 7, 6, 9, 0, 3, 1, 8, 5, 4]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
train_time 0.1374967098236084
eval_infos
eval time 0.004031658172607422
snapshot at best
2023-08-31 20:41:54,472 MainThread INFO: EPOCH:43
2023-08-31 20:41:54,472 MainThread INFO: Time Consumed:0.6697592735290527s
2023-08-31 20:41:54,473 MainThread INFO: Total Frames:66000s
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [02:50<00:20,  3.36s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1146.24808
Train_Epoch_Reward                    15691.00791
Running_Training_Average_Rewards      1410.28855
Explore_Time                          0.00401
Train___Time                          0.13750
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.35045
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96946
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.87337
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.07981
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47250
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13833
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.10766
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11755.87700
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00677
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.60079
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           10.32140     0.44148   10.76288    9.87992
alpha_0                               0.97407      0.00015   0.97421     0.97392
alpha_1                               0.97407      0.00015   0.97421     0.97392
alpha_2                               0.97409      0.00015   0.97423     0.97394
alpha_3                               0.97408      0.00015   0.97423     0.97394
alpha_4                               0.97410      0.00015   0.97425     0.97396
alpha_5                               0.97408      0.00015   0.97423     0.97393
alpha_6                               0.97407      0.00015   0.97422     0.97393
alpha_7                               0.97408      0.00015   0.97422     0.97393
alpha_8                               0.97409      0.00015   0.97423     0.97394
alpha_9                               0.97407      0.00015   0.97422     0.97393
Alpha_loss                            -0.17382     0.00118   -0.17263    -0.17500
Training/policy_loss                  -2.65724     0.00656   -2.65067    -2.66380
Training/qf1_loss                     2157.15234   93.94385  2251.09619  2063.20850
Training/qf2_loss                     2157.15234   93.94385  2251.09619  2063.20850
Training/pf_norm                      0.34525      0.02061   0.36585     0.32464
Training/qf1_norm                     26.06971     0.92569   26.99541    25.14402
Training/qf2_norm                     26.33214     0.92989   27.26203    25.40225
log_std/mean                          -0.03134     0.00020   -0.03114    -0.03153
log_std/std                           0.00327      0.00002   0.00329     0.00325
log_std/max                           -0.02746     0.00020   -0.02726    -0.02765
log_std/min                           -0.04169     0.00029   -0.04141    -0.04198
log_probs/mean                        -2.69514     0.00691   -2.68823    -2.70204
log_probs/std                         0.38340      0.01184   0.39524     0.37157
log_probs/max                         -1.55811     0.03316   -1.52496    -1.59127
log_probs/min                         -5.16147     0.85946   -4.30201    -6.02092
mean/mean                             -0.00027     0.00002   -0.00026    -0.00029
mean/std                              0.00232      0.00002   0.00234     0.00230
mean/max                              0.00530      0.00000   0.00530     0.00529
mean/min                              -0.00570     0.00002   -0.00569    -0.00572
------------------------------------  -----------  --------  ----------  ----------
sample: [5, 1, 6, 2, 7, 9, 8, 4, 3, 0]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
train_time 0.1269392967224121
eval_infos
eval time 0.0034096240997314453
snapshot at best
2023-08-31 20:41:55,270 MainThread INFO: EPOCH:44
2023-08-31 20:41:55,271 MainThread INFO: Time Consumed:0.6829707622528076s
2023-08-31 20:41:55,271 MainThread INFO: Total Frames:67500s
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:51<00:12,  2.60s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:52<00:19,  3.83s/it]
------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1150.53398
Train_Epoch_Reward                    8633.63922
Running_Training_Average_Rewards      1176.50712
Explore_Time                          0.00505
Train___Time                          0.12694
Eval____Time                          0.00341
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.92736
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96213
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.89365
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.05723
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46586
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13003
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.09965
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11802.06120
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.99891
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.57277
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.55281      0.04276    8.59557     8.51005
alpha_0                               0.97348      0.00015    0.97363     0.97334
alpha_1                               0.97348      0.00015    0.97363     0.97334
alpha_2                               0.97350      0.00015    0.97365     0.97336
alpha_3                               0.97350      0.00015    0.97364     0.97335
alpha_4                               0.97352      0.00015    0.97366     0.97337
alpha_5                               0.97350      0.00015    0.97364     0.97335
alpha_6                               0.97349      0.00015    0.97363     0.97334
alpha_7                               0.97349      0.00015    0.97364     0.97335
alpha_8                               0.97350      0.00015    0.97365     0.97335
alpha_9                               0.97349      0.00015    0.97364     0.97334
Alpha_loss                            -0.17811     0.00089    -0.17722    -0.17900
Training/policy_loss                  -2.66649     0.00439    -2.66210    -2.67088
Training/qf1_loss                     1485.28387   163.07611  1648.35999  1322.20776
Training/qf2_loss                     1485.28076   163.07507  1648.35583  1322.20569
Training/pf_norm                      0.31242      0.00156    0.31398     0.31086
Training/qf1_norm                     22.50674     0.09272    22.59946    22.41402
Training/qf2_norm                     22.74525     0.07894    22.82419    22.66630
log_std/mean                          -0.03212     0.00019    -0.03192    -0.03231
log_std/std                           0.00332      0.00001    0.00334     0.00331
log_std/max                           -0.02820     0.00017    -0.02804    -0.02837
log_std/min                           -0.04256     0.00013    -0.04243    -0.04269
log_probs/mean                        -2.70528     0.00434    -2.70095    -2.70962
log_probs/std                         0.36949      0.00322    0.37271     0.36627
log_probs/max                         -1.45518     0.01143    -1.44375    -1.46660
log_probs/min                         -4.80768     0.31435    -4.49333    -5.12204
mean/mean                             -0.00017     0.00003    -0.00014    -0.00020
mean/std                              0.00231      0.00000    0.00231     0.00231
mean/max                              0.00539      0.00002    0.00540     0.00537
mean/min                              -0.00569     0.00003    -0.00567    -0.00572
------------------------------------  -----------  ---------  ----------  ----------
start to update mask
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 319, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 310, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 305, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 382, in train
    self.update_masks(TASK_SAMPLE_NUM, task_amount, epoch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 296, in update_masks
    traj_sim_mtx = self.compute_policy_similarity_matrix(all_task_amount, task_traj_batch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 212, in compute_policy_similarity_matrix
    encoding = self.encode_policy_into_vectors(self.traj_encoder,
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 197, in encode_policy_into_vectors
    latents = network.encode(trajectories)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/networks/trajectory_encoder.py", line 83, in encode
    latents  = self.encode_lstm(trajectories)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/networks/trajectory_encoder.py", line 68, in encode_lstm
    encodings, _ = self.encoder_lstm(
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 581, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1096, in wait
    self._wait(timeout=sigint_timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1800, in _wait
    time.sleep(delay)
KeyboardInterrupt
