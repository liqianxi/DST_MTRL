2023-08-12 11:40:01,981 MainThread INFO: Experiment Name:must_mtsac
2023-08-12 11:40:01,981 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      400,
      400
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      256,
      128
    ]
  },
  "traj_encoder": {
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.9
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 20,
    "num_epochs": 10000,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "generator_lr": 1e-05,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 100,
    "update_end_epoch": 7000,
    "mask_update_interval": 50,
    "eval_episodes": 3
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
2023-08-12 11:41:00,169 MainThread INFO: EPOCH:0
2023-08-12 11:41:00,169 MainThread INFO: Time Consumed:0.006532430648803711s
2023-08-12 11:41:00,169 MainThread INFO: Total Frames:1500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                3467.99408
Running_Training_Average_Rewards  346.79941

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
2023-08-12 11:41:00,178 MainThread INFO: EPOCH:1
2023-08-12 11:41:00,178 MainThread INFO: Time Consumed:0.0030603408813476562s
2023-08-12 11:41:00,179 MainThread INFO: Total Frames:3000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                22879.15305
Running_Training_Average_Rewards  1317.35736

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
2023-08-12 11:41:01,089 MainThread INFO: EPOCH:2
2023-08-12 11:41:01,089 MainThread INFO: Time Consumed:0.9093117713928223s
2023-08-12 11:41:01,089 MainThread INFO: Total Frames:4500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                17184.88486
Running_Training_Average_Rewards  1451.06773

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
2023-08-12 11:41:02,098 MainThread INFO: EPOCH:3
2023-08-12 11:41:02,098 MainThread INFO: Time Consumed:1.0083494186401367s
2023-08-12 11:41:02,098 MainThread INFO: Total Frames:6000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                10428.71755
Running_Training_Average_Rewards  1683.09185

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
2023-08-12 11:41:03,344 MainThread INFO: EPOCH:4
2023-08-12 11:41:03,344 MainThread INFO: Time Consumed:1.242204189300537s
2023-08-12 11:41:03,344 MainThread INFO: Total Frames:7500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                12416.13092
Running_Training_Average_Rewards  1334.32444

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
2023-08-12 11:41:04,866 MainThread INFO: EPOCH:5
2023-08-12 11:41:04,868 MainThread INFO: Time Consumed:1.5204951763153076s
2023-08-12 11:41:04,868 MainThread INFO: Total Frames:9000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                61006.09140
Running_Training_Average_Rewards  2795.03133

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
2023-08-12 11:41:05,944 MainThread INFO: EPOCH:6
2023-08-12 11:41:05,944 MainThread INFO: Time Consumed:1.0741872787475586s
2023-08-12 11:41:05,944 MainThread INFO: Total Frames:10500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                6605.04531
Running_Training_Average_Rewards  2667.57559

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
2023-08-12 11:41:07,711 MainThread INFO: EPOCH:7
2023-08-12 11:41:07,711 MainThread INFO: Time Consumed:1.7661945819854736s
2023-08-12 11:41:07,711 MainThread INFO: Total Frames:12000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                9466.05585
Running_Training_Average_Rewards  2569.23975

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
2023-08-12 11:41:09,270 MainThread INFO: EPOCH:8
2023-08-12 11:41:09,270 MainThread INFO: Time Consumed:1.557922124862671s
2023-08-12 11:41:09,270 MainThread INFO: Total Frames:13500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                11873.22398
Running_Training_Average_Rewards  931.47750

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
2023-08-12 11:41:10,693 MainThread INFO: EPOCH:9
2023-08-12 11:41:10,694 MainThread INFO: Time Consumed:1.4221746921539307s
2023-08-12 11:41:10,694 MainThread INFO: Total Frames:15000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                4381.42402
Running_Training_Average_Rewards  857.35680

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
2023-08-12 11:41:11,566 MainThread INFO: EPOCH:10
2023-08-12 11:41:11,566 MainThread INFO: Time Consumed:0.8708815574645996s
2023-08-12 11:41:11,566 MainThread INFO: Total Frames:16500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                64269.90904
Running_Training_Average_Rewards  2684.15190

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
2023-08-12 11:41:12,520 MainThread INFO: EPOCH:11
2023-08-12 11:41:12,520 MainThread INFO: Time Consumed:0.953197717666626s
2023-08-12 11:41:12,520 MainThread INFO: Total Frames:18000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                6089.69765
Running_Training_Average_Rewards  2491.36769

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
2023-08-12 11:41:13,413 MainThread INFO: EPOCH:12
2023-08-12 11:41:13,414 MainThread INFO: Time Consumed:0.892430305480957s
2023-08-12 11:41:13,414 MainThread INFO: Total Frames:19500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                6525.16097
Running_Training_Average_Rewards  2562.82559

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
2023-08-12 11:41:14,258 MainThread INFO: EPOCH:13
2023-08-12 11:41:14,258 MainThread INFO: Time Consumed:0.8428432941436768s
2023-08-12 11:41:14,258 MainThread INFO: Total Frames:21000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                4751.76150
Running_Training_Average_Rewards  578.88734

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
2023-08-12 11:41:14,968 MainThread INFO: EPOCH:14
2023-08-12 11:41:14,969 MainThread INFO: Time Consumed:0.7095191478729248s
2023-08-12 11:41:14,969 MainThread INFO: Total Frames:22500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                16639.79280
Running_Training_Average_Rewards  930.55718

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
2023-08-12 11:41:16,553 MainThread INFO: EPOCH:15
2023-08-12 11:41:16,553 MainThread INFO: Time Consumed:1.583183765411377s
2023-08-12 11:41:16,553 MainThread INFO: Total Frames:24000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                3593.21948
Running_Training_Average_Rewards  832.82579

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
2023-08-12 11:41:17,516 MainThread INFO: EPOCH:16
2023-08-12 11:41:17,516 MainThread INFO: Time Consumed:0.9618585109710693s
2023-08-12 11:41:17,516 MainThread INFO: Total Frames:25500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                8728.63220
Running_Training_Average_Rewards  965.38815

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
2023-08-12 11:41:19,275 MainThread INFO: EPOCH:17
2023-08-12 11:41:19,276 MainThread INFO: Time Consumed:1.7583842277526855s
2023-08-12 11:41:19,276 MainThread INFO: Total Frames:27000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                18284.35045
Running_Training_Average_Rewards  1020.20674

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
2023-08-12 11:41:20,242 MainThread INFO: EPOCH:18
2023-08-12 11:41:20,242 MainThread INFO: Time Consumed:0.9656155109405518s
2023-08-12 11:41:20,243 MainThread INFO: Total Frames:28500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                28452.85653
Running_Training_Average_Rewards  1848.86131

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
2023-08-12 11:41:20,917 MainThread INFO: EPOCH:19
2023-08-12 11:41:20,917 MainThread INFO: Time Consumed:0.6732876300811768s
2023-08-12 11:41:20,917 MainThread INFO: Total Frames:30000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                10373.33835
Running_Training_Average_Rewards  1903.68484

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
2023-08-12 11:41:20,918 MainThread INFO: Finished Pretrain
  0%|          | 0/10000 [00:00<?, ?it/s]sample: [9, 0, 1, 2, 6, 8, 5, 4, 7, 3]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
snapshot at best
2023-08-12 11:41:30,989 MainThread INFO: EPOCH:0
2023-08-12 11:41:30,989 MainThread INFO: Time Consumed:9.992971420288086s
2023-08-12 11:41:30,989 MainThread INFO: Total Frames:31500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:330: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/10000 [00:10<29:57:31, 10.79s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1189.78794
Train_Epoch_Reward                    2365.58653
Running_Training_Average_Rewards      1373.05938
Explore_Time                          0.64106
Train___Time                          7.93346
Eval____Time                          0.00473
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.21424
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.85012
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.89316
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85439
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.58473
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24057
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20664
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12149.90980
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.83111
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.35544
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.07523     1.29670     13.78703    7.03080
alpha_0                               0.98498      0.00855     0.99970     0.97038
alpha_1                               0.98498      0.00855     0.99970     0.97040
alpha_2                               0.98498      0.00855     0.99970     0.97040
alpha_3                               0.98498      0.00855     0.99970     0.97040
alpha_4                               0.98499      0.00854     0.99970     0.97040
alpha_5                               0.98498      0.00855     0.99970     0.97039
alpha_6                               0.98498      0.00855     0.99970     0.97040
alpha_7                               0.98498      0.00855     0.99970     0.97039
alpha_8                               0.98498      0.00854     0.99970     0.97040
alpha_9                               0.98499      0.00855     0.99970     0.97040
Alpha_loss                            -0.10006     0.05847     -0.00000    -0.19978
Training/policy_loss                  -2.88186     0.17824     -2.67421    -3.29327
Training/qf1_loss                     3487.85768   1261.90410  7689.26709  1170.29651
Training/qf2_loss                     3487.78885   1261.89727  7689.19678  1170.24072
Training/pf_norm                      0.23507      0.11043     0.48115     0.11114
Training/qf1_norm                     43.29142     14.85138    86.00076    23.88380
Training/qf2_norm                     43.83146     15.34797    87.87869    23.87719
log_std/mean                          -0.08825     0.04883     0.00081     -0.13829
log_std/std                           0.00526      0.00279     0.00996     0.00173
log_std/max                           -0.07698     0.04317     0.00389     -0.11900
log_std/min                           -0.10183     0.05629     -0.00289    -0.16470
log_probs/mean                        -2.72108     0.01917     -2.67206    -2.75006
log_probs/std                         0.29310      0.07122     0.44267     0.20109
log_probs/max                         -1.87793     0.32025     -1.07247    -2.21440
log_probs/min                         -4.64617     0.61494     -3.56858    -7.06988
mean/mean                             -0.00054     0.00096     0.00094     -0.00270
mean/std                              0.00744      0.00206     0.00979     0.00180
mean/max                              0.01794      0.00517     0.02604     0.00355
mean/min                              -0.01678     0.00589     -0.00386    -0.02821
------------------------------------  -----------  ----------  ----------  ----------
snapshot at 0
history save at ./log/must_mtsac/mt10/12/model
sample: [0, 4, 2, 1, 5, 6, 7, 9, 3, 8]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
snapshot at best
2023-08-12 11:41:40,227 MainThread INFO: EPOCH:1
2023-08-12 11:41:40,228 MainThread INFO: Time Consumed:8.505849361419678s
2023-08-12 11:41:40,228 MainThread INFO: Total Frames:33000s
  0%|          | 2/10000 [00:19<26:23:48,  9.50s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1190.02756
Train_Epoch_Reward                    7626.36470
Running_Training_Average_Rewards      678.84299
Explore_Time                          0.00489
Train___Time                          7.28286
Eval____Time                          0.00419
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.81801
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.85012
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.89316
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85439
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.58473
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24057
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20664
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12149.90980
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.83111
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.35544
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           9.96251      1.56959     13.93685    6.72665
alpha_0                               0.95581      0.00828     0.97009     0.94168
alpha_1                               0.95582      0.00829     0.97011     0.94168
alpha_2                               0.95583      0.00828     0.97011     0.94169
alpha_3                               0.95583      0.00829     0.97011     0.94169
alpha_4                               0.95583      0.00829     0.97011     0.94169
alpha_5                               0.95583      0.00828     0.97010     0.94169
alpha_6                               0.95582      0.00829     0.97010     0.94168
alpha_7                               0.95581      0.00829     0.97010     0.94167
alpha_8                               0.95583      0.00829     0.97011     0.94168
alpha_9                               0.95583      0.00828     0.97011     0.94170
Alpha_loss                            -0.30244     0.05835     -0.20230    -0.40296
Training/policy_loss                  -4.23627     0.53937     -3.32411    -5.10987
Training/qf1_loss                     3440.25130   1606.99614  7578.44092  798.59045
Training/qf2_loss                     3439.85425   1606.99064  7577.88916  798.18848
Training/pf_norm                      0.14127      0.01793     0.18081     0.10807
Training/qf1_norm                     142.74317    48.79504    275.17038   68.02392
Training/qf2_norm                     145.18717    49.33210    278.89606   69.36819
log_std/mean                          -0.13541     0.00176     -0.13257    -0.13896
log_std/std                           0.00793      0.00062     0.00936     0.00665
log_std/max                           -0.11721     0.00424     -0.10905    -0.12493
log_std/min                           -0.15378     0.00293     -0.14765    -0.15915
log_probs/mean                        -2.73295     0.00747     -2.71323    -2.75208
log_probs/std                         0.23769      0.01510     0.27456     0.19995
log_probs/max                         -2.13368     0.05585     -1.85681    -2.21764
log_probs/min                         -5.09223     0.73810     -3.74567    -8.26776
mean/mean                             0.00195      0.00205     0.00533     -0.00280
mean/std                              0.01478      0.00542     0.02602     0.00902
mean/max                              0.04253      0.02371     0.09334     0.01563
mean/min                              -0.04018     0.02645     -0.01161    -0.09559
------------------------------------  -----------  ----------  ----------  ---------
sample: [1, 6, 7, 3, 4, 5, 8, 0, 2, 9]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
2023-08-12 11:41:48,536 MainThread INFO: EPOCH:2
2023-08-12 11:41:48,536 MainThread INFO: Time Consumed:8.207292795181274s
2023-08-12 11:41:48,536 MainThread INFO: Total Frames:34500s
  0%|          | 3/10000 [00:27<24:53:57,  8.97s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1154.31565
Train_Epoch_Reward                    8428.84625
Running_Training_Average_Rewards      614.02658
Explore_Time                          0.00530
Train___Time                          8.19641
Eval____Time                          0.00481
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.97294
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.55289
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.45823
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.87428
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.71165
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.28442
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.03660
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11796.82533
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.40081
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.37697
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.81050     1.51265     15.64587    7.63750
alpha_0                               0.92764      0.00795     0.94140     0.91416
alpha_1                               0.92754      0.00804     0.94139     0.91382
alpha_2                               0.92757      0.00803     0.94141     0.91386
alpha_3                               0.92756      0.00804     0.94141     0.91384
alpha_4                               0.92756      0.00804     0.94141     0.91384
alpha_5                               0.92756      0.00803     0.94141     0.91384
alpha_6                               0.92755      0.00804     0.94140     0.91384
alpha_7                               0.92754      0.00804     0.94139     0.91381
alpha_8                               0.92755      0.00804     0.94140     0.91383
alpha_9                               0.92757      0.00804     0.94142     0.91386
Alpha_loss                            -0.50361     0.05759     -0.40486    -0.60154
Training/policy_loss                  -5.75781     0.37975     -5.10974    -6.43820
Training/qf1_loss                     3884.07926   1481.31546  8215.41797  1199.22778
Training/qf2_loss                     3882.74513   1481.10552  8212.95996  1198.44897
Training/pf_norm                      0.14559      0.01784     0.18604     0.09432
Training/qf1_norm                     335.10278    77.92030    540.56006   187.34750
Training/qf2_norm                     339.50130    78.81260    547.54614   190.28873
log_std/mean                          -0.13648     0.00123     -0.13431    -0.13840
log_std/std                           0.01348      0.00284     0.01907     0.00903
log_std/max                           -0.11379     0.00459     -0.10422    -0.12150
log_std/min                           -0.17612     0.01077     -0.15337    -0.19455
log_probs/mean                        -2.72163     0.01180     -2.69223    -2.74490
log_probs/std                         0.28086      0.03718     0.36576     0.20971
log_probs/max                         -1.50783     0.42944     -0.52914    -2.17319
log_probs/min                         -5.10383     0.66823     -4.03941    -6.92752
mean/mean                             0.00594      0.00311     0.01117     0.00219
mean/std                              0.06099      0.02476     0.10742     0.02615
mean/max                              0.25578      0.11404     0.45834     0.09430
mean/min                              -0.26251     0.11585     -0.09546    -0.48032
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 6, 9, 1, 3, 7, 5, 0, 4, 8]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
snapshot at best
2023-08-12 11:41:58,744 MainThread INFO: EPOCH:3
2023-08-12 11:41:58,745 MainThread INFO: Time Consumed:10.030870199203491s
2023-08-12 11:41:58,745 MainThread INFO: Total Frames:36000s
  0%|          | 4/10000 [00:37<26:14:45,  9.45s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               5162.58309
Train_Epoch_Reward                    9540.54278
Running_Training_Average_Rewards      853.19179
Explore_Time                          0.02369
Train___Time                          8.69039
Eval____Time                          0.00507
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.54601
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.78392
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.81105
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.09833
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.99407
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.00573
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.69773
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 51880.65083
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.15673
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.72637
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           11.52968     1.35313     15.83263    7.83312
alpha_0                               0.90137      0.00712     0.91390     0.88955
alpha_1                               0.90011      0.00780     0.91355     0.88681
alpha_2                               0.90014      0.00780     0.91359     0.88683
alpha_3                               0.90012      0.00780     0.91356     0.88681
alpha_4                               0.90012      0.00780     0.91356     0.88681
alpha_5                               0.90013      0.00780     0.91357     0.88682
alpha_6                               0.90012      0.00780     0.91356     0.88682
alpha_7                               0.90009      0.00780     0.91354     0.88678
alpha_8                               0.90012      0.00780     0.91356     0.88681
alpha_9                               0.90014      0.00780     0.91358     0.88684
Alpha_loss                            -0.69699     0.05359     -0.60256    -0.78652
Training/policy_loss                  -7.37303     0.57615     -6.45235    -8.43554
Training/qf1_loss                     4220.30821   1398.93056  8034.05176  1294.82031
Training/qf2_loss                     4217.46547   1398.49546  8030.52979  1293.70667
Training/pf_norm                      0.16594      0.02699     0.25490     0.11185
Training/qf1_norm                     578.18357    102.22810   834.95050   334.21609
Training/qf2_norm                     584.27818    103.18298   842.04364   337.34610
log_std/mean                          -0.14152     0.00419     -0.13446    -0.14847
log_std/std                           0.03238      0.00946     0.05219     0.01615
log_std/max                           -0.11657     0.00365     -0.10765    -0.12196
log_std/min                           -0.29559     0.05358     -0.19802    -0.41321
log_probs/mean                        -2.65072     0.03726     -2.56471    -2.70856
log_probs/std                         0.50270      0.10153     0.73202     0.35046
log_probs/max                         0.36905      0.66034     1.97450     -0.82054
log_probs/min                         -5.56614     0.71824     -4.21929    -7.98638
mean/mean                             0.00970      0.00295     0.01400     0.00510
mean/std                              0.16943      0.03549     0.23205     0.10903
mean/max                              0.71008      0.13673     0.91334     0.46741
mean/min                              -0.78929     0.17738     -0.48738    -1.12635
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 2, 9, 5, 1, 7, 8, 4, 3, 0]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
2023-08-12 11:42:06,394 MainThread INFO: EPOCH:4
2023-08-12 11:42:06,394 MainThread INFO: Time Consumed:7.530269384384155s
2023-08-12 11:42:06,394 MainThread INFO: Total Frames:37500s
  0%|          | 5/10000 [00:45<24:25:37,  8.80s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2801.77430
Train_Epoch_Reward                    56755.73633
Running_Training_Average_Rewards      2490.83751
Explore_Time                          0.00721
Train___Time                          7.51799
Eval____Time                          0.00397
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.27582
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.93187
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.98338
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.09156
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.10495
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.58728
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.70002
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 28269.71779
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.13213
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.16781
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           11.55638     1.47428     15.50690    8.76063
alpha_0                               0.87954      0.00537     0.88933     0.87091
alpha_1                               0.87350      0.00756     0.88654     0.86059
alpha_2                               0.87353      0.00757     0.88656     0.86061
alpha_3                               0.87350      0.00757     0.88655     0.86058
alpha_4                               0.87351      0.00757     0.88655     0.86059
alpha_5                               0.87352      0.00757     0.88656     0.86061
alpha_6                               0.87351      0.00757     0.88655     0.86060
alpha_7                               0.87347      0.00757     0.88651     0.86056
alpha_8                               0.87350      0.00757     0.88654     0.86059
alpha_9                               0.87353      0.00757     0.88657     0.86062
Alpha_loss                            -0.87224     0.04792     -0.78585    -0.95259
Training/policy_loss                  -9.90851     0.88585     -8.46243    -11.50588
Training/qf1_loss                     4056.04649   1469.57664  7680.73193  1427.13306
Training/qf2_loss                     4051.53243   1468.87182  7674.21631  1424.92175
Training/pf_norm                      0.20750      0.04406     0.30854     0.13069
Training/qf1_norm                     781.55709    138.67961   1157.73206  484.61627
Training/qf2_norm                     787.80599    139.78349   1166.27551  488.67740
log_std/mean                          -0.15302     0.00612     -0.14541    -0.16626
log_std/std                           0.06724      0.01193     0.09146     0.04563
log_std/max                           -0.11556     0.00533     -0.10759    -0.12492
log_std/min                           -0.46373     0.05715     -0.36862    -0.59310
log_probs/mean                        -2.48631     0.06139     -2.35371    -2.60342
log_probs/std                         0.94967      0.16531     1.27665     0.65707
log_probs/max                         2.88145      0.85148     4.82014     1.39751
log_probs/min                         -5.88326     0.89031     -4.23467    -9.06329
mean/mean                             0.02621      0.00658     0.03630     0.01180
mean/std                              0.29070      0.03480     0.35792     0.22780
mean/max                              1.14254      0.10948     1.36607     0.90213
mean/min                              -1.29446     0.13517     -1.07997    -1.54719
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 1, 6, 3, 2, 7, 4, 0, 9, 8]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
2023-08-12 11:42:15,407 MainThread INFO: EPOCH:5
2023-08-12 11:42:15,408 MainThread INFO: Time Consumed:8.864326238632202s
2023-08-12 11:42:15,408 MainThread INFO: Total Frames:39000s
  0%|          | 6/10000 [00:54<24:37:23,  8.87s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1321.99019
Train_Epoch_Reward                    38885.05545
Running_Training_Average_Rewards      3506.04449
Explore_Time                          0.01016
Train___Time                          8.84868
Eval____Time                          0.00461
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.71711
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.85864
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.92879
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.33372
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.15676
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.44624
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.18778
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13474.51364
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.41292
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.56979
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           11.70789     1.54583     15.57602    8.35714
alpha_0                               0.86484      0.00305     0.87077     0.86034
alpha_1                               0.84768      0.00734     0.86033     0.83514
alpha_2                               0.84770      0.00734     0.86035     0.83517
alpha_3                               0.84768      0.00734     0.86033     0.83515
alpha_4                               0.84769      0.00734     0.86033     0.83516
alpha_5                               0.84770      0.00735     0.86036     0.83516
alpha_6                               0.84768      0.00735     0.86034     0.83515
alpha_7                               0.84764      0.00734     0.86030     0.83511
alpha_8                               0.84768      0.00734     0.86033     0.83514
alpha_9                               0.84771      0.00734     0.86036     0.83518
Alpha_loss                            -1.03108     0.04471     -0.94952    -1.10761
Training/policy_loss                  -13.61757    1.24556     -11.54955   -15.82960
Training/qf1_loss                     3965.52949   1394.09956  7812.90967  1278.57812
Training/qf2_loss                     3959.19054   1392.88912  7802.99756  1274.80029
Training/pf_norm                      0.25452      0.06535     0.41184     0.11757
Training/qf1_norm                     942.12130    200.70517   1487.63196  518.27991
Training/qf2_norm                     946.77080    202.29950   1495.39331  518.63239
log_std/mean                          -0.16562     0.00189     -0.16138    -0.16946
log_std/std                           0.09917      0.00909     0.11152     0.07888
log_std/max                           -0.11922     0.00483     -0.11058    -0.12749
log_std/min                           -0.57041     0.03270     -0.49640    -0.62843
log_probs/mean                        -2.27684     0.06452     -2.14643    -2.38685
log_probs/std                         1.53850      0.18167     1.86918     1.18791
log_probs/max                         5.49578      0.72833     6.66280     3.77319
log_probs/min                         -5.64826     1.11281     -3.99162    -10.24781
mean/mean                             0.04643      0.00434     0.05803     0.03693
mean/std                              0.39990      0.02811     0.44530     0.34862
mean/max                              1.48072      0.08794     1.62851     1.31940
mean/min                              -1.64827     0.09476     -1.45546    -1.77592
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 8, 9, 2, 5, 1, 4, 3, 0, 6]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
2023-08-12 11:42:23,785 MainThread INFO: EPOCH:6
2023-08-12 11:42:23,785 MainThread INFO: Time Consumed:8.21025013923645s
2023-08-12 11:42:23,785 MainThread INFO: Total Frames:40500s
  0%|          | 7/10000 [01:03<24:13:44,  8.73s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               936.40117
Train_Epoch_Reward                    18418.99684
Running_Training_Average_Rewards      3801.99295
Explore_Time                          0.02045
Train___Time                          8.18343
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.21209
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.05450
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.88699
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.81267
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36126
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91829
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.72218
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9614.50394
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.99056
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.53374
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           11.38724     1.34058     15.62814    7.62970
alpha_0                               0.85854      0.00072     0.86027     0.85785
alpha_1                               0.82261      0.00713     0.83489     0.81045
alpha_2                               0.82265      0.00712     0.83492     0.81049
alpha_3                               0.82262      0.00712     0.83490     0.81046
alpha_4                               0.82263      0.00712     0.83491     0.81047
alpha_5                               0.82264      0.00712     0.83491     0.81048
alpha_6                               0.82263      0.00712     0.83490     0.81047
alpha_7                               0.82259      0.00712     0.83486     0.81044
alpha_8                               0.82262      0.00713     0.83489     0.81046
alpha_9                               0.82266      0.00712     0.83493     0.81050
Alpha_loss                            -1.18715     0.04724     -1.10649    -1.26831
Training/policy_loss                  -18.53640    1.53937     -15.88031   -21.31613
Training/qf1_loss                     3544.62092   1206.03975  8054.95703  900.91663
Training/qf2_loss                     3536.81082   1204.72330  8044.28516  896.74969
Training/pf_norm                      0.30850      0.08646     0.57009     0.16733
Training/qf1_norm                     927.61836    228.28062   1631.08081  332.71497
Training/qf2_norm                     927.46470    230.36598   1637.78992  329.53439
log_std/mean                          -0.17087     0.00292     -0.16613    -0.17860
log_std/std                           0.11603      0.00475     0.12720     0.10776
log_std/max                           -0.11574     0.00314     -0.10930    -0.12002
log_std/min                           -0.61767     0.02933     -0.56265    -0.66630
log_probs/mean                        -2.09649     0.04679     -1.97666    -2.19237
log_probs/std                         2.05310      0.13161     2.37526     1.74674
log_probs/max                         7.45176      0.47357     8.29499     6.27538
log_probs/min                         -5.29055     0.99841     -3.88492    -10.61502
mean/mean                             0.05937      0.00223     0.06380     0.05554
mean/std                              0.48110      0.01644     0.51010     0.44698
mean/max                              1.75641      0.05234     1.84954     1.62969
mean/min                              -1.90057     0.05821     -1.76091    -2.02088
------------------------------------  -----------  ----------  ----------  ---------
sample: [4, 5, 0, 6, 1, 3, 8, 7, 9, 2]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
2023-08-12 11:42:32,716 MainThread INFO: EPOCH:7
2023-08-12 11:42:32,716 MainThread INFO: Time Consumed:8.738160371780396s
2023-08-12 11:42:32,716 MainThread INFO: Total Frames:42000s
  0%|          | 8/10000 [01:11<24:21:21,  8.78s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               825.03646
Train_Epoch_Reward                    10906.94691
Running_Training_Average_Rewards      2273.69997
Explore_Time                          0.00919
Train___Time                          8.72389
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.71211
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.55713
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.94308
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.40949
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.82533
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.04748
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07949
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8500.68408
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.92665
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.81872
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.86322     1.32742     13.88672    7.40051
alpha_0                               0.85889      0.00070     0.85996     0.85786
alpha_1                               0.79829      0.00691     0.81020     0.78649
alpha_2                               0.79833      0.00692     0.81025     0.78653
alpha_3                               0.79830      0.00692     0.81022     0.78650
alpha_4                               0.79832      0.00691     0.81023     0.78652
alpha_5                               0.79832      0.00692     0.81024     0.78652
alpha_6                               0.79832      0.00691     0.81023     0.78652
alpha_7                               0.79829      0.00691     0.81019     0.78649
alpha_8                               0.79830      0.00691     0.81022     0.78651
alpha_9                               0.79834      0.00691     0.81026     0.78655
Alpha_loss                            -1.35769     0.05381     -1.26994    -1.45013
Training/policy_loss                  -24.29011    1.67045     -21.25664   -27.08713
Training/qf1_loss                     3062.87827   1132.28181  6149.27832  911.83929
Training/qf2_loss                     3055.41212   1130.09894  6134.22754  907.14081
Training/pf_norm                      0.34527      0.11827     0.76335     0.13921
Training/qf1_norm                     722.62523    283.98624   1353.89502  166.97275
Training/qf2_norm                     713.57399    286.48689   1354.47070  150.91370
log_std/mean                          -0.17309     0.00286     -0.16806    -0.17826
log_std/std                           0.12342      0.00418     0.13260     0.11536
log_std/max                           -0.11732     0.00212     -0.11373    -0.12279
log_std/min                           -0.63575     0.02217     -0.58327    -0.68781
log_probs/mean                        -2.02200     0.03577     -1.94312    -2.10664
log_probs/std                         2.26729      0.09487     2.44838     2.03101
log_probs/max                         8.17689      0.34165     8.87253     7.30535
log_probs/min                         -5.34630     1.42625     -3.60862    -15.45472
mean/mean                             0.05846      0.00522     0.06412     0.04783
mean/std                              0.51021      0.00961     0.52715     0.48890
mean/max                              1.79491      0.03623     1.85097     1.72438
mean/min                              -2.02126     0.04583     -1.90987    -2.09760
------------------------------------  -----------  ----------  ----------  ---------
sample: [0, 8, 7, 3, 2, 1, 6, 9, 5, 4]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
2023-08-12 11:42:41,885 MainThread INFO: EPOCH:8
2023-08-12 11:42:41,885 MainThread INFO: Time Consumed:8.997465133666992s
2023-08-12 11:42:41,885 MainThread INFO: Total Frames:43500s
  0%|          | 9/10000 [01:21<24:44:55,  8.92s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               764.90002
Train_Epoch_Reward                    9364.52023
Running_Training_Average_Rewards      1289.68213
Explore_Time                          0.00979
Train___Time                          8.98194
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.48202
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.97550
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.65254
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.11520
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.13065
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.87579
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.52460
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7896.49205
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.49321
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.24233
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           11.03329    1.60998     16.22606    7.29019
alpha_0                               0.85890     0.00119     0.86005     0.85604
alpha_1                               0.77470     0.00671     0.78626     0.76325
alpha_2                               0.77473     0.00671     0.78629     0.76328
alpha_3                               0.77470     0.00671     0.78626     0.76326
alpha_4                               0.77472     0.00671     0.78628     0.76326
alpha_5                               0.77472     0.00671     0.78628     0.76327
alpha_6                               0.77472     0.00671     0.78628     0.76327
alpha_7                               0.77469     0.00671     0.78625     0.76324
alpha_8                               0.77471     0.00671     0.78627     0.76326
alpha_9                               0.77475     0.00671     0.78631     0.76329
Alpha_loss                            -1.55747    0.06078     -1.45047    -1.66160
Training/policy_loss                  -29.82222   1.52431     -26.96699   -32.32499
Training/qf1_loss                     3224.02013  1253.98141  6511.92334  776.24170
Training/qf2_loss                     3218.13149  1251.28958  6501.73193  773.87964
Training/pf_norm                      0.30290     0.08485     0.59790     0.11882
Training/qf1_norm                     623.82731   357.20025   1907.35718  38.37252
Training/qf2_norm                     615.53800   356.06736   1906.02283  52.30328
log_std/mean                          -0.16862    0.00292     -0.16273    -0.17225
log_std/std                           0.11202     0.00395     0.12147     0.10599
log_std/max                           -0.11811    0.00201     -0.11417    -0.12104
log_std/min                           -0.62337    0.01269     -0.59507    -0.64386
log_probs/mean                        -2.13955    0.05865     -2.00543    -2.24563
log_probs/std                         1.92230     0.17302     2.27880     1.62076
log_probs/max                         6.74963     0.81367     8.24738     5.20118
log_probs/min                         -5.31492    1.05603     -3.60710    -8.32170
mean/mean                             0.03105     0.01257     0.04970     0.00090
mean/std                              0.46819     0.02129     0.50521     0.42967
mean/max                              1.66583     0.05217     1.77769     1.59105
mean/min                              -2.02867    0.02777     -1.97856    -2.09963
------------------------------------  ----------  ----------  ----------  ---------
sample: [4, 2, 8, 5, 7, 1, 6, 9, 0, 3]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
2023-08-12 11:42:51,171 MainThread INFO: EPOCH:9
2023-08-12 11:42:51,171 MainThread INFO: Time Consumed:9.109575033187866s
2023-08-12 11:42:51,171 MainThread INFO: Total Frames:45000s
  0%|          | 10/10000 [01:30<25:01:37,  9.02s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               751.79802
Train_Epoch_Reward                    8631.21612
Running_Training_Average_Rewards      963.42278
Explore_Time                          0.00469
Train___Time                          9.09931
Eval____Time                          0.00489
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.44567
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.95464
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.12807
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.86661
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.57673
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19436
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.20155
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7777.41130
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.17427
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.88923
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           10.82956    1.62256     14.74093    6.87514
alpha_0                               0.84959     0.00406     0.85594     0.84236
alpha_1                               0.75181     0.00651     0.76302     0.74071
alpha_2                               0.75183     0.00651     0.76305     0.74072
alpha_3                               0.75180     0.00651     0.76303     0.74069
alpha_4                               0.75181     0.00651     0.76303     0.74070
alpha_5                               0.75183     0.00651     0.76304     0.74072
alpha_6                               0.75182     0.00651     0.76304     0.74072
alpha_7                               0.75180     0.00651     0.76301     0.74069
alpha_8                               0.75181     0.00651     0.76303     0.74070
alpha_9                               0.75185     0.00651     0.76307     0.74073
Alpha_loss                            -1.76255    0.05588     -1.66290    -1.85372
Training/policy_loss                  -34.48248   1.19468     -32.26875   -36.75217
Training/qf1_loss                     3113.31250  1188.33392  6403.12354  1023.29767
Training/qf2_loss                     3110.38139  1187.44332  6398.04639  1021.94159
Training/pf_norm                      0.32105     0.08225     0.52573     0.14645
Training/qf1_norm                     550.60649   369.44141   1628.32019  40.34103
Training/qf2_norm                     549.25238   369.90897   1630.91223  35.39430
log_std/mean                          -0.16235    0.00229     -0.15690    -0.16672
log_std/std                           0.09963     0.00387     0.10694     0.09410
log_std/max                           -0.10998    0.01218     -0.07698    -0.12162
log_std/min                           -0.62691    0.02015     -0.58704    -0.67786
log_probs/mean                        -2.27811    0.02987     -2.21144    -2.33808
log_probs/std                         1.51565     0.07604     1.68798     1.35006
log_probs/max                         5.21365     0.36229     5.81381     4.33014
log_probs/min                         -5.68977    1.46549     -3.90554    -12.21945
mean/mean                             -0.03902    0.02659     -0.00007    -0.08729
mean/std                              0.40488     0.01364     0.42835     0.38116
mean/max                              1.34203     0.15292     1.58811     1.06516
mean/min                              -1.91369    0.05964     -1.80510    -2.02226
------------------------------------  ----------  ----------  ----------  ----------
sample: [8, 4, 5, 0, 7, 6, 1, 2, 9, 3]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
2023-08-12 11:43:00,264 MainThread INFO: EPOCH:10
2023-08-12 11:43:00,264 MainThread INFO: Time Consumed:8.912763357162476s
2023-08-12 11:43:00,264 MainThread INFO: Total Frames:46500s
  0%|          | 11/10000 [01:39<25:07:38,  9.06s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               863.05057
Train_Epoch_Reward                    7960.85691
Running_Training_Average_Rewards      865.21978
Explore_Time                          0.01000
Train___Time                          8.89769
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.82452
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.97773
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.21846
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.39880
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.46575
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.45653
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.68821
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8878.94289
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.82861
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.57861
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           10.66351    1.59345     16.11180    7.67751
alpha_0                               0.83373     0.00552     0.84222     0.82378
alpha_1                               0.72960     0.00632     0.74049     0.71882
alpha_2                               0.72960     0.00632     0.74050     0.71881
alpha_3                               0.72958     0.00632     0.74047     0.71880
alpha_4                               0.72960     0.00632     0.74048     0.71882
alpha_5                               0.72961     0.00632     0.74050     0.71883
alpha_6                               0.72961     0.00632     0.74049     0.71883
alpha_7                               0.72958     0.00631     0.74046     0.71881
alpha_8                               0.72959     0.00632     0.74048     0.71881
alpha_9                               0.72962     0.00632     0.74051     0.71884
Alpha_loss                            -1.96178    0.06064     -1.86015    -2.05506
Training/policy_loss                  -38.80617   1.24015     -36.46901   -41.12869
Training/qf1_loss                     2984.95651  1315.37136  8483.74902  1015.49628
Training/qf2_loss                     2982.72090  1314.56229  8474.71875  1012.74670
Training/pf_norm                      0.29408     0.06116     0.49582     0.16613
Training/qf1_norm                     488.82991   408.44130   2109.76147  53.82492
Training/qf2_norm                     489.89601   410.49951   2119.25977  51.91737
log_std/mean                          -0.16169    0.00308     -0.15754    -0.16752
log_std/std                           0.08948     0.00563     0.09988     0.08117
log_std/max                           -0.11382    0.00450     -0.10638    -0.12130
log_std/min                           -0.57508    0.02435     -0.52705    -0.62300
log_probs/mean                        -2.35051    0.04710     -2.22951    -2.44234
log_probs/std                         1.31835     0.13207     1.67151     1.09819
log_probs/max                         4.41202     0.64797     5.80147     3.48859
log_probs/min                         -5.83696    1.12918     -4.07826    -9.87241
mean/mean                             -0.10141    0.00785     -0.08797    -0.11558
mean/std                              0.35371     0.02375     0.39762     0.32706
mean/max                              0.35887     0.37019     1.05502     0.02674
mean/min                              -1.69403    0.07857     -1.55329    -1.83847
------------------------------------  ----------  ----------  ----------  ----------
sample: [7, 3, 5, 9, 4, 1, 0, 8, 2, 6]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
2023-08-12 11:43:09,464 MainThread INFO: EPOCH:11
2023-08-12 11:43:09,464 MainThread INFO: Time Consumed:9.036643743515015s
2023-08-12 11:43:09,465 MainThread INFO: Total Frames:48000s
  0%|          | 12/10000 [01:48<25:11:03,  9.08s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               428.49976
Train_Epoch_Reward                    11537.93903
Running_Training_Average_Rewards      937.66707
Explore_Time                          0.00603
Train___Time                          9.02555
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.83190
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.80043
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.12505
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.17697
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.19176
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.51511
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.47224
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4528.10530
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.76985
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.22435
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.41960     1.62501     16.83066    7.73443
alpha_0                               0.81320      0.00632     0.82358     0.80190
alpha_1                               0.70804      0.00613     0.71861     0.69757
alpha_2                               0.70804      0.00613     0.71860     0.69757
alpha_3                               0.70802      0.00613     0.71858     0.69756
alpha_4                               0.70803      0.00613     0.71860     0.69757
alpha_5                               0.70805      0.00613     0.71861     0.69758
alpha_6                               0.70805      0.00613     0.71861     0.69759
alpha_7                               0.70803      0.00613     0.71859     0.69757
alpha_8                               0.70803      0.00613     0.71859     0.69756
alpha_9                               0.70806      0.00613     0.71862     0.69759
Alpha_loss                            -2.16162     0.06204     -2.05748    -2.27570
Training/policy_loss                  -42.79729    1.23659     -40.64073   -44.84051
Training/qf1_loss                     2992.87930   1281.56398  9059.65430  1010.01123
Training/qf2_loss                     2991.24659   1281.30822  9057.69238  1008.39435
Training/pf_norm                      0.20847      0.05477     0.42154     0.11936
Training/qf1_norm                     546.84918    462.07721   2641.22339  69.98238
Training/qf2_norm                     548.65978    464.03728   2649.91650  68.09351
log_std/mean                          -0.15897     0.00397     -0.15252    -0.16590
log_std/std                           0.08072      0.00526     0.08875     0.07244
log_std/max                           -0.11661     0.00438     -0.10687    -0.12207
log_std/min                           -0.49080     0.02557     -0.44577    -0.53140
log_probs/mean                        -2.40254     0.03954     -2.31635    -2.50659
log_probs/std                         1.18900      0.09897     1.37468     0.94950
log_probs/max                         4.06426      0.44984     4.91105     3.04391
log_probs/min                         -6.07514     1.15586     -4.17333    -9.54566
mean/mean                             -0.10291     0.00619     -0.09262    -0.11421
mean/std                              0.32451      0.01539     0.34469     0.29577
mean/max                              0.03665      0.00627     0.04623     0.02724
mean/min                              -1.36703     0.08477     -1.23818    -1.54682
------------------------------------  -----------  ----------  ----------  ----------
sample: [0, 8, 2, 4, 1, 3, 9, 6, 5, 7]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
2023-08-12 11:43:18,729 MainThread INFO: EPOCH:12
2023-08-12 11:43:18,730 MainThread INFO: Time Consumed:9.077865839004517s
2023-08-12 11:43:18,730 MainThread INFO: Total Frames:49500s
  0%|          | 13/10000 [01:57<25:21:38,  9.14s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               26.57893
Train_Epoch_Reward                    4665.50230
Running_Training_Average_Rewards      805.47661
Explore_Time                          0.01608
Train___Time                          9.05740
Eval____Time                          0.00373
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.85900
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.22137
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.43337
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.69136
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.67306
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.25739
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.85766
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 529.90382
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.63378
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.48755
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           10.05197    1.52325     15.84750    7.34458
alpha_0                               0.78777     0.00863     0.80165     0.77214
alpha_1                               0.68710     0.00595     0.69736     0.67695
alpha_2                               0.68711     0.00595     0.69736     0.67696
alpha_3                               0.68709     0.00595     0.69735     0.67694
alpha_4                               0.68710     0.00595     0.69736     0.67694
alpha_5                               0.68713     0.00595     0.69738     0.67697
alpha_6                               0.68713     0.00595     0.69738     0.67697
alpha_7                               0.68711     0.00595     0.69736     0.67696
alpha_8                               0.68710     0.00595     0.69735     0.67695
alpha_9                               0.68712     0.00595     0.69738     0.67696
Alpha_loss                            -2.39123    0.07344     -2.26315    -2.51018
Training/policy_loss                  -47.08723   1.18450     -45.04505   -49.25682
Training/qf1_loss                     2832.99781  1160.14524  5824.25000  1175.86707
Training/qf2_loss                     2831.55373  1159.78926  5821.55420  1175.13318
Training/pf_norm                      0.24159     0.06705     0.39465     0.12501
Training/qf1_norm                     510.07479   445.15331   2567.41528  59.80768
Training/qf2_norm                     511.84242   446.67977   2575.89502  60.95737
log_std/mean                          -0.14508    0.00481     -0.13864    -0.15317
log_std/std                           0.05522     0.01272     0.07576     0.03470
log_std/max                           -0.10479    0.00984     -0.08826    -0.11778
log_std/min                           -0.45930    0.05713     -0.35226    -0.52618
log_probs/mean                        -2.55575    0.06665     -2.43315    -2.67299
log_probs/std                         0.75010     0.18511     1.05583     0.44562
log_probs/max                         1.79837     1.10335     3.85486     0.15738
log_probs/min                         -5.87670    0.91498     -4.19246    -9.42819
mean/mean                             -0.05765    0.02862     -0.00464    -0.09279
mean/std                              0.24078     0.04122     0.29780     0.18095
mean/max                              0.07384     0.07174     0.31268     0.03721
mean/min                              -1.26312    0.12751     -1.02952    -1.40976
------------------------------------  ----------  ----------  ----------  ----------
sample: [2, 8, 7, 1, 3, 5, 6, 4, 0, 9]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
2023-08-12 11:43:26,913 MainThread INFO: EPOCH:13
2023-08-12 11:43:26,914 MainThread INFO: Time Consumed:7.980936527252197s
2023-08-12 11:43:26,914 MainThread INFO: Total Frames:51000s
  0%|          | 14/10000 [02:06<24:32:36,  8.85s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               17.60592
Train_Epoch_Reward                    312.37077
Running_Training_Average_Rewards      550.52707
Explore_Time                          0.00434
Train___Time                          7.97159
Eval____Time                          0.00408
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.52018
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.93459
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.44855
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.14452
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.41318
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.66362
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.86445
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 430.59281
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.76551
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.77906
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           9.56243     1.55637     14.13162    5.70897
alpha_0                               0.75647     0.00841     0.77180     0.74291
alpha_1                               0.66679     0.00577     0.67675     0.65694
alpha_2                               0.66680     0.00578     0.67676     0.65695
alpha_3                               0.66679     0.00577     0.67674     0.65694
alpha_4                               0.66679     0.00578     0.67674     0.65693
alpha_5                               0.66683     0.00577     0.67677     0.65698
alpha_6                               0.66681     0.00578     0.67677     0.65696
alpha_7                               0.66681     0.00577     0.67676     0.65695
alpha_8                               0.66679     0.00578     0.67674     0.65693
alpha_9                               0.66681     0.00577     0.67676     0.65696
Alpha_loss                            -2.59491    0.04613     -2.51118    -2.68115
Training/policy_loss                  -51.00586   1.25882     -49.13305   -53.37094
Training/qf1_loss                     2594.32738  1055.20978  6657.53906  602.32855
Training/qf2_loss                     2592.85942  1054.90410  6655.82520  601.67328
Training/pf_norm                      0.35044     0.08494     0.55079     0.15894
Training/qf1_norm                     543.04281   432.95729   2156.81030  61.51878
Training/qf2_norm                     544.74278   434.69928   2164.98291  61.52042
log_std/mean                          -0.14573    0.00502     -0.13876    -0.15332
log_std/std                           0.05118     0.01251     0.06401     0.03389
log_std/max                           -0.11100    0.00557     -0.09503    -0.11806
log_std/min                           -0.42934    0.07715     -0.31796    -0.51377
log_probs/mean                        -2.56646    0.04856     -2.49157    -2.66610
log_probs/std                         0.72394     0.12763     0.90304     0.50743
log_probs/max                         1.77311     0.77386     3.02420     0.43940
log_probs/min                         -5.92702    1.01250     -4.52939    -11.07354
mean/mean                             0.04015     0.02517     0.07547     -0.00386
mean/std                              0.23647     0.03152     0.26984     0.18939
mean/max                              1.04001     0.37834     1.39128     0.32349
mean/min                              -0.82341    0.21180     -0.35196    -1.04102
------------------------------------  ----------  ----------  ----------  ---------
sample: [8, 0, 1, 7, 3, 5, 6, 4, 2, 9]
replay_buffer._size: [5400 5400 5402 5400 5400 5400 5402 5405 5400 5401]
2023-08-12 11:43:35,975 MainThread INFO: EPOCH:14
2023-08-12 11:43:35,975 MainThread INFO: Time Consumed:8.892741680145264s
2023-08-12 11:43:35,975 MainThread INFO: Total Frames:52500s
  0%|          | 15/10000 [02:15<24:44:08,  8.92s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               13.36632
Train_Epoch_Reward                    285.52395
Running_Training_Average_Rewards      175.44657
Explore_Time                          0.03747
Train___Time                          8.85072
Eval____Time                          0.00376
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.35926
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -38.36102
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26785
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.88781
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33691
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.20482
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.34863
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 375.17862
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -21.75986
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.98928
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           9.41931     1.52708     14.08142    4.90728
alpha_0                               0.73059     0.00693     0.74265     0.71900
alpha_1                               0.64708     0.00560     0.65674     0.63752
alpha_2                               0.64709     0.00561     0.65675     0.63753
alpha_3                               0.64709     0.00560     0.65674     0.63752
alpha_4                               0.64708     0.00560     0.65673     0.63751
alpha_5                               0.64712     0.00560     0.65678     0.63756
alpha_6                               0.64710     0.00561     0.65676     0.63753
alpha_7                               0.64710     0.00560     0.65676     0.63753
alpha_8                               0.64708     0.00560     0.65673     0.63752
alpha_9                               0.64711     0.00560     0.65676     0.63755
Alpha_loss                            -2.77596    0.05330     -2.68004    -2.86802
Training/policy_loss                  -55.44625   1.47298     -53.04754   -57.77081
Training/qf1_loss                     2787.07053  1054.16876  6134.80615  428.96378
Training/qf2_loss                     2785.81514  1053.74817  6131.18701  428.46274
Training/pf_norm                      0.26107     0.07941     0.43136     0.12838
Training/qf1_norm                     614.26858   426.23328   2336.29053  64.33458
Training/qf2_norm                     615.59814   427.60899   2343.83228  64.81293
log_std/mean                          -0.15125    0.00212     -0.14670    -0.15421
log_std/std                           0.07176     0.00560     0.07884     0.06268
log_std/max                           -0.11059    0.00648     -0.09446    -0.12104
log_std/min                           -0.54657    0.03389     -0.47624    -0.60603
log_probs/mean                        -2.50602    0.02044     -2.45709    -2.54668
log_probs/std                         0.87640     0.04856     0.98593     0.77783
log_probs/max                         2.24144     0.24671     2.97437     1.62346
log_probs/min                         -6.07260    1.00828     -4.43694    -9.76572
mean/mean                             0.07080     0.00475     0.07627     0.06289
mean/std                              0.27668     0.00914     0.29335     0.26418
mean/max                              1.51057     0.06640     1.59148     1.38004
mean/min                              -0.13519    0.08692     -0.03307    -0.34237
------------------------------------  ----------  ----------  ----------  ---------
sample: [1, 4, 2, 9, 3, 5, 8, 6, 7, 0]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
2023-08-12 11:43:44,732 MainThread INFO: EPOCH:15
2023-08-12 11:43:44,734 MainThread INFO: Time Consumed:8.564598321914673s
2023-08-12 11:43:44,734 MainThread INFO: Total Frames:54000s
  0%|          | 16/10000 [02:23<24:35:35,  8.87s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               24.50642
Train_Epoch_Reward                    165.20853
Running_Training_Average_Rewards      25.43678
Explore_Time                          0.00457
Train___Time                          8.55550
Eval____Time                          0.00357
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.21889
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.92323
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.80826
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.96525
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.62124
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.63239
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.49400
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 486.69868
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.12578
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -21.84547
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           9.28644     1.37475     13.29010    6.16000
alpha_0                               0.70842     0.00598     0.71878     0.69812
alpha_1                               0.62796     0.00544     0.63733     0.61868
alpha_2                               0.62796     0.00544     0.63734     0.61867
alpha_3                               0.62796     0.00544     0.63733     0.61868
alpha_4                               0.62795     0.00544     0.63732     0.61866
alpha_5                               0.62800     0.00544     0.63737     0.61872
alpha_6                               0.62797     0.00544     0.63734     0.61869
alpha_7                               0.62798     0.00544     0.63734     0.61870
alpha_8                               0.62796     0.00544     0.63733     0.61868
alpha_9                               0.62798     0.00544     0.63735     0.61870
Alpha_loss                            -2.95684    0.05710     -2.85818    -3.05329
Training/policy_loss                  -59.98962   1.45840     -57.47528   -62.57532
Training/qf1_loss                     2765.21238  1027.46540  6312.02344  907.77521
Training/qf2_loss                     2764.32886  1027.42272  6311.44873  907.25385
Training/pf_norm                      0.19644     0.06034     0.39449     0.10095
Training/qf1_norm                     573.15725   452.13221   2267.46191  68.71146
Training/qf2_norm                     574.21256   453.36759   2274.20361  67.73114
log_std/mean                          -0.15388    0.00254     -0.14917    -0.15784
log_std/std                           0.07254     0.00318     0.07846     0.06693
log_std/max                           -0.11996    0.00351     -0.11440    -0.12572
log_std/min                           -0.54427    0.01362     -0.51942    -0.57385
log_probs/mean                        -2.46337    0.01924     -2.41889    -2.51744
log_probs/std                         0.99980     0.04334     1.11177     0.90114
log_probs/max                         3.00067     0.23943     3.50565     2.31590
log_probs/min                         -6.13570    1.13415     -3.95130    -10.54545
mean/mean                             0.07662     0.00527     0.08338     0.06823
mean/std                              0.30051     0.00497     0.31054     0.29216
mean/max                              1.57460     0.03019     1.62101     1.50815
mean/min                              -0.17800    0.08139     -0.04168    -0.27990
------------------------------------  ----------  ----------  ----------  ---------
sample: [7, 5, 8, 4, 0, 1, 9, 3, 2, 6]
replay_buffer._size: [5700 5700 5702 5700 5700 5700 5702 5702 5700 5700]
2023-08-12 11:43:53,828 MainThread INFO: EPOCH:16
2023-08-12 11:43:53,829 MainThread INFO: Time Consumed:8.931949377059937s
2023-08-12 11:43:53,829 MainThread INFO: Total Frames:55500s
  0%|          | 17/10000 [02:32<24:45:48,  8.93s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               74.54315
Train_Epoch_Reward                    393.74767
Running_Training_Average_Rewards      28.14934
Explore_Time                          0.03070
Train___Time                          8.89648
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.94713
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -38.36316
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.64366
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.95079
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.52997
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.73057
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.91757
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 989.88746
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.93010
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.44298
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.92777     1.44403     12.15851    6.20513
alpha_0                               0.68739     0.00644     0.69792     0.67586
alpha_1                               0.60940     0.00528     0.61849     0.60039
alpha_2                               0.60939     0.00528     0.61849     0.60039
alpha_3                               0.60940     0.00528     0.61849     0.60039
alpha_4                               0.60938     0.00528     0.61848     0.60037
alpha_5                               0.60945     0.00528     0.61854     0.60044
alpha_6                               0.60941     0.00528     0.61850     0.60041
alpha_7                               0.60942     0.00528     0.61851     0.60041
alpha_8                               0.60940     0.00528     0.61850     0.60040
alpha_9                               0.60943     0.00528     0.61852     0.60042
Alpha_loss                            -3.17084    0.07393     -3.04919    -3.29450
Training/policy_loss                  -64.20310   1.14576     -62.12987   -66.29353
Training/qf1_loss                     2476.12165  1105.00012  4806.29248  732.71399
Training/qf2_loss                     2475.52494  1104.72017  4806.64844  732.79865
Training/pf_norm                      0.24874     0.04206     0.33490     0.12401
Training/qf1_norm                     650.52698   413.44902   1854.83862  51.60469
Training/qf2_norm                     651.89694   414.90688   1859.13428  51.77093
log_std/mean                          -0.15067    0.00558     -0.14457    -0.15905
log_std/std                           0.06433     0.00685     0.07711     0.05571
log_std/max                           -0.09971    0.02287     -0.06341    -0.12553
log_std/min                           -0.46629    0.02862     -0.42121    -0.52389
log_probs/mean                        -2.51583    0.04915     -2.41051    -2.58830
log_probs/std                         0.85667     0.13696     1.08893     0.62404
log_probs/max                         2.28820     0.80036     3.60262     0.93232
log_probs/min                         -6.04114    0.88847     -4.14616    -8.41876
mean/mean                             0.06057     0.00806     0.07442     0.05182
mean/std                              0.26539     0.02964     0.30813     0.22586
mean/max                              1.27213     0.15164     1.55029     1.09400
mean/min                              -0.25336    0.10999     -0.05964    -0.36730
------------------------------------  ----------  ----------  ----------  ---------
sample: [4, 0, 1, 3, 9, 2, 5, 6, 8, 7]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
2023-08-12 11:44:03,377 MainThread INFO: EPOCH:17
2023-08-12 11:44:03,377 MainThread INFO: Time Consumed:9.353488206863403s
2023-08-12 11:44:03,377 MainThread INFO: Total Frames:57000s
  0%|          | 18/10000 [02:42<25:17:14,  9.12s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               113.49449
Train_Epoch_Reward                    396.03305
Running_Training_Average_Rewards      31.83297
Explore_Time                          0.00595
Train___Time                          9.34054
Eval____Time                          0.00614
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.26654
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.64028
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.77653
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.00915
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.22878
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95818
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.80995
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1380.12657
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.38366
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.10860
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.87463     1.55515     13.40112    5.27870
alpha_0                               0.66298     0.00736     0.67561     0.65068
alpha_1                               0.59139     0.00512     0.60021     0.58265
alpha_2                               0.59138     0.00512     0.60020     0.58264
alpha_3                               0.59138     0.00512     0.60021     0.58264
alpha_4                               0.59137     0.00512     0.60019     0.58263
alpha_5                               0.59143     0.00512     0.60026     0.58269
alpha_6                               0.59140     0.00512     0.60023     0.58266
alpha_7                               0.59141     0.00512     0.60023     0.58267
alpha_8                               0.59140     0.00512     0.60022     0.58267
alpha_9                               0.59142     0.00512     0.60024     0.58268
Alpha_loss                            -3.40274    0.05541     -3.29327    -3.49554
Training/policy_loss                  -68.18460   1.25882     -65.80103   -70.28704
Training/qf1_loss                     2585.72691  1081.59150  5477.13330  737.15570
Training/qf2_loss                     2585.35905  1081.44051  5476.92578  736.75488
Training/pf_norm                      0.37357     0.05700     0.50416     0.25923
Training/qf1_norm                     719.23709   498.35929   2540.96167  66.91173
Training/qf2_norm                     721.09476   499.59824   2548.27222  67.39249
log_std/mean                          -0.14429    0.00387     -0.13915    -0.15027
log_std/std                           0.05278     0.00532     0.05940     0.04390
log_std/max                           -0.07860    0.02391     -0.04312    -0.11744
log_std/min                           -0.45545    0.02232     -0.41461    -0.49172
log_probs/mean                        -2.59920    0.02389     -2.54815    -2.65062
log_probs/std                         0.62614     0.05697     0.79007     0.51815
log_probs/max                         1.06986     0.37395     1.87457     0.31970
log_probs/min                         -6.03486    0.96924     -4.24545    -9.71996
mean/mean                             0.03353     0.00998     0.05204     0.01244
mean/std                              0.21283     0.01645     0.24447     0.18838
mean/max                              1.17068     0.06404     1.25016     1.06485
mean/min                              -0.33515    0.22927     -0.07454    -0.77554
------------------------------------  ----------  ----------  ----------  ---------
sample: [3, 7, 8, 4, 6, 2, 9, 0, 5, 1]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
2023-08-12 11:44:12,768 MainThread INFO: EPOCH:18
2023-08-12 11:44:12,769 MainThread INFO: Time Consumed:9.209105730056763s
2023-08-12 11:44:12,769 MainThread INFO: Total Frames:58500s
  0%|          | 19/10000 [02:51<25:30:00,  9.20s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               180.61358
Train_Epoch_Reward                    1004.68466
Running_Training_Average_Rewards      59.81551
Explore_Time                          0.00593
Train___Time                          9.19840
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.86098
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.76068
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.65674
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.23144
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.79014
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.67734
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.75765
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2047.38713
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.50944
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.00692
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.66576     1.44405     13.23296    5.35708
alpha_0                               0.63982     0.00596     0.65045     0.62994
alpha_1                               0.57392     0.00497     0.58248     0.56544
alpha_2                               0.57391     0.00497     0.58247     0.56543
alpha_3                               0.57391     0.00497     0.58247     0.56543
alpha_4                               0.57390     0.00497     0.58246     0.56542
alpha_5                               0.57395     0.00497     0.58252     0.56547
alpha_6                               0.57393     0.00497     0.58249     0.56545
alpha_7                               0.57393     0.00497     0.58249     0.56546
alpha_8                               0.57392     0.00497     0.58249     0.56544
alpha_9                               0.57394     0.00497     0.58250     0.56545
Alpha_loss                            -3.56996    0.04842     -3.48192    -3.68102
Training/policy_loss                  -72.26555   1.08645     -70.05363   -74.61658
Training/qf1_loss                     2557.07211  1093.06363  5288.38135  760.32562
Training/qf2_loss                     2556.76015  1092.93833  5289.97412  760.86884
Training/pf_norm                      0.41995     0.07782     0.61273     0.26118
Training/qf1_norm                     697.62481   492.17906   2744.44556  85.86847
Training/qf2_norm                     699.29900   493.96750   2754.47046  86.45802
log_std/mean                          -0.14966    0.00181     -0.14546    -0.15194
log_std/std                           0.06893     0.00964     0.08056     0.05748
log_std/max                           -0.08961    0.02063     -0.04107    -0.12030
log_std/min                           -0.51775    0.06950     -0.40647    -0.62208
log_probs/mean                        -2.52412    0.03025     -2.46810    -2.57402
log_probs/std                         0.83933     0.07804     0.96821     0.69291
log_probs/max                         2.40231     0.45968     3.47850     1.45036
log_probs/min                         -6.08745    1.24728     -4.22158    -10.84226
mean/mean                             -0.02780    0.02224     0.01177     -0.05600
mean/std                              0.26571     0.01445     0.28642     0.24483
mean/max                              1.00791     0.19793     1.24402     0.51471
mean/min                              -1.08207    0.15025     -0.78387    -1.26893
------------------------------------  ----------  ----------  ----------  ---------
sample: [9, 3, 8, 1, 5, 0, 2, 6, 4, 7]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
2023-08-12 11:44:22,081 MainThread INFO: EPOCH:19
2023-08-12 11:44:22,081 MainThread INFO: Time Consumed:9.142776489257812s
2023-08-12 11:44:22,081 MainThread INFO: Total Frames:60000s
  0%|          | 20/10000 [03:01<25:35:37,  9.23s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1649.55426
Train_Epoch_Reward                    2505.13301
Running_Training_Average_Rewards      130.19502
Explore_Time                          0.00477
Train___Time                          9.13374
Eval____Time                          0.00356
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.67670
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.45842
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.90268
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.22537
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.96873
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.15661
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.27416
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16747.64219
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.92478
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.51210
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.31562      1.33859     11.72365    5.59737
alpha_0                               0.62023      0.00534     0.62974     0.61147
alpha_1                               0.55696      0.00482     0.56527     0.54874
alpha_2                               0.55695      0.00482     0.56526     0.54871
alpha_3                               0.55695      0.00482     0.56526     0.54872
alpha_4                               0.55694      0.00482     0.56525     0.54871
alpha_5                               0.55699      0.00482     0.56530     0.54877
alpha_6                               0.55697      0.00482     0.56528     0.54873
alpha_7                               0.55698      0.00482     0.56529     0.54875
alpha_8                               0.55697      0.00482     0.56527     0.54874
alpha_9                               0.55697      0.00482     0.56528     0.54875
Alpha_loss                            -3.74841     0.04197     -3.67122    -3.82257
Training/policy_loss                  -76.23137    1.33720     -73.98605   -78.59695
Training/qf1_loss                     2327.71767   1082.66870  6453.81641  742.98572
Training/qf2_loss                     2327.32499   1082.44299  6452.97754  742.64282
Training/pf_norm                      0.30731      0.10125     0.53960     0.10720
Training/qf1_norm                     637.36946    514.97216   2362.32910  59.49679
Training/qf2_norm                     638.74964    516.77107   2367.61816  59.48317
log_std/mean                          -0.14944     0.00414     -0.14322    -0.15638
log_std/std                           0.07557      0.00449     0.08469     0.06922
log_std/max                           -0.06550     0.06064     0.03057     -0.12202
log_std/min                           -0.59310     0.03727     -0.54154    -0.65867
log_probs/mean                        -2.48676     0.03760     -2.40653    -2.57383
log_probs/std                         0.92307      0.09948     1.11715     0.73931
log_probs/max                         2.73286      0.57392     3.93233     1.75466
log_probs/min                         -6.06242     1.06997     -4.13212    -8.64857
mean/mean                             -0.05801     0.00272     -0.05422    -0.06279
mean/std                              0.28735      0.02404     0.32650     0.25120
mean/max                              0.59356      0.19872     0.82911     0.24698
mean/min                              -1.55338     0.12951     -1.27208    -1.72002
------------------------------------  -----------  ----------  ----------  ---------
sample: [0, 3, 5, 2, 4, 8, 7, 9, 6, 1]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
2023-08-12 11:44:31,384 MainThread INFO: EPOCH:20
2023-08-12 11:44:31,385 MainThread INFO: Time Consumed:9.117462873458862s
2023-08-12 11:44:31,385 MainThread INFO: Total Frames:61500s
  0%|          | 21/10000 [03:10<25:39:53,  9.26s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               295.55437
Train_Epoch_Reward                    10217.37939
Running_Training_Average_Rewards      457.57324
Explore_Time                          0.00887
Train___Time                          9.10348
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.04983
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.45960
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.37737
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.88084
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.87128
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.38971
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.81458
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3217.66486
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.38787
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.89010
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.47710      1.18608    12.23503    5.87662
alpha_0                               0.60369      0.00438    0.61131     0.59605
alpha_1                               0.54051      0.00468    0.54857     0.53252
alpha_2                               0.54048      0.00468    0.54855     0.53250
alpha_3                               0.54049      0.00468    0.54855     0.53250
alpha_4                               0.54048      0.00468    0.54855     0.53249
alpha_5                               0.54054      0.00468    0.54860     0.53255
alpha_6                               0.54050      0.00468    0.54857     0.53251
alpha_7                               0.54052      0.00468    0.54859     0.53253
alpha_8                               0.54050      0.00468    0.54857     0.53251
alpha_9                               0.54051      0.00468    0.54858     0.53252
Alpha_loss                            -3.91391     0.06065    -3.81404    -4.03677
Training/policy_loss                  -80.49520    1.18887    -77.98090   -82.87891
Training/qf1_loss                     2434.06380   951.82337  5177.26270  785.13074
Training/qf2_loss                     2433.34683   951.68850  5175.44629  783.55341
Training/pf_norm                      0.24958      0.05460    0.40572     0.13601
Training/qf1_norm                     619.66105    456.99063  2311.55859  45.32592
Training/qf2_norm                     620.88638    458.66371  2317.64795  44.32634
log_std/mean                          -0.15197     0.00376    -0.14387    -0.15790
log_std/std                           0.08005      0.00567    0.08747     0.06762
log_std/max                           -0.10877     0.01336    -0.07765    -0.12197
log_std/min                           -0.59507     0.04563    -0.51576    -0.66843
log_probs/mean                        -2.43059     0.02459    -2.37519    -2.48326
log_probs/std                         1.09333      0.06991    1.23287     0.94029
log_probs/max                         3.44495      0.41222    4.36204     2.55240
log_probs/min                         -6.06651     1.23205    -4.31778    -11.13712
mean/mean                             -0.04871     0.00878    -0.03429    -0.06258
mean/std                              0.32741      0.00912    0.34294     0.30714
mean/max                              0.89514      0.06294    0.98211     0.80309
mean/min                              -1.69393     0.02801    -1.65227    -1.74113
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 3, 9, 6, 1, 0, 2, 4, 8, 5]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
2023-08-12 11:44:40,098 MainThread INFO: EPOCH:21
2023-08-12 11:44:40,098 MainThread INFO: Time Consumed:8.536325693130493s
2023-08-12 11:44:40,098 MainThread INFO: Total Frames:63000s
  0%|          | 22/10000 [03:19<25:16:28,  9.12s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               36.70668
Train_Epoch_Reward                    2341.55465
Running_Training_Average_Rewards      502.13557
Explore_Time                          0.01036
Train___Time                          8.52100
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.10779
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.54259
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.69841
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.03122
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.68320
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.51763
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.45676
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 628.63103
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.97783
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.54877
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.23728     1.36609     11.42719    5.11408
alpha_0                               0.58825     0.00419     0.59588     0.58141
alpha_1                               0.52453     0.00455     0.53236     0.51677
alpha_2                               0.52451     0.00454     0.53234     0.51676
alpha_3                               0.52452     0.00454     0.53234     0.51677
alpha_4                               0.52451     0.00454     0.53233     0.51676
alpha_5                               0.52456     0.00454     0.53239     0.51681
alpha_6                               0.52452     0.00454     0.53235     0.51677
alpha_7                               0.52454     0.00454     0.53237     0.51679
alpha_8                               0.52452     0.00454     0.53235     0.51677
alpha_9                               0.52453     0.00454     0.53236     0.51678
Alpha_loss                            -4.09173    0.03909     -4.02367    -4.16934
Training/policy_loss                  -84.36522   1.17018     -82.08251   -86.82369
Training/qf1_loss                     2445.92174  1052.05999  6520.77637  592.12714
Training/qf2_loss                     2445.12168  1051.82627  6519.78027  591.05676
Training/pf_norm                      0.32307     0.11924     0.53415     0.11650
Training/qf1_norm                     716.94409   494.81455   2177.14429  95.25371
Training/qf2_norm                     718.56642   496.82734   2185.48682  94.71133
log_std/mean                          -0.15381    0.00510     -0.14359    -0.16064
log_std/std                           0.08699     0.00363     0.09451     0.08065
log_std/max                           -0.07579    0.03216     -0.03488    -0.12605
log_std/min                           -0.58295    0.05646     -0.49830    -0.66721
log_probs/mean                        -2.40566    0.04168     -2.31879    -2.50914
log_probs/std                         1.15189     0.11070     1.34226     0.91424
log_probs/max                         3.63380     0.43995     4.39435     2.43102
log_probs/min                         -5.74546    1.00337     -4.05242    -8.61363
mean/mean                             0.00328     0.01920     0.02385     -0.03383
mean/std                              0.34255     0.01821     0.36460     0.30636
mean/max                              1.04111     0.13065     1.23574     0.80192
mean/min                              -1.75405    0.04376     -1.66261    -1.80583
------------------------------------  ----------  ----------  ----------  ---------
sample: [6, 1, 9, 7, 3, 5, 2, 8, 0, 4]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
2023-08-12 11:44:49,095 MainThread INFO: EPOCH:22
2023-08-12 11:44:49,096 MainThread INFO: Time Consumed:8.801682472229004s
2023-08-12 11:44:49,096 MainThread INFO: Total Frames:64500s
  0%|          | 23/10000 [03:28<25:06:33,  9.06s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               69.58647
Train_Epoch_Reward                    569.55125
Running_Training_Average_Rewards      437.61618
Explore_Time                          0.00443
Train___Time                          8.79206
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.80611
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.19846
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.33130
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.99982
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.18703
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.18552
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.38194
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 948.17005
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.58752
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.62763
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.33163     1.24606    11.93446    5.48708
alpha_0                               0.57451     0.00408    0.58128     0.56728
alpha_1                               0.50902     0.00441    0.51662     0.50149
alpha_2                               0.50901     0.00441    0.51660     0.50149
alpha_3                               0.50901     0.00441    0.51661     0.50148
alpha_4                               0.50901     0.00441    0.51660     0.50148
alpha_5                               0.50905     0.00441    0.51665     0.50153
alpha_6                               0.50902     0.00441    0.51662     0.50150
alpha_7                               0.50903     0.00441    0.51663     0.50151
alpha_8                               0.50902     0.00441    0.51662     0.50149
alpha_9                               0.50903     0.00441    0.51663     0.50151
Alpha_loss                            -4.28426    0.06665    -4.16069    -4.39306
Training/policy_loss                  -88.74089   1.10322    -86.32905   -90.76034
Training/qf1_loss                     2550.13298  957.69844  6247.42236  749.72565
Training/qf2_loss                     2549.29665  957.48122  6244.93408  749.56738
Training/pf_norm                      0.29652     0.10799    0.53990     0.12172
Training/qf1_norm                     691.97973   429.90608  2316.88062  115.22765
Training/qf2_norm                     693.48230   431.54229  2324.78345  114.69016
log_std/mean                          -0.15297    0.00164    -0.15082    -0.15808
log_std/std                           0.08612     0.00576    0.09494     0.07474
log_std/max                           -0.09717    0.04280    0.01751     -0.12544
log_std/min                           -0.56613    0.02931    -0.50220    -0.59864
log_probs/mean                        -2.40909    0.03069    -2.34610    -2.48572
log_probs/std                         1.15108     0.07986    1.30823     0.95465
log_probs/max                         3.47573     0.31397    4.00859     2.63789
log_probs/min                         -5.93915    1.06310    -4.22739    -8.87947
mean/mean                             0.01017     0.00347    0.01601     0.00395
mean/std                              0.34010     0.01354    0.36109     0.31696
mean/max                              1.28290     0.04110    1.34735     1.22035
mean/min                              -1.63633    0.06887    -1.51394    -1.73049
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 9, 1, 0, 4, 5, 3, 8, 7, 6]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
2023-08-12 11:44:58,695 MainThread INFO: EPOCH:23
2023-08-12 11:44:58,696 MainThread INFO: Time Consumed:9.433253288269043s
2023-08-12 11:44:58,696 MainThread INFO: Total Frames:66000s
  0%|          | 24/10000 [03:37<25:32:24,  9.22s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               180.45932
Train_Epoch_Reward                    816.29472
Running_Training_Average_Rewards      124.24669
Explore_Time                          0.01241
Train___Time                          9.41630
Eval____Time                          0.00391
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.64022
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.88158
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.29508
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.34905
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.70621
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.85022
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.29405
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2062.42741
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.11159
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.70621
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.05801     1.26935    11.56159    4.95408
alpha_0                               0.55916     0.00491    0.56713     0.55033
alpha_1                               0.49397     0.00428    0.50134     0.48667
alpha_2                               0.49397     0.00428    0.50134     0.48667
alpha_3                               0.49396     0.00428    0.50133     0.48666
alpha_4                               0.49396     0.00428    0.50133     0.48666
alpha_5                               0.49401     0.00427    0.50138     0.48671
alpha_6                               0.49398     0.00428    0.50135     0.48667
alpha_7                               0.49398     0.00428    0.50136     0.48668
alpha_8                               0.49397     0.00428    0.50134     0.48668
alpha_9                               0.49399     0.00428    0.50136     0.48668
Alpha_loss                            -4.52149    0.08111    -4.37818    -4.64368
Training/policy_loss                  -92.38560   1.02244    -90.30740   -94.66019
Training/qf1_loss                     2341.98435  949.67906  5192.50488  658.45282
Training/qf2_loss                     2341.30854  949.48547  5190.37500  657.33093
Training/pf_norm                      0.37450     0.09190    0.60084     0.19912
Training/qf1_norm                     682.85416   508.03836  2433.33765  109.99861
Training/qf2_norm                     684.22732   509.44025  2438.87378  109.43472
log_std/mean                          -0.15337    0.00300    -0.14890    -0.15761
log_std/std                           0.06637     0.01364    0.09313     0.04659
log_std/max                           -0.09525    0.04374    0.01658     -0.12646
log_std/min                           -0.45441    0.06168    -0.36528    -0.57324
log_probs/mean                        -2.48815    0.04749    -2.39102    -2.60655
log_probs/std                         0.94711     0.10336    1.14749     0.75305
log_probs/max                         2.84262     0.32185    3.62667     2.09091
log_probs/min                         -6.11973    1.05408    -4.23761    -9.57230
mean/mean                             0.00023     0.01036    0.00940     -0.02339
mean/std                              0.29556     0.02303    0.33231     0.26250
mean/max                              1.13712     0.17347    1.34714     0.83727
mean/min                              -1.33189    0.14924    -1.13841    -1.59116
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 8, 4, 1, 6, 3, 0, 9, 2, 7]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
2023-08-12 11:45:08,169 MainThread INFO: EPOCH:24
2023-08-12 11:45:08,169 MainThread INFO: Time Consumed:9.28153657913208s
2023-08-12 11:45:08,170 MainThread INFO: Total Frames:67500s
  0%|          | 25/10000 [03:47<25:48:15,  9.31s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               409.70607
Train_Epoch_Reward                    1512.07121
Running_Training_Average_Rewards      96.59724
Explore_Time                          0.01291
Train___Time                          9.26416
Eval____Time                          0.00367
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.30539
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.46290
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.82300
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.48280
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.82292
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.67404
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.32755
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4344.99289
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.43057
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.60301
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.03445     1.20776    10.76339    5.73370
alpha_0                               0.54116     0.00521    0.55015     0.53241
alpha_1                               0.47937     0.00415    0.48652     0.47229
alpha_2                               0.47937     0.00415    0.48652     0.47228
alpha_3                               0.47936     0.00415    0.48651     0.47227
alpha_4                               0.47936     0.00415    0.48651     0.47227
alpha_5                               0.47942     0.00415    0.48657     0.47233
alpha_6                               0.47937     0.00415    0.48653     0.47229
alpha_7                               0.47938     0.00415    0.48653     0.47230
alpha_8                               0.47938     0.00415    0.48653     0.47229
alpha_9                               0.47939     0.00415    0.48654     0.47230
Alpha_loss                            -4.73754    0.05580    -4.62542    -4.84529
Training/policy_loss                  -95.97131   1.26632    -93.60714   -98.48659
Training/qf1_loss                     2308.23390  961.33646  4740.05811  760.46252
Training/qf2_loss                     2307.58372  961.18649  4739.22363  759.57153
Training/pf_norm                      0.26238     0.08414    0.48915     0.14028
Training/qf1_norm                     726.53775   478.61104  2054.29248  107.44480
Training/qf2_norm                     728.12168   480.24817  2061.20215  108.95121
log_std/mean                          -0.15373    0.00283    -0.14991    -0.15884
log_std/std                           0.06604     0.00491    0.07290     0.05672
log_std/max                           -0.11779    0.00665    -0.09971    -0.12284
log_std/min                           -0.46535    0.02530    -0.42514    -0.52105
log_probs/mean                        -2.52185    0.02292    -2.46692    -2.57350
log_probs/std                         0.86610     0.05613    0.98449     0.71256
log_probs/max                         2.71056     0.35590    3.27467     1.34159
log_probs/min                         -6.09640    1.05498    -4.51805    -9.76248
mean/mean                             -0.01163    0.00830    -0.00031    -0.02508
mean/std                              0.26912     0.01053    0.28198     0.24915
mean/max                              0.81146     0.09762    0.96009     0.65294
mean/min                              -1.05493    0.06655    -0.94529    -1.19343
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 6, 5, 2, 4, 1, 0, 9, 8, 7]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
2023-08-12 11:45:17,539 MainThread INFO: EPOCH:25
2023-08-12 11:45:17,539 MainThread INFO: Time Consumed:9.184308290481567s
2023-08-12 11:45:17,539 MainThread INFO: Total Frames:69000s
  0%|          | 26/10000 [03:56<25:48:48,  9.32s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               698.15782
Train_Epoch_Reward                    3827.41630
Running_Training_Average_Rewards      205.19274
Explore_Time                          0.00473
Train___Time                          9.17499
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.15903
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.49451
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.83859
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.82004
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.54622
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.30216
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.74592
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7223.73625
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.97132
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.28025
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.93854     1.24702     11.60972    5.52382
alpha_0                               0.52466     0.00420     0.53224     0.51786
alpha_1                               0.46520     0.00403     0.47214     0.45833
alpha_2                               0.46520     0.00403     0.47214     0.45833
alpha_3                               0.46519     0.00403     0.47213     0.45832
alpha_4                               0.46519     0.00403     0.47213     0.45831
alpha_5                               0.46525     0.00403     0.47219     0.45837
alpha_6                               0.46520     0.00403     0.47215     0.45833
alpha_7                               0.46521     0.00403     0.47215     0.45834
alpha_8                               0.46521     0.00403     0.47215     0.45833
alpha_9                               0.46522     0.00403     0.47216     0.45835
Alpha_loss                            -4.87866    0.03765     -4.80665    -4.96691
Training/policy_loss                  -99.99194   1.06534     -97.85516   -102.38450
Training/qf1_loss                     2321.69171  1019.64930  6899.62744  760.16229
Training/qf2_loss                     2320.95666  1019.43838  6897.60156  759.65765
Training/pf_norm                      0.37063     0.11879     0.57057     0.10825
Training/qf1_norm                     708.79817   542.84991   2568.98462  88.18116
Training/qf2_norm                     710.09400   544.66847   2575.23193  88.36804
log_std/mean                          -0.15465    0.00299     -0.14858    -0.15992
log_std/std                           0.09419     0.00778     0.10579     0.07305
log_std/max                           -0.06495    0.03878     -0.01168    -0.11982
log_std/min                           -0.59464    0.03524     -0.49644    -0.65657
log_probs/mean                        -2.43696    0.04062     -2.33871    -2.52054
log_probs/std                         1.06342     0.11075     1.28862     0.81963
log_probs/max                         3.26873     0.48669     4.51522     2.22586
log_probs/min                         -5.75749    0.78252     -4.09718    -7.66731
mean/mean                             0.01131     0.00791     0.02241     -0.00019
mean/std                              0.31688     0.02484     0.35762     0.27311
mean/max                              1.30308     0.14001     1.48881     0.97037
mean/min                              -1.42561    0.14140     -1.14503    -1.64337
------------------------------------  ----------  ----------  ----------  ----------
sample: [0, 4, 6, 8, 9, 2, 3, 5, 1, 7]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
2023-08-12 11:45:26,551 MainThread INFO: EPOCH:26
2023-08-12 11:45:26,551 MainThread INFO: Time Consumed:8.832643747329712s
2023-08-12 11:45:26,551 MainThread INFO: Total Frames:70500s
  0%|          | 27/10000 [04:05<25:34:25,  9.23s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1503.15023
Train_Epoch_Reward                    8027.21075
Running_Training_Average_Rewards      445.55661
Explore_Time                          0.00551
Train___Time                          8.82189
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.90438
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.34214
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.98486
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.31290
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.22178
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.17711
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.45126
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15268.86333
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -21.80407
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16255
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.79848      1.37093     11.85667    4.55537
alpha_0                               0.51179      0.00336     0.51773     0.50606
alpha_1                               0.45145      0.00391     0.45819     0.44477
alpha_2                               0.45145      0.00391     0.45819     0.44478
alpha_3                               0.45145      0.00391     0.45818     0.44478
alpha_4                               0.45143      0.00391     0.45817     0.44476
alpha_5                               0.45149      0.00391     0.45823     0.44482
alpha_6                               0.45145      0.00391     0.45819     0.44478
alpha_7                               0.45146      0.00391     0.45820     0.44479
alpha_8                               0.45146      0.00391     0.45820     0.44479
alpha_9                               0.45148      0.00391     0.45821     0.44481
Alpha_loss                            -5.02962     0.05186     -4.94523    -5.13838
Training/policy_loss                  -103.96214   1.15588     -101.57994  -106.00149
Training/qf1_loss                     2291.19976   1076.64337  5663.57568  553.51678
Training/qf2_loss                     2290.74957   1076.47063  5663.75146  553.24329
Training/pf_norm                      0.20009      0.05715     0.32316     0.08197
Training/qf1_norm                     808.73061    561.39229   3084.34033  109.33667
Training/qf2_norm                     810.35235    563.00295   3092.07593  108.78320
log_std/mean                          -0.15698     0.00224     -0.15234    -0.16008
log_std/std                           0.08523      0.00372     0.09294     0.08019
log_std/max                           -0.11859     0.00136     -0.11635    -0.12199
log_std/min                           -0.60208     0.02105     -0.55624    -0.63177
log_probs/mean                        -2.37638     0.02452     -2.31907    -2.44338
log_probs/std                         1.24397      0.06071     1.37862     1.09367
log_probs/max                         4.19371      0.27315     4.77909     3.25414
log_probs/min                         -5.75729     1.06998     -4.31874    -11.39463
mean/mean                             0.01676      0.00195     0.01990     0.00994
mean/std                              0.35902      0.00778     0.36969     0.34241
mean/max                              1.32040      0.04995     1.40223     1.22313
mean/min                              -1.69784     0.04864     -1.58396    -1.75070
------------------------------------  -----------  ----------  ----------  ----------
sample: [0, 3, 8, 6, 2, 7, 9, 1, 4, 5]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
2023-08-12 11:45:35,265 MainThread INFO: EPOCH:27
2023-08-12 11:45:35,266 MainThread INFO: Time Consumed:8.528082609176636s
2023-08-12 11:45:35,266 MainThread INFO: Total Frames:72000s
  0%|          | 28/10000 [04:14<25:07:32,  9.07s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               395.33972
Train_Epoch_Reward                    19659.02107
Running_Training_Average_Rewards      1050.45494
Explore_Time                          0.00407
Train___Time                          8.51931
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.66401
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.38682
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.41990
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.17065
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.99064
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.80778
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.26247
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4200.50518
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.36938
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.03632
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.89275      1.40654     11.35804    4.46931
alpha_0                               0.49996      0.00346     0.50594     0.49402
alpha_1                               0.43810      0.00380     0.44464     0.43162
alpha_2                               0.43811      0.00379     0.44464     0.43163
alpha_3                               0.43811      0.00380     0.44465     0.43163
alpha_4                               0.43809      0.00379     0.44463     0.43162
alpha_5                               0.43814      0.00380     0.44468     0.43167
alpha_6                               0.43811      0.00379     0.44464     0.43164
alpha_7                               0.43811      0.00379     0.44465     0.43164
alpha_8                               0.43812      0.00379     0.44466     0.43164
alpha_9                               0.43814      0.00380     0.44468     0.43166
Alpha_loss                            -5.22528     0.05376     -5.13760    -5.31554
Training/policy_loss                  -108.18369   1.37705     -105.64386  -110.85335
Training/qf1_loss                     2319.13953   1022.58107  5871.21924  562.79260
Training/qf2_loss                     2318.70091   1022.34025  5869.76318  563.49329
Training/pf_norm                      0.27680      0.09613     0.44496     0.08273
Training/qf1_norm                     869.15950    552.43275   2796.98364  136.24979
Training/qf2_norm                     871.26537    554.50605   2807.47266  135.65170
log_std/mean                          -0.15473     0.00163     -0.15211    -0.15733
log_std/std                           0.09055      0.00480     0.10143     0.08254
log_std/max                           -0.09808     0.02092     -0.06658    -0.12143
log_std/min                           -0.60257     0.02396     -0.56546    -0.65042
log_probs/mean                        -2.38551     0.01677     -2.34752    -2.43767
log_probs/std                         1.20904      0.04669     1.34532     1.09144
log_probs/max                         3.80759      0.33122     4.41961     3.01987
log_probs/min                         -5.86273     1.23165     -4.24027    -10.05226
mean/mean                             0.00509      0.00525     0.01143     -0.00834
mean/std                              0.35350      0.00476     0.36064     0.34578
mean/max                              1.29519      0.06722     1.42663     1.21707
mean/min                              -1.76202     0.03188     -1.70682    -1.81247
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 3, 0, 8, 2, 6, 4, 7, 1, 9]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
2023-08-12 11:45:43,907 MainThread INFO: EPOCH:28
2023-08-12 11:45:43,908 MainThread INFO: Time Consumed:8.482519149780273s
2023-08-12 11:45:43,908 MainThread INFO: Total Frames:73500s
  0%|          | 29/10000 [04:23<24:44:50,  8.93s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               292.78516
Train_Epoch_Reward                    6139.75092
Running_Training_Average_Rewards      1127.53276
Explore_Time                          0.00421
Train___Time                          8.47311
Eval____Time                          0.00449
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.54907
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.27084
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.79180
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.36034
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.04318
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.58003
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.59643
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3162.94113
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.11595
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.78195
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.09434     1.49611     13.34560    5.14930
alpha_0                               0.48816     0.00322     0.49391     0.48314
alpha_1                               0.42515     0.00368     0.43150     0.41887
alpha_2                               0.42515     0.00368     0.43150     0.41887
alpha_3                               0.42516     0.00368     0.43150     0.41888
alpha_4                               0.42514     0.00368     0.43149     0.41886
alpha_5                               0.42519     0.00368     0.43154     0.41891
alpha_6                               0.42516     0.00368     0.43151     0.41888
alpha_7                               0.42516     0.00368     0.43151     0.41888
alpha_8                               0.42517     0.00368     0.43151     0.41889
alpha_9                               0.42518     0.00368     0.43153     0.41890
Alpha_loss                            -5.38539    0.02746     -5.31070    -5.43192
Training/policy_loss                  -112.13193  1.63993     -109.54223  -115.44269
Training/qf1_loss                     2329.86375  1116.07710  7081.91748  496.07529
Training/qf2_loss                     2329.44134  1115.82369  7079.46436  496.45224
Training/pf_norm                      0.32709     0.13382     0.59893     0.11566
Training/qf1_norm                     907.40531   749.26625   4269.29980  138.82933
Training/qf2_norm                     909.48587   750.90075   4278.81738  138.63966
log_std/mean                          -0.15967    0.00302     -0.15362    -0.16418
log_std/std                           0.09566     0.00714     0.11000     0.08756
log_std/max                           -0.11352    0.01514     -0.07009    -0.12613
log_std/min                           -0.63096    0.01978     -0.59431    -0.65815
log_probs/mean                        -2.34492    0.04955     -2.23460    -2.41217
log_probs/std                         1.31330     0.14167     1.61393     1.10838
log_probs/max                         3.92765     0.67102     5.47011     2.74025
log_probs/min                         -5.65719    1.06535     -3.97759    -9.38764
mean/mean                             -0.03117    0.00966     -0.00886    -0.04071
mean/std                              0.37493     0.02355     0.42078     0.34913
mean/max                              1.42349     0.06615     1.56027     1.35682
mean/min                              -1.86962    0.07969     -1.77380    -2.01665
------------------------------------  ----------  ----------  ----------  ----------
sample: [3, 8, 4, 9, 7, 0, 1, 6, 5, 2]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
2023-08-12 11:45:52,334 MainThread INFO: EPOCH:29
2023-08-12 11:45:52,334 MainThread INFO: Time Consumed:8.242177724838257s
2023-08-12 11:45:52,335 MainThread INFO: Total Frames:75000s
  0%|          | 30/10000 [04:31<24:21:35,  8.80s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1516.94177
Train_Epoch_Reward                    6949.87056
Running_Training_Average_Rewards      1091.62142
Explore_Time                          0.00382
Train___Time                          8.23382
Eval____Time                          0.00379
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.53548
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.85955
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.03507
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.94544
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.92755
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.30030
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.04243
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15413.38264
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.85443
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.46473
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.29947      1.31934     11.20767    5.19046
alpha_0                               0.47985      0.00162     0.48307     0.47786
alpha_1                               0.41259      0.00357     0.41874     0.40649
alpha_2                               0.41258      0.00357     0.41874     0.40649
alpha_3                               0.41260      0.00357     0.41875     0.40650
alpha_4                               0.41258      0.00357     0.41874     0.40649
alpha_5                               0.41263      0.00357     0.41878     0.40654
alpha_6                               0.41260      0.00357     0.41876     0.40650
alpha_7                               0.41259      0.00357     0.41875     0.40649
alpha_8                               0.41260      0.00357     0.41876     0.40651
alpha_9                               0.41261      0.00358     0.41877     0.40651
Alpha_loss                            -5.45526     0.02406     -5.39036    -5.52131
Training/policy_loss                  -117.19492   1.59751     -114.30019  -120.52187
Training/qf1_loss                     2553.77769   1064.94820  5601.33936  693.00580
Training/qf2_loss                     2553.35733   1064.71447  5599.74414  692.92499
Training/pf_norm                      0.23246      0.06613     0.43491     0.10954
Training/qf1_norm                     871.75277    525.62219   2450.21704  144.80864
Training/qf2_norm                     873.32856    527.09934   2459.92114  144.46361
log_std/mean                          -0.16776     0.00373     -0.16183    -0.17346
log_std/std                           0.11182      0.00781     0.12198     0.09814
log_std/max                           -0.12194     0.00311     -0.11658    -0.12814
log_std/min                           -0.63192     0.02337     -0.59595    -0.67262
log_probs/mean                        -2.18565     0.07244     -2.05859    -2.30673
log_probs/std                         1.77629      0.20543     2.13715     1.45573
log_probs/max                         5.97036      0.86324     7.54532     4.70390
log_probs/min                         -5.38570     1.17962     -3.94387    -11.16233
mean/mean                             -0.05450     0.00788     -0.04106    -0.06401
mean/std                              0.44791      0.02828     0.49113     0.40965
mean/max                              1.65000      0.11286     1.83168     1.48962
mean/min                              -2.06544     0.06461     -1.96094    -2.15681
------------------------------------  -----------  ----------  ----------  ----------
sample: [9, 2, 3, 5, 0, 7, 4, 8, 1, 6]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
2023-08-12 11:46:01,316 MainThread INFO: EPOCH:30
2023-08-12 11:46:01,317 MainThread INFO: Time Consumed:8.810880899429321s
2023-08-12 11:46:01,317 MainThread INFO: Total Frames:76500s
  0%|          | 31/10000 [04:40<24:28:55,  8.84s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2027.11575
Train_Epoch_Reward                    24678.31319
Running_Training_Average_Rewards      1258.93116
Explore_Time                          0.00926
Train___Time                          8.79708
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.17240
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.01189
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.18162
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.48322
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.66666
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.02856
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.53372
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20525.32601
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.51719
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.57322
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.12015      1.41436     13.23298    4.61317
alpha_0                               0.47667      0.00088     0.47784     0.47517
alpha_1                               0.40040      0.00347     0.40637     0.39448
alpha_2                               0.40039      0.00347     0.40636     0.39448
alpha_3                               0.40040      0.00347     0.40638     0.39448
alpha_4                               0.40039      0.00347     0.40637     0.39447
alpha_5                               0.40044      0.00347     0.40641     0.39452
alpha_6                               0.40041      0.00347     0.40638     0.39449
alpha_7                               0.40040      0.00347     0.40637     0.39448
alpha_8                               0.40041      0.00347     0.40638     0.39450
alpha_9                               0.40042      0.00347     0.40639     0.39450
Alpha_loss                            -5.59564     0.06355     -5.44873    -5.68544
Training/policy_loss                  -121.29154   1.31400     -119.06394  -124.02781
Training/qf1_loss                     2520.40853   1180.71167  6559.83545  475.69980
Training/qf2_loss                     2519.95349   1180.47964  6558.87988  475.98541
Training/pf_norm                      0.22363      0.05794     0.38829     0.08686
Training/qf1_norm                     888.55946    688.46251   3983.99170  131.81075
Training/qf2_norm                     890.37606    690.38411   3990.70825  130.49005
log_std/mean                          -0.16813     0.00233     -0.16390    -0.17207
log_std/std                           0.11370      0.00486     0.12080     0.10443
log_std/max                           -0.11799     0.00670     -0.10333    -0.12405
log_std/min                           -0.63533     0.01989     -0.60740    -0.67365
log_probs/mean                        -2.12852     0.03564     -2.04182    -2.20509
log_probs/std                         1.93686      0.09575     2.15690     1.74425
log_probs/max                         6.59334      0.40485     7.39813     5.80219
log_probs/min                         -5.20069     0.94840     -3.88157    -10.44385
mean/mean                             -0.04703     0.00960     -0.03702    -0.06240
mean/std                              0.47499      0.01084     0.48971     0.45467
mean/max                              1.76943      0.04056     1.83129     1.69390
mean/min                              -2.10911     0.02708     -2.04765    -2.14099
------------------------------------  -----------  ----------  ----------  ----------
sample: [0, 8, 7, 5, 6, 9, 4, 3, 2, 1]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
2023-08-12 11:46:10,147 MainThread INFO: EPOCH:31
2023-08-12 11:46:10,147 MainThread INFO: Time Consumed:8.623276710510254s
2023-08-12 11:46:10,148 MainThread INFO: Total Frames:78000s
  0%|          | 32/10000 [04:49<24:27:43,  8.83s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               746.75055
Train_Epoch_Reward                    29545.96132
Running_Training_Average_Rewards      2039.13817
Explore_Time                          0.00416
Train___Time                          8.61353
Eval____Time                          0.00484
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.38414
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.17670
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.60747
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.45535
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.55012
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.28672
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.43008
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7714.73070
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.70109
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.63350
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.44043      1.33971     12.25805    5.81451
alpha_0                               0.47456      0.00026     0.47515     0.47410
alpha_1                               0.38857      0.00336     0.39437     0.38283
alpha_2                               0.38856      0.00336     0.39436     0.38283
alpha_3                               0.38857      0.00336     0.39437     0.38283
alpha_4                               0.38856      0.00336     0.39435     0.38282
alpha_5                               0.38860      0.00336     0.39440     0.38286
alpha_6                               0.38857      0.00336     0.39437     0.38283
alpha_7                               0.38856      0.00337     0.39436     0.38282
alpha_8                               0.38858      0.00337     0.39438     0.38283
alpha_9                               0.38859      0.00336     0.39439     0.38285
Alpha_loss                            -5.74304     0.05220     -5.65225    -5.84187
Training/policy_loss                  -125.98097   1.44021     -122.98799  -128.81429
Training/qf1_loss                     2740.18125   1228.33578  7477.31006  904.07129
Training/qf2_loss                     2739.67405   1228.03718  7476.57275  903.72083
Training/pf_norm                      0.29959      0.11157     0.52853     0.08434
Training/qf1_norm                     935.32915    633.21288   3367.90845  128.27803
Training/qf2_norm                     937.18917    635.06325   3376.76758  128.34456
log_std/mean                          -0.16874     0.00151     -0.16620    -0.17262
log_std/std                           0.12093      0.00305     0.12855     0.11565
log_std/max                           -0.11246     0.01444     -0.07445    -0.12358
log_std/min                           -0.63703     0.02632     -0.60308    -0.70473
log_probs/mean                        -2.08209     0.02427     -2.01993    -2.13863
log_probs/std                         2.07006      0.06526     2.22735     1.90716
log_probs/max                         7.02101      0.27676     7.57281     6.41710
log_probs/min                         -5.21478     0.99773     -3.89833    -8.80032
mean/mean                             -0.04528     0.00871     -0.03740    -0.06818
mean/std                              0.49311      0.00576     0.50492     0.48289
mean/max                              1.80122      0.02450     1.84469     1.75677
mean/min                              -2.07830     0.02316     -2.02268    -2.12186
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 0, 4, 5, 6, 9, 3, 8, 1, 2]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
2023-08-12 11:46:19,237 MainThread INFO: EPOCH:32
2023-08-12 11:46:19,238 MainThread INFO: Time Consumed:8.9884192943573s
2023-08-12 11:46:19,238 MainThread INFO: Total Frames:79500s
  0%|          | 33/10000 [04:58<24:40:29,  8.91s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1511.97391
Train_Epoch_Reward                    9586.59780
Running_Training_Average_Rewards      2127.02908
Explore_Time                          0.01058
Train___Time                          8.97357
Eval____Time                          0.00359
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.93854
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.88044
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.50122
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.75745
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.63520
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19443
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.33900
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15373.18441
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.87328
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.32572
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.36480      1.41243     13.59599    5.06643
alpha_0                               0.47428      0.00027     0.47465     0.47365
alpha_1                               0.37709      0.00326     0.38271     0.37152
alpha_2                               0.37708      0.00327     0.38271     0.37151
alpha_3                               0.37708      0.00327     0.38271     0.37151
alpha_4                               0.37708      0.00327     0.38271     0.37151
alpha_5                               0.37712      0.00327     0.38275     0.37154
alpha_6                               0.37708      0.00327     0.38271     0.37151
alpha_7                               0.37708      0.00326     0.38270     0.37151
alpha_8                               0.37709      0.00327     0.38272     0.37152
alpha_9                               0.37710      0.00326     0.38273     0.37153
Alpha_loss                            -5.91731     0.08447     -5.77704    -6.06348
Training/policy_loss                  -130.08239   1.22319     -127.46764  -132.41875
Training/qf1_loss                     2665.68719   1040.12198  5548.74170  820.06671
Training/qf2_loss                     2665.27891   1039.95920  5547.41504  819.78729
Training/pf_norm                      0.25454      0.09405     0.47149     0.07487
Training/qf1_norm                     959.50059    718.31536   4600.55273  185.05360
Training/qf2_norm                     961.39648    720.13914   4613.52637  184.73743
log_std/mean                          -0.17167     0.00226     -0.16731    -0.17454
log_std/std                           0.11830      0.00670     0.12981     0.10764
log_std/max                           -0.12029     0.00345     -0.11467    -0.12678
log_std/min                           -0.63268     0.02564     -0.59976    -0.70557
log_probs/mean                        -2.07195     0.05020     -1.97742    -2.18495
log_probs/std                         2.11254      0.13995     2.35378     1.81397
log_probs/max                         7.54664      0.48099     8.38816     6.38890
log_probs/min                         -5.21940     1.05581     -3.76607    -10.19333
mean/mean                             -0.07294     0.00701     -0.05867    -0.08167
mean/std                              0.49260      0.01854     0.51585     0.46794
mean/max                              1.69101      0.07739     1.80146     1.58949
mean/min                              -2.04075     0.06213     -1.96589    -2.13793
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 4, 5, 8, 0, 7, 1, 2, 9, 6]
replay_buffer._size: [8250 8250 8250 8250 8250 8250 8250 8250 8250 8250]
2023-08-12 11:46:28,121 MainThread INFO: EPOCH:33
2023-08-12 11:46:28,122 MainThread INFO: Time Consumed:8.778380393981934s
2023-08-12 11:46:28,122 MainThread INFO: Total Frames:81000s
  0%|          | 34/10000 [05:07<24:39:14,  8.91s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               806.10033
Train_Epoch_Reward                    16511.95454
Running_Training_Average_Rewards      1854.81712
Explore_Time                          0.00747
Train___Time                          8.76536
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.89917
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.24203
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.15954
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.13339
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.26141
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.54883
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.25662
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8299.40469
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.27328
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.62712
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.30401      1.36456     11.92433    5.36063
alpha_0                               0.47309      0.00022     0.47363     0.47286
alpha_1                               0.36595      0.00317     0.37141     0.36054
alpha_2                               0.36594      0.00317     0.37140     0.36053
alpha_3                               0.36594      0.00317     0.37140     0.36053
alpha_4                               0.36594      0.00317     0.37140     0.36053
alpha_5                               0.36597      0.00317     0.37143     0.36056
alpha_6                               0.36594      0.00317     0.37140     0.36054
alpha_7                               0.36594      0.00317     0.37140     0.36053
alpha_8                               0.36595      0.00317     0.37141     0.36054
alpha_9                               0.36596      0.00317     0.37142     0.36055
Alpha_loss                            -6.09290     0.03712     -6.01642    -6.20500
Training/policy_loss                  -134.33979   1.45271     -131.60568  -137.21928
Training/qf1_loss                     2575.60264   1076.74395  6213.55615  848.28143
Training/qf2_loss                     2575.16419   1076.53414  6212.65381  848.50696
Training/pf_norm                      0.36082      0.11399     0.56380     0.11515
Training/qf1_norm                     981.57438    639.56994   3104.15796  128.46230
Training/qf2_norm                     983.57630    641.39471   3110.84888  127.35110
log_std/mean                          -0.16766     0.00311     -0.16252    -0.17274
log_std/std                           0.12692      0.00398     0.13513     0.11710
log_std/max                           -0.06907     0.04908     0.01970     -0.11565
log_std/min                           -0.63478     0.02086     -0.58619    -0.68140
log_probs/mean                        -2.06332     0.03486     -1.99003    -2.14871
log_probs/std                         2.13390      0.09953     2.35839     1.89349
log_probs/max                         7.36679      0.45535     8.46836     6.43880
log_probs/min                         -5.20775     0.94445     -3.93151    -8.45283
mean/mean                             -0.04310     0.00926     -0.02785    -0.05826
mean/std                              0.49771      0.01392     0.51981     0.47369
mean/max                              1.72860      0.03926     1.78247     1.64712
mean/min                              -2.01114     0.03141     -1.94658    -2.06031
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 7, 9, 4, 5, 1, 2, 8, 0, 6]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
2023-08-12 11:46:36,869 MainThread INFO: EPOCH:34
2023-08-12 11:46:36,869 MainThread INFO: Time Consumed:8.581611156463623s
2023-08-12 11:46:36,869 MainThread INFO: Total Frames:82500s
  0%|          | 35/10000 [05:16<24:32:35,  8.87s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               635.30192
Train_Epoch_Reward                    7493.78428
Running_Training_Average_Rewards      1119.74455
Explore_Time                          0.01048
Train___Time                          8.56653
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.95857
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.24483
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.88644
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.55920
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.90894
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.12905
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.95932
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6604.29318
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.40421
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.22343
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.25873     1.22510     11.08498    5.76471
alpha_0                               0.47331     0.00011     0.47343     0.47297
alpha_1                               0.35514     0.00307     0.36043     0.34989
alpha_2                               0.35512     0.00307     0.36042     0.34987
alpha_3                               0.35512     0.00308     0.36042     0.34987
alpha_4                               0.35512     0.00308     0.36043     0.34987
alpha_5                               0.35516     0.00308     0.36045     0.34991
alpha_6                               0.35512     0.00308     0.36043     0.34988
alpha_7                               0.35512     0.00307     0.36042     0.34987
alpha_8                               0.35513     0.00308     0.36043     0.34988
alpha_9                               0.35514     0.00308     0.36044     0.34988
Alpha_loss                            -6.28090    0.06712     -6.16055    -6.42566
Training/policy_loss                  -138.06928  1.30492     -135.31274  -140.50908
Training/qf1_loss                     2595.27586  1044.74933  6408.87451  717.49805
Training/qf2_loss                     2594.82432  1044.58124  6407.70996  717.03314
Training/pf_norm                      0.20396     0.05974     0.36606     0.08714
Training/qf1_norm                     949.38708   588.99421   2826.09521  149.29947
Training/qf2_norm                     951.21541   590.69380   2836.22363  149.03824
log_std/mean                          -0.17106    0.00105     -0.16839    -0.17308
log_std/std                           0.11769     0.00217     0.12087     0.11363
log_std/max                           -0.12043    0.00152     -0.11599    -0.12342
log_std/min                           -0.61037    0.02116     -0.57766    -0.64448
log_probs/mean                        -2.07161    0.02863     -2.01603    -2.15417
log_probs/std                         2.12016     0.07249     2.27599     1.89779
log_probs/max                         7.61618     0.24399     8.15169     6.99436
log_probs/min                         -5.33155    0.95277     -3.86800    -9.55979
mean/mean                             -0.02690    0.00395     -0.01527    -0.02960
mean/std                              0.49572     0.00802     0.50583     0.47910
mean/max                              1.66046     0.02734     1.72334     1.61105
mean/min                              -1.90042    0.08208     -1.72094    -1.98285
------------------------------------  ----------  ----------  ----------  ----------
sample: [0, 6, 2, 8, 5, 3, 7, 1, 4, 9]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
2023-08-12 11:46:46,404 MainThread INFO: EPOCH:35
2023-08-12 11:46:46,405 MainThread INFO: Time Consumed:9.32975149154663s
2023-08-12 11:46:46,405 MainThread INFO: Total Frames:84000s
  0%|          | 36/10000 [05:25<25:06:33,  9.07s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1062.34224
Train_Epoch_Reward                    5799.99714
Running_Training_Average_Rewards      993.52453
Explore_Time                          0.00418
Train___Time                          9.32054
Eval____Time                          0.00422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.77146
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.76321
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56176
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04748
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.21220
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.00524
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.03270
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10879.68075
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.80468
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.05958
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.89711      1.48277     12.51143    5.25060
alpha_0                               0.47198      0.00075     0.47295     0.47026
alpha_1                               0.34465      0.00298     0.34979     0.33955
alpha_2                               0.34462      0.00299     0.34977     0.33953
alpha_3                               0.34463      0.00298     0.34977     0.33954
alpha_4                               0.34463      0.00298     0.34977     0.33953
alpha_5                               0.34466      0.00299     0.34980     0.33956
alpha_6                               0.34463      0.00298     0.34977     0.33954
alpha_7                               0.34462      0.00299     0.34977     0.33953
alpha_8                               0.34463      0.00298     0.34977     0.33954
alpha_9                               0.34464      0.00298     0.34978     0.33954
Alpha_loss                            -6.49958     0.07838     -6.36088    -6.62644
Training/policy_loss                  -141.55782   0.83662     -139.98064  -143.64287
Training/qf1_loss                     2470.61715   1133.82871  6202.49951  740.33667
Training/qf2_loss                     2470.31598   1133.50441  6201.33545  740.19287
Training/pf_norm                      0.19212      0.04513     0.32611     0.08420
Training/qf1_norm                     1064.20028   784.48384   4140.64600  142.23982
Training/qf2_norm                     1066.58013   786.28085   4148.48828  141.68719
log_std/mean                          -0.17073     0.00207     -0.16709    -0.17373
log_std/std                           0.11436      0.00589     0.12355     0.10295
log_std/max                           -0.11951     0.00145     -0.11695    -0.12245
log_std/min                           -0.59115     0.01468     -0.56077    -0.62107
log_probs/mean                        -2.12040     0.03856     -2.03370    -2.18916
log_probs/std                         1.98852      0.10389     2.23303     1.77135
log_probs/max                         7.16117      0.35283     7.92815     6.20381
log_probs/min                         -5.41171     1.06196     -3.89171    -10.26141
mean/mean                             -0.00957     0.00397     -0.00426    -0.01490
mean/std                              0.47152      0.01504     0.49312     0.44299
mean/max                              1.59942      0.07728     1.70830     1.46360
mean/min                              -1.73354     0.02159     -1.69608    -1.77771
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 1, 8, 5, 0, 9, 4, 7, 2, 3]
replay_buffer._size: [8700 8700 8700 8700 8700 8700 8700 8700 8700 8700]
2023-08-12 11:46:56,177 MainThread INFO: EPOCH:36
2023-08-12 11:46:56,178 MainThread INFO: Time Consumed:9.627901792526245s
2023-08-12 11:46:56,178 MainThread INFO: Total Frames:85500s
  0%|          | 37/10000 [05:35<25:38:45,  9.27s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               978.26767
Train_Epoch_Reward                    11253.24321
Running_Training_Average_Rewards      818.23415
Explore_Time                          0.00480
Train___Time                          9.61796
Eval____Time                          0.00443
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.96299
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.89319
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.86151
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.36509
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.73369
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13759
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.89757
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10033.87131
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.18177
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.16124
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.29703      1.42607     12.54945    5.72499
alpha_0                               0.47099      0.00120     0.47313     0.46951
alpha_1                               0.33446      0.00290     0.33945     0.32951
alpha_2                               0.33443      0.00290     0.33942     0.32949
alpha_3                               0.33445      0.00290     0.33943     0.32950
alpha_4                               0.33444      0.00290     0.33943     0.32950
alpha_5                               0.33447      0.00290     0.33946     0.32952
alpha_6                               0.33445      0.00290     0.33944     0.32950
alpha_7                               0.33444      0.00290     0.33943     0.32950
alpha_8                               0.33445      0.00290     0.33944     0.32950
alpha_9                               0.33445      0.00290     0.33944     0.32951
Alpha_loss                            -6.58214     0.05451     -6.47318    -6.69026
Training/policy_loss                  -145.94163   1.22161     -143.28838  -148.27075
Training/qf1_loss                     2698.82544   1137.05313  6434.34961  840.81018
Training/qf2_loss                     2698.37318   1136.84333  6432.70264  840.72211
Training/pf_norm                      0.23195      0.06667     0.46779     0.11580
Training/qf1_norm                     1078.56882   750.79096   4267.79785  178.08899
Training/qf2_norm                     1080.52043   752.72419   4277.19385  177.39960
log_std/mean                          -0.17670     0.00320     -0.16945    -0.18271
log_std/std                           0.13148      0.00920     0.14730     0.10869
log_std/max                           -0.11693     0.00162     -0.11313    -0.12177
log_std/min                           -0.63148     0.02823     -0.58364    -0.69328
log_probs/mean                        -1.98857     0.06498     -1.88671    -2.20914
log_probs/std                         2.36592      0.18283     2.66555     1.75547
log_probs/max                         8.51212      0.62717     9.40679     6.53857
log_probs/min                         -5.24910     0.91535     -3.85647    -8.70410
mean/mean                             -0.00871     0.00217     -0.00572    -0.01170
mean/std                              0.52182      0.02277     0.54522     0.45117
mean/max                              1.75818      0.08373     1.84700     1.50382
mean/min                              -1.85228     0.06974     -1.73550    -1.99145
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 3, 0, 6, 5, 7, 8, 4, 1, 9]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
2023-08-12 11:47:05,841 MainThread INFO: EPOCH:37
2023-08-12 11:47:05,842 MainThread INFO: Time Consumed:9.497398138046265s
2023-08-12 11:47:05,842 MainThread INFO: Total Frames:87000s
  0%|          | 38/10000 [05:45<25:58:29,  9.39s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               902.30094
Train_Epoch_Reward                    11330.35720
Running_Training_Average_Rewards      946.11992
Explore_Time                          0.00342
Train___Time                          9.48970
Eval____Time                          0.00357
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.71503
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.33479
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40010
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.15580
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.06310
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.40527
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.12142
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9268.83233
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.97341
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.65405
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.11933      1.49713     13.74882    5.15593
alpha_0                               0.47582      0.00140     0.47781     0.47318
alpha_1                               0.32457      0.00281     0.32941     0.31977
alpha_2                               0.32455      0.00281     0.32939     0.31975
alpha_3                               0.32456      0.00281     0.32940     0.31977
alpha_4                               0.32455      0.00281     0.32940     0.31976
alpha_5                               0.32458      0.00281     0.32943     0.31979
alpha_6                               0.32456      0.00281     0.32940     0.31976
alpha_7                               0.32455      0.00281     0.32940     0.31976
alpha_8                               0.32456      0.00281     0.32940     0.31976
alpha_9                               0.32457      0.00281     0.32941     0.31977
Alpha_loss                            -6.75722     0.07536     -6.62566    -6.90429
Training/policy_loss                  -149.74151   0.98483     -147.64903  -152.54961
Training/qf1_loss                     2460.07494   1078.85877  6655.78271  730.91992
Training/qf2_loss                     2459.78945   1078.69529  6654.71826  731.72388
Training/pf_norm                      0.19661      0.06375     0.42128     0.08847
Training/qf1_norm                     1124.66842   880.43675   5313.39795  158.76764
Training/qf2_norm                     1126.89988   882.70464   5327.43359  158.20734
log_std/mean                          -0.17727     0.00227     -0.17386    -0.18127
log_std/std                           0.12619      0.00631     0.13562     0.11831
log_std/max                           -0.12101     0.00168     -0.11775    -0.12484
log_std/min                           -0.60617     0.02209     -0.56295    -0.64580
log_probs/mean                        -1.97885     0.03860     -1.91054    -2.06889
log_probs/std                         2.39147      0.10793     2.58999     2.14244
log_probs/max                         8.66778      0.34507     9.33851     7.75777
log_probs/min                         -5.05973     0.94549     -3.77153    -11.41166
mean/mean                             -0.01003     0.00153     -0.00775    -0.01234
mean/std                              0.52733      0.01213     0.54743     0.50509
mean/max                              1.77616      0.03372     1.84714     1.71249
mean/min                              -1.79459     0.03952     -1.71857    -1.87278
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 9, 6, 3, 1, 2, 4, 5, 8, 0]
replay_buffer._size: [9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]
2023-08-12 11:47:15,346 MainThread INFO: EPOCH:38
2023-08-12 11:47:15,346 MainThread INFO: Time Consumed:9.318869590759277s
2023-08-12 11:47:15,346 MainThread INFO: Total Frames:88500s
  0%|          | 39/10000 [05:54<26:07:33,  9.44s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               765.94995
Train_Epoch_Reward                    12044.15302
Running_Training_Average_Rewards      1154.25845
Explore_Time                          0.00516
Train___Time                          9.30884
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.49862
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.72025
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.35123
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.44352
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.09755
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.78466
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.44837
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7910.24965
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.22794
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.17799
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.23390      1.37089     11.95176    5.65083
alpha_0                               0.48094      0.00201     0.48409     0.47784
alpha_1                               0.31498      0.00273     0.31968     0.31032
alpha_2                               0.31495      0.00273     0.31966     0.31030
alpha_3                               0.31497      0.00273     0.31967     0.31032
alpha_4                               0.31497      0.00273     0.31966     0.31031
alpha_5                               0.31499      0.00273     0.31969     0.31034
alpha_6                               0.31497      0.00273     0.31967     0.31031
alpha_7                               0.31496      0.00273     0.31966     0.31031
alpha_8                               0.31497      0.00273     0.31967     0.31031
alpha_9                               0.31498      0.00273     0.31968     0.31033
Alpha_loss                            -6.92033     0.07108     -6.79896    -7.11226
Training/policy_loss                  -153.93503   1.32756     -151.23199  -156.45695
Training/qf1_loss                     2570.66734   1047.28179  5743.21240  983.48773
Training/qf2_loss                     2570.49527   1047.16498  5742.45850  983.70331
Training/pf_norm                      0.19313      0.06390     0.43334     0.05533
Training/qf1_norm                     1065.18103   763.38383   3716.44678  168.59729
Training/qf2_norm                     1067.08795   765.70108   3724.80835  168.50414
log_std/mean                          -0.17874     0.00209     -0.17457    -0.18213
log_std/std                           0.13058      0.00578     0.13789     0.11924
log_std/max                           -0.12103     0.00186     -0.11736    -0.12504
log_std/min                           -0.61995     0.02580     -0.57157    -0.65738
log_probs/mean                        -1.95195     0.04163     -1.83997    -2.08700
log_probs/std                         2.47056      0.11222     2.74041     2.16033
log_probs/max                         8.83017      0.38802     9.63373     7.99916
log_probs/min                         -5.19406     1.04501     -4.08144    -9.75921
mean/mean                             -0.01121     0.00195     -0.00768    -0.01415
mean/std                              0.53786      0.01331     0.55460     0.50545
mean/max                              1.84218      0.05205     1.91376     1.74699
mean/min                              -1.84269     0.04222     -1.73264    -1.90613
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 1, 6, 2, 7, 0, 9, 4, 5, 8]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
2023-08-12 11:47:24,252 MainThread INFO: EPOCH:39
2023-08-12 11:47:24,252 MainThread INFO: Time Consumed:8.73497724533081s
2023-08-12 11:47:24,253 MainThread INFO: Total Frames:90000s
  0%|          | 40/10000 [06:03<25:40:11,  9.28s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               810.02721
Train_Epoch_Reward                    10274.29518
Running_Training_Average_Rewards      1121.62685
Explore_Time                          0.00600
Train___Time                          8.72386
Eval____Time                          0.00438
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.53839
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.18926
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.29438
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.50736
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.73533
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.27965
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.75539
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8332.40656
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.77985
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.05483
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.97667      1.40875     11.35260    4.82175
alpha_0                               0.48437      0.00010     0.48452     0.48412
alpha_1                               0.30567      0.00265     0.31023     0.30115
alpha_2                               0.30564      0.00265     0.31020     0.30113
alpha_3                               0.30566      0.00265     0.31022     0.30114
alpha_4                               0.30566      0.00265     0.31022     0.30114
alpha_5                               0.30569      0.00265     0.31025     0.30117
alpha_6                               0.30566      0.00265     0.31022     0.30114
alpha_7                               0.30565      0.00265     0.31021     0.30114
alpha_8                               0.30566      0.00265     0.31022     0.30114
alpha_9                               0.30568      0.00264     0.31023     0.30117
Alpha_loss                            -7.18419     0.06523     -7.06144    -7.31598
Training/policy_loss                  -157.08589   1.13875     -154.27521  -159.58391
Training/qf1_loss                     2428.48287   1080.19039  5755.16504  871.26727
Training/qf2_loss                     2428.29244   1079.96065  5754.48682  871.05585
Training/pf_norm                      0.20888      0.06207     0.37745     0.09325
Training/qf1_norm                     1160.06350   766.15839   3957.94946  123.94741
Training/qf2_norm                     1161.82365   767.94325   3966.33716  123.34589
log_std/mean                          -0.17390     0.00272     -0.16748    -0.17753
log_std/std                           0.12005      0.00445     0.12680     0.11175
log_std/max                           -0.12036     0.00187     -0.11373    -0.12274
log_std/min                           -0.59871     0.02482     -0.54372    -0.62150
log_probs/mean                        -2.06510     0.03006     -2.00740    -2.13615
log_probs/std                         2.13949      0.07450     2.26955     1.92914
log_probs/max                         7.74502      0.26064     8.23315     7.06283
log_probs/min                         -5.33864     1.12114     -3.84317    -9.20293
mean/mean                             -0.00394     0.00250     0.00006     -0.00950
mean/std                              0.49146      0.00703     0.50314     0.47548
mean/max                              1.70459      0.02696     1.78290     1.65178
mean/min                              -1.73183     0.03963     -1.65107    -1.79033
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 4, 7, 3, 0, 6, 1, 9, 2, 8]
replay_buffer._size: [9300 9300 9300 9300 9300 9300 9300 9300 9300 9300]
2023-08-12 11:47:33,937 MainThread INFO: EPOCH:40
2023-08-12 11:47:33,938 MainThread INFO: Time Consumed:9.506882190704346s
2023-08-12 11:47:33,938 MainThread INFO: Total Frames:91500s
  0%|          | 41/10000 [06:13<25:58:26,  9.39s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               814.70533
Train_Epoch_Reward                    8507.20832
Running_Training_Average_Rewards      1027.52188
Explore_Time                          0.00399
Train___Time                          9.49926
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.03093
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.91639
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.59407
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.35798
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.26331
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.52110
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.71073
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8388.39214
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.67527
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.26906
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.11211     1.39826     11.21375    4.88607
alpha_0                               0.48344     0.00064     0.48418     0.48210
alpha_1                               0.29664     0.00257     0.30106     0.29225
alpha_2                               0.29661     0.00257     0.30104     0.29223
alpha_3                               0.29663     0.00257     0.30105     0.29224
alpha_4                               0.29663     0.00257     0.30105     0.29224
alpha_5                               0.29665     0.00257     0.30108     0.29226
alpha_6                               0.29662     0.00257     0.30105     0.29224
alpha_7                               0.29662     0.00257     0.30105     0.29224
alpha_8                               0.29662     0.00257     0.30105     0.29224
alpha_9                               0.29666     0.00256     0.30108     0.29229
Alpha_loss                            -7.38402    0.06917     -7.24521    -7.49360
Training/policy_loss                  -161.14303  1.08641     -158.48253  -163.70872
Training/qf1_loss                     2596.56714  1137.02956  6036.89551  683.60614
Training/qf2_loss                     2596.34444  1136.84783  6034.92822  683.50262
Training/pf_norm                      0.24827     0.08258     0.47670     0.06591
Training/qf1_norm                     1154.31731  697.09903   3435.90137  161.66345
Training/qf2_norm                     1156.37283  698.93534   3443.65503  160.88284
log_std/mean                          -0.17031    0.00244     -0.16568    -0.17445
log_std/std                           0.12028     0.00555     0.12950     0.10964
log_std/max                           -0.11923    0.00536     -0.11088    -0.12666
log_std/min                           -0.61521    0.01953     -0.58358    -0.65742
log_probs/mean                        -2.09033    0.03598     -2.00986    -2.16595
log_probs/std                         2.06560     0.09869     2.31969     1.85208
log_probs/max                         7.47679     0.38196     8.20876     6.50742
log_probs/min                         -5.14600    1.08053     -3.91423    -11.83222
mean/mean                             -0.01074    0.00918     0.00006     -0.03059
mean/std                              0.48547     0.01155     0.50420     0.46387
mean/max                              1.79230     0.04169     1.84812     1.71334
mean/min                              -1.78042    0.03827     -1.71535    -1.83673
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 9, 3, 4, 0, 8, 7, 1, 2, 5]
replay_buffer._size: [9450 9450 9450 9450 9450 9450 9450 9450 9450 9450]
2023-08-12 11:47:43,055 MainThread INFO: EPOCH:41
2023-08-12 11:47:43,055 MainThread INFO: Time Consumed:8.916822910308838s
2023-08-12 11:47:43,055 MainThread INFO: Total Frames:93000s
  0%|          | 42/10000 [06:22<25:43:37,  9.30s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               802.03384
Train_Epoch_Reward                    9827.09382
Running_Training_Average_Rewards      953.61991
Explore_Time                          0.00434
Train___Time                          8.90737
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.19697
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.25565
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.64150
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.36068
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.98937
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.78517
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.34560
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8268.02075
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.08943
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.01795
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.82168     1.41935     11.27833    4.46316
alpha_0                               0.47842     0.00310     0.48208     0.47192
alpha_1                               0.28787     0.00249     0.29217     0.28361
alpha_2                               0.28785     0.00249     0.29214     0.28359
alpha_3                               0.28786     0.00249     0.29216     0.28361
alpha_4                               0.28786     0.00249     0.29215     0.28360
alpha_5                               0.28788     0.00249     0.29218     0.28363
alpha_6                               0.28786     0.00249     0.29215     0.28360
alpha_7                               0.28786     0.00249     0.29215     0.28360
alpha_8                               0.28785     0.00249     0.29215     0.28360
alpha_9                               0.28792     0.00249     0.29220     0.28368
Alpha_loss                            -7.66865    0.10933     -7.47650    -7.82350
Training/policy_loss                  -164.06206  1.19779     -161.52863  -167.09747
Training/qf1_loss                     2496.38119  1207.95833  7536.36475  799.65253
Training/qf2_loss                     2496.26480  1207.88840  7536.01416  799.67383
Training/pf_norm                      0.29699     0.14620     0.59643     0.09519
Training/qf1_norm                     1173.55789  773.48936   3760.29736  203.84183
Training/qf2_norm                     1175.66749  775.31946   3765.94897  205.07582
log_std/mean                          -0.16067    0.00250     -0.15734    -0.16683
log_std/std                           0.10687     0.01290     0.12522     0.09001
log_std/max                           -0.04108    0.06953     0.07065     -0.12277
log_std/min                           -0.60011    0.01697     -0.57244    -0.64333
log_probs/mean                        -2.22895    0.08072     -2.08829    -2.37338
log_probs/std                         1.65745     0.22915     2.05849     1.30423
log_probs/max                         5.69805     1.11382     7.53451     4.11889
log_probs/min                         -5.58096    1.13295     -4.07021    -10.36829
mean/mean                             -0.03326    0.00625     -0.02378    -0.04212
mean/std                              0.42700     0.03385     0.48195     0.38413
mean/max                              1.75467     0.06041     1.83374     1.67082
mean/min                              -1.64362    0.12216     -1.47122    -1.80807
------------------------------------  ----------  ----------  ----------  ----------
sample: [8, 5, 3, 9, 7, 2, 4, 1, 6, 0]
replay_buffer._size: [9600 9600 9600 9600 9600 9600 9600 9600 9600 9600]
2023-08-12 11:47:52,026 MainThread INFO: EPOCH:42
2023-08-12 11:47:52,026 MainThread INFO: Time Consumed:8.771559238433838s
2023-08-12 11:47:52,026 MainThread INFO: Total Frames:94500s
  0%|          | 43/10000 [06:31<25:28:17,  9.21s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1005.69768
Train_Epoch_Reward                    8410.84320
Running_Training_Average_Rewards      891.50484
Explore_Time                          0.00722
Train___Time                          8.75850
Eval____Time                          0.00502
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.47167
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.17923
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.59282
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.01487
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.58749
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.63417
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.70088
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10298.37591
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.67444
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.54356
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.95038      1.27892    10.90286    4.92416
alpha_0                               0.46552      0.00368    0.47178     0.45953
alpha_1                               0.27936      0.00242    0.28353     0.27523
alpha_2                               0.27934      0.00242    0.28351     0.27521
alpha_3                               0.27936      0.00242    0.28352     0.27523
alpha_4                               0.27935      0.00242    0.28352     0.27522
alpha_5                               0.27937      0.00242    0.28354     0.27525
alpha_6                               0.27935      0.00242    0.28352     0.27522
alpha_7                               0.27935      0.00242    0.28352     0.27522
alpha_8                               0.27935      0.00242    0.28351     0.27522
alpha_9                               0.27944      0.00241    0.28359     0.27533
Alpha_loss                            -7.86023     0.05412    -7.74211    -7.94322
Training/policy_loss                  -167.77488   1.45892    -164.34488  -171.14694
Training/qf1_loss                     2505.02962   911.28077  4455.10156  810.21307
Training/qf2_loss                     2504.87053   911.18438  4455.05420  810.46234
Training/pf_norm                      0.26341      0.07490    0.45218     0.13607
Training/qf1_norm                     1099.92188   686.51858  3069.78760  202.88911
Training/qf2_norm                     1101.67481   688.18431  3077.18774  202.34163
log_std/mean                          -0.16411     0.00225    -0.16044    -0.16775
log_std/std                           0.10683      0.00533    0.11305     0.09784
log_std/max                           -0.11951     0.00288    -0.10998    -0.12372
log_std/min                           -0.61976     0.02768    -0.57831    -0.65747
log_probs/mean                        -2.23853     0.03412    -2.15394    -2.30695
log_probs/std                         1.61586      0.09218    1.85949     1.45147
log_probs/max                         5.27376      0.38775    6.23668     4.47718
log_probs/min                         -5.44749     0.97993    -3.97925    -7.93990
mean/mean                             -0.03236     0.00554    -0.02434    -0.04337
mean/std                              0.42445      0.01310    0.44500     0.40363
mean/max                              1.81203      0.04394    1.87809     1.73539
mean/min                              -1.64812     0.08574    -1.54873    -1.79263
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 6, 4, 1, 3, 8, 7, 5, 2, 9]
replay_buffer._size: [9750 9750 9750 9750 9750 9750 9750 9750 9750 9750]
2023-08-12 11:48:01,935 MainThread INFO: EPOCH:43
2023-08-12 11:48:01,935 MainThread INFO: Time Consumed:9.709736824035645s
2023-08-12 11:48:01,935 MainThread INFO: Total Frames:96000s
  0%|          | 44/10000 [06:41<26:01:37,  9.41s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1317.40696
Train_Epoch_Reward                    11540.52129
Running_Training_Average_Rewards      992.61528
Explore_Time                          0.00980
Train___Time                          9.69529
Eval____Time                          0.00393
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.16154
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.46709
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.84583
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.85854
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.91644
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.89906
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.38414
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13419.26520
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.19293
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.46999
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.08535      1.21822    11.42861    4.58340
alpha_0                               0.45482      0.00266    0.45944     0.45063
alpha_1                               0.27110      0.00235    0.27515     0.26709
alpha_2                               0.27108      0.00235    0.27513     0.26708
alpha_3                               0.27110      0.00235    0.27515     0.26710
alpha_4                               0.27109      0.00235    0.27514     0.26709
alpha_5                               0.27112      0.00235    0.27517     0.26711
alpha_6                               0.27109      0.00235    0.27514     0.26709
alpha_7                               0.27109      0.00235    0.27514     0.26709
alpha_8                               0.27109      0.00235    0.27514     0.26709
alpha_9                               0.27121      0.00235    0.27525     0.26720
Alpha_loss                            -8.01286     0.04543    -7.89937    -8.08510
Training/policy_loss                  -171.48793   1.20279    -169.29012  -174.17226
Training/qf1_loss                     2533.63253   960.81187  5833.88086  738.25854
Training/qf2_loss                     2533.50773   960.69103  5832.60156  738.49603
Training/pf_norm                      0.45662      0.17534    0.73415     0.12011
Training/qf1_norm                     1033.75421   726.41487  3440.60645  188.92082
Training/qf2_norm                     1035.50644   728.21273  3447.75830  187.95029
log_std/mean                          -0.16439     0.00320    -0.15988    -0.17051
log_std/std                           0.10981      0.00259    0.11558     0.10386
log_std/max                           -0.10797     0.01521    -0.07559    -0.12335
log_std/min                           -0.60249     0.02556    -0.55670    -0.64429
log_probs/mean                        -2.19357     0.03014    -2.11588    -2.26160
log_probs/std                         1.75821      0.08317    1.93856     1.55628
log_probs/max                         5.91412      0.44801    6.72448     4.79201
log_probs/min                         -5.59204     1.12142    -4.10503    -8.93311
mean/mean                             -0.01674     0.01865    0.02081     -0.04303
mean/std                              0.44400      0.01138    0.46153     0.42091
mean/max                              1.81585      0.07577    1.93031     1.67832
mean/min                              -1.72460     0.03049    -1.65374    -1.77114
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 3, 1, 0, 9, 7, 2, 5, 8, 6]
replay_buffer._size: [9900 9900 9900 9900 9900 9900 9900 9900 9900 9900]
2023-08-12 11:48:11,263 MainThread INFO: EPOCH:44
2023-08-12 11:48:11,263 MainThread INFO: Time Consumed:9.16364049911499s
2023-08-12 11:48:11,263 MainThread INFO: Total Frames:97500s
  0%|          | 45/10000 [06:50<25:57:24,  9.39s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               960.73320
Train_Epoch_Reward                    14362.65413
Running_Training_Average_Rewards      1143.80062
Explore_Time                          0.00632
Train___Time                          9.15282
Eval____Time                          0.00349
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.26307
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.93064
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.50405
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.07554
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.93661
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.44893
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.19376
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9848.67595
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.39140
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.59991
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.92688      1.28541     10.98169    5.59101
alpha_0                               0.44771      0.00203     0.45056     0.44346
alpha_1                               0.26309      0.00228     0.26701     0.25920
alpha_2                               0.26307      0.00228     0.26700     0.25918
alpha_3                               0.26309      0.00228     0.26702     0.25920
alpha_4                               0.26308      0.00228     0.26701     0.25920
alpha_5                               0.26311      0.00228     0.26703     0.25922
alpha_6                               0.26308      0.00228     0.26701     0.25919
alpha_7                               0.26308      0.00228     0.26701     0.25920
alpha_8                               0.26308      0.00228     0.26701     0.25919
alpha_9                               0.26320      0.00227     0.26712     0.25932
Alpha_loss                            -8.17692     0.09248     -8.01717    -8.32505
Training/policy_loss                  -174.64051   1.06871     -172.20477  -176.83238
Training/qf1_loss                     2493.14853   1041.98660  6572.19873  1053.66785
Training/qf2_loss                     2493.00324   1041.86116  6572.01123  1053.35559
Training/pf_norm                      0.42095      0.14456     0.70946     0.14088
Training/qf1_norm                     1148.80983   710.97278   3517.46436  178.64165
Training/qf2_norm                     1150.65330   712.87381   3528.25732  177.76561
log_std/mean                          -0.16414     0.00506     -0.15831    -0.17249
log_std/std                           0.11871      0.00661     0.13091     0.11023
log_std/max                           -0.06459     0.04987     0.01798     -0.12164
log_std/min                           -0.63608     0.04638     -0.57818    -0.71485
log_probs/mean                        -2.17038     0.05354     -2.04953    -2.26445
log_probs/std                         1.81860      0.15148     2.15953     1.56658
log_probs/max                         6.37794      0.71011     7.60615     4.85799
log_probs/min                         -5.66975     1.47180     -3.82626    -14.94055
mean/mean                             0.04382      0.01302     0.06445     0.02153
mean/std                              0.44989      0.02152     0.48673     0.42133
mean/max                              1.80357      0.06925     1.94698     1.73073
mean/min                              -1.71590     0.08463     -1.59884    -1.85797
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 8, 5, 1, 6, 0, 4, 9, 7, 2]
replay_buffer._size: [10050 10050 10050 10050 10050 10050 10050 10050 10050 10050]
2023-08-12 11:48:20,359 MainThread INFO: EPOCH:45
2023-08-12 11:48:20,359 MainThread INFO: Time Consumed:8.9211905002594s
2023-08-12 11:48:20,360 MainThread INFO: Total Frames:99000s
  0%|          | 46/10000 [06:59<25:42:41,  9.30s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               942.35439
Train_Epoch_Reward                    12730.98962
Running_Training_Average_Rewards      1287.80550
Explore_Time                          0.00902
Train___Time                          8.90705
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.20952
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.40145
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.41624
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.28626
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -25.64917
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -26.82647
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.01818
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9680.82511
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.09738
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.37656
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.16537      1.23619    11.14512    5.04930
alpha_0                               0.43803      0.00305    0.44336     0.43337
alpha_1                               0.25531      0.00221    0.25912     0.25153
alpha_2                               0.25530      0.00221    0.25911     0.25153
alpha_3                               0.25531      0.00221    0.25912     0.25154
alpha_4                               0.25531      0.00221    0.25912     0.25154
alpha_5                               0.25534      0.00221    0.25915     0.25157
alpha_6                               0.25531      0.00221    0.25911     0.25154
alpha_7                               0.25531      0.00221    0.25912     0.25153
alpha_8                               0.25530      0.00221    0.25911     0.25153
alpha_9                               0.25544      0.00221    0.25925     0.25167
Alpha_loss                            -8.38792     0.04402    -8.27297    -8.48096
Training/policy_loss                  -178.34701   1.21547    -175.59355  -181.75444
Training/qf1_loss                     2597.05707   970.02935  5003.61475  978.16260
Training/qf2_loss                     2597.04384   969.87535  5002.71436  977.95013
Training/pf_norm                      0.59492      0.22142    0.88419     0.06870
Training/qf1_norm                     1120.71905   670.75989  3191.60034  161.81937
Training/qf2_norm                     1122.49690   672.24767  3196.77783  161.25331
log_std/mean                          -0.16316     0.00387    -0.15903    -0.17485
log_std/std                           0.11117      0.00565    0.12371     0.10097
log_std/max                           -0.08812     0.03469    -0.02026    -0.11937
log_std/min                           -0.60694     0.02276    -0.56724    -0.64668
log_probs/mean                        -2.20284     0.04429    -2.06148    -2.29008
log_probs/std                         1.72899      0.11926    2.14174     1.50100
log_probs/max                         5.92725      0.52446    7.48198     5.13927
log_probs/min                         -5.43069     0.95411    -3.97935    -9.31882
mean/mean                             0.04415      0.01556    0.06443     0.01366
mean/std                              0.43555      0.01626    0.48837     0.41475
mean/max                              1.79974      0.03985    1.90959     1.72595
mean/min                              -1.57350     0.03893    -1.52218    -1.65126
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 4, 0, 9, 3, 8, 1, 2, 7, 5]
replay_buffer._size: [10200 10200 10200 10200 10200 10200 10200 10200 10200 10200]
2023-08-12 11:48:29,843 MainThread INFO: EPOCH:46
2023-08-12 11:48:29,844 MainThread INFO: Time Consumed:9.309860706329346s
2023-08-12 11:48:29,844 MainThread INFO: Total Frames:100500s
  0%|          | 47/10000 [07:08<25:51:45,  9.35s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               839.24348
Train_Epoch_Reward                    11220.24433
Running_Training_Average_Rewards      1277.12960
Explore_Time                          0.00983
Train___Time                          9.29470
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.00737
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.68735
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.46892
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.49015
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.60130
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.07215
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.88071
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8642.18595
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -21.71516
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.82806
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.10209      1.44519     11.53237    4.39710
alpha_0                               0.43367      0.00031     0.43418     0.43313
alpha_1                               0.24776      0.00214     0.25146     0.24410
alpha_2                               0.24776      0.00214     0.25145     0.24410
alpha_3                               0.24777      0.00215     0.25146     0.24411
alpha_4                               0.24777      0.00215     0.25147     0.24411
alpha_5                               0.24779      0.00215     0.25149     0.24413
alpha_6                               0.24776      0.00215     0.25146     0.24410
alpha_7                               0.24776      0.00215     0.25146     0.24410
alpha_8                               0.24776      0.00215     0.25146     0.24410
alpha_9                               0.24789      0.00215     0.25159     0.24422
Alpha_loss                            -8.44301     0.07985     -8.29070    -8.60823
Training/policy_loss                  -182.06991   1.30620     -179.55965  -185.17160
Training/qf1_loss                     2548.33001   1070.94033  6497.58740  854.65588
Training/qf2_loss                     2548.28257   1070.73224  6495.77783  854.58148
Training/pf_norm                      0.27029      0.12856     0.77279     0.08182
Training/qf1_norm                     1296.60442   777.73439   3617.93652  212.85202
Training/qf2_norm                     1298.55204   779.64947   3623.31348  212.83084
log_std/mean                          -0.17486     0.00273     -0.17032    -0.18054
log_std/std                           0.12565      0.00866     0.14156     0.10986
log_std/max                           -0.12055     0.00359     -0.11407    -0.12579
log_std/min                           -0.64515     0.04412     -0.57329    -0.72746
log_probs/mean                        -2.04854     0.04728     -1.95258    -2.15885
log_probs/std                         2.18952      0.12930     2.46599     1.88486
log_probs/max                         7.93531      0.39845     8.83628     6.97716
log_probs/min                         -5.28733     1.04285     -4.02225    -10.60047
mean/mean                             0.00124      0.00412     0.01314     -0.00417
mean/std                              0.49934      0.01538     0.52566     0.47389
mean/max                              1.85599      0.07095     1.99369     1.75742
mean/min                              -1.58574     0.06922     -1.48545    -1.72392
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 0, 4, 7, 8, 9, 3, 6, 2, 1]
replay_buffer._size: [10350 10350 10350 10350 10350 10350 10350 10350 10350 10350]
2023-08-12 11:48:39,499 MainThread INFO: EPOCH:47
2023-08-12 11:48:39,499 MainThread INFO: Time Consumed:9.451013326644897s
2023-08-12 11:48:39,499 MainThread INFO: Total Frames:102000s
  0%|          | 48/10000 [07:18<26:08:31,  9.46s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               763.06662
Train_Epoch_Reward                    9944.06626
Running_Training_Average_Rewards      1129.84334
Explore_Time                          0.00897
Train___Time                          9.43686
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.56145
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.79400
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.19440
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34793
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31783
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.86487
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.42674
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7885.89407
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.50653
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.21412
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.91086     1.33751    11.19300    4.95182
alpha_0                               0.43224     0.00147    0.43383     0.42844
alpha_1                               0.24044     0.00208    0.24403     0.23689
alpha_2                               0.24043     0.00208    0.24402     0.23688
alpha_3                               0.24045     0.00208    0.24403     0.23690
alpha_4                               0.24045     0.00208    0.24403     0.23690
alpha_5                               0.24047     0.00208    0.24406     0.23692
alpha_6                               0.24044     0.00208    0.24403     0.23689
alpha_7                               0.24044     0.00208    0.24403     0.23689
alpha_8                               0.24044     0.00208    0.24403     0.23688
alpha_9                               0.24057     0.00208    0.24415     0.23702
Alpha_loss                            -8.70588    0.11196    -8.53669    -8.90409
Training/policy_loss                  -184.95686  1.39266    -181.43066  -187.93152
Training/qf1_loss                     2425.70580  896.29194  4699.88770  909.20276
Training/qf2_loss                     2425.70924  896.19594  4699.76562  909.78821
Training/pf_norm                      0.29472     0.08344    0.47733     0.15322
Training/qf1_norm                     1185.80692  846.96123  3806.37402  177.15295
Training/qf2_norm                     1187.54499  849.04293  3813.08716  177.34126
log_std/mean                          -0.16775    0.00512    -0.15928    -0.17387
log_std/std                           0.11015     0.00687    0.11882     0.09861
log_std/max                           -0.11147    0.01629    -0.07307    -0.12323
log_std/min                           -0.61085    0.01116    -0.58187    -0.63327
log_probs/mean                        -2.14654    0.07437    -2.04394    -2.29620
log_probs/std                         1.90397     0.21157    2.17864     1.51312
log_probs/max                         6.96834     0.72332    7.89548     5.35237
log_probs/min                         -5.45621    0.95224    -4.05341    -8.32280
mean/mean                             -0.00386    0.00219    -0.00151    -0.00885
mean/std                              0.46198     0.02710    0.48975     0.41547
mean/max                              1.78400     0.03266    1.83107     1.72915
mean/min                              -1.64095    0.05169    -1.53483    -1.70906
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 2, 3, 6, 0, 4, 5, 1, 7, 8]
replay_buffer._size: [10500 10500 10500 10500 10500 10500 10500 10500 10500 10500]
2023-08-12 11:48:48,738 MainThread INFO: EPOCH:48
2023-08-12 11:48:48,738 MainThread INFO: Time Consumed:9.04892611503601s
2023-08-12 11:48:48,738 MainThread INFO: Total Frames:103500s
  0%|          | 49/10000 [07:27<25:57:30,  9.39s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               849.97683
Train_Epoch_Reward                    8122.88555
Running_Training_Average_Rewards      976.23987
Explore_Time                          0.00637
Train___Time                          9.03772
Eval____Time                          0.00414
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.90668
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.59074
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.30557
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62493
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.32062
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.07913
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.46852
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8734.74582
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.24354
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.43778
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.18609     1.45616     12.73256    5.04950
alpha_0                               0.42397     0.00182     0.42830     0.42213
alpha_1                               0.23334     0.00202     0.23682     0.22989
alpha_2                               0.23333     0.00202     0.23681     0.22988
alpha_3                               0.23334     0.00202     0.23683     0.22990
alpha_4                               0.23335     0.00202     0.23683     0.22991
alpha_5                               0.23336     0.00202     0.23684     0.22992
alpha_6                               0.23334     0.00202     0.23682     0.22989
alpha_7                               0.23334     0.00202     0.23682     0.22989
alpha_8                               0.23333     0.00202     0.23681     0.22988
alpha_9                               0.23347     0.00202     0.23695     0.23003
Alpha_loss                            -8.87382    0.03678     -8.76565    -8.96270
Training/policy_loss                  -189.17568  0.99716     -186.34010  -191.25211
Training/qf1_loss                     2552.53367  1157.72457  6055.43457  761.60791
Training/qf2_loss                     2552.62978  1157.59016  6054.75928  762.00580
Training/pf_norm                      0.39625     0.22573     0.94051     0.13345
Training/qf1_norm                     1333.07152  886.90535   5284.03564  172.72020
Training/qf2_norm                     1335.22934  889.54205   5294.35791  172.54768
log_std/mean                          -0.16899    0.00299     -0.16314    -0.17402
log_std/std                           0.12195     0.01135     0.13999     0.10447
log_std/max                           -0.11717    0.00553     -0.09355    -0.12627
log_std/min                           -0.70633    0.04775     -0.61007    -0.79703
log_probs/mean                        -2.13016    0.07026     -1.98300    -2.28325
log_probs/std                         1.93235     0.20243     2.34914     1.52551
log_probs/max                         6.95908     0.75798     8.39452     5.15755
log_probs/min                         -5.39081    1.09624     -3.81845    -11.96944
mean/mean                             0.00082     0.00981     0.01407     -0.01136
mean/std                              0.47106     0.02657     0.51266     0.42396
mean/max                              1.76662     0.08320     1.91807     1.61733
mean/min                              -1.94271    0.10787     -1.66304    -2.11240
------------------------------------  ----------  ----------  ----------  ----------
sample: [8, 3, 5, 7, 9, 1, 4, 0, 6, 2]
replay_buffer._size: [10650 10650 10650 10650 10650 10650 10650 10650 10650 10650]
2023-08-12 11:48:58,431 MainThread INFO: EPOCH:49
2023-08-12 11:48:58,431 MainThread INFO: Time Consumed:9.511085748672485s
2023-08-12 11:48:58,431 MainThread INFO: Total Frames:105000s
  0%|          | 50/10000 [07:37<26:12:26,  9.48s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1124.99205
Train_Epoch_Reward                    9237.25726
Running_Training_Average_Rewards      910.14030
Explore_Time                          0.00422
Train___Time                          9.50186
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.02091
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.18622
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.62166
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.08783
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.04722
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.71733
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.17189
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11495.56270
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.14060
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.64851
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.83560      1.63227     11.75585    4.80454
alpha_0                               0.42172      0.00013     0.42211     0.42157
alpha_1                               0.22644      0.00196     0.22982     0.22310
alpha_2                               0.22643      0.00196     0.22981     0.22309
alpha_3                               0.22645      0.00196     0.22983     0.22310
alpha_4                               0.22646      0.00196     0.22984     0.22312
alpha_5                               0.22647      0.00196     0.22985     0.22312
alpha_6                               0.22644      0.00196     0.22982     0.22310
alpha_7                               0.22644      0.00196     0.22982     0.22309
alpha_8                               0.22644      0.00196     0.22981     0.22309
alpha_9                               0.22657      0.00196     0.22996     0.22322
Alpha_loss                            -9.00209     0.05845     -8.89050    -9.12294
Training/policy_loss                  -191.73852   1.33912     -188.70972  -195.38225
Training/qf1_loss                     2496.20207   1213.02122  6200.63281  652.54608
Training/qf2_loss                     2496.32826   1212.91342  6198.87061  652.71564
Training/pf_norm                      0.23035      0.06812     0.38665     0.08403
Training/qf1_norm                     1480.39019   1031.20817  4606.02490  238.10336
Training/qf2_norm                     1482.97977   1033.65915  4617.60352  237.49170
log_std/mean                          -0.17253     0.00163     -0.16999    -0.17588
log_std/std                           0.12185      0.00278     0.12767     0.11722
log_std/max                           -0.11386     0.00174     -0.11157    -0.12061
log_std/min                           -0.61686     0.01996     -0.57886    -0.64891
log_probs/mean                        -2.06494     0.03014     -1.98674    -2.13996
log_probs/std                         2.14091      0.07728     2.32535     1.94371
log_probs/max                         7.67625      0.28535     8.30508     7.03797
log_probs/min                         -5.37202     0.96312     -3.89961    -9.21160
mean/mean                             -0.00610     0.00633     0.00714     -0.01409
mean/std                              0.49497      0.00745     0.51014     0.48476
mean/max                              1.61545      0.02986     1.66771     1.54363
mean/min                              -1.98183     0.04241     -1.90012    -2.03402
------------------------------------  -----------  ----------  ----------  ----------
start to update mask
sample: [3, 1, 7, 5, 4, 0, 8, 6, 9, 2]
replay_buffer._size: [10800 10800 10800 10800 10800 10800 10800 10800 10800 10800]
2023-08-12 11:49:08,529 MainThread INFO: EPOCH:50
2023-08-12 11:49:08,531 MainThread INFO: Time Consumed:8.225195407867432s
2023-08-12 11:49:08,531 MainThread INFO: Total Frames:106500s
  1%|          | 51/10000 [07:47<26:41:39,  9.66s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               719.18501
Train_Epoch_Reward                    12763.13255
Running_Training_Average_Rewards      1004.10918
Explore_Time                          0.00694
Train___Time                          8.21309
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.48328
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.03137
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.57486
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.05820
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.87139
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.88936
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.48081
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7460.70122
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.60571
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.85613
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.23110      1.53211     11.59901    4.68074
alpha_0                               0.40662      0.00845     0.42155     0.39382
alpha_1                               0.22034      0.00131     0.22303     0.21871
alpha_2                               0.22066      0.00102     0.22302     0.21972
alpha_3                               0.22043      0.00126     0.22304     0.21882
alpha_4                               0.22055      0.00113     0.22305     0.21940
alpha_5                               0.22053      0.00116     0.22305     0.21923
alpha_6                               0.22071      0.00098     0.22303     0.21984
alpha_7                               0.22045      0.00122     0.22303     0.21899
alpha_8                               0.22057      0.00109     0.22302     0.21948
alpha_9                               0.22073      0.00107     0.22316     0.21971
Alpha_loss                            -4.81230     3.41427     -0.15201    -9.68798
Training/policy_loss                  -20.82801    2.92147     -14.25179   -24.13933
Training/qf1_loss                     3007.76239   1214.81883  7209.35547  907.52325
Training/qf2_loss                     3144.11895   1221.41195  7491.79443  958.99103
Training/pf_norm                      0.39106      0.22899     0.94157     0.13643
Training/qf1_norm                     219.97886    79.55315    465.92236   106.73428
Training/qf2_norm                     356.93730    181.65351   887.29816   110.65848
log_std/mean                          -0.36563     0.14512     -0.08352    -0.53820
log_std/std                           0.06403      0.02959     0.09911     0.00355
log_std/max                           -0.20449     0.06529     -0.07590    -0.29041
log_std/min                           -0.49959     0.20795     -0.09067    -0.71753
log_probs/mean                        0.60625      2.32040     3.75491     -2.73656
log_probs/std                         1.85112      0.86639     2.74345     0.24602
log_probs/max                         4.80935      4.09460     9.61682     -1.99460
log_probs/min                         -6.89118     1.26243     -4.00917    -10.66596
mean/mean                             0.02647      0.10394     0.25358     -0.10327
mean/std                              0.94806      0.52098     1.52322     0.02941
mean/max                              1.24695      0.65050     1.94827     0.03359
mean/min                              -1.22805     0.70491     -0.03397    -1.95095
------------------------------------  -----------  ----------  ----------  ---------
sample: [7, 8, 9, 2, 0, 4, 1, 3, 6, 5]
replay_buffer._size: [10955 10955 10955 10955 10955 10955 10955 10954 10955 10954]
2023-08-12 11:49:17,699 MainThread INFO: EPOCH:51
2023-08-12 11:49:17,699 MainThread INFO: Time Consumed:8.9871187210083s
2023-08-12 11:49:17,699 MainThread INFO: Total Frames:108000s
  1%|          | 52/10000 [07:56<26:17:52,  9.52s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               641.24378
Train_Epoch_Reward                    7605.60249
Running_Training_Average_Rewards      986.86641
Explore_Time                          0.10519
Train___Time                          8.87629
Eval____Time                          0.00456
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.38864
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.71241
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.30977
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.04221
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.53619
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.70847
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.62719
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6674.87844
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.09611
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.01969
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.99711     1.46190     11.98065    5.21122
alpha_0                               0.38400     0.00557     0.39362     0.37467
alpha_1                               0.21826     0.00038     0.21870     0.21741
alpha_2                               0.22013     0.00023     0.22041     0.21962
alpha_3                               0.21772     0.00090     0.21881     0.21569
alpha_4                               0.21924     0.00018     0.21939     0.21871
alpha_5                               0.21884     0.00038     0.21923     0.21796
alpha_6                               0.22042     0.00023     0.22070     0.21987
alpha_7                               0.21839     0.00053     0.21898     0.21718
alpha_8                               0.21889     0.00059     0.21947     0.21752
alpha_9                               0.21926     0.00063     0.21978     0.21767
Alpha_loss                            -2.60727    1.96695     0.07347     -5.79412
Training/policy_loss                  -24.14888   0.55486     -23.38924   -25.50939
Training/qf1_loss                     2494.66624  1088.68390  6488.13574  878.73871
Training/qf2_loss                     2704.06349  1168.89497  6966.39697  904.87158
Training/pf_norm                      0.27183     0.09251     0.59439     0.09294
Training/qf1_norm                     198.54980   121.44305   634.32550   48.90567
Training/qf2_norm                     350.32354   123.83766   729.05151   123.84560
log_std/mean                          -0.44898    0.06185     -0.33907    -0.53452
log_std/std                           0.12180     0.02649     0.16349     0.07987
log_std/max                           -0.17469    0.07669     -0.07001    -0.28507
log_std/min                           -0.66380    0.03403     -0.57336    -0.71791
log_probs/mean                        2.14207     1.28973     3.90752     0.07642
log_probs/std                         2.43196     0.23023     2.77984     2.02434
log_probs/max                         7.38295     1.84220     9.84664     4.62001
log_probs/min                         -7.26922    1.22762     -5.20643    -11.14071
mean/mean                             -0.13659    0.05920     -0.04974    -0.20966
mean/std                              1.29875     0.19144     1.54302     0.98676
mean/max                              1.82446     0.13764     2.01473     1.60156
mean/min                              -1.83373    0.13006     -1.62714    -1.99644
------------------------------------  ----------  ----------  ----------  ---------
sample: [8, 6, 9, 1, 7, 4, 3, 5, 0, 2]
replay_buffer._size: [11100 11100 11100 11100 11100 11100 11100 11100 11100 11100]
2023-08-12 11:49:26,850 MainThread INFO: EPOCH:52
2023-08-12 11:49:26,850 MainThread INFO: Time Consumed:8.96135425567627s
2023-08-12 11:49:26,850 MainThread INFO: Total Frames:109500s
  1%|          | 53/10000 [08:06<25:58:21,  9.40s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               942.18570
Train_Epoch_Reward                    31200.94497
Running_Training_Average_Rewards      1718.98933
Explore_Time                          0.01117
Train___Time                          8.94471
Eval____Time                          0.00478
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.17300
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.97340
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.99752
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.46791
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.81573
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.46472
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.12594
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10153.89107
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.61623
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.39963
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.37572      1.40308     12.09263    5.28126
alpha_0                               0.36728      0.00363     0.37450     0.36260
alpha_1                               0.21585      0.00092     0.21738     0.21431
alpha_2                               0.21712      0.00163     0.21959     0.21410
alpha_3                               0.21239      0.00191     0.21563     0.20913
alpha_4                               0.21686      0.00124     0.21869     0.21443
alpha_5                               0.21598      0.00127     0.21793     0.21359
alpha_6                               0.21726      0.00170     0.21984     0.21411
alpha_7                               0.21468      0.00161     0.21715     0.21167
alpha_8                               0.21470      0.00177     0.21748     0.21154
alpha_9                               0.21451      0.00189     0.21761     0.21125
Alpha_loss                            -7.55778     0.70016     -5.82740    -8.45748
Training/policy_loss                  -26.85815    1.29706     -24.44339   -29.21157
Training/qf1_loss                     2704.40232   936.31491   5741.61865  1102.18311
Training/qf2_loss                     2904.71479   1013.07424  6222.41650  1130.92273
Training/pf_norm                      0.47444      0.08754     0.66951     0.25134
Training/qf1_norm                     214.59193    128.62635   599.92792   41.20018
Training/qf2_norm                     442.85879    159.05297   841.15582   111.66981
log_std/mean                          -0.28439     0.02079     -0.25564    -0.33187
log_std/std                           0.15992      0.01537     0.18590     0.13118
log_std/max                           -0.05488     0.01854     -0.02690    -0.09140
log_std/min                           -0.63256     0.05188     -0.52764    -0.71871
log_probs/mean                        -1.00618     0.40068     0.04675     -1.49635
log_probs/std                         2.04443      0.13711     2.35903     1.80957
log_probs/max                         5.27561      1.34262     7.88718     3.75825
log_probs/min                         -7.17537     1.23415     -5.17289    -11.31956
mean/mean                             -0.11407     0.07240     -0.03866    -0.22674
mean/std                              0.74835      0.08450     0.96908     0.65810
mean/max                              1.59390      0.07951     1.79978     1.46631
mean/min                              -1.49789     0.11686     -1.24302    -1.69893
------------------------------------  -----------  ----------  ----------  ----------
sample: [1, 5, 6, 0, 8, 9, 2, 7, 4, 3]
replay_buffer._size: [11250 11250 11250 11250 11250 11250 11250 11250 11250 11250]
2023-08-12 11:49:35,381 MainThread INFO: EPOCH:53
2023-08-12 11:49:35,381 MainThread INFO: Time Consumed:8.335506200790405s
2023-08-12 11:49:35,381 MainThread INFO: Total Frames:111000s
  1%|          | 54/10000 [08:14<25:14:43,  9.14s/it]------------------------------------  -----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1510.49296
Train_Epoch_Reward                    16443.37722
Running_Training_Average_Rewards      1841.66416
Explore_Time                          0.01303
Train___Time                          8.31565
Eval____Time                          0.00427
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.72069
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.98997
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.65157
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.36822
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.14421
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.96786
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.02049
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15709.34120
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.81446
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.73410
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.20562      1.40450     11.89776    5.19687
alpha_0                               0.36465      0.00205     0.36914     0.36244
alpha_1                               0.21285      0.00079     0.21428     0.21160
alpha_2                               0.21068      0.00193     0.21403     0.20748
alpha_3                               0.20686      0.00110     0.20907     0.20505
alpha_4                               0.21107      0.00193     0.21437     0.20790
alpha_5                               0.21050      0.00186     0.21354     0.20723
alpha_6                               0.21096      0.00172     0.21404     0.20801
alpha_7                               0.20839      0.00181     0.21160     0.20535
alpha_8                               0.20944      0.00099     0.21148     0.20779
alpha_9                               0.20909      0.00102     0.21118     0.20734
Alpha_loss                            -6.76569     0.50881     -6.17195    -8.11339
Training/policy_loss                  -31.21041    1.23536     -29.30598   -33.56199
Training/qf1_loss                     2558.49999   956.16628   6059.99951  977.02875
Training/qf2_loss                     2656.25455   1015.58844  6323.86084  985.03461
Training/pf_norm                      0.35209      0.08206     0.51947     0.21469
Training/qf1_norm                     206.79894    140.35891   632.31628   47.66073
Training/qf2_norm                     372.75278    195.42796   856.15350   62.25767
log_std/mean                          -0.32814     0.03334     -0.27716    -0.37839
log_std/std                           0.12028      0.01902     0.16586     0.09661
log_std/max                           -0.13354     0.03727     -0.03217    -0.17491
log_std/min                           -0.63627     0.06553     -0.55142    -0.75982
log_probs/mean                        -0.27473     0.36274     0.12403     -1.23415
log_probs/std                         2.97838      0.25088     3.31697     2.30640
log_probs/max                         10.00399     0.97579     11.79723    7.81304
log_probs/min                         -7.33420     1.04880     -5.64843    -11.40389
mean/mean                             -0.01543     0.04406     0.04873     -0.10249
mean/std                              0.93952      0.09075     1.01555     0.68942
mean/max                              2.07063      0.14561     2.33887     1.81927
mean/min                              -1.88257     0.17008     -1.63859    -2.17637
------------------------------------  -----------  ----------  ----------  ---------
sample: [7, 5, 0, 9, 3, 1, 4, 6, 2, 8]
replay_buffer._size: [11400 11400 11400 11400 11400 11400 11400 11400 11400 11400]
2023-08-12 11:49:44,306 MainThread INFO: EPOCH:54
2023-08-12 11:49:44,307 MainThread INFO: Time Consumed:8.72212266921997s
2023-08-12 11:49:44,307 MainThread INFO: Total Frames:112500s
  1%|          | 55/10000 [08:23<25:05:04,  9.08s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               831.15367
Train_Epoch_Reward                    16900.28261
Running_Training_Average_Rewards      2151.48683
Explore_Time                          0.00599
Train___Time                          8.71067
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.22353
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.11731
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.58522
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.42068
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -28.35223
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -35.40032
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.75068
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8841.59700
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.23843
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -73.97192
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.98595      1.30354    12.00220    5.47170
alpha_0                               0.37383      0.00277    0.37861     0.36925
alpha_1                               0.20959      0.00129    0.21157     0.20721
alpha_2                               0.20476      0.00150    0.20742     0.20225
alpha_3                               0.20303      0.00119    0.20501     0.20087
alpha_4                               0.20517      0.00157    0.20785     0.20251
alpha_5                               0.20406      0.00173    0.20716     0.20125
alpha_6                               0.20486      0.00179    0.20795     0.20179
alpha_7                               0.20252      0.00155    0.20529     0.19995
alpha_8                               0.20648      0.00077    0.20775     0.20502
alpha_9                               0.20521      0.00126    0.20730     0.20292
Alpha_loss                            -6.66672     0.20924    -6.21774    -7.12507
Training/policy_loss                  -35.12033    1.08457    -32.98389   -36.98521
Training/qf1_loss                     2414.99050   851.85588  4891.13916  804.25079
Training/qf2_loss                     2460.90599   868.76191  4956.78760  801.63049
Training/pf_norm                      0.32622      0.06324    0.48185     0.18715
Training/qf1_norm                     242.75549    168.68005  893.72565   49.19525
Training/qf2_norm                     339.74757    207.73768  1063.09204  67.11990
log_std/mean                          -0.31674     0.01518    -0.29522    -0.35194
log_std/std                           0.13643      0.00995    0.15260     0.11748
log_std/max                           -0.06897     0.02589    -0.02664    -0.13568
log_std/min                           -0.66056     0.03880    -0.59627    -0.75264
log_probs/mean                        -0.13192     0.12496    0.14289     -0.43254
log_probs/std                         2.86745      0.10857    3.09023     2.59507
log_probs/max                         9.94545      0.50485    11.08282    8.83253
log_probs/min                         -7.47683     1.06906    -5.72087    -11.81946
mean/mean                             -0.04733     0.05754    0.02240     -0.12561
mean/std                              0.96907      0.02019    1.00271     0.93637
mean/max                              2.20563      0.09953    2.34509     2.00710
mean/min                              -2.00477     0.05432    -1.93158    -2.10831
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 8, 9, 7, 3, 4, 2, 6, 1, 0]
replay_buffer._size: [11550 11550 11550 11550 11550 11550 11550 11550 11550 11550]
2023-08-12 11:49:53,385 MainThread INFO: EPOCH:55
2023-08-12 11:49:53,386 MainThread INFO: Time Consumed:8.869955778121948s
2023-08-12 11:49:53,386 MainThread INFO: Total Frames:114000s
  1%|          | 56/10000 [08:32<25:07:19,  9.09s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               737.59169
Train_Epoch_Reward                    11578.20760
Running_Training_Average_Rewards      1497.39558
Explore_Time                          0.02313
Train___Time                          8.84155
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.71784
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.67054
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.01960
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.89632
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.26346
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.56839
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.08252
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8012.16217
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.20537
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -91.82116
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.96445      1.39998    11.68595    4.26255
alpha_0                               0.38362      0.00302    0.38865     0.37868
alpha_1                               0.20410      0.00180    0.20715     0.20099
alpha_2                               0.19982      0.00134    0.20220     0.19755
alpha_3                               0.19829      0.00156    0.20082     0.19555
alpha_4                               0.19973      0.00158    0.20245     0.19700
alpha_5                               0.19898      0.00132    0.20121     0.19680
alpha_6                               0.19872      0.00176    0.20172     0.19572
alpha_7                               0.19767      0.00133    0.19991     0.19541
alpha_8                               0.20337      0.00108    0.20499     0.20150
alpha_9                               0.20029      0.00160    0.20288     0.19753
Alpha_loss                            -7.11352     0.35669    -6.41206    -7.68794
Training/policy_loss                  -38.58508    0.98978    -36.85286   -40.23698
Training/qf1_loss                     2497.17529   940.10243  6043.19482  711.28534
Training/qf2_loss                     2544.20560   960.53631  6172.56934  720.17731
Training/pf_norm                      0.36296      0.06980    0.59191     0.24366
Training/qf1_norm                     277.60979    175.56349  903.52454   56.74289
Training/qf2_norm                     376.85785    221.67753  1131.08435  60.21047
log_std/mean                          -0.30083     0.02670    -0.26989    -0.34968
log_std/std                           0.13598      0.01286    0.15381     0.11560
log_std/max                           -0.09935     0.03893    -0.04055    -0.15740
log_std/min                           -0.67196     0.04033    -0.61759    -0.75385
log_probs/mean                        -0.33394     0.21361    0.08608     -0.70262
log_probs/std                         2.85693      0.11520    3.09004     2.62539
log_probs/max                         10.11567     0.61939    11.68879    8.67818
log_probs/min                         -7.31574     0.84182    -5.52320    -9.71986
mean/mean                             0.02399      0.02437    0.05965     -0.02751
mean/std                              0.93609      0.04081    1.00161     0.86653
mean/max                              2.28115      0.10535    2.41010     2.06100
mean/min                              -2.09334     0.04518    -1.97964    -2.17354
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 4, 6, 8, 3, 9, 7, 1, 2, 5]
replay_buffer._size: [11700 11700 11700 11700 11700 11700 11700 11700 11700 11700]
2023-08-12 11:50:02,661 MainThread INFO: EPOCH:56
2023-08-12 11:50:02,662 MainThread INFO: Time Consumed:9.089431524276733s
2023-08-12 11:50:02,662 MainThread INFO: Total Frames:115500s
  1%|          | 57/10000 [08:41<25:13:32,  9.13s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               775.40812
Train_Epoch_Reward                    7219.64842
Running_Training_Average_Rewards      1189.93795
Explore_Time                          0.00924
Train___Time                          9.07528
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.22099
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.80209
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.75315
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.62761
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.16285
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.14193
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.33466
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8409.97709
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.95261
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -91.90003
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.80352     1.20248    11.24364    5.42416
alpha_0                               0.39340     0.00257    0.39793     0.38877
alpha_1                               0.19796     0.00165    0.20093     0.19529
alpha_2                               0.19536     0.00125    0.19751     0.19324
alpha_3                               0.19251     0.00175    0.19549     0.18948
alpha_4                               0.19412     0.00168    0.19695     0.19122
alpha_5                               0.19472     0.00116    0.19676     0.19272
alpha_6                               0.19273     0.00170    0.19566     0.18984
alpha_7                               0.19302     0.00139    0.19537     0.19061
alpha_8                               0.19954     0.00112    0.20146     0.19755
alpha_9                               0.19454     0.00173    0.19747     0.19154
Alpha_loss                            -7.57168    0.17502    -7.25184    -8.02452
Training/policy_loss                  -41.74015   1.03245    -39.67711   -43.81211
Training/qf1_loss                     2419.38544  953.00822  5059.48535  1049.06580
Training/qf2_loss                     2459.02931  968.17519  5127.42725  1054.77771
Training/pf_norm                      0.31968     0.07468    0.53163     0.16832
Training/qf1_norm                     276.50732   194.56598  945.27655   59.74715
Training/qf2_norm                     379.61888   238.78114  1081.88904  83.69894
log_std/mean                          -0.27071    0.01950    -0.23775    -0.29980
log_std/std                           0.13775     0.00999    0.15333     0.11766
log_std/max                           -0.10502    0.02342    -0.04818    -0.13213
log_std/min                           -0.66841    0.05132    -0.56711    -0.74626
log_probs/mean                        -0.54964    0.10508    -0.36369    -0.78433
log_probs/std                         2.82424     0.07876    3.02781     2.66688
log_probs/max                         9.94305     0.50585    11.14397    8.97580
log_probs/min                         -7.26380    0.83270    -5.33570    -10.08582
mean/mean                             -0.00926    0.01997    0.02318     -0.03906
mean/std                              0.90076     0.01830    0.93789     0.86123
mean/max                              2.28562     0.08908    2.47702     2.11710
mean/min                              -2.06953    0.09334    -1.90657    -2.22791
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 6, 1, 4, 3, 2, 7, 5, 0, 8]
replay_buffer._size: [11850 11850 11850 11850 11850 11850 11850 11850 11850 11850]
2023-08-12 11:50:11,667 MainThread INFO: EPOCH:57
2023-08-12 11:50:11,668 MainThread INFO: Time Consumed:8.830420970916748s
2023-08-12 11:50:11,668 MainThread INFO: Total Frames:117000s
  1%|          | 58/10000 [08:50<25:06:20,  9.09s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               785.16245
Train_Epoch_Reward                    9538.04800
Running_Training_Average_Rewards      944.53013
Explore_Time                          0.00956
Train___Time                          8.81577
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.59210
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.29256
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.14268
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.75787
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.33346
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.08492
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.10554
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8459.27671
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.91713
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -89.42596
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.92791     1.41418    11.72943    5.14468
alpha_0                               0.40334     0.00291    0.40781     0.39804
alpha_1                               0.19250     0.00158    0.19524     0.18994
alpha_2                               0.19155     0.00094    0.19320     0.18989
alpha_3                               0.18636     0.00178    0.18942     0.18334
alpha_4                               0.18836     0.00163    0.19116     0.18554
alpha_5                               0.19008     0.00156    0.19268     0.18743
alpha_6                               0.18681     0.00173    0.18978     0.18385
alpha_7                               0.18799     0.00150    0.19056     0.18540
alpha_8                               0.19441     0.00191    0.19750     0.19107
alpha_9                               0.18835     0.00182    0.19148     0.18524
Alpha_loss                            -8.42938    0.15836    -7.87777    -8.63662
Training/policy_loss                  -45.26667   0.87664    -43.52087   -47.06333
Training/qf1_loss                     2465.07178  905.86794  5352.76270  749.81964
Training/qf2_loss                     2500.07726  921.37480  5448.61865  739.69208
Training/pf_norm                      0.33435     0.06509    0.47200     0.20379
Training/qf1_norm                     343.49870   219.64296  1098.69189  87.21072
Training/qf2_norm                     454.49164   281.60549  1294.86084  98.02219
log_std/mean                          -0.24413    0.00898    -0.23176    -0.26191
log_std/std                           0.16493     0.00840    0.17676     0.15141
log_std/max                           -0.04189    0.01837    0.00337     -0.06281
log_std/min                           -0.72311    0.01487    -0.67478    -0.75090
log_probs/mean                        -0.98313    0.09052    -0.66410    -1.12603
log_probs/std                         2.83480     0.11400    3.06480     2.61413
log_probs/max                         9.98031     0.67731    11.66524    8.41162
log_probs/min                         -6.91168    0.90826    -5.27336    -9.82854
mean/mean                             -0.03196    0.00930    -0.00375    -0.04294
mean/std                              0.80174     0.02256    0.86287     0.77615
mean/max                              2.22198     0.03998    2.28682     2.11920
mean/min                              -2.08547    0.09098    -1.93224    -2.22926
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 7, 9, 6, 3, 0, 5, 2, 4, 1]
replay_buffer._size: [12000 12000 12000 12000 12000 12000 12000 12000 12000 12000]
2023-08-12 11:50:20,782 MainThread INFO: EPOCH:58
2023-08-12 11:50:20,782 MainThread INFO: Time Consumed:8.948867082595825s
2023-08-12 11:50:20,782 MainThread INFO: Total Frames:118500s
  1%|          | 59/10000 [08:59<25:08:50,  9.11s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               753.25680
Train_Epoch_Reward                    8690.14402
Running_Training_Average_Rewards      848.26135
Explore_Time                          0.00850
Train___Time                          8.93505
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.79707
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.37406
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -48.53171
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.68371
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.09515
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.15585
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  131.52716
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7952.99457
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.66831
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -83.64782
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.99745     1.54073     13.46798    4.72425
alpha_0                               0.41299     0.00314     0.41805     0.40789
alpha_1                               0.18766     0.00135     0.18989     0.18538
alpha_2                               0.18820     0.00092     0.18986     0.18664
alpha_3                               0.18044     0.00161     0.18328     0.17774
alpha_4                               0.18261     0.00165     0.18548     0.17982
alpha_5                               0.18475     0.00160     0.18738     0.18197
alpha_6                               0.18093     0.00167     0.18379     0.17809
alpha_7                               0.18283     0.00141     0.18534     0.18051
alpha_8                               0.18770     0.00189     0.19100     0.18453
alpha_9                               0.18220     0.00171     0.18518     0.17932
Alpha_loss                            -8.39738    0.10743     -8.14401    -8.70697
Training/policy_loss                  -48.59533   1.09477     -46.12973   -50.39284
Training/qf1_loss                     2525.53837  1003.56491  5685.01904  933.71771
Training/qf2_loss                     2557.81500  1024.45442  5799.80225  929.80353
Training/pf_norm                      0.37625     0.08570     0.68667     0.21509
Training/qf1_norm                     397.53619   279.77109   1631.61951  83.15544
Training/qf2_norm                     520.02208   352.14019   2033.90186  118.59631
log_std/mean                          -0.27955    0.01996     -0.25313    -0.31547
log_std/std                           0.16006     0.00567     0.17158     0.15030
log_std/max                           -0.06503    0.01978     -0.03207    -0.09175
log_std/min                           -0.72248    0.02385     -0.68476    -0.76824
log_probs/mean                        -0.86754    0.08213     -0.67741    -1.06895
log_probs/std                         2.85766     0.11737     3.14817     2.61914
log_probs/max                         9.78565     0.56390     10.97208    8.65645
log_probs/min                         -7.02842    1.03324     -5.06363    -9.84258
mean/mean                             -0.12480    0.04355     -0.04169    -0.18426
mean/std                              0.81234     0.00978     0.83789     0.79484
mean/max                              2.13497     0.05908     2.22452     2.02494
mean/min                              -2.15181    0.09450     -1.97121    -2.30986
------------------------------------  ----------  ----------  ----------  ---------
sample: [0, 1, 8, 6, 3, 9, 2, 4, 7, 5]
replay_buffer._size: [12150 12150 12150 12150 12150 12150 12150 12150 12150 12150]
2023-08-12 11:50:28,957 MainThread INFO: EPOCH:59
2023-08-12 11:50:28,957 MainThread INFO: Time Consumed:7.997301816940308s
2023-08-12 11:50:28,957 MainThread INFO: Total Frames:120000s
  1%|          | 60/10000 [09:08<24:22:57,  8.83s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               832.92629
Train_Epoch_Reward                    8964.85497
Running_Training_Average_Rewards      906.43490
Explore_Time                          0.00611
Train___Time                          7.98625
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.54135
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.98112
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.61126
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.13698
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.44127
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.80306
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.02566
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8886.01752
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.54047
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.67344
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.03373     1.48924     12.16613    5.12507
alpha_0                               0.42211     0.00235     0.42625     0.41813
alpha_1                               0.18365     0.00103     0.18534     0.18180
alpha_2                               0.18469     0.00114     0.18660     0.18270
alpha_3                               0.17517     0.00145     0.17769     0.17273
alpha_4                               0.17692     0.00165     0.17977     0.17410
alpha_5                               0.17927     0.00153     0.18191     0.17668
alpha_6                               0.17528     0.00160     0.17803     0.17255
alpha_7                               0.17824     0.00130     0.18046     0.17600
alpha_8                               0.18152     0.00169     0.18447     0.17866
alpha_9                               0.17654     0.00157     0.17927     0.17386
Alpha_loss                            -8.34817    0.12229     -8.07688    -8.58873
Training/policy_loss                  -51.68177   1.07408     -49.86261   -53.82782
Training/qf1_loss                     2548.46927  993.12691   5117.72852  1025.08179
Training/qf2_loss                     2568.67980  1000.21094  5174.03760  1018.27899
Training/pf_norm                      0.34228     0.07813     0.55617     0.19954
Training/qf1_norm                     415.61554   314.45338   1450.21997  91.32365
Training/qf2_norm                     544.17761   368.58275   1681.39917  124.57076
log_std/mean                          -0.29229    0.01255     -0.27029    -0.31293
log_std/std                           0.15299     0.00837     0.16841     0.13815
log_std/max                           0.00415     0.03105     0.06939     -0.04210
log_std/min                           -0.69045    0.04114     -0.58811    -0.75895
log_probs/mean                        -0.77315    0.07054     -0.58309    -0.93412
log_probs/std                         2.73168     0.09568     2.95065     2.53176
log_probs/max                         9.40617     0.47543     10.37855    7.87995
log_probs/min                         -7.13616    0.98968     -5.41773    -10.07275
mean/mean                             -0.11227    0.05466     -0.01552    -0.17582
mean/std                              0.83380     0.01435     0.86287     0.81140
mean/max                              2.23255     0.06763     2.34149     2.07423
mean/min                              -2.01374    0.06967     -1.90784    -2.16519
------------------------------------  ----------  ----------  ----------  ----------
sample: [1, 8, 2, 0, 5, 3, 4, 9, 7, 6]
replay_buffer._size: [12300 12300 12300 12300 12300 12300 12300 12300 12300 12300]
2023-08-12 11:50:37,556 MainThread INFO: EPOCH:60
2023-08-12 11:50:37,557 MainThread INFO: Time Consumed:8.423387050628662s
2023-08-12 11:50:37,557 MainThread INFO: Total Frames:121500s
  1%|          | 61/10000 [09:16<24:10:34,  8.76s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               854.59764
Train_Epoch_Reward                    8731.34954
Running_Training_Average_Rewards      879.54495
Explore_Time                          0.00447
Train___Time                          8.41365
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.02594
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -96.38689
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.25579
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.15044
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.72576
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.08880
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.90912
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9166.36284
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.02565
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.81809
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.91304     1.50433    11.90783    4.84660
alpha_0                               0.43072     0.00259    0.43550     0.42634
alpha_1                               0.17952     0.00133    0.18175     0.17713
alpha_2                               0.18059     0.00124    0.18266     0.17844
alpha_3                               0.17035     0.00134    0.17268     0.16809
alpha_4                               0.17130     0.00160    0.17404     0.16857
alpha_5                               0.17414     0.00143    0.17663     0.17176
alpha_6                               0.16983     0.00154    0.17250     0.16722
alpha_7                               0.17381     0.00122    0.17595     0.17173
alpha_8                               0.17592     0.00156    0.17861     0.17329
alpha_9                               0.17125     0.00147    0.17381     0.16876
Alpha_loss                            -8.46441    0.13075    -8.07503    -8.85366
Training/policy_loss                  -54.92840   1.01564    -53.17860   -57.05970
Training/qf1_loss                     2416.64490  953.80499  4570.72656  747.84137
Training/qf2_loss                     2430.84528  967.05907  4584.08740  690.29523
Training/pf_norm                      0.40166     0.11523    0.75957     0.21252
Training/qf1_norm                     447.59399   281.98798  1457.05005  126.86002
Training/qf2_norm                     577.67984   354.89770  1801.10730  97.99360
log_std/mean                          -0.28922    0.01199    -0.26976    -0.31389
log_std/std                           0.15992     0.00608    0.16934     0.14768
log_std/max                           -0.00191    0.04131    0.05856     -0.06113
log_std/min                           -0.71454    0.03868    -0.62799    -0.75870
log_probs/mean                        -0.75202    0.09702    -0.44359    -0.98484
log_probs/std                         2.70330     0.10042    2.96851     2.52405
log_probs/max                         9.52890     0.47303    10.68712    8.55202
log_probs/min                         -7.25113    0.85001    -5.64619    -9.95779
mean/mean                             -0.04037    0.01751    -0.01062    -0.07784
mean/std                              0.84604     0.01774    0.89797     0.81896
mean/max                              2.16536     0.10173    2.32566     1.95880
mean/min                              -2.09895    0.07694    -1.94903    -2.25741
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 0, 6, 1, 8, 4, 5, 7, 2, 3]
replay_buffer._size: [12450 12450 12450 12450 12450 12450 12450 12450 12450 12450]
2023-08-12 11:50:46,405 MainThread INFO: EPOCH:61
2023-08-12 11:50:46,406 MainThread INFO: Time Consumed:8.664993047714233s
2023-08-12 11:50:46,406 MainThread INFO: Total Frames:123000s
  1%|          | 62/10000 [09:25<24:15:16,  8.79s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1062.14227
Train_Epoch_Reward                    9060.38330
Running_Training_Average_Rewards      891.88626
Explore_Time                          0.01036
Train___Time                          8.64973
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.93086
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -96.44203
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.44837
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2199.19190
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -94.56538
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.37276
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.10368
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9059.80815
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.19766
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.51657
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.09281     1.48923     13.48329    5.38781
alpha_0                               0.44018     0.00220     0.44416     0.43562
alpha_1                               0.17421     0.00161     0.17707     0.17160
alpha_2                               0.17629     0.00132     0.17840     0.17390
alpha_3                               0.16589     0.00128     0.16804     0.16366
alpha_4                               0.16590     0.00152     0.16852     0.16331
alpha_5                               0.16969     0.00116     0.17172     0.16777
alpha_6                               0.16466     0.00146     0.16717     0.16218
alpha_7                               0.16971     0.00119     0.17169     0.16766
alpha_8                               0.17082     0.00143     0.17324     0.16836
alpha_9                               0.16638     0.00137     0.16871     0.16400
Alpha_loss                            -8.49141    0.24528     -7.96674    -8.88991
Training/policy_loss                  -58.07147   1.13154     -56.42976   -60.67997
Training/qf1_loss                     2516.38380  1011.04073  6881.71094  1008.87305
Training/qf2_loss                     2533.70204  1021.49611  6934.13623  1055.03699
Training/pf_norm                      0.45508     0.14275     0.78551     0.22702
Training/qf1_norm                     465.41193   336.66749   1956.27478  110.36677
Training/qf2_norm                     607.28633   412.56062   2321.82104  96.72166
log_std/mean                          -0.28487    0.01598     -0.25259    -0.31025
log_std/std                           0.15812     0.00720     0.16713     0.14568
log_std/max                           -0.00868    0.01375     0.01609     -0.03126
log_std/min                           -0.71161    0.03599     -0.65393    -0.77356
log_probs/mean                        -0.70046    0.16108     -0.39875    -0.96256
log_probs/std                         2.66061     0.16399     2.98432     2.39159
log_probs/max                         9.45925     0.77798     10.98561    8.16172
log_probs/min                         -7.42586    1.05262     -5.78270    -10.92436
mean/mean                             -0.03449    0.04198     0.05785     -0.10141
mean/std                              0.85811     0.03560     0.92760     0.81306
mean/max                              2.22838     0.09807     2.42370     2.10906
mean/min                              -1.99813    0.12352     -1.82022    -2.22172
------------------------------------  ----------  ----------  ----------  ----------
sample: [4, 0, 7, 3, 5, 9, 6, 2, 1, 8]
replay_buffer._size: [12600 12600 12600 12600 12600 12600 12600 12600 12600 12600]
2023-08-12 11:50:55,489 MainThread INFO: EPOCH:62
2023-08-12 11:50:55,489 MainThread INFO: Time Consumed:8.902113437652588s
2023-08-12 11:50:55,489 MainThread INFO: Total Frames:124500s
  1%|          | 63/10000 [09:34<24:28:15,  8.87s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               827.84235
Train_Epoch_Reward                    9905.28029
Running_Training_Average_Rewards      923.23377
Explore_Time                          0.00464
Train___Time                          8.89300
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.23243
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -94.90211
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.76290
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.80857
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -96.62065
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.41336
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.19980
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8935.91190
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -88.99476
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.55378
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.89714     1.21341    10.43432    5.17875
alpha_0                               0.44922     0.00244    0.45296     0.44430
alpha_1                               0.16876     0.00166    0.17155     0.16587
alpha_2                               0.17152     0.00131    0.17385     0.16932
alpha_3                               0.16146     0.00126    0.16361     0.15932
alpha_4                               0.16076     0.00143    0.16326     0.15833
alpha_5                               0.16583     0.00118    0.16774     0.16382
alpha_6                               0.15967     0.00143    0.16213     0.15724
alpha_7                               0.16577     0.00107    0.16762     0.16397
alpha_8                               0.16605     0.00133    0.16831     0.16378
alpha_9                               0.16164     0.00133    0.16395     0.15939
Alpha_loss                            -8.59453    0.19106    -8.09338    -8.98621
Training/policy_loss                  -61.16234   1.12643    -58.90421   -63.63219
Training/qf1_loss                     2472.28140  853.88432  5055.88770  1005.61377
Training/qf2_loss                     2471.30765  864.06673  5060.10889  1002.15234
Training/pf_norm                      0.54572     0.14827    0.93430     0.27743
Training/qf1_norm                     454.57031   243.68987  1077.44214  137.27519
Training/qf2_norm                     563.96285   309.22197  1343.60022  136.45374
log_std/mean                          -0.26272    0.02106    -0.22751    -0.31733
log_std/std                           0.16521     0.01018    0.18126     0.14415
log_std/max                           0.03821     0.02741    0.07321     -0.01884
log_std/min                           -0.70979    0.04454    -0.64687    -0.83577
log_probs/mean                        -0.68665    0.13001    -0.36572    -0.94337
log_probs/std                         2.64790     0.15291    3.04928     2.38484
log_probs/max                         9.16460     0.73515    11.28867    7.66537
log_probs/min                         -7.26240    0.85837    -5.30236    -9.42731
mean/mean                             -0.07159    0.06930    0.06193     -0.15215
mean/std                              0.86109     0.02701    0.92884     0.82605
mean/max                              2.20370     0.09540    2.39513     2.02952
mean/min                              -2.15340    0.07354    -1.97106    -2.28704
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 3, 0, 4, 8, 7, 2, 1, 5, 6]
replay_buffer._size: [12750 12750 12750 12750 12750 12750 12750 12750 12750 12750]
2023-08-12 11:51:04,505 MainThread INFO: EPOCH:63
2023-08-12 11:51:04,506 MainThread INFO: Time Consumed:8.848322629928589s
2023-08-12 11:51:04,506 MainThread INFO: Total Frames:126000s
  1%|          | 64/10000 [09:43<24:36:06,  8.91s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               779.70783
Train_Epoch_Reward                    11392.04612
Running_Training_Average_Rewards      1011.92366
Explore_Time                          0.00418
Train___Time                          8.83975
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.95363
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.27332
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.44072
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.88358
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -92.27793
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.36819
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.59429
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8461.17497
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.40668
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.89836
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.81695      1.27059    11.00770    4.71497
alpha_0                               0.45774      0.00264    0.46200     0.45305
alpha_1                               0.16297      0.00165    0.16582     0.16017
alpha_2                               0.16695      0.00137    0.16927     0.16460
alpha_3                               0.15729      0.00114    0.15928     0.15536
alpha_4                               0.15583      0.00143    0.15828     0.15338
alpha_5                               0.16212      0.00097    0.16378     0.16048
alpha_6                               0.15485      0.00136    0.15719     0.15253
alpha_7                               0.16227      0.00095    0.16394     0.16067
alpha_8                               0.16165      0.00120    0.16374     0.15963
alpha_9                               0.15724      0.00121    0.15935     0.15519
Alpha_loss                            -8.42238     0.22160    -8.03330    -8.90071
Training/policy_loss                  -64.02784    0.94494    -62.28576   -65.71089
Training/qf1_loss                     2499.55221   898.52016  4561.97607  772.40509
Training/qf2_loss                     2491.58696   901.08626  4477.70557  767.87079
Training/pf_norm                      0.53229      0.13320    0.90017     0.25163
Training/qf1_norm                     479.78820    307.94684  1446.60779  92.33337
Training/qf2_norm                     592.93473    371.67816  1612.96802  154.87009
log_std/mean                          -0.28505     0.01704    -0.25239    -0.31996
log_std/std                           0.16469      0.00557    0.17307     0.15285
log_std/max                           0.07651      0.04717    0.14644     -0.01410
log_std/min                           -0.74744     0.04731    -0.66073    -0.84455
log_probs/mean                        -0.51824     0.14890    -0.26279    -0.85372
log_probs/std                         2.70239      0.14069    2.96985     2.42325
log_probs/max                         9.50446      0.60778    10.81640    7.85520
log_probs/min                         -7.37473     0.95444    -5.75314    -10.35162
mean/mean                             -0.06056     0.01525    -0.04128    -0.11012
mean/std                              0.89521      0.02980    0.93943     0.83687
mean/max                              2.23466      0.09724    2.40004     2.07289
mean/min                              -2.07288     0.09761    -1.91213    -2.28535
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 5, 6, 4, 8, 7, 0, 1, 2, 9]
replay_buffer._size: [12900 12900 12900 12900 12900 12900 12900 12900 12900 12900]
2023-08-12 11:51:13,466 MainThread INFO: EPOCH:64
2023-08-12 11:51:13,466 MainThread INFO: Time Consumed:8.748508930206299s
2023-08-12 11:51:13,466 MainThread INFO: Total Frames:127500s
  1%|          | 65/10000 [09:52<24:39:09,  8.93s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1063.54691
Train_Epoch_Reward                    8803.06299
Running_Training_Average_Rewards      1003.34631
Explore_Time                          0.00915
Train___Time                          8.73472
Eval____Time                          0.00379
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.75980
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.09142
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.70607
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           179.42579
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.57377
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.24564
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.32037
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11081.40342
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.99152
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.67152
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.87182      1.43043    11.64330    5.21902
alpha_0                               0.46496      0.00199    0.46835     0.46205
alpha_1                               0.15751      0.00145    0.16011     0.15514
alpha_2                               0.16216      0.00143    0.16456     0.15963
alpha_3                               0.15348      0.00104    0.15532     0.15172
alpha_4                               0.15097      0.00136    0.15334     0.14870
alpha_5                               0.15846      0.00112    0.16044     0.15665
alpha_6                               0.15026      0.00127    0.15248     0.14814
alpha_7                               0.15904      0.00090    0.16063     0.15753
alpha_8                               0.15756      0.00114    0.15959     0.15567
alpha_9                               0.15322      0.00108    0.15515     0.15142
Alpha_loss                            -8.32000     0.44612    -7.37083    -8.98016
Training/policy_loss                  -67.05474    0.90623    -65.43047   -69.30195
Training/qf1_loss                     2425.93857   894.91791  5282.95557  907.47577
Training/qf2_loss                     2412.53060   892.51231  5241.46924  852.29315
Training/pf_norm                      0.58604      0.17844    1.09140     0.32044
Training/qf1_norm                     559.83072    350.76275  1899.08447  149.97348
Training/qf2_norm                     682.12538    439.42884  2228.46777  131.33105
log_std/mean                          -0.28546     0.02733    -0.24793    -0.34396
log_std/std                           0.18174      0.00445    0.18806     0.17135
log_std/max                           0.21645      0.05257    0.31395     0.12174
log_std/min                           -0.73165     0.04124    -0.64421    -0.79638
log_probs/mean                        -0.41670     0.28502    0.18990     -0.83453
log_probs/std                         2.58381      0.16712    2.99770     2.32987
log_probs/max                         9.23766      0.92172    11.46124    7.89229
log_probs/min                         -7.50778     0.92556    -5.66961    -11.43187
mean/mean                             -0.16686     0.02215    -0.11374    -0.19345
mean/std                              0.89561      0.05537    0.99960     0.83089
mean/max                              2.16413      0.11015    2.46203     1.97334
mean/min                              -2.11618     0.10412    -1.91551    -2.30279
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 3, 1, 9, 7, 2, 8, 0, 5, 4]
replay_buffer._size: [13055 13057 13054 13056 13060 13056 13056 13060 13059 13054]
2023-08-12 11:51:22,366 MainThread INFO: EPOCH:65
2023-08-12 11:51:22,366 MainThread INFO: Time Consumed:8.780701398849487s
2023-08-12 11:51:22,366 MainThread INFO: Total Frames:129000s
  1%|          | 66/10000 [10:01<24:36:01,  8.91s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1274.35691
Train_Epoch_Reward                    11234.66800
Running_Training_Average_Rewards      1047.65924
Explore_Time                          0.11781
Train___Time                          8.65870
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.81012
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.63718
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -72.49976
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.94762
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.96471
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.87512
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.66186
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13396.67277
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -87.35813
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.34919
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.99540      1.33576    12.15336    4.71398
alpha_0                               0.47167      0.00141    0.47410     0.46843
alpha_1                               0.15282      0.00135    0.15509     0.15048
alpha_2                               0.15695      0.00154    0.15957     0.15432
alpha_3                               0.14998      0.00100    0.15168     0.14830
alpha_4                               0.14647      0.00124    0.14865     0.14438
alpha_5                               0.15502      0.00098    0.15661     0.15331
alpha_6                               0.14603      0.00121    0.14810     0.14396
alpha_7                               0.15602      0.00089    0.15750     0.15449
alpha_8                               0.15400      0.00096    0.15564     0.15241
alpha_9                               0.14969      0.00099    0.15138     0.14803
Alpha_loss                            -8.03042     0.31815    -7.26304    -8.62986
Training/policy_loss                  -69.95895    1.23291    -67.73637   -72.88246
Training/qf1_loss                     2574.01972   953.61253  6327.34766  622.94598
Training/qf2_loss                     2541.35762   942.59334  6352.04541  600.53595
Training/pf_norm                      0.52296      0.14069    0.92698     0.27913
Training/qf1_norm                     527.39942    353.99949  1932.19031  107.50964
Training/qf2_norm                     677.12370    414.26829  2250.43359  156.83447
log_std/mean                          -0.27344     0.02031    -0.24344    -0.31715
log_std/std                           0.19511      0.01275    0.21397     0.17403
log_std/max                           0.30152      0.05566    0.37174     0.16935
log_std/min                           -0.75846     0.07050    -0.65215    -0.87922
log_probs/mean                        -0.20814     0.20418    0.27988     -0.58520
log_probs/std                         2.63196      0.16161    3.03989     2.33682
log_probs/max                         9.60468      0.72398    11.24935    8.42621
log_probs/min                         -7.54106     1.09421    -5.73135    -11.24438
mean/mean                             -0.08769     0.02913    -0.04471    -0.13403
mean/std                              0.95471      0.03640    1.04569     0.90038
mean/max                              2.30966      0.08445    2.48548     2.17003
mean/min                              -1.98734     0.12619    -1.77987    -2.25985
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 1, 4, 5, 6, 3, 2, 9, 8, 0]
replay_buffer._size: [13200 13200 13200 13200 13200 13200 13200 13200 13200 13200]
2023-08-12 11:51:31,301 MainThread INFO: EPOCH:66
2023-08-12 11:51:31,301 MainThread INFO: Time Consumed:8.765990257263184s
2023-08-12 11:51:31,301 MainThread INFO: Total Frames:130500s
  1%|          | 67/10000 [10:10<24:37:34,  8.93s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1074.50803
Train_Epoch_Reward                    13058.24739
Running_Training_Average_Rewards      1103.19928
Explore_Time                          0.00531
Train___Time                          8.75639
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.24979
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.19245
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -72.57241
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.32776
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.48483
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.29424
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.49094
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11431.56195
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -88.05862
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.81057
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.00988      1.35132    11.77333    5.04752
alpha_0                               0.47764      0.00140    0.47913     0.47419
alpha_1                               0.14827      0.00122    0.15043     0.14621
alpha_2                               0.15227      0.00114    0.15427     0.15019
alpha_3                               0.14677      0.00090    0.14827     0.14518
alpha_4                               0.14221      0.00124    0.14434     0.14011
alpha_5                               0.15203      0.00074    0.15328     0.15072
alpha_6                               0.14178      0.00125    0.14392     0.13964
alpha_7                               0.15319      0.00076    0.15446     0.15184
alpha_8                               0.15117      0.00073    0.15238     0.14989
alpha_9                               0.14663      0.00081    0.14800     0.14523
Alpha_loss                            -7.35376     0.32975    -6.65632    -8.07845
Training/policy_loss                  -73.03896    0.86272    -70.71315   -75.48714
Training/qf1_loss                     2644.81063   922.35265  5357.70020  1069.09302
Training/qf2_loss                     2601.12432   923.65787  5312.06250  1041.99963
Training/pf_norm                      0.52299      0.13056    0.86269     0.15368
Training/qf1_norm                     573.24958    330.51747  1742.95630  127.75209
Training/qf2_norm                     724.75241    389.27641  1995.23975  208.73515
log_std/mean                          -0.31633     0.00933    -0.29415    -0.32810
log_std/std                           0.18448      0.00815    0.20469     0.17439
log_std/max                           0.20713      0.02816    0.27907     0.16230
log_std/min                           -0.77853     0.04446    -0.66836    -0.83463
log_probs/mean                        0.19660      0.19487    0.62572     -0.20880
log_probs/std                         2.68104      0.14857    3.05997     2.44432
log_probs/max                         9.26771      0.68900    11.14238    8.22245
log_probs/min                         -7.49638     1.20662    -5.73419    -12.61662
mean/mean                             -0.15763     0.02940    -0.09761    -0.20051
mean/std                              1.01591      0.03938    1.09286     0.95140
mean/max                              2.27428      0.16703    2.59073     2.04357
mean/min                              -2.07439     0.09564    -1.90262    -2.30149
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 7, 3, 1, 2, 9, 6, 5, 0, 8]
replay_buffer._size: [13350 13350 13350 13350 13350 13350 13350 13350 13350 13350]
2023-08-12 11:51:40,363 MainThread INFO: EPOCH:67
2023-08-12 11:51:40,363 MainThread INFO: Time Consumed:8.862189531326294s
2023-08-12 11:51:40,363 MainThread INFO: Total Frames:132000s
  1%|          | 68/10000 [10:19<24:43:30,  8.96s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1389.86711
Train_Epoch_Reward                    10586.05578
Running_Training_Average_Rewards      1162.63237
Explore_Time                          0.00358
Train___Time                          8.85348
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.93568
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.58474
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.04963
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -70.98086
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.30704
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.58468
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.27911
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14601.28162
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.48240
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.40637
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.79634      1.36252    11.37289    4.86137
alpha_0                               0.47964      0.00045    0.48018     0.47902
alpha_1                               0.14401      0.00126    0.14617     0.14186
alpha_2                               0.14769      0.00144    0.15014     0.14522
alpha_3                               0.14351      0.00093    0.14515     0.14195
alpha_4                               0.13820      0.00105    0.14007     0.13648
alpha_5                               0.14911      0.00093    0.15070     0.14753
alpha_6                               0.13755      0.00117    0.13959     0.13556
alpha_7                               0.15018      0.00094    0.15181     0.14857
alpha_8                               0.14848      0.00078    0.14986     0.14714
alpha_9                               0.14373      0.00083    0.14520     0.14234
Alpha_loss                            -7.87518     0.26066    -7.28750    -8.37133
Training/policy_loss                  -75.62931    0.87437    -73.19807   -78.10414
Training/qf1_loss                     2474.49484   880.13988  4885.95459  883.49786
Training/qf2_loss                     2427.18821   879.45979  4768.26123  862.22015
Training/pf_norm                      0.50810      0.15599    1.20442     0.27552
Training/qf1_norm                     593.92032    337.52764  1890.21973  119.77947
Training/qf2_norm                     766.75896    437.72862  2181.45679  208.45609
log_std/mean                          -0.30604     0.01194    -0.28563    -0.32946
log_std/std                           0.20605      0.00627    0.21843     0.19097
log_std/max                           0.24492      0.03513    0.31474     0.15548
log_std/min                           -0.92754     0.07615    -0.78538    -1.09285
log_probs/mean                        -0.05387     0.15933    0.31595     -0.36571
log_probs/std                         2.54142      0.09339    2.79297     2.37303
log_probs/max                         9.03792      0.57945    10.40793    8.01450
log_probs/min                         -7.58702     1.11324    -5.67260    -12.21840
mean/mean                             -0.05646     0.01841    -0.03852    -0.09745
mean/std                              0.97412      0.02692    1.02498     0.92607
mean/max                              2.34301      0.06836    2.47557     2.18198
mean/min                              -1.94163     0.06848    -1.84252    -2.06870
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 1, 0, 6, 3, 4, 8, 5, 9, 2]
replay_buffer._size: [13500 13500 13500 13500 13500 13500 13500 13500 13500 13500]
2023-08-12 11:51:49,172 MainThread INFO: EPOCH:68
2023-08-12 11:51:49,173 MainThread INFO: Time Consumed:8.64879322052002s
2023-08-12 11:51:49,173 MainThread INFO: Total Frames:133500s
  1%|          | 69/10000 [10:28<24:35:48,  8.92s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               959.28663
Train_Epoch_Reward                    15312.56257
Running_Training_Average_Rewards      1298.56219
Explore_Time                          0.01230
Train___Time                          8.63153
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.17720
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.87813
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.09919
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -74.33363
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.76563
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.88610
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.75599
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10293.77287
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.52181
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.48890
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.59097      1.31382    11.13097    4.40709
alpha_0                               0.48196      0.00113    0.48462     0.48022
alpha_1                               0.13976      0.00118    0.14182     0.13785
alpha_2                               0.14290      0.00129    0.14517     0.14073
alpha_3                               0.14048      0.00082    0.14191     0.13914
alpha_4                               0.13489      0.00089    0.13644     0.13332
alpha_5                               0.14606      0.00083    0.14749     0.14472
alpha_6                               0.13358      0.00113    0.13553     0.13164
alpha_7                               0.14698      0.00092    0.14854     0.14548
alpha_8                               0.14587      0.00071    0.14711     0.14478
alpha_9                               0.14104      0.00074    0.14231     0.13984
Alpha_loss                            -7.14024     0.48849    -5.67145    -7.67517
Training/policy_loss                  -78.28061    1.34228    -75.97019   -81.98742
Training/qf1_loss                     2366.79921   838.90098  5508.71094  815.61047
Training/qf2_loss                     2298.08362   844.33560  5658.32568  781.56555
Training/pf_norm                      0.59838      0.22499    1.47126     0.27860
Training/qf1_norm                     614.90277    405.84058  2114.63037  154.57776
Training/qf2_norm                     732.29680    473.50998  2334.43530  157.57292
log_std/mean                          -0.33561     0.02193    -0.31287    -0.39555
log_std/std                           0.22231      0.00752    0.23546     0.21003
log_std/max                           0.18783      0.02906    0.22872     0.10017
log_std/min                           -1.25683     0.13401    -1.07315    -1.44309
log_probs/mean                        0.40098      0.28388    1.22666     0.09021
log_probs/std                         2.67928      0.15079    3.08118     2.38343
log_probs/max                         9.75468      0.57910    11.19131    8.28898
log_probs/min                         -7.55236     1.08574    -5.58324    -11.22345
mean/mean                             -0.01957     0.01471    0.00312     -0.04365
mean/std                              1.05464      0.04613    1.18448     1.00116
mean/max                              2.45687      0.06639    2.62629     2.36230
mean/min                              -2.05775     0.07374    -1.89682    -2.24971
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 8, 2, 1, 3, 4, 5, 0, 7, 6]
replay_buffer._size: [13650 13650 13650 13650 13650 13650 13650 13650 13650 13650]
2023-08-12 11:51:57,524 MainThread INFO: EPOCH:69
2023-08-12 11:51:57,525 MainThread INFO: Time Consumed:8.181135177612305s
2023-08-12 11:51:57,525 MainThread INFO: Total Frames:135000s
  1%|          | 70/10000 [10:36<24:10:04,  8.76s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               554.66633
Train_Epoch_Reward                    10131.70740
Running_Training_Average_Rewards      1201.01086
Explore_Time                          0.01216
Train___Time                          8.16463
Eval____Time                          0.00348
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.53221
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.55727
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.50343
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.12332
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.28824
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.17297
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.58755
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6263.80390
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.59890
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.77669
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.66542      1.22386    11.33744    5.05575
alpha_0                               0.48986      0.00294    0.49496     0.48473
alpha_1                               0.13693      0.00049    0.13782     0.13613
alpha_2                               0.13847      0.00128    0.14069     0.13629
alpha_3                               0.13793      0.00076    0.13912     0.13655
alpha_4                               0.13133      0.00116    0.13329     0.12933
alpha_5                               0.14383      0.00066    0.14471     0.14251
alpha_6                               0.12960      0.00116    0.13160     0.12762
alpha_7                               0.14442      0.00068    0.14546     0.14312
alpha_8                               0.14407      0.00053    0.14477     0.14306
alpha_9                               0.13876      0.00069    0.13982     0.13750
Alpha_loss                            -6.63871     0.71269    -5.23568    -7.72508
Training/policy_loss                  -81.24658    1.01630    -78.62351   -84.02634
Training/qf1_loss                     2465.06282   829.30499  4877.50537  994.58929
Training/qf2_loss                     2374.02503   818.21462  4848.77881  1034.95935
Training/pf_norm                      0.68581      0.23724    1.37019     0.26541
Training/qf1_norm                     580.30105    374.11968  2215.71899  136.41132
Training/qf2_norm                     717.12776    426.92270  2233.05591  174.34416
log_std/mean                          -0.35523     0.02651    -0.31971    -0.40854
log_std/std                           0.23374      0.01233    0.26156     0.21536
log_std/max                           0.18980      0.06386    0.30541     0.03315
log_std/min                           -1.63829     0.13848    -1.43557    -1.90368
log_probs/mean                        0.74097      0.35921    1.47813     0.20503
log_probs/std                         2.97606      0.13977    3.30323     2.75897
log_probs/max                         10.38468     0.38158    11.30069    9.43967
log_probs/min                         -7.44216     1.08611    -5.02282    -10.09786
mean/mean                             -0.05735     0.01434    -0.03451    -0.08038
mean/std                              1.11051      0.05814    1.22623     1.02269
mean/max                              2.49329      0.07329    2.63346     2.30083
mean/min                              -2.25248     0.05888    -2.11101    -2.43109
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 6, 4, 9, 5, 0, 3, 2, 1, 8]
replay_buffer._size: [13800 13800 13800 13800 13800 13800 13800 13800 13800 13800]
2023-08-12 11:52:05,874 MainThread INFO: EPOCH:70
2023-08-12 11:52:05,875 MainThread INFO: Time Consumed:8.159253120422363s
2023-08-12 11:52:05,875 MainThread INFO: Total Frames:136500s
  1%|          | 71/10000 [10:45<23:48:17,  8.63s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               702.22846
Train_Epoch_Reward                    7820.90232
Running_Training_Average_Rewards      1108.83908
Explore_Time                          0.00418
Train___Time                          8.14871
Eval____Time                          0.00543
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.16455
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.30653
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.51178
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.33024
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.57385
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.45033
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.15315
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7705.78160
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.67320
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.33339
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.17136     1.38474    12.22089    5.43710
alpha_0                               0.50237     0.00479    0.51151     0.49506
alpha_1                               0.13545     0.00035    0.13611     0.13482
alpha_2                               0.13414     0.00121    0.13625     0.13214
alpha_3                               0.13493     0.00094    0.13652     0.13332
alpha_4                               0.12725     0.00120    0.12929     0.12520
alpha_5                               0.14076     0.00098    0.14247     0.13908
alpha_6                               0.12566     0.00111    0.12758     0.12377
alpha_7                               0.14153     0.00090    0.14309     0.13998
alpha_8                               0.14178     0.00074    0.14304     0.14049
alpha_9                               0.13597     0.00089    0.13747     0.13442
Alpha_loss                            -7.41888    0.29060    -6.81631    -7.96878
Training/policy_loss                  -84.60829   1.08140    -81.93988   -86.86626
Training/qf1_loss                     2817.33900  955.30198  5521.03076  949.22150
Training/qf2_loss                     2713.89626  937.59105  5346.12598  928.09991
Training/pf_norm                      0.77905     0.29076    1.71089     0.37637
Training/qf1_norm                     705.46367   441.48885  2530.73242  187.78168
Training/qf2_norm                     829.13186   482.51222  2507.46777  241.81796
log_std/mean                          -0.33141    0.01432    -0.31600    -0.36438
log_std/std                           0.25906     0.00911    0.27607     0.24328
log_std/max                           0.36225     0.07569    0.49095     0.17583
log_std/min                           -1.81878    0.07572    -1.66179    -1.94450
log_probs/mean                        0.43780     0.16265    0.74283     0.10570
log_probs/std                         3.00454     0.10048    3.21742     2.74903
log_probs/max                         10.40902    0.44807    11.48933    9.47396
log_probs/min                         -7.48869    0.94689    -5.56856    -10.07010
mean/mean                             -0.16669    0.05229    -0.07107    -0.24587
mean/std                              1.05129     0.02564    1.09988     1.00964
mean/max                              2.39665     0.05122    2.49420     2.27585
mean/min                              -2.54541    0.19799    -2.26444    -2.97260
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 4, 1, 0, 6, 8, 3, 2, 7, 5]
replay_buffer._size: [13950 13950 13950 13950 13950 13950 13950 13950 13950 13950]
2023-08-12 11:52:15,141 MainThread INFO: EPOCH:71
2023-08-12 11:52:15,142 MainThread INFO: Time Consumed:9.106324434280396s
2023-08-12 11:52:15,142 MainThread INFO: Total Frames:138000s
  1%|          | 72/10000 [10:54<24:18:26,  8.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               581.10400
Train_Epoch_Reward                    7322.05429
Running_Training_Average_Rewards      842.48880
Explore_Time                          0.01673
Train___Time                          9.08421
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.31310
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.88090
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.93513
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.16018
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.02382
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.50773
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.19711
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6489.14253
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.51584
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.56870
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.79469     1.36293    12.51184    4.29392
alpha_0                               0.52042     0.00522    0.52952     0.51170
alpha_1                               0.13434     0.00024    0.13481     0.13399
alpha_2                               0.12997     0.00128    0.13210     0.12775
alpha_3                               0.13177     0.00087    0.13329     0.13031
alpha_4                               0.12319     0.00113    0.12516     0.12129
alpha_5                               0.13738     0.00098    0.13904     0.13568
alpha_6                               0.12191     0.00106    0.12373     0.12010
alpha_7                               0.13839     0.00090    0.13995     0.13687
alpha_8                               0.13931     0.00064    0.14046     0.13825
alpha_9                               0.13284     0.00091    0.13439     0.13129
Alpha_loss                            -7.36829    0.30039    -6.67287    -8.16529
Training/policy_loss                  -87.09846   1.09204    -84.06686   -89.38103
Training/qf1_loss                     2517.27833  854.17437  5208.15918  791.31866
Training/qf2_loss                     2391.87625  833.98912  5198.55908  805.85858
Training/pf_norm                      0.74896     0.28037    1.91671     0.27393
Training/qf1_norm                     713.90570   424.44367  2454.83374  159.55344
Training/qf2_norm                     823.37848   490.98654  2945.76855  221.13011
log_std/mean                          -0.34048    0.01714    -0.28701    -0.36916
log_std/std                           0.26329     0.00857    0.27669     0.24440
log_std/max                           0.48167     0.06968    0.62809     0.31765
log_std/min                           -1.95366    0.09231    -1.74081    -2.14417
log_probs/mean                        0.51674     0.15765    0.89132     0.12969
log_probs/std                         3.11241     0.09567    3.33578     2.82807
log_probs/max                         10.61559    0.39592    11.50860    9.57902
log_probs/min                         -7.34874    0.90590    -5.21330    -9.97592
mean/mean                             -0.19826    0.03285    -0.15339    -0.24248
mean/std                              1.06335     0.02716    1.11749     1.00562
mean/max                              2.27958     0.05287    2.37497     2.14144
mean/min                              -2.55974    0.17325    -2.30632    -2.91891
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 2, 5, 7, 3, 8, 1, 4, 0, 9]
replay_buffer._size: [14100 14100 14100 14100 14100 14100 14100 14100 14100 14100]
2023-08-12 11:52:24,579 MainThread INFO: EPOCH:72
2023-08-12 11:52:24,580 MainThread INFO: Time Consumed:9.275442838668823s
2023-08-12 11:52:24,580 MainThread INFO: Total Frames:139500s
  1%|          | 73/10000 [11:03<24:50:59,  9.01s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               639.92438
Train_Epoch_Reward                    6045.85762
Running_Training_Average_Rewards      706.29381
Explore_Time                          0.00923
Train___Time                          9.26117
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.39780
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.85802
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -32.67494
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.95626
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.90937
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.08693
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.85871
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6983.04129
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.69550
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.35992
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.76682     1.30574    12.27572    4.78992
alpha_0                               0.53963     0.00611    0.54975     0.52969
alpha_1                               0.13338     0.00030    0.13398     0.13297
alpha_2                               0.12553     0.00126    0.12771     0.12338
alpha_3                               0.12887     0.00077    0.13028     0.12757
alpha_4                               0.11941     0.00106    0.12125     0.11763
alpha_5                               0.13372     0.00108    0.13564     0.13191
alpha_6                               0.11829     0.00103    0.12007     0.11655
alpha_7                               0.13511     0.00098    0.13684     0.13347
alpha_8                               0.13715     0.00055    0.13823     0.13629
alpha_9                               0.12969     0.00088    0.13126     0.12822
Alpha_loss                            -7.48380    0.45860    -6.71274    -8.65374
Training/policy_loss                  -89.88928   1.19120    -86.87615   -92.18899
Training/qf1_loss                     2562.68228  959.56604  6533.59717  800.94037
Training/qf2_loss                     2406.17921  929.99068  6499.56250  691.63422
Training/pf_norm                      0.86030     0.40591    2.24020     0.28176
Training/qf1_norm                     717.18322   464.98654  2713.42627  165.10654
Training/qf2_norm                     811.20557   502.53323  3018.38062  195.34474
log_std/mean                          -0.33215    0.02489    -0.27801    -0.35552
log_std/std                           0.27583     0.00830    0.29294     0.26122
log_std/max                           0.48161     0.10377    0.64542     0.23278
log_std/min                           -2.16251    0.07040    -2.03032    -2.30916
log_probs/mean                        0.52806     0.24743    0.94985     -0.11022
log_probs/std                         3.17397     0.10724    3.43229     2.93816
log_probs/max                         11.07670    0.41253    11.72197    9.72295
log_probs/min                         -7.54656    1.14178    -5.24775    -12.57040
mean/mean                             -0.13869    0.01801    -0.10975    -0.16865
mean/std                              1.07358     0.04335    1.13056     0.98266
mean/max                              2.33411     0.07190    2.42601     2.20250
mean/min                              -2.65755    0.15862    -2.40299    -2.97869
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 6, 0, 9, 8, 5, 1, 3, 7, 4]
replay_buffer._size: [14250 14250 14250 14250 14250 14250 14250 14250 14250 14250]
2023-08-12 11:52:33,007 MainThread INFO: EPOCH:73
2023-08-12 11:52:33,007 MainThread INFO: Time Consumed:8.263147830963135s
2023-08-12 11:52:33,008 MainThread INFO: Total Frames:141000s
  1%|          | 74/10000 [11:12<24:20:50,  8.83s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               703.03943
Train_Epoch_Reward                    6698.00820
Running_Training_Average_Rewards      668.86400
Explore_Time                          0.01068
Train___Time                          8.24734
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.81385
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.96238
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.55892
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.53858
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.65898
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.14143
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.08005
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7698.98073
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -86.98188
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.85031
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.75780     1.48850     12.30689    4.88851
alpha_0                               0.55975     0.00592     0.56992     0.54993
alpha_1                               0.13244     0.00033     0.13296     0.13185
alpha_2                               0.12124     0.00121     0.12334     0.11920
alpha_3                               0.12611     0.00082     0.12754     0.12474
alpha_4                               0.11591     0.00097     0.11759     0.11426
alpha_5                               0.12993     0.00112     0.13187     0.12804
alpha_6                               0.11481     0.00099     0.11652     0.11313
alpha_7                               0.13157     0.00109     0.13343     0.12971
alpha_8                               0.13521     0.00059     0.13627     0.13426
alpha_9                               0.12662     0.00091     0.12819     0.12507
Alpha_loss                            -7.72626    0.30233     -7.06528    -8.20029
Training/policy_loss                  -92.38816   1.31256     -89.32018   -95.35330
Training/qf1_loss                     2564.20258  1012.26693  6217.03516  1136.96997
Training/qf2_loss                     2390.59554  971.29456   5837.91016  1044.82642
Training/pf_norm                      0.97000     0.51132     2.91299     0.35085
Training/qf1_norm                     787.34692   530.42405   3006.45508  162.51524
Training/qf2_norm                     926.47497   581.23702   3075.87500  217.35626
log_std/mean                          -0.33770    0.01579     -0.31872    -0.36597
log_std/std                           0.28631     0.00753     0.30270     0.27131
log_std/max                           0.53447     0.07888     0.64416     0.30045
log_std/min                           -2.33943    0.08930     -2.16560    -2.56005
log_probs/mean                        0.45970     0.17036     0.81774     0.17724
log_probs/std                         3.12670     0.07198     3.30520     2.99247
log_probs/max                         11.03354    0.42582     12.41761    9.65106
log_probs/min                         -7.45118    1.02955     -5.91858    -10.90680
mean/mean                             -0.13744    0.02378     -0.10435    -0.18032
mean/std                              1.05710     0.02523     1.10351     1.02237
mean/max                              2.22471     0.06277     2.34263     2.12045
mean/min                              -2.60138    0.17535     -2.30821    -2.96335
------------------------------------  ----------  ----------  ----------  ----------
sample: [0, 1, 7, 3, 8, 6, 2, 9, 5, 4]
replay_buffer._size: [14400 14400 14400 14400 14400 14400 14400 14400 14400 14400]
2023-08-12 11:52:42,325 MainThread INFO: EPOCH:74
2023-08-12 11:52:42,325 MainThread INFO: Time Consumed:9.162119626998901s
2023-08-12 11:52:42,326 MainThread INFO: Total Frames:142500s
  1%|          | 75/10000 [11:21<24:44:11,  8.97s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               692.93879
Train_Epoch_Reward                    7402.14396
Running_Training_Average_Rewards      671.53366
Explore_Time                          0.00399
Train___Time                          9.15340
Eval____Time                          0.00393
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.22413
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.28213
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -31.14171
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.20852
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.64362
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.71151
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.47347
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7547.84135
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.70824
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.06017
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.65720     1.51138    13.14681    4.07195
alpha_0                               0.57976     0.00553    0.58910     0.57013
alpha_1                               0.13098     0.00065    0.13184     0.12966
alpha_2                               0.11726     0.00111    0.11916     0.11534
alpha_3                               0.12331     0.00086    0.12472     0.12179
alpha_4                               0.11264     0.00095    0.11423     0.11098
alpha_5                               0.12620     0.00107    0.12801     0.12436
alpha_6                               0.11147     0.00096    0.11310     0.10982
alpha_7                               0.12777     0.00117    0.12967     0.12571
alpha_8                               0.13327     0.00068    0.13424     0.13198
alpha_9                               0.12345     0.00096    0.12504     0.12176
Alpha_loss                            -8.36105    0.72722    -7.01165    -9.30502
Training/policy_loss                  -94.66743   1.05654    -92.59277   -96.86250
Training/qf1_loss                     2559.38543  970.49208  5491.58398  770.00323
Training/qf2_loss                     2347.46805  954.87861  5260.22021  624.31488
Training/pf_norm                      0.96543     0.42233    2.62596     0.40406
Training/qf1_norm                     802.66606   582.59218  3454.94092  188.16415
Training/qf2_norm                     925.30263   636.77149  3671.50171  228.39160
log_std/mean                          -0.32320    0.02651    -0.28506    -0.36727
log_std/std                           0.30971     0.01667    0.33713     0.28335
log_std/max                           0.55237     0.09923    0.68458     0.32355
log_std/min                           -2.52905    0.10945    -2.34870    -2.75681
log_probs/mean                        0.18871     0.34691    0.86250     -0.24628
log_probs/std                         2.98071     0.10959    3.21311     2.76589
log_probs/max                         10.67815    0.41781    11.59088    9.69520
log_probs/min                         -7.64577    1.04928    -5.77573    -10.90246
mean/mean                             -0.16814    0.01583    -0.13687    -0.19788
mean/std                              0.99646     0.06708    1.10647     0.91332
mean/max                              2.11439     0.07409    2.22863     1.98601
mean/min                              -2.57602    0.17982    -2.32126    -2.95001
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 8, 0, 4, 3, 1, 2, 5, 9, 7]
replay_buffer._size: [14550 14550 14550 14550 14550 14550 14550 14550 14550 14550]
2023-08-12 11:52:51,796 MainThread INFO: EPOCH:75
2023-08-12 11:52:51,796 MainThread INFO: Time Consumed:9.287337303161621s
2023-08-12 11:52:51,796 MainThread INFO: Total Frames:144000s
  1%|          | 76/10000 [11:30<25:10:21,  9.13s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               878.71969
Train_Epoch_Reward                    7346.64525
Running_Training_Average_Rewards      714.89325
Explore_Time                          0.02123
Train___Time                          9.26105
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.83878
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.08009
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.49319
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.23080
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.61025
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.04445
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.01337
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9396.36786
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -81.78016
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.07988
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.44418     1.35591    11.43793    3.78125
alpha_0                               0.59792     0.00523    0.60717     0.58926
alpha_1                               0.12782     0.00109    0.12962     0.12585
alpha_2                               0.11341     0.00109    0.11531     0.11155
alpha_3                               0.12028     0.00085    0.12176     0.11884
alpha_4                               0.10930     0.00095    0.11094     0.10768
alpha_5                               0.12238     0.00116    0.12432     0.12039
alpha_6                               0.10815     0.00095    0.10979     0.10654
alpha_7                               0.12356     0.00123    0.12566     0.12145
alpha_8                               0.13071     0.00071    0.13195     0.12950
alpha_9                               0.12007     0.00096    0.12173     0.11843
Alpha_loss                            -9.09803    0.24130    -8.70744    -9.69746
Training/policy_loss                  -96.99989   1.20919    -94.18722   -100.57870
Training/qf1_loss                     2511.76449  944.88606  5663.84912  894.79047
Training/qf2_loss                     2253.58003  887.64463  5161.33154  644.44574
Training/pf_norm                      1.02754     0.51493    2.75183     0.39260
Training/qf1_norm                     833.02869   469.59761  2643.14282  222.27753
Training/qf2_norm                     904.76751   518.83641  2866.78027  232.01538
log_std/mean                          -0.31860    0.01663    -0.28278    -0.34680
log_std/std                           0.33278     0.00647    0.35390     0.31831
log_std/max                           0.49344     0.07848    0.58557     0.30620
log_std/min                           -2.66040    0.10137    -2.41853    -2.82228
log_probs/mean                        -0.11146    0.11770    0.12692     -0.40585
log_probs/std                         2.91536     0.07513    3.08235     2.64939
log_probs/max                         10.71870    0.35803    11.90172    9.67990
log_probs/min                         -7.33655    1.00076    -5.37636    -10.75137
mean/mean                             -0.10185    0.02667    -0.06656    -0.15798
mean/std                              0.93687     0.01904    0.96156     0.88996
mean/max                              2.05497     0.04311    2.11971     1.97921
mean/min                              -2.49375    0.11047    -2.28228    -2.67697
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 4, 3, 5, 2, 0, 9, 7, 8, 6]
replay_buffer._size: [14700 14700 14700 14700 14700 14700 14700 14700 14700 14700]
2023-08-12 11:53:01,129 MainThread INFO: EPOCH:76
2023-08-12 11:53:01,130 MainThread INFO: Time Consumed:9.162872791290283s
2023-08-12 11:53:01,130 MainThread INFO: Total Frames:145500s
  1%|          | 77/10000 [11:40<25:19:09,  9.19s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               736.02462
Train_Epoch_Reward                    8784.23949
Running_Training_Average_Rewards      784.43429
Explore_Time                          0.00397
Train___Time                          9.15415
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.25423
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.15034
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.60890
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.69563
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.36920
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -44.73890
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.21809
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7933.97943
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -88.19795
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.50000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.61700     1.22142    11.81468    4.34876
alpha_0                               0.61637     0.00500    0.62439     0.60737
alpha_1                               0.12369     0.00125    0.12581     0.12149
alpha_2                               0.10976     0.00101    0.11152     0.10806
alpha_3                               0.11742     0.00082    0.11881     0.11599
alpha_4                               0.10606     0.00092    0.10765     0.10451
alpha_5                               0.11859     0.00100    0.12035     0.11685
alpha_6                               0.10493     0.00091    0.10651     0.10338
alpha_7                               0.11945     0.00114    0.12141     0.11746
alpha_8                               0.12837     0.00068    0.12948     0.12710
alpha_9                               0.11682     0.00092    0.11840     0.11523
Alpha_loss                            -9.20278    0.23152    -8.70202    -9.64936
Training/policy_loss                  -99.62049   1.24155    -96.90224   -102.76849
Training/qf1_loss                     2525.35151  896.57798  5245.29785  843.77069
Training/qf2_loss                     2266.80151  854.14549  4633.50635  595.39856
Training/pf_norm                      1.36144     0.81324    5.12401     0.31550
Training/qf1_norm                     730.06659   444.33946  2883.97168  201.36322
Training/qf2_norm                     854.41453   517.35834  2989.23901  228.23793
log_std/mean                          -0.33738    0.01208    -0.32519    -0.38230
log_std/std                           0.32546     0.00594    0.33808     0.30845
log_std/max                           0.32225     0.04100    0.42226     0.21838
log_std/min                           -2.66978    0.08593    -2.47463    -2.83650
log_probs/mean                        -0.11923    0.11374    0.13424     -0.34975
log_probs/std                         2.85571     0.09940    3.06357     2.62991
log_probs/max                         10.48409    0.32353    11.38514    9.81154
log_probs/min                         -7.26390    1.05785    -5.62673    -10.97853
mean/mean                             -0.08851    0.04122    0.02968     -0.14850
mean/std                              0.93128     0.02011    0.97386     0.89682
mean/max                              2.16577     0.15008    2.74006     2.02279
mean/min                              -2.39408    0.11818    -2.20171    -2.67946
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 1, 3, 2, 6, 8, 4, 0, 7, 5]
replay_buffer._size: [14850 14850 14850 14850 14850 14850 14850 14850 14850 14850]
2023-08-12 11:53:10,452 MainThread INFO: EPOCH:77
2023-08-12 11:53:10,453 MainThread INFO: Time Consumed:9.1289803981781s
2023-08-12 11:53:10,453 MainThread INFO: Total Frames:147000s
  1%|          | 78/10000 [11:49<25:25:17,  9.22s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               865.30046
Train_Epoch_Reward                    7673.13700
Running_Training_Average_Rewards      793.46739
Explore_Time                          0.00842
Train___Time                          9.11617
Eval____Time                          0.00366
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.82939
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.42976
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.28629
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.54572
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.54816
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.18807
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.75315
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9235.27627
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.95360
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.73754
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.61542     1.24321    10.87455    5.05229
alpha_0                               0.63083     0.00345    0.63687     0.62453
alpha_1                               0.11942     0.00117    0.12145     0.11746
alpha_2                               0.10661     0.00082    0.10803     0.10519
alpha_3                               0.11460     0.00076    0.11596     0.11338
alpha_4                               0.10326     0.00071    0.10448     0.10200
alpha_5                               0.11488     0.00110    0.11682     0.11309
alpha_6                               0.10190     0.00084    0.10335     0.10047
alpha_7                               0.11556     0.00101    0.11742     0.11402
alpha_8                               0.12595     0.00056    0.12708     0.12534
alpha_9                               0.11371     0.00084    0.11520     0.11234
Alpha_loss                            -8.32623    0.54596    -7.34637    -9.20195
Training/policy_loss                  -102.36848  1.39776    -99.35899   -105.47759
Training/qf1_loss                     2499.13443  862.79747  5206.74365  1148.87537
Training/qf2_loss                     2200.18876  818.02309  4824.99023  925.64105
Training/pf_norm                      1.50929     0.72600    3.34002     0.58771
Training/qf1_norm                     797.42586   454.73516  2434.34424  202.32135
Training/qf2_norm                     904.37093   492.28108  2433.12329  274.88568
log_std/mean                          -0.40415    0.01251    -0.38308    -0.42318
log_std/std                           0.31280     0.01035    0.33117     0.28888
log_std/max                           0.16127     0.02588    0.21161     0.11279
log_std/min                           -2.74440    0.08671    -2.56310    -2.89919
log_probs/mean                        0.30056     0.27465    0.80358     -0.12479
log_probs/std                         2.77591     0.13539    3.08820     2.52967
log_probs/max                         10.75077    0.42226    11.84988    9.70167
log_probs/min                         -7.65941    1.28243    -5.74670    -14.32106
mean/mean                             -0.01238    0.06869    0.08076     -0.13667
mean/std                              1.00272     0.05265    1.09637     0.91676
mean/max                              2.33178     0.29258    2.88014     1.90087
mean/min                              -2.33196    0.09265    -2.14428    -2.49164
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 9, 2, 0, 6, 4, 8, 1, 7, 5]
replay_buffer._size: [15000 15000 15000 15000 15000 15000 15000 15000 15000 15000]
2023-08-12 11:53:19,757 MainThread INFO: EPOCH:78
2023-08-12 11:53:19,758 MainThread INFO: Time Consumed:9.115406036376953s
2023-08-12 11:53:19,758 MainThread INFO: Total Frames:148500s
  1%|          | 79/10000 [11:58<25:30:50,  9.26s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               764.97075
Train_Epoch_Reward                    8675.96578
Running_Training_Average_Rewards      837.77808
Explore_Time                          0.00450
Train___Time                          9.10598
Eval____Time                          0.00413
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.17563
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.62248
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.70825
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -72.90785
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.79930
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.96909
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.97776
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8244.35748
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.79890
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.69068
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.81697     1.49267     12.54358    4.87393
alpha_0                               0.64219     0.00314     0.64769     0.63698
alpha_1                               0.11565     0.00101     0.11742     0.11393
alpha_2                               0.10383     0.00076     0.10516     0.10257
alpha_3                               0.11216     0.00073     0.11336     0.11085
alpha_4                               0.10062     0.00078     0.10197     0.09929
alpha_5                               0.11141     0.00096     0.11306     0.10975
alpha_6                               0.09905     0.00080     0.10044     0.09768
alpha_7                               0.11265     0.00081     0.11399     0.11123
alpha_8                               0.12490     0.00036     0.12534     0.12413
alpha_9                               0.11096     0.00082     0.11232     0.10951
Alpha_loss                            -8.15245    0.26605     -7.56447    -8.75067
Training/policy_loss                  -104.49291  1.48424     -100.81561  -107.95509
Training/qf1_loss                     2663.83455  1073.05737  7194.95020  974.65265
Training/qf2_loss                     2321.45838  994.82978   6505.40967  689.79999
Training/pf_norm                      1.72904     1.00595     5.74253     0.45958
Training/qf1_norm                     931.57710   638.71430   3255.32178  183.73627
Training/qf2_norm                     1041.63794  700.01751   3975.68726  318.07703
log_std/mean                          -0.39094    0.00926     -0.37113    -0.40509
log_std/std                           0.30866     0.01438     0.33806     0.28356
log_std/max                           0.24995     0.05448     0.32884     0.16131
log_std/min                           -2.74548    0.14519     -2.48596    -3.00645
log_probs/mean                        0.41650     0.12259     0.68242     0.17409
log_probs/std                         2.76002     0.09023     2.98234     2.54471
log_probs/max                         10.91848    0.34112     11.78222    9.92945
log_probs/min                         -7.67392    1.09290     -5.87783    -11.63061
mean/mean                             -0.14322    0.01886     -0.11045    -0.17573
mean/std                              1.02328     0.02714     1.07133     0.97443
mean/max                              2.07567     0.09355     2.28934     1.88431
mean/min                              -2.20108    0.08358     -2.08246    -2.37049
------------------------------------  ----------  ----------  ----------  ----------
sample: [7, 5, 2, 1, 3, 9, 6, 8, 4, 0]
replay_buffer._size: [15150 15150 15150 15150 15150 15150 15150 15150 15150 15150]
2023-08-12 11:53:28,697 MainThread INFO: EPOCH:79
2023-08-12 11:53:28,697 MainThread INFO: Time Consumed:8.762449979782104s
2023-08-12 11:53:28,697 MainThread INFO: Total Frames:150000s
  1%|          | 80/10000 [12:07<25:13:15,  9.15s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               879.71024
Train_Epoch_Reward                    8370.64058
Running_Training_Average_Rewards      823.99145
Explore_Time                          0.01239
Train___Time                          8.74534
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.22506
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.56775
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.82233
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.67097
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.41464
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.87336
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.01377
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9427.88751
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.71945
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.47777
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.76035     1.61012     14.35996    4.77680
alpha_0                               0.65356     0.00299     0.65844     0.64783
alpha_1                               0.11218     0.00102     0.11390     0.11040
alpha_2                               0.10136     0.00071     0.10255     0.10011
alpha_3                               0.10934     0.00087     0.11082     0.10785
alpha_4                               0.09795     0.00077     0.09926     0.09661
alpha_5                               0.10812     0.00093     0.10972     0.10653
alpha_6                               0.09628     0.00080     0.09765     0.09491
alpha_7                               0.10975     0.00086     0.11120     0.10827
alpha_8                               0.12291     0.00073     0.12410     0.12168
alpha_9                               0.10791     0.00093     0.10948     0.10630
Alpha_loss                            -8.81494    0.31824     -8.20761    -9.40564
Training/policy_loss                  -106.59843  1.28368     -103.76842  -109.63804
Training/qf1_loss                     2766.74114  1200.99301  8208.43555  1124.15918
Training/qf2_loss                     2369.76220  1122.14749  7543.37354  850.39746
Training/pf_norm                      1.81914     1.17239     6.79635     0.40189
Training/qf1_norm                     981.33267   683.59993   4547.79199  202.29404
Training/qf2_norm                     1121.75520  788.66701   4919.24268  250.91231
log_std/mean                          -0.38504    0.01148     -0.36637    -0.40991
log_std/std                           0.33880     0.00887     0.36379     0.31869
log_std/max                           0.24265     0.04494     0.29870     0.16481
log_std/min                           -2.94846    0.09986     -2.75363    -3.15453
log_probs/mean                        0.15155     0.14766     0.42466     -0.11563
log_probs/std                         2.66018     0.07187     2.88352     2.46263
log_probs/max                         10.76790    0.44054     11.95068    9.80806
log_probs/min                         -7.49065    0.87603     -5.63398    -9.66782
mean/mean                             -0.16318    0.04730     -0.08627    -0.22038
mean/std                              0.96513     0.02481     1.01748     0.92264
mean/max                              2.15655     0.09771     2.31218     1.94250
mean/min                              -2.18529    0.04066     -2.05494    -2.25990
------------------------------------  ----------  ----------  ----------  ----------
sample: [8, 5, 4, 6, 7, 3, 2, 0, 1, 9]
replay_buffer._size: [15300 15300 15300 15300 15300 15300 15300 15300 15300 15300]
2023-08-12 11:53:37,271 MainThread INFO: EPOCH:80
2023-08-12 11:53:37,271 MainThread INFO: Time Consumed:8.395827293395996s
2023-08-12 11:53:37,271 MainThread INFO: Total Frames:151500s
  1%|          | 81/10000 [12:16<24:44:50,  8.98s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2209.78728
Train_Epoch_Reward                    9558.06722
Running_Training_Average_Rewards      886.82245
Explore_Time                          0.00423
Train___Time                          8.38563
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.89020
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.88244
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.55876
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.75128
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.78800
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.26190
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.64032
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 22713.77169
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.01385
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.11218
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.04825      1.41231    11.85647    4.56348
alpha_0                               0.66512      0.00498    0.67417     0.65852
alpha_1                               0.10847      0.00107    0.11036     0.10673
alpha_2                               0.09871      0.00080    0.10009     0.09737
alpha_3                               0.10641      0.00079    0.10782     0.10510
alpha_4                               0.09518      0.00082    0.09658     0.09377
alpha_5                               0.10499      0.00082    0.10649     0.10371
alpha_6                               0.09355      0.00076    0.09489     0.09229
alpha_7                               0.10680      0.00078    0.10824     0.10557
alpha_8                               0.12071      0.00045    0.12166     0.12016
alpha_9                               0.10466      0.00091    0.10626     0.10313
Alpha_loss                            -8.69095     0.75278    -7.37306    -9.71157
Training/policy_loss                  -109.44506   1.74307    -105.00191  -114.15205
Training/qf1_loss                     2854.94177   911.90266  5527.79541  1025.16199
Training/qf2_loss                     2461.47858   885.13959  5049.67969  770.33698
Training/pf_norm                      1.98292      1.07788    6.17712     0.55266
Training/qf1_norm                     987.63849    585.57684  3126.14844  207.91965
Training/qf2_norm                     1155.34639   653.27173  3821.85645  377.36667
log_std/mean                          -0.40831     0.02616    -0.36624    -0.45604
log_std/std                           0.34855      0.01284    0.36884     0.31987
log_std/max                           0.15015      0.05449    0.23704     0.04448
log_std/min                           -3.03048     0.11385    -2.76115    -3.22628
log_probs/mean                        0.29938      0.37957    0.96496     -0.26371
log_probs/std                         2.84502      0.15583    3.14000     2.53845
log_probs/max                         11.15466     0.72677    12.48316    9.39780
log_probs/min                         -7.59963     1.15148    -5.87473    -13.45441
mean/mean                             -0.01232     0.02676    0.02562     -0.08576
mean/std                              0.99826      0.06967    1.10791     0.90139
mean/max                              2.29778      0.11574    2.48189     1.99987
mean/min                              -2.15634     0.06084    -2.01911    -2.29046
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 8, 4, 6, 7, 1, 9, 3, 2, 5]
replay_buffer._size: [15450 15450 15450 15450 15450 15450 15450 15450 15450 15450]
2023-08-12 11:53:46,128 MainThread INFO: EPOCH:81
2023-08-12 11:53:46,128 MainThread INFO: Time Consumed:8.666173458099365s
2023-08-12 11:53:46,128 MainThread INFO: Total Frames:153000s
  1%|          | 82/10000 [12:25<24:37:58,  8.94s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2301.41551
Train_Epoch_Reward                    22706.23749
Running_Training_Average_Rewards      1354.49818
Explore_Time                          0.00611
Train___Time                          8.65548
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.38970
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.36320
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.74729
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.84615
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.41485
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.31013
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.89458
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 23608.78177
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.65450
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.00624
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.81311      1.30648    11.46295    4.77547
alpha_0                               0.68265      0.00498    0.69126     0.67433
alpha_1                               0.10501      0.00100    0.10670     0.10328
alpha_2                               0.09602      0.00077    0.09734     0.09470
alpha_3                               0.10367      0.00083    0.10508     0.10225
alpha_4                               0.09235      0.00082    0.09374     0.09095
alpha_5                               0.10242      0.00078    0.10369     0.10105
alpha_6                               0.09102      0.00073    0.09227     0.08977
alpha_7                               0.10429      0.00076    0.10555     0.10299
alpha_8                               0.11938      0.00049    0.12015     0.11853
alpha_9                               0.10155      0.00091    0.10310     0.10000
Alpha_loss                            -8.93788     0.38754    -8.04824    -9.59002
Training/policy_loss                  -111.37501   1.57660    -106.92677  -116.42791
Training/qf1_loss                     2846.48502   891.57126  5652.57617  1369.55396
Training/qf2_loss                     2388.90610   821.91087  4980.39209  877.51935
Training/pf_norm                      1.84633      0.98777    5.04126     0.41136
Training/qf1_norm                     906.57413    524.70497  2980.83521  246.26491
Training/qf2_norm                     1063.18076   604.16655  3186.10742  311.61124
log_std/mean                          -0.40708     0.01662    -0.37926    -0.43861
log_std/std                           0.34630      0.00872    0.36849     0.32442
log_std/max                           0.12985      0.05521    0.23994     0.05603
log_std/min                           -3.06924     0.09687    -2.86790    -3.27282
log_probs/mean                        0.23923      0.18124    0.61873     -0.13221
log_probs/std                         2.82864      0.08322    3.04007     2.65107
log_probs/max                         11.27044     0.51065    12.64976    9.63809
log_probs/min                         -7.56564     1.11637    -5.76228    -10.97462
mean/mean                             -0.00354     0.02449    0.04218     -0.04201
mean/std                              0.99120      0.03233    1.04790     0.93730
mean/max                              2.49624      0.24221    2.95377     2.11636
mean/min                              -2.22440     0.04114    -2.12184    -2.30996
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 6, 0, 7, 2, 9, 5, 8, 1, 4]
replay_buffer._size: [15600 15600 15600 15600 15600 15600 15600 15600 15600 15600]
2023-08-12 11:53:54,389 MainThread INFO: EPOCH:82
2023-08-12 11:53:54,389 MainThread INFO: Time Consumed:8.073838233947754s
2023-08-12 11:53:54,389 MainThread INFO: Total Frames:154500s
  1%|          | 83/10000 [12:33<24:06:22,  8.75s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2111.68727
Train_Epoch_Reward                    22724.15608
Running_Training_Average_Rewards      1832.94869
Explore_Time                          0.00647
Train___Time                          8.06300
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.69282
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.25262
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.71128
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.33509
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.77115
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.40918
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.98826
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 21686.01645
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.76117
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.22223
mean_success_rate                     0.20000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.65811      1.34057     11.54209    4.48534
alpha_0                               0.69981      0.00502     0.70882     0.69141
alpha_1                               0.10155      0.00097     0.10324     0.09997
alpha_2                               0.09335      0.00077     0.09468     0.09205
alpha_3                               0.10082      0.00081     0.10222     0.09946
alpha_4                               0.08953      0.00081     0.09092     0.08816
alpha_5                               0.09974      0.00073     0.10103     0.09854
alpha_6                               0.08851      0.00072     0.08974     0.08729
alpha_7                               0.10164      0.00075     0.10296     0.10045
alpha_8                               0.11758      0.00050     0.11851     0.11693
alpha_9                               0.09849      0.00084     0.09997     0.09708
Alpha_loss                            -8.83815     0.47388     -7.86712    -9.60623
Training/policy_loss                  -113.27261   1.98374     -109.34350  -118.91579
Training/qf1_loss                     2702.43564   1003.40532  5459.05615  785.70850
Training/qf2_loss                     2240.49652   916.05810   4688.79053  587.92468
Training/pf_norm                      2.00504      1.25566     6.58050     0.54883
Training/qf1_norm                     965.24770    572.21813   3194.63086  256.72061
Training/qf2_norm                     1063.13718   608.50246   3783.09497  313.40326
log_std/mean                          -0.42804     0.02442     -0.38683    -0.46519
log_std/std                           0.34206      0.00813     0.36204     0.30844
log_std/max                           0.06562      0.05030     0.15709     -0.00057
log_std/min                           -3.09568     0.08081     -2.85867    -3.22189
log_probs/mean                        0.33649      0.23052     0.78095     -0.05148
log_probs/std                         2.87681      0.08177     3.07132     2.70960
log_probs/max                         11.30553     0.43647     12.26535    9.98549
log_probs/min                         -7.55130     1.03096     -5.68167    -12.10396
mean/mean                             0.00888      0.02159     0.07135     -0.02835
mean/std                              1.00692      0.03841     1.08411     0.94638
mean/max                              2.88211      0.23733     3.19991     2.31042
mean/min                              -2.44087     0.14334     -2.15667    -2.66823
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 0, 7, 8, 5, 6, 2, 1, 9, 3]
replay_buffer._size: [15750 15750 15750 15750 15750 15750 15750 15750 15750 15750]
2023-08-12 11:54:03,556 MainThread INFO: EPOCH:83
2023-08-12 11:54:03,557 MainThread INFO: Time Consumed:8.965856790542603s
2023-08-12 11:54:03,557 MainThread INFO: Total Frames:156000s
  1%|          | 84/10000 [12:42<24:26:18,  8.87s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2138.78940
Train_Epoch_Reward                    20266.17867
Running_Training_Average_Rewards      2189.88574
Explore_Time                          0.00435
Train___Time                          8.95647
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.03277
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.58139
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.63529
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.85840
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.07231
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.17736
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.99475
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 21923.28756
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.57251
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.46874
mean_success_rate                     0.20000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.77086      1.33490     11.60791    4.66289
alpha_0                               0.71791      0.00549     0.72794     0.70902
alpha_1                               0.09858      0.00078     0.09994     0.09730
alpha_2                               0.09076      0.00074     0.09202     0.08951
alpha_3                               0.09804      0.00080     0.09943     0.09670
alpha_4                               0.08683      0.00075     0.08813     0.08555
alpha_5                               0.09740      0.00062     0.09851     0.09638
alpha_6                               0.08613      0.00066     0.08727     0.08502
alpha_7                               0.09936      0.00062     0.10043     0.09832
alpha_8                               0.11639      0.00032     0.11693     0.11589
alpha_9                               0.09568      0.00079     0.09705     0.09436
Alpha_loss                            -8.28817     0.33205     -7.65239    -9.03189
Training/policy_loss                  -115.73830   1.90715     -111.19116  -121.02844
Training/qf1_loss                     2909.13508   1049.72659  6159.88721  1322.26257
Training/qf2_loss                     2369.19821   981.27425   5213.25928  841.87207
Training/pf_norm                      2.50547      1.56362     8.07122     0.50615
Training/qf1_norm                     996.54923    576.31866   3130.86182  230.41759
Training/qf2_norm                     1113.59463   648.81894   3270.00537  362.58423
log_std/mean                          -0.43734     0.01195     -0.41260    -0.45838
log_std/std                           0.32860      0.01062     0.34768     0.30431
log_std/max                           0.09891      0.03977     0.16195     0.01665
log_std/min                           -3.05803     0.07407     -2.88053    -3.19131
log_probs/mean                        0.62103      0.17117     0.90468     0.22459
log_probs/std                         2.89079      0.07271     3.06349     2.66694
log_probs/max                         11.37053     0.42004     12.60277    10.31047
log_probs/min                         -7.47289     0.99856     -5.93670    -11.06586
mean/mean                             0.03705      0.03720     0.09631     -0.03365
mean/std                              1.06160      0.02791     1.11124     1.00177
mean/max                              3.06430      0.35812     3.71030     2.32122
mean/min                              -2.57954     0.06334     -2.32859    -2.69987
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 3, 0, 8, 2, 6, 1, 4, 9, 5]
replay_buffer._size: [15900 15900 15900 15900 15900 15900 15900 15900 15900 15900]
2023-08-12 11:54:12,470 MainThread INFO: EPOCH:84
2023-08-12 11:54:12,471 MainThread INFO: Time Consumed:8.74235224723816s
2023-08-12 11:54:12,471 MainThread INFO: Total Frames:157500s
  1%|          | 85/10000 [12:51<24:26:47,  8.88s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1975.48500
Train_Epoch_Reward                    21940.22173
Running_Training_Average_Rewards      2164.35188
Explore_Time                          0.00360
Train___Time                          8.73358
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.47453
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.40801
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.74669
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.32356
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.70625
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.22545
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.49892
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 20322.03001
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.63316
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.16349
mean_success_rate                     0.20000

Name                                  Mean         Std         Max         Min
Reward_Mean                           8.03562      1.57718     12.70187    5.37727
alpha_0                               0.73856      0.00596     0.74878     0.72815
alpha_1                               0.09611      0.00066     0.09727     0.09499
alpha_2                               0.08833      0.00067     0.08948     0.08717
alpha_3                               0.09542      0.00073     0.09668     0.09416
alpha_4                               0.08426      0.00073     0.08552     0.08301
alpha_5                               0.09524      0.00064     0.09635     0.09415
alpha_6                               0.08396      0.00060     0.08500     0.08293
alpha_7                               0.09730      0.00058     0.09830     0.09628
alpha_8                               0.11538      0.00034     0.11588     0.11472
alpha_9                               0.09309      0.00072     0.09433     0.09187
Alpha_loss                            -8.01525     0.24064     -7.57683    -8.70261
Training/policy_loss                  -118.38888   1.97071     -113.11050  -123.10811
Training/qf1_loss                     3022.34037   1127.37682  6281.91797  1141.82458
Training/qf2_loss                     2409.40431   985.84976   5072.82568  778.74390
Training/pf_norm                      2.65568      1.50449     6.83968     0.62288
Training/qf1_norm                     1212.16701   730.10447   3624.74463  313.38202
Training/qf2_norm                     1267.96872   798.28013   3491.79541  328.84467
log_std/mean                          -0.45524     0.00821     -0.43216    -0.47219
log_std/std                           0.31703      0.00731     0.33164     0.29653
log_std/max                           0.08697      0.02586     0.13680     0.02762
log_std/min                           -3.05477     0.05009     -2.83724    -3.15297
log_probs/mean                        0.78096      0.10798     0.99954     0.46058
log_probs/std                         2.86266      0.07177     3.07059     2.71005
log_probs/max                         11.24892     0.42931     12.37837    10.26504
log_probs/min                         -7.59939     1.16333     -5.79802    -11.35195
mean/mean                             0.00302      0.03662     0.06748     -0.07672
mean/std                              1.08993      0.01658     1.12712     1.04730
mean/max                              3.46591      0.32804     3.92834     2.76216
mean/min                              -2.65142     0.05810     -2.52726    -2.76508
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 2, 9, 8, 0, 5, 6, 7, 1, 3]
replay_buffer._size: [16050 16050 16050 16050 16050 16050 16050 16050 16050 16050]
2023-08-12 11:54:21,729 MainThread INFO: EPOCH:85
2023-08-12 11:54:21,729 MainThread INFO: Time Consumed:9.063056468963623s
2023-08-12 11:54:21,729 MainThread INFO: Total Frames:159000s
  1%|          | 86/10000 [13:00<24:45:09,  8.99s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1809.46180
Train_Epoch_Reward                    19291.37929
Running_Training_Average_Rewards      2049.92599
Explore_Time                          0.01301
Train___Time                          9.04484
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.34378
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.30626
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.33322
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.23325
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.20536
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.79386
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.63043
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18641.78648
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.21669
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.10564
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.02018      1.43842    12.54921    4.91068
alpha_0                               0.75911      0.00637    0.77111     0.74898
alpha_1                               0.09380      0.00066    0.09497     0.09275
alpha_2                               0.08596      0.00069    0.08715     0.08483
alpha_3                               0.09279      0.00077    0.09413     0.09153
alpha_4                               0.08172      0.00073    0.08298     0.08050
alpha_5                               0.09290      0.00070    0.09412     0.09175
alpha_6                               0.08187      0.00060    0.08291     0.08088
alpha_7                               0.09510      0.00065    0.09626     0.09406
alpha_8                               0.11387      0.00040    0.11470     0.11341
alpha_9                               0.09059      0.00071    0.09184     0.08941
Alpha_loss                            -8.18681     0.71970    -6.67459    -9.11223
Training/policy_loss                  -120.41794   1.92931    -115.30141  -124.71079
Training/qf1_loss                     3081.43154   937.06663  6214.89551  1228.25757
Training/qf2_loss                     2471.04896   871.42625  5284.17725  873.29651
Training/pf_norm                      2.45737      1.39544    7.66101     0.64785
Training/qf1_norm                     1176.76240   676.37536  4079.44019  257.22437
Training/qf2_norm                     1280.29020   640.12865  3883.36230  431.44055
log_std/mean                          -0.45365     0.03080    -0.41646    -0.50742
log_std/std                           0.30913      0.00897    0.33463     0.28442
log_std/max                           0.09605      0.03219    0.15842     0.03470
log_std/min                           -3.05306     0.04059    -2.87801    -3.10994
log_probs/mean                        0.75557      0.33908    1.43995     0.27922
log_probs/std                         2.88243      0.09183    3.09634     2.59773
log_probs/max                         11.35313     0.55683    12.83510    10.19521
log_probs/min                         -7.44903     0.92680    -5.86660    -10.05822
mean/mean                             -0.01524     0.03897    0.07475     -0.06834
mean/std                              1.08699      0.05070    1.18499     1.01131
mean/max                              3.68766      0.40501    4.37653     2.81596
mean/min                              -2.74052     0.06643    -2.58397    -2.85725
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 4, 5, 1, 6, 8, 9, 7, 0, 3]
replay_buffer._size: [16200 16200 16200 16200 16200 16200 16200 16200 16200 16200]
2023-08-12 11:54:30,886 MainThread INFO: EPOCH:86
2023-08-12 11:54:30,887 MainThread INFO: Time Consumed:8.96919298171997s
2023-08-12 11:54:30,887 MainThread INFO: Total Frames:160500s
  1%|          | 87/10000 [13:10<24:55:20,  9.05s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1560.77739
Train_Epoch_Reward                    17498.83413
Running_Training_Average_Rewards      1957.68117
Explore_Time                          0.00447
Train___Time                          8.96068
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.11937
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.79501
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.58056
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -38.54628
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.35144
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.60044
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.10497
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16145.28966
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.24996
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.16773
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.98350      1.35721    11.98743    4.69250
alpha_0                               0.78360      0.00729    0.79699     0.77137
alpha_1                               0.09190      0.00047    0.09274     0.09113
alpha_2                               0.08387      0.00056    0.08481     0.08291
alpha_3                               0.09034      0.00069    0.09150     0.08914
alpha_4                               0.07938      0.00065    0.08048     0.07826
alpha_5                               0.09070      0.00059    0.09173     0.08970
alpha_6                               0.08003      0.00051    0.08086     0.07913
alpha_7                               0.09303      0.00059    0.09404     0.09202
alpha_8                               0.11303      0.00026    0.11340     0.11258
alpha_9                               0.08831      0.00063    0.08939     0.08722
Alpha_loss                            -7.20573     0.35523    -6.34053    -8.04860
Training/policy_loss                  -123.21678   1.72165    -119.27728  -127.14307
Training/qf1_loss                     3060.07974   971.34667  7299.05713  1260.37390
Training/qf2_loss                     2402.86339   858.38472  6154.92041  831.52386
Training/pf_norm                      2.22804      1.26196    5.26294     0.48377
Training/qf1_norm                     1100.59801   655.88837  4188.89648  292.47717
Training/qf2_norm                     1225.90949   637.46266  3841.33667  366.31842
log_std/mean                          -0.48692     0.02147    -0.44975    -0.52196
log_std/std                           0.28974      0.00883    0.31196     0.26648
log_std/max                           0.11726      0.02023    0.18213     0.07090
log_std/min                           -3.03449     0.07334    -2.68837    -3.15456
log_probs/mean                        1.21268      0.15018    1.55651     0.84242
log_probs/std                         2.86004      0.08292    3.03956     2.66574
log_probs/max                         11.39972     0.40034    12.50597    10.63803
log_probs/min                         -7.92435     1.21582    -5.87303    -13.75245
mean/mean                             -0.04759     0.06843    0.08148     -0.11450
mean/std                              1.16194      0.01716    1.19276     1.12754
mean/max                              3.90716      0.39564    4.54690     3.07111
mean/min                              -2.86836     0.10978    -2.64763    -3.00941
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 5, 9, 1, 8, 7, 3, 2, 4, 0]
replay_buffer._size: [16350 16350 16350 16350 16350 16350 16350 16350 16350 16350]
2023-08-12 11:54:39,938 MainThread INFO: EPOCH:87
2023-08-12 11:54:39,938 MainThread INFO: Time Consumed:8.865546941757202s
2023-08-12 11:54:39,938 MainThread INFO: Total Frames:162000s
  1%|          | 88/10000 [13:19<24:53:30,  9.04s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               829.55409
Train_Epoch_Reward                    15049.03861
Running_Training_Average_Rewards      1727.97507
Explore_Time                          0.00907
Train___Time                          8.85154
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.02240
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.16114
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.75507
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.86137
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.75059
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.90180
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.79052
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8811.54184
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.83532
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.92272
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.93433      1.33605    11.40106    4.66815
alpha_0                               0.81007      0.00712    0.82204     0.79728
alpha_1                               0.09032      0.00049    0.09112     0.08946
alpha_2                               0.08198      0.00053    0.08289     0.08109
alpha_3                               0.08793      0.00068    0.08911     0.08679
alpha_4                               0.07715      0.00063    0.07824     0.07608
alpha_5                               0.08857      0.00067    0.08968     0.08740
alpha_6                               0.07825      0.00049    0.07911     0.07743
alpha_7                               0.09087      0.00069    0.09200     0.08968
alpha_8                               0.11208      0.00031    0.11258     0.11156
alpha_9                               0.08613      0.00062    0.08720     0.08508
Alpha_loss                            -7.41980     0.22398    -6.92172    -7.96767
Training/policy_loss                  -125.24799   2.48803    -119.90327  -131.05757
Training/qf1_loss                     3165.99481   994.05704  5820.73486  1412.01550
Training/qf2_loss                     2406.00460   889.29876  5096.10010  704.77484
Training/pf_norm                      2.70215      1.60686    7.76280     0.66901
Training/qf1_norm                     1142.79100   736.27190  3784.10352  224.22026
Training/qf2_norm                     1248.83427   704.06072  3699.07007  388.52921
log_std/mean                          -0.49255     0.01068    -0.47302    -0.51750
log_std/std                           0.28747      0.00894    0.30817     0.26844
log_std/max                           0.10297      0.01647    0.14895     0.07229
log_std/min                           -3.07043     0.08738    -2.66756    -3.15712
log_probs/mean                        1.13984      0.10518    1.35669     0.90289
log_probs/std                         2.80731      0.06932    2.97472     2.67959
log_probs/max                         11.04754     0.51443    12.31808    9.99175
log_probs/min                         -7.54933     1.03663    -6.01030    -10.97009
mean/mean                             -0.02387     0.03483    0.04736     -0.09435
mean/std                              1.14946      0.01485    1.17996     1.11810
mean/max                              4.02026      0.38427    4.48117     3.20850
mean/min                              -2.93169     0.05547    -2.68092    -3.05541
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 6, 9, 1, 8, 0, 4, 7, 3, 5]
replay_buffer._size: [16500 16500 16500 16500 16500 16500 16500 16500 16500 16500]
2023-08-12 11:54:49,097 MainThread INFO: EPOCH:88
2023-08-12 11:54:49,098 MainThread INFO: Time Consumed:8.945009708404541s
2023-08-12 11:54:49,098 MainThread INFO: Total Frames:163500s
  1%|          | 89/10000 [13:28<24:59:14,  9.08s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               645.56221
Train_Epoch_Reward                    8947.53566
Running_Training_Average_Rewards      1383.18028
Explore_Time                          0.00461
Train___Time                          8.93601
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.72548
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.58020
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.03795
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.46456
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.13345
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.63225
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.05309
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6978.12486
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.03165
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.84414
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.81287     1.36381     12.57303    5.10448
alpha_0                               0.83389     0.00695     0.84587     0.82229
alpha_1                               0.08851     0.00054     0.08944     0.08764
alpha_2                               0.08028     0.00042     0.08107     0.07962
alpha_3                               0.08574     0.00056     0.08676     0.08484
alpha_4                               0.07511     0.00052     0.07606     0.07426
alpha_5                               0.08618     0.00068     0.08737     0.08510
alpha_6                               0.07667     0.00041     0.07741     0.07599
alpha_7                               0.08857     0.00059     0.08966     0.08768
alpha_8                               0.11128     0.00012     0.11156     0.11114
alpha_9                               0.08414     0.00051     0.08506     0.08334
Alpha_loss                            -6.34737    0.87840     -5.04798    -7.89058
Training/policy_loss                  -127.25086  2.17638     -122.58864  -133.20769
Training/qf1_loss                     3077.75424  1083.56880  7331.26270  1300.82764
Training/qf2_loss                     2320.13015  913.62893   5807.40771  719.48187
Training/pf_norm                      2.38074     1.38853     6.63573     0.67071
Training/qf1_norm                     1169.44888  716.88746   3647.42969  360.38507
Training/qf2_norm                     1273.49667  686.60290   4183.40674  505.31924
log_std/mean                          -0.53672    0.03002     -0.48625    -0.57837
log_std/std                           0.28610     0.00923     0.30961     0.26584
log_std/max                           0.14172     0.02790     0.21734     0.09518
log_std/min                           -3.12737    0.11177     -2.76579    -3.22110
log_probs/mean                        1.59149     0.37663     2.15129     0.94307
log_probs/std                         2.74460     0.06851     2.92341     2.58421
log_probs/max                         10.71639    0.56849     12.46949    9.46116
log_probs/min                         -7.72672    1.19866     -5.55824    -11.23622
mean/mean                             0.08848     0.04933     0.17310     0.00487
mean/std                              1.20344     0.05278     1.27825     1.11760
mean/max                              4.11218     0.33737     4.62163     3.39166
mean/min                              -3.08456    0.10266     -2.90976    -3.24428
------------------------------------  ----------  ----------  ----------  ----------
sample: [2, 1, 8, 9, 6, 0, 4, 5, 7, 3]
replay_buffer._size: [16650 16650 16650 16650 16650 16650 16650 16650 16650 16650]
2023-08-12 11:54:58,347 MainThread INFO: EPOCH:89
2023-08-12 11:54:58,348 MainThread INFO: Time Consumed:9.049280166625977s
2023-08-12 11:54:58,348 MainThread INFO: Total Frames:165000s
  1%|          | 90/10000 [13:37<25:09:04,  9.14s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               600.02799
Train_Epoch_Reward                    7246.81118
Running_Training_Average_Rewards      1041.44618
Explore_Time                          0.01081
Train___Time                          9.03316
Eval____Time                          0.00460
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.63713
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.19464
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.77566
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.03206
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.27875
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.99541
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.93725
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6539.84674
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.04268
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.67328
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.87887     1.42633     12.64924    4.80851
alpha_0                               0.85616     0.00532     0.86553     0.84608
alpha_1                               0.08677     0.00053     0.08763     0.08583
alpha_2                               0.07880     0.00051     0.07961     0.07793
alpha_3                               0.08382     0.00061     0.08482     0.08276
alpha_4                               0.07327     0.00059     0.07425     0.07226
alpha_5                               0.08407     0.00062     0.08508     0.08296
alpha_6                               0.07512     0.00052     0.07598     0.07423
alpha_7                               0.08684     0.00053     0.08767     0.08589
alpha_8                               0.11066     0.00050     0.11126     0.10977
alpha_9                               0.08247     0.00053     0.08332     0.08154
Alpha_loss                            -7.18029    0.71806     -5.95483    -8.42027
Training/policy_loss                  -128.91215  2.20044     -122.29510  -133.95995
Training/qf1_loss                     3289.73748  1097.93579  7988.70020  1195.04102
Training/qf2_loss                     2440.57507  957.27334   5855.30615  938.52032
Training/pf_norm                      2.96314     1.67093     7.73654     0.78018
Training/qf1_norm                     1276.97673  702.84489   3276.86646  206.95000
Training/qf2_norm                     1350.52469  746.67745   4654.26465  451.96359
log_std/mean                          -0.50302    0.02466     -0.45481    -0.53320
log_std/std                           0.30426     0.01478     0.33679     0.27068
log_std/max                           0.14816     0.02868     0.21920     0.09631
log_std/min                           -3.24591    0.11210     -2.87144    -3.36903
log_probs/mean                        1.25439     0.31780     1.78096     0.67626
log_probs/std                         2.71019     0.07715     2.88881     2.56513
log_probs/max                         10.31339    0.62046     11.64341    9.00808
log_probs/min                         -7.52509    1.07033     -5.64371    -11.03845
mean/mean                             0.00331     0.05169     0.09375     -0.08418
mean/std                              1.16531     0.04818     1.25186     1.08606
mean/max                              3.73436     0.29557     4.17268     3.04616
mean/min                              -3.24293    0.03717     -3.11209    -3.28790
------------------------------------  ----------  ----------  ----------  ----------
sample: [4, 0, 7, 5, 3, 2, 1, 9, 6, 8]
replay_buffer._size: [16800 16800 16800 16800 16800 16800 16800 16800 16800 16800]
2023-08-12 11:55:06,848 MainThread INFO: EPOCH:90
2023-08-12 11:55:06,848 MainThread INFO: Time Consumed:8.31798505783081s
2023-08-12 11:55:06,848 MainThread INFO: Total Frames:166500s
  1%|          | 91/10000 [13:46<24:36:27,  8.94s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               699.25056
Train_Epoch_Reward                    5972.23824
Running_Training_Average_Rewards      738.88617
Explore_Time                          0.02769
Train___Time                          8.28572
Eval____Time                          0.00383
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.10921
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.50811
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.77168
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.25391
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.49983
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.10898
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.10991
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7633.89288
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.00611
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.01954
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.77041     1.36749     11.33482    4.69073
alpha_0                               0.87609     0.00583     0.88561     0.86577
alpha_1                               0.08492     0.00053     0.08581     0.08399
alpha_2                               0.07715     0.00044     0.07792     0.07643
alpha_3                               0.08177     0.00057     0.08274     0.08080
alpha_4                               0.07128     0.00055     0.07224     0.07036
alpha_5                               0.08183     0.00064     0.08293     0.08075
alpha_6                               0.07337     0.00048     0.07421     0.07258
alpha_7                               0.08500     0.00051     0.08588     0.08416
alpha_8                               0.10901     0.00049     0.10975     0.10810
alpha_9                               0.08063     0.00053     0.08152     0.07972
Alpha_loss                            -6.94799    0.26560     -6.44492    -7.73152
Training/policy_loss                  -131.04249  2.31402     -127.15472  -136.83284
Training/qf1_loss                     3174.86222  1028.82231  6600.93848  1392.54382
Training/qf2_loss                     2282.50572  900.56959   5147.93213  797.70428
Training/pf_norm                      3.00666     1.98269     9.81936     0.75852
Training/qf1_norm                     1234.77595  636.30796   3337.66089  306.94803
Training/qf2_norm                     1319.48638  663.67571   3635.07446  416.30359
log_std/mean                          -0.52834    0.01024     -0.51287    -0.54953
log_std/std                           0.30538     0.00877     0.32643     0.28191
log_std/max                           0.15817     0.02392     0.20072     0.10168
log_std/min                           -3.26619    0.12521     -2.82149    -3.45153
log_probs/mean                        1.36088     0.11320     1.59128     1.03735
log_probs/std                         2.67263     0.08417     2.84032     2.47775
log_probs/max                         10.43686    0.59413     12.01181    9.22558
log_probs/min                         -7.64653    1.11160     -5.46283    -10.95787
mean/mean                             0.06437     0.04004     0.13392     0.00854
mean/std                              1.17251     0.01405     1.20061     1.14219
mean/max                              3.88999     0.30817     4.29550     3.29164
mean/min                              -3.27929    0.03741     -3.10755    -3.34874
------------------------------------  ----------  ----------  ----------  ----------
sample: [2, 8, 0, 5, 7, 4, 9, 1, 3, 6]
replay_buffer._size: [16950 16950 16950 16950 16950 16950 16950 16950 16950 16950]
2023-08-12 11:55:16,134 MainThread INFO: EPOCH:91
2023-08-12 11:55:16,134 MainThread INFO: Time Consumed:9.109439134597778s
2023-08-12 11:55:16,134 MainThread INFO: Total Frames:168000s
  1%|          | 92/10000 [13:55<24:54:21,  9.05s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               641.75982
Train_Epoch_Reward                    7712.87815
Running_Training_Average_Rewards      697.73092
Explore_Time                          0.00419
Train___Time                          9.10097
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.88957
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.72467
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.27872
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.28762
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.80336
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.17693
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.60348
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7056.34195
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.93491
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.04451
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.57515     1.24340    10.79050    4.98591
alpha_0                               0.89275     0.00405    0.89920     0.88573
alpha_1                               0.08294     0.00061    0.08397     0.08187
alpha_2                               0.07573     0.00041    0.07642     0.07500
alpha_3                               0.07983     0.00056    0.08078     0.07885
alpha_4                               0.06948     0.00050    0.07034     0.06860
alpha_5                               0.07963     0.00066    0.08073     0.07846
alpha_6                               0.07180     0.00045    0.07256     0.07101
alpha_7                               0.08336     0.00048    0.08414     0.08250
alpha_8                               0.10694     0.00073    0.10808     0.10554
alpha_9                               0.07882     0.00052    0.07971     0.07792
Alpha_loss                            -7.17908    0.46955    -6.37591    -7.86918
Training/policy_loss                  -132.35188  2.58376    -127.02752  -138.06853
Training/qf1_loss                     3090.02538  896.73340  6157.22559  1279.05115
Training/qf2_loss                     2080.43788  754.44126  4447.79688  723.54535
Training/pf_norm                      2.85249     1.57359    7.09473     0.75198
Training/qf1_norm                     1224.62646  637.88645  3316.29321  233.98643
Training/qf2_norm                     1257.68614  611.49454  3273.01489  468.95663
log_std/mean                          -0.53864    0.02063    -0.50727    -0.57271
log_std/std                           0.32270     0.00898    0.34732     0.30352
log_std/max                           0.21694     0.04778    0.28541     0.12671
log_std/min                           -3.45665    0.12220    -3.08781    -3.56422
log_probs/mean                        1.25185     0.19522    1.60343     0.94231
log_probs/std                         2.56239     0.06722    2.74228     2.43877
log_probs/max                         10.10167    0.54595    12.32057    9.14791
log_probs/min                         -7.52757    1.23482    -5.64506    -11.62628
mean/mean                             0.05647     0.04660    0.14918     -0.01469
mean/std                              1.14974     0.02477    1.19367     1.10914
mean/max                              4.08442     0.22808    4.39645     3.71482
mean/min                              -3.35196    0.04375    -3.08335    -3.41326
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 5, 0, 6, 7, 2, 9, 3, 8, 4]
replay_buffer._size: [17100 17100 17100 17100 17100 17100 17100 17100 17100 17100]
2023-08-12 11:55:25,220 MainThread INFO: EPOCH:92
2023-08-12 11:55:25,221 MainThread INFO: Time Consumed:8.892714023590088s
2023-08-12 11:55:25,221 MainThread INFO: Total Frames:169500s
  1%|          | 93/10000 [14:04<24:55:17,  9.06s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               789.43584
Train_Epoch_Reward                    7411.50084
Running_Training_Average_Rewards      703.22057
Explore_Time                          0.00414
Train___Time                          8.88358
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.09125
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.07631
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.87687
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.21430
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.72729
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.46532
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.69832
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8527.83060
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.71277
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.60975
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.95698     1.31188    11.38482    4.82376
alpha_0                               0.90504     0.00362    0.91178     0.89930
alpha_1                               0.08090     0.00053    0.08185     0.08002
alpha_2                               0.07415     0.00049    0.07498     0.07331
alpha_3                               0.07793     0.00052    0.07883     0.07706
alpha_4                               0.06766     0.00055    0.06858     0.06671
alpha_5                               0.07729     0.00064    0.07844     0.07621
alpha_6                               0.07014     0.00050    0.07099     0.06928
alpha_7                               0.08160     0.00051    0.08248     0.08073
alpha_8                               0.10420     0.00073    0.10551     0.10297
alpha_9                               0.07702     0.00052    0.07790     0.07612
Alpha_loss                            -7.37077    0.28445    -6.45695    -7.98450
Training/policy_loss                  -134.56080  2.11857    -128.16713  -140.81059
Training/qf1_loss                     3372.73469  976.46775  7527.46582  1699.17664
Training/qf2_loss                     2271.81009  820.47150  5268.02051  760.52362
Training/pf_norm                      3.53665     2.14394    10.71612    0.53691
Training/qf1_norm                     1393.71171  758.89802  4165.57373  321.66245
Training/qf2_norm                     1354.51383  599.52443  3168.51709  460.43442
log_std/mean                          -0.54963    0.01251    -0.52556    -0.58452
log_std/std                           0.31816     0.00883    0.34079     0.28581
log_std/max                           0.25860     0.02691    0.31606     0.21242
log_std/min                           -3.40968    0.13510    -2.96696    -3.54421
log_probs/mean                        1.20640     0.12981    1.64256     0.95746
log_probs/std                         2.58487     0.06650    2.74380     2.39698
log_probs/max                         9.49781     0.54849    11.14846    8.33720
log_probs/min                         -7.53896    1.22887    -5.10812    -11.12028
mean/mean                             -0.03258    0.02943    0.03480     -0.09246
mean/std                              1.13931     0.01607    1.18287     1.11061
mean/max                              4.04950     0.19279    4.46352     3.74357
mean/min                              -3.46271    0.05920    -3.34004    -3.52659
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 4, 9, 2, 3, 7, 1, 8, 0, 6]
replay_buffer._size: [17250 17250 17250 17250 17250 17250 17250 17250 17250 17250]
2023-08-12 11:55:34,448 MainThread INFO: EPOCH:93
2023-08-12 11:55:34,449 MainThread INFO: Time Consumed:9.05678939819336s
2023-08-12 11:55:34,449 MainThread INFO: Total Frames:171000s
  1%|          | 94/10000 [14:13<25:02:58,  9.10s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               657.69796
Train_Epoch_Reward                    9251.59584
Running_Training_Average_Rewards      812.53249
Explore_Time                          0.00453
Train___Time                          9.04869
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.48746
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.36124
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.39083
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.63567
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.78776
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.42775
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.39966
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7213.83867
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -78.06500
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.30373
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.86901     1.18719    10.70801    5.62740
alpha_0                               0.92000     0.00479    0.92878     0.91197
alpha_1                               0.07926     0.00041    0.08000     0.07861
alpha_2                               0.07255     0.00042    0.07329     0.07186
alpha_3                               0.07635     0.00037    0.07704     0.07573
alpha_4                               0.06579     0.00053    0.06670     0.06488
alpha_5                               0.07530     0.00047    0.07619     0.07454
alpha_6                               0.06847     0.00045    0.06926     0.06772
alpha_7                               0.08017     0.00025    0.08071     0.07979
alpha_8                               0.10233     0.00026    0.10295     0.10198
alpha_9                               0.07535     0.00041    0.07610     0.07465
Alpha_loss                            -5.89553    0.53792    -4.82024    -6.94858
Training/policy_loss                  -137.10108  2.20525    -132.12103  -142.91765
Training/qf1_loss                     3249.34793  988.56116  5279.49023  1366.64148
Training/qf2_loss                     2129.61420  807.72483  4136.79150  862.04736
Training/pf_norm                      3.09796     1.81168    7.80694     0.67997
Training/qf1_norm                     1265.70610  720.05212  3566.47412  298.14435
Training/qf2_norm                     1325.02538  640.63035  3408.02539  551.66858
log_std/mean                          -0.60001    0.01529    -0.57272    -0.62265
log_std/std                           0.32151     0.00766    0.34478     0.30258
log_std/max                           0.23555     0.02781    0.29937     0.17751
log_std/min                           -3.49949    0.15071    -3.03113    -3.64490
log_probs/mean                        1.83152     0.22530    2.29861     1.37210
log_probs/std                         2.72458     0.07462    2.87455     2.51804
log_probs/max                         9.91023     0.60336    11.41683    8.61576
log_probs/min                         -7.53849    1.38747    -5.16001    -11.54132
mean/mean                             -0.02046    0.01610    0.02781     -0.05799
mean/std                              1.22958     0.03014    1.28101     1.17002
mean/max                              3.89916     0.14594    4.23504     3.70261
mean/min                              -3.63295    0.07915    -3.34558    -3.74745
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 2, 3, 1, 7, 5, 0, 6, 4, 9]
replay_buffer._size: [17400 17400 17400 17400 17400 17400 17400 17400 17400 17400]
2023-08-12 11:55:43,843 MainThread INFO: EPOCH:94
2023-08-12 11:55:43,843 MainThread INFO: Time Consumed:9.231690406799316s
2023-08-12 11:55:43,843 MainThread INFO: Total Frames:172500s
  1%|          | 95/10000 [14:23<25:18:28,  9.20s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               551.81739
Train_Epoch_Reward                    8810.38137
Running_Training_Average_Rewards      849.11593
Explore_Time                          0.00390
Train___Time                          9.22064
Eval____Time                          0.00654
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.90623
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.21119
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.26308
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.34181
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.25394
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.22638
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.62663
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6151.91982
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.31039
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.60625
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.93626     1.41387     11.40287    4.61368
alpha_0                               0.93723     0.00481     0.94617     0.92898
alpha_1                               0.07795     0.00037     0.07860     0.07735
alpha_2                               0.07119     0.00039     0.07184     0.07049
alpha_3                               0.07496     0.00044     0.07572     0.07424
alpha_4                               0.06397     0.00052     0.06486     0.06307
alpha_5                               0.07367     0.00051     0.07453     0.07281
alpha_6                               0.06696     0.00043     0.06770     0.06622
alpha_7                               0.07925     0.00031     0.07978     0.07876
alpha_8                               0.10110     0.00051     0.10197     0.10023
alpha_9                               0.07375     0.00051     0.07463     0.07291
Alpha_loss                            -6.28630    0.21637     -5.70726    -6.81954
Training/policy_loss                  -138.79169  2.54479     -132.54887  -144.20430
Training/qf1_loss                     3393.85184  1056.03160  6233.93896  1515.53430
Training/qf2_loss                     2156.63453  886.28038   4862.69238  677.41522
Training/pf_norm                      3.46781     1.89678     10.23681    0.65627
Training/qf1_norm                     1450.25931  773.31526   3846.84033  256.86154
Training/qf2_norm                     1436.54840  794.10048   4137.25244  387.65530
log_std/mean                          -0.58770    0.00918     -0.56620    -0.60644
log_std/std                           0.33208     0.00954     0.35811     0.31404
log_std/max                           0.28788     0.01865     0.32035     0.22594
log_std/min                           -3.59227    0.13467     -3.16054    -3.69660
log_probs/mean                        1.69081     0.09349     1.92792     1.45184
log_probs/std                         2.67415     0.07218     2.85667     2.51450
log_probs/max                         9.85969     0.54187     11.35888    8.55638
log_probs/min                         -7.25077    1.09401     -5.21443    -12.25082
mean/mean                             -0.05174    0.02732     0.00367     -0.09611
mean/std                              1.20928     0.01303     1.23262     1.17275
mean/max                              3.84522     0.13948     4.12795     3.62250
mean/min                              -3.63279    0.07194     -3.38896    -3.73105
------------------------------------  ----------  ----------  ----------  ----------
sample: [0, 4, 6, 2, 5, 7, 8, 3, 1, 9]
replay_buffer._size: [17550 17550 17550 17550 17550 17550 17550 17550 17550 17550]
2023-08-12 11:55:53,403 MainThread INFO: EPOCH:95
2023-08-12 11:55:53,404 MainThread INFO: Time Consumed:9.413253784179688s
2023-08-12 11:55:53,404 MainThread INFO: Total Frames:174000s
  1%|          | 96/10000 [14:32<25:35:07,  9.30s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               498.03066
Train_Epoch_Reward                    5103.02681
Running_Training_Average_Rewards      772.16680
Explore_Time                          0.00664
Train___Time                          9.40080
Eval____Time                          0.00505
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.76395
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.76994
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.96220
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.34735
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.97276
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.15661
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.14200
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5615.00613
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.29197
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.29279
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.62855     1.28301     11.24917    4.20059
alpha_0                               0.95226     0.00252     0.95489     0.94636
alpha_1                               0.07676     0.00035     0.07734     0.07616
alpha_2                               0.06973     0.00042     0.07047     0.06899
alpha_3                               0.07346     0.00046     0.07423     0.07265
alpha_4                               0.06212     0.00053     0.06305     0.06123
alpha_5                               0.07190     0.00051     0.07279     0.07102
alpha_6                               0.06544     0.00044     0.06620     0.06467
alpha_7                               0.07813     0.00036     0.07875     0.07750
alpha_8                               0.09919     0.00061     0.10021     0.09805
alpha_9                               0.07201     0.00051     0.07289     0.07114
Alpha_loss                            -6.64245    0.25315     -6.05932    -7.19002
Training/policy_loss                  -139.96450  2.67009     -132.83545  -147.07204
Training/qf1_loss                     3236.66616  1030.12963  7142.44092  1364.83203
Training/qf2_loss                     1924.28384  811.38578   5400.61768  566.03607
Training/pf_norm                      2.88500     1.45974     7.77099     1.04223
Training/qf1_norm                     1339.15642  743.55073   4000.94019  436.51471
Training/qf2_norm                     1384.27468  679.37422   4456.58789  467.05719
log_std/mean                          -0.60596    0.01496     -0.57825    -0.63090
log_std/std                           0.35168     0.00893     0.37702     0.33321
log_std/max                           0.29296     0.03502     0.38492     0.20451
log_std/min                           -3.63944    0.16732     -3.18139    -3.83062
log_probs/mean                        1.53034     0.10745     1.73671     1.27677
log_probs/std                         2.59101     0.09131     2.74262     2.36313
log_probs/max                         9.77510     0.62759     12.00353    8.08565
log_probs/min                         -7.47096    1.33264     -5.05104    -13.11362
mean/mean                             -0.00410    0.02963     0.05591     -0.05153
mean/std                              1.17530     0.01742     1.20424     1.13379
mean/max                              3.73748     0.05551     3.83954     3.63295
mean/min                              -3.73056    0.08082     -3.46272    -3.86057
------------------------------------  ----------  ----------  ----------  ----------
sample: [9, 5, 2, 4, 8, 0, 3, 7, 1, 6]
replay_buffer._size: [17705 17705 17705 17705 17705 17705 17706 17706 17705 17704]
2023-08-12 11:56:03,073 MainThread INFO: EPOCH:96
2023-08-12 11:56:03,075 MainThread INFO: Time Consumed:9.53629183769226s
2023-08-12 11:56:03,075 MainThread INFO: Total Frames:175500s
  1%|          | 97/10000 [14:42<25:53:18,  9.41s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               466.48205
Train_Epoch_Reward                    5023.65914
Running_Training_Average_Rewards      631.23558
Explore_Time                          0.11179
Train___Time                          9.41939
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.83158
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.07712
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.21320
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.90091
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.82445
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.29749
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.72379
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5294.34848
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -86.35298
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.30651
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.69410     1.34184    11.60122    4.42898
alpha_0                               0.96140     0.00355    0.96752     0.95500
alpha_1                               0.07568     0.00026    0.07615     0.07527
alpha_2                               0.06814     0.00049    0.06898     0.06730
alpha_3                               0.07187     0.00042    0.07263     0.07122
alpha_4                               0.06031     0.00053    0.06121     0.05941
alpha_5                               0.07019     0.00046    0.07100     0.06944
alpha_6                               0.06390     0.00043    0.06465     0.06320
alpha_7                               0.07691     0.00032    0.07748     0.07640
alpha_8                               0.09707     0.00051    0.09802     0.09631
alpha_9                               0.07023     0.00052    0.07112     0.06935
Alpha_loss                            -6.28184    0.40732    -5.39971    -6.90210
Training/policy_loss                  -141.96417  2.41821    -136.81743  -146.82530
Training/qf1_loss                     3382.59371  975.85052  5933.09473  1306.09644
Training/qf2_loss                     1977.81116  755.11246  4346.76660  603.05048
Training/pf_norm                      3.99031     2.46468    12.78551    0.74125
Training/qf1_norm                     1475.00821  774.33328  4050.40356  485.43936
Training/qf2_norm                     1352.18317  672.16172  3961.70435  526.72906
log_std/mean                          -0.62634    0.01307    -0.60065    -0.65076
log_std/std                           0.36227     0.00905    0.38411     0.33944
log_std/max                           0.38207     0.02982    0.42051     0.29214
log_std/min                           -3.75852    0.18894    -3.23280    -3.89888
log_probs/mean                        1.71461     0.16347    2.06840     1.45072
log_probs/std                         2.69592     0.06219    2.83703     2.52568
log_probs/max                         9.40439     0.50709    11.05837    8.36467
log_probs/min                         -7.48654    1.15084    -5.42377    -9.91883
mean/mean                             -0.01165    0.01355    0.01636     -0.04607
mean/std                              1.20163     0.02145    1.25139     1.16760
mean/max                              3.68213     0.02764    3.73599     3.62597
mean/min                              -3.87673    0.06798    -3.66578    -3.98190
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 6, 8, 1, 3, 5, 0, 9, 7, 4]
replay_buffer._size: [17850 17850 17850 17850 17850 17850 17850 17850 17850 17850]
2023-08-12 11:56:12,179 MainThread INFO: EPOCH:97
2023-08-12 11:56:12,179 MainThread INFO: Time Consumed:8.938623428344727s
2023-08-12 11:56:12,179 MainThread INFO: Total Frames:177000s
  1%|          | 98/10000 [14:51<25:38:32,  9.32s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               465.54081
Train_Epoch_Reward                    4794.74980
Running_Training_Average_Rewards      497.38119
Explore_Time                          0.01537
Train___Time                          8.91854
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.52463
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.33683
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.79270
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.81145
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.31122
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.09595
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.27235
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5316.83633
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -88.20090
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.08225
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           8.00227     1.59484     12.97331    5.15765
alpha_0                               0.97257     0.00239     0.97657     0.96765
alpha_1                               0.07496     0.00017     0.07527     0.07470
alpha_2                               0.06644     0.00050     0.06728     0.06555
alpha_3                               0.07065     0.00033     0.07121     0.07010
alpha_4                               0.05853     0.00051     0.05940     0.05766
alpha_5                               0.06874     0.00041     0.06943     0.06805
alpha_6                               0.06255     0.00037     0.06318     0.06192
alpha_7                               0.07597     0.00027     0.07639     0.07552
alpha_8                               0.09571     0.00040     0.09630     0.09505
alpha_9                               0.06850     0.00050     0.06934     0.06764
Alpha_loss                            -5.78507    0.38199     -4.96165    -6.55723
Training/policy_loss                  -143.88889  3.11777     -138.26729  -152.49969
Training/qf1_loss                     3690.22979  1291.17311  8238.46191  1703.32056
Training/qf2_loss                     2145.27110  1006.47119  5332.35254  640.36359
Training/pf_norm                      3.93144     2.34984     10.93649    0.78539
Training/qf1_norm                     1606.08300  889.93212   4279.99561  380.60168
Training/qf2_norm                     1611.37056  990.53250   6547.43213  462.77850
log_std/mean                          -0.63993    0.01201     -0.62016    -0.66829
log_std/std                           0.37435     0.00858     0.40059     0.35543
log_std/max                           0.42465     0.03466     0.49404     0.33988
log_std/min                           -3.89774    0.13630     -3.40668    -4.01650
log_probs/mean                        1.90623     0.15995     2.24470     1.61711
log_probs/std                         2.72944     0.07266     3.00780     2.58915
log_probs/max                         9.28208     0.50034     10.86074    8.10751
log_probs/min                         -7.21207    1.36063     -5.02340    -11.63233
mean/mean                             -0.06404    0.01961     -0.01997    -0.10831
mean/std                              1.22463     0.02048     1.26778     1.18588
mean/max                              3.63446     0.06371     3.74977     3.51292
mean/min                              -3.95388    0.06182     -3.73862    -4.03717
------------------------------------  ----------  ----------  ----------  ----------
sample: [1, 0, 4, 2, 6, 7, 3, 8, 9, 5]
replay_buffer._size: [18000 18000 18000 18000 18000 18000 18000 18000 18000 18000]
2023-08-12 11:56:21,680 MainThread INFO: EPOCH:98
2023-08-12 11:56:21,680 MainThread INFO: Time Consumed:9.306720972061157s
2023-08-12 11:56:21,680 MainThread INFO: Total Frames:178500s
  1%|          | 99/10000 [15:00<25:46:35,  9.37s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               471.95926
Train_Epoch_Reward                    4501.09413
Running_Training_Average_Rewards      477.31677
Explore_Time                          0.00442
Train___Time                          9.29638
Eval____Time                          0.00525
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.47481
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.87224
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.54349
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.85716
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.81576
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.47886
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.81554
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5363.39110
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -85.95659
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.98402
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.51613     1.58868     13.09142    4.09406
alpha_0                               0.98396     0.00394     0.99058     0.97669
alpha_1                               0.07460     0.00006     0.07470     0.07449
alpha_2                               0.06463     0.00053     0.06553     0.06371
alpha_3                               0.06964     0.00026     0.07009     0.06918
alpha_4                               0.05680     0.00049     0.05764     0.05597
alpha_5                               0.06752     0.00030     0.06804     0.06698
alpha_6                               0.06147     0.00023     0.06191     0.06110
alpha_7                               0.07527     0.00013     0.07551     0.07505
alpha_8                               0.09461     0.00027     0.09504     0.09409
alpha_9                               0.06679     0.00049     0.06763     0.06592
Alpha_loss                            -5.09864    0.36149     -4.41252    -6.11368
Training/policy_loss                  -144.76665  2.83971     -138.77660  -152.32425
Training/qf1_loss                     3429.19656  1153.98422  8404.04102  1255.54761
Training/qf2_loss                     1937.42489  936.75546   6311.31055  543.93274
Training/pf_norm                      4.57159     2.87760     16.25589    0.83632
Training/qf1_norm                     1620.30586  949.64749   5946.06738  468.36682
Training/qf2_norm                     1651.94387  889.84543   4973.85840  422.79410
log_std/mean                          -0.64126    0.01318     -0.60598    -0.66145
log_std/std                           0.38096     0.01118     0.40969     0.35919
log_std/max                           0.49275     0.02542     0.52340     0.42053
log_std/min                           -3.90785    0.18285     -3.37753    -4.13095
log_probs/mean                        2.19773     0.14664     2.44745     1.77100
log_probs/std                         2.84291     0.06062     3.01757     2.68482
log_probs/max                         9.80297     0.60380     11.42199    8.62878
log_probs/min                         -7.24920    1.34000     -5.06482    -11.40103
mean/mean                             -0.06915    0.02073     -0.02819    -0.12042
mean/std                              1.27545     0.01845     1.31246     1.21630
mean/max                              3.43483     0.13919     3.62053     3.15729
mean/min                              -4.01381    0.06191     -3.82989    -4.08764
------------------------------------  ----------  ----------  ----------  ----------
sample: [8, 9, 7, 3, 6, 5, 0, 4, 1, 2]
replay_buffer._size: [18150 18150 18150 18150 18150 18150 18150 18150 18150 18150]
2023-08-12 11:56:31,353 MainThread INFO: EPOCH:99
2023-08-12 11:56:31,354 MainThread INFO: Time Consumed:9.561124086380005s
2023-08-12 11:56:31,354 MainThread INFO: Total Frames:180000s
  1%|          | 100/10000 [15:10<26:02:52,  9.47s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               460.81877
Train_Epoch_Reward                    5045.71852
Running_Training_Average_Rewards      478.05208
Explore_Time                          0.00461
Train___Time                          9.55162
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.91427
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.06021
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.85088
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.48871
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.08200
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.20231
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.61167
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5251.28653
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -85.99047
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.89833
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.30883     1.17700     10.70125    4.42508
alpha_0                               0.98920     0.00116     0.99096     0.98768
alpha_1                               0.07440     0.00003     0.07449     0.07436
alpha_2                               0.06265     0.00062     0.06369     0.06156
alpha_3                               0.06861     0.00032     0.06917     0.06808
alpha_4                               0.05514     0.00047     0.05595     0.05435
alpha_5                               0.06631     0.00036     0.06697     0.06571
alpha_6                               0.06066     0.00024     0.06109     0.06028
alpha_7                               0.07465     0.00022     0.07504     0.07425
alpha_8                               0.09300     0.00065     0.09407     0.09185
alpha_9                               0.06497     0.00053     0.06590     0.06404
Alpha_loss                            -5.75744    0.24745     -5.07655    -6.41087
Training/policy_loss                  -145.53801  3.21248     -136.15923  -152.76689
Training/qf1_loss                     3362.23207  1028.66957  7161.65723  1527.51465
Training/qf2_loss                     1774.79820  780.51504   5275.37354  580.55042
Training/pf_norm                      3.80400     2.70909     15.42233    0.89890
Training/qf1_norm                     1399.44849  737.42982   3323.23730  421.12238
Training/qf2_norm                     1356.64085  659.92050   3686.01831  500.25659
log_std/mean                          -0.62929    0.00966     -0.60549    -0.64711
log_std/std                           0.39752     0.00878     0.41882     0.37301
log_std/max                           0.53441     0.04688     0.61942     0.44070
log_std/min                           -3.90383    0.19315     -3.35310    -4.08348
log_probs/mean                        1.89678     0.10374     2.16318     1.62567
log_probs/std                         2.78613     0.07648     2.93628     2.61081
log_probs/max                         9.71216     0.71141     11.33702    8.02179
log_probs/min                         -7.30061    1.16219     -5.55137    -12.07731
mean/mean                             -0.08199    0.03276     -0.01734    -0.14624
mean/std                              1.22697     0.01112     1.25907     1.20393
mean/max                              3.20744     0.20338     3.52271     2.88872
mean/min                              -4.05610    0.05213     -3.89329    -4.10925
------------------------------------  ----------  ----------  ----------  ----------
start to update mask
sample: [8, 6, 9, 2, 3, 5, 0, 4, 1, 7]
replay_buffer._size: [18300 18300 18300 18300 18300 18300 18300 18300 18300 18300]
2023-08-12 11:56:40,086 MainThread INFO: EPOCH:100
2023-08-12 11:56:40,086 MainThread INFO: Time Consumed:7.379732370376587s
2023-08-12 11:56:40,086 MainThread INFO: Total Frames:181500s
  1%|          | 101/10000 [15:20<26:34:37,  9.67s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               463.38736
Train_Epoch_Reward                    4898.36990
Running_Training_Average_Rewards      481.50609
Explore_Time                          0.00464
Train___Time                          7.36962
Eval____Time                          0.00474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.13786
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.57043
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.58820
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.91663
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.30618
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.66987
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.02583
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5265.77475
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.40790
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.27821
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           7.47738      1.61492      11.75311     4.32274
alpha_0                               0.96166      0.01730      0.98777      0.93315
alpha_1                               0.07377      0.00043      0.07436      0.07308
alpha_2                               0.06043      0.00063      0.06154      0.05942
alpha_3                               0.06758      0.00033      0.06807      0.06692
alpha_4                               0.05366      0.00037      0.05433      0.05304
alpha_5                               0.06500      0.00041      0.06570      0.06434
alpha_6                               0.06079      0.00044      0.06167      0.06027
alpha_7                               0.07387      0.00018      0.07424      0.07364
alpha_8                               0.09022      0.00121      0.09183      0.08778
alpha_9                               0.06301      0.00062      0.06403      0.06189
Alpha_loss                            -5.01862     0.38677      -4.27226     -5.80391
Training/policy_loss                  -35.04026    3.94557      -28.03377    -45.99666
Training/qf1_loss                     11507.89801  5873.18272   24272.56641  3164.67334
Training/qf2_loss                     2876.80010   1514.60729   7532.20557   772.56354
Training/pf_norm                      18.38821     9.31470      36.74838     4.63702
Training/qf1_norm                     15017.83542  11372.68263  37071.65625  2138.20532
Training/qf2_norm                     4278.44523   3245.35997   14986.50488  861.88397
log_std/mean                          -0.64636     0.02241      -0.60310     -0.67447
log_std/std                           0.38119      0.02115      0.43908      0.34748
log_std/max                           0.46135      0.16018      0.85015      0.26527
log_std/min                           -3.71276     0.38227      -2.80830     -4.31173
log_probs/mean                        1.91287      0.15147      2.19549      1.63049
log_probs/std                         3.29525      0.20423      3.69223      2.99776
log_probs/max                         14.14901     1.19373      17.04772     11.89535
log_probs/min                         -7.22882     1.13793      -5.17027     -10.29857
mean/mean                             -0.01744     0.06626      0.09948      -0.12001
mean/std                              1.22852      0.03053      1.28947      1.17227
mean/max                              3.34958      0.21085      3.69800      2.81041
mean/min                              -3.99487     0.18280      -3.68388     -4.50660
------------------------------------  -----------  -----------  -----------  ----------
snapshot at 100
history save at ./log/must_mtsac/mt10/12/model
sample: [1, 4, 2, 9, 0, 5, 8, 6, 3, 7]
replay_buffer._size: [18450 18450 18450 18450 18450 18450 18450 18450 18450 18450]
2023-08-12 11:56:49,623 MainThread INFO: EPOCH:101
2023-08-12 11:56:49,623 MainThread INFO: Time Consumed:8.033112049102783s
2023-08-12 11:56:49,623 MainThread INFO: Total Frames:183000s
  1%|          | 102/10000 [15:28<25:22:01,  9.23s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               507.24994
Train_Epoch_Reward                    4737.11492
Running_Training_Average_Rewards      489.37344
Explore_Time                          0.00373
Train___Time                          8.02388
Eval____Time                          0.00486
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.30246
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.00207
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.48111
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.62707
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.68308
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.00311
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.84321
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5711.13023
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.15921
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.52952
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.43892     1.26080     10.57763    4.52101
alpha_0                               0.91703     0.00602     0.93263     0.91199
alpha_1                               0.07327     0.00014     0.07345     0.07305
alpha_2                               0.05873     0.00035     0.05941     0.05821
alpha_3                               0.06611     0.00039     0.06690     0.06551
alpha_4                               0.05270     0.00015     0.05302     0.05240
alpha_5                               0.06364     0.00035     0.06432     0.06308
alpha_6                               0.06196     0.00013     0.06212     0.06169
alpha_7                               0.07306     0.00029     0.07363     0.07260
alpha_8                               0.08660     0.00051     0.08772     0.08602
alpha_9                               0.06085     0.00054     0.06186     0.05995
Alpha_loss                            -3.54528    0.87542     -2.29087    -6.02575
Training/policy_loss                  -45.68547   3.39771     -37.59768   -55.58771
Training/qf1_loss                     4590.55605  1168.51889  7930.42725  2027.04260
Training/qf2_loss                     2070.35431  801.60341   4344.35498  757.64026
Training/pf_norm                      4.01395     1.47224     11.11855    2.07459
Training/qf1_norm                     1865.85643  765.24855   4490.01270  696.18604
Training/qf2_norm                     1526.99824  707.10204   4476.38574  609.47748
log_std/mean                          -0.83790    0.08608     -0.62426    -0.92872
log_std/std                           0.44662     0.02025     0.49631     0.38507
log_std/max                           0.79826     0.17295     0.97718     0.30080
log_std/min                           -3.64978    0.22203     -3.01794    -3.91996
log_probs/mean                        2.67987     0.41520     3.18996     1.51748
log_probs/std                         3.14304     0.22476     3.73426     2.81861
log_probs/max                         14.47845    1.06527     17.18185    12.05997
log_probs/min                         -7.24051    1.36476     -4.82844    -12.20284
mean/mean                             0.12363     0.07909     0.22076     -0.06658
mean/std                              1.25885     0.03357     1.31130     1.17314
mean/max                              4.05124     0.42491     4.76800     3.19268
mean/min                              -4.00045    0.21198     -3.66947    -4.53803
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 1, 7, 3, 0, 8, 2, 9, 5, 4]
replay_buffer._size: [18600 18600 18600 18600 18600 18600 18600 18600 18600 18600]
2023-08-12 11:56:58,683 MainThread INFO: EPOCH:102
2023-08-12 11:56:58,683 MainThread INFO: Time Consumed:8.881102085113525s
2023-08-12 11:56:58,683 MainThread INFO: Total Frames:184500s
  1%|          | 103/10000 [15:37<25:09:52,  9.15s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               648.50794
Train_Epoch_Reward                    5210.60646
Running_Training_Average_Rewards      494.86971
Explore_Time                          0.00459
Train___Time                          8.87177
Eval____Time                          0.00412
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.91458
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.74839
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.65371
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -72.23883
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.95911
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.96558
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.70791
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7056.37776
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.21387
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.89639
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.62029     1.24348     10.71741    3.87878
alpha_0                               0.92793     0.00862     0.94347     0.91439
alpha_1                               0.07364     0.00050     0.07479     0.07317
alpha_2                               0.05810     0.00005     0.05821     0.05804
alpha_3                               0.06477     0.00049     0.06550     0.06387
alpha_4                               0.05182     0.00035     0.05239     0.05122
alpha_5                               0.06240     0.00044     0.06307     0.06159
alpha_6                               0.06125     0.00030     0.06171     0.06075
alpha_7                               0.07195     0.00045     0.07259     0.07108
alpha_8                               0.09081     0.00191     0.09414     0.08766
alpha_9                               0.05889     0.00064     0.05993     0.05776
Alpha_loss                            -2.90511    0.45320     -1.85878    -3.91941
Training/policy_loss                  -50.56871   3.18047     -43.51226   -58.28259
Training/qf1_loss                     4405.68754  1017.54744  7408.74316  2053.40210
Training/qf2_loss                     2170.05437  744.64754   4347.50000  801.23309
Training/pf_norm                      3.53978     1.54685     8.59416     1.67842
Training/qf1_norm                     1655.68407  820.65002   4733.80371  664.18579
Training/qf2_norm                     1619.26012  820.58012   5672.59229  563.22540
log_std/mean                          -0.86427    0.04443     -0.80941    -0.96275
log_std/std                           0.49161     0.01056     0.51583     0.46947
log_std/max                           0.25089     0.07244     0.42196     0.06040
log_std/min                           -3.69814    0.15830     -3.26282    -3.91366
log_probs/mean                        3.20339     0.16965     3.54510     2.79334
log_probs/std                         4.05997     0.23800     4.57684     3.60272
log_probs/max                         16.78792    0.62405     18.46458    15.46454
log_probs/min                         -7.00046    1.14420     -4.90817    -10.85326
mean/mean                             0.07502     0.02631     0.14351     0.02880
mean/std                              1.35173     0.02925     1.40612     1.29390
mean/max                              4.11668     0.34426     4.80465     3.54286
mean/min                              -4.59809    0.35976     -3.88570    -5.02388
------------------------------------  ----------  ----------  ----------  ----------
sample: [4, 9, 7, 8, 2, 0, 5, 6, 3, 1]
replay_buffer._size: [18750 18750 18750 18750 18750 18750 18750 18750 18750 18750]
2023-08-12 11:57:07,701 MainThread INFO: EPOCH:103
2023-08-12 11:57:07,701 MainThread INFO: Time Consumed:8.826061010360718s
2023-08-12 11:57:07,702 MainThread INFO: Total Frames:186000s
  1%|          | 104/10000 [15:46<25:02:53,  9.11s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               773.97841
Train_Epoch_Reward                    5725.19844
Running_Training_Average_Rewards      522.43066
Explore_Time                          0.02337
Train___Time                          8.79752
Eval____Time                          0.00455
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.21851
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.58114
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.77373
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.02524
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.84072
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.42043
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.65175
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8390.84197
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.41246
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.13391
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.42590     1.33345     10.65126    4.13334
alpha_0                               0.96199     0.01090     0.98079     0.94380
alpha_1                               0.07694     0.00134     0.07937     0.07483
alpha_2                               0.05842     0.00029     0.05901     0.05805
alpha_3                               0.06295     0.00047     0.06385     0.06219
alpha_4                               0.05080     0.00020     0.05121     0.05051
alpha_5                               0.06090     0.00035     0.06158     0.06040
alpha_6                               0.06065     0.00004     0.06075     0.06061
alpha_7                               0.07036     0.00034     0.07106     0.06986
alpha_8                               0.09709     0.00161     0.09963     0.09420
alpha_9                               0.05660     0.00065     0.05773     0.05551
Alpha_loss                            -0.06805    1.06519     1.57196     -2.21507
Training/policy_loss                  -54.48546   2.90543     -48.57054   -61.26216
Training/qf1_loss                     4216.81854  1174.57831  7699.36670  1547.02539
Training/qf2_loss                     1989.96648  775.62729   4618.16357  404.11871
Training/pf_norm                      3.45044     1.63389     8.44648     1.04621
Training/qf1_norm                     1680.86433  817.21001   3875.09229  514.20386
Training/qf2_norm                     1578.28228  761.13412   4071.00513  622.03088
log_std/mean                          -0.92010    0.02060     -0.86355    -0.96613
log_std/std                           0.45094     0.01396     0.48070     0.41261
log_std/max                           0.23562     0.05653     0.34547     -0.04281
log_std/min                           -3.77775    0.13923     -3.30652    -3.89705
log_probs/mean                        4.28862     0.39265     4.86764     3.48140
log_probs/std                         4.31969     0.09929     4.57439     4.10976
log_probs/max                         19.25595    1.08690     21.22457    17.19889
log_probs/min                         -6.80054    1.16388     -4.83172    -10.31773
mean/mean                             0.10540     0.04718     0.17697     0.02142
mean/std                              1.48810     0.05249     1.58615     1.39983
mean/max                              4.33665     0.24205     4.65664     3.74377
mean/min                              -4.94286    0.35154     -4.07727    -5.33111
------------------------------------  ----------  ----------  ----------  ----------
sample: [1, 9, 3, 8, 2, 6, 4, 0, 7, 5]
replay_buffer._size: [18900 18900 18900 18900 18900 18900 18900 18900 18900 18900]
2023-08-12 11:57:16,260 MainThread INFO: EPOCH:104
2023-08-12 11:57:16,260 MainThread INFO: Time Consumed:8.385318994522095s
2023-08-12 11:57:16,260 MainThread INFO: Total Frames:187500s
  1%|          | 105/10000 [15:55<24:35:41,  8.95s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1222.21354
Train_Epoch_Reward                    7831.40593
Running_Training_Average_Rewards      625.57369
Explore_Time                          0.01261
Train___Time                          8.36776
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.19976
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.19975
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.56810
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.27426
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.61672
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.18509
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.34436
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12745.91768
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.74870
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.64555
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.30569      1.28486     11.37231    4.87399
alpha_0                               0.99856      0.00992     1.01521     0.98118
alpha_1                               0.08194      0.00143     0.08430     0.07942
alpha_2                               0.05988      0.00049     0.06068     0.05902
alpha_3                               0.06146      0.00041     0.06217     0.06074
alpha_4                               0.05038      0.00006     0.05051     0.05029
alpha_5                               0.06015      0.00012     0.06039     0.05997
alpha_6                               0.06096      0.00009     0.06104     0.06076
alpha_7                               0.06951      0.00018     0.06985     0.06921
alpha_8                               0.10137      0.00090     0.10272     0.09967
alpha_9                               0.05448      0.00058     0.05549     0.05350
Alpha_loss                            0.89503      0.38639     1.62140     -0.11217
Training/policy_loss                  -57.17249    3.39893     -49.02432   -65.28445
Training/qf1_loss                     4190.22817   1220.96673  8504.06934  2083.50269
Training/qf2_loss                     1862.72400   795.71321   5309.42383  663.98004
Training/pf_norm                      5.17023      3.75014     16.62281    0.64833
Training/qf1_norm                     1632.23692   888.90331   5822.14160  555.93256
Training/qf2_norm                     1522.83549   745.74822   4779.66943  540.76227
log_std/mean                          -0.83804     0.03810     -0.78007    -0.90582
log_std/std                           0.41140      0.01083     0.43794     0.38505
log_std/max                           0.35933      0.05300     0.42697     0.08720
log_std/min                           -3.72929     0.13613     -3.35884    -3.84587
log_probs/mean                        4.60715      0.15259     4.90082     4.26078
log_probs/std                         4.19954      0.14713     4.49621     3.89293
log_probs/max                         20.39998     0.60983     21.90233    18.52708
log_probs/min                         -6.60965     1.14176     -4.65011    -11.02406
mean/mean                             0.12784      0.04301     0.19965     0.05046
mean/std                              1.57856      0.01075     1.60570     1.55674
mean/max                              4.43223      0.10140     4.66323     4.25538
mean/min                              -5.25826     0.34782     -4.48459    -5.74854
------------------------------------  -----------  ----------  ----------  ----------
sample: [8, 4, 2, 7, 1, 5, 3, 0, 6, 9]
replay_buffer._size: [19050 19050 19050 19050 19050 19050 19050 19050 19050 19050]
2023-08-12 11:57:24,950 MainThread INFO: EPOCH:105
2023-08-12 11:57:24,951 MainThread INFO: Time Consumed:8.530411958694458s
2023-08-12 11:57:24,951 MainThread INFO: Total Frames:189000s
  1%|          | 106/10000 [16:04<24:24:46,  8.88s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1126.31581
Train_Epoch_Reward                    12179.90857
Running_Training_Average_Rewards      857.88377
Explore_Time                          0.00491
Train___Time                          8.52084
Eval____Time                          0.00412
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.85267
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.62322
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.03405
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.09595
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.20092
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.87419
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.06884
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11815.25276
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.94558
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.39927
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.68930      1.33710     10.72512    4.49597
alpha_0                               1.03404      0.01155     1.05453     1.01551
alpha_1                               0.08658      0.00131     0.08880     0.08434
alpha_2                               0.06146      0.00047     0.06225     0.06069
alpha_3                               0.06018      0.00028     0.06073     0.05975
alpha_4                               0.05040      0.00009     0.05059     0.05029
alpha_5                               0.06004      0.00010     0.06029     0.05995
alpha_6                               0.06064      0.00028     0.06102     0.06008
alpha_7                               0.06933      0.00017     0.06968     0.06915
alpha_8                               0.10342      0.00032     0.10381     0.10274
alpha_9                               0.05266      0.00046     0.05348     0.05191
Alpha_loss                            1.22984      0.35887     2.19667     0.37663
Training/policy_loss                  -60.16464    3.02264     -53.19929   -68.56715
Training/qf1_loss                     4398.28909   1104.93721  8135.18213  2015.25867
Training/qf2_loss                     1947.18778   747.26868   3972.60205  533.39038
Training/pf_norm                      4.46938      3.43219     24.99556    1.10165
Training/qf1_norm                     1719.08134   978.02429   5136.10010  546.96802
Training/qf2_norm                     1557.79598   766.99898   4476.59277  489.50085
log_std/mean                          -0.76567     0.01816     -0.72265    -0.79799
log_std/std                           0.41339      0.00849     0.43722     0.39334
log_std/max                           0.45779      0.07633     0.52983     0.17957
log_std/min                           -3.74308     0.15768     -3.33314    -3.88290
log_probs/mean                        4.73462      0.14039     5.10866     4.37816
log_probs/std                         4.07482      0.09844     4.29916     3.87192
log_probs/max                         21.23323     1.02534     23.61883    19.14111
log_probs/min                         -6.76536     1.35286     -4.05295    -12.33277
mean/mean                             0.05903      0.03065     0.13225     0.00097
mean/std                              1.63721      0.02565     1.68804     1.56780
mean/max                              4.62403      0.12970     4.80094     4.36480
mean/min                              -5.62866     0.39456     -4.40013    -5.96419
------------------------------------  -----------  ----------  ----------  ----------
sample: [9, 4, 2, 1, 0, 5, 8, 7, 3, 6]
replay_buffer._size: [19200 19200 19200 19200 19200 19200 19200 19200 19200 19200]
2023-08-12 11:57:33,137 MainThread INFO: EPOCH:106
2023-08-12 11:57:33,137 MainThread INFO: Time Consumed:7.984472036361694s
2023-08-12 11:57:33,137 MainThread INFO: Total Frames:190500s
  1%|          | 107/10000 [16:12<23:55:11,  8.70s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1159.29625
Train_Epoch_Reward                    11889.14633
Running_Training_Average_Rewards      1063.34869
Explore_Time                          0.00490
Train___Time                          7.97504
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.55046
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.89562
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -24.10022
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.36054
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.96391
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.11027
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.07826
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12171.29921
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.50030
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.77717
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.37809      1.48609     12.31754     4.67772
alpha_0                               1.07011      0.00774     1.08197      1.05495
alpha_1                               0.09066      0.00096     0.09215      0.08884
alpha_2                               0.06288      0.00034     0.06345      0.06226
alpha_3                               0.05923      0.00032     0.05974      0.05870
alpha_4                               0.05075      0.00006     0.05080      0.05059
alpha_5                               0.06089      0.00037     0.06153      0.06030
alpha_6                               0.05933      0.00042     0.06007      0.05864
alpha_7                               0.07004      0.00017     0.07028      0.06969
alpha_8                               0.10348      0.00034     0.10382      0.10272
alpha_9                               0.05126      0.00035     0.05189      0.05068
Alpha_loss                            0.16623      0.57488     1.45517      -0.89571
Training/policy_loss                  -61.29572    3.75857     -54.00492    -71.55154
Training/qf1_loss                     4284.17059   1380.34434  10207.48633  1765.75488
Training/qf2_loss                     1781.29815   868.74745   5316.14990   524.35596
Training/pf_norm                      3.98848      2.70527     15.17410     0.89044
Training/qf1_norm                     1725.71456   913.19967   4894.13135   544.46356
Training/qf2_norm                     1731.32378   887.74404   5201.36328   585.96747
log_std/mean                          -0.69512     0.01298     -0.67597     -0.72848
log_std/std                           0.41384      0.00786     0.43528      0.39543
log_std/max                           0.47792      0.05084     0.54123      0.26068
log_std/min                           -3.72007     0.12933     -3.31464     -3.85527
log_probs/mean                        4.24438      0.24445     4.78402      3.82713
log_probs/std                         3.75218      0.19155     4.18106      3.42019
log_probs/max                         20.44037     1.37779     23.34644     17.28724
log_probs/min                         -6.83664     1.31612     -4.36432     -10.96290
mean/mean                             -0.02975     0.03968     0.04152      -0.10258
mean/std                              1.59926      0.03193     1.66606      1.54383
mean/max                              4.69246      0.09384     4.87558      4.51656
mean/min                              -5.71382     0.34896     -4.71626     -6.10251
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 7, 1, 0, 9, 6, 3, 4, 5, 2]
replay_buffer._size: [19350 19350 19350 19350 19350 19350 19350 19350 19350 19350]
2023-08-12 11:57:41,998 MainThread INFO: EPOCH:107
2023-08-12 11:57:41,998 MainThread INFO: Time Consumed:8.417843580245972s
2023-08-12 11:57:41,998 MainThread INFO: Total Frames:192000s
  1%|          | 108/10000 [16:21<23:55:26,  8.71s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1142.10658
Train_Epoch_Reward                    12327.35014
Running_Training_Average_Rewards      1213.21350
Explore_Time                          0.01558
Train___Time                          8.39749
Eval____Time                          0.00405
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.54164
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.54991
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.52694
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.54158
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.76544
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -120.36374
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.10389
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11969.58477
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.93629
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.18955
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.43385      1.32142     10.94332    5.39566
alpha_0                               1.08732      0.00203     1.09086     1.08218
alpha_1                               0.09330      0.00062     0.09443     0.09218
alpha_2                               0.06408      0.00040     0.06476     0.06346
alpha_3                               0.05837      0.00018     0.05870     0.05816
alpha_4                               0.05039      0.00027     0.05075     0.04988
alpha_5                               0.06217      0.00034     0.06278     0.06155
alpha_6                               0.05811      0.00028     0.05863     0.05770
alpha_7                               0.07052      0.00015     0.07088     0.07029
alpha_8                               0.10131      0.00086     0.10270     0.09989
alpha_9                               0.05015      0.00030     0.05067     0.04968
Alpha_loss                            -0.61124     0.66743     1.21619     -1.60091
Training/policy_loss                  -62.86385    3.33253     -53.75204   -70.59279
Training/qf1_loss                     4156.85335   1170.68267  7336.38281  2129.84424
Training/qf2_loss                     1647.86788   732.48288   3768.50000  546.89032
Training/pf_norm                      3.67945      2.09192     10.60208    1.05704
Training/qf1_norm                     1728.04794   1050.09150  5366.13330  529.77124
Training/qf2_norm                     1684.52832   838.10313   4491.13867  564.49097
log_std/mean                          -0.69838     0.02160     -0.66440    -0.75427
log_std/std                           0.41752      0.00994     0.43976     0.39362
log_std/max                           0.46048      0.06546     0.51699     0.12863
log_std/min                           -3.67010     0.12636     -3.25272    -3.77384
log_probs/mean                        3.86774      0.27083     4.60724     3.46206
log_probs/std                         3.53325      0.09971     3.81345     3.31362
log_probs/max                         19.60652     0.98092     21.57575    16.11644
log_probs/min                         -6.91009     1.14827     -4.82366    -10.15269
mean/mean                             -0.07711     0.03536     -0.01393    -0.16224
mean/std                              1.54424      0.03283     1.62463     1.49530
mean/max                              4.80427      0.08011     4.92700     4.66851
mean/min                              -5.41516     0.27459     -4.69675    -5.91328
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 6, 8, 2, 3, 0, 4, 5, 9, 1]
replay_buffer._size: [19500 19500 19500 19500 19500 19500 19500 19500 19500 19500]
2023-08-12 11:57:51,017 MainThread INFO: EPOCH:108
2023-08-12 11:57:51,017 MainThread INFO: Time Consumed:8.835568904876709s
2023-08-12 11:57:51,018 MainThread INFO: Total Frames:193500s
  1%|          | 109/10000 [16:30<24:11:04,  8.80s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1222.41288
Train_Epoch_Reward                    10527.50279
Running_Training_Average_Rewards      1158.13331
Explore_Time                          0.00755
Train___Time                          8.82369
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.48040
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.56189
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.43733
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.12101
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.50444
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.28057
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.05861
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12646.59041
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.94178
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.07562
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.47830      1.30209     10.65420    4.79471
alpha_0                               1.09867      0.00387     1.10457     1.09101
alpha_1                               0.09603      0.00092     0.09760     0.09446
alpha_2                               0.06523      0.00025     0.06559     0.06477
alpha_3                               0.05867      0.00030     0.05920     0.05820
alpha_4                               0.04938      0.00027     0.04987     0.04894
alpha_5                               0.06366      0.00052     0.06461     0.06280
alpha_6                               0.05754      0.00007     0.05769     0.05746
alpha_7                               0.07196      0.00065     0.07309     0.07089
alpha_8                               0.09884      0.00059     0.09987     0.09787
alpha_9                               0.04931      0.00022     0.04968     0.04894
Alpha_loss                            1.18091      0.38889     2.21481     0.15495
Training/policy_loss                  -64.41495    3.35665     -57.95116   -72.46404
Training/qf1_loss                     4220.71992   1076.01395  7274.17139  2373.54663
Training/qf2_loss                     1682.36843   682.46997   3403.87866  555.85046
Training/pf_norm                      4.06614      2.38440     13.54658    0.93921
Training/qf1_norm                     1816.98227   912.19408   5290.56836  619.90784
Training/qf2_norm                     1647.97118   725.32848   4185.78174  493.73764
log_std/mean                          -0.74885     0.00727     -0.73204    -0.76822
log_std/std                           0.41484      0.00881     0.44396     0.39607
log_std/max                           0.46408      0.04731     0.54098     0.22159
log_std/min                           -3.63986     0.11315     -3.33244    -3.75825
log_probs/mean                        4.56920      0.14681     4.96051     4.21264
log_probs/std                         3.57186      0.09068     3.76555     3.32072
log_probs/max                         18.56708     0.90837     20.11864    15.79536
log_probs/min                         -6.78865     1.47961     -4.36301    -11.82278
mean/mean                             -0.09688     0.04407     -0.01784    -0.18602
mean/std                              1.62293      0.01828     1.66846     1.58319
mean/max                              4.89013      0.06598     4.98420     4.61587
mean/min                              -5.32365     0.21326     -4.67528    -5.62148
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 9, 2, 6, 4, 0, 5, 8, 1, 7]
replay_buffer._size: [19650 19650 19650 19650 19650 19650 19650 19650 19650 19650]
2023-08-12 11:57:59,625 MainThread INFO: EPOCH:109
2023-08-12 11:57:59,626 MainThread INFO: Time Consumed:8.425103187561035s
2023-08-12 11:57:59,626 MainThread INFO: Total Frames:195000s
  1%|          | 110/10000 [16:38<24:01:35,  8.75s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1340.63079
Train_Epoch_Reward                    13096.48991
Running_Training_Average_Rewards      1198.37809
Explore_Time                          0.00396
Train___Time                          8.41619
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.73382
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.83550
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.83130
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.81717
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.89096
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.63050
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.20982
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12541.78653
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.81377
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1315.28421
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.66597      1.26762     11.14128    4.89328
alpha_0                               1.11148      0.00395     1.11742     1.10471
alpha_1                               0.09895      0.00073     0.10015     0.09763
alpha_2                               0.06565      0.00003     0.06569     0.06559
alpha_3                               0.05979      0.00033     0.06036     0.05922
alpha_4                               0.04854      0.00023     0.04893     0.04813
alpha_5                               0.06566      0.00059     0.06662     0.06463
alpha_6                               0.05748      0.00001     0.05750     0.05745
alpha_7                               0.07421      0.00061     0.07530     0.07312
alpha_8                               0.09705      0.00047     0.09786     0.09625
alpha_9                               0.04850      0.00026     0.04893     0.04803
Alpha_loss                            0.56793      0.59002     1.79571     -0.50576
Training/policy_loss                  -67.08870    3.38883     -58.87095   -75.54903
Training/qf1_loss                     4314.99184   1081.71984  7741.14551  2275.46265
Training/qf2_loss                     1658.96214   734.09216   4087.78491  621.08331
Training/pf_norm                      3.90412      2.57174     14.27874    0.82615
Training/qf1_norm                     1814.08402   1069.30251  5554.89941  579.71100
Training/qf2_norm                     1590.92085   841.71709   5151.74756  530.37335
log_std/mean                          -0.72640     0.01551     -0.69067    -0.75879
log_std/std                           0.41027      0.00966     0.43230     0.38465
log_std/max                           0.49562      0.05181     0.56638     0.23992
log_std/min                           -3.62192     0.10421     -3.35343    -3.74880
log_probs/mean                        4.33607      0.24201     4.84813     3.87502
log_probs/std                         3.41830      0.08731     3.61525     3.20832
log_probs/max                         17.44147     0.80506     19.04225    15.10515
log_probs/min                         -6.68683     1.22558     -3.83190    -11.09399
mean/mean                             -0.16459     0.02123     -0.11657    -0.20426
mean/std                              1.59084      0.02866     1.65823     1.53987
mean/max                              4.97315      0.05045     5.03186     4.75264
mean/min                              -5.26982     0.20891     -4.60997    -5.61469
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 0, 4, 3, 6, 1, 5, 2, 8, 9]
replay_buffer._size: [19800 19800 19800 19800 19800 19800 19800 19800 19800 19800]
2023-08-12 11:58:08,053 MainThread INFO: EPOCH:110
2023-08-12 11:58:08,053 MainThread INFO: Time Consumed:8.212064743041992s
2023-08-12 11:58:08,053 MainThread INFO: Total Frames:196500s
  1%|          | 111/10000 [16:47<23:45:07,  8.65s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1145.23391
Train_Epoch_Reward                    12069.80602
Running_Training_Average_Rewards      1189.79329
Explore_Time                          0.00669
Train___Time                          8.20055
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.95083
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.88380
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.48378
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.67428
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.62837
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.85280
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.29331
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11919.14401
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.52577
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.51195
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.69201      1.25242     10.80342    4.82365
alpha_0                               1.11847      0.00104     1.12069     1.11728
alpha_1                               0.10111      0.00058     0.10222     0.10017
alpha_2                               0.06556      0.00006     0.06562     0.06539
alpha_3                               0.06089      0.00033     0.06151     0.06037
alpha_4                               0.04757      0.00032     0.04812     0.04706
alpha_5                               0.06739      0.00047     0.06824     0.06663
alpha_6                               0.05735      0.00006     0.05745     0.05726
alpha_7                               0.07627      0.00055     0.07725     0.07532
alpha_8                               0.09529      0.00052     0.09623     0.09449
alpha_9                               0.04736      0.00040     0.04801     0.04666
Alpha_loss                            -0.43671     0.52562     0.62340     -1.35016
Training/policy_loss                  -68.05405    3.14217     -60.76525   -75.07405
Training/qf1_loss                     4476.64682   1179.52027  7844.79639  2459.66113
Training/qf2_loss                     1689.23540   722.16533   3728.77710  499.18307
Training/pf_norm                      3.83056      2.44077     12.22260    0.83535
Training/qf1_norm                     1888.51793   941.72217   4641.52637  494.99805
Training/qf2_norm                     1570.20950   720.14039   4104.42285  633.53253
log_std/mean                          -0.71754     0.01509     -0.68353    -0.74277
log_std/std                           0.40065      0.00959     0.42875     0.38051
log_std/max                           0.54332      0.03304     0.60276     0.38029
log_std/min                           -3.57098     0.12438     -3.20733    -3.70753
log_probs/mean                        3.95446      0.20984     4.39425     3.59454
log_probs/std                         3.43348      0.10511     3.64014     3.10145
log_probs/max                         16.63864     0.90557     18.61375    14.15781
log_probs/min                         -7.15161     1.42506     -4.32599    -14.63895
mean/mean                             -0.11200     0.04141     -0.02878    -0.20044
mean/std                              1.54412      0.03026     1.59388     1.48917
mean/max                              4.94681      0.16142     5.05027     3.43983
mean/min                              -4.98373     0.15291     -4.53203    -5.23063
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 8, 1, 4, 6, 9, 2, 7, 0, 5]
replay_buffer._size: [19950 19950 19950 19950 19950 19950 19950 19950 19950 19950]
2023-08-12 11:58:16,401 MainThread INFO: EPOCH:111
2023-08-12 11:58:16,401 MainThread INFO: Time Consumed:8.174405574798584s
2023-08-12 11:58:16,402 MainThread INFO: Total Frames:198000s
  1%|          | 112/10000 [16:55<23:30:44,  8.56s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1032.02360
Train_Epoch_Reward                    11329.53895
Running_Training_Average_Rewards      1216.52783
Explore_Time                          0.01123
Train___Time                          8.15816
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.57119
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.57114
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.48920
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.91658
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.81850
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.38125
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.17504
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10808.98824
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.02323
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.80609
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.36578      1.50810     13.33327    4.50919
alpha_0                               1.12120      0.00058     1.12256     1.12059
alpha_1                               0.10332      0.00062     0.10432     0.10224
alpha_2                               0.06512      0.00014     0.06539     0.06487
alpha_3                               0.06209      0.00032     0.06261     0.06152
alpha_4                               0.04655      0.00029     0.04705     0.04603
alpha_5                               0.06892      0.00037     0.06951     0.06825
alpha_6                               0.05763      0.00012     0.05783     0.05741
alpha_7                               0.07821      0.00054     0.07908     0.07727
alpha_8                               0.09349      0.00060     0.09447     0.09239
alpha_9                               0.04589      0.00043     0.04664     0.04515
Alpha_loss                            -0.86190     0.49188     0.09899     -2.23308
Training/policy_loss                  -69.13612    3.42257     -60.87107   -78.16957
Training/qf1_loss                     4455.93924   1184.95458  9896.35156  2270.50073
Training/qf2_loss                     1531.45305   678.61098   4284.79150  476.16226
Training/pf_norm                      3.56926      2.06515     11.73211    0.81997
Training/qf1_norm                     2162.16681   1155.99636  6397.43408  653.56104
Training/qf2_norm                     1755.80812   898.33842   5813.03223  579.89380
log_std/mean                          -0.70118     0.01109     -0.67639    -0.72557
log_std/std                           0.40198      0.01335     0.43094     0.37031
log_std/max                           0.51123      0.05291     0.58990     0.18352
log_std/min                           -3.52413     0.14263     -3.04383    -3.66901
log_probs/mean                        3.79635      0.18885     4.19817     3.23529
log_probs/std                         3.42015      0.07995     3.64928     3.18108
log_probs/max                         16.27144     1.12626     19.01488    13.79987
log_probs/min                         -7.02208     1.36637     -4.59026    -12.64896
mean/mean                             0.02095      0.04542     0.08861     -0.07245
mean/std                              1.53200      0.02561     1.59211     1.46519
mean/max                              4.97107      0.09621     5.12719     4.76994
mean/min                              -4.81488     0.19378     -4.38926    -5.06460
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 6, 4, 7, 9, 8, 1, 5, 0, 2]
replay_buffer._size: [20100 20100 20100 20100 20100 20100 20100 20100 20100 20100]
2023-08-12 11:58:25,137 MainThread INFO: EPOCH:112
2023-08-12 11:58:25,137 MainThread INFO: Time Consumed:8.569089651107788s
2023-08-12 11:58:25,137 MainThread INFO: Total Frames:199500s
  1%|          | 113/10000 [17:04<23:38:47,  8.61s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1096.92615
Train_Epoch_Reward                    11096.09175
Running_Training_Average_Rewards      1149.84789
Explore_Time                          0.00643
Train___Time                          8.55860
Eval____Time                          0.00353
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.77347
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.19527
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.51112
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.87227
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.61634
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.60949
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.57314
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11496.77365
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.92577
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.43525
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.39968      1.26689     10.43924    3.82234
alpha_0                               1.12561      0.00233     1.12867     1.12257
alpha_1                               0.10539      0.00059     0.10618     0.10434
alpha_2                               0.06430      0.00038     0.06487     0.06362
alpha_3                               0.06308      0.00026     0.06339     0.06262
alpha_4                               0.04556      0.00026     0.04602     0.04510
alpha_5                               0.07028      0.00049     0.07106     0.06951
alpha_6                               0.05808      0.00015     0.05826     0.05783
alpha_7                               0.07973      0.00033     0.08010     0.07910
alpha_8                               0.09140      0.00057     0.09237     0.09032
alpha_9                               0.04442      0.00041     0.04513     0.04371
Alpha_loss                            -1.46992     1.07389     -0.08155    -3.92909
Training/policy_loss                  -70.47944    3.56266     -61.21727   -78.55917
Training/qf1_loss                     4630.05038   1220.28991  8916.67480  1746.62012
Training/qf2_loss                     1512.21542   626.30660   3483.32007  484.46188
Training/pf_norm                      3.75780      2.56115     13.44480    0.82151
Training/qf1_norm                     2095.05613   1078.80962  5643.05713  738.61169
Training/qf2_norm                     1547.48295   817.53580   5013.96143  545.31628
log_std/mean                          -0.68735     0.02036     -0.64670    -0.71742
log_std/std                           0.40588      0.01339     0.44072     0.37663
log_std/max                           0.50362      0.05181     0.59057     0.19812
log_std/min                           -3.49093     0.14598     -3.07429    -3.62864
log_probs/mean                        3.58551      0.42517     4.17324     2.60856
log_probs/std                         3.29732      0.14054     3.57923     2.94811
log_probs/max                         15.25248     0.79557     17.55421    13.71696
log_probs/min                         -6.86565     1.14114     -4.17981    -10.64734
mean/mean                             0.01937      0.02936     0.08192     -0.06971
mean/std                              1.50123      0.06003     1.56376     1.36321
mean/max                              4.87075      0.07389     5.03284     4.53001
mean/min                              -4.75612     0.19746     -4.36361    -5.04411
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 4, 3, 1, 5, 0, 8, 6, 7, 9]
replay_buffer._size: [20250 20250 20250 20250 20250 20250 20250 20250 20250 20250]
2023-08-12 11:58:34,351 MainThread INFO: EPOCH:113
2023-08-12 11:58:34,351 MainThread INFO: Time Consumed:9.018470525741577s
2023-08-12 11:58:34,351 MainThread INFO: Total Frames:201000s
  1%|          | 114/10000 [17:13<24:09:31,  8.80s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1078.70988
Train_Epoch_Reward                    8277.42072
Running_Training_Average_Rewards      1023.43505
Explore_Time                          0.00446
Train___Time                          9.00920
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.86663
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.61404
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.57233
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.57130
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.58509
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.65777
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.75306
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11311.33325
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.32251
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.29170
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.44163      1.35659     10.78041    4.51580
alpha_0                               1.12885      0.00058     1.13036     1.12808
alpha_1                               0.10633      0.00015     0.10669     0.10618
alpha_2                               0.06284      0.00047     0.06360     0.06198
alpha_3                               0.06347      0.00016     0.06389     0.06333
alpha_4                               0.04445      0.00037     0.04508     0.04385
alpha_5                               0.07187      0.00055     0.07294     0.07107
alpha_6                               0.05790      0.00013     0.05821     0.05777
alpha_7                               0.07972      0.00017     0.08005     0.07953
alpha_8                               0.08936      0.00044     0.09029     0.08879
alpha_9                               0.04302      0.00037     0.04369     0.04244
Alpha_loss                            -2.27165     1.02486     -0.35968    -3.92826
Training/policy_loss                  -70.45467    3.58871     -60.73050   -80.79324
Training/qf1_loss                     4784.07475   1300.80477  8434.29980  2412.67822
Training/qf2_loss                     1520.31863   684.72028   4360.24170  357.46664
Training/pf_norm                      2.74510      1.32592     8.80634     0.82883
Training/qf1_norm                     2115.25533   1043.36523  5933.77832  598.46094
Training/qf2_norm                     1737.12019   897.05804   5002.65234  601.10101
log_std/mean                          -0.69486     0.03320     -0.64874    -0.75447
log_std/std                           0.41666      0.00860     0.43386     0.39346
log_std/max                           0.50442      0.05812     0.60709     0.33686
log_std/min                           -3.42479     0.16621     -3.04282    -3.59323
log_probs/mean                        3.28064      0.38948     4.05590     2.61438
log_probs/std                         3.14377      0.08962     3.38118     2.94204
log_probs/max                         14.89667     0.85752     16.76637    12.83083
log_probs/min                         -7.06779     1.38272     -4.93860    -12.74430
mean/mean                             -0.00441     0.06258     0.11069     -0.11583
mean/std                              1.44453      0.04644     1.52718     1.36220
mean/max                              4.80011      0.05186     4.90181     4.60827
mean/min                              -4.58227     0.13704     -4.25246    -4.79944
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 6, 9, 2, 0, 8, 1, 7, 5, 3]
replay_buffer._size: [20400 20400 20400 20400 20400 20400 20400 20400 20400 20400]
2023-08-12 11:58:43,671 MainThread INFO: EPOCH:114
2023-08-12 11:58:43,671 MainThread INFO: Time Consumed:9.092411994934082s
2023-08-12 11:58:43,671 MainThread INFO: Total Frames:202500s
  1%|          | 115/10000 [17:22<24:34:10,  8.95s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1007.17420
Train_Epoch_Reward                    8586.16763
Running_Training_Average_Rewards      931.98934
Explore_Time                          0.00409
Train___Time                          9.08392
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.15784
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.30922
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.53473
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.94017
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.06551
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.74476
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.31067
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10593.60224
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.94216
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.85520
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.64175      1.38837     12.42233    4.34086
alpha_0                               1.13169      0.00097     1.13365     1.13038
alpha_1                               0.10721      0.00031     0.10770     0.10670
alpha_2                               0.06110      0.00047     0.06197     0.06038
alpha_3                               0.06475      0.00053     0.06565     0.06390
alpha_4                               0.04341      0.00022     0.04384     0.04303
alpha_5                               0.07416      0.00065     0.07523     0.07297
alpha_6                               0.05844      0.00033     0.05894     0.05791
alpha_7                               0.07975      0.00012     0.07990     0.07958
alpha_8                               0.08852      0.00014     0.08878     0.08829
alpha_9                               0.04197      0.00025     0.04243     0.04156
Alpha_loss                            -0.40264     0.52323     0.83579     -1.60383
Training/policy_loss                  -72.51870    4.13098     -60.74615   -81.40514
Training/qf1_loss                     4835.44686   1190.87430  8808.56934  2828.99438
Training/qf2_loss                     1576.85217   666.06656   3450.24219  495.24600
Training/pf_norm                      3.05929      1.66733     10.97700    0.77049
Training/qf1_norm                     2086.90678   998.55553   5699.45410  550.60986
Training/qf2_norm                     1697.77031   870.55578   6307.52930  600.21722
log_std/mean                          -0.75366     0.01530     -0.71595    -0.78331
log_std/std                           0.41188      0.00841     0.43411     0.39431
log_std/max                           0.45087      0.04742     0.50616     0.25217
log_std/min                           -3.31484     0.16368     -2.91868    -3.48926
log_probs/mean                        3.95486      0.20107     4.45556     3.55611
log_probs/std                         3.12470      0.11223     3.38264     2.85629
log_probs/max                         15.19924     0.83329     17.16526    13.07342
log_probs/min                         -6.70697     1.31812     -3.89432    -11.18362
mean/mean                             0.13860      0.08250     0.26787     0.00623
mean/std                              1.51828      0.02608     1.58453     1.46764
mean/max                              4.95708      0.16508     5.25466     4.73333
mean/min                              -4.42266     0.21000     -4.06728    -4.77781
------------------------------------  -----------  ----------  ----------  ----------
sample: [1, 4, 5, 0, 2, 7, 9, 8, 6, 3]
replay_buffer._size: [20550 20550 20550 20550 20550 20550 20550 20550 20550 20550]
2023-08-12 11:58:53,120 MainThread INFO: EPOCH:115
2023-08-12 11:58:53,121 MainThread INFO: Time Consumed:9.265972375869751s
2023-08-12 11:58:53,121 MainThread INFO: Total Frames:204000s
  1%|          | 116/10000 [17:32<24:59:12,  9.10s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               970.14045
Train_Epoch_Reward                    10575.86074
Running_Training_Average_Rewards      914.64830
Explore_Time                          0.00401
Train___Time                          9.25766
Eval____Time                          0.00360
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.78388
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.54574
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.28756
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.86539
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.05775
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.69201
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.15285
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10207.39876
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.41121
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.19784
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.51228      1.26619     10.35369    5.01137
alpha_0                               1.13853      0.00492     1.14736     1.13306
alpha_1                               0.10826      0.00048     0.10918     0.10770
alpha_2                               0.05971      0.00042     0.06037     0.05891
alpha_3                               0.06654      0.00057     0.06747     0.06566
alpha_4                               0.04263      0.00020     0.04302     0.04234
alpha_5                               0.07662      0.00089     0.07809     0.07525
alpha_6                               0.05946      0.00044     0.06036     0.05895
alpha_7                               0.07974      0.00008     0.07986     0.07963
alpha_8                               0.08855      0.00030     0.08901     0.08823
alpha_9                               0.04125      0.00016     0.04156     0.04098
Alpha_loss                            0.55339      1.08502     2.69706     -1.39981
Training/policy_loss                  -73.90300    3.96623     -63.99614   -84.55700
Training/qf1_loss                     4885.48884   1293.91452  8750.66504  2358.10547
Training/qf2_loss                     1479.30151   703.95515   3914.68286  502.83487
Training/pf_norm                      3.39756      1.84423     12.53401    1.07005
Training/qf1_norm                     2097.88348   954.12102   4856.94678  609.61505
Training/qf2_norm                     1841.66464   795.06741   4393.37256  585.92792
log_std/mean                          -0.75594     0.02320     -0.71818    -0.79754
log_std/std                           0.40256      0.01027     0.42860     0.37594
log_std/max                           0.42305      0.05318     0.49397     0.17138
log_std/min                           -3.30300     0.11796     -2.90795    -3.40511
log_probs/mean                        4.35591      0.43490     5.22973     3.55787
log_probs/std                         3.16974      0.12813     3.44652     2.90099
log_probs/max                         15.62945     1.07721     18.37253    12.98209
log_probs/min                         -6.43570     1.30845     -4.02184    -11.23999
mean/mean                             0.13826      0.04997     0.25189     0.04849
mean/std                              1.57988      0.05610     1.68564     1.46866
mean/max                              5.00596      0.10849     5.24832     4.84849
mean/min                              -4.24515     0.12074     -4.03591    -4.50828
------------------------------------  -----------  ----------  ----------  ----------
sample: [0, 7, 5, 9, 1, 8, 3, 6, 4, 2]
replay_buffer._size: [20700 20700 20700 20700 20700 20700 20700 20700 20700 20700]
2023-08-12 11:59:01,765 MainThread INFO: EPOCH:116
2023-08-12 11:59:01,766 MainThread INFO: Time Consumed:8.446531772613525s
2023-08-12 11:59:01,766 MainThread INFO: Total Frames:205500s
  1%|          | 117/10000 [17:40<24:37:50,  8.97s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1170.31827
Train_Epoch_Reward                    9054.60828
Running_Training_Average_Rewards      940.55455
Explore_Time                          0.00477
Train___Time                          8.43728
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.88546
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.56715
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.90821
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.69037
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.15438
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.64565
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.91009
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12308.69060
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.25787
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.48869
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.17785      1.28073     10.74375    4.09964
alpha_0                               1.15949      0.00679     1.16959     1.14756
alpha_1                               0.10968      0.00025     0.11006     0.10919
alpha_2                               0.05803      0.00048     0.05889     0.05727
alpha_3                               0.06793      0.00026     0.06841     0.06748
alpha_4                               0.04211      0.00012     0.04233     0.04190
alpha_5                               0.07911      0.00057     0.08011     0.07811
alpha_6                               0.06108      0.00035     0.06158     0.06038
alpha_7                               0.07930      0.00035     0.07984     0.07865
alpha_8                               0.08885      0.00006     0.08899     0.08874
alpha_9                               0.04061      0.00020     0.04097     0.04028
Alpha_loss                            -0.57048     0.40292     0.35256     -1.50231
Training/policy_loss                  -74.34431    4.26857     -64.35128   -85.22566
Training/qf1_loss                     4774.70118   1188.31062  8325.24512  2174.84741
Training/qf2_loss                     1288.11388   556.64042   2747.16553  386.11755
Training/pf_norm                      3.32965      1.61415     8.74322     0.97782
Training/qf1_norm                     2137.70429   1034.84844  6243.61719  562.24182
Training/qf2_norm                     1819.29228   787.00534   4421.87939  702.78754
log_std/mean                          -0.73086     0.01169     -0.70577    -0.75953
log_std/std                           0.42804      0.00808     0.44492     0.40308
log_std/max                           0.43058      0.04632     0.54583     0.29679
log_std/min                           -3.33942     0.11953     -2.94722    -3.46861
log_probs/mean                        3.93081      0.15766     4.30717     3.57422
log_probs/std                         3.02250      0.09844     3.25888     2.80757
log_probs/max                         15.03318     0.87106     16.85530    12.28859
log_probs/min                         -6.66215     1.29349     -3.94587    -10.29280
mean/mean                             0.08813      0.04751     0.18500     0.01078
mean/std                              1.52552      0.01878     1.56250     1.48280
mean/max                              5.08071      0.09677     5.23495     4.92664
mean/min                              -4.23375     0.17626     -3.91260    -4.46437
------------------------------------  -----------  ----------  ----------  ----------
sample: [8, 7, 3, 2, 1, 4, 0, 9, 5, 6]
replay_buffer._size: [20852 20852 20854 20852 20855 20852 20852 20852 20864 20852]
2023-08-12 11:59:11,075 MainThread INFO: EPOCH:117
2023-08-12 11:59:11,076 MainThread INFO: Time Consumed:9.140218257904053s
2023-08-12 11:59:11,076 MainThread INFO: Total Frames:207000s
  1%|          | 118/10000 [17:50<24:55:51,  9.08s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1175.47583
Train_Epoch_Reward                    11634.92454
Running_Training_Average_Rewards      1042.17979
Explore_Time                          0.06338
Train___Time                          9.07230
Eval____Time                          0.00400
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.57345
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.79568
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.53279
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.53940
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.72672
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.67427
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.69759
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12278.62299
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.11194
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.21281
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.21553      1.40330     12.00567    4.29784
alpha_0                               1.17854      0.00422     1.18471     1.16980
alpha_1                               0.11005      0.00003     0.11008     0.10994
alpha_2                               0.05652      0.00042     0.05725     0.05581
alpha_3                               0.06883      0.00026     0.06934     0.06842
alpha_4                               0.04165      0.00014     0.04190     0.04140
alpha_5                               0.08098      0.00045     0.08169     0.08013
alpha_6                               0.06179      0.00014     0.06206     0.06159
alpha_7                               0.07776      0.00050     0.07863     0.07689
alpha_8                               0.08830      0.00024     0.08874     0.08794
alpha_9                               0.03993      0.00020     0.04028     0.03960
Alpha_loss                            -1.35597     0.39084     -0.39869    -2.14741
Training/policy_loss                  -74.93039    4.24749     -65.96522   -84.38628
Training/qf1_loss                     4753.18433   1219.21370  8382.94336  2675.57300
Training/qf2_loss                     1315.91617   605.45109   3224.69995  418.40283
Training/pf_norm                      3.15720      1.70485     9.79193     0.89551
Training/qf1_norm                     2156.06674   1157.83277  5599.56055  463.23401
Training/qf2_norm                     1599.52208   981.34011   6174.04736  449.42014
log_std/mean                          -0.71952     0.01455     -0.69187    -0.75069
log_std/std                           0.42130      0.00801     0.44090     0.39843
log_std/max                           0.46201      0.05107     0.59494     0.33550
log_std/min                           -3.19504     0.17077     -2.79975    -3.36228
log_probs/mean                        3.60074      0.14793     3.93793     3.29903
log_probs/std                         2.90067      0.06743     3.08118     2.72857
log_probs/max                         14.44963     0.91046     16.47780    12.70193
log_probs/min                         -6.58323     1.33510     -4.53619    -13.46518
mean/mean                             0.06500      0.04461     0.15815     -0.01466
mean/std                              1.47589      0.01624     1.51999     1.43968
mean/max                              5.09036      0.07121     5.25633     4.89633
mean/min                              -4.16400     0.16326     -3.83414    -4.42130
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 1, 7, 4, 5, 0, 9, 8, 6, 3]
replay_buffer._size: [21000 21000 21000 21000 21000 21000 21000 21000 21000 21000]
2023-08-12 11:59:20,161 MainThread INFO: EPOCH:118
2023-08-12 11:59:20,161 MainThread INFO: Time Consumed:8.90170431137085s
2023-08-12 11:59:20,161 MainThread INFO: Total Frames:208500s
  1%|          | 119/10000 [17:59<24:53:54,  9.07s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1138.98497
Train_Epoch_Reward                    12208.13101
Running_Training_Average_Rewards      1096.58879
Explore_Time                          0.01029
Train___Time                          8.88641
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.18592
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.97304
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.60315
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.63792
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.76613
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.49833
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.46150
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11982.66448
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.69967
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.98913
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.43369      1.55260     11.94800    4.77491
alpha_0                               1.19102      0.00556     1.20223     1.18477
alpha_1                               0.11002      0.00018     0.11048     0.10983
alpha_2                               0.05509      0.00043     0.05580     0.05428
alpha_3                               0.06994      0.00040     0.07071     0.06935
alpha_4                               0.04114      0.00012     0.04139     0.04101
alpha_5                               0.08270      0.00065     0.08386     0.08170
alpha_6                               0.06257      0.00044     0.06357     0.06207
alpha_7                               0.07588      0.00050     0.07687     0.07522
alpha_8                               0.08813      0.00025     0.08874     0.08788
alpha_9                               0.03931      0.00015     0.03959     0.03907
Alpha_loss                            0.03579      0.96319     2.00667     -2.03351
Training/policy_loss                  -75.23660    3.74798     -64.82382   -85.79492
Training/qf1_loss                     4826.73408   1301.64536  9175.64258  2373.91455
Training/qf2_loss                     1339.52232   580.73754   3716.24658  440.02100
Training/pf_norm                      3.48286      1.71659     10.26507    1.00504
Training/qf1_norm                     2432.54383   1351.31192  7497.98779  434.73950
Training/qf2_norm                     1858.34508   1036.88683  6430.07861  627.00189
log_std/mean                          -0.74544     0.01592     -0.69414    -0.76738
log_std/std                           0.41072      0.00891     0.43016     0.39282
log_std/max                           0.43126      0.05643     0.58757     0.26873
log_std/min                           -3.17415     0.14323     -2.84295    -3.33531
log_probs/mean                        4.14540      0.38697     4.89715     3.31472
log_probs/std                         3.01864      0.15925     3.39614     2.73458
log_probs/max                         15.40488     1.24325     18.75971    13.00664
log_probs/min                         -6.61672     1.24776     -4.08865    -9.72594
mean/mean                             0.13964      0.05109     0.19770     0.04176
mean/std                              1.54509      0.05441     1.65183     1.43591
mean/max                              5.11704      0.17721     5.27665     4.78713
mean/min                              -4.00035     0.14878     -3.72572    -4.31830
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 0, 4, 2, 7, 3, 5, 1, 9, 8]
replay_buffer._size: [21150 21150 21150 21150 21150 21150 21150 21150 21150 21150]
2023-08-12 11:59:29,197 MainThread INFO: EPOCH:119
2023-08-12 11:59:29,198 MainThread INFO: Time Consumed:8.81913161277771s
2023-08-12 11:59:29,198 MainThread INFO: Total Frames:210000s
  1%|          | 120/10000 [18:08<24:52:20,  9.06s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1157.95884
Train_Epoch_Reward                    10755.98862
Running_Training_Average_Rewards      1153.30147
Explore_Time                          0.01685
Train___Time                          8.79765
Eval____Time                          0.00397
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.92448
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.11944
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.69009
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.27123
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.14900
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.88596
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.46139
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12183.32812
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.42866
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.80945
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.56929      1.35987     11.40682    4.08578
alpha_0                               1.20936      0.00397     1.21521     1.20242
alpha_1                               0.11060      0.00014     0.11078     0.11032
alpha_2                               0.05334      0.00052     0.05426     0.05247
alpha_3                               0.07130      0.00034     0.07190     0.07072
alpha_4                               0.04102      0.00002     0.04105     0.04097
alpha_5                               0.08487      0.00055     0.08581     0.08388
alpha_6                               0.06488      0.00065     0.06586     0.06360
alpha_7                               0.07456      0.00044     0.07521     0.07376
alpha_8                               0.08933      0.00035     0.09007     0.08876
alpha_9                               0.03881      0.00014     0.03906     0.03858
Alpha_loss                            -0.05140     0.58132     1.11802     -1.26623
Training/policy_loss                  -76.64147    4.75567     -61.20916   -86.80013
Training/qf1_loss                     5236.86128   1263.16488  8694.97168  2605.63672
Training/qf2_loss                     1396.95807   576.70691   3040.53198  505.01389
Training/pf_norm                      3.40981      1.93243     11.20913    0.91220
Training/qf1_norm                     2402.81545   1190.89486  6714.14746  645.73236
Training/qf2_norm                     1864.42903   917.68908   5023.57812  579.91315
log_std/mean                          -0.74303     0.01089     -0.71544    -0.76148
log_std/std                           0.41765      0.00761     0.44009     0.40077
log_std/max                           0.40533      0.03485     0.48137     0.25972
log_std/min                           -3.09626     0.14983     -2.69908    -3.21404
log_probs/mean                        4.07458      0.23080     4.56108     3.64651
log_probs/std                         3.08457      0.10217     3.30887     2.91996
log_probs/max                         15.73541     1.23985     18.51125    13.36300
log_probs/min                         -6.73646     1.52967     -3.37160    -13.24936
mean/mean                             0.06849      0.01581     0.11634     0.02939
mean/std                              1.53560      0.03232     1.60208     1.47212
mean/max                              4.95758      0.08097     5.08739     4.58709
mean/min                              -4.03181     0.16389     -3.64110    -4.33112
------------------------------------  -----------  ----------  ----------  ----------
sample: [8, 0, 4, 2, 1, 6, 7, 3, 5, 9]
replay_buffer._size: [21300 21300 21300 21300 21300 21300 21300 21300 21300 21300]
2023-08-12 11:59:38,412 MainThread INFO: EPOCH:120
2023-08-12 11:59:38,412 MainThread INFO: Time Consumed:9.019546747207642s
2023-08-12 11:59:38,412 MainThread INFO: Total Frames:211500s
  1%|          | 121/10000 [18:17<24:58:07,  9.10s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1174.48275
Train_Epoch_Reward                    11809.33473
Running_Training_Average_Rewards      1159.11515
Explore_Time                          0.00363
Train___Time                          9.01099
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.39406
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.23286
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.21497
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.51447
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.66383
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.68501
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.64265
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12353.01201
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.80481
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.03182
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.51708      1.30329     10.40225    4.32760
alpha_0                               1.21863      0.00233     1.22291     1.21513
alpha_1                               0.10983      0.00029     0.11031     0.10936
alpha_2                               0.05170      0.00043     0.05245     0.05095
alpha_3                               0.07259      0.00040     0.07327     0.07191
alpha_4                               0.04078      0.00012     0.04096     0.04058
alpha_5                               0.08686      0.00058     0.08779     0.08583
alpha_6                               0.06651      0.00035     0.06715     0.06588
alpha_7                               0.07280      0.00054     0.07374     0.07187
alpha_8                               0.09128      0.00075     0.09259     0.09009
alpha_9                               0.03844      0.00007     0.03858     0.03831
Alpha_loss                            -0.23671     0.58094     0.73151     -1.59494
Training/policy_loss                  -77.12964    4.46538     -67.45431   -87.57173
Training/qf1_loss                     5376.43461   1294.05846  8796.16602  2820.17456
Training/qf2_loss                     1382.08498   573.79636   3055.51953  340.25046
Training/pf_norm                      2.93033      1.69425     10.23393    1.19519
Training/qf1_norm                     2368.65616   1062.23785  5390.79541  808.12946
Training/qf2_norm                     1830.25596   823.80775   4991.41846  730.68634
log_std/mean                          -0.74653     0.01246     -0.71909    -0.77174
log_std/std                           0.41905      0.00741     0.44113     0.40087
log_std/max                           0.37674      0.04148     0.44842     0.24065
log_std/min                           -3.05804     0.11749     -2.72209    -3.15326
log_probs/mean                        4.00762      0.23022     4.44629     3.48529
log_probs/std                         2.98435      0.08307     3.23113     2.79072
log_probs/max                         14.73444     0.81828     16.67064    12.53472
log_probs/min                         -6.71261     1.54389     -4.31371    -14.33145
mean/mean                             0.13457      0.02046     0.17739     0.08995
mean/std                              1.51913      0.02933     1.58063     1.44915
mean/max                              5.21399      0.08729     5.34542     4.75645
mean/min                              -3.71297     0.07353     -3.52333    -3.88525
------------------------------------  -----------  ----------  ----------  ----------
sample: [9, 7, 3, 6, 4, 1, 2, 0, 5, 8]
replay_buffer._size: [21458 21457 21458 21458 21458 21457 21458 21458 21457 21457]
2023-08-12 11:59:47,508 MainThread INFO: EPOCH:121
2023-08-12 11:59:47,508 MainThread INFO: Time Consumed:8.943724393844604s
2023-08-12 11:59:47,508 MainThread INFO: Total Frames:213000s
  1%|          | 122/10000 [18:26<24:58:11,  9.10s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1160.02255
Train_Epoch_Reward                    12338.81435
Running_Training_Average_Rewards      1163.47126
Explore_Time                          0.15785
Train___Time                          8.78102
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.82076
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.87719
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.00060
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.75912
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.80652
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.74215
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.05755
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12205.79819
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.94668
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.56216
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.46407      1.35999     11.56266     3.97438
alpha_0                               1.22766      0.00146     1.22915      1.22312
alpha_1                               0.10891      0.00052     0.10939      0.10778
alpha_2                               0.05020      0.00039     0.05093      0.04963
alpha_3                               0.07389      0.00028     0.07442      0.07328
alpha_4                               0.04042      0.00016     0.04058      0.04007
alpha_5                               0.08874      0.00054     0.08971      0.08780
alpha_6                               0.06776      0.00023     0.06796      0.06717
alpha_7                               0.07075      0.00070     0.07185      0.06954
alpha_8                               0.09362      0.00047     0.09444      0.09262
alpha_9                               0.03817      0.00009     0.03831      0.03804
Alpha_loss                            -0.94500     0.91058     0.99033      -2.45013
Training/policy_loss                  -77.80123    4.81599     -65.05859    -90.81502
Training/qf1_loss                     5408.96688   1420.07253  10106.80371  3267.12402
Training/qf2_loss                     1342.66788   570.18847   3222.75757   309.83551
Training/pf_norm                      3.02881      2.00061     12.84151     0.75081
Training/qf1_norm                     2559.20099   1342.20388  9146.93848   866.33887
Training/qf2_norm                     1891.17471   931.91971   4576.60938   517.78296
log_std/mean                          -0.74318     0.01654     -0.71594     -0.78386
log_std/std                           0.42032      0.00863     0.44016      0.40174
log_std/max                           0.30376      0.04959     0.40218      0.15987
log_std/min                           -2.98431     0.11011     -2.69372     -3.10987
log_probs/mean                        3.71703      0.36422     4.51352      3.11190
log_probs/std                         2.96735      0.08435     3.19839      2.75491
log_probs/max                         15.40526     1.23838     18.17333     12.11285
log_probs/min                         -6.80441     1.48858     -4.60799     -11.68803
mean/mean                             0.11419      0.02481     0.15556      0.03975
mean/std                              1.47793      0.05044     1.58907      1.39720
mean/max                              5.39777      0.19990     5.68403      4.81748
mean/min                              -3.63748     0.10922     -3.28491     -3.84954
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 0, 1, 5, 3, 9, 6, 7, 4]
replay_buffer._size: [21600 21600 21600 21600 21600 21600 21600 21600 21600 21600]
2023-08-12 11:59:56,484 MainThread INFO: EPOCH:122
2023-08-12 11:59:56,484 MainThread INFO: Time Consumed:8.799756526947021s
2023-08-12 11:59:56,484 MainThread INFO: Total Frames:214500s
  1%|          | 123/10000 [18:35<24:52:16,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1115.00974
Train_Epoch_Reward                    11357.16049
Running_Training_Average_Rewards      1183.51032
Explore_Time                          0.00555
Train___Time                          8.78865
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.41378
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.75652
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.45647
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.78935
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.93675
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.82996
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.67062
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11767.03090
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.63779
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.44221
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.67962      1.55360     11.79582     4.48613
alpha_0                               1.22245      0.00190     1.22682      1.21906
alpha_1                               0.10649      0.00066     0.10775      0.10546
alpha_2                               0.04913      0.00030     0.04962      0.04861
alpha_3                               0.07535      0.00057     0.07636      0.07444
alpha_4                               0.03961      0.00024     0.04006      0.03923
alpha_5                               0.09068      0.00062     0.09190      0.08973
alpha_6                               0.06817      0.00030     0.06875      0.06784
alpha_7                               0.06833      0.00069     0.06952      0.06716
alpha_8                               0.09553      0.00066     0.09670      0.09446
alpha_9                               0.03798      0.00003     0.03804      0.03795
Alpha_loss                            -0.59812     0.63185     1.17919      -2.19891
Training/policy_loss                  -77.97326    4.73883     -66.77618    -88.92451
Training/qf1_loss                     5684.12313   1478.34004  10792.26855  2590.72095
Training/qf2_loss                     1481.27566   673.25972   4021.44458   478.58054
Training/pf_norm                      2.69427      1.32524     7.89197      0.79435
Training/qf1_norm                     2574.63832   1286.94977  7221.29346   677.91016
Training/qf2_norm                     2005.03366   931.81012   5812.12402   654.01263
log_std/mean                          -0.75352     0.01470     -0.72171     -0.78158
log_std/std                           0.41787      0.00709     0.43240      0.39991
log_std/max                           0.33710      0.05535     0.41535      0.16852
log_std/min                           -2.94274     0.07580     -2.71869     -3.05128
log_probs/mean                        3.83313      0.25260     4.56289      3.23932
log_probs/std                         3.03317      0.07917     3.25146      2.85854
log_probs/max                         16.72704     1.18981     19.87708     13.33463
log_probs/min                         -6.71747     1.30377     -4.42577     -12.41637
mean/mean                             0.14554      0.03630     0.22589      0.07749
mean/std                              1.49146      0.03157     1.56581      1.41650
mean/max                              5.68656      0.05824     5.77877      5.50205
mean/min                              -3.62800     0.14994     -3.35306     -3.90294
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 5, 1, 2, 0, 3, 6, 7, 9, 4]
replay_buffer._size: [21750 21750 21750 21750 21750 21750 21750 21750 21750 21750]
2023-08-12 12:00:05,584 MainThread INFO: EPOCH:123
2023-08-12 12:00:05,584 MainThread INFO: Time Consumed:8.918885469436646s
2023-08-12 12:00:05,584 MainThread INFO: Total Frames:216000s
  1%|          | 124/10000 [18:44<24:54:07,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1088.24091
Train_Epoch_Reward                    10524.30130
Running_Training_Average_Rewards      1140.67587
Explore_Time                          0.00581
Train___Time                          8.90819
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.33219
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.59891
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.17983
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.03285
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.04724
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.09101
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.11040
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11501.08918
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.13943
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.14822
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.60227      1.53259     11.83534     4.48056
alpha_0                               1.22306      0.00360     1.22853      1.21798
alpha_1                               0.10472      0.00036     0.10544      0.10427
alpha_2                               0.04808      0.00031     0.04860      0.04754
alpha_3                               0.07783      0.00087     0.07932      0.07638
alpha_4                               0.03893      0.00013     0.03922      0.03877
alpha_5                               0.09320      0.00072     0.09447      0.09193
alpha_6                               0.06960      0.00054     0.07059      0.06877
alpha_7                               0.06624      0.00051     0.06714      0.06541
alpha_8                               0.09810      0.00079     0.09947      0.09672
alpha_9                               0.03810      0.00008     0.03824      0.03796
Alpha_loss                            0.70159      0.42532     1.71266      -0.22763
Training/policy_loss                  -79.78738    5.11466     -65.75726    -94.61990
Training/qf1_loss                     5810.72372   1605.27694  10024.43945  3092.64966
Training/qf2_loss                     1382.30815   681.76006   3466.04492   353.77194
Training/pf_norm                      3.18343      2.30185     15.07571     1.04663
Training/qf1_norm                     2739.45526   1560.96405  7206.31689   867.11157
Training/qf2_norm                     1957.35478   1073.01919  7413.78125   740.20221
log_std/mean                          -0.77067     0.01621     -0.73862     -0.80431
log_std/std                           0.41419      0.00871     0.43267      0.39249
log_std/max                           0.24901      0.06091     0.35279      0.11972
log_std/min                           -2.94050     0.08802     -2.74018     -3.08634
log_probs/mean                        4.35615      0.16716     4.72955      3.96063
log_probs/std                         3.07324      0.06744     3.24821      2.87845
log_probs/max                         16.30006     1.29481     19.44059     12.82590
log_probs/min                         -6.66487     1.47981     -4.34164     -11.27106
mean/mean                             0.13275      0.02304     0.18247      0.07321
mean/std                              1.56379      0.02376     1.61612      1.50948
mean/max                              5.81479      0.10655     5.92493      5.07705
mean/min                              -3.53909     0.22769     -3.24115     -3.93929
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 3, 5, 7, 9, 4, 6, 1, 0]
replay_buffer._size: [21900 21900 21900 21900 21902 21900 21902 21900 21900 21900]
2023-08-12 12:00:14,638 MainThread INFO: EPOCH:124
2023-08-12 12:00:14,638 MainThread INFO: Time Consumed:8.93784761428833s
2023-08-12 12:00:14,638 MainThread INFO: Total Frames:217500s
  1%|▏         | 125/10000 [18:53<24:51:47,  9.06s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1091.95086
Train_Epoch_Reward                    10969.88754
Running_Training_Average_Rewards      1095.04498
Explore_Time                          0.02564
Train___Time                          8.90763
Eval____Time                          0.00405
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.81063
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.35096
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.81665
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.26209
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.16190
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.03721
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.86846
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11539.27790
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.36828
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.09312
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.51258      1.36226     11.64078    4.33032
alpha_0                               1.23706      0.00565     1.24856     1.22860
alpha_1                               0.10440      0.00017     0.10476     0.10424
alpha_2                               0.04696      0.00033     0.04752     0.04641
alpha_3                               0.08072      0.00077     0.08196     0.07935
alpha_4                               0.03890      0.00013     0.03921     0.03877
alpha_5                               0.09621      0.00098     0.09788     0.09450
alpha_6                               0.07180      0.00073     0.07310     0.07061
alpha_7                               0.06462      0.00047     0.06540     0.06379
alpha_8                               0.10086      0.00077     0.10206     0.09950
alpha_9                               0.03835      0.00005     0.03840     0.03824
Alpha_loss                            1.56112      0.29015     2.36221     0.99089
Training/policy_loss                  -79.92678    4.57290     -69.77753   -92.39877
Training/qf1_loss                     5760.41638   1396.28026  8893.95020  3290.85718
Training/qf2_loss                     1246.14152   568.14814   3413.04297  377.71417
Training/pf_norm                      3.20809      2.00771     11.78146    1.03713
Training/qf1_norm                     2720.22368   1304.04579  6755.16113  949.20679
Training/qf2_norm                     1782.37467   792.33608   4733.40234  622.09198
log_std/mean                          -0.76886     0.01033     -0.74632    -0.79380
log_std/std                           0.40858      0.00781     0.42709     0.39090
log_std/max                           0.14203      0.03660     0.19879     0.05732
log_std/min                           -2.89386     0.08164     -2.75808    -3.03953
log_probs/mean                        4.70383      0.11584     4.99898     4.46457
log_probs/std                         3.12667      0.06436     3.32999     2.99221
log_probs/max                         14.46307     0.65534     16.28348    12.85163
log_probs/min                         -6.50191     1.36929     -3.65369    -10.19051
mean/mean                             0.10130      0.01759     0.14568     0.06455
mean/std                              1.61438      0.01356     1.64969     1.57929
mean/max                              5.52822      0.22735     5.87882     4.91527
mean/min                              -3.50092     0.16495     -3.22104    -3.78683
------------------------------------  -----------  ----------  ----------  ----------
sample: [9, 5, 4, 2, 3, 7, 6, 0, 8, 1]
replay_buffer._size: [22050 22050 22050 22050 22050 22050 22050 22050 22050 22050]
2023-08-12 12:00:23,853 MainThread INFO: EPOCH:125
2023-08-12 12:00:23,854 MainThread INFO: Time Consumed:9.03810429573059s
2023-08-12 12:00:23,854 MainThread INFO: Total Frames:219000s
  1%|▏         | 126/10000 [19:03<24:59:11,  9.11s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1055.00327
Train_Epoch_Reward                    11560.14640
Running_Training_Average_Rewards      1101.81117
Explore_Time                          0.00927
Train___Time                          9.02457
Eval____Time                          0.00380
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.06298
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.43093
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.29948
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.87571
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.65875
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.89736
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.13043
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11162.08218
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.95062
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.74319
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.49761      1.39157     10.75654     4.92647
alpha_0                               1.26386      0.00880     1.27899      1.24897
alpha_1                               0.10424      0.00044     0.10478      0.10346
alpha_2                               0.04578      0.00037     0.04640      0.04517
alpha_3                               0.08317      0.00080     0.08467      0.08198
alpha_4                               0.03960      0.00021     0.03995      0.03922
alpha_5                               0.09986      0.00123     0.10205      0.09791
alpha_6                               0.07381      0.00031     0.07427      0.07313
alpha_7                               0.06275      0.00056     0.06377      0.06186
alpha_8                               0.10308      0.00074     0.10455      0.10207
alpha_9                               0.03838      0.00003     0.03846      0.03835
Alpha_loss                            0.90437      0.43860     1.66492      -0.16497
Training/policy_loss                  -80.30531    4.86433     -68.39301    -91.55651
Training/qf1_loss                     5909.24969   1345.16496  11624.41309  3558.27808
Training/qf2_loss                     1215.58410   475.80448   2538.55518   370.81467
Training/pf_norm                      2.87651      1.30048     8.57964      0.80638
Training/qf1_norm                     2751.93719   1341.60838  7769.25391   948.40228
Training/qf2_norm                     1990.90298   930.23029   6012.51074   601.59961
log_std/mean                          -0.74727     0.00891     -0.72058     -0.76350
log_std/std                           0.42201      0.00690     0.43684      0.40370
log_std/max                           0.13361      0.04188     0.25127      0.03885
log_std/min                           -2.89458     0.08353     -2.76349     -3.03652
log_probs/mean                        4.46611      0.17635     4.77105      4.03318
log_probs/std                         3.20699      0.08165     3.40186      2.99794
log_probs/max                         13.91586     0.75301     16.21956     12.42417
log_probs/min                         -6.87163     1.59375     -4.22324     -11.49170
mean/mean                             0.14554      0.03966     0.21725      0.06961
mean/std                              1.57955      0.02017     1.61957      1.53420
mean/max                              5.25700      0.11003     5.38246      4.69485
mean/min                              -3.48798     0.17188     -3.12206     -3.78251
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 1, 6, 9, 2, 8, 7, 3, 5]
replay_buffer._size: [22200 22200 22200 22200 22200 22200 22200 22200 22200 22200]
2023-08-12 12:00:33,012 MainThread INFO: EPOCH:126
2023-08-12 12:00:33,013 MainThread INFO: Time Consumed:8.980458736419678s
2023-08-12 12:00:33,013 MainThread INFO: Total Frames:220500s
  1%|▏         | 127/10000 [19:12<25:02:44,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1081.84516
Train_Epoch_Reward                    10514.91166
Running_Training_Average_Rewards      1101.49819
Explore_Time                          0.01175
Train___Time                          8.96396
Eval____Time                          0.00405
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.89762
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.58156
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.59245
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.21764
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.08690
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.98355
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.77314
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11421.51597
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.90460
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.02688
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.27266      1.39038     11.76119     4.14875
alpha_0                               1.29048      0.00631     1.30113      1.27937
alpha_1                               0.10186      0.00103     0.10344      0.10013
alpha_2                               0.04446      0.00042     0.04516      0.04376
alpha_3                               0.08563      0.00053     0.08667      0.08470
alpha_4                               0.04011      0.00008     0.04028      0.03995
alpha_5                               0.10325      0.00072     0.10471      0.10209
alpha_6                               0.07418      0.00008     0.07431      0.07407
alpha_7                               0.06093      0.00050     0.06184      0.06016
alpha_8                               0.10544      0.00065     0.10682      0.10457
alpha_9                               0.03853      0.00007     0.03870      0.03847
Alpha_loss                            -0.44367     0.98790     1.14855      -2.25537
Training/policy_loss                  -80.30448    5.09864     -68.55033    -91.76245
Training/qf1_loss                     6147.91889   1404.36844  10667.27734  2918.42920
Training/qf2_loss                     1269.63083   596.45616   2980.64038   290.25864
Training/pf_norm                      2.40402      1.09412     5.73072      0.89667
Training/qf1_norm                     2890.70772   1296.60588  7100.64502   996.41235
Training/qf2_norm                     2127.86812   1047.81204  6623.15625   738.40637
log_std/mean                          -0.74191     0.02281     -0.70448     -0.78280
log_std/std                           0.42044      0.00930     0.44186      0.39902
log_std/max                           0.19825      0.06298     0.31637      0.07871
log_std/min                           -2.83219     0.07941     -2.70327     -2.96395
log_probs/mean                        3.92157      0.38226     4.54158      3.19938
log_probs/std                         3.12071      0.10644     3.33753      2.89174
log_probs/max                         14.16571     0.82346     15.98215     11.78450
log_probs/min                         -6.80963     1.32948     -4.29216     -10.35337
mean/mean                             0.06396      0.04874     0.12401      -0.03470
mean/std                              1.50243      0.05027     1.57932      1.41198
mean/max                              5.39515      0.14557     5.57268      5.09070
mean/min                              -3.57831     0.16548     -3.19124     -3.84960
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 1, 3, 9, 2, 0, 6, 7, 5, 4]
replay_buffer._size: [22350 22350 22350 22350 22350 22350 22350 22350 22350 22350]
2023-08-12 12:00:41,646 MainThread INFO: EPOCH:127
2023-08-12 12:00:41,646 MainThread INFO: Time Consumed:8.473553895950317s
2023-08-12 12:00:41,646 MainThread INFO: Total Frames:222000s
  1%|▏         | 128/10000 [19:20<24:38:46,  8.99s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1072.57700
Train_Epoch_Reward                    10928.06035
Running_Training_Average_Rewards      1100.10395
Explore_Time                          0.02130
Train___Time                          8.44720
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.47978
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.59372
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.00021
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.47518
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.52198
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.42933
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.39187
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11342.36049
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.43906
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.25939
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.50212      1.38823     11.32606    5.08069
alpha_0                               1.31345      0.00682     1.32422     1.30134
alpha_1                               0.09812      0.00122     0.10010     0.09594
alpha_2                               0.04308      0.00039     0.04375     0.04243
alpha_3                               0.08777      0.00055     0.08869     0.08670
alpha_4                               0.04031      0.00004     0.04035     0.04023
alpha_5                               0.10586      0.00057     0.10673     0.10474
alpha_6                               0.07428      0.00003     0.07435     0.07420
alpha_7                               0.05950      0.00037     0.06014     0.05891
alpha_8                               0.10802      0.00056     0.10891     0.10685
alpha_9                               0.03892      0.00012     0.03913     0.03871
Alpha_loss                            -0.81248     0.44795     0.35956     -1.54211
Training/policy_loss                  -80.80872    5.93125     -65.29745   -95.09478
Training/qf1_loss                     6400.80888   1665.67265  9934.76074  2736.62354
Training/qf2_loss                     1343.29991   596.75892   3256.23120  401.83984
Training/pf_norm                      2.70447      1.48740     10.14878    0.79821
Training/qf1_norm                     3064.22999   1562.71818  8576.87207  1006.90710
Training/qf2_norm                     2182.23209   998.82624   5310.90039  725.08972
log_std/mean                          -0.74165     0.01092     -0.71534    -0.76606
log_std/std                           0.42827      0.00873     0.45010     0.40033
log_std/max                           0.28925      0.10544     0.46236     0.07951
log_std/min                           -2.82179     0.08560     -2.68341    -2.95860
log_probs/mean                        3.77907      0.17845     4.24918     3.43765
log_probs/std                         3.12493      0.06387     3.27238     2.95574
log_probs/max                         15.05011     0.85603     16.80696    13.33429
log_probs/min                         -6.80503     1.35447     -4.69605    -12.40200
mean/mean                             0.07977      0.03026     0.14848     0.03290
mean/std                              1.48370      0.02231     1.53843     1.43711
mean/max                              5.68978      0.15544     5.96714     5.17754
mean/min                              -3.68498     0.18657     -3.07589    -3.95456
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 8, 0, 6, 1, 2, 5, 3, 9, 7]
replay_buffer._size: [22500 22500 22500 22500 22500 22500 22500 22500 22500 22500]
2023-08-12 12:00:51,012 MainThread INFO: EPOCH:128
2023-08-12 12:00:51,013 MainThread INFO: Time Consumed:9.19362735748291s
2023-08-12 12:00:51,013 MainThread INFO: Total Frames:223500s
  1%|▏         | 129/10000 [19:30<24:55:18,  9.09s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1000.53289
Train_Epoch_Reward                    11123.09575
Running_Training_Average_Rewards      1085.53559
Explore_Time                          0.01561
Train___Time                          9.17286
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.61155
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.76333
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.67599
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.65632
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.58085
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.27299
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.53215
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10620.36786
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.24422
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.70157
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.56462      1.36371     11.22158     4.45790
alpha_0                               1.33409      0.00678     1.34650      1.32433
alpha_1                               0.09368      0.00126     0.09589      0.09172
alpha_2                               0.04184      0.00033     0.04241      0.04130
alpha_3                               0.08965      0.00052     0.09049      0.08871
alpha_4                               0.04025      0.00003     0.04037      0.04022
alpha_5                               0.10778      0.00065     0.10886      0.10674
alpha_6                               0.07486      0.00038     0.07573      0.07436
alpha_7                               0.05845      0.00026     0.05890      0.05812
alpha_8                               0.11042      0.00090     0.11196      0.10893
alpha_9                               0.03949      0.00022     0.03990      0.03914
Alpha_loss                            0.07072      0.66464     1.61743      -0.85749
Training/policy_loss                  -80.16947    5.42495     -67.84681    -94.23093
Training/qf1_loss                     6807.07808   1652.47255  11575.86914  3297.74780
Training/qf2_loss                     1337.80950   527.64187   3618.00317   386.50656
Training/pf_norm                      2.16089      0.91696     6.23934      0.89796
Training/qf1_norm                     2925.64401   1556.68944  9116.12793   785.66229
Training/qf2_norm                     2068.93067   942.66400   6297.56885   682.43665
log_std/mean                          -0.76147     0.01847     -0.71559     -0.80045
log_std/std                           0.42802      0.01158     0.45085      0.40419
log_std/max                           0.29378      0.13078     0.49323      0.06397
log_std/min                           -2.81775     0.07560     -2.66317     -2.94298
log_probs/mean                        4.10257      0.25613     4.74000      3.71065
log_probs/std                         3.17809      0.06259     3.34254      2.97539
log_probs/max                         15.27709     0.99622     17.62004     13.05835
log_probs/min                         -6.56725     1.15424     -4.31853     -9.65699
mean/mean                             0.16738      0.02384     0.21757      0.12327
mean/std                              1.52041      0.03088     1.59950      1.46803
mean/max                              6.01103      0.12608     6.20674      5.76629
mean/min                              -3.68618     0.20964     -3.23456     -3.97284
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 6, 4, 1, 0, 5, 9, 8, 2, 3]
replay_buffer._size: [22650 22650 22650 22650 22650 22650 22650 22650 22650 22650]
2023-08-12 12:00:59,628 MainThread INFO: EPOCH:129
2023-08-12 12:00:59,628 MainThread INFO: Time Consumed:8.416609048843384s
2023-08-12 12:00:59,628 MainThread INFO: Total Frames:225000s
  1%|▏         | 130/10000 [19:38<24:33:28,  8.96s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1054.59415
Train_Epoch_Reward                    9689.90139
Running_Training_Average_Rewards      1058.03525
Explore_Time                          0.01091
Train___Time                          8.40051
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.15242
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.91293
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.15581
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.35795
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.84899
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.24135
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.21604
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11149.90633
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.93526
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.14411
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.58846      1.43847     12.00673     4.28424
alpha_0                               1.35917      0.00733     1.37283      1.34678
alpha_1                               0.09007      0.00098     0.09169      0.08838
alpha_2                               0.04074      0.00033     0.04129      0.04017
alpha_3                               0.09103      0.00021     0.09122      0.09050
alpha_4                               0.04058      0.00009     0.04066      0.04038
alpha_5                               0.10961      0.00044     0.11044      0.10888
alpha_6                               0.07676      0.00045     0.07723      0.07576
alpha_7                               0.05789      0.00023     0.05812      0.05737
alpha_8                               0.11275      0.00030     0.11299      0.11199
alpha_9                               0.04026      0.00019     0.04058      0.03990
Alpha_loss                            -0.63306     0.73507     0.75853      -1.84430
Training/policy_loss                  -80.95548    5.65562     -67.97503    -93.66418
Training/qf1_loss                     6817.52377   1707.22468  12432.08105  3134.07959
Training/qf2_loss                     1316.96199   629.98236   3349.65698   301.20776
Training/pf_norm                      2.68991      1.24362     7.88461      1.20440
Training/qf1_norm                     3037.02752   1546.37009  8562.20898   946.58752
Training/qf2_norm                     2146.67253   1178.27720  7233.35059   599.30994
log_std/mean                          -0.77641     0.01178     -0.74770     -0.80059
log_std/std                           0.41430      0.00546     0.43056      0.40169
log_std/max                           0.07874      0.03309     0.17047      0.00744
log_std/min                           -2.81202     0.06034     -2.65748     -2.95569
log_probs/mean                        3.82979      0.28001     4.41719      3.31907
log_probs/std                         3.08771      0.07291     3.29299      2.93055
log_probs/max                         14.66686     0.82569     16.54730     12.68839
log_probs/min                         -6.63986     1.39861     -4.49861     -12.30381
mean/mean                             0.11731      0.04266     0.20390      0.02757
mean/std                              1.47958      0.03728     1.55821      1.40920
mean/max                              5.95904      0.23042     6.29591      5.61177
mean/min                              -3.80215     0.16583     -3.36349     -4.16738
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 5, 3, 8, 4, 7, 9, 1, 6]
replay_buffer._size: [22800 22800 22800 22800 22800 22800 22800 22800 22800 22800]
2023-08-12 12:01:08,648 MainThread INFO: EPOCH:130
2023-08-12 12:01:08,649 MainThread INFO: Time Consumed:8.86202096939087s
2023-08-12 12:01:08,649 MainThread INFO: Total Frames:226500s
  1%|▏         | 131/10000 [19:47<24:35:47,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1029.04053
Train_Epoch_Reward                    10271.18570
Running_Training_Average_Rewards      1036.13943
Explore_Time                          0.00469
Train___Time                          8.85290
Eval____Time                          0.00394
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.62939
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.70422
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.38085
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.19273
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.09973
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.77213
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.55768
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10849.60490
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.67779
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.18503
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.31446      1.55968     12.64603     3.68072
alpha_0                               1.37940      0.00340     1.38338      1.37304
alpha_1                               0.08684      0.00084     0.08835      0.08546
alpha_2                               0.03968      0.00027     0.04016      0.03922
alpha_3                               0.09139      0.00010     0.09157      0.09122
alpha_4                               0.04047      0.00014     0.04064      0.04016
alpha_5                               0.11147      0.00062     0.11250      0.11046
alpha_6                               0.07737      0.00008     0.07752      0.07723
alpha_7                               0.05676      0.00031     0.05735      0.05632
alpha_8                               0.11288      0.00004     0.11293      0.11278
alpha_9                               0.04097      0.00021     0.04132      0.04059
Alpha_loss                            -1.02677     0.34229     -0.01168     -1.70362
Training/policy_loss                  -80.42312    6.04770     -60.59414    -93.93155
Training/qf1_loss                     6833.22275   1612.23203  11356.00098  3354.47437
Training/qf2_loss                     1259.79682   570.12837   2982.10669   273.39218
Training/pf_norm                      2.79439      1.40714     7.58485      1.09578
Training/qf1_norm                     3316.00408   2093.03812  9763.41113   680.70026
Training/qf2_norm                     2246.11551   1132.80514  6056.96143   571.28717
log_std/mean                          -0.77243     0.00828     -0.75570     -0.78976
log_std/std                           0.41325      0.00752     0.42855      0.39419
log_std/max                           0.03361      0.04860     0.15412      -0.07430
log_std/min                           -2.82870     0.05989     -2.66333     -2.93477
log_probs/mean                        3.66872      0.14996     4.08520      3.39929
log_probs/std                         3.02540      0.07235     3.23264      2.86024
log_probs/max                         16.48879     0.87997     18.22973     14.20401
log_probs/min                         -6.55206     1.37871     -3.92207     -10.64500
mean/mean                             0.14726      0.05961     0.24133      0.04640
mean/std                              1.45767      0.01907     1.50801      1.41950
mean/max                              6.31734      0.10184     6.50485      6.01827
mean/min                              -3.82190     0.19550     -3.34294     -4.15110
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 5, 4, 0, 1, 2, 7, 3, 8, 6]
replay_buffer._size: [22950 22950 22950 22950 22950 22950 22950 22950 22950 22950]
2023-08-12 12:01:18,149 MainThread INFO: EPOCH:131
2023-08-12 12:01:18,149 MainThread INFO: Time Consumed:9.291134119033813s
2023-08-12 12:01:18,149 MainThread INFO: Total Frames:228000s
  1%|▏         | 132/10000 [19:57<25:01:07,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1013.03091
Train_Epoch_Reward                    9693.64841
Running_Training_Average_Rewards      988.49118
Explore_Time                          0.00595
Train___Time                          9.28097
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.22014
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.96694
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.52804
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.65852
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.08703
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.75067
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.68338
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10665.19195
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.44454
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.54364
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.61883      1.35374     12.35605     4.77503
alpha_0                               1.38320      0.00190     1.38555      1.38000
alpha_1                               0.08447      0.00051     0.08544      0.08365
alpha_2                               0.03889      0.00014     0.03921      0.03873
alpha_3                               0.09203      0.00030     0.09256      0.09157
alpha_4                               0.03963      0.00030     0.04015      0.03914
alpha_5                               0.11321      0.00042     0.11391      0.11251
alpha_6                               0.07781      0.00013     0.07793      0.07753
alpha_7                               0.05608      0.00013     0.05631      0.05586
alpha_8                               0.11308      0.00024     0.11341      0.11277
alpha_9                               0.04173      0.00026     0.04220      0.04133
Alpha_loss                            -0.47783     0.40701     0.45120      -1.39081
Training/policy_loss                  -82.69456    5.57643     -71.60848    -97.07043
Training/qf1_loss                     7124.32349   1988.77161  12506.26074  3528.98682
Training/qf2_loss                     1256.51520   563.09740   2806.19165   351.32449
Training/pf_norm                      2.92952      1.44972     8.68075      1.07743
Training/qf1_norm                     3072.89383   1443.37530  6996.18018   1078.75586
Training/qf2_norm                     1904.15533   897.55186   4903.43896   642.33118
log_std/mean                          -0.79769     0.01088     -0.77309     -0.82097
log_std/std                           0.41767      0.00696     0.43935      0.39932
log_std/max                           0.02546      0.03331     0.10491      -0.04815
log_std/min                           -2.90980     0.05686     -2.72181     -3.00294
log_probs/mean                        3.86184      0.14672     4.20068      3.51678
log_probs/std                         3.09144      0.07812     3.30332      2.90305
log_probs/max                         18.89923     1.38965     21.18656     13.58049
log_probs/min                         -6.45895     1.27759     -4.00301     -10.52442
mean/mean                             0.12284      0.03230     0.17817      0.05654
mean/std                              1.48979      0.01895     1.52954      1.44412
mean/max                              6.69650      0.22938     6.97752      6.13503
mean/min                              -3.82361     0.24381     -3.28716     -4.34323
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 6, 5, 0, 2, 3, 8, 4, 7, 9]
replay_buffer._size: [23100 23100 23100 23100 23100 23100 23100 23100 23100 23100]
2023-08-12 12:01:27,655 MainThread INFO: EPOCH:132
2023-08-12 12:01:27,655 MainThread INFO: Time Consumed:9.322649955749512s
2023-08-12 12:01:27,655 MainThread INFO: Total Frames:229500s
  1%|▏         | 133/10000 [20:06<25:19:13,  9.24s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               904.47145
Train_Epoch_Reward                    9903.45178
Running_Training_Average_Rewards      995.60953
Explore_Time                          0.00513
Train___Time                          9.31284
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.75069
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.96337
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.59262
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.36416
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.18703
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.11645
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.89428
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9564.60914
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.65463
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -11.37137
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.42392     1.36387     10.12341     3.90316
alpha_0                               1.38384     0.00251     1.38711      1.37996
alpha_1                               0.08296     0.00033     0.08364      0.08253
alpha_2                               0.03850     0.00017     0.03873      0.03816
alpha_3                               0.09283     0.00011     0.09295      0.09257
alpha_4                               0.03865     0.00028     0.03913      0.03818
alpha_5                               0.11523     0.00080     0.11661      0.11392
alpha_6                               0.07848     0.00059     0.07974      0.07787
alpha_7                               0.05573     0.00004     0.05585      0.05569
alpha_8                               0.11369     0.00027     0.11414      0.11339
alpha_9                               0.04268     0.00027     0.04307      0.04221
Alpha_loss                            -0.02106    0.43298     1.26549      -0.84865
Training/policy_loss                  -80.86900   6.22311     -66.25604    -97.66496
Training/qf1_loss                     7048.18808  1832.79367  13739.38184  3510.62573
Training/qf2_loss                     1217.22121  534.51617   2675.54956   311.67853
Training/pf_norm                      3.13629     1.76342     10.66489     1.17797
Training/qf1_norm                     3145.10528  1357.21267  6849.87891   1141.96716
Training/qf2_norm                     2342.37458  1095.06002  5832.03418   583.94946
log_std/mean                          -0.77889    0.01148     -0.75323     -0.80815
log_std/std                           0.41190     0.00622     0.42857      0.39646
log_std/max                           0.07091     0.04632     0.15191      -0.05517
log_std/min                           -2.90475    0.06583     -2.68833     -3.00818
log_probs/mean                        4.07408     0.20871     4.63319      3.74000
log_probs/std                         3.15517     0.07419     3.33294      2.98583
log_probs/max                         18.55063    1.27163     20.83792     15.25827
log_probs/min                         -6.49266    1.39473     -4.39719     -10.91745
mean/mean                             0.06244     0.02750     0.12390      0.00558
mean/std                              1.53159     0.02624     1.60095      1.47933
mean/max                              6.63639     0.17124     6.88252      5.67856
mean/min                              -3.94538    0.17416     -3.33628     -4.38405
------------------------------------  ----------  ----------  -----------  ----------
sample: [3, 4, 9, 1, 7, 0, 5, 6, 2, 8]
replay_buffer._size: [23250 23250 23250 23250 23250 23250 23250 23250 23250 23251]
2023-08-12 12:01:36,651 MainThread INFO: EPOCH:133
2023-08-12 12:01:36,651 MainThread INFO: Time Consumed:8.866127729415894s
2023-08-12 12:01:36,651 MainThread INFO: Total Frames:231000s
  1%|▏         | 134/10000 [20:15<25:07:14,  9.17s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1263.72375
Train_Epoch_Reward                    8941.02108
Running_Training_Average_Rewards      951.27071
Explore_Time                          0.01721
Train___Time                          8.84372
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.96030
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.95392
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.30941
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -75.47415
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.11083
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -90.39487
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.42689
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11357.80113
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.67557
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1805.74231
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.38564      1.31859     10.95784     4.52666
alpha_0                               1.39631      0.00804     1.40888      1.38632
alpha_1                               0.08240      0.00007     0.08256      0.08232
alpha_2                               0.03774      0.00025     0.03815      0.03729
alpha_3                               0.09299      0.00014     0.09323      0.09285
alpha_4                               0.03783      0.00016     0.03817      0.03765
alpha_5                               0.11817      0.00094     0.11987      0.11664
alpha_6                               0.08133      0.00095     0.08312      0.07977
alpha_7                               0.05585      0.00011     0.05604      0.05572
alpha_8                               0.11490      0.00054     0.11572      0.11414
alpha_9                               0.04360      0.00037     0.04427      0.04308
Alpha_loss                            0.89748      0.54025     2.13750      -0.32827
Training/policy_loss                  -82.21015    5.90661     -69.80211    -99.16889
Training/qf1_loss                     7394.50991   1998.39583  13326.19434  3310.03296
Training/qf2_loss                     1181.27331   520.81827   3018.80957   394.19751
Training/pf_norm                      2.52154      1.03134     7.39204      1.19689
Training/qf1_norm                     3485.33142   1589.57481  10021.86719  1041.07507
Training/qf2_norm                     2187.69250   975.74649   5252.54102   731.78247
log_std/mean                          -0.77957     0.01163     -0.75566     -0.80679
log_std/std                           0.40738      0.00956     0.43058      0.38664
log_std/max                           0.14495      0.03204     0.20036      0.07340
log_std/min                           -2.94990     0.05555     -2.75561     -3.03759
log_probs/mean                        4.46263      0.20817     4.95294      4.00209
log_probs/std                         3.16169      0.07918     3.42547      2.91423
log_probs/max                         17.67300     1.45449     20.88982     14.73611
log_probs/min                         -6.25482     1.08849     -4.02283     -9.94501
mean/mean                             0.06691      0.05765     0.17663      -0.02418
mean/std                              1.58169      0.02604     1.63557      1.52986
mean/max                              6.50167      0.24093     6.84433      5.72109
mean/min                              -3.95257     0.14188     -3.41611     -4.16445
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 0, 3, 5, 6, 8, 9, 2, 4, 1]
replay_buffer._size: [23400 23400 23400 23400 23400 23400 23400 23400 23400 23400]
2023-08-12 12:01:45,988 MainThread INFO: EPOCH:134
2023-08-12 12:01:45,990 MainThread INFO: Time Consumed:9.166323900222778s
2023-08-12 12:01:45,990 MainThread INFO: Total Frames:232500s
  1%|▏         | 135/10000 [20:25<25:16:42,  9.22s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               986.03640
Train_Epoch_Reward                    11085.13176
Running_Training_Average_Rewards      997.65349
Explore_Time                          0.00456
Train___Time                          9.15695
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.47313
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.99169
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.39753
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.18114
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.15391
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.61439
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.72822
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10378.74958
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.99291
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.85266
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.41307      1.27514     11.61298     4.37293
alpha_0                               1.41576      0.00440     1.42132      1.40872
alpha_1                               0.08267      0.00005     0.08274      0.08256
alpha_2                               0.03686      0.00025     0.03728      0.03643
alpha_3                               0.09336      0.00006     0.09343      0.09324
alpha_4                               0.03759      0.00008     0.03766      0.03738
alpha_5                               0.12192      0.00118     0.12394      0.11990
alpha_6                               0.08479      0.00076     0.08571      0.08316
alpha_7                               0.05608      0.00008     0.05618      0.05590
alpha_8                               0.11598      0.00010     0.11608      0.11573
alpha_9                               0.04485      0.00031     0.04537      0.04429
Alpha_loss                            0.55838      0.79541     2.06955      -1.03258
Training/policy_loss                  -81.37716    5.78123     -69.33132    -97.70006
Training/qf1_loss                     7192.66755   1753.79967  11258.81152  3324.44995
Training/qf2_loss                     1160.82207   520.45865   2728.68921   221.98912
Training/pf_norm                      3.33125      1.76347     12.32113     1.16001
Training/qf1_norm                     3293.57373   1449.21143  7055.20850   1094.36328
Training/qf2_norm                     2144.30608   1107.83472  6842.58301   695.11261
log_std/mean                          -0.77737     0.01539     -0.74603     -0.81545
log_std/std                           0.40406      0.00797     0.41984      0.38703
log_std/max                           0.10911      0.02474     0.15421      0.00304
log_std/min                           -2.99541     0.04319     -2.86439     -3.08787
log_probs/mean                        4.31832      0.31334     4.96186      3.69911
log_probs/std                         3.10441      0.08572     3.32028      2.90254
log_probs/max                         15.72245     0.94552     17.85523     13.64108
log_probs/min                         -6.35887     1.36048     -3.04264     -12.05272
mean/mean                             -0.05132     0.03911     0.01849      -0.14582
mean/std                              1.55369      0.04499     1.64510      1.46405
mean/max                              5.96503      0.11276     6.20583      5.66880
mean/min                              -4.15002     0.18514     -3.44775     -4.42550
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 6, 9, 4, 7, 8, 2, 0, 1, 3]
replay_buffer._size: [23550 23550 23550 23550 23550 23550 23550 23550 23550 23550]
2023-08-12 12:01:55,612 MainThread INFO: EPOCH:135
2023-08-12 12:01:55,612 MainThread INFO: Time Consumed:9.478154182434082s
2023-08-12 12:01:55,612 MainThread INFO: Total Frames:234000s
  1%|▏         | 136/10000 [20:34<25:39:39,  9.37s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1049.24839
Train_Epoch_Reward                    9612.54926
Running_Training_Average_Rewards      987.95674
Explore_Time                          0.01742
Train___Time                          9.45670
Eval____Time                          0.00332
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.78639
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.20339
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.58886
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.16317
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.67387
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.27515
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.99143
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9563.31131
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.78933
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1423.64417
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.49140     1.44284     11.94901     4.08843
alpha_0                               1.42330     0.00084     1.42501      1.42149
alpha_1                               0.08275     0.00010     0.08286      0.08260
alpha_2                               0.03607     0.00020     0.03642      0.03572
alpha_3                               0.09304     0.00019     0.09336      0.09276
alpha_4                               0.03696     0.00025     0.03737      0.03651
alpha_5                               0.12600     0.00109     0.12779      0.12398
alpha_6                               0.08593     0.00011     0.08608      0.08573
alpha_7                               0.05576     0.00009     0.05590      0.05558
alpha_8                               0.11654     0.00035     0.11714      0.11607
alpha_9                               0.04602     0.00040     0.04672      0.04539
Alpha_loss                            0.01797     0.39962     0.82912      -0.76925
Training/policy_loss                  -80.57221   5.78971     -68.89754    -96.09375
Training/qf1_loss                     7584.62177  1938.60205  13781.52344  3111.56226
Training/qf2_loss                     1129.13819  529.15888   2797.24585   357.80276
Training/pf_norm                      2.64257     1.00552     7.05683      1.23087
Training/qf1_norm                     3481.98248  1546.42354  9831.87109   1246.57239
Training/qf2_norm                     2328.81853  995.81808   5525.10547   898.53363
log_std/mean                          -0.79013    0.01436     -0.75614     -0.82269
log_std/std                           0.41265     0.00845     0.43265      0.38775
log_std/max                           0.09890     0.03178     0.16689      -0.00115
log_std/min                           -3.08043    0.05598     -2.87382     -3.16619
log_probs/mean                        4.09147     0.16018     4.44124      3.81957
log_probs/std                         3.11059     0.06712     3.28733      2.96674
log_probs/max                         16.06999    0.93555     17.83002     13.87381
log_probs/min                         -6.40809    1.24242     -3.91992     -9.86695
mean/mean                             0.02888     0.05534     0.11148      -0.11868
mean/std                              1.51936     0.01911     1.56487      1.48291
mean/max                              5.99735     0.11220     6.17692      5.62562
mean/min                              -3.96231    0.16969     -3.51300     -4.22336
------------------------------------  ----------  ----------  -----------  ----------
sample: [1, 3, 5, 0, 7, 9, 6, 8, 4, 2]
replay_buffer._size: [23702 23702 23702 23702 23705 23702 23702 23702 23702 23702]
2023-08-12 12:02:04,720 MainThread INFO: EPOCH:136
2023-08-12 12:02:04,720 MainThread INFO: Time Consumed:8.901742219924927s
2023-08-12 12:02:04,721 MainThread INFO: Total Frames:235500s
  1%|▏         | 137/10000 [20:43<25:22:49,  9.26s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               859.79214
Train_Epoch_Reward                    11102.13118
Running_Training_Average_Rewards      1059.99374
Explore_Time                          0.07638
Train___Time                          8.82057
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.11664
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.42966
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.51738
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.86658
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.83305
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.69409
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.16075
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9108.80250
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.40758
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.85532
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.21275      1.25227     10.52120     4.26933
alpha_0                               1.41523      0.00398     1.42211      1.40941
alpha_1                               0.08296      0.00005     0.08307      0.08286
alpha_2                               0.03540      0.00019     0.03571      0.03504
alpha_3                               0.09273      0.00002     0.09277      0.09270
alpha_4                               0.03600      0.00030     0.03650      0.03549
alpha_5                               0.12990      0.00124     0.13209      0.12783
alpha_6                               0.08605      0.00017     0.08623      0.08574
alpha_7                               0.05538      0.00010     0.05558      0.05526
alpha_8                               0.11778      0.00043     0.11864      0.11715
alpha_9                               0.04747      0.00042     0.04820      0.04673
Alpha_loss                            0.23040      0.50013     1.53121      -0.87289
Training/policy_loss                  -80.84755    6.40230     -63.50521    -96.43230
Training/qf1_loss                     7477.74716   1893.94664  12764.74707  3774.17358
Training/qf2_loss                     1083.72096   528.90170   3582.72925   273.31262
Training/pf_norm                      2.80088      1.44055     9.13394      0.90707
Training/qf1_norm                     3340.59756   1491.98605  8173.25146   1037.08582
Training/qf2_norm                     2060.59019   935.95810   5534.34570   628.40173
log_std/mean                          -0.79617     0.01283     -0.76787     -0.82140
log_std/std                           0.40399      0.00703     0.41841      0.38618
log_std/max                           0.03105      0.03898     0.11694      -0.04898
log_std/min                           -3.09920     0.05233     -2.93041     -3.20624
log_probs/mean                        4.17527      0.21963     4.66250      3.66534
log_probs/std                         3.07181      0.06317     3.25916      2.95268
log_probs/max                         14.98210     0.74939     17.28817     13.43832
log_probs/min                         -6.49060     1.38330     -4.21954     -11.24794
mean/mean                             0.02636      0.01759     0.06985      -0.01440
mean/std                              1.52512      0.02670     1.58452      1.45906
mean/max                              5.71474      0.10244     5.93415      5.34759
mean/min                              -4.07964     0.17253     -3.63629     -4.38057
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 3, 4, 5, 8, 2, 0, 9, 6, 7]
replay_buffer._size: [23850 23850 23850 23850 23850 23850 23850 23850 23850 23850]
2023-08-12 12:02:14,409 MainThread INFO: EPOCH:137
2023-08-12 12:02:14,409 MainThread INFO: Time Consumed:9.465748071670532s
2023-08-12 12:02:14,409 MainThread INFO: Total Frames:237000s
  1%|▏         | 138/10000 [20:53<25:43:09,  9.39s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1009.62542
Train_Epoch_Reward                    9198.94590
Running_Training_Average_Rewards      997.12088
Explore_Time                          0.00510
Train___Time                          9.45618
Eval____Time                          0.00374
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.80769
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.15040
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.34634
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.45342
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -84.65768
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.35081
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.82743
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9494.92577
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.29248
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1109.21467
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.21671     1.42894     12.17199     3.88852
alpha_0                               1.40551     0.00292     1.40971      1.40109
alpha_1                               0.08337     0.00024     0.08393      0.08308
alpha_2                               0.03464     0.00021     0.03503      0.03437
alpha_3                               0.09290     0.00016     0.09312      0.09268
alpha_4                               0.03507     0.00021     0.03548      0.03476
alpha_5                               0.13435     0.00129     0.13653      0.13213
alpha_6                               0.08636     0.00021     0.08695      0.08622
alpha_7                               0.05547     0.00017     0.05581      0.05528
alpha_8                               0.11959     0.00069     0.12103      0.11866
alpha_9                               0.04898     0.00046     0.04980      0.04822
Alpha_loss                            0.78780     0.68836     2.30323      -0.50351
Training/policy_loss                  -81.01506   6.72295     -66.73159    -106.19769
Training/qf1_loss                     7527.60871  1686.14107  11266.48047  4128.80957
Training/qf2_loss                     1022.88671  461.32829   2627.71484   315.61685
Training/pf_norm                      2.51156     0.96531     6.48247      1.13319
Training/qf1_norm                     3560.15964  1772.59963  9351.23828   1025.00354
Training/qf2_norm                     2329.29340  1282.98407  8161.41455   502.87820
log_std/mean                          -0.81412    0.01024     -0.78401     -0.83312
log_std/std                           0.40430     0.00876     0.42645      0.37479
log_std/max                           0.03287     0.05490     0.11546      -0.09790
log_std/min                           -3.22867    0.06482     -2.95877     -3.30546
log_probs/mean                        4.40663     0.26913     4.95926      3.91961
log_probs/std                         3.05219     0.05622     3.17699      2.89441
log_probs/max                         15.35039    0.64739     16.63964     13.16058
log_probs/min                         -6.25609    1.33114     -3.74998     -11.14887
mean/mean                             0.10906     0.04896     0.19477      0.01462
mean/std                              1.55301     0.03612     1.62529      1.49195
mean/max                              5.92524     0.17331     6.12179      4.88678
mean/min                              -3.99156    0.21840     -3.46727     -4.40368
------------------------------------  ----------  ----------  -----------  ----------
sample: [1, 8, 5, 0, 4, 9, 3, 7, 6, 2]
replay_buffer._size: [24000 24000 24000 24000 24000 24000 24000 24000 24000 24000]
2023-08-12 12:02:23,894 MainThread INFO: EPOCH:138
2023-08-12 12:02:23,895 MainThread INFO: Time Consumed:9.307925701141357s
2023-08-12 12:02:23,895 MainThread INFO: Total Frames:238500s
  1%|▏         | 139/10000 [21:03<25:47:32,  9.42s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               955.68975
Train_Epoch_Reward                    10137.93623
Running_Training_Average_Rewards      1014.63378
Explore_Time                          0.01875
Train___Time                          9.28488
Eval____Time                          0.00364
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.59673
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.01432
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.29163
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.78002
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.81426
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.83066
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.47877
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10069.65640
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.04602
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.90645
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.16346      1.30145     10.90153     4.28002
alpha_0                               1.39956      0.00358     1.40883      1.39550
alpha_1                               0.08399      0.00006     0.08408      0.08386
alpha_2                               0.03396      0.00029     0.03437      0.03342
alpha_3                               0.09289      0.00011     0.09312      0.09276
alpha_4                               0.03427      0.00028     0.03475      0.03382
alpha_5                               0.13824      0.00110     0.14030      0.13657
alpha_6                               0.08694      0.00018     0.08719      0.08661
alpha_7                               0.05571      0.00007     0.05582      0.05558
alpha_8                               0.12164      0.00036     0.12230      0.12106
alpha_9                               0.05039      0.00034     0.05101      0.04981
Alpha_loss                            -0.52673     0.36088     0.44938      -1.45698
Training/policy_loss                  -80.20086    6.66728     -63.19347    -96.60740
Training/qf1_loss                     7835.55805   2122.71263  14944.92969  4164.48047
Training/qf2_loss                     982.75891    382.51946   2469.12744   318.01669
Training/pf_norm                      2.71009      1.04728     6.55355      1.28177
Training/qf1_norm                     3665.77944   1588.91127  9299.33203   1135.23706
Training/qf2_norm                     1825.40703   827.28426   4637.57910   652.16278
log_std/mean                          -0.80387     0.01313     -0.77832     -0.82912
log_std/std                           0.41064      0.00823     0.43098      0.39071
log_std/max                           0.09331      0.07191     0.20138      -0.07143
log_std/min                           -3.26090     0.05267     -3.07028     -3.35129
log_probs/mean                        3.91263      0.15119     4.15991      3.55176
log_probs/std                         3.03115      0.06740     3.22738      2.88914
log_probs/max                         15.20712     0.77115     16.84423     13.17453
log_probs/min                         -6.67946     1.51573     -4.18919     -11.34397
mean/mean                             0.07430      0.02905     0.12896      0.00020
mean/std                              1.48948      0.01995     1.53268      1.44368
mean/max                              6.11606      0.21542     6.39380      5.55432
mean/min                              -4.27473     0.31095     -3.53310     -4.66658
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 7, 6, 8, 1, 0, 4, 9, 2, 5]
replay_buffer._size: [24150 24150 24150 24150 24150 24150 24150 24150 24150 24150]
2023-08-12 12:02:32,858 MainThread INFO: EPOCH:139
2023-08-12 12:02:32,859 MainThread INFO: Time Consumed:8.788815975189209s
2023-08-12 12:02:32,859 MainThread INFO: Total Frames:240000s
  1%|▏         | 140/10000 [21:12<25:25:01,  9.28s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               838.31308
Train_Epoch_Reward                    9444.36055
Running_Training_Average_Rewards      959.37476
Explore_Time                          0.00740
Train___Time                          8.77621
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.89271
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.73012
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.41621
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.31117
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.55235
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.20333
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.91427
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8901.55128
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.23242
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.16786
mean_success_rate                     0.10000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.35607     1.44309     12.79602     4.47657
alpha_0                               1.40226     0.00309     1.40648      1.39728
alpha_1                               0.08377     0.00005     0.08386      0.08371
alpha_2                               0.03293     0.00026     0.03341      0.03252
alpha_3                               0.09292     0.00020     0.09311      0.09239
alpha_4                               0.03352     0.00018     0.03382      0.03319
alpha_5                               0.14257     0.00122     0.14440      0.14035
alpha_6                               0.08662     0.00008     0.08674      0.08651
alpha_7                               0.05575     0.00013     0.05593      0.05556
alpha_8                               0.12357     0.00074     0.12448      0.12231
alpha_9                               0.05171     0.00038     0.05227      0.05102
Alpha_loss                            -0.07854    0.45233     0.75546      -1.05644
Training/policy_loss                  -81.24290   6.42975     -69.77280    -97.50216
Training/qf1_loss                     7964.86323  1766.07177  12645.81543  4446.51416
Training/qf2_loss                     997.44227   520.30488   2739.97656   302.73022
Training/pf_norm                      2.34441     0.63229     4.60081      1.01224
Training/qf1_norm                     4089.63665  2212.52284  15183.64746  1116.39111
Training/qf2_norm                     2076.18077  1064.34172  5802.15527   483.17447
log_std/mean                          -0.81341    0.00831     -0.79481     -0.83566
log_std/std                           0.41437     0.00812     0.43318      0.39377
log_std/max                           0.09869     0.05864     0.19225      -0.04976
log_std/min                           -3.38563    0.07161     -3.09415     -3.49785
log_probs/mean                        4.09861     0.19568     4.46182      3.66842
log_probs/std                         3.02082     0.07227     3.21567      2.87514
log_probs/max                         15.78114    0.71165     17.06190     13.69626
log_probs/min                         -6.49499    1.33220     -3.61528     -12.76409
mean/mean                             0.06792     0.02051     0.12639      0.03031
mean/std                              1.51465     0.02741     1.56320      1.44605
mean/max                              6.19107     0.15282     6.40657      5.53356
mean/min                              -4.15680    0.29440     -3.34797     -4.64949
------------------------------------  ----------  ----------  -----------  ----------
sample: [6, 5, 2, 3, 9, 1, 7, 0, 8, 4]
replay_buffer._size: [24300 24300 24300 24300 24300 24300 24300 24300 24300 24300]
2023-08-12 12:02:42,781 MainThread INFO: EPOCH:140
2023-08-12 12:02:42,781 MainThread INFO: Time Consumed:9.72910737991333s
2023-08-12 12:02:42,781 MainThread INFO: Total Frames:241500s
  1%|▏         | 141/10000 [21:21<25:56:27,  9.47s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               929.36979
Train_Epoch_Reward                    8283.46167
Running_Training_Average_Rewards      928.85861
Explore_Time                          0.00503
Train___Time                          9.71958
Eval____Time                          0.00358
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.71239
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.27526
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.59266
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.73055
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.76145
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.73685
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.78848
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9834.38655
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.43344
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.65761
mean_success_rate                     0.10000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.42158     1.27484     10.78913     4.00190
alpha_0                               1.40436     0.00356     1.40834      1.39586
alpha_1                               0.08395     0.00007     0.08403      0.08382
alpha_2                               0.03223     0.00016     0.03251      0.03196
alpha_3                               0.09217     0.00007     0.09237      0.09209
alpha_4                               0.03284     0.00022     0.03318      0.03240
alpha_5                               0.14633     0.00108     0.14817      0.14443
alpha_6                               0.08740     0.00049     0.08830      0.08671
alpha_7                               0.05613     0.00013     0.05641      0.05589
alpha_8                               0.12590     0.00087     0.12737      0.12448
alpha_9                               0.05289     0.00035     0.05344      0.05228
Alpha_loss                            0.36869     0.51447     1.66505      -0.73588
Training/policy_loss                  -79.96780   7.10133     -65.65270    -97.54970
Training/qf1_loss                     8045.46724  1654.59900  13130.58496  4738.37109
Training/qf2_loss                     1051.15249  430.67948   2240.20312   418.85410
Training/pf_norm                      2.83327     0.87351     5.03811      1.31097
Training/qf1_norm                     3712.77184  1614.81532  10416.03809  1452.22437
Training/qf2_norm                     2334.75240  1178.47892  6455.75244   756.16486
log_std/mean                          -0.83308    0.01279     -0.80745     -0.86393
log_std/std                           0.42102     0.00968     0.44578      0.39600
log_std/max                           0.06431     0.06569     0.16474      -0.05523
log_std/min                           -3.41831    0.05855     -3.20413     -3.50396
log_probs/mean                        4.24747     0.21194     4.78299      3.82666
log_probs/std                         2.99651     0.07192     3.16664      2.83426
log_probs/max                         15.22351    0.90224     17.20357     13.44304
log_probs/min                         -6.33264    1.48168     -3.54384     -12.44601
mean/mean                             0.03612     0.05810     0.13156      -0.09691
mean/std                              1.52280     0.02808     1.59113      1.46828
mean/max                              5.87812     0.21287     6.23151      5.47886
mean/min                              -4.17470    0.25459     -3.34391     -4.61150
------------------------------------  ----------  ----------  -----------  ----------
sample: [7, 3, 4, 5, 1, 2, 9, 8, 0, 6]
replay_buffer._size: [24450 24450 24450 24450 24450 24450 24450 24450 24450 24450]
2023-08-12 12:02:51,496 MainThread INFO: EPOCH:141
2023-08-12 12:02:51,496 MainThread INFO: Time Consumed:8.514432668685913s
2023-08-12 12:02:51,496 MainThread INFO: Total Frames:243000s
  1%|▏         | 142/10000 [21:30<25:19:04,  9.25s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               809.55691
Train_Epoch_Reward                    8849.27981
Running_Training_Average_Rewards      885.90340
Explore_Time                          0.00956
Train___Time                          8.50007
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.88963
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.79454
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.59440
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.60959
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.71625
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.91516
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.08150
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8630.17876
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.42102
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.58756
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.37715     1.31046     10.59310     4.13066
alpha_0                               1.38399     0.00579     1.39548      1.37348
alpha_1                               0.08351     0.00018     0.08391      0.08332
alpha_2                               0.03156     0.00024     0.03196      0.03118
alpha_3                               0.09293     0.00047     0.09386      0.09229
alpha_4                               0.03182     0.00030     0.03238      0.03133
alpha_5                               0.15014     0.00111     0.15203      0.14822
alpha_6                               0.08920     0.00054     0.09024      0.08832
alpha_7                               0.05696     0.00035     0.05767      0.05642
alpha_8                               0.12886     0.00095     0.13068      0.12740
alpha_9                               0.05394     0.00033     0.05454      0.05344
Alpha_loss                            0.15557     0.50687     1.34490      -0.68832
Training/policy_loss                  -78.82063   6.21181     -58.54402    -97.62309
Training/qf1_loss                     8302.80879  1978.32652  13142.59375  3805.73755
Training/qf2_loss                     1065.68352  448.07877   2107.79419   382.76749
Training/pf_norm                      3.01675     1.57323     14.69014     1.20284
Training/qf1_norm                     3921.20430  1762.78937  9792.67773   1251.55615
Training/qf2_norm                     2202.77828  1025.38754  6633.30029   656.76868
log_std/mean                          -0.83241    0.01276     -0.80581     -0.86582
log_std/std                           0.43172     0.00974     0.45130      0.40972
log_std/max                           0.08440     0.05913     0.17952      -0.03454
log_std/min                           -3.46004    0.05996     -3.22596     -3.53765
log_probs/mean                        4.18445     0.20963     4.59973      3.84235
log_probs/std                         3.02544     0.06428     3.19141      2.86216
log_probs/max                         14.72830    0.73883     17.03118     12.97647
log_probs/min                         -6.47785    1.42473     -4.43406     -10.35485
mean/mean                             -0.02936    0.02747     0.01661      -0.09338
mean/std                              1.51110     0.02633     1.57082      1.46619
mean/max                              5.78448     0.12149     5.98667      5.33403
mean/min                              -4.24545    0.22231     -3.50734     -4.64801
------------------------------------  ----------  ----------  -----------  ----------
sample: [4, 8, 6, 9, 3, 7, 2, 0, 1, 5]
replay_buffer._size: [24600 24600 24600 24600 24600 24600 24600 24600 24600 24600]
2023-08-12 12:03:01,072 MainThread INFO: EPOCH:142
2023-08-12 12:03:01,073 MainThread INFO: Time Consumed:9.402941942214966s
2023-08-12 12:03:01,073 MainThread INFO: Total Frames:244500s
  1%|▏         | 143/10000 [21:40<25:36:37,  9.35s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               907.65156
Train_Epoch_Reward                    7873.57128
Running_Training_Average_Rewards      833.54376
Explore_Time                          0.00484
Train___Time                          9.39290
Eval____Time                          0.00450
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.69244
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.52544
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.58169
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.67005
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.22527
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.59937
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.00488
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9579.15326
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.05603
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.28244
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.18530     1.32137     11.13734     4.65677
alpha_0                               1.36841     0.00298     1.37312      1.36235
alpha_1                               0.08356     0.00015     0.08376      0.08332
alpha_2                               0.03103     0.00007     0.03117      0.03088
alpha_3                               0.09520     0.00072     0.09645      0.09389
alpha_4                               0.03079     0.00031     0.03132      0.03026
alpha_5                               0.15411     0.00117     0.15619      0.15207
alpha_6                               0.09200     0.00091     0.09322      0.09027
alpha_7                               0.05855     0.00055     0.05962      0.05769
alpha_8                               0.13222     0.00062     0.13303      0.13073
alpha_9                               0.05514     0.00031     0.05566      0.05455
Alpha_loss                            0.72133     0.34425     1.48540      -0.18113
Training/policy_loss                  -78.03359   6.69211     -64.45600    -96.33221
Training/qf1_loss                     8474.62027  2047.62906  13717.85352  3657.06128
Training/qf2_loss                     1078.29124  554.41356   3029.62744   377.75323
Training/pf_norm                      2.71464     0.99461     6.61692      1.01326
Training/qf1_norm                     3712.31139  1699.86624  10035.49512  800.43982
Training/qf2_norm                     2716.51065  1360.66679  7415.06494   532.29034
log_std/mean                          -0.85159    0.01068     -0.83083     -0.87921
log_std/std                           0.44081     0.01039     0.46702      0.41565
log_std/max                           0.06992     0.05700     0.18083      -0.06125
log_std/min                           -3.47982    0.06189     -3.26981     -3.57620
log_probs/mean                        4.40367     0.15141     4.78797      4.03162
log_probs/std                         3.03994     0.06041     3.17344      2.89632
log_probs/max                         15.22530    0.81590     17.77412     13.77425
log_probs/min                         -6.24507    1.20978     -4.01241     -9.75980
mean/mean                             -0.11539    0.03156     -0.03320     -0.18550
mean/std                              1.52758     0.02438     1.58152      1.47391
mean/max                              5.56989     0.11249     5.74996      5.08411
mean/min                              -4.37588    0.24164     -3.61231     -5.01201
------------------------------------  ----------  ----------  -----------  ----------
sample: [4, 0, 2, 3, 5, 7, 8, 9, 1, 6]
replay_buffer._size: [24750 24750 24750 24750 24750 24750 24750 24750 24750 24750]
2023-08-12 12:03:11,004 MainThread INFO: EPOCH:143
2023-08-12 12:03:11,004 MainThread INFO: Time Consumed:9.74621033668518s
2023-08-12 12:03:11,004 MainThread INFO: Total Frames:246000s
  1%|▏         | 144/10000 [21:50<26:05:44,  9.53s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               903.90925
Train_Epoch_Reward                    9326.82395
Running_Training_Average_Rewards      868.32250
Explore_Time                          0.00531
Train___Time                          9.73523
Eval____Time                          0.00502
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.71777
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.86572
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.47466
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.32508
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.55400
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.44135
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.29912
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9549.40216
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.88884
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.74313
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.72422     1.45688     11.72634     4.46415
alpha_0                               1.34966     0.00764     1.36215      1.33836
alpha_1                               0.08368     0.00007     0.08376      0.08357
alpha_2                               0.03054     0.00020     0.03088      0.03022
alpha_3                               0.09768     0.00066     0.09882      0.09648
alpha_4                               0.02977     0.00026     0.03025      0.02940
alpha_5                               0.15834     0.00115     0.16031      0.15624
alpha_6                               0.09399     0.00048     0.09492      0.09323
alpha_7                               0.06083     0.00067     0.06202      0.05964
alpha_8                               0.13364     0.00026     0.13409      0.13305
alpha_9                               0.05621     0.00034     0.05688      0.05567
Alpha_loss                            0.39601     0.56751     1.73498      -0.50755
Training/policy_loss                  -81.04558   8.01054     -63.92673    -108.27383
Training/qf1_loss                     8883.45552  2449.43255  16046.25684  4500.78076
Training/qf2_loss                     1110.39898  512.50013   2783.65405   449.46558
Training/pf_norm                      3.01439     1.12464     7.34608      1.43249
Training/qf1_norm                     4233.20474  1762.09503  11097.09668  1259.32849
Training/qf2_norm                     2327.60380  1021.44020  6170.36572   803.41772
log_std/mean                          -0.86892    0.01528     -0.84269     -0.90610
log_std/std                           0.44880     0.00941     0.47034      0.42244
log_std/max                           0.13263     0.04528     0.20777      -0.01280
log_std/min                           -3.50774    0.04451     -3.30425     -3.57528
log_probs/mean                        4.25663     0.22729     4.75738      3.88547
log_probs/std                         3.05735     0.05589     3.27185      2.94790
log_probs/max                         15.33708    0.79190     17.70889     13.18687
log_probs/min                         -6.29021    1.35232     -4.24063     -11.30607
mean/mean                             -0.08549    0.04200     -0.00204     -0.17326
mean/std                              1.49686     0.02850     1.56973      1.44519
mean/max                              5.49165     0.14238     5.65732      4.90691
mean/min                              -4.41447    0.28358     -3.56914     -5.01092
------------------------------------  ----------  ----------  -----------  ----------
sample: [8, 1, 2, 4, 6, 3, 9, 5, 0, 7]
replay_buffer._size: [24900 24900 24900 24900 24900 24900 24900 24900 24900 24900]
2023-08-12 12:03:20,944 MainThread INFO: EPOCH:144
2023-08-12 12:03:20,944 MainThread INFO: Time Consumed:9.777191638946533s
2023-08-12 12:03:20,944 MainThread INFO: Total Frames:247500s
  1%|▏         | 145/10000 [22:00<26:25:54,  9.66s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               899.10021
Train_Epoch_Reward                    8472.45406
Running_Training_Average_Rewards      855.76164
Explore_Time                          0.00613
Train___Time                          9.76569
Eval____Time                          0.00465
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.29395
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.64836
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.34245
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.79287
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.58528
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.87370
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.98090
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9468.35186
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.60317
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.22910
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.28189     1.50381     10.56689     4.08126
alpha_0                               1.32734     0.00459     1.33826      1.32110
alpha_1                               0.08403     0.00023     0.08445      0.08364
alpha_2                               0.03018     0.00004     0.03028      0.03015
alpha_3                               0.10064     0.00123     0.10293      0.09885
alpha_4                               0.02933     0.00002     0.02940      0.02931
alpha_5                               0.16196     0.00084     0.16347      0.16035
alpha_6                               0.09619     0.00065     0.09725      0.09495
alpha_7                               0.06307     0.00060     0.06407      0.06204
alpha_8                               0.13535     0.00081     0.13686      0.13411
alpha_9                               0.05797     0.00067     0.05918      0.05690
Alpha_loss                            1.90138     0.59221     3.41773      1.01247
Training/policy_loss                  -79.29134   7.53235     -62.00040    -102.56451
Training/qf1_loss                     8575.76304  2153.78507  15467.09082  4598.39990
Training/qf2_loss                     1097.68765  502.95865   2502.40356   356.49301
Training/pf_norm                      2.84735     0.94087     6.35704      1.29710
Training/qf1_norm                     4210.30519  1881.63029  10011.35645  975.54852
Training/qf2_norm                     2555.64144  1200.32167  6059.24463   711.06769
log_std/mean                          -0.87194    0.00905     -0.85365     -0.89058
log_std/std                           0.44777     0.00878     0.47033      0.42595
log_std/max                           0.12247     0.05851     0.22082      -0.06104
log_std/min                           -3.50426    0.05596     -3.30368     -3.59160
log_probs/mean                        4.74159     0.23378     5.30034      4.32294
log_probs/std                         3.04354     0.07124     3.25627      2.89256
log_probs/max                         15.79327    0.66073     18.25081     14.45871
log_probs/min                         -6.31132    1.40710     -3.89950     -10.68696
mean/mean                             0.06685     0.05946     0.18337      -0.04192
mean/std                              1.57611     0.03211     1.65033      1.51293
mean/max                              5.46574     0.15743     5.72369      4.57420
mean/min                              -4.25818    0.31468     -3.65548     -4.89325
------------------------------------  ----------  ----------  -----------  ----------
sample: [9, 0, 2, 8, 1, 5, 6, 7, 3, 4]
replay_buffer._size: [25050 25050 25050 25050 25050 25050 25050 25050 25050 25050]
2023-08-12 12:03:29,974 MainThread INFO: EPOCH:145
2023-08-12 12:03:29,974 MainThread INFO: Time Consumed:8.833605527877808s
2023-08-12 12:03:29,974 MainThread INFO: Total Frames:249000s
  1%|▏         | 146/10000 [22:09<25:53:52,  9.46s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               909.28496
Train_Epoch_Reward                    8688.49799
Running_Training_Average_Rewards      882.92587
Explore_Time                          0.00785
Train___Time                          8.82052
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.52936
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.66492
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.37637
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.44294
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.95864
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.46259
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.53170
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9590.47134
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.61810
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.03706
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.49500     1.21382     11.39660     3.51805
alpha_0                               1.31294     0.00509     1.32089      1.30614
alpha_1                               0.08466     0.00010     0.08493      0.08446
alpha_2                               0.03031     0.00001     0.03033      0.03028
alpha_3                               0.10530     0.00127     0.10743      0.10298
alpha_4                               0.02956     0.00010     0.02978      0.02940
alpha_5                               0.16494     0.00085     0.16658      0.16350
alpha_6                               0.09781     0.00027     0.09835      0.09727
alpha_7                               0.06514     0.00065     0.06635      0.06408
alpha_8                               0.13802     0.00057     0.13909      0.13688
alpha_9                               0.06046     0.00072     0.06171      0.05920
Alpha_loss                            1.96118     0.65431     3.77572      0.75925
Training/policy_loss                  -80.41729   7.02254     -67.50668    -101.71094
Training/qf1_loss                     9130.87128  2349.78177  19776.90625  4307.79541
Training/qf2_loss                     1128.16535  491.73350   3005.71606   322.86154
Training/pf_norm                      3.26371     1.25883     7.50681      1.43681
Training/qf1_norm                     3930.64295  1775.49164  9259.07715   1055.69519
Training/qf2_norm                     2234.15118  942.36901   5274.94531   507.35834
log_std/mean                          -0.86945    0.01011     -0.84724     -0.89064
log_std/std                           0.44897     0.00993     0.48026      0.42591
log_std/max                           0.16369     0.06760     0.26172      -0.04329
log_std/min                           -3.46843    0.06043     -3.29698     -3.58987
log_probs/mean                        4.76324     0.27686     5.46569      4.31465
log_probs/std                         3.07212     0.07660     3.24764      2.89245
log_probs/max                         16.15663    0.82846     18.89548     14.24673
log_probs/min                         -6.16967    1.54232     -3.43976     -11.39142
mean/mean                             0.10429     0.02856     0.18063      0.05488
mean/std                              1.58402     0.03588     1.66406      1.51550
mean/max                              5.59125     0.09389     5.75685      5.26640
mean/min                              -4.33008    0.28902     -3.60853     -4.85864
------------------------------------  ----------  ----------  -----------  ----------
sample: [5, 9, 6, 0, 2, 1, 3, 8, 4, 7]
replay_buffer._size: [25200 25200 25200 25200 25200 25200 25200 25200 25200 25200]
2023-08-12 12:03:39,747 MainThread INFO: EPOCH:146
2023-08-12 12:03:39,747 MainThread INFO: Time Consumed:9.593831777572632s
2023-08-12 12:03:39,747 MainThread INFO: Total Frames:250500s
  1%|▏         | 147/10000 [22:18<26:09:51,  9.56s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               859.70343
Train_Epoch_Reward                    9701.65600
Running_Training_Average_Rewards      895.42027
Explore_Time                          0.00379
Train___Time                          9.58249
Eval____Time                          0.00591
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.04078
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.27484
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.43412
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.24804
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.18212
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.43263
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.74082
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9129.51637
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.32563
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.80308
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.24719     1.59278     11.87412     3.85132
alpha_0                               1.30809     0.00225     1.31157      1.30387
alpha_1                               0.08508     0.00015     0.08526      0.08473
alpha_2                               0.03043     0.00004     0.03046      0.03033
alpha_3                               0.10892     0.00064     0.10998      0.10748
alpha_4                               0.03018     0.00020     0.03048      0.02979
alpha_5                               0.16820     0.00081     0.16964      0.16662
alpha_6                               0.09941     0.00055     0.10039      0.09838
alpha_7                               0.06784     0.00077     0.06914      0.06639
alpha_8                               0.13919     0.00025     0.13960      0.13886
alpha_9                               0.06281     0.00056     0.06373      0.06174
Alpha_loss                            1.64811     0.63247     3.55443      0.66806
Training/policy_loss                  -78.06782   7.70372     -58.06991    -95.91100
Training/qf1_loss                     9005.38555  2548.24996  16805.67188  4568.42822
Training/qf2_loss                     1067.27189  512.26260   2547.24756   301.83737
Training/pf_norm                      3.15812     1.21223     7.97416      1.52460
Training/qf1_norm                     4290.54376  2058.02188  11722.31250  1348.96338
Training/qf2_norm                     2870.85218  1319.91998  6481.91797   823.68549
log_std/mean                          -0.87258    0.02156     -0.83682     -0.91530
log_std/std                           0.44469     0.01038     0.46875      0.41562
log_std/max                           0.14091     0.05492     0.24213      -0.02250
log_std/min                           -3.46062    0.06490     -3.28425     -3.55925
log_probs/mean                        4.62087     0.25891     5.51281      4.19237
log_probs/std                         3.04354     0.06452     3.20292      2.88208
log_probs/max                         16.14458    0.99973     18.71677     13.28331
log_probs/min                         -6.20009    1.36264     -3.69794     -10.00804
mean/mean                             0.01253     0.03867     0.08649      -0.06827
mean/std                              1.55861     0.03634     1.67453      1.49958
mean/max                              5.33871     0.08623     5.45030      4.85620
mean/min                              -4.44482    0.37959     -3.74059     -5.10582
------------------------------------  ----------  ----------  -----------  ----------
sample: [3, 5, 6, 8, 2, 1, 0, 7, 4, 9]
replay_buffer._size: [25350 25350 25350 25350 25350 25350 25350 25350 25350 25350]
2023-08-12 12:03:49,571 MainThread INFO: EPOCH:147
2023-08-12 12:03:49,572 MainThread INFO: Time Consumed:9.642136812210083s
2023-08-12 12:03:49,572 MainThread INFO: Total Frames:252000s
  1%|▏         | 148/10000 [22:28<26:21:21,  9.63s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               831.34616
Train_Epoch_Reward                    8846.91647
Running_Training_Average_Rewards      907.90235
Explore_Time                          0.00795
Train___Time                          9.62884
Eval____Time                          0.00468
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.07024
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.07870
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.39322
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.72509
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.31925
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.53531
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.46349
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8835.24696
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.10419
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.09585
mean_success_rate                     0.10000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.37357     1.32804     10.62953     4.37584
alpha_0                               1.29452     0.00616     1.30425      1.28744
alpha_1                               0.08376     0.00056     0.08472      0.08295
alpha_2                               0.03015     0.00020     0.03044      0.02984
alpha_3                               0.11177     0.00112     0.11384      0.11001
alpha_4                               0.03069     0.00014     0.03098      0.03048
alpha_5                               0.17106     0.00085     0.17273      0.16967
alpha_6                               0.10117     0.00043     0.10210      0.10041
alpha_7                               0.07065     0.00088     0.07223      0.06917
alpha_8                               0.14068     0.00075     0.14218      0.13934
alpha_9                               0.06473     0.00061     0.06585      0.06375
Alpha_loss                            1.24660     0.52079     2.40712      0.12029
Training/policy_loss                  -77.62177   7.58625     -60.50819    -97.96946
Training/qf1_loss                     9318.57322  2278.16207  17275.85547  4860.33154
Training/qf2_loss                     1117.68876  504.52974   2744.24707   409.17276
Training/pf_norm                      3.38672     1.09624     7.36078      1.24796
Training/qf1_norm                     4085.90849  1936.93856  10333.34082  696.49451
Training/qf2_norm                     2772.38135  1225.89836  7093.16504   860.28479
log_std/mean                          -0.89848    0.01784     -0.87057     -0.93273
log_std/std                           0.45509     0.00751     0.47554      0.43927
log_std/max                           0.17095     0.05871     0.26295      -0.01564
log_std/min                           -3.47160    0.06513     -3.27564     -3.55955
log_probs/mean                        4.52125     0.22657     5.08590      4.09229
log_probs/std                         3.19299     0.06889     3.34666      2.98948
log_probs/max                         16.36864    0.95641     19.13053     14.31377
log_probs/min                         -6.21296    1.27005     -4.29297     -11.43229
mean/mean                             -0.00543    0.03552     0.05472      -0.08350
mean/std                              1.53587     0.02597     1.59838      1.47448
mean/max                              5.59025     0.11433     5.75489      5.06301
mean/min                              -4.56648    0.39185     -3.68808     -5.20067
------------------------------------  ----------  ----------  -----------  ----------
sample: [5, 2, 9, 8, 6, 4, 7, 3, 0, 1]
replay_buffer._size: [25500 25500 25500 25500 25500 25500 25500 25500 25500 25500]
2023-08-12 12:03:58,687 MainThread INFO: EPOCH:148
2023-08-12 12:03:58,688 MainThread INFO: Time Consumed:8.939289808273315s
2023-08-12 12:03:58,688 MainThread INFO: Total Frames:253500s
  1%|▏         | 149/10000 [22:37<25:55:52,  9.48s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               831.22270
Train_Epoch_Reward                    8551.35858
Running_Training_Average_Rewards      903.33104
Explore_Time                          0.01521
Train___Time                          8.91874
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.48568
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.88934
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.55451
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.05980
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.62767
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.72898
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.00800
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8819.29028
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.67185
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -12.03746
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.38421     1.53375     12.27212     3.88939
alpha_0                               1.28006     0.00489     1.28737      1.27199
alpha_1                               0.08252     0.00021     0.08294      0.08227
alpha_2                               0.02952     0.00019     0.02983      0.02921
alpha_3                               0.11607     0.00131     0.11840      0.11388
alpha_4                               0.03147     0.00030     0.03202      0.03099
alpha_5                               0.17423     0.00077     0.17576      0.17278
alpha_6                               0.10315     0.00047     0.10381      0.10213
alpha_7                               0.07350     0.00071     0.07479      0.07226
alpha_8                               0.14419     0.00122     0.14664      0.14222
alpha_9                               0.06699     0.00066     0.06818      0.06587
Alpha_loss                            1.66083     0.48481     2.81145      0.78140
Training/policy_loss                  -76.84504   8.96204     -51.04129    -96.77663
Training/qf1_loss                     9415.67127  2276.11121  17332.83789  5303.44238
Training/qf2_loss                     1109.97532  491.18728   2733.72729   384.42072
Training/pf_norm                      3.80476     1.50065     10.54069     1.31509
Training/qf1_norm                     4174.51982  1981.94042  13362.03027  1346.35864
Training/qf2_norm                     2525.12069  1319.30111  7838.92578   924.61212
log_std/mean                          -0.90698    0.01120     -0.88266     -0.93279
log_std/std                           0.45792     0.00890     0.48067      0.43572
log_std/max                           0.16244     0.05819     0.24347      -0.01455
log_std/min                           -3.43974    0.05905     -3.25095     -3.52778
log_probs/mean                        4.67699     0.21616     5.17890      4.29618
log_probs/std                         3.23000     0.07381     3.39801      3.04028
log_probs/max                         17.33226    0.76256     18.76721     15.15947
log_probs/min                         -6.23041    1.48191     -3.72702     -11.86156
mean/mean                             0.00719     0.03458     0.07885      -0.05357
mean/std                              1.55797     0.03118     1.62744      1.49687
mean/max                              5.87260     0.23194     6.20873      4.49005
mean/min                              -4.58761    0.41143     -3.72254     -5.36947
------------------------------------  ----------  ----------  -----------  ----------
sample: [7, 0, 3, 1, 6, 2, 4, 9, 5, 8]
replay_buffer._size: [25655 25650 25650 25650 25650 25657 25650 25653 25650 25650]
2023-08-12 12:04:07,918 MainThread INFO: EPOCH:149
2023-08-12 12:04:07,919 MainThread INFO: Time Consumed:9.03621220588684s
2023-08-12 12:04:07,919 MainThread INFO: Total Frames:255000s
  2%|▏         | 150/10000 [22:47<25:43:43,  9.40s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               786.67947
Train_Epoch_Reward                    8101.32019
Running_Training_Average_Rewards      849.98651
Explore_Time                          0.05775
Train___Time                          8.97302
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.74167
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.11958
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.53775
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.20176
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.83226
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.86065
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.17167
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8378.89625
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.37915
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.25712
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.45259     1.47838     11.95191     3.51588
alpha_0                               1.26460     0.00603     1.27252      1.25414
alpha_1                               0.08183     0.00040     0.08227      0.08104
alpha_2                               0.02890     0.00020     0.02921      0.02856
alpha_3                               0.12067     0.00121     0.12267      0.11845
alpha_4                               0.03266     0.00034     0.03323      0.03204
alpha_5                               0.17728     0.00082     0.17879      0.17580
alpha_6                               0.10385     0.00016     0.10405      0.10360
alpha_7                               0.07641     0.00095     0.07805      0.07482
alpha_8                               0.14896     0.00118     0.15090      0.14670
alpha_9                               0.06946     0.00072     0.07071      0.06821
Alpha_loss                            1.50280     0.46175     2.57891      0.69319
Training/policy_loss                  -77.62191   7.78855     -61.72565    -97.52398
Training/qf1_loss                     9598.77890  2568.77019  18515.07617  5329.48779
Training/qf2_loss                     1086.61058  463.80187   3282.82983   317.52792
Training/pf_norm                      3.89796     1.36162     7.66608      1.84007
Training/qf1_norm                     4285.89622  2108.23603  11590.41504  1275.01331
Training/qf2_norm                     2601.57362  1273.23012  7371.48730   684.80029
log_std/mean                          -0.89702    0.01062     -0.86963     -0.92695
log_std/std                           0.45983     0.01053     0.48235      0.43253
log_std/max                           0.20952     0.05093     0.26051      0.05732
log_std/min                           -3.37249    0.07035     -3.18260     -3.48670
log_probs/mean                        4.60152     0.19750     5.07142      4.25792
log_probs/std                         3.30643     0.07947     3.46915      3.08806
log_probs/max                         17.86140    1.20503     21.81493     14.92089
log_probs/min                         -6.44553    1.42541     -3.90828     -12.24548
mean/mean                             0.07032     0.02761     0.12744      -0.00318
mean/std                              1.55478     0.02666     1.61733      1.50626
mean/max                              6.18462     0.14675     6.37546      5.33835
mean/min                              -4.79841    0.44726     -4.09759     -5.55503
------------------------------------  ----------  ----------  -----------  ----------
start to update mask
sample: [9, 5, 6, 4, 8, 3, 0, 2, 1, 7]
replay_buffer._size: [25809 25800 25800 25800 25800 25800 25800 25806 25800 25800]
2023-08-12 12:04:17,436 MainThread INFO: EPOCH:150
2023-08-12 12:04:17,436 MainThread INFO: Time Consumed:8.21163296699524s
2023-08-12 12:04:17,436 MainThread INFO: Total Frames:256500s
  2%|▏         | 151/10000 [22:56<25:48:51,  9.44s/it]------------------------------------  -----------  -----------  ------------  ----------
Name                                  Value
Running_Average_Rewards               845.45377
Train_Epoch_Reward                    7786.58230
Running_Training_Average_Rewards      814.64204
Explore_Time                          0.03233
Train___Time                          8.17358
Eval____Time                          0.00463
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.60427
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.26186
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.32761
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.47520
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.01191
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.17870
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.39588
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8974.91051
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.89959
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.21779
mean_success_rate                     0.00000

Name                                  Mean         Std          Max           Min
Reward_Mean                           7.27112      1.40163      11.27470      4.61991
alpha_0                               1.31752      0.04034      1.37091       1.25416
alpha_1                               0.08458      0.00212      0.08854       0.08104
alpha_2                               0.02842      0.00007      0.02855       0.02833
alpha_3                               0.12270      0.00088      0.12360       0.12071
alpha_4                               0.03356      0.00020      0.03414       0.03325
alpha_5                               0.18213      0.00140      0.18366       0.17885
alpha_6                               0.10118      0.00161      0.10369       0.09923
alpha_7                               0.07864      0.00046      0.07923       0.07773
alpha_8                               0.15193      0.00134      0.15360       0.14909
alpha_9                               0.07248      0.00086      0.07380       0.07074
Alpha_loss                            1.81945      1.89854      4.55741       -1.45708
Training/policy_loss                  -2.12299     19.45221     45.35572      -35.54014
Training/qf1_loss                     11074.48643  4367.18656   22910.72656   4424.71436
Training/qf2_loss                     6305.35845   5827.49025   22182.12500   1480.37036
Training/pf_norm                      22.07762     13.09977     61.05448      7.69978
Training/qf1_norm                     10036.80233  6689.51769   23936.69727   1946.53088
Training/qf2_norm                     28198.62716  37517.37979  141832.00000  2377.36206
log_std/mean                          -0.96613     0.02021      -0.92089      -1.00621
log_std/std                           0.53150      0.04266      0.60046       0.47416
log_std/max                           0.26182      0.08094      0.44537       0.12910
log_std/min                           -3.18780     0.06594      -2.98304      -3.29882
log_probs/mean                        4.95574      0.76550      6.32768       3.72350
log_probs/std                         4.11910      0.50495      4.98328       3.48752
log_probs/max                         20.63732     2.95453      30.16934      17.20413
log_probs/min                         -6.39723     1.21808      -4.17198      -9.98908
mean/mean                             0.22825      0.14489      0.45407       0.03673
mean/std                              1.60669      0.10844      1.79788       1.40657
mean/max                              7.19215      0.68556      8.11902       5.64614
mean/min                              -6.18537     0.94726      -4.07914      -8.04109
------------------------------------  -----------  -----------  ------------  ----------
sample: [6, 5, 0, 2, 3, 7, 4, 1, 8, 9]
replay_buffer._size: [25950 25950 25950 25950 25950 25950 25950 25950 25950 25950]
2023-08-12 12:04:26,629 MainThread INFO: EPOCH:151
2023-08-12 12:04:26,629 MainThread INFO: Time Consumed:8.996806621551514s
2023-08-12 12:04:26,629 MainThread INFO: Total Frames:258000s
  2%|▏         | 152/10000 [23:05<25:36:47,  9.36s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               868.18272
Train_Epoch_Reward                    8556.19716
Running_Training_Average_Rewards      814.80332
Explore_Time                          0.01410
Train___Time                          8.97668
Eval____Time                          0.00485
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.76804
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.70277
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.46220
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.26176
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.80673
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.68454
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.09938
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9198.25715
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.69832
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.94621
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           7.39294     1.38076     11.50782     4.67038
alpha_0                               1.39735     0.02034     1.44026      1.37138
alpha_1                               0.09305     0.00228     0.09637      0.08865
alpha_2                               0.02879     0.00035     0.02957      0.02841
alpha_3                               0.12118     0.00082     0.12301      0.12033
alpha_4                               0.03512     0.00046     0.03581      0.03416
alpha_5                               0.18067     0.00053     0.18180      0.18001
alpha_6                               0.10012     0.00058     0.10127      0.09928
alpha_7                               0.07806     0.00031     0.07859      0.07764
alpha_8                               0.14878     0.00024     0.14909      0.14805
alpha_9                               0.07573     0.00119     0.07781      0.07383
Alpha_loss                            4.78437     0.37674     5.55942      3.87106
Training/policy_loss                  -22.52642   9.19268     1.24669      -46.89009
Training/qf1_loss                     9527.73752  2412.69171  16605.76562  4755.85986
Training/qf2_loss                     1507.62494  511.22670   3343.90942   525.68469
Training/pf_norm                      7.46723     2.60996     20.70761     3.97854
Training/qf1_norm                     4772.92811  1829.68680  11379.05176  1848.37524
Training/qf2_norm                     3375.20238  1303.64891  7438.86426   1265.33398
log_std/mean                          -1.10214    0.04713     -0.98140     -1.16538
log_std/std                           0.56009     0.02951     0.61075      0.51654
log_std/max                           0.43151     0.16972     0.88217      0.13496
log_std/min                           -3.12614    0.09167     -2.85831     -3.26814
log_probs/mean                        6.02534     0.21056     6.44504      5.35143
log_probs/std                         4.33828     0.43444     5.12462      3.49183
log_probs/max                         26.44260    4.72666     37.49663     17.66301
log_probs/min                         -5.71565    1.73615     -2.98510     -13.03577
mean/mean                             0.41460     0.03546     0.48492      0.34977
mean/std                              1.72685     0.05670     1.84126      1.63862
mean/max                              7.02988     0.57438     7.95455      5.98833
mean/min                              -9.00494    1.58037     -6.22133     -11.40294
------------------------------------  ----------  ----------  -----------  ----------
sample: [3, 9, 4, 1, 7, 8, 2, 0, 6, 5]
replay_buffer._size: [26105 26105 26105 26105 26105 26105 26105 26105 26104 26104]
2023-08-12 12:04:35,660 MainThread INFO: EPOCH:152
2023-08-12 12:04:35,661 MainThread INFO: Time Consumed:8.835047483444214s
2023-08-12 12:04:35,661 MainThread INFO: Total Frames:259500s
  2%|▏         | 153/10000 [23:14<25:20:56,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1028.10525
Train_Epoch_Reward                    8519.50406
Running_Training_Average_Rewards      828.74278
Explore_Time                          0.11248
Train___Time                          8.71771
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.05028
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.80304
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.28666
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.86407
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -93.08044
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.63888
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.22972
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10955.39994
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.01720
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -92.37712
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.44534      1.53890     10.98158     3.99184
alpha_0                               1.48959      0.02633     1.53101      1.44135
alpha_1                               0.09829      0.00103     0.09999      0.09641
alpha_2                               0.03070      0.00063     0.03172      0.02959
alpha_3                               0.12696      0.00237     0.13086      0.12307
alpha_4                               0.03646      0.00040     0.03718      0.03582
alpha_5                               0.18412      0.00170     0.18780      0.18184
alpha_6                               0.10290      0.00107     0.10494      0.10129
alpha_7                               0.07963      0.00075     0.08110      0.07860
alpha_8                               0.14408      0.00246     0.14800      0.13980
alpha_9                               0.07969      0.00107     0.08154      0.07785
Alpha_loss                            4.86748      0.26931     5.61204      4.02833
Training/policy_loss                  -25.25619    7.70864     -10.11849    -40.86698
Training/qf1_loss                     9552.72908   2330.53918  14990.45996  4285.61719
Training/qf2_loss                     1337.68060   542.49124   2763.57690   533.28656
Training/pf_norm                      7.24954      3.48398     19.76720     2.74057
Training/qf1_norm                     4640.21397   2001.95223  10676.38281  1424.22070
Training/qf2_norm                     3130.40778   1332.61438  7000.41650   935.29889
log_std/mean                          -1.03910     0.02546     -0.98990     -1.09728
log_std/std                           0.50598      0.01224     0.52717      0.47584
log_std/max                           0.45913      0.04410     0.53232      0.34671
log_std/min                           -3.03529     0.04881     -2.84566     -3.11109
log_probs/mean                        6.12857      0.11983     6.40966      5.81707
log_probs/std                         3.44138      0.09553     3.67333      3.20209
log_probs/max                         21.23187     3.56176     32.33903     15.25193
log_probs/min                         -5.51883     1.82012     -2.46152     -13.39395
mean/mean                             0.41642      0.01688     0.45734      0.38092
mean/std                              1.69922      0.01851     1.73396      1.65145
mean/max                              5.87879      0.12675     5.98963      4.86676
mean/min                              -7.91298     1.78809     -4.52733     -10.28300
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 6, 8, 3, 0, 2, 9, 4, 5, 1]
replay_buffer._size: [26250 26250 26250 26250 26250 26250 26250 26250 26250 26250]
2023-08-12 12:04:44,091 MainThread INFO: EPOCH:153
2023-08-12 12:04:44,091 MainThread INFO: Time Consumed:8.254388332366943s
2023-08-12 12:04:44,091 MainThread INFO: Total Frames:261000s
  2%|▏         | 154/10000 [23:23<24:38:17,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1191.44320
Train_Epoch_Reward                    9985.14979
Running_Training_Average_Rewards      902.02837
Explore_Time                          0.00989
Train___Time                          8.23964
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.58575
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.59688
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.16048
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.70208
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.66480
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.95430
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.99381
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12491.29049
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.23395
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -75.96649
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.40143      1.45927     14.08636     3.73332
alpha_0                               1.56642      0.02012     1.59847      1.53172
alpha_1                               0.10092      0.00037     0.10127      0.10002
alpha_2                               0.03272      0.00060     0.03378      0.03174
alpha_3                               0.13313      0.00113     0.13472      0.13092
alpha_4                               0.03794      0.00042     0.03867      0.03720
alpha_5                               0.19258      0.00269     0.19728      0.18791
alpha_6                               0.10854      0.00237     0.11287      0.10499
alpha_7                               0.08316      0.00124     0.08531      0.08114
alpha_8                               0.13647      0.00167     0.13972      0.13398
alpha_9                               0.08338      0.00102     0.08507      0.08158
Alpha_loss                            4.94786      0.25673     5.56265      4.32659
Training/policy_loss                  -27.91876    7.93856     -9.08449     -46.80299
Training/qf1_loss                     10255.75378  2782.47001  21162.39453  4892.42334
Training/qf2_loss                     1329.00184   596.31431   5040.30225   294.40973
Training/pf_norm                      6.20340      2.51296     16.11033     2.38976
Training/qf1_norm                     4659.68993   2122.29973  12301.08789  1480.39038
Training/qf2_norm                     2811.55523   1489.63781  9944.72852   795.96771
log_std/mean                          -0.97604     0.02065     -0.93214     -1.00796
log_std/std                           0.44317      0.02282     0.49111      0.40876
log_std/max                           0.30243      0.09799     0.43790      0.06455
log_std/min                           -2.80177     0.12387     -2.47209     -3.01531
log_probs/mean                        6.13459      0.12007     6.41923      5.87488
log_probs/std                         3.46352      0.14304     3.77947      3.17583
log_probs/max                         20.67567     1.33116     24.14244     16.94347
log_probs/min                         -5.50873     1.55191     -2.85755     -11.34333
mean/mean                             0.31758      0.05210     0.45218      0.24917
mean/std                              1.74904      0.02580     1.80346      1.68557
mean/max                              5.29988      0.22878     5.85868      4.61763
mean/min                              -6.68145     1.30505     -4.06444     -8.25464
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 7, 1, 9, 3, 2, 6, 4, 8, 0]
replay_buffer._size: [26400 26400 26400 26400 26400 26400 26400 26400 26400 26400]
2023-08-12 12:04:52,529 MainThread INFO: EPOCH:154
2023-08-12 12:04:52,530 MainThread INFO: Time Consumed:8.242390632629395s
2023-08-12 12:04:52,530 MainThread INFO: Total Frames:262500s
  2%|▏         | 155/10000 [23:31<24:10:02,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               934.23585
Train_Epoch_Reward                    11965.25439
Running_Training_Average_Rewards      1015.66361
Explore_Time                          0.00433
Train___Time                          8.23268
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.06338
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.48844
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.58310
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.67941
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.10485
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.15725
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.82323
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9883.14124
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.57385
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.30922
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.35807      1.41589     11.39932     3.94791
alpha_0                               1.62493      0.01460     1.64781      1.59897
alpha_1                               0.10079      0.00037     0.10125      0.10003
alpha_2                               0.03487      0.00063     0.03594      0.03380
alpha_3                               0.13477      0.00023     0.13496      0.13413
alpha_4                               0.03976      0.00069     0.04101      0.03869
alpha_5                               0.20197      0.00250     0.20604      0.19738
alpha_6                               0.11713      0.00231     0.12080      0.11296
alpha_7                               0.08774      0.00134     0.08981      0.08535
alpha_8                               0.13325      0.00032     0.13395      0.13286
alpha_9                               0.08648      0.00075     0.08765      0.08510
Alpha_loss                            4.96611      0.35640     5.75761      4.12813
Training/policy_loss                  -30.82737    8.58603     -7.56722     -53.51399
Training/qf1_loss                     10752.27338  2460.04216  16733.63672  5731.99951
Training/qf2_loss                     1240.45329   507.79536   3013.97681   442.59341
Training/pf_norm                      5.60407      2.28608     11.93480     2.37474
Training/qf1_norm                     4601.96600   2168.91721  13235.61328  1661.92896
Training/qf2_norm                     2874.04620   1539.75479  8647.81738   891.23810
log_std/mean                          -0.94430     0.01414     -0.91582     -0.97185
log_std/std                           0.39517      0.01068     0.41803      0.37026
log_std/max                           0.40033      0.21896     0.69673      -0.01813
log_std/min                           -2.55840     0.07694     -2.34141     -2.73254
log_probs/mean                        6.02144      0.18883     6.31359      5.47655
log_probs/std                         3.75016      0.11228     4.00616      3.45842
log_probs/max                         21.16390     0.99461     23.31248     19.02281
log_probs/min                         -5.50796     1.54353     -2.78299     -11.15634
mean/mean                             0.22475      0.03532     0.28749      0.15875
mean/std                              1.75796      0.02344     1.79809      1.69411
mean/max                              4.98139      0.15431     5.17367      3.93038
mean/min                              -5.91691     0.89212     -3.92739     -6.70745
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 1, 7, 4, 3, 8, 2, 5, 9, 0]
replay_buffer._size: [26550 26550 26550 26550 26550 26550 26550 26550 26550 26550]
2023-08-12 12:05:01,688 MainThread INFO: EPOCH:155
2023-08-12 12:05:01,688 MainThread INFO: Time Consumed:8.987548351287842s
2023-08-12 12:05:01,688 MainThread INFO: Total Frames:264000s
  2%|▏         | 156/10000 [23:40<24:25:45,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               836.60630
Train_Epoch_Reward                    8734.33915
Running_Training_Average_Rewards      1022.82478
Explore_Time                          0.00442
Train___Time                          8.97828
Eval____Time                          0.00413
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.98220
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.07232
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.70602
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.07524
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.08184
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.72427
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.76357
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8873.47701
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.90077
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.10775
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.45076      1.38705     12.28327     4.58601
alpha_0                               1.66488      0.00915     1.67976      1.64811
alpha_1                               0.09915      0.00053     0.10002      0.09828
alpha_2                               0.03702      0.00063     0.03810      0.03596
alpha_3                               0.13266      0.00087     0.13410      0.13113
alpha_4                               0.04230      0.00076     0.04360      0.04103
alpha_5                               0.20929      0.00200     0.21269      0.20610
alpha_6                               0.12339      0.00144     0.12574      0.12085
alpha_7                               0.09087      0.00053     0.09163      0.08984
alpha_8                               0.13645      0.00192     0.14015      0.13382
alpha_9                               0.08858      0.00055     0.08952      0.08766
Alpha_loss                            4.62808      0.41395     5.45797      3.61372
Training/policy_loss                  -31.64574    7.80060     -11.82794    -52.92451
Training/qf1_loss                     10226.13669  2658.99272  16294.44434  5739.93311
Training/qf2_loss                     1275.38257   488.42600   2983.17505   548.82062
Training/pf_norm                      5.78563      2.54975     15.19559     2.31209
Training/qf1_norm                     4748.75088   2098.50370  11893.90039  1619.29248
Training/qf2_norm                     2936.11030   1535.85563  9825.81738   811.14838
log_std/mean                          -0.92322     0.00582     -0.91008     -0.93829
log_std/std                           0.37618      0.00622     0.38889      0.36328
log_std/max                           0.58881      0.22530     0.79149      0.06131
log_std/min                           -2.78953     0.16141     -2.41607     -3.05404
log_probs/mean                        5.79654      0.16195     6.17295      5.36996
log_probs/std                         3.80392      0.13619     4.15891      3.46537
log_probs/max                         21.02621     1.19393     25.51431     19.06259
log_probs/min                         -5.64518     1.54662     -3.34549     -12.82922
mean/mean                             0.19420      0.02531     0.25022      0.13766
mean/std                              1.73372      0.02303     1.79371      1.68169
mean/max                              4.62862      0.13367     4.89267      4.16779
mean/min                              -5.98889     1.13585     -4.08285     -7.20691
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 6, 7, 5, 8, 3, 1, 4, 0, 2]
replay_buffer._size: [26700 26700 26700 26700 26700 26700 26700 26700 26700 26700]
2023-08-12 12:05:10,501 MainThread INFO: EPOCH:156
2023-08-12 12:05:10,502 MainThread INFO: Time Consumed:8.63548493385315s
2023-08-12 12:05:10,502 MainThread INFO: Total Frames:265500s
  2%|▏         | 157/10000 [23:49<24:20:35,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               785.94651
Train_Epoch_Reward                    8382.75570
Running_Training_Average_Rewards      969.41164
Explore_Time                          0.00682
Train___Time                          8.62408
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.11184
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.73515
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.80021
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.73359
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.09385
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.83949
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.66934
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8385.73045
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.88324
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.39861
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.19202      1.30100     11.12619     3.79769
alpha_0                               1.68853      0.00415     1.69431      1.68005
alpha_1                               0.09772      0.00027     0.09826      0.09736
alpha_2                               0.03907      0.00054     0.03997      0.03813
alpha_3                               0.12906      0.00114     0.13110      0.12717
alpha_4                               0.04480      0.00068     0.04595      0.04363
alpha_5                               0.21452      0.00108     0.21617      0.21274
alpha_6                               0.12753      0.00101     0.12926      0.12579
alpha_7                               0.09214      0.00036     0.09281      0.09164
alpha_8                               0.14391      0.00213     0.14765      0.14023
alpha_9                               0.09029      0.00045     0.09108      0.08954
Alpha_loss                            4.00652      0.46954     5.20368      3.22732
Training/policy_loss                  -33.04573    9.24626     -13.05723    -54.05668
Training/qf1_loss                     10303.10635  2352.60568  16677.05273  5852.03906
Training/qf2_loss                     1226.49020   411.96942   2714.46851   424.05637
Training/pf_norm                      6.63980      3.69685     20.33868     2.32482
Training/qf1_norm                     4947.89558   2297.28303  11119.87695  1484.96057
Training/qf2_norm                     3544.77150   1617.76210  9579.83496   995.14264
log_std/mean                          -0.92191     0.01324     -0.89545     -0.94795
log_std/std                           0.37888      0.00701     0.39389      0.35806
log_std/max                           0.59040      0.19841     0.76734      0.11835
log_std/min                           -2.92672     0.17269     -2.29384     -3.17725
log_probs/mean                        5.48248      0.20405     6.00618      5.08570
log_probs/std                         3.56235      0.10590     3.82318      3.30958
log_probs/max                         22.47083     2.39184     27.97052     17.61340
log_probs/min                         -5.79616     1.52879     -3.00122     -9.56548
mean/mean                             0.18428      0.02738     0.23268      0.14059
mean/std                              1.68059      0.02279     1.73016      1.62770
mean/max                              4.42211      0.11155     4.63406      3.93972
mean/min                              -6.57136     1.23264     -4.07707     -7.70183
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 7, 2, 3, 4, 8, 1, 9, 5]
replay_buffer._size: [26850 26850 26850 26850 26850 26850 26850 26850 26850 26850]
2023-08-12 12:05:19,678 MainThread INFO: EPOCH:157
2023-08-12 12:05:19,678 MainThread INFO: Time Consumed:9.0058913230896s
2023-08-12 12:05:19,679 MainThread INFO: Total Frames:267000s
  2%|▏         | 158/10000 [23:58<24:35:38,  9.00s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               703.23637
Train_Epoch_Reward                    8491.06798
Running_Training_Average_Rewards      853.60543
Explore_Time                          0.00468
Train___Time                          8.99622
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.31480
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.82492
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.66920
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.10396
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.10475
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.73405
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.38632
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7656.22808
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.47638
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.24999
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.97336     1.44303     11.01548     3.79809
alpha_0                               1.69679     0.00103     1.69815      1.69440
alpha_1                               0.09732     0.00003     0.09738      0.09728
alpha_2                               0.04079     0.00045     0.04151      0.03999
alpha_3                               0.12554     0.00090     0.12713      0.12398
alpha_4                               0.04713     0.00065     0.04816      0.04597
alpha_5                               0.21761     0.00069     0.21828      0.21619
alpha_6                               0.13157     0.00138     0.13391      0.12929
alpha_7                               0.09392     0.00068     0.09512      0.09283
alpha_8                               0.15250     0.00277     0.15711      0.14774
alpha_9                               0.09190     0.00046     0.09262      0.09109
Alpha_loss                            4.22268     0.63615     5.41193      2.93876
Training/policy_loss                  -32.97820   10.26639    -8.66262     -60.87399
Training/qf1_loss                     9917.27960  2338.45949  15696.93750  4739.27686
Training/qf2_loss                     1198.83598  531.87717   2983.91650   369.87033
Training/pf_norm                      5.83874     2.39467     16.08685     2.56442
Training/qf1_norm                     4853.86637  2404.71411  12217.47949  1203.09875
Training/qf2_norm                     2674.98553  1201.72448  6875.24805   922.39484
log_std/mean                          -0.94671    0.01289     -0.92041     -0.97230
log_std/std                           0.38602     0.00628     0.39892      0.37134
log_std/max                           0.40204     0.17458     0.61074      0.00187
log_std/min                           -2.95827    0.22048     -2.24310     -3.21546
log_probs/mean                        5.61762     0.26617     6.08804      5.06763
log_probs/std                         3.45328     0.14064     3.73074      3.17288
log_probs/max                         23.17786    3.65768     29.67697     15.88321
log_probs/min                         -5.78287    1.53054     -3.27950     -10.72139
mean/mean                             0.18564     0.02706     0.24467      0.13936
mean/std                              1.67914     0.03641     1.74759      1.60386
mean/max                              4.22614     0.10892     4.35635      3.62582
mean/min                              -6.72949    1.37355     -3.96801     -8.18903
------------------------------------  ----------  ----------  -----------  ----------
sample: [7, 4, 8, 3, 9, 1, 5, 0, 2, 6]
replay_buffer._size: [27000 27000 27000 27000 27000 27000 27000 27000 27000 27000]
2023-08-12 12:05:29,072 MainThread INFO: EPOCH:158
2023-08-12 12:05:29,074 MainThread INFO: Time Consumed:9.217547178268433s
2023-08-12 12:05:29,074 MainThread INFO: Total Frames:268500s
  2%|▏         | 159/10000 [24:08<24:52:34,  9.10s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               654.94615
Train_Epoch_Reward                    8186.45061
Running_Training_Average_Rewards      835.34248
Explore_Time                          0.00394
Train___Time                          9.20766
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.62772
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.24041
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.31232
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.78319
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.75951
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.31299
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.27449
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7198.62907
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.82329
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.03363
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.13454      1.50042     11.15106     4.08702
alpha_0                               1.69711      0.00116     1.69851      1.69454
alpha_1                               0.09753      0.00013     0.09786      0.09738
alpha_2                               0.04215      0.00038     0.04282      0.04152
alpha_3                               0.12223      0.00098     0.12395      0.12056
alpha_4                               0.04904      0.00051     0.04994      0.04818
alpha_5                               0.21813      0.00026     0.21864      0.21781
alpha_6                               0.13635      0.00147     0.13893      0.13396
alpha_7                               0.09672      0.00098     0.09847      0.09514
alpha_8                               0.16113      0.00228     0.16498      0.15720
alpha_9                               0.09313      0.00028     0.09355      0.09263
Alpha_loss                            3.67600      0.37217     4.34706      2.72568
Training/policy_loss                  -32.32068    9.05663     -11.56790    -54.69032
Training/qf1_loss                     10522.12104  2514.89899  16478.08203  5254.95264
Training/qf2_loss                     1266.72940   558.69063   2929.29932   367.82730
Training/pf_norm                      5.29728      1.97828     11.66631     2.10185
Training/qf1_norm                     4861.11374   2261.48243  12920.16113  2285.97168
Training/qf2_norm                     2810.69322   1273.92066  6929.95020   1044.82959
log_std/mean                          -0.93895     0.00881     -0.91740     -0.95777
log_std/std                           0.38533      0.00682     0.40315      0.36737
log_std/max                           0.29985      0.10608     0.47234      0.03151
log_std/min                           -2.88690     0.22073     -2.27120     -3.13484
log_probs/mean                        5.42042      0.16156     5.76132      4.94639
log_probs/std                         3.33491      0.11013     3.62954      3.05069
log_probs/max                         24.42648     4.67590     32.02049     14.93291
log_probs/min                         -5.48912     1.41740     -3.14935     -11.46917
mean/mean                             0.21512      0.02588     0.26447      0.15333
mean/std                              1.64684      0.02154     1.68526      1.58044
mean/max                              4.29791      0.13342     4.45888      3.57751
mean/min                              -7.10332     1.58729     -3.93649     -8.52008
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 7, 1, 3, 2, 9, 5, 4, 6]
replay_buffer._size: [27150 27150 27150 27150 27150 27150 27150 27150 27150 27150]
2023-08-12 12:05:38,085 MainThread INFO: EPOCH:159
2023-08-12 12:05:38,088 MainThread INFO: Time Consumed:8.785112619400024s
2023-08-12 12:05:38,088 MainThread INFO: Total Frames:270000s
  2%|▏         | 160/10000 [24:17<24:48:24,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               674.86792
Train_Epoch_Reward                    6142.78548
Running_Training_Average_Rewards      760.67680
Explore_Time                          0.00388
Train___Time                          8.77629
Eval____Time                          0.00427
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.50630
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.94561
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.68215
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.24970
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.65240
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.68071
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.24112
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7345.98529
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.26057
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.08749
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.88652      1.40044     10.44281     4.07944
alpha_0                               1.68797      0.00424     1.69452      1.68101
alpha_1                               0.09850      0.00037     0.09912      0.09787
alpha_2                               0.04341      0.00033     0.04399      0.04283
alpha_3                               0.11901      0.00084     0.12053      0.11769
alpha_4                               0.05079      0.00049     0.05167      0.04996
alpha_5                               0.21813      0.00034     0.21865      0.21741
alpha_6                               0.14116      0.00121     0.14325      0.13898
alpha_7                               0.10069      0.00138     0.10313      0.09850
alpha_8                               0.16841      0.00190     0.17162      0.16505
alpha_9                               0.09370      0.00006     0.09376      0.09355
Alpha_loss                            3.32916      0.25006     4.13704      2.78749
Training/policy_loss                  -32.85247    8.92503     -12.69435    -66.22781
Training/qf1_loss                     10147.14472  2304.42509  17543.33594  5565.04150
Training/qf2_loss                     1219.33488   539.95479   3122.74585   444.95020
Training/pf_norm                      5.81809      2.76300     15.99293     2.00770
Training/qf1_norm                     4999.10398   2370.08080  12078.93652  1803.10291
Training/qf2_norm                     2661.73479   1227.05474  6278.52344   757.82489
log_std/mean                          -0.93386     0.00878     -0.91737     -0.95826
log_std/std                           0.38777      0.00533     0.40679      0.37655
log_std/max                           0.36468      0.11539     0.49917      0.08141
log_std/min                           -2.83465     0.21367     -2.23925     -3.11529
log_probs/mean                        5.25216      0.11392     5.59097      5.01104
log_probs/std                         3.29208      0.12282     3.65788      3.03032
log_probs/max                         25.81202     5.90046     34.67870     15.27767
log_probs/min                         -5.87448     1.67816     -3.20979     -13.54103
mean/mean                             0.25332      0.03695     0.31963      0.17281
mean/std                              1.61676      0.01606     1.66964      1.57507
mean/max                              4.36791      0.10743     4.51435      3.98226
mean/min                              -7.15724     1.66163     -3.40439     -8.92587
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 3, 5, 7, 0, 9, 6, 1, 8]
replay_buffer._size: [27300 27300 27300 27300 27300 27300 27300 27300 27300 27300]
2023-08-12 12:05:47,014 MainThread INFO: EPOCH:160
2023-08-12 12:05:47,015 MainThread INFO: Time Consumed:8.78171968460083s
2023-08-12 12:05:47,015 MainThread INFO: Total Frames:271500s
  2%|▏         | 161/10000 [24:26<24:40:59,  9.03s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               671.57661
Train_Epoch_Reward                    7528.71345
Running_Training_Average_Rewards      728.59832
Explore_Time                          0.01534
Train___Time                          8.76147
Eval____Time                          0.00379
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.31182
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.93093
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.35768
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.47487
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.32219
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.57520
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.02404
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7309.90355
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.06218
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.07852
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.29025      1.29474     11.46423     4.45492
alpha_0                               1.67525      0.00408     1.68092      1.66834
alpha_1                               0.09972      0.00037     0.10044      0.09913
alpha_2                               0.04457      0.00032     0.04512      0.04400
alpha_3                               0.11624      0.00083     0.11766      0.11492
alpha_4                               0.05264      0.00053     0.05349      0.05169
alpha_5                               0.21710      0.00012     0.21739      0.21687
alpha_6                               0.14530      0.00113     0.14721      0.14329
alpha_7                               0.10566      0.00146     0.10817      0.10318
alpha_8                               0.17475      0.00176     0.17782      0.17168
alpha_9                               0.09338      0.00022     0.09371      0.09299
Alpha_loss                            3.11485      0.33821     3.82529      2.10161
Training/policy_loss                  -35.36580    8.34875     -12.37901    -56.26696
Training/qf1_loss                     10997.56505  2412.64642  18307.09766  5764.37744
Training/qf2_loss                     1211.13636   481.28726   2578.17285   430.38931
Training/pf_norm                      5.68176      2.25231     16.95013     2.15942
Training/qf1_norm                     5075.91997   2123.99360  11009.54395  1790.28625
Training/qf2_norm                     2648.21246   1254.09861  6691.30908   851.50842
log_std/mean                          -0.94314     0.00594     -0.92716     -0.95446
log_std/std                           0.38161      0.00479     0.39119      0.37025
log_std/max                           0.34571      0.12849     0.46398      0.03792
log_std/min                           -2.80970     0.21737     -2.28084     -3.02166
log_probs/mean                        5.19507      0.15353     5.53127      4.80616
log_probs/std                         3.36096      0.13531     3.80023      3.06297
log_probs/max                         27.97574     6.59334     36.99132     15.37025
log_probs/min                         -5.48148     1.23625     -3.08628     -8.64923
mean/mean                             0.21120      0.02778     0.26856      0.15702
mean/std                              1.60852      0.02319     1.65508      1.54454
mean/max                              4.33705      0.14908     4.49912      3.66281
mean/min                              -7.52564     1.75263     -3.96026     -9.15751
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 5, 3, 1, 4, 0, 8, 6, 9]
replay_buffer._size: [27450 27450 27450 27450 27450 27450 27450 27450 27450 27450]
2023-08-12 12:05:55,326 MainThread INFO: EPOCH:161
2023-08-12 12:05:55,327 MainThread INFO: Time Consumed:8.143922090530396s
2023-08-12 12:05:55,327 MainThread INFO: Total Frames:273000s
  2%|▏         | 162/10000 [24:34<24:05:11,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               669.89123
Train_Epoch_Reward                    6358.41155
Running_Training_Average_Rewards      667.66368
Explore_Time                          0.00927
Train___Time                          8.12912
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.26988
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.03483
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.33001
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.11359
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.24709
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.69961
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.22537
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7293.67490
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.57796
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.26424
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.24544      1.27725     11.38069     4.71333
alpha_0                               1.65873      0.00546     1.66820      1.65116
alpha_1                               0.10136      0.00052     0.10224      0.10046
alpha_2                               0.04556      0.00023     0.04594      0.04513
alpha_3                               0.11391      0.00050     0.11489      0.11323
alpha_4                               0.05413      0.00034     0.05473      0.05351
alpha_5                               0.21568      0.00062     0.21686      0.21492
alpha_6                               0.14916      0.00111     0.15121      0.14725
alpha_7                               0.11115      0.00179     0.11436      0.10823
alpha_8                               0.18114      0.00188     0.18440      0.17789
alpha_9                               0.09251      0.00029     0.09299      0.09203
Alpha_loss                            2.66326      0.31462     3.31330      1.93948
Training/policy_loss                  -32.46816    8.98989     -13.58470    -55.72808
Training/qf1_loss                     10832.99890  2747.77343  18424.36914  5740.85400
Training/qf2_loss                     1243.37833   530.26680   3458.61011   350.35614
Training/pf_norm                      5.73008      1.98006     11.94135     2.69400
Training/qf1_norm                     4977.57993   2373.44855  15071.49805  2009.58801
Training/qf2_norm                     2907.35589   1618.48330  8739.70020   1030.94543
log_std/mean                          -0.95505     0.00915     -0.93477     -0.98083
log_std/std                           0.39118      0.00566     0.40362      0.37301
log_std/max                           0.35167      0.11678     0.46257      0.05425
log_std/min                           -2.81982     0.22766     -2.43216     -3.07556
log_probs/mean                        5.06873      0.15459     5.39644      4.70821
log_probs/std                         3.31741      0.14969     3.79368      2.96925
log_probs/max                         29.99904     6.81603     38.50247     15.88392
log_probs/min                         -6.03694     1.52944     -3.82578     -11.80720
mean/mean                             0.22928      0.01705     0.27061      0.19686
mean/std                              1.57802      0.02231     1.63696      1.53103
mean/max                              4.54886      0.10314     4.70473      3.74573
mean/min                              -7.82914     1.66476     -4.64657     -9.35995
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 2, 6, 8, 0, 7, 1, 4, 5, 9]
replay_buffer._size: [27600 27600 27600 27600 27600 27600 27600 27600 27600 27600]
2023-08-12 12:06:04,296 MainThread INFO: EPOCH:162
2023-08-12 12:06:04,296 MainThread INFO: Time Consumed:8.809465646743774s
2023-08-12 12:06:04,296 MainThread INFO: Total Frames:274500s
  2%|▏         | 163/10000 [24:43<24:12:38,  8.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               662.93076
Train_Epoch_Reward                    6065.72990
Running_Training_Average_Rewards      665.09516
Explore_Time                          0.00599
Train___Time                          8.79955
Eval____Time                          0.00327
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.31372
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.51750
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.50032
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.49354
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -92.58934
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.99199
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.66543
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7216.97956
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.24798
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.35217
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.18829      1.25290     11.77631     3.33785
alpha_0                               1.64941      0.00145     1.65293      1.64795
alpha_1                               0.10316      0.00052     0.10408      0.10226
alpha_2                               0.04638      0.00025     0.04680      0.04595
alpha_3                               0.11268      0.00032     0.11322      0.11215
alpha_4                               0.05567      0.00061     0.05681      0.05475
alpha_5                               0.21422      0.00032     0.21491      0.21382
alpha_6                               0.15375      0.00143     0.15610      0.15126
alpha_7                               0.11770      0.00191     0.12100      0.11442
alpha_8                               0.18774      0.00187     0.19090      0.18447
alpha_9                               0.09146      0.00035     0.09203      0.09086
Alpha_loss                            3.30166      0.32314     4.06358      2.62497
Training/policy_loss                  -32.17374    9.54854     3.43562      -61.43524
Training/qf1_loss                     11455.60713  3107.58603  25061.18555  5973.59326
Training/qf2_loss                     1238.16656   449.19152   3085.67749   557.99945
Training/pf_norm                      6.41147      2.19672     12.93872     2.22020
Training/qf1_norm                     5043.25841   2281.86327  13340.23633  1699.20068
Training/qf2_norm                     3435.28351   1760.29882  9395.69531   868.70117
log_std/mean                          -0.96460     0.00921     -0.94222     -0.98574
log_std/std                           0.37918      0.00653     0.39509      0.36245
log_std/max                           0.30241      0.13296     0.49516      0.05548
log_std/min                           -2.93970     0.21815     -2.31566     -3.22407
log_probs/mean                        5.39672      0.17207     5.76636      4.97813
log_probs/std                         3.51320      0.16837     4.05480      3.09777
log_probs/max                         31.02124     7.09895     39.98548     16.09286
log_probs/min                         -5.77501     1.52211     -3.65952     -12.31384
mean/mean                             0.18935      0.02361     0.23245      0.14374
mean/std                              1.63221      0.02631     1.70164      1.57904
mean/max                              4.64563      0.24620     5.03429      3.75573
mean/min                              -7.97739     1.71195     -5.00376     -9.60161
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 9, 0, 5, 7, 1, 2, 8, 6, 3]
replay_buffer._size: [27750 27750 27750 27750 27750 27750 27750 27750 27750 27750]
2023-08-12 12:06:13,430 MainThread INFO: EPOCH:163
2023-08-12 12:06:13,431 MainThread INFO: Time Consumed:8.974481105804443s
2023-08-12 12:06:13,431 MainThread INFO: Total Frames:276000s
  2%|▏         | 164/10000 [24:52<24:27:13,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               668.89202
Train_Epoch_Reward                    7094.24297
Running_Training_Average_Rewards      650.61281
Explore_Time                          0.01038
Train___Time                          8.95884
Eval____Time                          0.00449
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.79972
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.47143
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.35548
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.38356
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.38585
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.85663
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.24211
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7279.30808
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.59348
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.29960
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.30489      1.50182     10.95758     4.42426
alpha_0                               1.65992      0.00344     1.66438      1.65302
alpha_1                               0.10502      0.00049     0.10572      0.10410
alpha_2                               0.04726      0.00025     0.04766      0.04681
alpha_3                               0.11167      0.00027     0.11214      0.11126
alpha_4                               0.05817      0.00074     0.05934      0.05684
alpha_5                               0.21467      0.00023     0.21492      0.21406
alpha_6                               0.15849      0.00133     0.16065      0.15614
alpha_7                               0.12420      0.00180     0.12726      0.12107
alpha_8                               0.19430      0.00186     0.19726      0.19097
alpha_9                               0.09020      0.00037     0.09084      0.08958
Alpha_loss                            3.28907      0.50063     4.37518      2.23276
Training/policy_loss                  -31.64035    10.27538    -2.39368     -54.15182
Training/qf1_loss                     11672.70121  3519.26092  21822.04883  6332.14404
Training/qf2_loss                     1283.32198   617.39414   4097.14600   448.26230
Training/pf_norm                      6.07581      2.44442     16.36246     2.65429
Training/qf1_norm                     5127.37364   2288.56119  13223.60059  1491.62769
Training/qf2_norm                     3101.77897   1466.25036  7218.90088   876.11969
log_std/mean                          -0.97359     0.01043     -0.94741     -0.99273
log_std/std                           0.37743      0.00611     0.39343      0.36412
log_std/max                           0.36719      0.11500     0.49044      0.05392
log_std/min                           -2.99239     0.23294     -2.41550     -3.28192
log_probs/mean                        5.42549      0.23667     5.88610      4.89295
log_probs/std                         3.60000      0.14248     3.93874      3.23988
log_probs/max                         31.72737     8.22796     41.67293     17.37057
log_probs/min                         -5.74578     1.47477     -3.32477     -10.43503
mean/mean                             0.15716      0.02983     0.22257      0.10087
mean/std                              1.63612      0.03417     1.70872      1.56499
mean/max                              4.80133      0.42956     5.29768      4.12405
mean/min                              -8.17680     1.93652     -4.59729     -9.97576
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 6, 5, 3, 2, 9, 1, 7, 8]
replay_buffer._size: [27900 27900 27900 27900 27900 27900 27900 27900 27900 27900]
2023-08-12 12:06:22,400 MainThread INFO: EPOCH:164
2023-08-12 12:06:22,401 MainThread INFO: Time Consumed:8.807226657867432s
2023-08-12 12:06:22,401 MainThread INFO: Total Frames:277500s
  2%|▏         | 165/10000 [25:01<24:27:11,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               678.55716
Train_Epoch_Reward                    6522.53079
Running_Training_Average_Rewards      656.08346
Explore_Time                          0.01038
Train___Time                          8.79170
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.13263
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.88609
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.45123
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.95651
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -92.47943
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.07066
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.85565
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7373.17180
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.56667
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.20132
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.97254      1.50291     10.83762     3.83355
alpha_0                               1.66167      0.00329     1.66473      1.65434
alpha_1                               0.10629      0.00028     0.10678      0.10574
alpha_2                               0.04800      0.00018     0.04828      0.04767
alpha_3                               0.11129      0.00014     0.11165      0.11116
alpha_4                               0.06007      0.00037     0.06062      0.05936
alpha_5                               0.21532      0.00026     0.21562      0.21479
alpha_6                               0.16232      0.00089     0.16377      0.16069
alpha_7                               0.13034      0.00180     0.13354      0.12732
alpha_8                               0.19964      0.00128     0.20167      0.19731
alpha_9                               0.08915      0.00025     0.08957      0.08876
Alpha_loss                            2.29304      0.39126     3.05132      1.52073
Training/policy_loss                  -31.01880    9.72729     -0.12319     -52.31499
Training/qf1_loss                     11314.82541  2993.43440  19513.49023  5948.10010
Training/qf2_loss                     1152.55279   459.53188   3078.20776   458.28146
Training/pf_norm                      5.54783      2.43031     13.56535     2.35156
Training/qf1_norm                     5755.50910   2599.95796  12724.99805  1708.73987
Training/qf2_norm                     3118.00481   1356.57108  7806.51953   977.37939
log_std/mean                          -0.98304     0.00728     -0.96731     -1.00419
log_std/std                           0.38579      0.00597     0.40337      0.37320
log_std/max                           0.27612      0.11968     0.42387      -0.00282
log_std/min                           -3.01202     0.17496     -2.65168     -3.27476
log_probs/mean                        4.99628      0.19354     5.34560      4.59397
log_probs/std                         3.45046      0.14248     3.77834      3.09726
log_probs/max                         34.91964     8.06263     44.35148     16.79405
log_probs/min                         -6.14411     1.22631     -3.90278     -9.09690
mean/mean                             0.24385      0.03741     0.31083      0.17750
mean/std                              1.55957      0.03065     1.63236      1.48920
mean/max                              5.03203      0.48769     5.61851      3.82153
mean/min                              -8.54861     1.70756     -4.90776     -10.01614
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 3, 7, 5, 9, 0, 4, 2, 1, 8]
replay_buffer._size: [28050 28050 28050 28050 28050 28050 28050 28050 28050 28050]
2023-08-12 12:06:31,610 MainThread INFO: EPOCH:165
2023-08-12 12:06:31,610 MainThread INFO: Time Consumed:9.051432609558105s
2023-08-12 12:06:31,611 MainThread INFO: Total Frames:279000s
  2%|▏         | 166/10000 [25:10<24:41:38,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               733.88509
Train_Epoch_Reward                    6933.03258
Running_Training_Average_Rewards      684.99354
Explore_Time                          0.00475
Train___Time                          9.04189
Eval____Time                          0.00385
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.23516
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.40386
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.18232
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.20989
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.46213
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.68437
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.43274
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7921.12879
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.34791
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.31952
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.15853      1.30420     10.39650     4.34921
alpha_0                               1.65041      0.00259     1.65420      1.64455
alpha_1                               0.10797      0.00073     0.10921      0.10680
alpha_2                               0.04866      0.00022     0.04900      0.04829
alpha_3                               0.11223      0.00034     0.11289      0.11166
alpha_4                               0.06117      0.00030     0.06165      0.06063
alpha_5                               0.21486      0.00033     0.21535      0.21427
alpha_6                               0.16586      0.00116     0.16766      0.16381
alpha_7                               0.13698      0.00192     0.14027      0.13361
alpha_8                               0.20393      0.00136     0.20636      0.20171
alpha_9                               0.08870      0.00004     0.08881      0.08866
Alpha_loss                            2.58579      0.30704     3.35494      1.85443
Training/policy_loss                  -32.28148    9.65553     -6.68602     -57.27757
Training/qf1_loss                     11767.61707  2958.86800  20273.56250  5976.40332
Training/qf2_loss                     1217.45131   516.52887   2716.21313   497.54181
Training/pf_norm                      6.76423      3.03257     17.78559     2.46326
Training/qf1_norm                     5438.43971   2130.32725  11859.63281  1601.35535
Training/qf2_norm                     3299.52797   1630.94918  10213.78125  934.38605
log_std/mean                          -0.99424     0.00762     -0.97462     -1.01505
log_std/std                           0.38864      0.00545     0.40294      0.37678
log_std/max                           0.27394      0.11217     0.37650      -0.02314
log_std/min                           -2.96874     0.16312     -2.57677     -3.15684
log_probs/mean                        5.14544      0.15496     5.55702      4.80885
log_probs/std                         3.53160      0.16377     3.95031      3.28386
log_probs/max                         34.96642     9.32209     45.02465     18.34788
log_probs/min                         -5.90772     1.34457     -3.12091     -10.23200
mean/mean                             0.30378      0.01191     0.32725      0.26294
mean/std                              1.56847      0.02401     1.62718      1.51042
mean/max                              5.17245      0.39705     5.73880      4.05690
mean/min                              -8.22465     1.91388     -4.55624     -9.94439
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 2, 9, 8, 3, 1, 7, 4, 6, 0]
replay_buffer._size: [28200 28200 28200 28200 28200 28200 28200 28200 28200 28200]
2023-08-12 12:06:40,462 MainThread INFO: EPOCH:166
2023-08-12 12:06:40,462 MainThread INFO: Time Consumed:8.682506799697876s
2023-08-12 12:06:40,462 MainThread INFO: Total Frames:280500s
  2%|▏         | 167/10000 [25:19<24:30:51,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               717.14060
Train_Epoch_Reward                    6818.91181
Running_Training_Average_Rewards      675.81584
Explore_Time                          0.00955
Train___Time                          8.66842
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.84464
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.59620
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.40092
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.58788
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.36572
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.71554
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.19677
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7759.37436
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.74760
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.51309
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.19108      1.31923     10.98028     4.12014
alpha_0                               1.63733      0.00514     1.64444      1.62814
alpha_1                               0.11036      0.00066     0.11160      0.10924
alpha_2                               0.04923      0.00013     0.04947      0.04901
alpha_3                               0.11409      0.00076     0.11554      0.11291
alpha_4                               0.06202      0.00023     0.06245      0.06165
alpha_5                               0.21361      0.00040     0.21424      0.21287
alpha_6                               0.16912      0.00088     0.17073      0.16768
alpha_7                               0.14386      0.00206     0.14734      0.14034
alpha_8                               0.20892      0.00138     0.21120      0.20641
alpha_9                               0.08918      0.00021     0.08958      0.08882
Alpha_loss                            2.46100      0.34668     3.35849      1.73635
Training/policy_loss                  -32.16288    9.78486     -7.33602     -61.59727
Training/qf1_loss                     11567.17900  2951.66204  20280.73242  5550.95215
Training/qf2_loss                     1200.19659   470.33282   3061.22998   386.05798
Training/pf_norm                      6.75081      2.42906     13.67252     2.81226
Training/qf1_norm                     5336.91094   2272.44221  14174.92578  2208.46216
Training/qf2_norm                     3243.29477   1322.73817  6811.82812   1062.42102
log_std/mean                          -0.99115     0.01095     -0.96237     -1.00963
log_std/std                           0.39249      0.00625     0.40975      0.38112
log_std/max                           0.26597      0.10456     0.39253      -0.08689
log_std/min                           -2.89451     0.14972     -2.59662     -3.13120
log_probs/mean                        5.10860      0.18622     5.55288      4.71059
log_probs/std                         3.60519      0.19017     4.13639      3.20887
log_probs/max                         34.99467     9.34164     45.17870     15.53291
log_probs/min                         -5.91415     1.18458     -3.62768     -10.19501
mean/mean                             0.34355      0.03927     0.42712      0.28965
mean/std                              1.55750      0.02982     1.62546      1.49119
mean/max                              5.39460      0.51727     6.02549      3.74166
mean/min                              -8.11273     2.00416     -4.76515     -10.16992
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 1, 7, 4, 2, 3, 9, 5, 0, 6]
replay_buffer._size: [28350 28350 28350 28350 28350 28350 28350 28350 28350 28350]
2023-08-12 12:06:49,436 MainThread INFO: EPOCH:167
2023-08-12 12:06:49,436 MainThread INFO: Time Consumed:8.78192663192749s
2023-08-12 12:06:49,436 MainThread INFO: Total Frames:282000s
  2%|▏         | 168/10000 [25:28<24:30:53,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               706.52855
Train_Epoch_Reward                    7069.01525
Running_Training_Average_Rewards      694.03199
Explore_Time                          0.01178
Train___Time                          8.76513
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.51839
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.02409
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.43327
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.90723
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.70952
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.43760
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.85927
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7653.90202
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.15392
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.57326
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.25167      1.62374     13.35438     3.29248
alpha_0                               1.61627      0.00725     1.62796      1.60413
alpha_1                               0.11334      0.00101     0.11506      0.11163
alpha_2                               0.04994      0.00028     0.05039      0.04947
alpha_3                               0.11701      0.00087     0.11860      0.11557
alpha_4                               0.06312      0.00040     0.06378      0.06246
alpha_5                               0.21290      0.00013     0.21315      0.21259
alpha_6                               0.17292      0.00120     0.17482      0.17077
alpha_7                               0.15071      0.00195     0.15414      0.14741
alpha_8                               0.21353      0.00131     0.21573      0.21124
alpha_9                               0.08992      0.00021     0.09033      0.08959
Alpha_loss                            3.05468      0.29817     3.76126      2.23303
Training/policy_loss                  -31.52773    9.55170     -2.11806     -51.20848
Training/qf1_loss                     11960.84665  3130.16332  18753.91016  5544.59912
Training/qf2_loss                     1182.96897   537.61975   3550.59839   317.87460
Training/pf_norm                      6.44050      2.42867     15.03590     2.96177
Training/qf1_norm                     5822.71539   2578.82466  15950.87305  2150.10522
Training/qf2_norm                     2985.70051   1510.47034  9514.09961   899.73041
log_std/mean                          -0.97074     0.01787     -0.93629     -0.99951
log_std/std                           0.38882      0.00516     0.40186      0.37886
log_std/max                           0.19918      0.08637     0.38127      -0.00575
log_std/min                           -2.83896     0.15536     -2.54005     -3.03175
log_probs/mean                        5.33551      0.15193     5.74758      5.00549
log_probs/std                         3.68892      0.14442     4.06816      3.38978
log_probs/max                         37.82073     8.74126     46.04386     16.79170
log_probs/min                         -5.72050     1.30240     -3.49558     -9.47647
mean/mean                             0.34308      0.04241     0.40281      0.25784
mean/std                              1.60542      0.02130     1.65078      1.55094
mean/max                              5.63136      0.52039     6.21791      4.07411
mean/min                              -8.84495     1.77859     -4.43888     -10.17163
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 4, 7, 1, 8, 5, 3, 0, 2, 9]
replay_buffer._size: [28500 28500 28500 28500 28500 28500 28500 28500 28500 28500]
2023-08-12 12:06:58,612 MainThread INFO: EPOCH:168
2023-08-12 12:06:58,612 MainThread INFO: Time Consumed:8.997952222824097s
2023-08-12 12:06:58,613 MainThread INFO: Total Frames:283500s
  2%|▏         | 169/10000 [25:37<24:41:36,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               792.53286
Train_Epoch_Reward                    7294.40350
Running_Training_Average_Rewards      706.07769
Explore_Time                          0.00859
Train___Time                          8.98500
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.38820
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.43000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42519
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.78343
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.51122
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.00702
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.61797
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8515.89806
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.53376
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.87264
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.01496      1.35095     10.84266     3.64342
alpha_0                               1.59510      0.00429     1.60386      1.59027
alpha_1                               0.11680      0.00091     0.11820      0.11509
alpha_2                               0.05087      0.00025     0.05127      0.05040
alpha_3                               0.12021      0.00097     0.12199      0.11863
alpha_4                               0.06442      0.00035     0.06498      0.06380
alpha_5                               0.21188      0.00041     0.21258      0.21102
alpha_6                               0.17648      0.00088     0.17776      0.17486
alpha_7                               0.15752      0.00196     0.16094      0.15420
alpha_8                               0.21749      0.00089     0.21889      0.21577
alpha_9                               0.09083      0.00027     0.09129      0.09034
Alpha_loss                            2.59828      0.38922     3.38411      1.56570
Training/policy_loss                  -31.15054    9.94181     -10.23038    -53.32490
Training/qf1_loss                     11587.70371  2901.04130  21106.09766  5836.22217
Training/qf2_loss                     1163.89067   423.61678   2223.28174   483.79449
Training/pf_norm                      6.51845      2.43851     15.38519     2.43805
Training/qf1_norm                     5411.79687   2354.06153  13091.56836  2143.38208
Training/qf2_norm                     2669.23125   1296.78075  7294.39062   904.83881
log_std/mean                          -0.95945     0.01113     -0.93355     -0.98258
log_std/std                           0.38124      0.00580     0.39925      0.36599
log_std/max                           0.15965      0.07424     0.27356      -0.05646
log_std/min                           -2.80177     0.14433     -2.49646     -2.97797
log_probs/mean                        5.16605      0.17764     5.66611      4.70212
log_probs/std                         3.71192      0.14920     4.05476      3.38203
log_probs/max                         35.25394     9.72128     47.77907     18.20668
log_probs/min                         -6.00706     1.40476     -3.69131     -11.83722
mean/mean                             0.33277      0.01422     0.36398      0.29937
mean/std                              1.58679      0.02801     1.66365      1.52670
mean/max                              5.63157      0.70646     6.67241      4.20513
mean/min                              -7.97984     1.96694     -3.37840     -10.10895
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 4, 3, 5, 6, 9, 2, 8, 0, 1]
replay_buffer._size: [28650 28650 28650 28650 28650 28650 28650 28650 28650 28650]
2023-08-12 12:07:07,095 MainThread INFO: EPOCH:169
2023-08-12 12:07:07,096 MainThread INFO: Time Consumed:8.317001342773438s
2023-08-12 12:07:07,096 MainThread INFO: Total Frames:285000s
  2%|▏         | 170/10000 [25:46<24:12:04,  8.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               760.73686
Train_Epoch_Reward                    7800.48486
Running_Training_Average_Rewards      738.79679
Explore_Time                          0.02291
Train___Time                          8.28916
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.46098
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.50541
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.37686
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.85075
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.17722
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.37390
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.56570
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8201.03385
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.15087
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.20354
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.11389      1.35926     11.56571     4.47740
alpha_0                               1.58591      0.00394     1.59147      1.57863
alpha_1                               0.11945      0.00072     0.12063      0.11823
alpha_2                               0.05160      0.00018     0.05188      0.05128
alpha_3                               0.12376      0.00093     0.12528      0.12203
alpha_4                               0.06554      0.00034     0.06614      0.06499
alpha_5                               0.20986      0.00042     0.21097      0.20950
alpha_6                               0.17828      0.00026     0.17872      0.17778
alpha_7                               0.16421      0.00182     0.16733      0.16101
alpha_8                               0.22005      0.00066     0.22109      0.21892
alpha_9                               0.09202      0.00048     0.09284      0.09130
Alpha_loss                            2.16719      0.33725     3.00653      1.43215
Training/policy_loss                  -29.96314    11.34331    -7.93223     -60.10153
Training/qf1_loss                     12475.25858  3421.18037  22675.76367  6263.63818
Training/qf2_loss                     1150.89621   443.31914   2362.05347   380.45090
Training/pf_norm                      7.52300      2.79376     18.12390     2.72642
Training/qf1_norm                     5627.81860   2560.45174  14164.59375  1843.54541
Training/qf2_norm                     3141.09093   1622.42806  7662.62256   934.35083
log_std/mean                          -0.95105     0.00618     -0.93454     -0.96490
log_std/std                           0.38879      0.00621     0.40347      0.37437
log_std/max                           0.15570      0.08002     0.26959      -0.06081
log_std/min                           -2.79099     0.14058     -2.52267     -2.97914
log_probs/mean                        4.96178      0.17357     5.39979      4.57748
log_probs/std                         3.79129      0.18823     4.31750      3.45427
log_probs/max                         36.80517     10.09292    47.46956     18.30324
log_probs/min                         -6.13176     1.56361     -3.52849     -11.49980
mean/mean                             0.23942      0.04334     0.32015      0.18041
mean/std                              1.57704      0.02759     1.65729      1.52230
mean/max                              5.87905      0.68995     6.67240      4.83794
mean/min                              -8.32067     2.04888     -4.52467     -10.27907
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 0, 7, 4, 1, 3, 6, 8, 2, 9]
replay_buffer._size: [28800 28800 28800 28800 28800 28800 28800 28800 28800 28800]
2023-08-12 12:07:16,412 MainThread INFO: EPOCH:170
2023-08-12 12:07:16,412 MainThread INFO: Time Consumed:9.120380878448486s
2023-08-12 12:07:16,412 MainThread INFO: Total Frames:286500s
  2%|▏         | 171/10000 [25:55<24:37:29,  9.02s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               726.66661
Train_Epoch_Reward                    8234.44285
Running_Training_Average_Rewards      777.64437
Explore_Time                          0.01811
Train___Time                          9.09710
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.08938
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.26277
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.49322
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.77604
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.33278
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.60771
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.23937
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7859.37948
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.57042
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.34169
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.02568      1.30322     11.39362     4.09460
alpha_0                               1.56323      0.00798     1.57831      1.54939
alpha_1                               0.12158      0.00059     0.12281      0.12065
alpha_2                               0.05194      0.00003     0.05197      0.05188
alpha_3                               0.12738      0.00132     0.12969      0.12532
alpha_4                               0.06653      0.00019     0.06687      0.06615
alpha_5                               0.20958      0.00006     0.20966      0.20947
alpha_6                               0.17897      0.00021     0.17960      0.17872
alpha_7                               0.17047      0.00187     0.17373      0.16739
alpha_8                               0.22132      0.00014     0.22152      0.22101
alpha_9                               0.09379      0.00054     0.09467      0.09285
Alpha_loss                            1.64174      0.24352     2.09402      0.89583
Training/policy_loss                  -29.06557    9.97174     -5.57000     -54.74204
Training/qf1_loss                     12157.17038  3171.15216  20321.80273  6547.30566
Training/qf2_loss                     1140.97503   395.85780   2351.90088   486.39902
Training/pf_norm                      7.61508      2.82647     16.34890     3.14111
Training/qf1_norm                     5212.32833   2621.77772  17495.23047  1853.10522
Training/qf2_norm                     3098.00687   1438.42515  8580.55664   875.22223
log_std/mean                          -0.97066     0.01784     -0.93560     -1.00480
log_std/std                           0.38816      0.00542     0.39974      0.37507
log_std/max                           0.09281      0.07416     0.20125      -0.09444
log_std/min                           -2.75480     0.10648     -2.51486     -2.91779
log_probs/mean                        4.74311      0.12489     5.05637      4.44970
log_probs/std                         3.86973      0.19462     4.39406      3.53749
log_probs/max                         39.77725     9.41579     48.52287     18.03584
log_probs/min                         -6.21883     1.39326     -3.63067     -10.82095
mean/mean                             0.27418      0.03851     0.33300      0.20150
mean/std                              1.53069      0.02458     1.59055      1.47491
mean/max                              6.27082      0.80734     6.99746      4.85962
mean/min                              -8.73505     1.92796     -4.71005     -10.22774
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 3, 5, 6, 2, 4, 8, 0, 1, 9]
replay_buffer._size: [28950 28950 28950 28950 28950 28950 28950 28950 28950 28950]
2023-08-12 12:07:25,466 MainThread INFO: EPOCH:171
2023-08-12 12:07:25,466 MainThread INFO: Time Consumed:8.879507303237915s
2023-08-12 12:07:25,466 MainThread INFO: Total Frames:288000s
  2%|▏         | 172/10000 [26:04<24:37:58,  9.02s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               750.53646
Train_Epoch_Reward                    7038.09410
Running_Training_Average_Rewards      769.10073
Explore_Time                          0.01227
Train___Time                          8.86216
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.16311
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.66901
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.31268
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.47610
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.15385
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.17685
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.38553
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8095.27177
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.38675
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.18329
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.16468      1.32794     11.59809     3.88689
alpha_0                               1.53457      0.00741     1.54896      1.52103
alpha_1                               0.12438      0.00083     0.12568      0.12284
alpha_2                               0.05181      0.00004     0.05188      0.05175
alpha_3                               0.13149      0.00092     0.13293      0.12973
alpha_4                               0.06727      0.00025     0.06773      0.06688
alpha_5                               0.20957      0.00017     0.20981      0.20923
alpha_6                               0.18127      0.00104     0.18293      0.17963
alpha_7                               0.17686      0.00178     0.17992      0.17380
alpha_8                               0.22018      0.00045     0.22100      0.21932
alpha_9                               0.09572      0.00064     0.09695      0.09470
Alpha_loss                            1.65796      0.29192     2.36828      0.99044
Training/policy_loss                  -29.20246    11.07290    2.44204      -58.15280
Training/qf1_loss                     12287.29701  3278.17082  20738.93164  6354.26562
Training/qf2_loss                     1239.33874   484.40323   2952.75269   397.43015
Training/pf_norm                      7.24433      3.32808     23.66615     3.07632
Training/qf1_norm                     6189.02428   2521.13177  14393.35547  2578.50635
Training/qf2_norm                     2830.03144   1354.00450  7040.86328   912.16510
log_std/mean                          -0.95526     0.00921     -0.93305     -0.97609
log_std/std                           0.37419      0.00722     0.39412      0.35785
log_std/max                           0.07612      0.05943     0.21772      -0.11505
log_std/min                           -2.73455     0.09195     -2.51806     -2.86003
log_probs/mean                        4.76466      0.15861     5.10966      4.41655
log_probs/std                         3.84573      0.16699     4.30137      3.54580
log_probs/max                         39.39190     9.87577     48.28349     18.74534
log_probs/min                         -6.35081     1.42157     -3.00268     -9.96990
mean/mean                             0.27167      0.04171     0.35963      0.21368
mean/std                              1.54189      0.02354     1.60476      1.48984
mean/max                              6.19146      0.83835     6.98956      4.46446
mean/min                              -8.65122     1.99860     -4.39917     -10.32152
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 0, 4, 1, 7, 6, 8, 9, 3, 2]
replay_buffer._size: [29100 29100 29100 29100 29100 29100 29100 29100 29100 29100]
2023-08-12 12:07:35,063 MainThread INFO: EPOCH:172
2023-08-12 12:07:35,063 MainThread INFO: Time Consumed:9.399173498153687s
2023-08-12 12:07:35,063 MainThread INFO: Total Frames:289500s
  2%|▏         | 173/10000 [26:14<25:03:29,  9.18s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               792.26079
Train_Epoch_Reward                    7518.28127
Running_Training_Average_Rewards      759.69394
Explore_Time                          0.00775
Train___Time                          9.38660
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.70222
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.05624
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.33048
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.74657
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.30397
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.77962
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.26249
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8519.88950
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.26731
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.83268
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.21505      1.43803     10.84700     3.99843
alpha_0                               1.51473      0.00321     1.52077      1.50914
alpha_1                               0.12705      0.00086     0.12864      0.12570
alpha_2                               0.05154      0.00011     0.05175      0.05137
alpha_3                               0.13439      0.00076     0.13550      0.13295
alpha_4                               0.06817      0.00027     0.06863      0.06774
alpha_5                               0.20911      0.00039     0.20962      0.20847
alpha_6                               0.18376      0.00054     0.18476      0.18295
alpha_7                               0.18317      0.00183     0.18628      0.17998
alpha_8                               0.21771      0.00095     0.21929      0.21603
alpha_9                               0.09865      0.00095     0.10027      0.09698
Alpha_loss                            1.48176      0.26577     2.24645      0.82234
Training/policy_loss                  -30.05330    10.59942    -4.95912     -56.93789
Training/qf1_loss                     12529.21292  3586.36902  21613.91992  6175.58594
Training/qf2_loss                     1151.01815   434.78467   2749.88745   396.16855
Training/pf_norm                      8.87828      3.91686     19.43865     3.26924
Training/qf1_norm                     5734.83417   2544.82584  15459.82715  2054.74561
Training/qf2_norm                     2939.67410   1342.21384  7762.17188   922.17798
log_std/mean                          -0.94784     0.01219     -0.92514     -0.97310
log_std/std                           0.37536      0.00587     0.39048      0.36186
log_std/max                           0.09795      0.04062     0.22067      -0.02863
log_std/min                           -2.72361     0.07317     -2.54744     -2.82218
log_probs/mean                        4.72376      0.14857     5.10888      4.36313
log_probs/std                         3.91780      0.21042     4.64659      3.53395
log_probs/max                         39.07190     9.94408     48.91639     19.65530
log_probs/min                         -6.38180     1.52523     -3.85683     -11.54918
mean/mean                             0.29493      0.02267     0.33719      0.25029
mean/std                              1.53974      0.02649     1.60182      1.48429
mean/max                              6.33086      0.71597     7.01751      4.66190
mean/min                              -8.44798     2.00974     -3.95423     -10.23201
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 5, 4, 3, 2, 7, 6, 0, 9, 8]
replay_buffer._size: [29250 29250 29250 29250 29250 29250 29250 29250 29250 29250]
2023-08-12 12:07:43,662 MainThread INFO: EPOCH:173
2023-08-12 12:07:43,662 MainThread INFO: Time Consumed:8.414608240127563s
2023-08-12 12:07:43,662 MainThread INFO: Total Frames:291000s
  2%|▏         | 174/10000 [26:22<24:34:55,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               733.83532
Train_Epoch_Reward                    7995.27641
Running_Training_Average_Rewards      751.72173
Explore_Time                          0.02620
Train___Time                          8.38357
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.60584
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.08069
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.43879
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.43837
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.46339
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.76991
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.48932
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7933.95597
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.20152
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.11493
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.02711      1.20826     10.22137     4.72558
alpha_0                               1.51057      0.00095     1.51186      1.50852
alpha_1                               0.13059      0.00102     0.13212      0.12868
alpha_2                               0.05123      0.00007     0.05137      0.05115
alpha_3                               0.13615      0.00028     0.13646      0.13552
alpha_4                               0.06920      0.00035     0.06981      0.06864
alpha_5                               0.20934      0.00031     0.20987      0.20879
alpha_6                               0.18644      0.00106     0.18823      0.18479
alpha_7                               0.18955      0.00189     0.19275      0.18634
alpha_8                               0.21453      0.00088     0.21600      0.21279
alpha_9                               0.10175      0.00081     0.10313      0.10030
Alpha_loss                            1.54759      0.31924     2.10444      0.61512
Training/policy_loss                  -27.95247    9.65807     -4.04241     -50.68053
Training/qf1_loss                     12648.84913  3302.58946  20782.58203  5986.63623
Training/qf2_loss                     1155.56642   441.38192   2874.02026   415.45840
Training/pf_norm                      7.57897      3.36499     22.56141     3.06835
Training/qf1_norm                     6145.89403   3217.72590  19319.25977  1803.70288
Training/qf2_norm                     2971.62516   1458.70630  8266.77148   1053.85474
log_std/mean                          -0.93009     0.01000     -0.90524     -0.94901
log_std/std                           0.36137      0.00547     0.37692      0.34886
log_std/max                           0.04558      0.06067     0.19575      -0.13992
log_std/min                           -2.72141     0.07738     -2.52300     -2.84638
log_probs/mean                        4.78710      0.18711     5.16025      4.28227
log_probs/std                         3.89853      0.17297     4.38285      3.57747
log_probs/max                         37.66775     10.35828    48.49092     20.21622
log_probs/min                         -6.34104     1.44063     -3.39977     -10.48828
mean/mean                             0.23642      0.02714     0.31901      0.18811
mean/std                              1.56950      0.02744     1.63113      1.49598
mean/max                              6.23221      0.74810     7.06786      4.38822
mean/min                              -8.42248     2.06260     -4.59182     -10.25062
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 0, 4, 3, 6, 2, 5, 8, 1, 9]
replay_buffer._size: [29400 29400 29400 29400 29400 29400 29400 29400 29400 29400]
2023-08-12 12:07:52,741 MainThread INFO: EPOCH:174
2023-08-12 12:07:52,743 MainThread INFO: Time Consumed:8.966248989105225s
2023-08-12 12:07:52,743 MainThread INFO: Total Frames:292500s
  2%|▏         | 175/10000 [26:31<24:41:15,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               781.10615
Train_Epoch_Reward                    7301.20077
Running_Training_Average_Rewards      760.49195
Explore_Time                          0.01476
Train___Time                          8.94660
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.23346
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.47870
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.17463
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.14445
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.52019
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.57996
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.25565
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8409.61077
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.75650
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.40573
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.05669      1.27532     10.71260     3.91590
alpha_0                               1.51564      0.00346     1.51987      1.51013
alpha_1                               0.13370      0.00102     0.13568      0.13215
alpha_2                               0.05109      0.00004     0.05115      0.05105
alpha_3                               0.13653      0.00014     0.13691      0.13642
alpha_4                               0.07035      0.00031     0.07094      0.06982
alpha_5                               0.21021      0.00065     0.21103      0.20907
alpha_6                               0.18833      0.00017     0.18858      0.18809
alpha_7                               0.19589      0.00182     0.19911      0.19281
alpha_8                               0.21071      0.00116     0.21274      0.20885
alpha_9                               0.10461      0.00083     0.10599      0.10315
Alpha_loss                            1.44250      0.40717     2.31420      0.67920
Training/policy_loss                  -27.72384    11.21768    2.69568      -52.88740
Training/qf1_loss                     12380.27825  3129.73543  20688.61523  5715.02539
Training/qf2_loss                     1156.89344   440.37784   2653.01953   386.18488
Training/pf_norm                      7.40164      2.91930     17.77279     2.61735
Training/qf1_norm                     6178.88792   2742.14321  16110.73633  1703.14087
Training/qf2_norm                     3051.48430   1457.49872  8416.65039   768.57184
log_std/mean                          -0.94340     0.01124     -0.92154     -0.96798
log_std/std                           0.36908      0.00671     0.38521      0.35321
log_std/max                           0.02259      0.06457     0.11789      -0.16357
log_std/min                           -2.81874     0.07218     -2.63870     -2.94760
log_probs/mean                        4.74113      0.19850     5.14558      4.34539
log_probs/std                         3.91466      0.20217     4.46435      3.61503
log_probs/max                         37.33187     10.60335    49.01656     20.95049
log_probs/min                         -6.23581     1.39617     -3.01729     -10.53484
mean/mean                             0.25247      0.02068     0.30186      0.20789
mean/std                              1.55247      0.02949     1.62936      1.49355
mean/max                              6.37472      0.75496     7.16488      5.36322
mean/min                              -8.24885     2.11303     -4.69926     -10.32774
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 4, 0, 6, 3, 2, 1, 7, 5]
replay_buffer._size: [29550 29550 29550 29550 29550 29550 29550 29550 29550 29550]
2023-08-12 12:08:01,450 MainThread INFO: EPOCH:175
2023-08-12 12:08:01,451 MainThread INFO: Time Consumed:8.484234809875488s
2023-08-12 12:08:01,451 MainThread INFO: Total Frames:294000s
  2%|▏         | 176/10000 [26:40<24:21:45,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               773.64240
Train_Epoch_Reward                    7327.77406
Running_Training_Average_Rewards      754.14171
Explore_Time                          0.00485
Train___Time                          8.47414
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.02726
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.15601
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.44737
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.13408
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.45303
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.65270
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.09864
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8333.12624
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.48210
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.25105
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.21467      1.55833     11.05403     3.72239
alpha_0                               1.52131      0.00119     1.52315      1.51939
alpha_1                               0.13763      0.00109     0.13939      0.13572
alpha_2                               0.05123      0.00008     0.05138      0.05110
alpha_3                               0.13723      0.00012     0.13738      0.13692
alpha_4                               0.07156      0.00037     0.07222      0.07095
alpha_5                               0.21086      0.00015     0.21109      0.21062
alpha_6                               0.18883      0.00033     0.18942      0.18837
alpha_7                               0.20233      0.00182     0.20541      0.19918
alpha_8                               0.20674      0.00122     0.20881      0.20457
alpha_9                               0.10725      0.00067     0.10825      0.10602
Alpha_loss                            1.35545      0.30700     2.32841      0.70082
Training/policy_loss                  -27.16055    10.80429    -3.46319     -54.51352
Training/qf1_loss                     12870.52040  3091.76515  20493.49023  6450.47900
Training/qf2_loss                     1188.80720   456.29658   2757.14502   420.33154
Training/pf_norm                      7.59371      2.50895     16.00794     3.21890
Training/qf1_norm                     6278.88444   2757.09559  16846.25000  2502.52344
Training/qf2_norm                     4006.10839   2122.32979  10511.21973  827.88037
log_std/mean                          -0.94031     0.00789     -0.92411     -0.95751
log_std/std                           0.36834      0.00607     0.38575      0.35135
log_std/max                           0.09683      0.07879     0.21993      -0.15097
log_std/min                           -2.84882     0.05806     -2.70592     -2.92314
log_probs/mean                        4.67151      0.14839     5.03102      4.33802
log_probs/std                         3.91219      0.19700     4.36088      3.54185
log_probs/max                         39.34434     9.71494     48.48325     20.68352
log_probs/min                         -6.16079     1.31035     -3.53149     -10.24241
mean/mean                             0.27226      0.01682     0.31010      0.22977
mean/std                              1.54477      0.02540     1.60966      1.48642
mean/max                              6.59139      0.68198     7.38853      5.29080
mean/min                              -8.77123     1.95851     -4.53921     -10.33061
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 5, 3, 4, 7, 8, 6, 1, 9]
replay_buffer._size: [29700 29700 29700 29700 29700 29700 29700 29700 29700 29700]
2023-08-12 12:08:10,907 MainThread INFO: EPOCH:176
2023-08-12 12:08:10,907 MainThread INFO: Time Consumed:9.263741970062256s
2023-08-12 12:08:10,907 MainThread INFO: Total Frames:295500s
  2%|▏         | 177/10000 [26:50<24:48:17,  9.09s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               795.31541
Train_Epoch_Reward                    7891.68369
Running_Training_Average_Rewards      750.68862
Explore_Time                          0.01117
Train___Time                          9.24791
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.80277
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.36407
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.35058
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.31414
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.47307
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.23445
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.25599
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8549.84765
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.18678
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.71165
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94043      1.22659     10.09356     3.99674
alpha_0                               1.52414      0.00240     1.53018      1.52145
alpha_1                               0.14077      0.00081     0.14225      0.13942
alpha_2                               0.05150      0.00009     0.05172      0.05138
alpha_3                               0.13779      0.00036     0.13846      0.13722
alpha_4                               0.07281      0.00035     0.07348      0.07223
alpha_5                               0.21096      0.00014     0.21130      0.21074
alpha_6                               0.18965      0.00026     0.19045      0.18941
alpha_7                               0.20876      0.00194     0.21215      0.20547
alpha_8                               0.20251      0.00115     0.20452      0.20065
alpha_9                               0.10904      0.00047     0.10985      0.10826
Alpha_loss                            1.39149      0.37903     2.28073      0.34724
Training/policy_loss                  -27.38094    12.67959    4.36719      -56.67311
Training/qf1_loss                     12585.01404  3462.75546  25115.02344  4542.12451
Training/qf2_loss                     1118.05730   408.91972   2647.35620   494.04697
Training/pf_norm                      7.76955      2.88790     16.37120     2.87261
Training/qf1_norm                     6042.52291   2750.89703  14511.86621  2320.53564
Training/qf2_norm                     3831.69821   1799.98935  8988.24121   1091.53320
log_std/mean                          -0.94222     0.01316     -0.92057     -0.96810
log_std/std                           0.37585      0.00672     0.39646      0.35767
log_std/max                           0.15668      0.10038     0.29442      -0.12911
log_std/min                           -2.88246     0.06871     -2.71985     -3.01370
log_probs/mean                        4.71234      0.20728     5.20953      4.11248
log_probs/std                         3.88513      0.17351     4.30025      3.53004
log_probs/max                         38.72400     9.84498     48.45194     21.05461
log_probs/min                         -5.96080     1.27648     -3.45795     -11.32947
mean/mean                             0.28649      0.02336     0.32580      0.22796
mean/std                              1.54401      0.03101     1.62515      1.45895
mean/max                              6.57798      0.82606     7.39573      4.53411
mean/min                              -8.49117     2.04285     -4.33498     -10.23253
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 3, 0, 4, 1, 5, 2, 9, 7, 8]
replay_buffer._size: [29850 29850 29850 29850 29850 29850 29850 29850 29850 29850]
2023-08-12 12:08:19,951 MainThread INFO: EPOCH:177
2023-08-12 12:08:19,952 MainThread INFO: Time Consumed:8.851434469223022s
2023-08-12 12:08:19,952 MainThread INFO: Total Frames:297000s
  2%|▏         | 178/10000 [26:59<24:45:01,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               786.56387
Train_Epoch_Reward                    7815.65027
Running_Training_Average_Rewards      767.83693
Explore_Time                          0.00675
Train___Time                          8.83930
Eval____Time                          0.00468
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.11509
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.58801
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42687
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.45952
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.48389
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.74589
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.11003
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8462.21678
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.68326
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.96550
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.05466      1.43647     10.59578     4.16734
alpha_0                               1.53408      0.00284     1.54278      1.53030
alpha_1                               0.14370      0.00089     0.14518      0.14228
alpha_2                               0.05207      0.00019     0.05240      0.05173
alpha_3                               0.13888      0.00020     0.13909      0.13847
alpha_4                               0.07425      0.00038     0.07483      0.07350
alpha_5                               0.21126      0.00014     0.21147      0.21100
alpha_6                               0.19140      0.00033     0.19177      0.19049
alpha_7                               0.21530      0.00176     0.21834      0.21222
alpha_8                               0.19812      0.00145     0.20061      0.19565
alpha_9                               0.11072      0.00056     0.11166      0.10986
Alpha_loss                            1.23244      0.26271     1.77981      0.52447
Training/policy_loss                  -26.10825    11.92932    -1.29220     -64.93457
Training/qf1_loss                     13383.71455  3407.86416  24090.97852  6530.78174
Training/qf2_loss                     1100.27050   378.04833   2236.37427   392.63083
Training/pf_norm                      7.41910      3.06884     21.77254     2.66617
Training/qf1_norm                     6585.72307   2874.61351  17748.00586  2465.76318
Training/qf2_norm                     3585.01010   1670.66205  9590.90723   1172.68311
log_std/mean                          -0.94450     0.00737     -0.92295     -0.95872
log_std/std                           0.38415      0.00651     0.39829      0.36561
log_std/max                           0.16124      0.11844     0.33714      -0.14987
log_std/min                           -2.93542     0.06270     -2.76995     -3.04261
log_probs/mean                        4.62938      0.10542     4.84836      4.35683
log_probs/std                         3.84870      0.16970     4.24828      3.45370
log_probs/max                         38.80707     9.97968     49.30929     19.11018
log_probs/min                         -6.24761     1.40558     -4.06034     -10.69949
mean/mean                             0.28125      0.03295     0.35101      0.22138
mean/std                              1.53040      0.01843     1.57115      1.48734
mean/max                              6.53783      0.78482     7.38438      5.29873
mean/min                              -8.51202     2.00912     -4.94772     -10.30623
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 6, 9, 5, 8, 1, 7, 3, 2, 4]
replay_buffer._size: [30000 30000 30000 30000 30000 30000 30000 30000 30000 30000]
2023-08-12 12:08:28,382 MainThread INFO: EPOCH:178
2023-08-12 12:08:28,382 MainThread INFO: Time Consumed:8.240537405014038s
2023-08-12 12:08:28,383 MainThread INFO: Total Frames:298500s
  2%|▏         | 179/10000 [27:07<24:18:36,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               822.79818
Train_Epoch_Reward                    8045.76453
Running_Training_Average_Rewards      791.76995
Explore_Time                          0.00524
Train___Time                          8.23078
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.04237
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.86459
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.14503
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.19810
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.43823
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.87688
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -87.49814
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8819.60727
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.44045
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.12166
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.98822      1.19512     10.03111     4.36196
alpha_0                               1.54839      0.00164     1.55089      1.54324
alpha_1                               0.14664      0.00096     0.14839      0.14520
alpha_2                               0.05282      0.00030     0.05339      0.05241
alpha_3                               0.13838      0.00026     0.13889      0.13789
alpha_4                               0.07558      0.00046     0.07634      0.07484
alpha_5                               0.21234      0.00053     0.21302      0.21146
alpha_6                               0.19217      0.00028     0.19245      0.19173
alpha_7                               0.22165      0.00184     0.22477      0.21841
alpha_8                               0.19333      0.00126     0.19560      0.19120
alpha_9                               0.11232      0.00049     0.11322      0.11166
Alpha_loss                            1.40442      0.34572     2.12775      0.38696
Training/policy_loss                  -24.40143    9.10107     -6.90331     -49.13238
Training/qf1_loss                     13099.67399  3795.41350  26787.71875  6286.72900
Training/qf2_loss                     1205.32393   496.03670   3293.94507   551.44305
Training/pf_norm                      8.40351      3.40809     18.22960     2.83250
Training/qf1_norm                     5910.41813   2615.29133  14500.62207  2139.99023
Training/qf2_norm                     3529.97367   1586.98151  7671.79736   1049.90088
log_std/mean                          -0.93716     0.01118     -0.91106     -0.95535
log_std/std                           0.38821      0.00752     0.40770      0.37014
log_std/max                           0.17120      0.15527     0.35771      -0.14500
log_std/min                           -2.97584     0.06774     -2.85873     -3.13396
log_probs/mean                        4.68347      0.16374     5.03894      4.23428
log_probs/std                         3.89747      0.17997     4.38221      3.57762
log_probs/max                         38.86862     10.29825    48.95923     22.45686
log_probs/min                         -6.22225     1.25920     -3.72436     -10.28948
mean/mean                             0.27183      0.02999     0.34000      0.22155
mean/std                              1.54690      0.02303     1.60897      1.49876
mean/max                              6.53065      0.58878     7.20099      5.57755
mean/min                              -8.45722     2.10911     -4.83965     -10.34516
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 7, 1, 6, 8, 2, 3, 0, 9, 4]
replay_buffer._size: [30150 30150 30150 30150 30150 30150 30150 30150 30150 30150]
2023-08-12 12:08:37,084 MainThread INFO: EPOCH:179
2023-08-12 12:08:37,085 MainThread INFO: Time Consumed:8.482290744781494s
2023-08-12 12:08:37,085 MainThread INFO: Total Frames:300000s
  2%|▏         | 180/10000 [27:16<24:07:13,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               801.73391
Train_Epoch_Reward                    8609.94630
Running_Training_Average_Rewards      815.71204
Explore_Time                          0.00391
Train___Time                          8.47326
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.91269
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.31111
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.33331
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.15561
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.39802
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.32856
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.71981
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8613.86777
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.99002
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.37957
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.84331      1.43921     10.92063     3.72999
alpha_0                               1.55810      0.00479     1.56776      1.55098
alpha_1                               0.15021      0.00095     0.15167      0.14843
alpha_2                               0.05404      0.00036     0.05469      0.05341
alpha_3                               0.13725      0.00033     0.13788      0.13687
alpha_4                               0.07706      0.00042     0.07778      0.07635
alpha_5                               0.21337      0.00028     0.21369      0.21294
alpha_6                               0.19237      0.00007     0.19250      0.19221
alpha_7                               0.22797      0.00183     0.23109      0.22483
alpha_8                               0.18950      0.00094     0.19115      0.18780
alpha_9                               0.11410      0.00044     0.11491      0.11324
Alpha_loss                            1.34356      0.24553     2.19522      0.80127
Training/policy_loss                  -23.77464    11.80076    1.53042      -53.13453
Training/qf1_loss                     13210.20382  3520.36523  21355.41992  5991.48438
Training/qf2_loss                     1162.18753   443.47760   2682.23535   457.50122
Training/pf_norm                      8.44097      2.98897     16.46479     3.10599
Training/qf1_norm                     6398.04587   2717.33680  15265.95898  2113.47241
Training/qf2_norm                     3707.99022   1478.27139  9312.12207   1114.19080
log_std/mean                          -0.94710     0.00767     -0.92946     -0.96352
log_std/std                           0.40247      0.00879     0.42495      0.38404
log_std/max                           0.14592      0.14571     0.28547      -0.14135
log_std/min                           -3.01936     0.07373     -2.87165     -3.17621
log_probs/mean                        4.67373      0.13629     4.97687      4.36913
log_probs/std                         3.84681      0.17922     4.25508      3.44033
log_probs/max                         39.27702     9.80837     48.70290     22.57683
log_probs/min                         -6.48134     1.43963     -3.79952     -12.30548
mean/mean                             0.26287      0.02891     0.31817      0.21513
mean/std                              1.53902      0.02153     1.58740      1.48907
mean/max                              6.57563      0.54234     7.10203      5.51743
mean/min                              -8.57803     1.97399     -5.12749     -10.33601
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 8, 5, 1, 0, 6, 3, 7, 2, 9]
replay_buffer._size: [30300 30300 30300 30300 30300 30300 30300 30300 30300 30300]
2023-08-12 12:08:45,697 MainThread INFO: EPOCH:180
2023-08-12 12:08:45,697 MainThread INFO: Time Consumed:8.336637496948242s
2023-08-12 12:08:45,697 MainThread INFO: Total Frames:301500s
  2%|▏         | 181/10000 [27:24<23:54:09,  8.76s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               808.47445
Train_Epoch_Reward                    8642.94112
Running_Training_Average_Rewards      843.28840
Explore_Time                          0.00939
Train___Time                          8.32235
Eval____Time                          0.00427
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.86035
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.22645
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.44954
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.26687
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.39972
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.36263
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -87.99449
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8675.27641
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.29913
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.67272
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94121      1.28537     9.70519      3.97628
alpha_0                               1.57870      0.00555     1.58767      1.56800
alpha_1                               0.15295      0.00076     0.15426      0.15170
alpha_2                               0.05553      0.00049     0.05640      0.05471
alpha_3                               0.13641      0.00045     0.13693      0.13564
alpha_4                               0.07851      0.00043     0.07931      0.07780
alpha_5                               0.21307      0.00061     0.21387      0.21221
alpha_6                               0.19175      0.00018     0.19220      0.19161
alpha_7                               0.23418      0.00173     0.23709      0.23115
alpha_8                               0.18644      0.00068     0.18776      0.18533
alpha_9                               0.11617      0.00067     0.11721      0.11494
Alpha_loss                            1.37359      0.23855     1.97136      0.76799
Training/policy_loss                  -23.04957    13.24415    5.09671      -54.25153
Training/qf1_loss                     12920.72265  3725.21444  24810.73828  6620.67334
Training/qf2_loss                     1166.92702   408.66960   2538.92358   431.04361
Training/pf_norm                      8.22920      3.30408     18.58369     2.55698
Training/qf1_norm                     6091.70512   2593.33043  16192.91797  2376.84937
Training/qf2_norm                     3069.90154   1385.94933  9071.29199   833.06818
log_std/mean                          -0.93968     0.00734     -0.92171     -0.95648
log_std/std                           0.41513      0.00590     0.42811      0.40353
log_std/max                           0.16565      0.13321     0.36040      -0.12093
log_std/min                           -3.10999     0.03943     -2.95441     -3.17130
log_probs/mean                        4.67541      0.12279     5.01520      4.36381
log_probs/std                         3.83126      0.15681     4.18013      3.45387
log_probs/max                         37.34159     9.90442     49.19391     23.56187
log_probs/min                         -6.22435     1.15996     -4.29008     -10.15585
mean/mean                             0.25591      0.02693     0.31225      0.20125
mean/std                              1.54208      0.02022     1.59345      1.50780
mean/max                              6.45035      0.46000     7.06966      5.81187
mean/min                              -8.02641     2.05301     -4.42001     -10.25432
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 2, 4, 1, 6, 9, 8, 0, 3, 7]
replay_buffer._size: [30450 30450 30450 30450 30450 30450 30450 30450 30450 30450]
2023-08-12 12:08:55,170 MainThread INFO: EPOCH:181
2023-08-12 12:08:55,171 MainThread INFO: Time Consumed:9.283159732818604s
2023-08-12 12:08:55,171 MainThread INFO: Total Frames:303000s
  2%|▏         | 182/10000 [27:34<24:27:24,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               749.10716
Train_Epoch_Reward                    8071.27015
Running_Training_Average_Rewards      844.13859
Explore_Time                          0.00664
Train___Time                          9.27169
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.27048
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.88378
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.52637
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.93682
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.41775
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.84515
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.98538
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8092.83621
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.75375
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.14511
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.72381      1.35464     10.10616     3.48967
alpha_0                               1.60400      0.00864     1.61788      1.58790
alpha_1                               0.15557      0.00071     0.15674      0.15429
alpha_2                               0.05720      0.00044     0.05797      0.05642
alpha_3                               0.13489      0.00045     0.13563      0.13415
alpha_4                               0.08044      0.00067     0.08158      0.07933
alpha_5                               0.21467      0.00127     0.21678      0.21267
alpha_6                               0.19195      0.00026     0.19238      0.19160
alpha_7                               0.24007      0.00168     0.24294      0.23715
alpha_8                               0.18381      0.00094     0.18530      0.18210
alpha_9                               0.11788      0.00034     0.11839      0.11722
Alpha_loss                            1.39961      0.27053     2.04747      0.82165
Training/policy_loss                  -23.29060    11.31794    2.72035      -65.12312
Training/qf1_loss                     12634.30832  3799.04076  27795.22461  6887.52686
Training/qf2_loss                     1121.11623   475.77741   2734.51538   407.31421
Training/pf_norm                      9.50934      3.59341     19.35242     2.65512
Training/qf1_norm                     6440.25847   2809.84430  15311.11523  1918.08472
Training/qf2_norm                     3258.80253   1535.58567  8266.67578   1004.43768
log_std/mean                          -0.93818     0.00737     -0.91946     -0.95269
log_std/std                           0.41800      0.00721     0.43578      0.40006
log_std/max                           0.19531      0.17940     0.44261      -0.12496
log_std/min                           -3.12058     0.04277     -3.01348     -3.22802
log_probs/mean                        4.72068      0.15112     5.17376      4.37775
log_probs/std                         3.81921      0.19250     4.29323      3.46595
log_probs/max                         36.96661     10.54199    48.46185     19.43516
log_probs/min                         -6.29603     1.46865     -3.60637     -11.71722
mean/mean                             0.25943      0.01716     0.29130      0.21761
mean/std                              1.55102      0.02377     1.60290      1.49998
mean/max                              6.33681      0.52939     7.01926      5.28992
mean/min                              -8.28564     2.04554     -4.33216     -10.29749
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 3, 1, 7, 4, 0, 6, 9, 5, 8]
replay_buffer._size: [30600 30600 30600 30600 30600 30600 30600 30600 30600 30600]
2023-08-12 12:09:04,693 MainThread INFO: EPOCH:182
2023-08-12 12:09:04,693 MainThread INFO: Time Consumed:9.353331089019775s
2023-08-12 12:09:04,693 MainThread INFO: Total Frames:304500s
  2%|▏         | 183/10000 [27:43<24:54:18,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               851.59003
Train_Epoch_Reward                    7507.97749
Running_Training_Average_Rewards      807.40629
Explore_Time                          0.01089
Train___Time                          9.33724
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.09616
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.04192
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.45105
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.61821
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.31748
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.64772
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.48266
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9114.10876
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.00965
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.54356
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.14979      1.47293     10.54674     4.17383
alpha_0                               1.62956      0.00701     1.64160      1.61816
alpha_1                               0.15768      0.00045     0.15839      0.15676
alpha_2                               0.05889      0.00053     0.05985      0.05799
alpha_3                               0.13383      0.00013     0.13414      0.13368
alpha_4                               0.08257      0.00053     0.08347      0.08160
alpha_5                               0.21605      0.00029     0.21677      0.21579
alpha_6                               0.19186      0.00051     0.19238      0.19086
alpha_7                               0.24583      0.00164     0.24871      0.24300
alpha_8                               0.18054      0.00091     0.18206      0.17907
alpha_9                               0.11896      0.00033     0.11964      0.11840
Alpha_loss                            1.21007      0.28549     1.71416      0.33143
Training/policy_loss                  -23.76899    11.05608    10.64417     -49.98764
Training/qf1_loss                     13027.62241  3777.69390  22694.77148  5768.67578
Training/qf2_loss                     1271.34976   525.75566   2720.79272   377.94186
Training/pf_norm                      8.39543      2.82347     16.40236     3.77157
Training/qf1_norm                     6999.28657   2964.69480  17454.02148  2259.26367
Training/qf2_norm                     3641.98303   1699.22364  9927.23242   1166.90845
log_std/mean                          -0.94686     0.01282     -0.92113     -0.97470
log_std/std                           0.43069      0.00905     0.44872      0.40387
log_std/max                           0.26059      0.23309     0.55475      -0.18182
log_std/min                           -3.17316     0.05027     -3.06672     -3.26793
log_probs/mean                        4.59636      0.15098     4.89527      4.25903
log_probs/std                         3.80241      0.18570     4.20103      3.36290
log_probs/max                         36.72838     10.34884    48.94910     21.74380
log_probs/min                         -6.32765     1.47417     -3.50536     -11.01490
mean/mean                             0.28792      0.02274     0.32492      0.22666
mean/std                              1.51634      0.02240     1.56041      1.46263
mean/max                              6.27175      0.76598     7.19532      4.64391
mean/min                              -8.00388     2.12183     -4.22417     -10.20376
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 4, 0, 7, 8, 6, 1, 3, 5, 9]
replay_buffer._size: [30750 30750 30750 30750 30750 30750 30750 30750 30750 30750]
2023-08-12 12:09:13,833 MainThread INFO: EPOCH:183
2023-08-12 12:09:13,833 MainThread INFO: Time Consumed:8.954719543457031s
2023-08-12 12:09:13,834 MainThread INFO: Total Frames:306000s
  2%|▏         | 184/10000 [27:52<24:54:01,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               795.29155
Train_Epoch_Reward                    8292.60283
Running_Training_Average_Rewards      795.72835
Explore_Time                          0.01802
Train___Time                          8.93177
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.88982
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.90318
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.40602
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.56464
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.24400
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.59395
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.13956
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8544.88571
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.20776
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.02128
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.11710      1.28571     9.74347      2.93252
alpha_0                               1.64612      0.00315     1.65305      1.64191
alpha_1                               0.15904      0.00043     0.15999      0.15841
alpha_2                               0.06081      0.00056     0.06186      0.05987
alpha_3                               0.13433      0.00035     0.13481      0.13390
alpha_4                               0.08460      0.00068     0.08578      0.08349
alpha_5                               0.21430      0.00065     0.21578      0.21346
alpha_6                               0.18983      0.00048     0.19085      0.18942
alpha_7                               0.25184      0.00178     0.25490      0.24878
alpha_8                               0.17790      0.00060     0.17905      0.17690
alpha_9                               0.12093      0.00084     0.12254      0.11966
Alpha_loss                            1.43760      0.31397     2.26503      0.61722
Training/policy_loss                  -24.08714    11.11428    4.48802      -57.58017
Training/qf1_loss                     13278.79621  4255.93433  26408.00586  5324.54932
Training/qf2_loss                     1240.58071   504.23561   2519.76294   541.48047
Training/pf_norm                      10.19791     5.11414     29.01441     3.42424
Training/qf1_norm                     7314.53632   3502.61390  16862.39844  2068.09058
Training/qf2_norm                     4024.06601   1765.88676  8521.45996   1006.37183
log_std/mean                          -0.95536     0.00668     -0.93540     -0.97398
log_std/std                           0.44285      0.00743     0.46670      0.42379
log_std/max                           0.38469      0.22117     0.67002      -0.05434
log_std/min                           -3.30254     0.05679     -3.18625     -3.39597
log_probs/mean                        4.68172      0.17725     5.11723      4.27184
log_probs/std                         3.83936      0.18184     4.29482      3.42983
log_probs/max                         38.50516     9.64415     48.89221     20.87648
log_probs/min                         -6.36155     1.22745     -3.60669     -9.67658
mean/mean                             0.34033      0.03125     0.39360      0.27301
mean/std                              1.51247      0.03033     1.57765      1.44089
mean/max                              6.47856      0.83792     7.42330      5.34047
mean/min                              -8.28654     1.91369     -4.33816     -10.20893
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 4, 9, 1, 6, 0, 8, 7, 5, 3]
replay_buffer._size: [30900 30900 30900 30900 30900 30900 30900 30900 30900 30900]
2023-08-12 12:09:22,812 MainThread INFO: EPOCH:184
2023-08-12 12:09:22,813 MainThread INFO: Time Consumed:8.803746223449707s
2023-08-12 12:09:22,813 MainThread INFO: Total Frames:307500s
  2%|▏         | 185/10000 [28:01<24:45:52,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               789.22352
Train_Epoch_Reward                    7914.02172
Running_Training_Average_Rewards      790.48673
Explore_Time                          0.00861
Train___Time                          8.79006
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.79908
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.93261
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.16233
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.47425
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.40200
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.69494
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.36949
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8484.45802
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.02188
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.36623
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.25746      1.49480     10.88109     3.45731
alpha_0                               1.66936      0.00839     1.67698      1.65323
alpha_1                               0.16166      0.00105     0.16364      0.16002
alpha_2                               0.06330      0.00080     0.06458      0.06189
alpha_3                               0.13472      0.00025     0.13500      0.13419
alpha_4                               0.08697      0.00068     0.08817      0.08580
alpha_5                               0.21267      0.00037     0.21344      0.21218
alpha_6                               0.19015      0.00025     0.19044      0.18953
alpha_7                               0.25782      0.00169     0.26080      0.25496
alpha_8                               0.17609      0.00044     0.17689      0.17538
alpha_9                               0.12451      0.00118     0.12672      0.12258
Alpha_loss                            1.76433      0.24504     2.42416      1.24211
Training/policy_loss                  -23.05155    12.85669    5.56380      -53.77179
Training/qf1_loss                     13994.11116  3885.59924  25878.58789  6417.45068
Training/qf2_loss                     1212.33827   414.27579   2469.25562   549.54077
Training/pf_norm                      8.53105      3.42045     18.32332     3.70054
Training/qf1_norm                     7167.46288   3178.23230  23925.43555  1925.56445
Training/qf2_norm                     3349.81457   1686.50388  8843.48828   984.17206
log_std/mean                          -0.95893     0.01192     -0.93694     -0.98765
log_std/std                           0.45177      0.00846     0.48028      0.43462
log_std/max                           0.36146      0.20268     0.60011      -0.01780
log_std/min                           -3.42109     0.05201     -3.21795     -3.51237
log_probs/mean                        4.85902      0.13858     5.21113      4.53893
log_probs/std                         3.91920      0.20245     4.50331      3.50646
log_probs/max                         38.96772     9.54931     48.86063     22.38766
log_probs/min                         -6.05196     1.49674     -3.58016     -14.14241
mean/mean                             0.31597      0.03167     0.39261      0.26721
mean/std                              1.54546      0.02192     1.61757      1.48689
mean/max                              6.42002      0.72495     7.14585      5.28973
mean/min                              -8.40615     1.97112     -4.16865     -10.20128
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 0, 4, 6, 7, 2, 3, 5, 9, 8]
replay_buffer._size: [31050 31050 31050 31050 31050 31050 31050 31050 31050 31050]
2023-08-12 12:09:32,114 MainThread INFO: EPOCH:185
2023-08-12 12:09:32,114 MainThread INFO: Time Consumed:9.119999647140503s
2023-08-12 12:09:32,114 MainThread INFO: Total Frames:309000s
  2%|▏         | 186/10000 [28:11<24:56:41,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               765.79924
Train_Epoch_Reward                    7837.61606
Running_Training_Average_Rewards      801.47469
Explore_Time                          0.00415
Train___Time                          9.11147
Eval____Time                          0.00381
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.37642
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.14272
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42490
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.05073
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.22116
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.42276
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.33648
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8254.08501
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.93139
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.18610
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.99456      1.38012     10.56717     3.88047
alpha_0                               1.67498      0.00214     1.67875      1.67278
alpha_1                               0.16551      0.00110     0.16731      0.16368
alpha_2                               0.06563      0.00062     0.06671      0.06460
alpha_3                               0.13323      0.00051     0.13416      0.13229
alpha_4                               0.08954      0.00081     0.09090      0.08820
alpha_5                               0.21103      0.00048     0.21215      0.21059
alpha_6                               0.18949      0.00017     0.18994      0.18930
alpha_7                               0.26395      0.00176     0.26697      0.26086
alpha_8                               0.17452      0.00050     0.17537      0.17356
alpha_9                               0.12930      0.00150     0.13168      0.12676
Alpha_loss                            1.61154      0.30897     2.34569      0.91757
Training/policy_loss                  -20.44446    13.25201    10.02632     -52.95056
Training/qf1_loss                     13450.85607  4061.32096  27660.42188  6523.65186
Training/qf2_loss                     1198.52185   408.71879   2313.83569   474.09424
Training/pf_norm                      11.55807     4.69117     25.96540     3.36046
Training/qf1_norm                     6865.71799   3252.72338  20957.29883  2095.57812
Training/qf2_norm                     3718.83266   1688.54182  8978.42871   1122.03137
log_std/mean                          -0.94081     0.00862     -0.91832     -0.95925
log_std/std                           0.46111      0.00793     0.48218      0.44596
log_std/max                           0.31063      0.16038     0.47023      -0.02231
log_std/min                           -3.51939     0.02538     -3.43943     -3.56545
log_probs/mean                        4.76540      0.17036     5.21315      4.40072
log_probs/std                         3.90396      0.17064     4.49540      3.56624
log_probs/max                         38.34228     9.56221     48.96222     22.21862
log_probs/min                         -6.15007     1.39468     -3.40309     -10.78745
mean/mean                             0.33039      0.03370     0.38042      0.25428
mean/std                              1.53813      0.02344     1.60980      1.48241
mean/max                              6.46086      0.64559     7.12600      5.56822
mean/min                              -8.38317     2.11365     -4.40854     -10.34886
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 7, 1, 6, 8, 4, 5, 9, 0, 3]
replay_buffer._size: [31200 31200 31200 31200 31200 31200 31200 31200 31200 31200]
2023-08-12 12:09:40,924 MainThread INFO: EPOCH:186
2023-08-12 12:09:40,924 MainThread INFO: Time Consumed:8.622838973999023s
2023-08-12 12:09:40,924 MainThread INFO: Total Frames:310500s
  2%|▏         | 187/10000 [28:20<24:39:36,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               734.72666
Train_Epoch_Reward                    7941.39965
Running_Training_Average_Rewards      789.76791
Explore_Time                          0.00387
Train___Time                          8.61387
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.84334
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.31377
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.45141
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.05333
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.25831
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.11318
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.12437
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7946.77811
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.22752
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.12630
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.07828      1.52468     11.95947     3.74837
alpha_0                               1.67978      0.00442     1.68456      1.67296
alpha_1                               0.16901      0.00103     0.17094      0.16734
alpha_2                               0.06782      0.00063     0.06885      0.06674
alpha_3                               0.13114      0.00067     0.13227      0.12995
alpha_4                               0.09222      0.00079     0.09368      0.09093
alpha_5                               0.21225      0.00093     0.21391      0.21072
alpha_6                               0.18908      0.00016     0.18947      0.18886
alpha_7                               0.27000      0.00171     0.27289      0.26703
alpha_8                               0.17255      0.00048     0.17353      0.17177
alpha_9                               0.13387      0.00128     0.13618      0.13172
Alpha_loss                            1.57345      0.24345     2.08001      0.91088
Training/policy_loss                  -21.66810    11.80544    15.77117     -48.84330
Training/qf1_loss                     14174.08730  3602.99493  26432.58789  8137.61035
Training/qf2_loss                     1329.77310   482.13496   2760.47437   546.31653
Training/pf_norm                      10.95834     4.46031     23.14458     3.44560
Training/qf1_norm                     7071.40659   3010.27323  18584.70117  2574.79785
Training/qf2_norm                     3670.74782   1691.77566  9348.03906   1208.72803
log_std/mean                          -0.95883     0.00876     -0.94084     -0.98070
log_std/std                           0.45933      0.00627     0.47480      0.44452
log_std/max                           0.30255      0.21643     0.57627      -0.06451
log_std/min                           -3.58246     0.10629     -2.91006     -3.65817
log_probs/mean                        4.78434      0.14998     5.17696      4.42760
log_probs/std                         3.83280      0.17797     4.40627      3.47648
log_probs/max                         38.14182     9.89959     48.43745     20.52542
log_probs/min                         -6.14679     1.26309     -3.79026     -10.26767
mean/mean                             0.29802      0.03764     0.38452      0.23464
mean/std                              1.53781      0.02334     1.60814      1.48428
mean/max                              6.32067      0.49071     6.85985      4.90697
mean/min                              -8.51485     2.03190     -4.50495     -10.35472
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 0, 3, 5, 2, 6, 4, 7, 8]
replay_buffer._size: [31350 31350 31350 31350 31350 31350 31350 31350 31350 31350]
2023-08-12 12:09:50,589 MainThread INFO: EPOCH:187
2023-08-12 12:09:50,590 MainThread INFO: Time Consumed:9.484770774841309s
2023-08-12 12:09:50,590 MainThread INFO: Total Frames:312000s
  2%|▏         | 188/10000 [28:29<25:11:23,  9.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               822.62098
Train_Epoch_Reward                    7369.94155
Running_Training_Average_Rewards      771.63191
Explore_Time                          0.00401
Train___Time                          9.47617
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.75811
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.11206
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42317
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.54289
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.12226
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.32379
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.78414
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8823.42530
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.13519
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.01394
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.81326      1.44691     11.17461     3.89598
alpha_0                               1.68154      0.00291     1.68434      1.67333
alpha_1                               0.17326      0.00124     0.17506      0.17098
alpha_2                               0.06977      0.00057     0.07077      0.06887
alpha_3                               0.12854      0.00095     0.12993      0.12674
alpha_4                               0.09541      0.00093     0.09691      0.09372
alpha_5                               0.21630      0.00129     0.21813      0.21396
alpha_6                               0.18829      0.00036     0.18885      0.18731
alpha_7                               0.27573      0.00167     0.27862      0.27294
alpha_8                               0.17114      0.00045     0.17176      0.17013
alpha_9                               0.13860      0.00124     0.14049      0.13624
Alpha_loss                            1.46024      0.34077     2.22412      0.79643
Training/policy_loss                  -19.38954    13.04478    16.35169     -55.84475
Training/qf1_loss                     13491.05204  3495.39719  22171.77930  7251.66797
Training/qf2_loss                     1231.29343   579.78862   2981.41626   468.61090
Training/pf_norm                      12.07799     5.52056     28.68021     3.60377
Training/qf1_norm                     7122.19673   3100.15012  15092.50000  2089.42847
Training/qf2_norm                     3639.40180   1792.67279  11510.51270  1361.95203
log_std/mean                          -0.95151     0.01285     -0.92663     -0.97768
log_std/std                           0.45679      0.00761     0.47732      0.43797
log_std/max                           0.35950      0.26528     0.65560      -0.04178
log_std/min                           -3.58553     0.12330     -2.84978     -3.69876
log_probs/mean                        4.69929      0.19912     5.14536      4.30195
log_probs/std                         3.86132      0.18394     4.28558      3.47115
log_probs/max                         36.79850     9.39580     48.09792     22.22061
log_probs/min                         -6.31629     1.20155     -3.76603     -10.00803
mean/mean                             0.30638      0.05317     0.41230      0.22155
mean/std                              1.52895      0.02679     1.58863      1.46955
mean/max                              6.22260      0.33466     6.88464      4.41886
mean/min                              -8.36263     1.97571     -4.72900     -10.45091
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 9, 4, 0, 1, 5, 8, 3, 7, 2]
replay_buffer._size: [31500 31500 31500 31500 31500 31500 31500 31500 31500 31500]
2023-08-12 12:09:59,236 MainThread INFO: EPOCH:188
2023-08-12 12:09:59,237 MainThread INFO: Time Consumed:8.472750186920166s
2023-08-12 12:09:59,237 MainThread INFO: Total Frames:313500s
  2%|▏         | 189/10000 [28:38<24:43:28,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               818.97655
Train_Epoch_Reward                    8075.75122
Running_Training_Average_Rewards      779.56975
Explore_Time                          0.01016
Train___Time                          8.45765
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.29427
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.87595
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.45072
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.85704
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.06035
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.39704
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.03889
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8790.04662
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.07779
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.22907
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89393      1.26329     10.95938     3.58266
alpha_0                               1.66317      0.00584     1.67303      1.65072
alpha_1                               0.17647      0.00083     0.17826      0.17509
alpha_2                               0.07157      0.00044     0.07241      0.07079
alpha_3                               0.12555      0.00061     0.12671      0.12467
alpha_4                               0.09870      0.00109     0.10074      0.09694
alpha_5                               0.22057      0.00133     0.22268      0.21816
alpha_6                               0.18412      0.00185     0.18726      0.18133
alpha_7                               0.28159      0.00178     0.28475      0.27867
alpha_8                               0.16878      0.00069     0.17010      0.16778
alpha_9                               0.14233      0.00107     0.14436      0.14053
Alpha_loss                            1.35775      0.40686     2.22304      0.46825
Training/policy_loss                  -19.59307    11.62563    1.56081      -53.46179
Training/qf1_loss                     12731.98081  3755.69012  21620.16602  5502.92773
Training/qf2_loss                     1314.68831   529.50007   2799.32959   380.47238
Training/pf_norm                      9.47470      4.89367     30.84837     2.75280
Training/qf1_norm                     6466.46737   2612.42129  13493.51465  2433.78296
Training/qf2_norm                     3926.03019   1892.46492  10476.91699  1196.94580
log_std/mean                          -0.94252     0.01257     -0.90387     -0.96789
log_std/std                           0.46441      0.00660     0.48022      0.44859
log_std/max                           0.38037      0.25213     0.71711      -0.06967
log_std/min                           -3.67669     0.09678     -2.82113     -3.71617
log_probs/mean                        4.63231      0.20026     5.06584      4.20625
log_probs/std                         3.93726      0.19835     4.44742      3.56977
log_probs/max                         36.61397     9.82853     48.59732     20.71217
log_probs/min                         -6.37297     1.19846     -3.60406     -10.45471
mean/mean                             0.34108      0.04725     0.42616      0.26970
mean/std                              1.51963      0.02558     1.56685      1.46299
mean/max                              6.34935      0.19335     6.64513      5.59455
mean/min                              -8.27676     2.11104     -4.32712     -10.46808
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 5, 0, 2, 4, 3, 9, 7, 6]
replay_buffer._size: [31650 31650 31650 31650 31650 31650 31650 31650 31650 31650]
2023-08-12 12:10:08,834 MainThread INFO: EPOCH:189
2023-08-12 12:10:08,835 MainThread INFO: Time Consumed:9.409539937973022s
2023-08-12 12:10:08,835 MainThread INFO: Total Frames:315000s
  2%|▏         | 190/10000 [28:47<25:06:01,  9.21s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               808.39116
Train_Epoch_Reward                    8242.16715
Running_Training_Average_Rewards      789.59533
Explore_Time                          0.00679
Train___Time                          9.39740
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.47084
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.63522
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.43221
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.04700
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.01078
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.68661
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.23762
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8674.58435
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.67189
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.48062
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.11849      1.22429     10.05516     4.23601
alpha_0                               1.63561      0.00714     1.65030      1.62319
alpha_1                               0.18098      0.00165     0.18380      0.17831
alpha_2                               0.07339      0.00060     0.07443      0.07243
alpha_3                               0.12333      0.00090     0.12466      0.12177
alpha_4                               0.10312      0.00133     0.10535      0.10079
alpha_5                               0.22411      0.00117     0.22634      0.22269
alpha_6                               0.17960      0.00076     0.18129      0.17858
alpha_7                               0.28806      0.00202     0.29169      0.28480
alpha_8                               0.16781      0.00018     0.16811      0.16756
alpha_9                               0.14673      0.00128     0.14886      0.14441
Alpha_loss                            1.73795      0.22364     2.26207      1.26599
Training/policy_loss                  -20.48622    10.75878    4.68914      -48.00191
Training/qf1_loss                     13954.35737  4297.97876  28918.95312  6560.78613
Training/qf2_loss                     1292.13553   482.53368   2844.55737   569.81683
Training/pf_norm                      10.38191     4.28439     30.73975     4.15179
Training/qf1_norm                     7005.07800   3456.06283  23150.49023  2583.76489
Training/qf2_norm                     3668.03874   1872.43566  9740.77734   894.83673
log_std/mean                          -0.92800     0.01169     -0.90358     -0.95179
log_std/std                           0.45863      0.00746     0.47318      0.43489
log_std/max                           0.45946      0.23494     0.71570      0.04435
log_std/min                           -3.68327     0.08454     -3.24319     -3.74420
log_probs/mean                        4.84697      0.13150     5.15049      4.54008
log_probs/std                         4.03020      0.18799     4.75983      3.68834
log_probs/max                         37.09380     9.27614     47.64789     21.89270
log_probs/min                         -6.28339     1.39252     -3.34567     -10.05746
mean/mean                             0.37304      0.04128     0.43943      0.29542
mean/std                              1.55724      0.02363     1.61087      1.48934
mean/max                              6.49221      0.11902     6.62186      5.88015
mean/min                              -8.55846     1.94735     -4.70951     -10.24999
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 3, 2, 6, 4, 1, 0, 8, 7, 9]
replay_buffer._size: [31800 31800 31800 31800 31806 31806 31800 31800 31800 31800]
2023-08-12 12:10:18,056 MainThread INFO: EPOCH:190
2023-08-12 12:10:18,399 MainThread INFO: Time Consumed:9.023377180099487s
2023-08-12 12:10:18,399 MainThread INFO: Total Frames:316500s
  2%|▏         | 191/10000 [28:57<25:24:26,  9.32s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               790.29071
Train_Epoch_Reward                    7946.81856
Running_Training_Average_Rewards      808.82456
Explore_Time                          0.03684
Train___Time                          8.98124
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.35284
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.96504
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.39414
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.84276
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.14138
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.15556
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.26559
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8512.22531
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.93946
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.26139
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.78274      1.35018     10.10916     3.18086
alpha_0                               1.60771      0.00787     1.62285      1.59579
alpha_1                               0.18619      0.00124     0.18838      0.18386
alpha_2                               0.07520      0.00040     0.07587      0.07445
alpha_3                               0.12036      0.00084     0.12175      0.11904
alpha_4                               0.10738      0.00115     0.10936      0.10539
alpha_5                               0.22795      0.00079     0.22955      0.22640
alpha_6                               0.17663      0.00139     0.17856      0.17425
alpha_7                               0.29533      0.00200     0.29864      0.29176
alpha_8                               0.16712      0.00057     0.16789      0.16613
alpha_9                               0.15067      0.00100     0.15239      0.14890
Alpha_loss                            1.25190      0.27192     1.94291      0.56695
Training/policy_loss                  -20.89361    11.26797    0.63232      -51.29316
Training/qf1_loss                     13947.13698  4117.19256  25865.13477  4981.26904
Training/qf2_loss                     1251.08091   392.11974   2461.19507   502.42041
Training/pf_norm                      11.50554     5.23985     31.31172     4.18385
Training/qf1_norm                     7425.78194   3253.83954  18216.32617  2817.40527
Training/qf2_norm                     3763.54929   1736.57719  9691.73633   1114.39453
log_std/mean                          -0.92378     0.01248     -0.90475     -0.95479
log_std/std                           0.45671      0.00694     0.47284      0.44054
log_std/max                           0.36781      0.23502     0.66041      0.03370
log_std/min                           -3.67144     0.10362     -2.86625     -3.73928
log_probs/mean                        4.61856      0.14945     4.97691      4.19561
log_probs/std                         3.97454      0.16725     4.34931      3.58303
log_probs/max                         34.86015     9.23594     46.73331     20.82010
log_probs/min                         -6.24073     1.41417     -3.47032     -10.99067
mean/mean                             0.35943      0.02441     0.40211      0.30274
mean/std                              1.52732      0.02486     1.57602      1.45851
mean/max                              6.53770      0.17912     6.83191      5.43597
mean/min                              -8.17859     1.97802     -4.43825     -10.26889
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 2, 7, 6, 9, 0, 3, 4, 5, 1]
replay_buffer._size: [31950 31950 31950 31950 31950 31950 31950 31950 31950 31950]
2023-08-12 12:10:27,543 MainThread INFO: EPOCH:191
2023-08-12 12:10:27,543 MainThread INFO: Time Consumed:9.0209219455719s
2023-08-12 12:10:27,543 MainThread INFO: Total Frames:318000s
  2%|▏         | 192/10000 [29:06<25:15:25,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               793.87565
Train_Epoch_Reward                    7133.02145
Running_Training_Average_Rewards      777.40024
Explore_Time                          0.00416
Train___Time                          9.01198
Eval____Time                          0.00412
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.42185
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.43917
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.28838
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.46062
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.29002
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.25756
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.26546
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8541.20210
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.29996
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.72261
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.77088      1.29411     10.77110     4.09049
alpha_0                               1.58534      0.00707     1.59580      1.57380
alpha_1                               0.19090      0.00154     0.19369      0.18843
alpha_2                               0.07648      0.00033     0.07703      0.07589
alpha_3                               0.11780      0.00061     0.11901      0.11681
alpha_4                               0.11127      0.00112     0.11322      0.10940
alpha_5                               0.23165      0.00119     0.23396      0.22961
alpha_6                               0.17093      0.00208     0.17421      0.16767
alpha_7                               0.30185      0.00179     0.30494      0.29871
alpha_8                               0.16526      0.00060     0.16612      0.16437
alpha_9                               0.15398      0.00098     0.15566      0.15242
Alpha_loss                            1.05953      0.27265     1.73629      0.42239
Training/policy_loss                  -18.67498    11.07958    11.09288     -45.57495
Training/qf1_loss                     13141.81106  3851.37989  28155.90039  5344.91357
Training/qf2_loss                     1261.99417   430.92941   2378.24976   581.32056
Training/pf_norm                      12.85559     6.08571     31.28867     3.71970
Training/qf1_norm                     6768.75970   3376.92395  16310.85547  2036.65259
Training/qf2_norm                     3260.51955   1557.84301  8507.83301   1085.84399
log_std/mean                          -0.93288     0.01476     -0.90035     -0.96406
log_std/std                           0.45922      0.00864     0.48284      0.43919
log_std/max                           0.32588      0.25695     0.66224      -0.05739
log_std/min                           -3.66863     0.15381     -3.01583     -3.77527
log_probs/mean                        4.53451      0.16657     4.90838      4.08343
log_probs/std                         3.96812      0.18751     4.65438      3.62037
log_probs/max                         34.33124     9.30053     47.12731     22.91295
log_probs/min                         -6.34999     1.41438     -3.93607     -13.45067
mean/mean                             0.32117      0.02040     0.36785      0.26820
mean/std                              1.52178      0.02306     1.57985      1.44302
mean/max                              6.66581      0.26298     6.92770      5.29518
mean/min                              -8.23671     1.89257     -5.01020     -10.40101
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 9, 5, 1, 2, 8, 6, 4, 3, 7]
replay_buffer._size: [32100 32100 32100 32100 32100 32100 32100 32100 32100 32100]
2023-08-12 12:10:36,896 MainThread INFO: EPOCH:192
2023-08-12 12:10:36,897 MainThread INFO: Time Consumed:9.165750980377197s
2023-08-12 12:10:36,897 MainThread INFO: Total Frames:319500s
  2%|▏         | 193/10000 [29:16<25:19:58,  9.30s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               869.06788
Train_Epoch_Reward                    7737.63649
Running_Training_Average_Rewards      760.58255
Explore_Time                          0.00608
Train___Time                          9.15326
Eval____Time                          0.00510
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.34364
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.70747
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42546
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.85853
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.16869
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.36975
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.04337
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9295.40098
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.37351
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.43178
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.03698      1.34318     10.78069     4.62298
alpha_0                               1.56882      0.00244     1.57359      1.56608
alpha_1                               0.19633      0.00134     0.19850      0.19375
alpha_2                               0.07769      0.00039     0.07848      0.07704
alpha_3                               0.11596      0.00036     0.11679      0.11561
alpha_4                               0.11495      0.00090     0.11635      0.11326
alpha_5                               0.23565      0.00084     0.23678      0.23401
alpha_6                               0.16553      0.00117     0.16762      0.16371
alpha_7                               0.30807      0.00188     0.31132      0.30500
alpha_8                               0.16393      0.00038     0.16436      0.16299
alpha_9                               0.15720      0.00076     0.15836      0.15569
Alpha_loss                            1.02290      0.22734     1.68857      0.55809
Training/policy_loss                  -21.15593    13.66631    12.07104     -54.16063
Training/qf1_loss                     13552.94758  4044.51014  24546.88086  6206.21143
Training/qf2_loss                     1338.56190   463.25378   3349.93823   467.92725
Training/pf_norm                      12.50265     5.94326     44.36036     3.80724
Training/qf1_norm                     7180.13000   3231.10676  19378.42188  2572.06348
Training/qf2_norm                     4430.91476   2082.03511  11583.84277  1452.92883
log_std/mean                          -0.93373     0.01240     -0.90955     -0.96792
log_std/std                           0.46010      0.00682     0.47423      0.44141
log_std/max                           0.43735      0.27619     0.75949      -0.04932
log_std/min                           -3.67002     0.17083     -2.72164     -3.78744
log_probs/mean                        4.55121      0.14159     4.92011      4.19692
log_probs/std                         3.91386      0.18539     4.51273      3.51044
log_probs/max                         35.30020     9.18601     47.06005     20.81030
log_probs/min                         -6.41030     1.45838     -3.60640     -11.11108
mean/mean                             0.29702      0.03416     0.36148      0.22483
mean/std                              1.52468      0.02277     1.58629      1.46672
mean/max                              6.56842      0.20597     6.80047      5.43724
mean/min                              -8.22330     1.96667     -4.67099     -10.19854
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 3, 7, 4, 6, 5, 0, 9, 1, 8]
replay_buffer._size: [32250 32250 32250 32250 32250 32250 32250 32250 32250 32250]
2023-08-12 12:10:45,398 MainThread INFO: EPOCH:193
2023-08-12 12:10:45,398 MainThread INFO: Time Consumed:8.320755243301392s
2023-08-12 12:10:45,398 MainThread INFO: Total Frames:321000s
  2%|▏         | 194/10000 [29:24<24:39:57,  9.06s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               839.59740
Train_Epoch_Reward                    9482.78027
Running_Training_Average_Rewards      811.78127
Explore_Time                          0.00498
Train___Time                          8.31093
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.45249
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.06349
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.38258
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.07426
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.94590
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.05901
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.50226
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9001.53439
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.90307
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.17732
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.90770      1.43918     10.72507     3.74546
alpha_0                               1.56592      0.00104     1.56780      1.56426
alpha_1                               0.20112      0.00164     0.20416      0.19855
alpha_2                               0.08000      0.00095     0.08183      0.07851
alpha_3                               0.11603      0.00011     0.11615      0.11578
alpha_4                               0.11777      0.00085     0.11917      0.11638
alpha_5                               0.23848      0.00150     0.24152      0.23680
alpha_6                               0.16220      0.00075     0.16368      0.16144
alpha_7                               0.31470      0.00199     0.31821      0.31139
alpha_8                               0.16219      0.00033     0.16297      0.16190
alpha_9                               0.15988      0.00097     0.16154      0.15839
Alpha_loss                            1.51561      0.31627     2.22579      0.61478
Training/policy_loss                  -18.23290    13.92126    13.18828     -47.26336
Training/qf1_loss                     13230.95499  4561.46783  32183.68164  6852.12500
Training/qf2_loss                     1226.83030   422.48907   2560.83447   505.78525
Training/pf_norm                      12.38319     5.73148     27.88693     3.86089
Training/qf1_norm                     7072.31410   3753.05539  19753.02344  2277.22144
Training/qf2_norm                     3854.81392   1834.32446  10620.23535  1193.38525
log_std/mean                          -0.93616     0.01446     -0.90747     -0.96431
log_std/std                           0.45604      0.00946     0.48045      0.43398
log_std/max                           0.48601      0.30347     0.79686      -0.02615
log_std/min                           -3.64420     0.06630     -3.26158     -3.70091
log_probs/mean                        4.79029      0.18974     5.21264      4.32218
log_probs/std                         4.02489      0.15565     4.39459      3.71114
log_probs/max                         35.64371     9.01715     46.84769     22.92593
log_probs/min                         -6.08926     1.34786     -4.03267     -11.36852
mean/mean                             0.29197      0.03200     0.35143      0.22973
mean/std                              1.56607      0.02730     1.63109      1.49963
mean/max                              6.41008      0.15421     6.58755      5.36327
mean/min                              -8.31104     1.83442     -5.16631     -10.08186
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 2, 5, 8, 7, 0, 4, 6, 1]
replay_buffer._size: [32400 32400 32400 32400 32400 32400 32400 32400 32400 32400]
2023-08-12 12:10:55,013 MainThread INFO: EPOCH:194
2023-08-12 12:10:55,013 MainThread INFO: Time Consumed:9.416346788406372s
2023-08-12 12:10:55,013 MainThread INFO: Total Frames:322500s
  2%|▏         | 195/10000 [29:34<25:06:13,  9.22s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               822.75721
Train_Epoch_Reward                    8661.30118
Running_Training_Average_Rewards      862.72393
Explore_Time                          0.00421
Train___Time                          9.40635
Eval____Time                          0.00468
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.48215
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.92062
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.22965
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.93145
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.06737
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.19174
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.93313
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8843.05090
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.13414
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.58861
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80864      1.13583     9.68044      4.35438
alpha_0                               1.57686      0.00767     1.59066      1.56645
alpha_1                               0.20768      0.00204     0.21125      0.20423
alpha_2                               0.08428      0.00142     0.08668      0.08188
alpha_3                               0.11601      0.00009     0.11612      0.11586
alpha_4                               0.12048      0.00078     0.12188      0.11920
alpha_5                               0.24678      0.00358     0.25301      0.24160
alpha_6                               0.16254      0.00062     0.16353      0.16159
alpha_7                               0.32162      0.00188     0.32481      0.31829
alpha_8                               0.16142      0.00035     0.16198      0.16067
alpha_9                               0.16302      0.00081     0.16426      0.16157
Alpha_loss                            1.89066      0.25542     2.59414      1.18434
Training/policy_loss                  -17.69157    12.45149    9.91056      -51.52439
Training/qf1_loss                     14135.92525  4281.38666  26553.81250  6418.14209
Training/qf2_loss                     1210.13402   397.02572   2239.10132   505.18546
Training/pf_norm                      12.20276     5.55211     26.62918     3.42805
Training/qf1_norm                     7169.34988   2823.70887  20162.37305  2976.46265
Training/qf2_norm                     3320.46950   1740.95895  10494.77832  1042.66479
log_std/mean                          -0.96546     0.01287     -0.93328     -0.98935
log_std/std                           0.44443      0.00621     0.45926      0.42317
log_std/max                           0.50482      0.32680     0.81730      -0.07656
log_std/min                           -3.60707     0.06759     -3.23874     -3.67459
log_probs/mean                        5.02314      0.14362     5.38269      4.65877
log_probs/std                         4.06625      0.16336     4.46848      3.62138
log_probs/max                         36.10542     9.19097     46.66900     21.08190
log_probs/min                         -6.06266     1.30666     -3.55465     -10.05614
mean/mean                             0.24744      0.01857     0.28300      0.20271
mean/std                              1.59836      0.02290     1.66588      1.54316
mean/max                              6.31640      0.12904     6.50178      5.63529
mean/min                              -8.54450     1.82219     -4.97314     -10.20092
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 1, 0, 7, 2, 6, 4, 3, 8, 5]
replay_buffer._size: [32550 32550 32550 32550 32550 32550 32550 32550 32550 32550]
2023-08-12 12:11:04,353 MainThread INFO: EPOCH:195
2023-08-12 12:11:04,354 MainThread INFO: Time Consumed:9.16080641746521s
2023-08-12 12:11:04,354 MainThread INFO: Total Frames:324000s
  2%|▏         | 196/10000 [29:43<25:12:09,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               804.34304
Train_Epoch_Reward                    8633.69442
Running_Training_Average_Rewards      892.59253
Explore_Time                          0.01281
Train___Time                          9.14301
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.45602
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.81845
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.23753
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.46248
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.04986
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.82332
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.08219
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8648.41560
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.86185
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.19352
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94180      1.28553     11.23408     4.07564
alpha_0                               1.61057      0.01198     1.63097      1.59098
alpha_1                               0.21484      0.00209     0.21858      0.21132
alpha_2                               0.08877      0.00123     0.09096      0.08673
alpha_3                               0.11636      0.00016     0.11655      0.11607
alpha_4                               0.12317      0.00070     0.12434      0.12191
alpha_5                               0.25793      0.00328     0.26452      0.25309
alpha_6                               0.16282      0.00032     0.16353      0.16253
alpha_7                               0.32819      0.00196     0.33158      0.32487
alpha_8                               0.15921      0.00089     0.16064      0.15764
alpha_9                               0.16462      0.00011     0.16471      0.16428
Alpha_loss                            1.56686      0.24281     2.08738      1.11103
Training/policy_loss                  -19.16262    12.85425    8.71603      -62.10823
Training/qf1_loss                     14751.97965  4621.80030  29300.19727  6330.61475
Training/qf2_loss                     1292.16156   482.33923   3349.27124   611.40570
Training/pf_norm                      14.19945     7.08077     31.36639     4.42310
Training/qf1_norm                     7811.18355   3582.77666  24021.16992  1688.75732
Training/qf2_norm                     4032.56058   2096.24245  12179.55371  967.62299
log_std/mean                          -0.97133     0.00836     -0.95202     -0.99488
log_std/std                           0.43281      0.00921     0.45858      0.41583
log_std/max                           0.62877      0.36024     0.92519      -0.13310
log_std/min                           -3.46616     0.05599     -3.26429     -3.55876
log_probs/mean                        4.90201      0.14946     5.23756      4.55266
log_probs/std                         4.08300      0.16615     4.49355      3.72441
log_probs/max                         37.27411     9.00649     47.10751     22.76336
log_probs/min                         -6.37278     1.54499     -3.69898     -11.12376
mean/mean                             0.24090      0.03484     0.30913      0.16150
mean/std                              1.57928      0.02416     1.64220      1.52460
mean/max                              6.33351      0.09251     6.51490      5.91548
mean/min                              -8.76896     1.79326     -4.78940     -10.25854
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 1, 8, 4, 5, 0, 7, 2, 6]
replay_buffer._size: [32700 32700 32700 32700 32700 32700 32700 32700 32700 32700]
2023-08-12 12:11:13,276 MainThread INFO: EPOCH:196
2023-08-12 12:11:13,277 MainThread INFO: Time Consumed:8.747852802276611s
2023-08-12 12:11:13,277 MainThread INFO: Total Frames:325500s
  2%|▏         | 197/10000 [29:52<24:55:55,  9.16s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               851.64965
Train_Epoch_Reward                    7827.15969
Running_Training_Average_Rewards      837.40518
Explore_Time                          0.00537
Train___Time                          8.73687
Eval____Time                          0.00484
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.01944
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.60478
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.35376
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -67.55601
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.74506
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.00218
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.93313
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9129.56845
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.15598
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.70165
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.83578      1.51458     11.73394     2.95704
alpha_0                               1.65702      0.01525     1.68230      1.63143
alpha_1                               0.22298      0.00252     0.22739      0.21866
alpha_2                               0.09303      0.00106     0.09467      0.09101
alpha_3                               0.11685      0.00030     0.11753      0.11653
alpha_4                               0.12559      0.00071     0.12680      0.12437
alpha_5                               0.27089      0.00277     0.27459      0.26470
alpha_6                               0.16328      0.00034     0.16375      0.16274
alpha_7                               0.33550      0.00216     0.33919      0.33165
alpha_8                               0.15670      0.00047     0.15761      0.15607
alpha_9                               0.16455      0.00011     0.16483      0.16444
Alpha_loss                            1.49930      0.32439     2.24723      0.90404
Training/policy_loss                  -17.74333    13.50240    13.94662     -51.09863
Training/qf1_loss                     13884.77305  3842.84465  27392.27148  5998.67139
Training/qf2_loss                     1325.04582   451.20682   2627.57056   570.99170
Training/pf_norm                      12.82717     5.75463     33.53460     4.58682
Training/qf1_norm                     7904.56814   3770.04028  22886.18359  2284.87646
Training/qf2_norm                     4453.10174   2020.04093  10683.23242  1170.88940
log_std/mean                          -0.96466     0.01349     -0.93415     -0.99650
log_std/std                           0.43493      0.00997     0.45427      0.41303
log_std/max                           0.64280      0.40160     1.11805      -0.09129
log_std/min                           -3.28525     0.08161     -2.88120     -3.41294
log_probs/mean                        4.91850      0.19075     5.34019      4.47710
log_probs/std                         4.04732      0.15225     4.40494      3.65823
log_probs/max                         34.44076     8.84389     46.35928     21.66423
log_probs/min                         -6.05179     1.45079     -3.75026     -10.67245
mean/mean                             0.23204      0.04517     0.32464      0.14831
mean/std                              1.58478      0.03290     1.65333      1.50946
mean/max                              6.33767      0.16469     6.56401      5.29601
mean/min                              -8.09025     1.75928     -5.02433     -9.85286
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 5, 9, 6, 2, 3, 1, 8, 0, 7]
replay_buffer._size: [32852 32850 32850 32850 32850 32850 32850 32851 32850 32850]
2023-08-12 12:11:22,027 MainThread INFO: EPOCH:197
2023-08-12 12:11:22,028 MainThread INFO: Time Consumed:8.542107582092285s
2023-08-12 12:11:22,028 MainThread INFO: Total Frames:327000s
  2%|▏         | 198/10000 [30:01<24:38:33,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               850.67285
Train_Epoch_Reward                    7941.59035
Running_Training_Average_Rewards      813.41482
Explore_Time                          0.02471
Train___Time                          8.50869
Eval____Time                          0.00740
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.30154
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.41728
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.23647
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.63463
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.94758
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.40829
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.00108
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9112.96732
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.35556
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.93642
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.53290      1.41624     10.18188     3.25601
alpha_0                               1.70733      0.01739     1.73974      1.68266
alpha_1                               0.23162      0.00227     0.23546      0.22748
alpha_2                               0.09626      0.00086     0.09754      0.09471
alpha_3                               0.11834      0.00048     0.11928      0.11755
alpha_4                               0.12805      0.00072     0.12929      0.12682
alpha_5                               0.27831      0.00255     0.28285      0.27466
alpha_6                               0.16365      0.00092     0.16536      0.16263
alpha_7                               0.34262      0.00190     0.34574      0.33927
alpha_8                               0.15471      0.00109     0.15620      0.15267
alpha_9                               0.16441      0.00034     0.16486      0.16376
Alpha_loss                            1.18284      0.26819     1.64462      0.30359
Training/policy_loss                  -16.03625    12.82101    12.55258     -51.40344
Training/qf1_loss                     13619.17819  4291.27286  27630.66602  6339.12061
Training/qf2_loss                     1218.41249   442.13169   2479.01465   519.04230
Training/pf_norm                      13.42614     6.62897     30.80126     4.53036
Training/qf1_norm                     7393.29430   2968.43524  14815.95312  2630.88208
Training/qf2_norm                     3658.85542   1848.02149  11784.88086  873.02802
log_std/mean                          -0.95157     0.01332     -0.91902     -0.98138
log_std/std                           0.44065      0.00869     0.46469      0.42224
log_std/max                           0.80679      0.38347     1.16899      -0.05871
log_std/min                           -3.20313     0.10531     -2.66023     -3.29855
log_probs/mean                        4.77380      0.15210     5.05654      4.27872
log_probs/std                         3.97183      0.15463     4.41536      3.65152
log_probs/max                         34.81134     8.27623     44.77032     22.05304
log_probs/min                         -6.12672     1.24914     -3.99255     -10.58187
mean/mean                             0.22188      0.02003     0.26990      0.17857
mean/std                              1.57416      0.02457     1.62474      1.50530
mean/max                              6.64511      0.21195     6.89988      5.63761
mean/min                              -8.33009     1.64062     -4.94985     -9.77194
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 2, 1, 8, 6, 5, 4, 7, 0]
replay_buffer._size: [33000 33000 33000 33000 33000 33000 33000 33000 33000 33000]
2023-08-12 12:11:31,175 MainThread INFO: EPOCH:198
2023-08-12 12:11:31,175 MainThread INFO: Time Consumed:8.972848892211914s
2023-08-12 12:11:31,175 MainThread INFO: Total Frames:328500s
  2%|▏         | 199/10000 [30:10<24:41:18,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               784.21633
Train_Epoch_Reward                    8928.43269
Running_Training_Average_Rewards      823.23942
Explore_Time                          0.00910
Train___Time                          8.95902
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.53970
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.07475
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.24258
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.38682
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.07109
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.01444
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.27811
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8456.61694
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.59335
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.25285
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94621      1.18839     9.79382      4.03923
alpha_0                               1.77492      0.01923     1.80860      1.74035
alpha_1                               0.23996      0.00260     0.24442      0.23553
alpha_2                               0.09842      0.00053     0.09927      0.09755
alpha_3                               0.12053      0.00069     0.12174      0.11930
alpha_4                               0.13059      0.00072     0.13172      0.12931
alpha_5                               0.28545      0.00141     0.28754      0.28290
alpha_6                               0.16770      0.00138     0.16967      0.16538
alpha_7                               0.34915      0.00200     0.35270      0.34579
alpha_8                               0.15088      0.00099     0.15263      0.14911
alpha_9                               0.16290      0.00052     0.16375      0.16194
Alpha_loss                            0.97995      0.27672     1.90723      0.26080
Training/policy_loss                  -19.75297    12.03291    13.87094     -48.58751
Training/qf1_loss                     13946.94299  4319.16505  23936.30664  4057.50000
Training/qf2_loss                     1308.80963   441.26411   2637.04517   585.25110
Training/pf_norm                      13.67898     7.25054     35.15223     5.28288
Training/qf1_norm                     7782.34879   3593.86446  19461.64258  2772.89575
Training/qf2_norm                     3709.30260   1696.10102  9276.36816   1231.07947
log_std/mean                          -0.93804     0.01031     -0.91604     -0.96060
log_std/std                           0.45122      0.00704     0.47200      0.43119
log_std/max                           0.81119      0.44438     1.21812      -0.06860
log_std/min                           -3.20795     0.09353     -2.75371     -3.29911
log_probs/mean                        4.71976      0.15881     5.19765      4.36609
log_probs/std                         3.90442      0.16722     4.27016      3.52558
log_probs/max                         33.02210     8.33437     44.30239     19.86697
log_probs/min                         -6.19111     1.38581     -3.39418     -11.70145
mean/mean                             0.23186      0.03327     0.28300      0.13813
mean/std                              1.57236      0.02352     1.63059      1.52536
mean/max                              6.77508      0.19695     6.94157      5.76215
mean/min                              -7.90847     1.72119     -5.16641     -9.69336
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 4, 5, 8, 6, 2, 0, 7, 1, 9]
replay_buffer._size: [33150 33150 33150 33150 33150 33150 33150 33150 33150 33150]
2023-08-12 12:11:40,247 MainThread INFO: EPOCH:199
2023-08-12 12:11:40,248 MainThread INFO: Time Consumed:8.903750658035278s
2023-08-12 12:11:40,248 MainThread INFO: Total Frames:330000s
  2%|▏         | 200/10000 [30:19<24:40:23,  9.06s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               834.53281
Train_Epoch_Reward                    7030.70738
Running_Training_Average_Rewards      796.69101
Explore_Time                          0.00456
Train___Time                          8.89354
Eval____Time                          0.00449
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.38376
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.37691
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.27199
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.90210
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.89905
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.00119
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.31152
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8965.30630
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.60978
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.22193
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.16823      1.53996     11.41152     3.40992
alpha_0                               1.84364      0.02040     1.88135      1.80941
alpha_1                               0.24882      0.00252     0.25302      0.24450
alpha_2                               0.10051      0.00080     0.10190      0.09928
alpha_3                               0.12407      0.00164     0.12710      0.12176
alpha_4                               0.13308      0.00085     0.13453      0.13174
alpha_5                               0.29122      0.00247     0.29557      0.28757
alpha_6                               0.17121      0.00073     0.17200      0.16971
alpha_7                               0.35659      0.00219     0.36032      0.35278
alpha_8                               0.14694      0.00120     0.14906      0.14490
alpha_9                               0.16067      0.00078     0.16191      0.15926
Alpha_loss                            1.14434      0.28194     1.69318      0.37322
Training/policy_loss                  -19.08715    13.51511    18.37922     -47.23208
Training/qf1_loss                     15157.23442  4626.13116  30465.53125  5985.23926
Training/qf2_loss                     1364.87413   477.04901   2670.91016   555.92236
Training/pf_norm                      11.71184     5.39651     31.70224     4.07727
Training/qf1_norm                     8053.66054   4030.02531  20588.27148  2909.26514
Training/qf2_norm                     4278.30150   2040.86914  12606.84375  1135.33789
log_std/mean                          -0.93754     0.01045     -0.91572     -0.96347
log_std/std                           0.46211      0.00748     0.47919      0.44463
log_std/max                           0.98250      0.40254     1.34201      0.00702
log_std/min                           -3.18556     0.03583     -3.02046     -3.21517
log_probs/mean                        4.81045      0.16245     5.15325      4.32534
log_probs/std                         3.94957      0.15953     4.34742      3.64076
log_probs/max                         33.27852     8.32904     43.93493     21.00007
log_probs/min                         -6.43086     1.48971     -3.58826     -10.90288
mean/mean                             0.21149      0.01929     0.26231      0.16820
mean/std                              1.59219      0.02330     1.63619      1.51930
mean/max                              6.71356      0.09227     6.88403      6.43086
mean/min                              -8.12779     1.52735     -5.30824     -9.46915
------------------------------------  -----------  ----------  -----------  ----------
start to update mask
sample: [4, 8, 0, 1, 7, 6, 3, 9, 5, 2]
replay_buffer._size: [33300 33300 33300 33300 33300 33300 33300 33300 33300 33300]
2023-08-12 12:11:49,929 MainThread INFO: EPOCH:200
2023-08-12 12:11:49,930 MainThread INFO: Time Consumed:8.802344560623169s
2023-08-12 12:11:49,930 MainThread INFO: Total Frames:331500s
  2%|▏         | 201/10000 [30:30<26:06:55,  9.59s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               822.01201
Train_Epoch_Reward                    8517.20680
Running_Training_Average_Rewards      815.87823
Explore_Time                          0.01017
Train___Time                          8.78656
Eval____Time                          0.00494
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.05372
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.96730
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.41060
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.17255
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.99470
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.20014
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.33261
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8839.10124
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.86575
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.98381
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           6.94362      1.33868      12.56531     3.71464
alpha_0                               1.90841      0.01355      1.93061      1.88217
alpha_1                               0.25725      0.00418      0.26720      0.25309
alpha_2                               0.10215      0.00045      0.10346      0.10169
alpha_3                               0.13247      0.00271      0.13592      0.12716
alpha_4                               0.13633      0.00153      0.13986      0.13455
alpha_5                               0.29268      0.00348      0.29677      0.28582
alpha_6                               0.16491      0.00485      0.17185      0.15733
alpha_7                               0.36226      0.00071      0.36283      0.36039
alpha_8                               0.14192      0.00157      0.14486      0.14014
alpha_9                               0.16000      0.00181      0.16473      0.15848
Alpha_loss                            1.10017      1.51327      3.52616      -1.03144
Training/policy_loss                  108.57224    16.76091     141.65010    66.95770
Training/qf1_loss                     27140.00174  14108.72391  62251.18750  9828.59570
Training/qf2_loss                     1752.39004   1036.69393   5267.20068   708.99994
Training/pf_norm                      19.75012     8.64140      51.13753     6.88866
Training/qf1_norm                     25744.38949  20198.11429  76949.83594  5645.31250
Training/qf2_norm                     9066.75408   10717.92411  49306.78906  1341.56702
log_std/mean                          -0.98011     0.08107      -0.86925     -1.09921
log_std/std                           0.51216      0.02037      0.53942      0.46224
log_std/max                           0.60052      0.29200      0.97711      -0.03464
log_std/min                           -3.08305     0.11962      -2.75031     -3.25688
log_probs/mean                        4.68801      0.81763      6.02611      3.46078
log_probs/std                         4.55084      0.39756      5.30564      3.85710
log_probs/max                         29.36116     3.28686      36.51141     21.28243
log_probs/min                         -6.41672     1.26725      -4.03619     -10.62084
mean/mean                             0.43769      0.11335      0.57307      0.21975
mean/std                              1.51541      0.07876      1.65389      1.36767
mean/max                              7.68078      0.65048      8.24851      6.19041
mean/min                              -6.46699     0.64045      -4.97107     -7.34301
------------------------------------  -----------  -----------  -----------  ----------
snapshot at 200
history save at ./log/must_mtsac/mt10/12/model
sample: [8, 7, 1, 4, 0, 6, 5, 2, 9, 3]
replay_buffer._size: [33450 33450 33450 33450 33450 33450 33450 33450 33450 33450]
2023-08-12 12:11:59,383 MainThread INFO: EPOCH:201
2023-08-12 12:11:59,383 MainThread INFO: Time Consumed:8.20051884651184s
2023-08-12 12:11:59,383 MainThread INFO: Total Frames:333000s
  2%|▏         | 202/10000 [30:38<25:04:10,  9.21s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               862.40456
Train_Epoch_Reward                    8784.07869
Running_Training_Average_Rewards      811.06643
Explore_Time                          0.00487
Train___Time                          8.19061
Eval____Time                          0.00449
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.08924
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.53050
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.38471
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.64124
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.74857
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.50338
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.16181
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9238.20289
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.03696
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.06084
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.03932      1.28883     10.55621     4.09638
alpha_0                               1.94921      0.01239     1.97811      1.93106
alpha_1                               0.27753      0.00528     0.28645      0.26748
alpha_2                               0.10600      0.00131     0.10808      0.10351
alpha_3                               0.13418      0.00138     0.13598      0.13196
alpha_4                               0.14192      0.00069     0.14258      0.13996
alpha_5                               0.27609      0.00608     0.28566      0.26497
alpha_6                               0.15250      0.00291     0.15723      0.14716
alpha_7                               0.36440      0.00120     0.36661      0.36268
alpha_8                               0.14530      0.00202     0.14806      0.14140
alpha_9                               0.16691      0.00066     0.16772      0.16487
Alpha_loss                            0.79818      0.82166     2.89651      -0.29938
Training/policy_loss                  94.46849     14.12128    126.06188    58.73776
Training/qf1_loss                     14282.80372  4583.88363  29207.50586  6591.27686
Training/qf2_loss                     1277.05903   419.20230   2272.54663   503.47296
Training/pf_norm                      12.87728     5.48908     29.92307     5.10247
Training/qf1_norm                     7802.05316   2892.92963  16290.97656  3361.10376
Training/qf2_norm                     3417.16603   1461.21448  8980.67676   1340.06616
log_std/mean                          -0.88692     0.07296     -0.81637     -1.05175
log_std/std                           0.47591      0.01832     0.52032      0.45105
log_std/max                           1.00152      0.29779     1.44988      0.01545
log_std/min                           -2.95132     0.15220     -2.55516     -3.23466
log_probs/mean                        4.58292      0.40735     5.61097      3.94159
log_probs/std                         4.50365      0.18145     4.88128      4.10114
log_probs/max                         28.85390     4.10901     37.14319     22.27234
log_probs/min                         -6.72198     1.41667     -3.10447     -12.27050
mean/mean                             0.16001      0.16285     0.50907      -0.00902
mean/std                              1.59892      0.02204     1.66353      1.54620
mean/max                              7.40619      0.37878     8.15962      6.04362
mean/min                              -6.55675     0.38269     -5.23455     -7.18048
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 2, 7, 6, 9, 1, 5, 3, 4]
replay_buffer._size: [33600 33600 33600 33600 33600 33600 33600 33600 33600 33600]
2023-08-12 12:12:08,445 MainThread INFO: EPOCH:202
2023-08-12 12:12:08,446 MainThread INFO: Time Consumed:8.898430109024048s
2023-08-12 12:12:08,446 MainThread INFO: Total Frames:334500s
  2%|▏         | 203/10000 [30:47<24:57:35,  9.17s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               646.13007
Train_Epoch_Reward                    9650.18435
Running_Training_Average_Rewards      898.38233
Explore_Time                          0.00929
Train___Time                          8.88454
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.21681
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.52850
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.20977
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -73.07447
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.76037
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.03325
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -91.10899
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7113.80846
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.94126
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.63430
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.02122      1.31153     11.37303     4.22814
alpha_0                               2.01502      0.02062     2.04943      1.97912
alpha_1                               0.29455      0.00432     0.30127      0.28663
alpha_2                               0.11007      0.00112     0.11191      0.10812
alpha_3                               0.13067      0.00061     0.13192      0.12990
alpha_4                               0.14324      0.00043     0.14403      0.14259
alpha_5                               0.25662      0.00361     0.26475      0.25234
alpha_6                               0.14190      0.00283     0.14704      0.13725
alpha_7                               0.36874      0.00110     0.37041      0.36667
alpha_8                               0.14848      0.00046     0.14895      0.14726
alpha_9                               0.16527      0.00069     0.16632      0.16402
Alpha_loss                            0.06370      0.21722     0.60492      -0.35657
Training/policy_loss                  91.16675     12.18442    118.92440    60.59944
Training/qf1_loss                     14735.33353  4421.09154  26096.02930  5779.89648
Training/qf2_loss                     1191.20622   508.25849   2772.87109   476.12012
Training/pf_norm                      13.71023     6.74726     36.16016     4.48918
Training/qf1_norm                     7522.87517   3523.55206  17803.15039  2221.65601
Training/qf2_norm                     4130.14520   1931.99888  11314.82324  1136.98438
log_std/mean                          -0.82873     0.01496     -0.80321     -0.86339
log_std/std                           0.44258      0.00978     0.47231      0.42310
log_std/max                           0.91185      0.30571     1.45290      0.34968
log_std/min                           -2.75770     0.07374     -2.59734     -2.90264
log_probs/mean                        4.25491      0.15203     4.61798      3.90439
log_probs/std                         4.33265      0.20597     4.76801      3.89394
log_probs/max                         28.21144     4.93373     38.85997     19.57101
log_probs/min                         -6.63679     1.01589     -4.74568     -9.07489
mean/mean                             0.11744      0.02610     0.18038      0.07214
mean/std                              1.59713      0.02515     1.67411      1.54293
mean/max                              7.54647      0.24729     7.86486      6.13833
mean/min                              -6.76918     0.20967     -6.36433     -7.18042
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 4, 8, 5, 6, 0, 3, 7, 2, 9]
replay_buffer._size: [33750 33750 33750 33750 33750 33750 33750 33750 33750 33750]
2023-08-12 12:12:17,527 MainThread INFO: EPOCH:203
2023-08-12 12:12:17,528 MainThread INFO: Time Consumed:8.883927583694458s
2023-08-12 12:12:17,528 MainThread INFO: Total Frames:336000s
  2%|▏         | 204/10000 [30:56<24:51:20,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               565.39971
Train_Epoch_Reward                    6764.69401
Running_Training_Average_Rewards      839.96524
Explore_Time                          0.00436
Train___Time                          8.87298
Eval____Time                          0.00490
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.08221
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -108.83463
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.68339
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.15504
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.41170
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.68205
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.65115
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6344.40053
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.60237
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.30095
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.64450      1.27371     9.56554      3.95651
alpha_0                               2.08351      0.02071     2.11758      2.05001
alpha_1                               0.30629      0.00269     0.31060      0.30138
alpha_2                               0.11341      0.00075     0.11455      0.11195
alpha_3                               0.12975      0.00014     0.12990      0.12936
alpha_4                               0.14503      0.00057     0.14602      0.14405
alpha_5                               0.25137      0.00079     0.25230      0.24964
alpha_6                               0.13355      0.00196     0.13716      0.13037
alpha_7                               0.37193      0.00085     0.37347      0.37044
alpha_8                               0.14531      0.00111     0.14722      0.14330
alpha_9                               0.16252      0.00083     0.16399      0.16117
Alpha_loss                            -0.14440     0.23946     0.50621      -0.58326
Training/policy_loss                  94.57441     13.48520    126.57871    60.15850
Training/qf1_loss                     14081.09289  4252.25363  34057.55078  7483.13428
Training/qf2_loss                     1080.71897   398.13872   2299.71899   433.63547
Training/pf_norm                      12.27235     5.26906     32.46743     4.73647
Training/qf1_norm                     7206.53324   3559.15673  19978.30078  2701.14185
Training/qf2_norm                     3599.39293   1689.03699  7992.20166   974.21484
log_std/mean                          -0.83714     0.01016     -0.81336     -0.86133
log_std/std                           0.43010      0.00476     0.44224      0.41831
log_std/max                           0.57749      0.11253     0.76480      0.24880
log_std/min                           -2.81583     0.12971     -2.45557     -2.93365
log_probs/mean                        4.15550      0.14538     4.58546      3.80123
log_probs/std                         3.94037      0.13519     4.27502      3.66413
log_probs/max                         26.53276     4.40213     35.93124     18.91931
log_probs/min                         -6.81966     1.31267     -4.56981     -10.76289
mean/mean                             0.16234      0.02538     0.21202      0.08546
mean/std                              1.56653      0.02445     1.64655      1.51280
mean/max                              7.63510      0.23253     7.94432      6.82502
mean/min                              -6.39216     0.14620     -6.12545     -6.76985
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 5, 8, 9, 3, 0, 6, 1, 2, 7]
replay_buffer._size: [33900 33900 33900 33900 33900 33900 33900 33900 33900 33900]
2023-08-12 12:12:25,866 MainThread INFO: EPOCH:204
2023-08-12 12:12:25,866 MainThread INFO: Time Consumed:8.179224252700806s
2023-08-12 12:12:25,866 MainThread INFO: Total Frames:337500s
  2%|▏         | 205/10000 [31:05<24:15:34,  8.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               690.57429
Train_Epoch_Reward                    5870.20770
Running_Training_Average_Rewards      742.83620
Explore_Time                          0.01459
Train___Time                          8.15991
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.05591
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -107.38518
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.60440
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.49095
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.26998
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.45818
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.62470
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7642.52152
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.84983
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.03945
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.10972      1.41434     10.10744     4.25276
alpha_0                               2.15998      0.02509     2.19993      2.11823
alpha_1                               0.31400      0.00183     0.31710      0.31068
alpha_2                               0.11725      0.00212     0.12127      0.11457
alpha_3                               0.12878      0.00028     0.12934      0.12822
alpha_4                               0.14708      0.00056     0.14793      0.14605
alpha_5                               0.24733      0.00126     0.24959      0.24522
alpha_6                               0.12778      0.00140     0.13032      0.12545
alpha_7                               0.37647      0.00184     0.37969      0.37352
alpha_8                               0.14209      0.00049     0.14324      0.14116
alpha_9                               0.15969      0.00080     0.16114      0.15830
Alpha_loss                            0.69555      0.48991     1.62461      -0.51585
Training/policy_loss                  90.03318     14.17397    121.49306    53.70658
Training/qf1_loss                     15112.52479  4752.87345  29517.46875  7190.22656
Training/qf2_loss                     1136.88592   477.26745   2618.77417   363.31442
Training/pf_norm                      12.89781     6.99397     41.69203     4.61369
Training/qf1_norm                     7755.20211   3497.51324  23659.07227  2413.83374
Training/qf2_norm                     3687.60409   1567.92793  8314.86035   1249.22278
log_std/mean                          -0.86591     0.01047     -0.83061     -0.88532
log_std/std                           0.42102      0.00451     0.43262      0.40983
log_std/max                           0.66886      0.13146     0.86632      0.38831
log_std/min                           -2.83561     0.14103     -2.47677     -2.96369
log_probs/mean                        4.57147      0.25720     5.06454      3.88240
log_probs/std                         4.27205      0.28243     4.83142      3.68351
log_probs/max                         26.01752     3.36646     33.83475     20.32638
log_probs/min                         -6.82011     1.28120     -4.39709     -12.01181
mean/mean                             0.11277      0.03321     0.20299      0.05127
mean/std                              1.63044      0.04308     1.71129      1.52007
mean/max                              5.96590      0.51530     7.18506      4.92408
mean/min                              -6.16514     0.17209     -5.77785     -6.57030
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 9, 2, 6, 4, 5, 1, 7, 0]
replay_buffer._size: [34050 34050 34050 34050 34050 34050 34050 34050 34050 34050]
2023-08-12 12:12:34,927 MainThread INFO: EPOCH:205
2023-08-12 12:12:34,927 MainThread INFO: Time Consumed:8.882174491882324s
2023-08-12 12:12:34,927 MainThread INFO: Total Frames:339000s
  2%|▏         | 206/10000 [31:14<24:19:42,  8.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               827.83602
Train_Epoch_Reward                    6980.94863
Running_Training_Average_Rewards      653.86168
Explore_Time                          0.00685
Train___Time                          8.87164
Eval____Time                          0.00322
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.28914
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.20425
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.35596
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.05340
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.16339
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.93668
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.56977
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8091.88224
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.96219
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           873.01271
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.84303      1.42423     9.65478      3.10563
alpha_0                               2.22620      0.01474     2.25144      2.20049
alpha_1                               0.31993      0.00151     0.32237      0.31716
alpha_2                               0.12524      0.00221     0.12894      0.12135
alpha_3                               0.12781      0.00013     0.12821      0.12770
alpha_4                               0.14801      0.00007     0.14809      0.14786
alpha_5                               0.24050      0.00270     0.24516      0.23643
alpha_6                               0.12321      0.00124     0.12540      0.12114
alpha_7                               0.38267      0.00186     0.38583      0.37973
alpha_8                               0.13994      0.00059     0.14113      0.13916
alpha_9                               0.15656      0.00097     0.15827      0.15503
Alpha_loss                            0.64108      0.22264     1.07025      0.00678
Training/policy_loss                  89.65488     14.22641    126.05727    65.26884
Training/qf1_loss                     15180.86371  4623.15750  29355.06250  7112.17725
Training/qf2_loss                     1156.43383   516.01262   2873.96265   376.91156
Training/pf_norm                      10.87458     3.61063     21.42483     5.10022
Training/qf1_norm                     8079.52500   4041.65227  22252.94727  2770.22217
Training/qf2_norm                     3772.33158   1878.47555  10589.72559  1141.91064
log_std/mean                          -0.89553     0.01768     -0.86195     -0.92364
log_std/std                           0.42277      0.00494     0.43442      0.41001
log_std/max                           0.68534      0.12866     0.90083      0.42384
log_std/min                           -2.88515     0.12979     -2.61098     -3.04016
log_probs/mean                        4.46545      0.14260     4.73960      4.08121
log_probs/std                         4.37759      0.12479     4.67434      3.92738
log_probs/max                         27.25850     3.93746     34.13534     20.17636
log_probs/min                         -6.69393     1.16346     -4.09533     -10.28066
mean/mean                             0.10395      0.02229     0.15572      0.06036
mean/std                              1.59486      0.02203     1.65857      1.53842
mean/max                              5.94741      0.49854     6.50796      4.61705
mean/min                              -5.82163     0.25548     -5.24014     -6.23504
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 9, 6, 7, 8, 2, 3, 1, 0, 5]
replay_buffer._size: [34200 34200 34200 34200 34200 34200 34200 34200 34200 34200]
2023-08-12 12:12:44,234 MainThread INFO: EPOCH:206
2023-08-12 12:12:44,234 MainThread INFO: Time Consumed:9.124545574188232s
2023-08-12 12:12:44,234 MainThread INFO: Total Frames:340500s
  2%|▏         | 207/10000 [31:23<24:37:21,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               819.09464
Train_Epoch_Reward                    8444.83087
Running_Training_Average_Rewards      709.86624
Explore_Time                          0.00424
Train___Time                          9.11537
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.50860
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.31633
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.92253
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.95262
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.75873
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.39877
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.47408
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8281.71461
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.37894
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           583.94240
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.67641      1.23763     10.05710     4.27603
alpha_0                               2.26635      0.00784     2.27732      2.25191
alpha_1                               0.32487      0.00138     0.32728      0.32242
alpha_2                               0.13209      0.00172     0.13488      0.12900
alpha_3                               0.12727      0.00033     0.12783      0.12689
alpha_4                               0.14787      0.00005     0.14794      0.14780
alpha_5                               0.23341      0.00183     0.23637      0.22997
alpha_6                               0.11927      0.00102     0.12110      0.11758
alpha_7                               0.38887      0.00172     0.39148      0.38590
alpha_8                               0.13884      0.00019     0.13918      0.13862
alpha_9                               0.15355      0.00079     0.15500      0.15228
Alpha_loss                            0.51295      0.18475     1.04298      0.06232
Training/policy_loss                  89.47236     14.01248    118.64516    51.25223
Training/qf1_loss                     14778.90579  4418.41563  26244.82617  7193.02490
Training/qf2_loss                     1044.32266   399.67719   2425.83447   461.87643
Training/pf_norm                      14.10321     6.25348     30.25779     4.59179
Training/qf1_norm                     7285.30986   2965.86675  15312.96191  2566.33472
Training/qf2_norm                     3770.12466   1850.33880  9909.28809   1138.33862
log_std/mean                          -0.89630     0.00988     -0.87835     -0.91776
log_std/std                           0.42324      0.00693     0.43951      0.40917
log_std/max                           0.57730      0.08445     0.73983      0.37369
log_std/min                           -2.88667     0.11625     -2.62700     -3.05102
log_probs/mean                        4.36798      0.14030     4.74255      4.03251
log_probs/std                         4.11211      0.13278     4.41623      3.80598
log_probs/max                         25.39646     3.80340     32.93022     18.01552
log_probs/min                         -6.57638     1.42472     -4.64515     -14.84257
mean/mean                             0.11858      0.01710     0.15597      0.07362
mean/std                              1.57198      0.02449     1.61564      1.50947
mean/max                              5.92524      0.67217     6.54691      4.46753
mean/min                              -5.46190     0.32296     -4.96025     -5.91327
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 5, 1, 9, 3, 7, 6, 8, 2, 4]
replay_buffer._size: [34350 34350 34350 34350 34350 34350 34350 34350 34350 34350]
2023-08-12 12:12:53,303 MainThread INFO: EPOCH:207
2023-08-12 12:12:53,304 MainThread INFO: Time Consumed:8.871020317077637s
2023-08-12 12:12:53,304 MainThread INFO: Total Frames:342000s
  2%|▏         | 208/10000 [31:32<24:37:36,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               817.46991
Train_Epoch_Reward                    8684.45961
Running_Training_Average_Rewards      803.67464
Explore_Time                          0.00597
Train___Time                          8.86079
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.64081
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.36338
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.99396
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.81132
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.19353
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.08075
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.40003
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8294.67660
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.97705
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           567.48335
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.64778      1.26848     11.16531     3.26183
alpha_0                               2.28517      0.00348     2.28893      2.27733
alpha_1                               0.32982      0.00141     0.33213      0.32733
alpha_2                               0.13767      0.00153     0.14016      0.13494
alpha_3                               0.12708      0.00010     0.12723      0.12692
alpha_4                               0.14819      0.00018     0.14844      0.14792
alpha_5                               0.22813      0.00079     0.22989      0.22645
alpha_6                               0.11631      0.00063     0.11755      0.11533
alpha_7                               0.39417      0.00152     0.39677      0.39152
alpha_8                               0.13897      0.00023     0.13939      0.13864
alpha_9                               0.15128      0.00060     0.15226      0.15009
Alpha_loss                            0.76158      0.25341     1.23258      0.12529
Training/policy_loss                  90.70352     13.34755    125.02512    63.80774
Training/qf1_loss                     14298.20208  4200.67982  28054.08789  7372.22803
Training/qf2_loss                     1058.65320   403.79612   2400.17432   442.81662
Training/pf_norm                      13.99429     5.73760     32.76875     5.23482
Training/qf1_norm                     7558.66179   2989.29863  17860.19922  2596.26685
Training/qf2_norm                     4559.34820   2149.82071  10477.39648  1079.68103
log_std/mean                          -0.90164     0.02037     -0.86118     -0.93648
log_std/std                           0.43505      0.00704     0.45476      0.41838
log_std/max                           0.52109      0.06836     0.65172      0.37866
log_std/min                           -2.91731     0.08992     -2.56387     -3.02585
log_probs/mean                        4.48909      0.16399     4.86303      4.13885
log_probs/std                         3.95484      0.12410     4.23156      3.67860
log_probs/max                         24.99316     3.14041     31.42382     18.83661
log_probs/min                         -6.41942     1.47140     -3.92326     -11.82421
mean/mean                             0.15097      0.02278     0.20839      0.10506
mean/std                              1.57798      0.02193     1.62122      1.52365
mean/max                              6.00557      0.58120     6.57795      4.49809
mean/min                              -5.53146     0.38022     -4.84362     -5.94357
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 6, 1, 7, 3, 5, 2, 0, 4, 9]
replay_buffer._size: [34500 34500 34500 34500 34500 34500 34500 34500 34500 34500]
2023-08-12 12:13:02,472 MainThread INFO: EPOCH:208
2023-08-12 12:13:02,473 MainThread INFO: Time Consumed:9.048650741577148s
2023-08-12 12:13:02,473 MainThread INFO: Total Frames:343500s
  2%|▏         | 209/10000 [31:41<24:43:33,  9.09s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               880.14895
Train_Epoch_Reward                    7971.46148
Running_Training_Average_Rewards      836.69173
Explore_Time                          0.00376
Train___Time                          9.04057
Eval____Time                          0.00376
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.56857
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.18235
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.38180
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.03392
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.74273
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.08932
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.17023
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9016.57125
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.48049
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           447.56766
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.90081      1.25960     10.28013     4.27835
alpha_0                               2.28850      0.00143     2.29342      2.28715
alpha_1                               0.33419      0.00125     0.33646      0.33217
alpha_2                               0.14246      0.00133     0.14473      0.14020
alpha_3                               0.12715      0.00011     0.12740      0.12704
alpha_4                               0.14824      0.00024     0.14847      0.14773
alpha_5                               0.22288      0.00243     0.22638      0.21804
alpha_6                               0.11461      0.00039     0.11531      0.11390
alpha_7                               0.39853      0.00080     0.39952      0.39683
alpha_8                               0.14043      0.00058     0.14123      0.13941
alpha_9                               0.14862      0.00093     0.15006      0.14687
Alpha_loss                            0.42785      0.22949     0.83531      -0.20223
Training/policy_loss                  89.36797     12.95203    123.34016    61.05034
Training/qf1_loss                     14428.25771  4488.45465  30239.79492  6461.86035
Training/qf2_loss                     1087.50887   433.18040   2606.84302   430.06369
Training/pf_norm                      14.04096     5.91835     33.51350     4.54200
Training/qf1_norm                     7783.63956   3735.76020  20687.27539  2091.69727
Training/qf2_norm                     3415.33897   1471.95908  8087.37598   1452.03870
log_std/mean                          -0.88369     0.00743     -0.86652     -0.90601
log_std/std                           0.43648      0.00530     0.44776      0.41990
log_std/max                           0.46515      0.06151     0.58399      0.27133
log_std/min                           -2.89679     0.09272     -2.69369     -3.01146
log_probs/mean                        4.26667      0.14434     4.53080      3.87126
log_probs/std                         3.94708      0.10689     4.17994      3.68077
log_probs/max                         24.36762     3.00088     31.37222     18.24791
log_probs/min                         -6.43552     1.30300     -4.21391     -12.21505
mean/mean                             0.14537      0.03251     0.22029      0.09397
mean/std                              1.54962      0.02046     1.60053      1.49962
mean/max                              6.03975      0.70846     6.74282      4.48046
mean/min                              -5.31445     0.44766     -4.66649     -5.95309
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 4, 5, 2, 6, 8, 9, 3, 0, 1]
replay_buffer._size: [34650 34650 34650 34650 34650 34650 34650 34650 34650 34650]
2023-08-12 12:13:11,509 MainThread INFO: EPOCH:209
2023-08-12 12:13:11,510 MainThread INFO: Time Consumed:8.85741376876831s
2023-08-12 12:13:11,510 MainThread INFO: Total Frames:345000s
  2%|▏         | 210/10000 [31:50<24:40:19,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               865.57995
Train_Epoch_Reward                    8441.50649
Running_Training_Average_Rewards      836.58092
Explore_Time                          0.00911
Train___Time                          8.84356
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.86514
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.28045
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.40573
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.21659
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.63342
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.06356
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.82153
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8781.24422
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.98827
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           534.83000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.90880      1.21607     11.66244     4.61730
alpha_0                               2.30373      0.00442     2.30827      2.29367
alpha_1                               0.33949      0.00172     0.34248      0.33651
alpha_2                               0.14704      0.00125     0.14914      0.14478
alpha_3                               0.12814      0.00059     0.12950      0.12740
alpha_4                               0.14745      0.00017     0.14773      0.14714
alpha_5                               0.21364      0.00277     0.21793      0.20842
alpha_6                               0.11340      0.00027     0.11389      0.11294
alpha_7                               0.39952      0.00023     0.39976      0.39911
alpha_8                               0.14175      0.00030     0.14248      0.14123
alpha_9                               0.14517      0.00094     0.14683      0.14368
Alpha_loss                            0.47975      0.32687     1.14164      -0.33714
Training/policy_loss                  86.19228     14.33312    119.70418    51.04605
Training/qf1_loss                     14801.63218  5105.85453  35774.66797  6676.43115
Training/qf2_loss                     1115.79442   427.38234   2891.46118   517.64417
Training/pf_norm                      12.66756     5.51035     39.08362     3.41347
Training/qf1_norm                     7935.58602   4463.65886  25532.30859  2902.34692
Training/qf2_norm                     3950.19781   2114.17204  14096.21875  1122.08179
log_std/mean                          -0.90878     0.01587     -0.87686     -0.94113
log_std/std                           0.44543      0.00877     0.46421      0.42695
log_std/max                           0.36642      0.04441     0.46745      0.25987
log_std/min                           -2.97936     0.06556     -2.75838     -3.07395
log_probs/mean                        4.29917      0.22730     4.77179      3.75855
log_probs/std                         3.97055      0.11452     4.37908      3.72880
log_probs/max                         24.87828     3.22911     31.57481     17.70883
log_probs/min                         -6.47028     1.36553     -4.33371     -12.10209
mean/mean                             0.14113      0.01390     0.17218      0.10746
mean/std                              1.53781      0.03209     1.60423      1.45120
mean/max                              6.01550      0.72414     6.75101      4.52901
mean/min                              -5.27469     0.47828     -4.49084     -6.02069
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 7, 0, 1, 5, 3, 6, 8, 9]
replay_buffer._size: [34800 34800 34800 34800 34800 34800 34800 34800 34800 34800]
2023-08-12 12:13:20,232 MainThread INFO: EPOCH:210
2023-08-12 12:13:20,232 MainThread INFO: Time Consumed:8.547695636749268s
2023-08-12 12:13:20,232 MainThread INFO: Total Frames:346500s
  2%|▏         | 211/10000 [31:59<24:22:56,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               854.15915
Train_Epoch_Reward                    8439.07778
Running_Training_Average_Rewards      828.40152
Explore_Time                          0.01009
Train___Time                          8.53309
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.23424
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -108.23605
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.80176
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.67530
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.13685
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.12394
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.23471
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8535.95691
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.37086
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           655.44829
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68709      1.33141     9.61213      3.56992
alpha_0                               2.30215      0.00323     2.30649      2.29725
alpha_1                               0.34539      0.00157     0.34814      0.34255
alpha_2                               0.15188      0.00157     0.15453      0.14919
alpha_3                               0.13106      0.00079     0.13247      0.12954
alpha_4                               0.14704      0.00009     0.14713      0.14684
alpha_5                               0.20384      0.00241     0.20833      0.20045
alpha_6                               0.11304      0.00020     0.11357      0.11287
alpha_7                               0.39891      0.00014     0.39920      0.39878
alpha_8                               0.14432      0.00098     0.14598      0.14252
alpha_9                               0.14212      0.00097     0.14366      0.14051
Alpha_loss                            0.91031      0.23523     1.43433      0.25426
Training/policy_loss                  90.36567     14.84875    120.00512    55.85222
Training/qf1_loss                     14284.90512  4286.98156  28759.08398  7735.30957
Training/qf2_loss                     1018.62072   445.08219   2426.43628   396.30392
Training/pf_norm                      12.51580     6.60953     42.08606     4.05960
Training/qf1_norm                     8158.51301   3769.05683  20808.34375  2902.03442
Training/qf2_norm                     4213.87835   2004.99353  9250.83203   1090.43469
log_std/mean                          -0.91182     0.00803     -0.89220     -0.93021
log_std/std                           0.45124      0.00683     0.47064      0.43723
log_std/max                           0.31249      0.04610     0.41279      0.21670
log_std/min                           -2.98999     0.08241     -2.58433     -3.05119
log_probs/mean                        4.48595      0.15545     4.86549      4.10004
log_probs/std                         4.06122      0.09643     4.27704      3.85538
log_probs/max                         24.14321     2.94709     29.06163     18.73965
log_probs/min                         -6.62908     1.47339     -4.43488     -14.33757
mean/mean                             0.15826      0.01816     0.20874      0.12084
mean/std                              1.56045      0.02197     1.60425      1.50124
mean/max                              5.98450      0.60279     6.60169      4.76474
mean/min                              -5.31767     0.55114     -4.46598     -5.90531
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 8, 7, 5, 0, 3, 6, 9, 2, 1]
replay_buffer._size: [34950 34950 34950 34950 34950 34950 34950 34950 34950 34950]
2023-08-12 12:13:29,586 MainThread INFO: EPOCH:211
2023-08-12 12:13:29,587 MainThread INFO: Time Consumed:9.154472351074219s
2023-08-12 12:13:29,587 MainThread INFO: Total Frames:348000s
  2%|▏         | 212/10000 [32:08<24:41:47,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               832.41851
Train_Epoch_Reward                    8154.20656
Running_Training_Average_Rewards      834.49303
Explore_Time                          0.00465
Train___Time                          9.14467
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.17162
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -108.42787
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.83261
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -67.26068
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.32535
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.20134
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.17308
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8757.06408
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.53796
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           221.05154
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61118      1.32243     10.47359     3.93451
alpha_0                               2.31099      0.00750     2.32236      2.29896
alpha_1                               0.35085      0.00146     0.35322      0.34819
alpha_2                               0.15701      0.00136     0.15928      0.15459
alpha_3                               0.13430      0.00113     0.13631      0.13250
alpha_4                               0.14653      0.00018     0.14683      0.14624
alpha_5                               0.19776      0.00158     0.20041      0.19508
alpha_6                               0.11454      0.00048     0.11525      0.11360
alpha_7                               0.39832      0.00062     0.39886      0.39662
alpha_8                               0.14736      0.00093     0.14926      0.14601
alpha_9                               0.13920      0.00067     0.14049      0.13818
Alpha_loss                            0.86920      0.21263     1.41548      0.34174
Training/policy_loss                  90.35388     14.19981    129.53362    56.55701
Training/qf1_loss                     13984.43840  3712.88629  26488.71289  7125.66943
Training/qf2_loss                     1030.18772   435.37300   2946.31714   366.26367
Training/pf_norm                      13.43637     6.31255     30.74984     4.46893
Training/qf1_norm                     7777.84641   3045.85569  16998.03125  2532.20581
Training/qf2_norm                     3511.47459   1634.80626  9654.24805   1138.63538
log_std/mean                          -0.91659     0.00637     -0.89931     -0.93003
log_std/std                           0.45254      0.00908     0.48161      0.43224
log_std/max                           0.27611      0.04908     0.37724      0.15411
log_std/min                           -2.98538     0.07288     -2.61441     -3.10149
log_probs/mean                        4.50083      0.15648     4.84876      4.11312
log_probs/std                         3.95117      0.10559     4.29212      3.68388
log_probs/max                         23.69192     2.67458     29.39047     17.99229
log_probs/min                         -6.44897     1.22274     -4.03940     -10.40928
mean/mean                             0.16883      0.03252     0.24762      0.10743
mean/std                              1.55260      0.02638     1.61247      1.49676
mean/max                              5.95302      0.58760     6.56591      4.89848
mean/min                              -5.19588     0.64684     -4.22887     -5.96147
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 0, 7, 2, 5, 8, 6, 4, 3]
replay_buffer._size: [35100 35100 35100 35100 35100 35100 35100 35100 35100 35100]
2023-08-12 12:13:38,064 MainThread INFO: EPOCH:212
2023-08-12 12:13:38,064 MainThread INFO: Time Consumed:8.304524421691895s
2023-08-12 12:13:38,064 MainThread INFO: Total Frames:349500s
  2%|▏         | 213/10000 [32:17<24:12:06,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               859.04596
Train_Epoch_Reward                    8231.34848
Running_Training_Average_Rewards      827.48776
Explore_Time                          0.00418
Train___Time                          8.29589
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.96942
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -110.72754
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.40183
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.21474
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.17168
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.36226
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.04109
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8933.15423
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.80733
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           305.00127
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.96233      1.42779     11.02013     2.90916
alpha_0                               2.32467      0.00438     2.33379      2.31969
alpha_1                               0.35597      0.00162     0.35856      0.35326
alpha_2                               0.16202      0.00164     0.16488      0.15933
alpha_3                               0.13729      0.00053     0.13812      0.13635
alpha_4                               0.14645      0.00017     0.14684      0.14624
alpha_5                               0.19237      0.00144     0.19503      0.19002
alpha_6                               0.11563      0.00019     0.11595      0.11526
alpha_7                               0.39448      0.00090     0.39656      0.39327
alpha_8                               0.15137      0.00129     0.15369      0.14930
alpha_9                               0.13711      0.00061     0.13816      0.13608
Alpha_loss                            0.91391      0.22141     1.47450      0.25512
Training/policy_loss                  89.65768     15.00461    130.58995    35.20868
Training/qf1_loss                     14694.21186  4384.62278  29515.90039  7685.14307
Training/qf2_loss                     1100.30224   478.64113   2807.16260   342.51031
Training/pf_norm                      13.64159     8.01734     48.81451     4.53852
Training/qf1_norm                     8559.54798   3383.07536  19742.33984  2236.46069
Training/qf2_norm                     4015.16537   1968.75480  10477.91895  1098.03259
log_std/mean                          -0.92447     0.01251     -0.89742     -0.94830
log_std/std                           0.45641      0.00632     0.47339      0.43991
log_std/max                           0.29189      0.05567     0.47777      0.15352
log_std/min                           -3.01663     0.06779     -2.58351     -3.08375
log_probs/mean                        4.52831      0.16391     4.86271      4.08205
log_probs/std                         4.05787      0.10890     4.50797      3.81057
log_probs/max                         23.55891     2.62625     28.24802     18.05735
log_probs/min                         -6.50642     1.34281     -4.27822     -12.87382
mean/mean                             0.18845      0.02705     0.24901      0.11866
mean/std                              1.55166      0.02209     1.61625      1.47646
mean/max                              6.07774      0.54494     6.66359      4.23219
mean/min                              -5.18587     0.67219     -4.28739     -5.91322
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 7, 2, 1, 9, 8, 6, 4, 3, 5]
replay_buffer._size: [35250 35250 35250 35250 35250 35250 35250 35250 35250 35250]
2023-08-12 12:13:46,471 MainThread INFO: EPOCH:213
2023-08-12 12:13:46,472 MainThread INFO: Time Consumed:8.24746584892273s
2023-08-12 12:13:46,472 MainThread INFO: Total Frames:351000s
  2%|▏         | 214/10000 [32:25<23:49:54,  8.77s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               922.26062
Train_Epoch_Reward                    8441.35733
Running_Training_Average_Rewards      827.56375
Explore_Time                          0.00585
Train___Time                          8.23712
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.53762
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -110.15562
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.39385
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -67.08736
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.67770
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.88579
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.35547
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9179.99357
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.70600
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           681.41205
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.62666      1.17540     9.83435      3.87550
alpha_0                               2.34106      0.00407     2.34669      2.33379
alpha_1                               0.36087      0.00141     0.36330      0.35860
alpha_2                               0.16760      0.00158     0.17036      0.16493
alpha_3                               0.13762      0.00085     0.13825      0.13533
alpha_4                               0.14766      0.00063     0.14898      0.14685
alpha_5                               0.18837      0.00070     0.18996      0.18745
alpha_6                               0.11618      0.00009     0.11628      0.11596
alpha_7                               0.39116      0.00155     0.39324      0.38834
alpha_8                               0.15647      0.00174     0.15975      0.15373
alpha_9                               0.13491      0.00063     0.13606      0.13379
Alpha_loss                            0.87501      0.20201     1.27948      0.40315
Training/policy_loss                  89.98352     14.68947    117.52334    38.96115
Training/qf1_loss                     15438.28812  4129.99576  27935.92773  8769.54102
Training/qf2_loss                     1071.16223   420.30328   2559.65527   477.44101
Training/pf_norm                      13.43725     6.58366     45.89497     3.22858
Training/qf1_norm                     8289.21597   4005.69208  20267.07422  2432.63403
Training/qf2_norm                     3492.96566   1713.46254  9091.37598   828.42029
log_std/mean                          -0.92586     0.01411     -0.88863     -0.96135
log_std/std                           0.44799      0.00502     0.46186      0.43686
log_std/max                           0.26359      0.07261     0.46780      0.10506
log_std/min                           -2.98473     0.09413     -2.63208     -3.10690
log_probs/mean                        4.52132      0.14367     4.79614      4.05033
log_probs/std                         4.01394      0.08480     4.20482      3.78937
log_probs/max                         23.01576     2.41552     27.62184     17.84781
log_probs/min                         -6.51472     1.40525     -4.14491     -10.86051
mean/mean                             0.21776      0.01682     0.26403      0.17777
mean/std                              1.54729      0.01820     1.58314      1.49399
mean/max                              6.05156      0.42083     6.47855      4.17428
mean/min                              -5.16396     0.70767     -4.10653     -6.12388
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 5, 3, 6, 2, 1, 9, 8, 7]
replay_buffer._size: [35400 35400 35400 35400 35400 35400 35400 35400 35400 35400]
2023-08-12 12:13:55,127 MainThread INFO: EPOCH:214
2023-08-12 12:13:55,127 MainThread INFO: Time Consumed:8.459258556365967s
2023-08-12 12:13:55,127 MainThread INFO: Total Frames:352500s
  2%|▏         | 215/10000 [32:34<23:42:00,  8.72s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               845.86937
Train_Epoch_Reward                    9583.37186
Running_Training_Average_Rewards      875.20259
Explore_Time                          0.00418
Train___Time                          8.45033
Eval____Time                          0.00419
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.44843
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.92150
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.26570
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.02437
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.05084
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.51600
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.73417
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8584.31847
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.91545
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           527.25172
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.81894      1.41998     10.73894     3.40134
alpha_0                               2.34803      0.00198     2.35056      2.34450
alpha_1                               0.36601      0.00161     0.36878      0.36334
alpha_2                               0.17288      0.00146     0.17548      0.17041
alpha_3                               0.13129      0.00215     0.13525      0.12831
alpha_4                               0.15073      0.00111     0.15275      0.14901
alpha_5                               0.18767      0.00014     0.18793      0.18744
alpha_6                               0.11561      0.00063     0.11629      0.11429
alpha_7                               0.38534      0.00197     0.38830      0.38209
alpha_8                               0.16342      0.00194     0.16677      0.15983
alpha_9                               0.13278      0.00056     0.13377      0.13173
Alpha_loss                            0.61235      0.23597     1.20553      0.16743
Training/policy_loss                  88.87485     15.18842    125.47892    53.93710
Training/qf1_loss                     14521.58003  4192.61342  27733.69336  6507.95068
Training/qf2_loss                     1011.48662   338.05798   1859.58130   460.10263
Training/pf_norm                      13.05922     5.86188     31.56250     4.66366
Training/qf1_norm                     8146.48603   3759.60548  18446.80859  2718.82520
Training/qf2_norm                     3415.85348   1541.43194  12329.42773  1111.75159
log_std/mean                          -0.93027     0.01078     -0.91047     -0.96513
log_std/std                           0.45277      0.00717     0.47016      0.43570
log_std/max                           0.26572      0.06828     0.45024      0.12979
log_std/min                           -2.99140     0.08965     -2.55680     -3.10061
log_probs/mean                        4.39244      0.17677     4.83110      4.03780
log_probs/std                         4.02305      0.13627     4.39846      3.74435
log_probs/max                         22.75522     2.54852     27.58420     17.59123
log_probs/min                         -6.54159     1.30412     -4.46955     -10.55131
mean/mean                             0.27209      0.04140     0.34092      0.18960
mean/std                              1.52001      0.02370     1.58390      1.47002
mean/max                              6.21647      0.24767     6.58347      4.87829
mean/min                              -5.16930     0.74636     -4.22128     -6.19944
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 5, 1, 0, 3, 6, 2, 4, 9, 7]
replay_buffer._size: [35550 35550 35550 35550 35550 35550 35550 35550 35550 35550]
2023-08-12 12:14:04,456 MainThread INFO: EPOCH:215
2023-08-12 12:14:04,456 MainThread INFO: Time Consumed:9.1603844165802s
2023-08-12 12:14:04,456 MainThread INFO: Total Frames:354000s
  2%|▏         | 216/10000 [32:43<24:13:35,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               925.40210
Train_Epoch_Reward                    8094.24465
Running_Training_Average_Rewards      870.63246
Explore_Time                          0.00381
Train___Time                          9.15180
Eval____Time                          0.00422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.62828
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -97.33634
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.80532
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.06886
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.71865
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.72086
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.47514
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9882.05381
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -19.29734
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.98204
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68994      1.29380     10.22091     3.97187
alpha_0                               2.34654      0.00125     2.34894      2.34466
alpha_1                               0.37112      0.00132     0.37323      0.36884
alpha_2                               0.17825      0.00161     0.18111      0.17554
alpha_3                               0.12730      0.00038     0.12828      0.12694
alpha_4                               0.15476      0.00122     0.15702      0.15279
alpha_5                               0.18891      0.00059     0.19019      0.18796
alpha_6                               0.11234      0.00117     0.11426      0.11035
alpha_7                               0.37969      0.00129     0.38205      0.37761
alpha_8                               0.17056      0.00214     0.17449      0.16685
alpha_9                               0.13073      0.00047     0.13170      0.13005
Alpha_loss                            0.72929      0.28269     1.28610      0.00922
Training/policy_loss                  88.51203     14.79134    127.74575    52.57584
Training/qf1_loss                     15566.12283  5591.75464  39856.52344  4592.19092
Training/qf2_loss                     1067.58093   421.31579   2634.55298   506.06210
Training/pf_norm                      14.65377     6.67586     36.88293     5.62709
Training/qf1_norm                     8519.05340   4351.87907  29702.48047  2477.44092
Training/qf2_norm                     3853.44866   1826.99910  9411.63965   871.61517
log_std/mean                          -0.95528     0.01908     -0.91399     -0.98819
log_std/std                           0.46226      0.00680     0.47465      0.44529
log_std/max                           0.26967      0.09070     0.53617      0.08245
log_std/min                           -2.85442     0.06297     -2.49021     -2.90568
log_probs/mean                        4.48062      0.18998     4.87270      4.02661
log_probs/std                         4.10426      0.10406     4.39478      3.84442
log_probs/max                         22.42007     2.61182     27.22915     17.55133
log_probs/min                         -6.52302     1.19833     -4.34992     -10.53640
mean/mean                             0.27233      0.01868     0.31717      0.22860
mean/std                              1.52055      0.02383     1.58451      1.45436
mean/max                              6.21828      0.17634     6.53936      5.49604
mean/min                              -5.04991     0.70809     -4.00090     -5.91048
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 7, 2, 5, 4, 1, 6, 3, 0, 8]
replay_buffer._size: [35700 35700 35700 35700 35700 35700 35700 35700 35700 35700]
2023-08-12 12:14:12,927 MainThread INFO: EPOCH:216
2023-08-12 12:14:12,928 MainThread INFO: Time Consumed:8.265292406082153s
2023-08-12 12:14:12,928 MainThread INFO: Total Frames:355500s
  2%|▏         | 217/10000 [32:52<23:50:08,  8.77s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               846.96848
Train_Epoch_Reward                    10465.75194
Running_Training_Average_Rewards      938.11228
Explore_Time                          0.01529
Train___Time                          8.24537
Eval____Time                          0.00397
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.28298
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.66537
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -85.48529
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.00407
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.88290
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.42108
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.43245
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8010.19513
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.54220
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1061.20600
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.54183      1.11875     10.28327     4.17881
alpha_0                               2.34820      0.00180     2.35133      2.34566
alpha_1                               0.37505      0.00120     0.37748      0.37327
alpha_2                               0.18381      0.00155     0.18648      0.18116
alpha_3                               0.12734      0.00011     0.12765      0.12721
alpha_4                               0.15833      0.00066     0.15960      0.15706
alpha_5                               0.19281      0.00172     0.19614      0.19023
alpha_6                               0.10837      0.00113     0.11032      0.10653
alpha_7                               0.37603      0.00069     0.37757      0.37509
alpha_8                               0.17897      0.00267     0.18400      0.17458
alpha_9                               0.12932      0.00044     0.13005      0.12873
Alpha_loss                            0.80036      0.29877     1.46727      0.11341
Training/policy_loss                  90.78673     13.70074    122.79372    52.33854
Training/qf1_loss                     15340.31645  4926.80169  28371.86523  5846.60498
Training/qf2_loss                     1059.99784   373.97263   2170.15405   461.19296
Training/pf_norm                      11.38932     4.60560     25.13049     4.94519
Training/qf1_norm                     7977.32789   3447.22347  21351.95898  2545.38354
Training/qf2_norm                     3487.94679   1705.28468  8641.49707   1131.09607
log_std/mean                          -0.98490     0.01572     -0.95678     -1.01707
log_std/std                           0.46769      0.00619     0.48276      0.45383
log_std/max                           0.28036      0.10089     0.52678      0.06214
log_std/min                           -2.75066     0.06880     -2.49958     -2.87776
log_probs/mean                        4.55987      0.18950     4.93548      4.15357
log_probs/std                         4.03306      0.10302     4.34538      3.79139
log_probs/max                         22.44835     2.20448     25.93211     18.25877
log_probs/min                         -6.52514     1.43395     -3.65078     -11.30659
mean/mean                             0.19699      0.02227     0.25863      0.15580
mean/std                              1.52253      0.02453     1.57901      1.47660
mean/max                              6.12416      0.23789     6.33287      4.65958
mean/min                              -5.33239     0.66239     -4.01092     -5.92138
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 2, 5, 4, 7, 0, 9, 8, 1]
replay_buffer._size: [35850 35850 35850 35850 35850 35850 35850 35850 35850 35850]
2023-08-12 12:14:22,150 MainThread INFO: EPOCH:217
2023-08-12 12:14:22,150 MainThread INFO: Time Consumed:9.03777027130127s
2023-08-12 12:14:22,150 MainThread INFO: Total Frames:357000s
  2%|▏         | 218/10000 [33:01<24:11:51,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               795.56852
Train_Epoch_Reward                    7108.92555
Running_Training_Average_Rewards      855.63074
Explore_Time                          0.01127
Train___Time                          9.02149
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.79174
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.04374
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.95463
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.78098
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.51158
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.28493
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.87264
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8546.52733
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -18.45424
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.14761
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68624      1.34553     9.35998      3.81252
alpha_0                               2.35726      0.00431     2.36570      2.34958
alpha_1                               0.38093      0.00205     0.38459      0.37755
alpha_2                               0.18916      0.00151     0.19179      0.18653
alpha_3                               0.12762      0.00010     0.12780      0.12747
alpha_4                               0.16118      0.00103     0.16316      0.15963
alpha_5                               0.20056      0.00252     0.20491      0.19623
alpha_6                               0.10484      0.00104     0.10650      0.10294
alpha_7                               0.37340      0.00110     0.37507      0.37167
alpha_8                               0.18913      0.00276     0.19389      0.18412
alpha_9                               0.12824      0.00036     0.12873      0.12760
Alpha_loss                            0.88249      0.17829     1.23786      0.45291
Training/policy_loss                  88.42297     13.84421    118.46067    49.72503
Training/qf1_loss                     14743.34657  4516.87007  25683.19336  7957.75488
Training/qf2_loss                     1069.77100   411.03041   2386.96069   314.04059
Training/pf_norm                      13.26889     6.31043     37.01154     5.61119
Training/qf1_norm                     8464.62742   3798.31205  21092.17578  2818.73608
Training/qf2_norm                     3782.92003   1911.74716  13184.03906  959.71393
log_std/mean                          -0.96230     0.01478     -0.93394     -0.99882
log_std/std                           0.46989      0.00620     0.48225      0.45300
log_std/max                           0.34362      0.13040     0.56300      0.09128
log_std/min                           -2.66967     0.08433     -2.40711     -2.85970
log_probs/mean                        4.65989      0.14044     5.06221      4.34394
log_probs/std                         4.08677      0.11067     4.38353      3.88467
log_probs/max                         22.87973     2.07716     26.45055     17.77191
log_probs/min                         -6.47085     1.34562     -4.32947     -10.61897
mean/mean                             0.20667      0.02793     0.26470      0.15059
mean/std                              1.55209      0.02189     1.60615      1.50470
mean/max                              6.20884      0.30535     6.53518      4.71154
mean/min                              -5.19213     0.60306     -4.09722     -5.93728
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 4, 9, 6, 0, 7, 1, 3, 5]
replay_buffer._size: [36000 36000 36000 36000 36000 36000 36000 36000 36000 36000]
2023-08-12 12:14:31,694 MainThread INFO: EPOCH:218
2023-08-12 12:14:31,694 MainThread INFO: Time Consumed:9.379451513290405s
2023-08-12 12:14:31,694 MainThread INFO: Total Frames:358500s
  2%|▏         | 219/10000 [33:10<24:43:51,  9.10s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               817.20308
Train_Epoch_Reward                    7839.82363
Running_Training_Average_Rewards      847.15004
Explore_Time                          0.01343
Train___Time                          9.36150
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.31780
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.61523
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.86461
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.53639
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.86693
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.09602
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.13887
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8753.57329
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -13.93111
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -12.17553
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70102      1.55041     10.32043     3.18094
alpha_0                               2.38115      0.00797     2.39303      2.36593
alpha_1                               0.38798      0.00195     0.39142      0.38466
alpha_2                               0.19472      0.00168     0.19761      0.19184
alpha_3                               0.12818      0.00017     0.12838      0.12781
alpha_4                               0.16522      0.00110     0.16679      0.16320
alpha_5                               0.20913      0.00226     0.21308      0.20500
alpha_6                               0.10094      0.00118     0.10290      0.09881
alpha_7                               0.37031      0.00113     0.37165      0.36823
alpha_8                               0.19863      0.00248     0.20289      0.19400
alpha_9                               0.12748      0.00006     0.12765      0.12741
Alpha_loss                            0.77762      0.21782     1.39004      0.30514
Training/policy_loss                  91.28161     16.62189    137.45094    54.05804
Training/qf1_loss                     14949.97879  4887.93076  33572.56641  5821.03516
Training/qf2_loss                     1091.53804   465.08103   2599.00903   412.15097
Training/pf_norm                      12.40521     4.89434     29.53568     4.51250
Training/qf1_norm                     9254.75253   4282.75370  26069.75781  3210.66016
Training/qf2_norm                     4220.01903   2552.13854  12700.31543  894.47473
log_std/mean                          -0.94831     0.01268     -0.92189     -0.98234
log_std/std                           0.47087      0.00567     0.48543      0.45756
log_std/max                           0.34194      0.16245     0.54322      0.05224
log_std/min                           -2.59184     0.06010     -2.40902     -2.77463
log_probs/mean                        4.64091      0.14672     4.97781      4.31359
log_probs/std                         4.07887      0.09224     4.31072      3.87534
log_probs/max                         22.54180     1.98647     26.20246     18.43915
log_probs/min                         -6.67567     1.37767     -4.01135     -9.98969
mean/mean                             0.26308      0.02337     0.32120      0.20207
mean/std                              1.54744      0.01864     1.58360      1.50551
mean/max                              6.31880      0.25329     6.56051      4.76688
mean/min                              -5.02568     0.55325     -4.07597     -5.68757
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 9, 1, 2, 3, 4, 0, 5, 7, 8]
replay_buffer._size: [36150 36150 36150 36150 36150 36150 36150 36150 36150 36150]
2023-08-12 12:14:40,961 MainThread INFO: EPOCH:219
2023-08-12 12:14:40,961 MainThread INFO: Time Consumed:9.07772707939148s
2023-08-12 12:14:40,961 MainThread INFO: Total Frames:360000s
  2%|▏         | 220/10000 [33:20<24:51:36,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               818.05379
Train_Epoch_Reward                    8428.75984
Running_Training_Average_Rewards      779.25030
Explore_Time                          0.01350
Train___Time                          9.05940
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.58251
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.93441
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.81198
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.35654
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.63447
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.34689
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.07192
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8721.44167
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          23.85510
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.02016
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.01456      1.32257     10.77413     3.94454
alpha_0                               2.41413      0.01264     2.43399      2.39337
alpha_1                               0.39475      0.00198     0.39849      0.39149
alpha_2                               0.20065      0.00166     0.20343      0.19767
alpha_3                               0.12850      0.00020     0.12892      0.12825
alpha_4                               0.16837      0.00109     0.17049      0.16682
alpha_5                               0.21702      0.00214     0.22054      0.21316
alpha_6                               0.09620      0.00153     0.09876      0.09356
alpha_7                               0.36656      0.00107     0.36820      0.36440
alpha_8                               0.20722      0.00244     0.21146      0.20298
alpha_9                               0.12810      0.00036     0.12883      0.12766
Alpha_loss                            0.45148      0.18817     0.88882      -0.01315
Training/policy_loss                  89.41599     15.23988    117.81890    50.77273
Training/qf1_loss                     15307.29796  4534.57755  27382.32227  8148.17676
Training/qf2_loss                     1130.71238   361.86609   2375.13940   483.60156
Training/pf_norm                      13.52204     7.15339     47.19573     4.60225
Training/qf1_norm                     8632.80820   3558.88266  17865.20117  2512.30542
Training/qf2_norm                     4233.39886   2144.21624  12119.84863  1017.58716
log_std/mean                          -0.93522     0.00753     -0.91963     -0.95903
log_std/std                           0.48147      0.00655     0.49694      0.46557
log_std/max                           0.36922      0.20596     0.64230      0.03699
log_std/min                           -2.54214     0.03802     -2.42649     -2.61111
log_probs/mean                        4.52135      0.11472     4.77781      4.24872
log_probs/std                         4.11826      0.09226     4.33597      3.87339
log_probs/max                         22.70856     2.17123     26.43858     18.00202
log_probs/min                         -6.38293     1.16975     -4.33066     -10.49471
mean/mean                             0.28841      0.03107     0.36411      0.22459
mean/std                              1.53646      0.01675     1.57556      1.49130
mean/max                              6.37997      0.26023     6.69513      5.47572
mean/min                              -4.97563     0.57006     -3.92338     -5.69589
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 2, 8, 0, 3, 7, 9, 1, 6]
replay_buffer._size: [36300 36300 36300 36300 36300 36300 36300 36300 36300 36300]
2023-08-12 12:14:50,518 MainThread INFO: EPOCH:220
2023-08-12 12:14:50,518 MainThread INFO: Time Consumed:9.351997375488281s
2023-08-12 12:14:50,518 MainThread INFO: Total Frames:361500s
  2%|▏         | 221/10000 [33:29<25:10:51,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               819.62191
Train_Epoch_Reward                    8186.06555
Running_Training_Average_Rewards      815.15497
Explore_Time                          0.01026
Train___Time                          9.33705
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.72651
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.62584
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -73.16911
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.69740
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.70794
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.21058
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.70414
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8432.90042
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          313.39570
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.23553
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85668      1.35200     10.83810     3.56858
alpha_0                               2.44027      0.00402     2.44736      2.43415
alpha_1                               0.40194      0.00186     0.40493      0.39857
alpha_2                               0.20657      0.00180     0.20958      0.20349
alpha_3                               0.13000      0.00078     0.13148      0.12893
alpha_4                               0.17329      0.00160     0.17613      0.17055
alpha_5                               0.22549      0.00293     0.23037      0.22062
alpha_6                               0.09123      0.00125     0.09351      0.08922
alpha_7                               0.36395      0.00028     0.36437      0.36337
alpha_8                               0.21645      0.00287     0.22116      0.21154
alpha_9                               0.13012      0.00086     0.13165      0.12885
Alpha_loss                            0.80115      0.22178     1.42104      0.24804
Training/policy_loss                  90.44722     13.44429    122.71633    54.66529
Training/qf1_loss                     15115.05542  4217.82323  27423.04102  7168.49707
Training/qf2_loss                     1136.48905   438.77424   2298.95728   485.88931
Training/pf_norm                      15.10439     6.76596     35.42822     5.18603
Training/qf1_norm                     8095.53151   3260.89334  19635.16992  2632.66016
Training/qf2_norm                     4500.16215   2222.98380  12699.03516  822.26056
log_std/mean                          -0.94230     0.01216     -0.91836     -0.97045
log_std/std                           0.48485      0.00566     0.49652      0.47221
log_std/max                           0.35169      0.25191     0.64862      -0.07893
log_std/min                           -2.62672     0.04210     -2.51815     -2.74735
log_probs/mean                        4.71142      0.15490     5.07447      4.36420
log_probs/std                         4.13278      0.10573     4.38728      3.89124
log_probs/max                         22.39348     2.26357     26.40323     17.62149
log_probs/min                         -6.57177     1.22749     -4.44527     -10.98868
mean/mean                             0.33555      0.02510     0.39030      0.28288
mean/std                              1.54851      0.02394     1.59999      1.48707
mean/max                              6.21975      0.40456     6.71645      4.72036
mean/min                              -4.92082     0.52993     -3.81046     -5.50182
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 2, 1, 3, 6, 9, 5, 8, 7, 4]
replay_buffer._size: [36450 36450 36450 36450 36450 36450 36450 36450 36450 36450]
2023-08-12 12:14:59,202 MainThread INFO: EPOCH:221
2023-08-12 12:14:59,202 MainThread INFO: Time Consumed:8.480807781219482s
2023-08-12 12:14:59,202 MainThread INFO: Total Frames:363000s
  2%|▏         | 222/10000 [33:38<24:41:44,  9.09s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               804.33890
Train_Epoch_Reward                    9048.38210
Running_Training_Average_Rewards      855.44025
Explore_Time                          0.00729
Train___Time                          8.46868
Eval____Time                          0.00383
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.55864
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.96463
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.23264
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.26418
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.57150
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.23506
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.66690
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8595.09612
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -19.67788
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.53575
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.66234      1.34235     10.38614     3.71191
alpha_0                               2.44855      0.00172     2.45061      2.44499
alpha_1                               0.40784      0.00139     0.40988      0.40501
alpha_2                               0.21275      0.00182     0.21581      0.20964
alpha_3                               0.13258      0.00051     0.13332      0.13151
alpha_4                               0.17843      0.00112     0.18002      0.17619
alpha_5                               0.23496      0.00271     0.23972      0.23047
alpha_6                               0.08765      0.00085     0.08919      0.08627
alpha_7                               0.36321      0.00040     0.36368      0.36256
alpha_8                               0.22620      0.00279     0.23086      0.22127
alpha_9                               0.13296      0.00066     0.13393      0.13168
Alpha_loss                            0.79298      0.17870     1.16585      0.37636
Training/policy_loss                  88.93705     12.42724    119.69201    56.94435
Training/qf1_loss                     14796.69657  4850.23318  32131.96875  6309.55225
Training/qf2_loss                     1059.66533   426.37988   2735.23828   452.37793
Training/pf_norm                      12.74694     5.17584     28.30038     4.88761
Training/qf1_norm                     8354.25623   3495.12835  19964.10547  2795.29224
Training/qf2_norm                     4171.06077   1966.94769  9550.19434   927.44385
log_std/mean                          -0.94106     0.01003     -0.91599     -0.96083
log_std/std                           0.48208      0.00607     0.49883      0.46311
log_std/max                           0.43027      0.20018     0.65210      -0.01543
log_std/min                           -2.72099     0.06364     -2.57182     -2.81808
log_probs/mean                        4.66442      0.12408     4.98842      4.30851
log_probs/std                         4.00720      0.11295     4.22569      3.73055
log_probs/max                         22.80302     2.10439     26.77452     18.16809
log_probs/min                         -6.50358     1.42700     -4.06052     -11.14974
mean/mean                             0.32819      0.02538     0.39406      0.27499
mean/std                              1.53722      0.01732     1.57584      1.48981
mean/max                              6.12630      0.41840     6.67739      5.11053
mean/min                              -5.03164     0.53345     -3.67139     -5.53072
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 6, 7, 5, 0, 9, 8, 1, 4, 3]
replay_buffer._size: [36600 36600 36600 36600 36600 36600 36600 36600 36600 36600]
2023-08-12 12:15:07,675 MainThread INFO: EPOCH:222
2023-08-12 12:15:07,675 MainThread INFO: Time Consumed:8.274507522583008s
2023-08-12 12:15:07,675 MainThread INFO: Total Frames:364500s
  2%|▏         | 223/10000 [33:46<24:14:09,  8.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               950.31001
Train_Epoch_Reward                    8093.01140
Running_Training_Average_Rewards      844.24864
Explore_Time                          0.01156
Train___Time                          8.25849
Eval____Time                          0.00383
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.34442
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.94641
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -72.10687
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.94329
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.22881
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.03293
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.63626
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8944.30839
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          1111.00947
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.97877
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70690      1.40350     10.14711     3.76765
alpha_0                               2.45139      0.00277     2.45500      2.44512
alpha_1                               0.41263      0.00171     0.41559      0.40992
alpha_2                               0.21901      0.00189     0.22230      0.21587
alpha_3                               0.13359      0.00019     0.13401      0.13331
alpha_4                               0.18242      0.00149     0.18501      0.18005
alpha_5                               0.24453      0.00258     0.24891      0.23983
alpha_6                               0.08533      0.00048     0.08624      0.08458
alpha_7                               0.36220      0.00050     0.36267      0.36108
alpha_8                               0.23571      0.00275     0.24020      0.23096
alpha_9                               0.13498      0.00068     0.13613      0.13395
Alpha_loss                            1.05173      0.17424     1.54501      0.35019
Training/policy_loss                  90.67851     14.14577    137.47237    56.15255
Training/qf1_loss                     15776.94647  5528.75889  36806.90625  6860.55029
Training/qf2_loss                     1108.62555   437.67061   2667.75073   444.62070
Training/pf_norm                      13.32749     4.96307     31.64294     4.59891
Training/qf1_norm                     9846.99713   5484.70481  35676.85156  3317.76782
Training/qf2_norm                     3749.16920   1763.54732  10135.30664  957.94739
log_std/mean                          -0.92861     0.00675     -0.91400     -0.94487
log_std/std                           0.47660      0.00555     0.49084      0.46139
log_std/max                           0.44525      0.24053     0.70033      -0.03890
log_std/min                           -2.78189     0.08226     -2.54576     -2.90188
log_probs/mean                        4.80833      0.12879     5.14424      4.45292
log_probs/std                         3.98703      0.08264     4.16666      3.78090
log_probs/max                         22.81915     1.77937     26.24544     18.47551
log_probs/min                         -6.66431     1.51253     -3.98368     -13.98975
mean/mean                             0.34748      0.01930     0.38536      0.30446
mean/std                              1.56728      0.01810     1.61315      1.51537
mean/max                              6.10258      0.41455     6.53684      5.07864
mean/min                              -4.93209     0.37873     -3.92413     -5.36789
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 6, 8, 2, 0, 7, 1, 4, 5]
replay_buffer._size: [36750 36750 36750 36750 36750 36750 36750 36750 36750 36750]
2023-08-12 12:15:16,916 MainThread INFO: EPOCH:223
2023-08-12 12:15:16,916 MainThread INFO: Time Consumed:9.085808038711548s
2023-08-12 12:15:16,916 MainThread INFO: Total Frames:366000s
  2%|▏         | 224/10000 [33:56<24:27:08,  9.00s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1007.52998
Train_Epoch_Reward                    8590.31894
Running_Training_Average_Rewards      857.72375
Explore_Time                          0.00392
Train___Time                          9.07713
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.22003
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.58445
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.87845
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.30733
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.47663
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.97192
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.66621
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8977.55541
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          1655.40117
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.55177
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56088      1.49572     10.99744     3.69162
alpha_0                               2.45157      0.00385     2.45584      2.44208
alpha_1                               0.41916      0.00188     0.42247      0.41566
alpha_2                               0.22536      0.00169     0.22823      0.22237
alpha_3                               0.13511      0.00062     0.13621      0.13403
alpha_4                               0.18756      0.00144     0.18996      0.18506
alpha_5                               0.25295      0.00217     0.25637      0.24899
alpha_6                               0.08408      0.00023     0.08457      0.08379
alpha_7                               0.35998      0.00080     0.36104      0.35851
alpha_8                               0.24425      0.00234     0.24834      0.24028
alpha_9                               0.13706      0.00054     0.13804      0.13615
Alpha_loss                            1.08179      0.18269     1.55403      0.56571
Training/policy_loss                  94.45670     15.33023    126.65112    48.15981
Training/qf1_loss                     14135.75233  4621.80858  30336.79688  7000.70312
Training/qf2_loss                     1009.24755   398.49138   2232.77808   370.73923
Training/pf_norm                      13.07156     6.19045     37.96432     5.46475
Training/qf1_norm                     8241.78020   3813.11899  21250.89258  3172.30078
Training/qf2_norm                     4156.33565   1756.46040  8556.51367   1158.27075
log_std/mean                          -0.91710     0.00970     -0.89710     -0.93936
log_std/std                           0.48556      0.00651     0.50218      0.46536
log_std/max                           0.44895      0.22748     0.69717      0.01260
log_std/min                           -2.81470     0.06823     -2.61908     -2.88997
log_probs/mean                        4.76270      0.13152     5.12234      4.45931
log_probs/std                         3.89731      0.10964     4.15090      3.60828
log_probs/max                         22.68151     2.18836     26.16872     18.49302
log_probs/min                         -6.54307     1.73391     -4.09206     -13.62924
mean/mean                             0.37115      0.02257     0.42337      0.32152
mean/std                              1.55902      0.01776     1.61015      1.51370
mean/max                              6.18404      0.42577     6.58916      5.00703
mean/min                              -4.85368     0.31852     -3.92749     -5.23269
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 2, 9, 7, 5, 3, 6, 8, 4, 0]
replay_buffer._size: [36900 36900 36900 36900 36900 36900 36900 36900 36900 36900]
2023-08-12 12:15:26,409 MainThread INFO: EPOCH:224
2023-08-12 12:15:26,409 MainThread INFO: Time Consumed:9.31902027130127s
2023-08-12 12:15:26,410 MainThread INFO: Total Frames:367500s
  2%|▏         | 225/10000 [34:05<24:52:43,  9.16s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               903.36031
Train_Epoch_Reward                    10056.28515
Running_Training_Average_Rewards      891.32052
Explore_Time                          0.00494
Train___Time                          9.30875
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.94173
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.31193
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.28222
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.33435
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.07301
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.01951
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.89919
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8703.25185
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          893.33324
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.12000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.62791      1.25999     9.53335      3.46581
alpha_0                               2.42774      0.00881     2.44184      2.41398
alpha_1                               0.42566      0.00171     0.42814      0.42255
alpha_2                               0.23127      0.00177     0.23433      0.22829
alpha_3                               0.13827      0.00136     0.14049      0.13624
alpha_4                               0.19227      0.00125     0.19408      0.19002
alpha_5                               0.25907      0.00142     0.26108      0.25643
alpha_6                               0.08377      0.00002     0.08380      0.08375
alpha_7                               0.35744      0.00056     0.35848      0.35613
alpha_8                               0.25289      0.00259     0.25709      0.24843
alpha_9                               0.13975      0.00104     0.14140      0.13807
Alpha_loss                            1.16049      0.25572     1.70994      0.47271
Training/policy_loss                  90.55123     15.19037    126.00769    59.70340
Training/qf1_loss                     14805.64631  5233.21254  32696.22461  6294.57617
Training/qf2_loss                     1048.19443   383.90484   2132.11108   490.34674
Training/pf_norm                      12.62306     5.52032     37.28940     5.30357
Training/qf1_norm                     8362.70214   3994.00108  27661.92578  3948.51001
Training/qf2_norm                     3578.73939   1470.34783  7989.30615   993.69733
log_std/mean                          -0.92388     0.01472     -0.88538     -0.95187
log_std/std                           0.48484      0.00792     0.50313      0.46491
log_std/max                           0.38760      0.24661     0.75412      -0.04723
log_std/min                           -2.84032     0.08253     -2.64955     -2.98439
log_probs/mean                        4.74645      0.16454     5.02909      4.31176
log_probs/std                         3.81420      0.08785     4.03896      3.56990
log_probs/max                         22.42246     2.08251     26.49287     17.83228
log_probs/min                         -6.15588     1.12649     -3.30379     -9.07122
mean/mean                             0.40063      0.02661     0.45765      0.34271
mean/std                              1.53560      0.02044     1.58226      1.48235
mean/max                              5.95755      0.37170     6.48629      4.35588
mean/min                              -4.71995     0.33022     -3.75597     -5.15559
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 5, 9, 2, 0, 4, 1, 6, 7]
replay_buffer._size: [37050 37050 37050 37050 37050 37050 37050 37050 37050 37050]
2023-08-12 12:15:35,623 MainThread INFO: EPOCH:225
2023-08-12 12:15:35,623 MainThread INFO: Time Consumed:9.054268836975098s
2023-08-12 12:15:35,624 MainThread INFO: Total Frames:369000s
  2%|▏         | 226/10000 [34:14<24:52:54,  9.16s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               983.81098
Train_Epoch_Reward                    9178.62445
Running_Training_Average_Rewards      927.50762
Explore_Time                          0.00407
Train___Time                          9.04480
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.95210
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.31766
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.27400
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.50426
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.43481
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.22981
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.88557
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9131.98696
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          1274.80974
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.08874
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60564      1.21352     9.57411      3.36697
alpha_0                               2.40544      0.00332     2.41365      2.40257
alpha_1                               0.43003      0.00135     0.43299      0.42817
alpha_2                               0.23742      0.00177     0.24045      0.23439
alpha_3                               0.14252      0.00125     0.14483      0.14052
alpha_4                               0.19488      0.00043     0.19587      0.19411
alpha_5                               0.26193      0.00063     0.26309      0.26109
alpha_6                               0.08383      0.00009     0.08404      0.08375
alpha_7                               0.35506      0.00061     0.35607      0.35414
alpha_8                               0.26102      0.00245     0.26534      0.25715
alpha_9                               0.14240      0.00061     0.14359      0.14142
Alpha_loss                            1.03197      0.21608     1.61032      0.51187
Training/policy_loss                  91.48965     14.93633    122.97025    58.88591
Training/qf1_loss                     15098.08770  4987.11525  30384.61914  7052.95166
Training/qf2_loss                     1047.79449   347.02723   2181.44507   489.89883
Training/pf_norm                      12.76954     5.40482     29.28211     4.56499
Training/qf1_norm                     9054.14584   3881.18641  20138.16211  2641.39062
Training/qf2_norm                     3724.32655   1633.23311  8976.65039   1106.43152
log_std/mean                          -0.91889     0.01736     -0.88344     -0.95597
log_std/std                           0.47889      0.00483     0.49547      0.46664
log_std/max                           0.46359      0.21624     0.74564      -0.04263
log_std/min                           -2.85746     0.10984     -2.63542     -3.04514
log_probs/mean                        4.69091      0.15853     5.02387      4.26220
log_probs/std                         3.85596      0.10166     4.10011      3.63441
log_probs/max                         22.37727     2.13687     26.88508     17.82765
log_probs/min                         -6.34422     1.30080     -3.57491     -9.86828
mean/mean                             0.37026      0.02039     0.42792      0.33182
mean/std                              1.53983      0.02092     1.58064      1.47443
mean/max                              6.06919      0.32482     6.50369      5.10659
mean/min                              -4.81652     0.25605     -4.04273     -5.15909
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 0, 5, 3, 2, 6, 1, 7, 4]
replay_buffer._size: [37200 37200 37200 37200 37200 37200 37200 37200 37200 37200]
2023-08-12 12:15:44,857 MainThread INFO: EPOCH:226
2023-08-12 12:15:44,857 MainThread INFO: Time Consumed:9.066920280456543s
2023-08-12 12:15:44,857 MainThread INFO: Total Frames:370500s
  2%|▏         | 227/10000 [34:24<24:57:30,  9.19s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               832.57685
Train_Epoch_Reward                    8324.79255
Running_Training_Average_Rewards      918.65674
Explore_Time                          0.01158
Train___Time                          9.05059
Eval____Time                          0.00413
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.58339
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.43257
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.49121
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.43323
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.24292
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.90546
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.80676
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8855.02712
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -20.13357
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.22952
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75209      1.28861     9.97341      3.17548
alpha_0                               2.41291      0.00430     2.41866      2.40456
alpha_1                               0.43521      0.00116     0.43755      0.43307
alpha_2                               0.24341      0.00167     0.24629      0.24051
alpha_3                               0.14796      0.00183     0.15118      0.14489
alpha_4                               0.19726      0.00086     0.19890      0.19591
alpha_5                               0.26531      0.00134     0.26731      0.26311
alpha_6                               0.08435      0.00018     0.08469      0.08405
alpha_7                               0.35435      0.00025     0.35483      0.35406
alpha_8                               0.27063      0.00288     0.27509      0.26544
alpha_9                               0.14491      0.00062     0.14565      0.14363
Alpha_loss                            1.14396      0.17881     1.56520      0.68355
Training/policy_loss                  90.61610     14.67071    120.23108    44.20427
Training/qf1_loss                     15082.38123  4436.34192  35011.39453  5061.92529
Training/qf2_loss                     1110.14165   375.50325   2650.28760   598.80096
Training/pf_norm                      13.01621     5.80377     37.62222     4.65539
Training/qf1_norm                     8799.85434   4177.67777  22565.68945  2427.81982
Training/qf2_norm                     3863.58580   1806.15981  11373.95410  1365.54163
log_std/mean                          -0.91777     0.00948     -0.89144     -0.93878
log_std/std                           0.48185      0.00533     0.49668      0.46859
log_std/max                           0.46597      0.22032     0.70355      -0.01379
log_std/min                           -2.89213     0.11790     -2.65663     -3.02105
log_probs/mean                        4.78303      0.13855     5.07779      4.41849
log_probs/std                         3.83536      0.08690     4.01092      3.65816
log_probs/max                         22.55174     2.22384     26.95767     17.03012
log_probs/min                         -6.20196     1.25426     -3.99488     -10.03335
mean/mean                             0.34276      0.02933     0.39822      0.27021
mean/std                              1.56110      0.02090     1.61384      1.51790
mean/max                              6.06123      0.27243     6.46868      4.96539
mean/min                              -4.85585     0.26018     -4.11480     -5.16112
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 1, 7, 2, 8, 0, 9, 5, 6]
replay_buffer._size: [37350 37350 37350 37350 37350 37350 37350 37350 37350 37350]
2023-08-12 12:15:54,274 MainThread INFO: EPOCH:227
2023-08-12 12:15:54,274 MainThread INFO: Time Consumed:9.224076509475708s
2023-08-12 12:15:54,275 MainThread INFO: Total Frames:372000s
  2%|▏         | 228/10000 [34:33<25:06:45,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               848.02938
Train_Epoch_Reward                    7913.84599
Running_Training_Average_Rewards      847.24210
Explore_Time                          0.00902
Train___Time                          9.21065
Eval____Time                          0.00385
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.42109
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.51521
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.22317
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.50064
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.66947
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.01429
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.05874
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9022.40038
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.75106
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.95294
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65087      1.20659     9.83710      4.11905
alpha_0                               2.41576      0.00382     2.42043      2.40662
alpha_1                               0.44049      0.00166     0.44347      0.43761
alpha_2                               0.24930      0.00169     0.25218      0.24635
alpha_3                               0.15422      0.00158     0.15684      0.15125
alpha_4                               0.20042      0.00072     0.20161      0.19893
alpha_5                               0.26889      0.00091     0.27046      0.26733
alpha_6                               0.08506      0.00022     0.08550      0.08469
alpha_7                               0.35386      0.00029     0.35429      0.35338
alpha_8                               0.27941      0.00240     0.28354      0.27517
alpha_9                               0.14637      0.00036     0.14691      0.14566
Alpha_loss                            1.05836      0.17865     1.48984      0.65668
Training/policy_loss                  94.02293     13.42588    118.92383    52.72064
Training/qf1_loss                     13775.12513  4492.30949  28202.10352  5451.31982
Training/qf2_loss                     1096.94344   465.02506   4154.72510   435.65121
Training/pf_norm                      12.52425     5.82649     33.76788     4.57320
Training/qf1_norm                     8290.08551   3635.44189  22600.61523  2414.29297
Training/qf2_norm                     3607.92836   1695.40965  9647.06445   1314.04858
log_std/mean                          -0.90373     0.01568     -0.87542     -0.93291
log_std/std                           0.48536      0.00428     0.49959      0.47574
log_std/max                           0.41807      0.23424     0.75431      -0.05592
log_std/min                           -2.90739     0.07534     -2.70458     -3.01917
log_probs/mean                        4.69604      0.13192     5.06394      4.43613
log_probs/std                         3.82056      0.09718     4.05804      3.58285
log_probs/max                         23.28302     2.04912     26.74216     17.93047
log_probs/min                         -6.30535     1.26432     -4.16442     -9.28834
mean/mean                             0.34087      0.01975     0.39007      0.28671
mean/std                              1.55287      0.01912     1.59051      1.51559
mean/max                              6.08180      0.27640     6.43576      5.48982
mean/min                              -4.93589     0.25586     -4.12790     -5.23107
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 5, 4, 2, 0, 1, 6, 3, 9, 8]
replay_buffer._size: [37500 37500 37500 37500 37500 37500 37500 37500 37500 37500]
2023-08-12 12:16:02,933 MainThread INFO: EPOCH:228
2023-08-12 12:16:02,934 MainThread INFO: Time Consumed:8.445039510726929s
2023-08-12 12:16:02,934 MainThread INFO: Total Frames:373500s
  2%|▏         | 229/10000 [34:42<24:37:42,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               839.29381
Train_Epoch_Reward                    9277.14687
Running_Training_Average_Rewards      850.52618
Explore_Time                          0.00373
Train___Time                          8.43638
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.08759
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.79601
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.35385
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -70.31794
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.44720
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.76440
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.16844
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8944.76996
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.80148
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.09492
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.57173      1.13263     9.45080      3.93079
alpha_0                               2.39793      0.00400     2.40650      2.39302
alpha_1                               0.44740      0.00249     0.45158      0.44353
alpha_2                               0.25451      0.00136     0.25706      0.25223
alpha_3                               0.15992      0.00176     0.16280      0.15690
alpha_4                               0.20391      0.00147     0.20611      0.20164
alpha_5                               0.27065      0.00027     0.27134      0.27037
alpha_6                               0.08634      0.00053     0.08730      0.08551
alpha_7                               0.35064      0.00215     0.35349      0.34753
alpha_8                               0.28721      0.00224     0.29152      0.28362
alpha_9                               0.14744      0.00044     0.14822      0.14690
Alpha_loss                            1.09329      0.19532     1.65152      0.67493
Training/policy_loss                  90.91098     15.57879    130.00996    53.66762
Training/qf1_loss                     15514.97877  5569.51279  36926.46484  5901.07568
Training/qf2_loss                     1081.30190   355.65478   2197.64917   438.35205
Training/pf_norm                      12.12560     4.73491     22.86832     4.46268
Training/qf1_norm                     8215.98955   3646.80057  17846.78711  1704.96802
Training/qf2_norm                     3775.18160   1666.23203  10148.23535  1025.49231
log_std/mean                          -0.90586     0.01404     -0.87772     -0.93521
log_std/std                           0.48549      0.00613     0.50776      0.47471
log_std/max                           0.44574      0.20920     0.71269      0.01611
log_std/min                           -2.93199     0.10249     -2.73802     -3.10572
log_probs/mean                        4.67922      0.15686     5.06100      4.30626
log_probs/std                         3.83108      0.10219     4.09997      3.59745
log_probs/max                         23.16346     1.96885     26.82173     18.30943
log_probs/min                         -6.50523     1.52325     -4.33769     -12.79296
mean/mean                             0.37095      0.02818     0.44395      0.30238
mean/std                              1.54449      0.02332     1.60441      1.48961
mean/max                              6.13647      0.23751     6.43821      5.46411
mean/min                              -4.95088     0.25957     -4.19684     -5.31545
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 4, 6, 5, 1, 2, 7, 0, 9]
replay_buffer._size: [37650 37650 37650 37650 37650 37650 37650 37650 37650 37650]
2023-08-12 12:16:12,358 MainThread INFO: EPOCH:229
2023-08-12 12:16:12,358 MainThread INFO: Time Consumed:9.203750371932983s
2023-08-12 12:16:12,358 MainThread INFO: Total Frames:375000s
  2%|▏         | 230/10000 [34:51<24:54:52,  9.18s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               849.37395
Train_Epoch_Reward                    8371.65440
Running_Training_Average_Rewards      852.08824
Explore_Time                          0.01122
Train___Time                          9.18738
Eval____Time                          0.00412
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.86233
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.95039
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.98024
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -70.49493
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.56965
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.79159
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.12902
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9083.73643
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.23175
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.98697
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.84557      1.36493     10.07092     4.02242
alpha_0                               2.40379      0.00384     2.40863      2.39506
alpha_1                               0.45582      0.00229     0.45955      0.45165
alpha_2                               0.25976      0.00155     0.26225      0.25711
alpha_3                               0.16611      0.00208     0.16954      0.16284
alpha_4                               0.20865      0.00123     0.21023      0.20615
alpha_5                               0.27270      0.00100     0.27435      0.27135
alpha_6                               0.08843      0.00060     0.08946      0.08733
alpha_7                               0.34681      0.00032     0.34751      0.34624
alpha_8                               0.29622      0.00263     0.30021      0.29162
alpha_9                               0.14937      0.00070     0.15056      0.14824
Alpha_loss                            1.19626      0.20507     1.88938      0.79409
Training/policy_loss                  93.09545     15.69484    137.31995    47.91177
Training/qf1_loss                     15662.26776  4996.42883  37330.56641  6457.17383
Training/qf2_loss                     1145.52021   429.63433   2617.73755   478.09473
Training/pf_norm                      13.10403     5.70659     36.42228     5.08362
Training/qf1_norm                     8366.33551   4157.68864  31644.08984  2588.11182
Training/qf2_norm                     3808.91377   1564.57557  8937.02051   1107.66040
log_std/mean                          -0.89590     0.01674     -0.86379     -0.92444
log_std/std                           0.48488      0.00565     0.49757      0.46990
log_std/max                           0.52884      0.19050     0.76507      0.10588
log_std/min                           -2.96201     0.12426     -2.65895     -3.13254
log_probs/mean                        4.77049      0.16548     5.23462      4.43139
log_probs/std                         3.83296      0.11467     4.20380      3.59351
log_probs/max                         22.97876     2.23391     26.55862     17.26768
log_probs/min                         -6.51091     1.47387     -3.72587     -13.05367
mean/mean                             0.36171      0.03153     0.41952      0.29680
mean/std                              1.56421      0.02164     1.63054      1.52168
mean/max                              6.07604      0.25030     6.61505      5.37585
mean/min                              -4.85844     0.29445     -4.16268     -5.22490
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 5, 8, 4, 2, 0, 6, 9, 7, 3]
replay_buffer._size: [37800 37800 37800 37802 37800 37800 37800 37800 37802 37800]
2023-08-12 12:16:21,834 MainThread INFO: EPOCH:230
2023-08-12 12:16:21,835 MainThread INFO: Time Consumed:9.258216619491577s
2023-08-12 12:16:21,835 MainThread INFO: Total Frames:376500s
  2%|▏         | 231/10000 [35:00<25:08:52,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               819.53867
Train_Epoch_Reward                    7830.21444
Running_Training_Average_Rewards      849.30052
Explore_Time                          0.02629
Train___Time                          9.22556
Eval____Time                          0.00473
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.96728
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.23974
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.53489
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -71.56311
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.43898
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.37332
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.32161
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8784.65520
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.85223
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.97736
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.53805      1.38442     11.20603     3.93266
alpha_0                               2.38948      0.00728     2.39984      2.37259
alpha_1                               0.46375      0.00243     0.46822      0.45963
alpha_2                               0.26355      0.00057     0.26459      0.26230
alpha_3                               0.17292      0.00201     0.17626      0.16959
alpha_4                               0.21290      0.00166     0.21568      0.21025
alpha_5                               0.27561      0.00108     0.27748      0.27437
alpha_6                               0.09081      0.00074     0.09204      0.08948
alpha_7                               0.34138      0.00270     0.34622      0.33782
alpha_8                               0.30323      0.00170     0.30610      0.30028
alpha_9                               0.15139      0.00055     0.15228      0.15058
Alpha_loss                            0.98356      0.14485     1.33604      0.69449
Training/policy_loss                  93.01422     16.15539    128.71521    55.86893
Training/qf1_loss                     14776.96750  5174.93590  30358.93750  7129.15771
Training/qf2_loss                     1071.27208   428.00794   2415.80444   420.19199
Training/pf_norm                      14.32530     6.67300     38.61620     5.43232
Training/qf1_norm                     8713.36200   4115.46506  20361.98828  2295.79248
Training/qf2_norm                     4088.67369   1784.11258  10575.19922  1362.05493
log_std/mean                          -0.89012     0.01248     -0.85818     -0.91181
log_std/std                           0.49779      0.00467     0.51060      0.48334
log_std/max                           0.49772      0.18080     0.74028      0.09169
log_std/min                           -2.98708     0.16587     -2.72539     -3.22649
log_probs/mean                        4.55854      0.11810     4.89006      4.16818
log_probs/std                         3.78092      0.09777     4.00974      3.57655
log_probs/max                         23.60710     2.08696     27.63154     18.97264
log_probs/min                         -5.99367     1.04734     -3.88019     -9.20118
mean/mean                             0.38710      0.02524     0.44522      0.31315
mean/std                              1.52918      0.01820     1.57562      1.48531
mean/max                              6.40917      0.19506     6.71906      5.47765
mean/min                              -5.03924     0.32142     -4.23467     -5.40600
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 2, 9, 7, 4, 0, 1, 8, 5, 3]
replay_buffer._size: [37950 37950 37950 37950 37950 37950 37950 37950 37950 37950]
2023-08-12 12:16:30,537 MainThread INFO: EPOCH:231
2023-08-12 12:16:30,537 MainThread INFO: Time Consumed:8.503846406936646s
2023-08-12 12:16:30,537 MainThread INFO: Total Frames:378000s
  2%|▏         | 232/10000 [35:09<24:41:14,  9.10s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               846.65613
Train_Epoch_Reward                    7819.55872
Running_Training_Average_Rewards      800.71425
Explore_Time                          0.00525
Train___Time                          8.49339
Eval____Time                          0.00467
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.49783
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.58897
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -14.69936
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.99992
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.59832
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.71218
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.19202
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9048.66152
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.83457
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.97708
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.47267      1.39882     9.57907      3.44934
alpha_0                               2.36318      0.00340     2.37215      2.35822
alpha_1                               0.47095      0.00123     0.47302      0.46831
alpha_2                               0.26654      0.00115     0.26836      0.26462
alpha_3                               0.17910      0.00164     0.18195      0.17632
alpha_4                               0.21790      0.00132     0.21996      0.21572
alpha_5                               0.27926      0.00111     0.28114      0.27751
alpha_6                               0.09355      0.00091     0.09510      0.09206
alpha_7                               0.33508      0.00172     0.33777      0.33214
alpha_8                               0.30956      0.00208     0.31328      0.30616
alpha_9                               0.15315      0.00059     0.15426      0.15229
Alpha_loss                            1.05622      0.17633     1.42698      0.55390
Training/policy_loss                  95.10737     15.50714    132.01389    53.83190
Training/qf1_loss                     14116.00353  5150.43554  32621.73828  6642.18066
Training/qf2_loss                     1028.54406   356.09004   2196.34106   522.06836
Training/pf_norm                      13.52385     6.08606     39.27659     5.77814
Training/qf1_norm                     8717.63290   4297.87239  29459.00391  2978.19775
Training/qf2_norm                     3854.48128   1873.96885  11012.59863  1173.26257
log_std/mean                          -0.90540     0.00939     -0.88094     -0.92277
log_std/std                           0.50339      0.00565     0.51652      0.49084
log_std/max                           0.48566      0.15565     0.79582      0.10179
log_std/min                           -3.00660     0.20459     -2.73946     -3.29600
log_probs/mean                        4.62810      0.12496     4.93879      4.34369
log_probs/std                         3.76735      0.11160     4.11368      3.47483
log_probs/max                         23.78329     1.96981     27.62617     20.04933
log_probs/min                         -6.46089     1.69174     -3.89607     -13.81021
mean/mean                             0.38422      0.02361     0.43222      0.31311
mean/std                              1.53688      0.01831     1.57856      1.49582
mean/max                              6.58163      0.18212     6.84115      5.61750
mean/min                              -5.00710     0.23362     -4.24814     -5.36013
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 6, 4, 0, 5, 2, 7, 1, 3]
replay_buffer._size: [38100 38100 38100 38100 38100 38100 38100 38100 38100 38100]
2023-08-12 12:16:39,531 MainThread INFO: EPOCH:232
2023-08-12 12:16:39,532 MainThread INFO: Time Consumed:8.83310079574585s
2023-08-12 12:16:39,532 MainThread INFO: Total Frames:379500s
  2%|▏         | 233/10000 [35:18<24:37:34,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               852.44547
Train_Epoch_Reward                    7849.33399
Running_Training_Average_Rewards      783.30357
Explore_Time                          0.00761
Train___Time                          8.82008
Eval____Time                          0.00482
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.73001
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.26230
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.19338
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -77.61162
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.64211
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.55479
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.26442
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9125.91148
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.97421
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.22391
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56659      1.22851     9.41006      3.70723
alpha_0                               2.36485      0.00108     2.36648      2.36121
alpha_1                               0.47479      0.00120     0.47715      0.47304
alpha_2                               0.26968      0.00065     0.27074      0.26839
alpha_3                               0.18446      0.00151     0.18721      0.18201
alpha_4                               0.22110      0.00104     0.22311      0.21999
alpha_5                               0.28243      0.00057     0.28354      0.28117
alpha_6                               0.09636      0.00072     0.09758      0.09513
alpha_7                               0.32934      0.00174     0.33207      0.32651
alpha_8                               0.31694      0.00186     0.32019      0.31336
alpha_9                               0.15593      0.00097     0.15775      0.15429
Alpha_loss                            0.81666      0.15630     1.32658      0.50870
Training/policy_loss                  91.73425     17.72590    132.99666    41.33252
Training/qf1_loss                     14540.89963  5479.62282  37668.77734  6623.92529
Training/qf2_loss                     1059.26893   409.41922   2525.44141   452.89102
Training/pf_norm                      14.24708     6.36393     42.22975     4.62660
Training/qf1_norm                     8342.10418   3813.30659  23468.85938  2371.76880
Training/qf2_norm                     3474.17445   1545.73374  9576.99414   1208.64258
log_std/mean                          -0.89385     0.01646     -0.86031     -0.93290
log_std/std                           0.50739      0.00532     0.51881      0.49650
log_std/max                           0.42266      0.14108     0.73715      0.06960
log_std/min                           -3.04594     0.22906     -2.74761     -3.31567
log_probs/mean                        4.48796      0.11567     4.90213      4.20846
log_probs/std                         3.74525      0.10505     3.99386      3.48401
log_probs/max                         23.84207     2.20380     27.36062     18.66711
log_probs/min                         -6.66795     1.46789     -3.33001     -13.59978
mean/mean                             0.35982      0.03517     0.45064      0.28096
mean/std                              1.51990      0.01593     1.55666      1.48416
mean/max                              6.45551      0.23778     6.75394      5.61871
mean/min                              -5.18638     0.29580     -4.46805     -5.68159
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 6, 4, 5, 9, 0, 2, 1, 3, 8]
replay_buffer._size: [38250 38250 38250 38250 38250 38250 38250 38250 38250 38250]
2023-08-12 12:16:48,136 MainThread INFO: EPOCH:233
2023-08-12 12:16:48,136 MainThread INFO: Time Consumed:8.438834428787231s
2023-08-12 12:16:48,136 MainThread INFO: Total Frames:381000s
  2%|▏         | 234/10000 [35:27<24:13:01,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               897.73662
Train_Epoch_Reward                    8147.17271
Running_Training_Average_Rewards      793.86885
Explore_Time                          0.00449
Train___Time                          8.42970
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.57773
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.95086
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.27851
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.49600
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.51006
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.66410
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.11259
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9584.46724
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -86.66095
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.85026
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.66250      1.44880     10.46334     3.30018
alpha_0                               2.35753      0.00107     2.36094      2.35582
alpha_1                               0.48027      0.00193     0.48352      0.47719
alpha_2                               0.27159      0.00040     0.27232      0.27077
alpha_3                               0.19056      0.00215     0.19448      0.18727
alpha_4                               0.22461      0.00111     0.22628      0.22313
alpha_5                               0.28397      0.00017     0.28432      0.28357
alpha_6                               0.09859      0.00058     0.09954      0.09760
alpha_7                               0.32535      0.00083     0.32649      0.32418
alpha_8                               0.32369      0.00185     0.32678      0.32028
alpha_9                               0.16046      0.00182     0.16387      0.15779
Alpha_loss                            0.75141      0.15240     1.11910      0.35795
Training/policy_loss                  92.93380     15.93887    139.47447    50.58898
Training/qf1_loss                     14376.01831  4072.93488  24392.68750  6836.42334
Training/qf2_loss                     1078.91931   374.27716   2136.16895   455.85864
Training/pf_norm                      12.79851     5.89042     38.11491     4.00471
Training/qf1_norm                     8854.07989   3695.69770  21530.35352  3658.27002
Training/qf2_norm                     4413.63097   2167.57179  11488.97266  1125.59131
log_std/mean                          -0.88760     0.01093     -0.85567     -0.91430
log_std/std                           0.50945      0.00461     0.52188      0.50047
log_std/max                           0.40714      0.11940     0.67263      0.05310
log_std/min                           -2.99404     0.25782     -2.70489     -3.38223
log_probs/mean                        4.46816      0.10868     4.69025      4.17174
log_probs/std                         3.74127      0.09804     3.98882      3.55166
log_probs/max                         24.00357     1.98808     28.06171     19.83035
log_probs/min                         -6.29674     1.18953     -4.00748     -12.15652
mean/mean                             0.33217      0.03077     0.42718      0.25694
mean/std                              1.52047      0.01576     1.56778      1.47851
mean/max                              6.30622      0.21791     6.65824      5.59031
mean/min                              -5.40637     0.39901     -4.15194     -5.90688
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 5, 4, 7, 2, 1, 3, 0, 8, 6]
replay_buffer._size: [38400 38400 38400 38400 38400 38400 38400 38400 38400 38400]
2023-08-12 12:16:57,735 MainThread INFO: EPOCH:234
2023-08-12 12:16:57,736 MainThread INFO: Time Consumed:9.407826900482178s
2023-08-12 12:16:57,736 MainThread INFO: Total Frames:382500s
  2%|▏         | 235/10000 [35:36<24:45:44,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               863.86873
Train_Epoch_Reward                    9451.58399
Running_Training_Average_Rewards      848.26969
Explore_Time                          0.02181
Train___Time                          9.38073
Eval____Time                          0.00466
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.07207
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.02200
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.12526
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.65397
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.45729
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.41422
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.17348
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9240.08652
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.93866
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.54225
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68413      1.25615     9.80043      3.75954
alpha_0                               2.35668      0.00326     2.36197      2.35140
alpha_1                               0.48706      0.00204     0.49016      0.48358
alpha_2                               0.27334      0.00062     0.27451      0.27235
alpha_3                               0.19859      0.00244     0.20287      0.19456
alpha_4                               0.22752      0.00094     0.22943      0.22628
alpha_5                               0.28513      0.00093     0.28730      0.28433
alpha_6                               0.10050      0.00058     0.10157      0.09956
alpha_7                               0.32296      0.00084     0.32434      0.32113
alpha_8                               0.32963      0.00158     0.33233      0.32685
alpha_9                               0.16804      0.00268     0.17262      0.16394
Alpha_loss                            0.84595      0.20238     1.29289      0.28758
Training/policy_loss                  93.96873     16.35705    133.01619    58.15118
Training/qf1_loss                     15465.94654  5225.46808  29946.14453  7071.99072
Training/qf2_loss                     1050.24795   387.48261   2537.58813   424.04123
Training/pf_norm                      13.16991     4.79956     26.29919     5.10804
Training/qf1_norm                     8629.96424   3870.04367  19426.35547  2436.87476
Training/qf2_norm                     4484.18007   2280.66030  12731.04883  874.36902
log_std/mean                          -0.89065     0.02338     -0.85252     -0.93498
log_std/std                           0.51014      0.00423     0.51859      0.50058
log_std/max                           0.39216      0.11948     0.73544      0.10065
log_std/min                           -3.06757     0.28565     -2.70421     -3.46885
log_probs/mean                        4.53870      0.16429     4.87065      4.02479
log_probs/std                         3.76466      0.09406     4.07827      3.50108
log_probs/max                         24.04208     1.80491     27.64681     20.33783
log_probs/min                         -6.60526     1.48964     -4.29896     -11.84145
mean/mean                             0.35046      0.02526     0.41646      0.29938
mean/std                              1.52508      0.01897     1.57122      1.46464
mean/max                              6.31456      0.26521     6.70669      4.77273
mean/min                              -5.41971     0.33992     -4.51421     -5.99138
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 1, 2, 7, 9, 8, 3, 5, 0, 4]
replay_buffer._size: [38550 38550 38550 38550 38550 38550 38550 38550 38550 38550]
2023-08-12 12:17:07,281 MainThread INFO: EPOCH:235
2023-08-12 12:17:07,281 MainThread INFO: Time Consumed:9.389816999435425s
2023-08-12 12:17:07,281 MainThread INFO: Total Frames:384000s
  2%|▏         | 236/10000 [35:46<25:05:36,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               857.75025
Train_Epoch_Reward                    9259.35991
Running_Training_Average_Rewards      895.27055
Explore_Time                          0.00461
Train___Time                          9.38116
Eval____Time                          0.00353
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.59915
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.20831
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.17144
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -84.18531
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.76361
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.53298
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.18443
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9175.52467
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.41423
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.96274
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.83999      1.37620     10.53032     3.33309
alpha_0                               2.36333      0.00107     2.36550      2.36089
alpha_1                               0.49172      0.00101     0.49302      0.49018
alpha_2                               0.27540      0.00064     0.27684      0.27452
alpha_3                               0.20654      0.00205     0.21000      0.20295
alpha_4                               0.23171      0.00120     0.23367      0.22948
alpha_5                               0.29033      0.00162     0.29268      0.28736
alpha_6                               0.10285      0.00076     0.10420      0.10159
alpha_7                               0.31879      0.00108     0.32107      0.31680
alpha_8                               0.33444      0.00126     0.33651      0.33237
alpha_9                               0.17656      0.00230     0.18040      0.17269
Alpha_loss                            0.86239      0.14614     1.19182      0.38632
Training/policy_loss                  93.26442     16.82916    131.71980    51.41861
Training/qf1_loss                     14562.98034  4600.36502  29551.53711  5968.83887
Training/qf2_loss                     1158.10073   376.14618   2240.00391   482.72574
Training/pf_norm                      14.17141     6.96942     40.12875     4.55230
Training/qf1_norm                     8905.44058   4114.45544  26206.32422  2065.79102
Training/qf2_norm                     4947.08949   2418.66380  11718.08301  1381.04993
log_std/mean                          -0.87294     0.00777     -0.85429     -0.88973
log_std/std                           0.50202      0.00613     0.51476      0.48817
log_std/max                           0.42227      0.10748     0.68135      0.11964
log_std/min                           -3.10207     0.29604     -2.64943     -3.42546
log_probs/mean                        4.51968      0.10805     4.83366      4.21741
log_probs/std                         3.74252      0.10283     4.00641      3.47106
log_probs/max                         23.59574     1.92373     27.72723     18.90241
log_probs/min                         -6.52911     1.31250     -3.75427     -10.56849
mean/mean                             0.36257      0.02325     0.42663      0.31392
mean/std                              1.52814      0.01700     1.57499      1.49021
mean/max                              6.25783      0.31395     6.75687      4.56393
mean/min                              -5.29689     0.39882     -4.21836     -5.76491
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 0, 5, 2, 4, 1, 7, 3, 6, 8]
replay_buffer._size: [38700 38700 38700 38700 38700 38700 38700 38700 38700 38700]
2023-08-12 12:17:16,259 MainThread INFO: EPOCH:236
2023-08-12 12:17:16,260 MainThread INFO: Time Consumed:8.78885269165039s
2023-08-12 12:17:16,260 MainThread INFO: Total Frames:385500s
  2%|▏         | 237/10000 [35:55<24:53:24,  9.18s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               904.68605
Train_Epoch_Reward                    8536.01810
Running_Training_Average_Rewards      908.23207
Explore_Time                          0.00442
Train___Time                          8.77942
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.17423
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.38334
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.41848
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.14421
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.94444
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.39825
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.15510
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9648.09958
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -81.86168
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.75931
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80656      1.25590     9.96160      4.12950
alpha_0                               2.36178      0.00602     2.37434      2.35587
alpha_1                               0.49585      0.00215     0.49885      0.49281
alpha_2                               0.27824      0.00095     0.28013      0.27688
alpha_3                               0.21319      0.00182     0.21620      0.21006
alpha_4                               0.23632      0.00131     0.23788      0.23372
alpha_5                               0.29393      0.00063     0.29488      0.29271
alpha_6                               0.10604      0.00107     0.10787      0.10424
alpha_7                               0.31428      0.00109     0.31673      0.31309
alpha_8                               0.33813      0.00130     0.34089      0.33653
alpha_9                               0.18424      0.00225     0.18799      0.18048
Alpha_loss                            0.91766      0.16690     1.39953      0.52342
Training/policy_loss                  94.05763     16.02774    128.61449    55.30207
Training/qf1_loss                     15169.31957  5536.89475  37245.23828  5669.12939
Training/qf2_loss                     1095.22896   403.36437   2408.95630   500.76218
Training/pf_norm                      15.20929     7.25882     49.62972     4.52789
Training/qf1_norm                     8795.78683   4327.20040  29642.13281  2824.78979
Training/qf2_norm                     3481.57524   1527.46030  9432.75781   1014.83807
log_std/mean                          -0.86662     0.01146     -0.84753     -0.90160
log_std/std                           0.49443      0.00617     0.51130      0.48205
log_std/max                           0.41515      0.11371     0.77219      0.05526
log_std/min                           -3.04008     0.32037     -2.65211     -3.45491
log_probs/mean                        4.58205      0.14211     5.02216      4.30271
log_probs/std                         3.81747      0.10636     4.09041      3.53471
log_probs/max                         24.14419     2.29018     28.24734     17.32331
log_probs/min                         -6.70017     1.68279     -3.71104     -12.29626
mean/mean                             0.35785      0.03127     0.40480      0.26543
mean/std                              1.54806      0.02161     1.60995      1.50359
mean/max                              6.19322      0.33165     6.80274      5.42643
mean/min                              -5.39939     0.32278     -4.20726     -5.78861
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 9, 1, 5, 4, 7, 6, 3, 2]
replay_buffer._size: [38850 38850 38850 38850 38850 38850 38850 38850 38850 38850]
2023-08-12 12:17:24,912 MainThread INFO: EPOCH:237
2023-08-12 12:17:24,912 MainThread INFO: Time Consumed:8.51551604270935s
2023-08-12 12:17:24,912 MainThread INFO: Total Frames:387000s
  2%|▏         | 238/10000 [36:04<24:26:16,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               911.02732
Train_Epoch_Reward                    10064.75015
Running_Training_Average_Rewards      928.67094
Explore_Time                          0.00389
Train___Time                          8.50531
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.20802
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.94419
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -16.68146
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.11617
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.79899
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.68952
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.29146
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9709.17529
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.40566
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.76659
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89670      1.30769     10.38566     4.28909
alpha_0                               2.37745      0.00215     2.38020      2.37170
alpha_1                               0.49738      0.00061     0.49868      0.49643
alpha_2                               0.28023      0.00040     0.28073      0.27951
alpha_3                               0.21774      0.00107     0.21988      0.21625
alpha_4                               0.23804      0.00059     0.23953      0.23746
alpha_5                               0.29810      0.00192     0.30127      0.29492
alpha_6                               0.10974      0.00113     0.11176      0.10790
alpha_7                               0.31173      0.00115     0.31335      0.30950
alpha_8                               0.34175      0.00026     0.34216      0.34096
alpha_9                               0.19096      0.00176     0.19399      0.18806
Alpha_loss                            0.63503      0.14735     1.02367      0.29300
Training/policy_loss                  95.01419     15.00518    136.44762    47.95598
Training/qf1_loss                     14583.53957  4305.65935  24685.56250  7467.23047
Training/qf2_loss                     1073.88145   408.74273   2547.21313   494.25439
Training/pf_norm                      13.86298     6.55495     34.58016     5.24517
Training/qf1_norm                     9226.74894   4013.84251  19470.62695  3805.31445
Training/qf2_norm                     4166.00207   1754.95124  8758.32910   1061.44238
log_std/mean                          -0.86250     0.01228     -0.84237     -0.89766
log_std/std                           0.49931      0.00580     0.51170      0.48400
log_std/max                           0.35409      0.12937     0.73099      0.08423
log_std/min                           -3.04290     0.31207     -2.62237     -3.47719
log_probs/mean                        4.31927      0.12017     4.61502      4.00534
log_probs/std                         3.74350      0.09727     4.03113      3.50618
log_probs/max                         23.96385     1.96828     28.11780     18.25805
log_probs/min                         -6.42853     1.20406     -4.07720     -9.08432
mean/mean                             0.37852      0.03897     0.46127      0.26007
mean/std                              1.49613      0.02180     1.54840      1.44935
mean/max                              6.30525      0.32417     6.87911      5.49282
mean/min                              -5.31743     0.41314     -3.84122     -5.90792
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 9, 3, 2, 8, 1, 5, 6, 4, 7]
replay_buffer._size: [39000 39000 39000 39000 39000 39000 39000 39000 39000 39000]
2023-08-12 12:17:34,254 MainThread INFO: EPOCH:238
2023-08-12 12:17:34,254 MainThread INFO: Time Consumed:9.157121419906616s
2023-08-12 12:17:34,254 MainThread INFO: Total Frames:388500s
  2%|▏         | 239/10000 [36:13<24:42:29,  9.11s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               937.87800
Train_Epoch_Reward                    8539.90114
Running_Training_Average_Rewards      904.68898
Explore_Time                          0.00517
Train___Time                          9.14689
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.50128
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.24454
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.82559
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.08629
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.27323
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.90461
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.82272
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9972.64530
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.26829
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.93875
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.58179      1.40148     10.31852     2.71880
alpha_0                               2.36057      0.00631     2.37150      2.34922
alpha_1                               0.49946      0.00135     0.50126      0.49763
alpha_2                               0.27959      0.00033     0.28008      0.27920
alpha_3                               0.22352      0.00218     0.22703      0.21994
alpha_4                               0.24276      0.00188     0.24580      0.23958
alpha_5                               0.30327      0.00082     0.30410      0.30133
alpha_6                               0.11384      0.00113     0.11568      0.11180
alpha_7                               0.30765      0.00110     0.30942      0.30556
alpha_8                               0.34158      0.00008     0.34168      0.34135
alpha_9                               0.19759      0.00208     0.20114      0.19405
Alpha_loss                            0.78042      0.19372     1.16779      0.36134
Training/policy_loss                  97.25535     17.27950    137.81540    51.05833
Training/qf1_loss                     14971.40419  5486.79634  35159.47656  6513.96338
Training/qf2_loss                     1033.99731   384.07464   2391.53979   479.14630
Training/pf_norm                      14.06927     7.06820     36.44150     5.53147
Training/qf1_norm                     9126.41471   4891.18416  31104.63867  2979.00854
Training/qf2_norm                     3934.91839   1978.77821  10796.89551  918.16882
log_std/mean                          -0.87194     0.01233     -0.84079     -0.89810
log_std/std                           0.49902      0.00540     0.51430      0.48128
log_std/max                           0.41078      0.18079     0.89447      0.12001
log_std/min                           -3.10717     0.35432     -2.65646     -3.54158
log_probs/mean                        4.42303      0.16385     4.75049      4.05808
log_probs/std                         3.82257      0.11111     4.09678      3.50108
log_probs/max                         24.66505     1.93215     27.95186     19.11128
log_probs/min                         -6.55508     1.51668     -3.76614     -10.73623
mean/mean                             0.39676      0.02287     0.44875      0.34424
mean/std                              1.50620      0.02275     1.56106      1.45418
mean/max                              6.29380      0.23118     6.76206      5.64139
mean/min                              -5.45580     0.37744     -3.82308     -5.82610
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 1, 0, 5, 6, 7, 9, 2, 4]
replay_buffer._size: [39150 39150 39150 39150 39150 39150 39150 39150 39150 39150]
2023-08-12 12:17:43,181 MainThread INFO: EPOCH:239
2023-08-12 12:17:43,181 MainThread INFO: Time Consumed:8.71251392364502s
2023-08-12 12:17:43,181 MainThread INFO: Total Frames:390000s
  2%|▏         | 240/10000 [36:22<24:33:10,  9.06s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               820.25571
Train_Epoch_Reward                    9336.30094
Running_Training_Average_Rewards      931.36507
Explore_Time                          0.00484
Train___Time                          8.70349
Eval____Time                          0.00364
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.82408
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.86356
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.41589
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.41008
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.68881
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.57201
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.08232
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8802.96984
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.87705
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.67890
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65026      1.24250     9.57033      3.34731
alpha_0                               2.34635      0.00175     2.34938      2.34385
alpha_1                               0.50262      0.00064     0.50332      0.50127
alpha_2                               0.27938      0.00022     0.27990      0.27899
alpha_3                               0.22980      0.00124     0.23175      0.22711
alpha_4                               0.24782      0.00096     0.24981      0.24586
alpha_5                               0.30654      0.00175     0.30966      0.30408
alpha_6                               0.11749      0.00105     0.11936      0.11572
alpha_7                               0.30481      0.00031     0.30554      0.30395
alpha_8                               0.34202      0.00029     0.34226      0.34135
alpha_9                               0.20395      0.00149     0.20647      0.20120
Alpha_loss                            0.62198      0.13543     1.04050      0.27365
Training/policy_loss                  93.80031     18.02621    136.38020    30.48102
Training/qf1_loss                     15006.79646  5205.61801  28080.47852  7511.80713
Training/qf2_loss                     1024.63528   354.84612   2604.12305   494.77841
Training/pf_norm                      12.37555     5.38647     32.36552     4.18307
Training/qf1_norm                     8801.96033   3807.90408  20815.21484  2344.51562
Training/qf2_norm                     4145.80695   1831.84009  9288.49805   982.54199
log_std/mean                          -0.86335     0.00847     -0.84229     -0.87969
log_std/std                           0.49157      0.00541     0.50514      0.47793
log_std/max                           0.40566      0.18368     0.95301      0.18309
log_std/min                           -3.06061     0.35429     -2.57311     -3.48345
log_probs/mean                        4.35408      0.10954     4.61098      3.98784
log_probs/std                         3.74417      0.10187     3.99413      3.49266
log_probs/max                         23.69402     1.73457     26.85861     18.49374
log_probs/min                         -6.52990     1.32962     -4.17690     -11.52550
mean/mean                             0.37991      0.02767     0.46179      0.31919
mean/std                              1.49898      0.01699     1.53820      1.45792
mean/max                              6.30515      0.30265     6.80159      5.64061
mean/min                              -5.31762     0.32088     -4.24624     -5.78262
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 6, 4, 0, 8, 9, 1, 7, 5, 3]
replay_buffer._size: [39300 39300 39300 39300 39300 39300 39300 39300 39300 39300]
2023-08-12 12:17:52,705 MainThread INFO: EPOCH:240
2023-08-12 12:17:52,707 MainThread INFO: Time Consumed:9.358838319778442s
2023-08-12 12:17:52,707 MainThread INFO: Total Frames:391500s
  2%|▏         | 241/10000 [36:31<25:00:17,  9.22s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               798.01185
Train_Epoch_Reward                    8690.66852
Running_Training_Average_Rewards      885.56235
Explore_Time                          0.00474
Train___Time                          9.34913
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.39178
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.93580
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -60.09442
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -87.09002
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.84174
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.40165
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.31058
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8616.63837
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.26419
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.18973
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.86555      1.14679     10.73818     3.93233
alpha_0                               2.34613      0.00298     2.35153      2.34243
alpha_1                               0.50435      0.00105     0.50700      0.50314
alpha_2                               0.27828      0.00036     0.27897      0.27776
alpha_3                               0.23334      0.00080     0.23463      0.23180
alpha_4                               0.25411      0.00237     0.25833      0.24990
alpha_5                               0.31300      0.00155     0.31512      0.30974
alpha_6                               0.12166      0.00132     0.12390      0.11940
alpha_7                               0.30213      0.00133     0.30389      0.29974
alpha_8                               0.34169      0.00017     0.34200      0.34143
alpha_9                               0.20826      0.00081     0.20963      0.20652
Alpha_loss                            0.65380      0.17338     1.05995      0.18383
Training/policy_loss                  97.05480     15.19718    131.49359    58.64036
Training/qf1_loss                     15090.13721  5181.36458  35245.07422  6680.60156
Training/qf2_loss                     1075.30038   408.37207   2647.95630   432.05890
Training/pf_norm                      13.78464     5.53748     32.24207     5.66577
Training/qf1_norm                     8813.87746   3812.00984  20838.86133  2735.92944
Training/qf2_norm                     4003.41715   1608.96055  9423.20605   1182.90918
log_std/mean                          -0.85173     0.01483     -0.82024     -0.88057
log_std/std                           0.49506      0.00508     0.50635      0.48175
log_std/max                           0.36232      0.17541     0.85256      0.16282
log_std/min                           -3.05711     0.36609     -2.59792     -3.49530
log_probs/mean                        4.36184      0.14890     4.76540      4.01833
log_probs/std                         3.73715      0.11322     3.95401      3.49532
log_probs/max                         23.81566     1.75930     27.69833     17.79598
log_probs/min                         -6.71186     1.32036     -4.17443     -11.65076
mean/mean                             0.44826      0.02221     0.50450      0.38304
mean/std                              1.49304      0.01808     1.54428      1.45247
mean/max                              6.69092      0.29917     7.08517      5.38523
mean/min                              -5.30344     0.24659     -4.05395     -5.71203
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 1, 2, 7, 5, 8, 3, 0, 6, 4]
replay_buffer._size: [39450 39450 39450 39450 39450 39450 39450 39450 39450 39450]
2023-08-12 12:18:01,779 MainThread INFO: EPOCH:241
2023-08-12 12:18:01,780 MainThread INFO: Time Consumed:8.85316014289856s
2023-08-12 12:18:01,780 MainThread INFO: Total Frames:393000s
  2%|▏         | 242/10000 [36:40<24:48:17,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               901.81028
Train_Epoch_Reward                    8095.30489
Running_Training_Average_Rewards      870.74248
Explore_Time                          0.01351
Train___Time                          8.83534
Eval____Time                          0.00364
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.55215
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.13105
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.92100
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -87.13427
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.23510
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.56687
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.16523
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9612.02025
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.54022
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.67160
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.55778      1.21520     10.09338     3.75117
alpha_0                               2.33438      0.00522     2.34259      2.32478
alpha_1                               0.50695      0.00061     0.50762      0.50588
alpha_2                               0.27769      0.00025     0.27790      0.27699
alpha_3                               0.23523      0.00052     0.23652      0.23465
alpha_4                               0.26180      0.00197     0.26541      0.25841
alpha_5                               0.31732      0.00129     0.31926      0.31515
alpha_6                               0.12606      0.00119     0.12811      0.12395
alpha_7                               0.29680      0.00151     0.29967      0.29370
alpha_8                               0.34201      0.00045     0.34250      0.34100
alpha_9                               0.21076      0.00064     0.21179      0.20966
Alpha_loss                            0.51737      0.13712     0.85247      0.14174
Training/policy_loss                  97.40218     16.68501    133.29665    62.03889
Training/qf1_loss                     13974.04239  4987.95146  30179.39062  6383.34863
Training/qf2_loss                     1078.15044   437.72628   2692.05444   437.74307
Training/pf_norm                      13.53785     5.42639     28.12085     4.37843
Training/qf1_norm                     8426.07335   3984.89139  21965.11133  2363.56519
Training/qf2_norm                     4127.00638   2215.28015  12245.93164  1449.88159
log_std/mean                          -0.85958     0.00872     -0.83881     -0.87899
log_std/std                           0.48738      0.00509     0.50073      0.47288
log_std/max                           0.39140      0.17510     0.82764      0.15751
log_std/min                           -3.06089     0.39615     -2.52817     -3.52873
log_probs/mean                        4.24635      0.10934     4.51796      3.98816
log_probs/std                         3.69652      0.10771     3.95108      3.42197
log_probs/max                         23.42211     1.68879     26.74464     18.49806
log_probs/min                         -6.54967     1.22279     -4.17139     -9.31222
mean/mean                             0.42760      0.02964     0.48985      0.36096
mean/std                              1.47262      0.01703     1.50712      1.43247
mean/max                              6.43925      0.23029     6.79663      5.41773
mean/min                              -5.20609     0.26381     -4.07536     -5.48557
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 5, 4, 8, 2, 1, 9, 0, 7]
replay_buffer._size: [39600 39600 39600 39600 39600 39600 39600 39600 39600 39600]
2023-08-12 12:18:10,942 MainThread INFO: EPOCH:242
2023-08-12 12:18:10,943 MainThread INFO: Time Consumed:8.930551767349243s
2023-08-12 12:18:10,943 MainThread INFO: Total Frames:394500s
  2%|▏         | 243/10000 [36:50<24:48:37,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               814.95009
Train_Epoch_Reward                    8920.06408
Running_Training_Average_Rewards      856.86792
Explore_Time                          0.00485
Train___Time                          8.92108
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.61496
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.73018
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -70.17092
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.74880
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.07164
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.69204
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.38280
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8792.97293
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.38735
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.67337
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.69178      1.32175     11.26440     4.10248
alpha_0                               2.32341      0.00228     2.32661      2.31921
alpha_1                               0.50688      0.00034     0.50734      0.50607
alpha_2                               0.27668      0.00008     0.27696      0.27659
alpha_3                               0.23771      0.00056     0.23854      0.23657
alpha_4                               0.26792      0.00127     0.27002      0.26549
alpha_5                               0.32166      0.00131     0.32337      0.31931
alpha_6                               0.13058      0.00144     0.13304      0.12816
alpha_7                               0.29189      0.00139     0.29362      0.28908
alpha_8                               0.34118      0.00021     0.34159      0.34090
alpha_9                               0.21258      0.00031     0.21300      0.21183
Alpha_loss                            0.55099      0.13006     0.90800      0.23179
Training/policy_loss                  97.40112     16.85239    143.86626    45.61067
Training/qf1_loss                     14450.91246  4491.95698  29370.21875  6747.79395
Training/qf2_loss                     1050.81792   438.91970   2882.07544   506.71945
Training/pf_norm                      13.73417     5.83087     28.00754     4.40081
Training/qf1_norm                     8969.15830   4175.22696  24484.60547  3425.64819
Training/qf2_norm                     4310.89305   1888.17981  9995.26660   1363.11804
log_std/mean                          -0.85080     0.01120     -0.82800     -0.87617
log_std/std                           0.48881      0.00450     0.50034      0.47949
log_std/max                           0.35286      0.15322     0.83066      0.18356
log_std/min                           -3.05981     0.38852     -2.55985     -3.53452
log_probs/mean                        4.29992      0.11192     4.65993      4.08386
log_probs/std                         3.71303      0.09411     4.02247      3.46984
log_probs/max                         22.97563     1.50755     25.70999     17.80236
log_probs/min                         -6.51354     1.37544     -3.59280     -11.61999
mean/mean                             0.43808      0.02059     0.49827      0.38398
mean/std                              1.48723      0.01704     1.52814      1.45513
mean/max                              6.42927      0.28371     6.66640      4.38350
mean/min                              -5.04946     0.20624     -4.10096     -5.33951
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 3, 6, 9, 2, 4, 8, 7, 0, 5]
replay_buffer._size: [39750 39750 39750 39750 39750 39750 39750 39750 39750 39750]
2023-08-12 12:18:20,355 MainThread INFO: EPOCH:243
2023-08-12 12:18:20,355 MainThread INFO: Time Consumed:9.214241027832031s
2023-08-12 12:18:20,355 MainThread INFO: Total Frames:396000s
  2%|▏         | 244/10000 [36:59<25:02:33,  9.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               849.01323
Train_Epoch_Reward                    8926.08438
Running_Training_Average_Rewards      864.71511
Explore_Time                          0.00501
Train___Time                          9.20526
Eval____Time                          0.00341
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.20880
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.27033
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.07383
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.49445
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.96772
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.51067
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.35782
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9138.61836
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.16683
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.43557
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.88650      1.45021     10.86740     3.84705
alpha_0                               2.31748      0.00453     2.32446      2.31056
alpha_1                               0.50553      0.00050     0.50648      0.50490
alpha_2                               0.27667      0.00007     0.27676      0.27658
alpha_3                               0.23900      0.00016     0.23919      0.23855
alpha_4                               0.27276      0.00167     0.27538      0.27006
alpha_5                               0.32227      0.00074     0.32332      0.32121
alpha_6                               0.13566      0.00148     0.13814      0.13309
alpha_7                               0.28295      0.00364     0.28900      0.27742
alpha_8                               0.34069      0.00057     0.34160      0.33998
alpha_9                               0.21327      0.00029     0.21391      0.21299
Alpha_loss                            0.42490      0.15759     0.81105      -0.00029
Training/policy_loss                  94.93009     17.01038    133.70421    59.77626
Training/qf1_loss                     15075.47716  5201.07238  33947.67969  6012.91748
Training/qf2_loss                     1057.42050   412.70946   2500.02637   506.52637
Training/pf_norm                      13.72696     5.65859     31.42889     4.09858
Training/qf1_norm                     9359.07200   4477.24064  28794.62891  3438.62695
Training/qf2_norm                     3677.60982   1897.51628  10056.39941  974.81177
log_std/mean                          -0.84934     0.02034     -0.81255     -0.88620
log_std/std                           0.49326      0.00424     0.50464      0.48325
log_std/max                           0.33629      0.16349     0.83940      0.10194
log_std/min                           -3.09087     0.42591     -2.55936     -3.60770
log_probs/mean                        4.17288      0.12603     4.43951      3.86314
log_probs/std                         3.68072      0.09907     3.89701      3.39446
log_probs/max                         23.38236     1.49586     26.64089     18.97488
log_probs/min                         -6.51248     1.28005     -4.30807     -11.55264
mean/mean                             0.46291      0.01995     0.50853      0.41386
mean/std                              1.46287      0.01753     1.50056      1.41232
mean/max                              6.74092      0.38706     7.01944      4.36560
mean/min                              -5.09180     0.22369     -4.28843     -5.50927
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 1, 2, 4, 5, 0, 6, 3, 7]
replay_buffer._size: [39900 39900 39900 39900 39900 39900 39900 39900 39900 39900]
2023-08-12 12:18:29,969 MainThread INFO: EPOCH:244
2023-08-12 12:18:29,969 MainThread INFO: Time Consumed:9.450283288955688s
2023-08-12 12:18:29,969 MainThread INFO: Total Frames:397500s
  2%|▏         | 245/10000 [37:09<25:20:34,  9.35s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               823.06058
Train_Epoch_Reward                    9324.91047
Running_Training_Average_Rewards      905.70196
Explore_Time                          0.00427
Train___Time                          9.44084
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.55498
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.13412
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.69165
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.41921
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.44998
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.85204
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.41970
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8885.13548
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.30588
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.70216
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70542      1.24393     10.39592     3.79423
alpha_0                               2.30917      0.00157     2.31179      2.30640
alpha_1                               0.50532      0.00065     0.50603      0.50401
alpha_2                               0.27664      0.00007     0.27674      0.27641
alpha_3                               0.23986      0.00027     0.24017      0.23920
alpha_4                               0.27736      0.00086     0.27818      0.27542
alpha_5                               0.32043      0.00056     0.32125      0.31951
alpha_6                               0.14051      0.00126     0.14253      0.13819
alpha_7                               0.27370      0.00208     0.27736      0.27034
alpha_8                               0.33962      0.00028     0.33996      0.33897
alpha_9                               0.21404      0.00011     0.21417      0.21372
Alpha_loss                            0.31411      0.16449     0.76790      -0.07483
Training/policy_loss                  95.76994     16.76977    142.23767    53.21987
Training/qf1_loss                     14590.23959  5092.33248  39105.98047  7022.53467
Training/qf2_loss                     1067.97882   415.23884   2562.12402   503.73419
Training/pf_norm                      15.10498     7.10463     40.22535     5.67002
Training/qf1_norm                     9424.98727   4701.37797  32430.26367  2535.40088
Training/qf2_norm                     3836.31811   1777.12432  9103.92676   1517.78552
log_std/mean                          -0.85958     0.01121     -0.83160     -0.88272
log_std/std                           0.48347      0.00594     0.49465      0.46795
log_std/max                           0.36108      0.20632     0.88182      0.08710
log_std/min                           -3.05685     0.43864     -2.47511     -3.59529
log_probs/mean                        4.13637      0.13670     4.55087      3.89899
log_probs/std                         3.65159      0.10016     3.87421      3.40980
log_probs/max                         23.49200     1.49909     26.18830     19.39493
log_probs/min                         -6.34732     1.27641     -3.88259     -10.26666
mean/mean                             0.43713      0.04421     0.53992      0.34755
mean/std                              1.45307      0.01592     1.49833      1.42219
mean/max                              6.50377      0.34624     7.02618      5.03151
mean/min                              -5.08639     0.26082     -4.16001     -5.48788
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 6, 3, 4, 1, 9, 2, 7, 0, 8]
replay_buffer._size: [40050 40050 40050 40050 40050 40050 40050 40050 40050 40050]
2023-08-12 12:18:39,739 MainThread INFO: EPOCH:245
2023-08-12 12:18:39,739 MainThread INFO: Time Consumed:9.60219955444336s
2023-08-12 12:18:39,739 MainThread INFO: Total Frames:399000s
  2%|▏         | 246/10000 [37:18<25:41:56,  9.49s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               822.78173
Train_Epoch_Reward                    9485.12709
Running_Training_Average_Rewards      924.53740
Explore_Time                          0.01094
Train___Time                          9.58616
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.30074
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.82752
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.65351
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.96453
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.78706
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.00968
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.39380
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8886.60329
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.23595
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -8.61323
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.51752      1.34878     10.40434     3.69399
alpha_0                               2.30386      0.00106     2.30669      2.30178
alpha_1                               0.50322      0.00049     0.50399      0.50239
alpha_2                               0.27460      0.00102     0.27638      0.27294
alpha_3                               0.24088      0.00061     0.24208      0.24018
alpha_4                               0.28020      0.00128     0.28223      0.27820
alpha_5                               0.31997      0.00025     0.32058      0.31958
alpha_6                               0.14452      0.00115     0.14650      0.14257
alpha_7                               0.26583      0.00280     0.27028      0.26145
alpha_8                               0.33678      0.00153     0.33895      0.33403
alpha_9                               0.21361      0.00015     0.21406      0.21350
Alpha_loss                            0.19146      0.13084     0.53297      -0.11216
Training/policy_loss                  98.54374     17.71807    146.30090    55.87626
Training/qf1_loss                     14236.44751  5008.37699  28210.60742  5651.31885
Training/qf2_loss                     1015.23985   369.61496   2462.38989   489.80460
Training/pf_norm                      14.04842     6.30153     35.36562     5.47035
Training/qf1_norm                     9247.53785   4008.24804  24157.40234  3950.01685
Training/qf2_norm                     4798.62128   2226.36866  13821.00098  1464.36072
log_std/mean                          -0.86502     0.01231     -0.83770     -0.89019
log_std/std                           0.48397      0.00505     0.49562      0.47136
log_std/max                           0.37948      0.19207     0.88999      0.11509
log_std/min                           -3.09733     0.42372     -2.46891     -3.59494
log_probs/mean                        4.05343      0.10955     4.34005      3.73858
log_probs/std                         3.65942      0.11715     3.98467      3.40919
log_probs/max                         22.81526     2.05652     26.71572     15.53093
log_probs/min                         -6.64216     1.43818     -4.13383     -10.13498
mean/mean                             0.44852      0.02486     0.49484      0.39635
mean/std                              1.42804      0.01856     1.47120      1.37120
mean/max                              6.38498      0.27265     6.65430      4.82942
mean/min                              -5.01270     0.37401     -3.57866     -5.42708
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 5, 4, 8, 2, 9, 1, 7, 3]
replay_buffer._size: [40200 40200 40200 40200 40200 40200 40200 40200 40200 40200]
2023-08-12 12:18:48,346 MainThread INFO: EPOCH:246
2023-08-12 12:18:48,346 MainThread INFO: Time Consumed:8.384930849075317s
2023-08-12 12:18:48,347 MainThread INFO: Total Frames:400500s
  2%|▏         | 247/10000 [37:27<24:56:24,  9.21s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1003.39059
Train_Epoch_Reward                    8954.56173
Running_Training_Average_Rewards      925.48664
Explore_Time                          0.01421
Train___Time                          8.36603
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.19458
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.46371
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -43.09129
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.97325
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.40518
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.75675
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.29097
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9537.65897
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.77796
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1103.20066
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.84838      1.47695     10.25455     3.69512
alpha_0                               2.30709      0.00329     2.31292      2.30339
alpha_1                               0.50192      0.00033     0.50309      0.50152
alpha_2                               0.27098      0.00115     0.27290      0.26893
alpha_3                               0.24422      0.00133     0.24626      0.24212
alpha_4                               0.28487      0.00166     0.28731      0.28226
alpha_5                               0.32143      0.00064     0.32256      0.32059
alpha_6                               0.14864      0.00128     0.15078      0.14654
alpha_7                               0.25712      0.00284     0.26139      0.25255
alpha_8                               0.33106      0.00208     0.33397      0.32743
alpha_9                               0.21506      0.00076     0.21625      0.21402
Alpha_loss                            0.21623      0.14593     0.50437      -0.10990
Training/policy_loss                  94.06316     19.16038    139.35240    39.49849
Training/qf1_loss                     14416.76586  5492.41005  38678.08984  6533.67334
Training/qf2_loss                     1082.51577   379.15459   2401.40576   557.67291
Training/pf_norm                      14.06180     5.69793     28.97299     5.99296
Training/qf1_norm                     8859.43478   4422.29325  25252.61719  2921.93066
Training/qf2_norm                     4376.03648   2090.15955  9933.67969   1365.02991
log_std/mean                          -0.87429     0.01569     -0.82770     -0.89746
log_std/std                           0.48074      0.00436     0.49150      0.47011
log_std/max                           0.32040      0.17899     0.84180      0.07716
log_std/min                           -3.04826     0.42596     -2.47666     -3.59965
log_probs/mean                        4.09043      0.11389     4.37650      3.82284
log_probs/std                         3.65369      0.12262     3.91305      3.36115
log_probs/max                         23.50865     2.03541     27.02029     18.13998
log_probs/min                         -6.68172     1.48102     -4.23734     -12.56371
mean/mean                             0.51218      0.03556     0.58812      0.44134
mean/std                              1.40996      0.02057     1.45832      1.34778
mean/max                              6.42456      0.27831     6.78227      5.41113
mean/min                              -5.09237     0.37319     -3.87984     -5.56089
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 5, 2, 4, 8, 0, 7, 1, 6]
replay_buffer._size: [40350 40350 40350 40350 40350 40350 40350 40350 40350 40350]
2023-08-12 12:18:57,364 MainThread INFO: EPOCH:247
2023-08-12 12:18:57,365 MainThread INFO: Time Consumed:8.850660562515259s
2023-08-12 12:18:57,365 MainThread INFO: Total Frames:402000s
  2%|▏         | 248/10000 [37:36<24:47:30,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1048.70533
Train_Epoch_Reward                    8783.85225
Running_Training_Average_Rewards      907.45137
Explore_Time                          0.00936
Train___Time                          8.83642
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.11851
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.09284
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.18207
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.60282
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.05343
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.35842
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.18446
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9971.03928
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.10276
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1162.70932
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65022      1.50196     10.24890     3.47742
alpha_0                               2.31161      0.00184     2.31518      2.30909
alpha_1                               0.50553      0.00169     0.50838      0.50233
alpha_2                               0.26682      0.00098     0.26888      0.26572
alpha_3                               0.24685      0.00050     0.24769      0.24626
alpha_4                               0.28908      0.00133     0.29236      0.28734
alpha_5                               0.32171      0.00072     0.32254      0.32029
alpha_6                               0.15271      0.00114     0.15478      0.15082
alpha_7                               0.24870      0.00210     0.25247      0.24529
alpha_8                               0.32463      0.00126     0.32735      0.32295
alpha_9                               0.21780      0.00082     0.21902      0.21627
Alpha_loss                            0.22477      0.16788     0.61115      -0.11538
Training/policy_loss                  97.92278     16.41398    131.62675    63.02775
Training/qf1_loss                     15855.18322  6087.51523  34145.94922  6140.60645
Training/qf2_loss                     1072.91714   489.91305   3277.33447   441.65219
Training/pf_norm                      14.49631     7.42280     41.17764     5.79401
Training/qf1_norm                     8990.35390   3992.16397  22246.67188  2664.42920
Training/qf2_norm                     4444.62573   2339.64181  15385.34277  1424.75525
log_std/mean                          -0.87799     0.00887     -0.85735     -0.89914
log_std/std                           0.47331      0.00564     0.48726      0.45907
log_std/max                           0.30431      0.17628     0.67835      0.04107
log_std/min                           -3.09786     0.44037     -2.43056     -3.63239
log_probs/mean                        4.10768      0.14356     4.42627      3.77987
log_probs/std                         3.62666      0.10291     3.94461      3.40626
log_probs/max                         23.50394     2.31802     27.48531     17.52593
log_probs/min                         -6.49923     1.36464     -3.74658     -11.27149
mean/mean                             0.49969      0.02416     0.54622      0.44655
mean/std                              1.41845      0.02588     1.47814      1.34367
mean/max                              6.41546      0.27997     6.71644      5.41842
mean/min                              -5.18524     0.38007     -4.06289     -5.65134
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 0, 5, 8, 2, 3, 6, 7, 4, 1]
replay_buffer._size: [40500 40500 40500 40500 40500 40500 40500 40500 40500 40500]
2023-08-12 12:19:06,618 MainThread INFO: EPOCH:248
2023-08-12 12:19:06,619 MainThread INFO: Time Consumed:9.06108283996582s
2023-08-12 12:19:06,619 MainThread INFO: Total Frames:403500s
  2%|▏         | 249/10000 [37:45<24:52:00,  9.18s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               998.45450
Train_Epoch_Reward                    8658.16549
Running_Training_Average_Rewards      879.88598
Explore_Time                          0.01602
Train___Time                          9.04032
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.64006
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.39188
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.62061
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -87.09915
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.63657
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.64617
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.43656
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9352.61958
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.23690
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1270.63327
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.74999      1.42164     10.21906     3.89957
alpha_0                               2.32310      0.00374     2.32840      2.31514
alpha_1                               0.51310      0.00264     0.51639      0.50843
alpha_2                               0.26577      0.00036     0.26615      0.26471
alpha_3                               0.24762      0.00029     0.24793      0.24699
alpha_4                               0.29661      0.00202     0.29974      0.29247
alpha_5                               0.31801      0.00133     0.32027      0.31582
alpha_6                               0.15686      0.00109     0.15861      0.15482
alpha_7                               0.24212      0.00215     0.24526      0.23816
alpha_8                               0.32139      0.00124     0.32300      0.31892
alpha_9                               0.21991      0.00060     0.22107      0.21903
Alpha_loss                            0.16797      0.21616     0.56412      -0.32236
Training/policy_loss                  99.51356     18.25781    136.86786    46.81322
Training/qf1_loss                     14122.63226  5029.56212  30346.52539  5356.78223
Training/qf2_loss                     1055.69544   347.58562   2095.45020   454.23239
Training/pf_norm                      14.21321     6.21907     31.32421     4.78649
Training/qf1_norm                     8589.62938   3789.56889  20074.44141  2842.29272
Training/qf2_norm                     3969.59224   2093.04655  11848.20898  1192.09302
log_std/mean                          -0.87143     0.01086     -0.84529     -0.89361
log_std/std                           0.46796      0.00493     0.47693      0.45556
log_std/max                           0.22862      0.17784     0.71538      0.01183
log_std/min                           -3.03885     0.42633     -2.41343     -3.59060
log_probs/mean                        4.09282      0.17878     4.46704      3.51032
log_probs/std                         3.70853      0.10470     3.92455      3.44226
log_probs/max                         23.23339     2.44027     28.01059     17.61438
log_probs/min                         -6.43413     1.37285     -3.82361     -10.18988
mean/mean                             0.45130      0.02302     0.50449      0.38790
mean/std                              1.43809      0.02637     1.48623      1.36327
mean/max                              6.42116      0.38922     6.86727      5.39989
mean/min                              -5.23181     0.42468     -4.02809     -5.79115
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 6, 0, 3, 1, 9, 2, 7, 8, 4]
replay_buffer._size: [40650 40650 40650 40650 40650 40650 40650 40650 40650 40650]
2023-08-12 12:19:15,947 MainThread INFO: EPOCH:249
2023-08-12 12:19:15,950 MainThread INFO: Time Consumed:9.146967649459839s
2023-08-12 12:19:15,950 MainThread INFO: Total Frames:405000s
  2%|▎         | 250/10000 [37:55<24:59:27,  9.23s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1061.96997
Train_Epoch_Reward                    8672.30334
Running_Training_Average_Rewards      870.47737
Explore_Time                          0.00624
Train___Time                          9.13561
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.13123
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.73862
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.52867
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -87.45391
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.95437
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.44941
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.10292
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9929.17600
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.18492
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1328.06778
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.53900      1.49157     10.79038     3.59713
alpha_0                               2.33750      0.00882     2.34967      2.32470
alpha_1                               0.51586      0.00045     0.51650      0.51511
alpha_2                               0.26248      0.00125     0.26466      0.26036
alpha_3                               0.24643      0.00042     0.24698      0.24590
alpha_4                               0.30148      0.00109     0.30422      0.29977
alpha_5                               0.31416      0.00119     0.31579      0.31214
alpha_6                               0.16028      0.00096     0.16205      0.15865
alpha_7                               0.23525      0.00205     0.23811      0.23118
alpha_8                               0.31741      0.00077     0.31888      0.31565
alpha_9                               0.22202      0.00043     0.22280      0.22109
Alpha_loss                            0.02393      0.16139     0.48014      -0.36914
Training/policy_loss                  101.27468    16.85460    140.17155    54.95481
Training/qf1_loss                     14638.47192  4451.03995  28161.04688  6414.92188
Training/qf2_loss                     1057.88068   390.03031   2360.30981   501.57608
Training/pf_norm                      13.80616     6.26568     35.07647     5.34215
Training/qf1_norm                     9306.25788   3484.52286  21958.20117  3526.08789
Training/qf2_norm                     4682.48188   2124.45758  10002.80762  1539.02612
log_std/mean                          -0.87322     0.01140     -0.84276     -0.90397
log_std/std                           0.47487      0.00791     0.49687      0.46044
log_std/max                           0.30069      0.17896     0.75809      0.05884
log_std/min                           -3.21738     0.42801     -2.38659     -3.67895
log_probs/mean                        4.00958      0.12373     4.36913      3.66298
log_probs/std                         3.67194      0.10951     3.95711      3.41456
log_probs/max                         23.78921     2.73935     28.23041     16.74332
log_probs/min                         -6.57376     1.25106     -4.23170     -10.66047
mean/mean                             0.43092      0.04029     0.51040      0.36317
mean/std                              1.42591      0.01970     1.46705      1.38243
mean/max                              6.36805      0.52488     6.98546      4.53648
mean/min                              -5.35204     0.40857     -3.79347     -5.92892
------------------------------------  -----------  ----------  -----------  ----------
start to update mask
sample: [2, 6, 8, 9, 5, 4, 1, 3, 0, 7]
replay_buffer._size: [40800 40800 40800 40800 40800 40800 40800 40800 40800 40800]
2023-08-12 12:19:25,481 MainThread INFO: EPOCH:250
2023-08-12 12:19:25,481 MainThread INFO: Time Consumed:8.386584997177124s
2023-08-12 12:19:25,481 MainThread INFO: Total Frames:406500s
  3%|▎         | 251/10000 [38:04<25:13:49,  9.32s/it]------------------------------------  ------------  ------------  -------------  -----------
Name                                  Value
Running_Average_Rewards               1041.21478
Train_Epoch_Reward                    10715.56789
Running_Training_Average_Rewards      934.86789
Explore_Time                          0.03975
Train___Time                          8.34177
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.64717
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.79960
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.26326
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -88.12822
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.63243
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.23126
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.05113
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9806.10631
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.88845
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1242.68300
mean_success_rate                     0.00000

Name                                  Mean          Std           Max            Min
Reward_Mean                           6.37479       1.11562       9.48005        3.73491
alpha_0                               2.44105       0.06447       2.54433        2.34999
alpha_1                               0.55383       0.02406       0.59484        0.51669
alpha_2                               0.25952       0.00142       0.26350        0.25807
alpha_3                               0.24904       0.00589       0.26138        0.24296
alpha_4                               0.32053       0.01231       0.34375        0.30434
alpha_5                               0.32357       0.00814       0.34009        0.31215
alpha_6                               0.16505       0.00191       0.16840        0.16209
alpha_7                               0.22878       0.00258       0.23402        0.22475
alpha_8                               0.32076       0.00253       0.32547        0.31558
alpha_9                               0.23223       0.00770       0.24773        0.22285
Alpha_loss                            3.00725       1.86278       5.72806        0.48934
Training/policy_loss                  248.74767     35.21318      326.66208      174.77994
Training/qf1_loss                     17688.18382   6864.29222    32444.97852    7385.86865
Training/qf2_loss                     128881.60864  103887.90691  347031.81250   13025.27051
Training/pf_norm                      64.59955      25.65192      152.08939      33.84499
Training/qf1_norm                     25712.35141   13156.72521   52059.17969    6988.48730
Training/qf2_norm                     366322.75152  340014.42065  1062064.25000  39577.34375
log_std/mean                          -0.94461      0.09571       -0.81607       -1.10129
log_std/std                           0.54572       0.01325       0.58211        0.52222
log_std/max                           0.53358       0.16836       0.98891        0.20150
log_std/min                           -3.32085      0.38932       -2.63419       -3.81239
log_probs/mean                        7.17947       1.68329       9.56904        4.64932
log_probs/std                         5.31695       0.77577       6.51251        3.82489
log_probs/max                         33.21236      6.65179       46.94778       23.18577
log_probs/min                         -5.70605      1.55283       -2.36920       -10.21122
mean/mean                             0.78081       0.10930       0.93661        0.52274
mean/std                              1.87432       0.23279       2.16969        1.54828
mean/max                              9.26874       0.72836       10.15057       7.25544
mean/min                              -6.51332      1.34382       -4.17398       -9.20968
------------------------------------  ------------  ------------  -------------  -----------
sample: [0, 2, 6, 9, 7, 3, 8, 4, 1, 5]
replay_buffer._size: [40950 40950 40950 40950 40950 40950 40950 40950 40950 40950]
2023-08-12 12:19:34,281 MainThread INFO: EPOCH:251
2023-08-12 12:19:34,281 MainThread INFO: Time Consumed:8.615610837936401s
2023-08-12 12:19:34,281 MainThread INFO: Total Frames:408000s
  3%|▎         | 252/10000 [38:13<24:48:56,  9.16s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1050.02537
Train_Epoch_Reward                    8753.55311
Running_Training_Average_Rewards      938.04748
Explore_Time                          0.00421
Train___Time                          8.60690
Eval____Time                          0.00391
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.05247
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.98850
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.17359
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -87.81594
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.57162
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.47679
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.22410
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9797.28001
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.97785
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1343.25455
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.63169      1.29453     9.94118      3.08915
alpha_0                               2.64796      0.05941     2.73348      2.54612
alpha_1                               0.62402      0.01478     0.64549      0.59554
alpha_2                               0.27733      0.00833     0.29098      0.26370
alpha_3                               0.27663      0.00837     0.28909      0.26168
alpha_4                               0.36376      0.01016     0.37818      0.34422
alpha_5                               0.35734      0.00824     0.37089      0.34051
alpha_6                               0.17486      0.00419     0.18190      0.16848
alpha_7                               0.24444      0.00640     0.25462      0.23420
alpha_8                               0.33788      0.00564     0.34436      0.32577
alpha_9                               0.26322      0.00801     0.27454      0.24806
Alpha_loss                            6.00941      0.90570     7.34123      4.23732
Training/policy_loss                  203.13479    17.62914    241.20293    164.80200
Training/qf1_loss                     9837.21319   2981.34576  19865.34375  5224.30811
Training/qf2_loss                     5367.97564   2283.42416  12568.76270  2593.32593
Training/pf_norm                      23.59091     7.90955     53.05495     10.76087
Training/qf1_norm                     8528.08415   2986.06442  17683.72852  3958.86938
Training/qf2_norm                     13035.29612  8129.41423  46575.80078  4860.49902
log_std/mean                          -0.95492     0.13194     -0.79679     -1.12303
log_std/std                           0.51061      0.03795     0.56167      0.43839
log_std/max                           0.73498      0.26754     1.37323      0.27308
log_std/min                           -3.22841     0.39335     -2.26354     -3.87386
log_probs/mean                        9.79266      0.93079     11.14622     7.99187
log_probs/std                         5.35875      0.43140     6.04800      4.53359
log_probs/max                         36.06011     5.00508     44.21644     25.22130
log_probs/min                         -4.31736     1.35620     -0.94631     -7.56764
mean/mean                             1.20603      0.19318     1.43518      0.79837
mean/std                              2.03187      0.12582     2.20659      1.79976
mean/max                              9.97334      0.48742     10.43956     8.24758
mean/min                              -8.23933     1.72469     -4.50829     -10.04273
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 7, 0, 3, 8, 1, 5, 9, 4, 6]
replay_buffer._size: [41100 41100 41100 41100 41100 41100 41100 41100 41100 41100]
2023-08-12 12:19:43,003 MainThread INFO: EPOCH:252
2023-08-12 12:19:43,003 MainThread INFO: Time Consumed:8.540335893630981s
2023-08-12 12:19:43,004 MainThread INFO: Total Frames:409500s
  3%|▎         | 253/10000 [38:22<24:26:45,  9.03s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               618.80069
Train_Epoch_Reward                    8547.55554
Running_Training_Average_Rewards      933.88922
Explore_Time                          0.01188
Train___Time                          8.52444
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.26955
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.62945
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.80212
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -92.49995
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.71627
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.26134
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.86585
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6932.34059
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.85538
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.43373
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.51767     1.19061     9.06954      3.77269
alpha_0                               2.77942     0.02543     2.82307      2.73446
alpha_1                               0.65903     0.00712     0.67043      0.64580
alpha_2                               0.30134     0.00538     0.30970      0.29122
alpha_3                               0.29243     0.00110     0.29332      0.28924
alpha_4                               0.38325     0.00226     0.38655      0.37834
alpha_5                               0.38677     0.00858     0.40061      0.37122
alpha_6                               0.18657     0.00238     0.19042      0.18201
alpha_7                               0.25994     0.00295     0.26557      0.25475
alpha_8                               0.35174     0.00507     0.36164      0.34444
alpha_9                               0.28044     0.00325     0.28611      0.27468
Alpha_loss                            3.18499     0.46460     4.28408      2.50882
Training/policy_loss                  203.89198   14.20105    240.65913    169.51343
Training/qf1_loss                     9265.84687  3166.76046  18373.02148  4138.65771
Training/qf2_loss                     2698.77005  531.72875   4376.12256   1823.13513
Training/pf_norm                      22.02857    9.50664     50.91766     10.16968
Training/qf1_norm                     7225.19784  3277.17369  16195.62012  2235.47070
Training/qf2_norm                     7155.55522  2909.71888  17188.27148  3415.76489
log_std/mean                          -0.88088    0.03688     -0.80925     -0.92959
log_std/std                           0.41310     0.01383     0.44293      0.38740
log_std/max                           0.32775     0.19991     0.88619      -0.03175
log_std/min                           -2.88017    0.24515     -2.23967     -3.13993
log_probs/mean                        7.22196     0.40749     8.31361      6.61524
log_probs/std                         4.29521     0.21503     4.77112      3.94422
log_probs/max                         35.03898    5.52953     41.14784     22.35561
log_probs/min                         -5.09432    1.51719     -2.14787     -10.37359
mean/mean                             1.01971     0.13958     1.27890      0.78759
mean/std                              1.74052     0.03315     1.83477      1.68079
mean/max                              8.98880     0.59505     9.96358      7.05217
mean/min                              -7.76805    1.52528     -3.94153     -9.01214
------------------------------------  ----------  ----------  -----------  ----------
sample: [2, 7, 1, 3, 4, 5, 8, 9, 6, 0]
replay_buffer._size: [41250 41250 41250 41250 41250 41250 41250 41250 41250 41250]
2023-08-12 12:19:51,639 MainThread INFO: EPOCH:253
2023-08-12 12:19:51,639 MainThread INFO: Time Consumed:8.468172550201416s
2023-08-12 12:19:51,640 MainThread INFO: Total Frames:411000s
  3%|▎         | 254/10000 [38:30<24:07:31,  8.91s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               646.88179
Train_Epoch_Reward                    6272.61213
Running_Training_Average_Rewards      785.79069
Explore_Time                          0.00516
Train___Time                          8.45899
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.32870
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.08802
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -85.60624
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.90510
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.99103
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.59371
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -91.08125
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7234.59645
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -90.39119
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.79334
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.48536     1.40946     11.23201     3.78608
alpha_0                               2.87079     0.02918     2.92229      2.82390
alpha_1                               0.68090     0.00564     0.69004      0.67064
alpha_2                               0.31711     0.00459     0.32551      0.30983
alpha_3                               0.29181     0.00049     0.29278      0.29108
alpha_4                               0.38833     0.00087     0.38957      0.38660
alpha_5                               0.41176     0.00597     0.42144      0.40085
alpha_6                               0.19461     0.00245     0.19886      0.19050
alpha_7                               0.27370     0.00452     0.28101      0.26571
alpha_8                               0.37513     0.00763     0.38758      0.36190
alpha_9                               0.29342     0.00445     0.30141      0.28623
Alpha_loss                            3.01663     0.13161     3.40755      2.73343
Training/policy_loss                  196.88841   15.29961    232.67827    155.04390
Training/qf1_loss                     9433.13548  3514.64215  22969.53516  4221.87646
Training/qf2_loss                     2051.34078  351.76466   3258.21509   1418.22388
Training/pf_norm                      17.67683    6.63529     38.08914     7.57893
Training/qf1_norm                     7299.25290  3218.12033  16892.29102  2632.90552
Training/qf2_norm                     6231.72172  2976.26745  15831.47949  2681.72729
log_std/mean                          -0.92960    0.00797     -0.91064     -0.94782
log_std/std                           0.39283     0.00554     0.40647      0.38007
log_std/max                           0.11728     0.09471     0.42078      -0.07752
log_std/min                           -2.79505    0.21026     -2.18297     -3.03466
log_probs/mean                        7.08510     0.12308     7.35795      6.77265
log_probs/std                         4.23522     0.15069     4.55862      3.87768
log_probs/max                         34.28198    4.97522     39.44564     21.85051
log_probs/min                         -5.30820    1.48883     -2.29593     -9.55084
mean/mean                             0.75060     0.04649     0.85782      0.67947
mean/std                              1.80144     0.02233     1.84715      1.73647
mean/max                              8.36317     0.55599     9.03641      6.79172
mean/min                              -7.54709    1.24536     -4.26663     -8.62089
------------------------------------  ----------  ----------  -----------  ----------
sample: [7, 3, 9, 0, 8, 2, 1, 5, 4, 6]
replay_buffer._size: [41400 41400 41400 41400 41400 41400 41400 41400 41400 41400]
2023-08-12 12:20:00,841 MainThread INFO: EPOCH:254
2023-08-12 12:20:00,841 MainThread INFO: Time Consumed:9.012727499008179s
2023-08-12 12:20:00,841 MainThread INFO: Total Frames:412500s
  3%|▎         | 255/10000 [38:39<24:21:28,  9.00s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               870.10818
Train_Epoch_Reward                    6706.18621
Running_Training_Average_Rewards      717.54513
Explore_Time                          0.00625
Train___Time                          9.00224
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -111.11875
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.97458
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -85.21054
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.25009
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.20196
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.39647
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.64263
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9461.37036
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -85.72514
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.76840
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.58799     1.31381     9.66455      4.09678
alpha_0                               2.97432     0.02955     3.02656      2.92335
alpha_1                               0.69781     0.00410     0.70433      0.69021
alpha_2                               0.33440     0.00510     0.34334      0.32569
alpha_3                               0.29048     0.00033     0.29107      0.28987
alpha_4                               0.38995     0.00014     0.39008      0.38959
alpha_5                               0.43016     0.00499     0.43879      0.42163
alpha_6                               0.20336     0.00254     0.20763      0.19895
alpha_7                               0.28612     0.00245     0.28937      0.28114
alpha_8                               0.39628     0.00452     0.40350      0.38779
alpha_9                               0.30941     0.00447     0.31694      0.30158
Alpha_loss                            2.55732     0.21430     3.18402      2.11960
Training/policy_loss                  192.71873   19.18240    236.27176    140.40894
Training/qf1_loss                     9487.20554  3697.85575  20791.91211  3742.72900
Training/qf2_loss                     1796.72446  371.80973   3154.26367   1212.08508
Training/pf_norm                      17.92853    8.52579     44.72250     5.89792
Training/qf1_norm                     7901.87450  2991.23912  18820.49219  2790.81860
Training/qf2_norm                     4945.01695  2182.90812  12498.48145  1725.97888
log_std/mean                          -0.91821    0.01307     -0.89001     -0.94268
log_std/std                           0.39105     0.00543     0.40534      0.37859
log_std/max                           0.09562     0.06761     0.21886      -0.01467
log_std/min                           -2.74007    0.10270     -2.22292     -2.82419
log_probs/mean                        6.68074     0.20128     7.21580      6.10514
log_probs/std                         4.35091     0.14334     4.66100      4.01027
log_probs/max                         33.57607    3.48328     37.17461     22.86970
log_probs/min                         -5.63843    1.40379     -3.22761     -11.06886
mean/mean                             0.69911     0.02336     0.76265      0.64573
mean/std                              1.76505     0.02673     1.82885      1.69522
mean/max                              8.36099     0.46092     9.17899      7.27229
mean/min                              -7.38670    0.72241     -5.38331     -8.00503
------------------------------------  ----------  ----------  -----------  ----------
sample: [9, 1, 4, 7, 3, 8, 2, 0, 6, 5]
replay_buffer._size: [41550 41550 41550 41550 41550 41550 41550 41550 41550 41550]
2023-08-12 12:20:09,539 MainThread INFO: EPOCH:255
2023-08-12 12:20:09,539 MainThread INFO: Time Consumed:8.535053014755249s
2023-08-12 12:20:09,539 MainThread INFO: Total Frames:414000s
  3%|▎         | 256/10000 [38:48<24:06:39,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               968.63575
Train_Epoch_Reward                    8456.27691
Running_Training_Average_Rewards      714.50251
Explore_Time                          0.00584
Train___Time                          8.52531
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -111.17063
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.94842
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.32197
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.05315
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.82807
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.93080
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.86824
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10459.95895
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.76813
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.71201
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.44459      1.34802     10.71324     3.72465
alpha_0                               3.08453      0.03135     3.13658      3.02771
alpha_1                               0.70998      0.00325     0.71542      0.70444
alpha_2                               0.35236      0.00497     0.36047      0.34352
alpha_3                               0.28921      0.00041     0.28985      0.28834
alpha_4                               0.38945      0.00030     0.38987      0.38882
alpha_5                               0.44755      0.00491     0.45541      0.43898
alpha_6                               0.21170      0.00226     0.21543      0.20771
alpha_7                               0.29131      0.00111     0.29316      0.28941
alpha_8                               0.41000      0.00387     0.41692      0.40362
alpha_9                               0.32379      0.00380     0.33001      0.31709
Alpha_loss                            2.07471      0.23434     2.46838      1.49277
Training/policy_loss                  192.03953    17.62958    233.99620    151.37186
Training/qf1_loss                     10025.18584  3811.36028  22255.43945  4520.57227
Training/qf2_loss                     1734.00354   396.97511   3551.37427   1031.52673
Training/pf_norm                      20.13899     9.92849     52.79481     6.85266
Training/qf1_norm                     7247.03482   3324.85635  20176.54688  2592.50220
Training/qf2_norm                     5667.44561   2734.38039  15318.11914  2066.90405
log_std/mean                          -0.91741     0.00936     -0.88965     -0.93819
log_std/std                           0.39925      0.00759     0.42056      0.38134
log_std/max                           0.03189      0.06348     0.25482      -0.11038
log_std/min                           -2.79094     0.06454     -2.52091     -2.91603
log_probs/mean                        6.31916      0.21544     6.71505      5.78789
log_probs/std                         4.35251      0.14551     4.72356      3.99350
log_probs/max                         32.10332     2.88631     35.33935     21.84573
log_probs/min                         -5.97224     1.30956     -2.90958     -9.55970
mean/mean                             0.69769      0.02606     0.75008      0.63467
mean/std                              1.70900      0.03102     1.78663      1.62816
mean/max                              8.08093      0.50098     9.04665      7.04365
mean/min                              -6.92240     0.62016     -5.07322     -7.48968
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 5, 8, 4, 7, 1, 9, 0, 2, 3]
replay_buffer._size: [41700 41700 41700 41700 41700 41700 41700 41700 41700 41700]
2023-08-12 12:20:18,236 MainThread INFO: EPOCH:256
2023-08-12 12:20:18,236 MainThread INFO: Time Consumed:8.516332387924194s
2023-08-12 12:20:18,236 MainThread INFO: Total Frames:415500s
  3%|▎         | 257/10000 [38:57<23:56:14,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               993.97410
Train_Epoch_Reward                    10638.28169
Running_Training_Average_Rewards      860.02483
Explore_Time                          0.00364
Train___Time                          8.50924
Eval____Time                          0.00285
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -109.82833
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.56344
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.39976
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.58528
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.72456
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.87348
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.89445
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10720.99472
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.64543
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.73895
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60544      1.27785     10.16834     3.68946
alpha_0                               3.18926      0.03034     3.24079      3.13759
alpha_1                               0.71965      0.00244     0.72385      0.71552
alpha_2                               0.36757      0.00396     0.37429      0.36062
alpha_3                               0.28724      0.00062     0.28832      0.28615
alpha_4                               0.38786      0.00066     0.38880      0.38651
alpha_5                               0.46262      0.00420     0.46973      0.45554
alpha_6                               0.21871      0.00175     0.22156      0.21551
alpha_7                               0.29474      0.00093     0.29628      0.29319
alpha_8                               0.42636      0.00557     0.43581      0.41708
alpha_9                               0.33481      0.00252     0.33874      0.33012
Alpha_loss                            1.50760      0.20292     1.92121      1.08580
Training/policy_loss                  185.71849    17.02451    226.74841    132.75362
Training/qf1_loss                     10469.06120  3855.06956  26595.06250  3865.84253
Training/qf2_loss                     1698.66341   445.86230   3521.97974   934.48566
Training/pf_norm                      19.84176     10.53351    50.23244     5.50763
Training/qf1_norm                     7863.96284   3746.53620  26971.00586  2601.59131
Training/qf2_norm                     5211.29362   2468.15382  12565.78613  1947.72827
log_std/mean                          -0.90156     0.01165     -0.87699     -0.93302
log_std/std                           0.40200      0.00592     0.41680      0.38580
log_std/max                           0.05690      0.07679     0.28033      -0.18911
log_std/min                           -2.78839     0.09880     -2.52398     -3.04056
log_probs/mean                        5.83767      0.17543     6.14000      5.36038
log_probs/std                         4.13461      0.11113     4.48309      3.79897
log_probs/max                         30.65574     2.46573     33.72974     20.80851
log_probs/min                         -5.91558     1.26188     -3.74668     -9.81807
mean/mean                             0.65870      0.02278     0.71060      0.60503
mean/std                              1.64765      0.02531     1.70869      1.59074
mean/max                              7.65745      0.44230     8.73822      6.80487
mean/min                              -6.53661     0.41932     -5.19330     -6.98321
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 7, 3, 2, 0, 4, 8, 9, 1, 5]
replay_buffer._size: [41850 41850 41850 41850 41850 41850 41850 41850 41850 41850]
2023-08-12 12:20:27,037 MainThread INFO: EPOCH:257
2023-08-12 12:20:27,037 MainThread INFO: Time Consumed:8.628543138504028s
2023-08-12 12:20:27,037 MainThread INFO: Total Frames:417000s
  3%|▎         | 258/10000 [39:06<23:54:06,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1020.18085
Train_Epoch_Reward                    9741.57016
Running_Training_Average_Rewards      961.20429
Explore_Time                          0.01096
Train___Time                          8.61379
Eval____Time                          0.00326
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -110.21977
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.81741
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.97774
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -88.02765
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.32333
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.84304
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.48774
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11005.34990
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -81.01478
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -78.82996
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.53117      1.13355     9.87556      4.33856
alpha_0                               3.28777      0.02688     3.33410      3.24179
alpha_1                               0.72655      0.00136     0.72856      0.72392
alpha_2                               0.38031      0.00329     0.38570      0.37442
alpha_3                               0.28528      0.00051     0.28613      0.28433
alpha_4                               0.38485      0.00094     0.38648      0.38319
alpha_5                               0.47635      0.00376     0.48271      0.46986
alpha_6                               0.22393      0.00130     0.22602      0.22161
alpha_7                               0.29761      0.00071     0.29869      0.29631
alpha_8                               0.44494      0.00500     0.45307      0.43599
alpha_9                               0.34104      0.00110     0.34245      0.33880
Alpha_loss                            0.97011      0.20817     1.40710      0.53023
Training/policy_loss                  184.84696    14.80680    221.28722    153.10905
Training/qf1_loss                     9777.20506   3875.31466  24003.02539  3263.87402
Training/qf2_loss                     1593.75282   315.77123   2669.67798   1016.35547
Training/pf_norm                      15.75586     8.51615     59.25627     6.81005
Training/qf1_norm                     7323.86625   3361.56843  19816.60742  2432.96289
Training/qf2_norm                     4950.91229   2361.44018  13722.06836  1232.94556
log_std/mean                          -0.88886     0.01012     -0.86784     -0.91088
log_std/std                           0.40490      0.00671     0.42564      0.38479
log_std/max                           0.05531      0.08462     0.34430      -0.10399
log_std/min                           -2.84856     0.17188     -2.60255     -3.20900
log_probs/mean                        5.29842      0.19948     5.72290      4.92291
log_probs/std                         3.97490      0.13892     4.28898      3.65958
log_probs/max                         28.65565     2.62466     32.25619     20.01596
log_probs/min                         -6.13715     1.54299     -3.46457     -12.50734
mean/mean                             0.62648      0.02564     0.69081      0.57389
mean/std                              1.57648      0.02876     1.64542      1.52038
mean/max                              7.15989      0.44774     8.21593      6.40688
mean/min                              -6.02537     0.32411     -4.78234     -6.41247
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 1, 4, 8, 0, 7, 5, 3, 6]
replay_buffer._size: [42000 42000 42000 42000 42000 42000 42000 42000 42000 42000]
2023-08-12 12:20:36,163 MainThread INFO: EPOCH:258
2023-08-12 12:20:36,163 MainThread INFO: Time Consumed:8.955222845077515s
2023-08-12 12:20:36,163 MainThread INFO: Total Frames:418500s
  3%|▎         | 259/10000 [39:15<24:08:27,  8.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               969.77510
Train_Epoch_Reward                    10314.15207
Running_Training_Average_Rewards      1023.13346
Explore_Time                          0.00389
Train___Time                          8.94727
Eval____Time                          0.00338
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -113.60490
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.97302
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.13447
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.38998
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.89516
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.80678
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.82380
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10499.35331
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.53197
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -80.44224
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61223      1.19183     9.66671      3.35471
alpha_0                               3.38853      0.03005     3.43728      3.33502
alpha_1                               0.72922      0.00029     0.72984      0.72858
alpha_2                               0.39109      0.00299     0.39603      0.38581
alpha_3                               0.28338      0.00058     0.28431      0.28252
alpha_4                               0.38164      0.00091     0.38316      0.38016
alpha_5                               0.48903      0.00344     0.49491      0.48285
alpha_6                               0.22762      0.00084     0.22898      0.22605
alpha_7                               0.29893      0.00007     0.29900      0.29871
alpha_8                               0.46002      0.00354     0.46541      0.45323
alpha_9                               0.34232      0.00027     0.34258      0.34169
Alpha_loss                            0.51420      0.16027     0.89838      0.16968
Training/policy_loss                  186.18120    16.52252    221.46390    139.49510
Training/qf1_loss                     10322.34209  4032.55333  25000.86523  4376.30615
Training/qf2_loss                     1593.27823   388.05031   2995.70776   938.20966
Training/pf_norm                      16.16010     6.62875     35.53536     6.15807
Training/qf1_norm                     8136.51158   3970.70652  25436.26562  2304.14648
Training/qf2_norm                     4899.25547   2431.63036  14685.93848  1423.15405
log_std/mean                          -0.88490     0.00765     -0.87211     -0.90783
log_std/std                           0.39904      0.00635     0.41332      0.38601
log_std/max                           0.07526      0.10016     0.37799      -0.15866
log_std/min                           -2.94504     0.17800     -2.73904     -3.28691
log_probs/mean                        4.89038      0.18871     5.38107      4.49180
log_probs/std                         3.81264      0.12379     4.15390      3.49868
log_probs/max                         26.41347     2.25062     36.20884     19.18815
log_probs/min                         -6.13880     1.14840     -4.03897     -9.99792
mean/mean                             0.60693      0.03285     0.68889      0.52700
mean/std                              1.51664      0.02227     1.57147      1.47061
mean/max                              6.68867      0.47691     7.67273      5.86848
mean/min                              -5.43739     0.17875     -4.89198     -5.73149
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 6, 2, 3, 9, 0, 5, 8, 4, 1]
replay_buffer._size: [42150 42150 42150 42150 42150 42150 42150 42150 42150 42150]
2023-08-12 12:20:45,299 MainThread INFO: EPOCH:259
2023-08-12 12:20:45,300 MainThread INFO: Time Consumed:8.980079174041748s
2023-08-12 12:20:45,300 MainThread INFO: Total Frames:420000s
  3%|▎         | 260/10000 [39:24<24:18:22,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               928.43959
Train_Epoch_Reward                    9835.11045
Running_Training_Average_Rewards      996.36109
Explore_Time                          0.00574
Train___Time                          8.97035
Eval____Time                          0.00338
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.90404
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.46085
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.51464
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.05302
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.19883
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.95418
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.03127
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10081.87894
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.39925
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -80.96692
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61528      1.43697     9.54558      3.00741
alpha_0                               3.48254      0.02564     3.52446      3.43812
alpha_1                               0.73008      0.00017     0.73036      0.72964
alpha_2                               0.40028      0.00229     0.40405      0.39613
alpha_3                               0.28189      0.00031     0.28250      0.28156
alpha_4                               0.37916      0.00057     0.38014      0.37801
alpha_5                               0.50014      0.00279     0.50475      0.49503
alpha_6                               0.23007      0.00064     0.23117      0.22900
alpha_7                               0.29842      0.00033     0.29888      0.29778
alpha_8                               0.46802      0.00110     0.46912      0.46548
alpha_9                               0.34005      0.00108     0.34166      0.33799
Alpha_loss                            0.19084      0.12372     0.41843      -0.14308
Training/policy_loss                  184.65404    15.53377    223.65604    147.10274
Training/qf1_loss                     10917.35231  3961.48202  21299.56641  4421.77588
Training/qf2_loss                     1558.18195   395.59510   2725.54370   938.27094
Training/pf_norm                      16.38646     6.52116     34.36454     5.49236
Training/qf1_norm                     8400.80424   3780.11851  21561.65625  2873.60107
Training/qf2_norm                     5832.90383   2745.39781  14544.21973  1996.90735
log_std/mean                          -0.87511     0.00855     -0.85226     -0.89800
log_std/std                           0.39165      0.00710     0.41217      0.37847
log_std/max                           0.10287      0.08967     0.39990      -0.02020
log_std/min                           -2.86024     0.14141     -2.64657     -3.22136
log_probs/mean                        4.48387      0.17022     4.84891      4.10202
log_probs/std                         3.68819      0.10813     4.02779      3.40134
log_probs/max                         25.03540     1.69789     27.34014     18.64556
log_probs/min                         -6.33598     1.43282     -3.94242     -11.42110
mean/mean                             0.53525      0.03870     0.60016      0.43934
mean/std                              1.48058      0.01760     1.52674      1.43695
mean/max                              6.40728      0.39483     7.19144      5.72877
mean/min                              -5.34065     0.27538     -4.69326     -5.73250
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 5, 0, 6, 2, 4, 8, 1, 7, 3]
replay_buffer._size: [42300 42300 42300 42300 42300 42300 42300 42300 42300 42300]
2023-08-12 12:20:53,947 MainThread INFO: EPOCH:260
2023-08-12 12:20:53,947 MainThread INFO: Time Consumed:8.451246976852417s
2023-08-12 12:20:53,947 MainThread INFO: Total Frames:421500s
  3%|▎         | 261/10000 [39:33<24:02:05,  8.88s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               887.43006
Train_Epoch_Reward                    9241.83710
Running_Training_Average_Rewards      979.70332
Explore_Time                          0.00540
Train___Time                          8.44178
Eval____Time                          0.00341
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.74328
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.05908
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.28527
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -84.35568
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.60436
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.11805
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.26966
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9653.36485
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.03983
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -80.58907
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.92081      1.44714     10.66782     3.47426
alpha_0                               3.56071      0.02012     3.59421      3.52516
alpha_1                               0.72850      0.00094     0.72963      0.72664
alpha_2                               0.40729      0.00170     0.41002      0.40412
alpha_3                               0.28115      0.00027     0.28158      0.28072
alpha_4                               0.37668      0.00087     0.37799      0.37520
alpha_5                               0.50906      0.00240     0.51299      0.50484
alpha_6                               0.23268      0.00088     0.23432      0.23120
alpha_7                               0.29716      0.00037     0.29778      0.29652
alpha_8                               0.46575      0.00260     0.46896      0.46071
alpha_9                               0.33552      0.00146     0.33794      0.33291
Alpha_loss                            -0.00320     0.14151     0.37649      -0.32947
Training/policy_loss                  183.60163    16.35113    228.44315    145.02722
Training/qf1_loss                     10340.03417  3872.37188  22050.00781  4149.08984
Training/qf2_loss                     1612.28021   474.57874   3710.35132   855.18359
Training/pf_norm                      15.77464     7.05853     45.51819     6.90369
Training/qf1_norm                     8284.87165   3506.15845  18235.00586  3255.89380
Training/qf2_norm                     5276.40729   2711.26344  12856.05176  1389.48901
log_std/mean                          -0.85988     0.00909     -0.83986     -0.88122
log_std/std                           0.38381      0.00626     0.39819      0.36825
log_std/max                           0.17527      0.09159     0.44110      0.06557
log_std/min                           -2.80130     0.12378     -2.59423     -3.06440
log_probs/mean                        4.15398      0.18367     4.56622      3.80977
log_probs/std                         3.65843      0.10966     3.94637      3.39279
log_probs/max                         24.36815     1.91780     27.23850     17.66849
log_probs/min                         -6.46878     1.33876     -4.24539     -10.63821
mean/mean                             0.47081      0.05036     0.57013      0.36466
mean/std                              1.45424      0.01834     1.50617      1.42091
mean/max                              6.34696      0.41941     7.10397      5.62537
mean/min                              -5.27878     0.33834     -4.34366     -5.72915
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 9, 4, 1, 0, 6, 8, 5, 3, 2]
replay_buffer._size: [42450 42450 42450 42450 42450 42450 42450 42450 42450 42450]
2023-08-12 12:21:02,455 MainThread INFO: EPOCH:261
2023-08-12 12:21:02,455 MainThread INFO: Time Consumed:8.315144777297974s
2023-08-12 12:21:02,455 MainThread INFO: Total Frames:423000s
  3%|▎         | 262/10000 [39:41<23:44:08,  8.77s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               869.43253
Train_Epoch_Reward                    7474.30660
Running_Training_Average_Rewards      885.04181
Explore_Time                          0.00409
Train___Time                          8.30707
Eval____Time                          0.00327
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.32538
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.90867
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.92376
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.10789
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.14007
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -132.46470
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.51156
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9473.58724
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.40999
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -80.46992
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.55981      1.31514     9.36523      3.77215
alpha_0                               3.62430      0.01724     3.65357      3.59482
alpha_1                               0.72523      0.00059     0.72659      0.72456
alpha_2                               0.41210      0.00109     0.41372      0.41007
alpha_3                               0.28038      0.00013     0.28071      0.28022
alpha_4                               0.37375      0.00082     0.37517      0.37244
alpha_5                               0.51546      0.00131     0.51749      0.51305
alpha_6                               0.23641      0.00127     0.23875      0.23435
alpha_7                               0.29589      0.00033     0.29651      0.29530
alpha_8                               0.45376      0.00416     0.46060      0.44640
alpha_9                               0.33001      0.00167     0.33286      0.32718
Alpha_loss                            -0.09307     0.11559     0.16318      -0.32337
Training/policy_loss                  184.29010    15.70613    231.54898    144.07780
Training/qf1_loss                     11179.68712  4517.78700  24442.44727  4223.90967
Training/qf2_loss                     1543.64830   406.47988   2816.88745   943.93878
Training/pf_norm                      15.84043     7.20479     36.27472     6.45395
Training/qf1_norm                     8859.41585   4353.50908  30093.49805  2917.34399
Training/qf2_norm                     4574.07975   2271.50109  12480.52930  1504.48267
log_std/mean                          -0.86311     0.00950     -0.83141     -0.88786
log_std/std                           0.37863      0.00568     0.39377      0.36416
log_std/max                           0.24192      0.09570     0.54082      0.05646
log_std/min                           -2.76650     0.11535     -2.53345     -2.99498
log_probs/mean                        3.99199      0.13102     4.36590      3.70036
log_probs/std                         3.67733      0.11185     3.93732      3.36848
log_probs/max                         23.75753     1.97534     26.74829     16.75326
log_probs/min                         -6.48156     1.23954     -3.84301     -9.56462
mean/mean                             0.43899      0.03193     0.51119      0.37884
mean/std                              1.43800      0.01774     1.48735      1.40194
mean/max                              6.14317      0.40237     6.90999      5.47849
mean/min                              -5.24764     0.29300     -4.60300     -5.60552
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 4, 5, 2, 8, 9, 7, 6, 0]
replay_buffer._size: [42600 42600 42600 42600 42600 42600 42600 42600 42600 42600]
2023-08-12 12:21:11,667 MainThread INFO: EPOCH:262
2023-08-12 12:21:11,670 MainThread INFO: Time Consumed:9.02226996421814s
2023-08-12 12:21:11,670 MainThread INFO: Total Frames:424500s
  3%|▎         | 263/10000 [39:50<24:06:07,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               856.06127
Train_Epoch_Reward                    8767.98848
Running_Training_Average_Rewards      849.47107
Explore_Time                          0.00677
Train___Time                          9.01127
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -112.33406
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.55834
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.40098
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -85.24390
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.63240
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.15914
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.86076
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9324.32026
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.64103
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -79.87697
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.67026      1.26422     10.58887     3.78104
alpha_0                               3.68600      0.01806     3.71377      3.65414
alpha_1                               0.72273      0.00127     0.72454      0.72039
alpha_2                               0.41469      0.00044     0.41533      0.41374
alpha_3                               0.27992      0.00026     0.28025      0.27932
alpha_4                               0.37123      0.00065     0.37241      0.37024
alpha_5                               0.51874      0.00082     0.52031      0.51752
alpha_6                               0.24148      0.00159     0.24423      0.23880
alpha_7                               0.29499      0.00012     0.29529      0.29487
alpha_8                               0.43832      0.00467     0.44624      0.43019
alpha_9                               0.32422      0.00168     0.32713      0.32136
Alpha_loss                            -0.15764     0.10428     0.07109      -0.40455
Training/policy_loss                  184.08341    16.83147    231.18005    147.44572
Training/qf1_loss                     10261.75364  4048.99125  22312.01562  4142.34277
Training/qf2_loss                     1552.26782   396.64465   2690.60522   842.06494
Training/pf_norm                      13.75757     4.66693     26.89081     6.59274
Training/qf1_norm                     7717.58575   3305.46256  18923.88086  2232.23340
Training/qf2_norm                     4732.52000   2124.78583  12956.20703  1325.47949
log_std/mean                          -0.85943     0.00819     -0.84309     -0.87902
log_std/std                           0.37786      0.00685     0.39431      0.36445
log_std/max                           0.31462      0.05059     0.46605      0.10646
log_std/min                           -2.76424     0.08926     -2.59867     -2.92935
log_probs/mean                        3.88066      0.10888     4.16865      3.68308
log_probs/std                         3.68427      0.10374     3.94219      3.37420
log_probs/max                         24.37910     1.56913     28.00336     17.20947
log_probs/min                         -6.47657     1.29469     -4.16121     -10.97641
mean/mean                             0.42498      0.03203     0.49150      0.34393
mean/std                              1.42805      0.01512     1.46191      1.38765
mean/max                              6.12271      0.46636     6.94296      5.64779
mean/min                              -5.10430     0.27856     -4.51639     -5.44287
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 4, 9, 0, 5, 7, 1, 6, 3, 2]
replay_buffer._size: [42750 42750 42750 42750 42750 42750 42750 42750 42750 42750]
2023-08-12 12:21:20,963 MainThread INFO: EPOCH:263
2023-08-12 12:21:20,964 MainThread INFO: Time Consumed:9.10301160812378s
2023-08-12 12:21:20,964 MainThread INFO: Total Frames:426000s
  3%|▎         | 264/10000 [40:00<24:23:10,  9.02s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               882.51385
Train_Epoch_Reward                    8351.48636
Running_Training_Average_Rewards      819.79271
Explore_Time                          0.00429
Train___Time                          9.09436
Eval____Time                          0.00358
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.59560
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.25942
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.91253
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -83.28237
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.26586
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.94954
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.47151
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9584.56412
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.84700
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -79.84178
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70575      1.42538     10.17395     3.37562
alpha_0                               3.73716      0.01377     3.76191      3.71422
alpha_1                               0.71832      0.00130     0.72034      0.71595
alpha_2                               0.41611      0.00044     0.41675      0.41534
alpha_3                               0.27858      0.00031     0.27930      0.27802
alpha_4                               0.36940      0.00039     0.37021      0.36874
alpha_5                               0.52125      0.00035     0.52166      0.52035
alpha_6                               0.24758      0.00198     0.25100      0.24428
alpha_7                               0.29565      0.00034     0.29634      0.29503
alpha_8                               0.42164      0.00486     0.43003      0.41354
alpha_9                               0.31830      0.00174     0.32130      0.31539
Alpha_loss                            -0.10678     0.11958     0.20616      -0.39202
Training/policy_loss                  183.73417    15.81666    219.23567    128.76976
Training/qf1_loss                     10891.79634  4214.61754  25069.50781  4419.40186
Training/qf2_loss                     1571.34041   493.77345   3138.51392   740.67627
Training/pf_norm                      13.72223     4.72008     27.53853     6.20565
Training/qf1_norm                     9033.70652   4586.29538  29332.91797  3588.92822
Training/qf2_norm                     4978.14060   2393.89889  12245.03906  1208.33630
log_std/mean                          -0.85067     0.01054     -0.82720     -0.87797
log_std/std                           0.38257      0.00579     0.39335      0.36631
log_std/max                           0.29759      0.06485     0.48663      0.04099
log_std/min                           -2.81474     0.06290     -2.42221     -2.88761
log_probs/mean                        3.88009      0.10134     4.15387      3.67329
log_probs/std                         3.72217      0.09774     4.04655      3.47532
log_probs/max                         23.74915     1.96008     26.17639     15.52447
log_probs/min                         -6.63545     1.20717     -4.49429     -11.89322
mean/mean                             0.39930      0.02878     0.46665      0.31263
mean/std                              1.44022      0.01804     1.48441      1.39539
mean/max                              6.15965      0.44636     6.93342      5.45406
mean/min                              -5.21106     0.35844     -4.04299     -5.78290
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 5, 8, 0, 1, 2, 7, 4, 3, 6]
replay_buffer._size: [42908 42906 42905 42907 42907 42907 42908 42900 42907 42900]
2023-08-12 12:21:29,849 MainThread INFO: EPOCH:264
2023-08-12 12:21:29,850 MainThread INFO: Time Consumed:8.702529430389404s
2023-08-12 12:21:29,850 MainThread INFO: Total Frames:427500s
  3%|▎         | 265/10000 [40:09<24:19:02,  8.99s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               908.61484
Train_Epoch_Reward                    8208.76453
Running_Training_Average_Rewards      844.27465
Explore_Time                          0.08979
Train___Time                          8.60766
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -107.36662
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.49527
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.20343
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.00596
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.76886
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.98906
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.34673
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9845.19056
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.79955
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -77.06671
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.48692     1.35478     9.93548      3.18136
alpha_0                               3.78478     0.01228     3.80690      3.76230
alpha_1                               0.71297     0.00160     0.71589      0.71078
alpha_2                               0.41669     0.00012     0.41683      0.41644
alpha_3                               0.27664     0.00087     0.27799      0.27508
alpha_4                               0.36735     0.00072     0.36872      0.36627
alpha_5                               0.52073     0.00047     0.52129      0.52009
alpha_6                               0.25440     0.00195     0.25782      0.25107
alpha_7                               0.29730     0.00065     0.29870      0.29636
alpha_8                               0.40773     0.00274     0.41339      0.40442
alpha_9                               0.31254     0.00162     0.31533      0.30984
Alpha_loss                            -0.11817    0.13759     0.17834      -0.40823
Training/policy_loss                  184.12158   15.12899    224.40147    131.96175
Training/qf1_loss                     9555.02261  3200.37384  18524.37305  3776.77612
Training/qf2_loss                     1442.26713  381.84789   2778.26294   861.09711
Training/pf_norm                      14.91912    5.19530     29.82183     6.66871
Training/qf1_norm                     7289.08643  2649.14356  15630.45703  1781.09216
Training/qf2_norm                     4881.01901  2614.37174  13206.54785  1273.46545
log_std/mean                          -0.86256    0.01430     -0.83577     -0.89001
log_std/std                           0.38328     0.00598     0.39972      0.36974
log_std/max                           0.23377     0.05728     0.38673      0.03637
log_std/min                           -2.82768    0.08583     -2.46725     -3.00537
log_probs/mean                        3.87619     0.15491     4.25240      3.59312
log_probs/std                         3.63740     0.10150     3.94310      3.41577
log_probs/max                         23.27477    1.99988     25.88437     16.86276
log_probs/min                         -6.55813    1.31470     -4.25113     -10.88738
mean/mean                             0.34937     0.02817     0.41440      0.29321
mean/std                              1.44115     0.01883     1.47682      1.40616
mean/max                              6.13047     0.44609     6.94925      5.00470
mean/min                              -5.29014    0.43217     -4.21112     -5.81077
------------------------------------  ----------  ----------  -----------  ----------
sample: [6, 4, 8, 2, 5, 1, 3, 9, 7, 0]
replay_buffer._size: [43050 43050 43050 43050 43050 43050 43050 43050 43050 43050]
2023-08-12 12:21:38,939 MainThread INFO: EPOCH:265
2023-08-12 12:21:38,940 MainThread INFO: Time Consumed:8.902729988098145s
2023-08-12 12:21:38,940 MainThread INFO: Total Frames:429000s
  3%|▎         | 266/10000 [40:18<24:21:15,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               874.22332
Train_Epoch_Reward                    8218.90690
Running_Training_Average_Rewards      825.97193
Explore_Time                          0.00498
Train___Time                          8.89263
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -106.73229
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.94681
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.88607
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -82.93804
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.73014
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.83423
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.13547
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9481.02167
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.25161
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.33383
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.25300      1.24651     9.89866      3.34366
alpha_0                               3.82993      0.01225     3.84830      3.80748
alpha_1                               0.70805      0.00183     0.71075      0.70485
alpha_2                               0.41621      0.00011     0.41643      0.41603
alpha_3                               0.27283      0.00148     0.27505      0.27021
alpha_4                               0.36515      0.00074     0.36625      0.36381
alpha_5                               0.51969      0.00035     0.52018      0.51873
alpha_6                               0.26148      0.00211     0.26504      0.25789
alpha_7                               0.30053      0.00108     0.30258      0.29874
alpha_8                               0.40531      0.00094     0.40728      0.40431
alpha_9                               0.30696      0.00168     0.30979      0.30411
Alpha_loss                            -0.00928     0.11035     0.19990      -0.27754
Training/policy_loss                  182.79923    16.49617    228.01270    146.56400
Training/qf1_loss                     10311.54759  3428.73990  20149.58789  4329.15186
Training/qf2_loss                     1387.20196   351.69133   2401.86792   683.94135
Training/pf_norm                      16.63472     7.55124     40.54221     5.24895
Training/qf1_norm                     7239.71522   3433.62880  21509.05078  2335.14868
Training/qf2_norm                     4651.81802   2338.59685  14035.51855  1367.10120
log_std/mean                          -0.85507     0.00787     -0.83553     -0.87163
log_std/std                           0.38552      0.00533     0.39809      0.37284
log_std/max                           0.16293      0.05968     0.36038      0.03920
log_std/min                           -2.83739     0.09754     -2.42749     -3.00992
log_probs/mean                        3.98313      0.10591     4.24239      3.74348
log_probs/std                         3.63808      0.10442     3.95768      3.43457
log_probs/max                         23.03757     1.69438     25.13448     18.21637
log_probs/min                         -6.58370     1.49797     -4.31379     -10.87702
mean/mean                             0.28695      0.03395     0.36360      0.20565
mean/std                              1.47362      0.01582     1.51330      1.44028
mean/max                              6.18102      0.39575     6.88642      4.94698
mean/min                              -5.30153     0.56006     -4.09350     -6.04092
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 7, 5, 3, 8, 4, 9, 6, 1]
replay_buffer._size: [43200 43200 43200 43200 43200 43200 43200 43200 43200 43200]
2023-08-12 12:21:48,554 MainThread INFO: EPOCH:266
2023-08-12 12:21:48,554 MainThread INFO: Time Consumed:9.456703186035156s
2023-08-12 12:21:48,555 MainThread INFO: Total Frames:430500s
  3%|▎         | 267/10000 [40:27<24:52:12,  9.20s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               911.89922
Train_Epoch_Reward                    9417.10785
Running_Training_Average_Rewards      861.49264
Explore_Time                          0.00499
Train___Time                          9.44648
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -111.08603
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.31606
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.24332
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.18836
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.01943
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.55770
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.56836
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9862.20326
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.75512
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.47664
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.38788      1.37644     9.50418      3.40248
alpha_0                               3.86637      0.00879     3.87787      3.84875
alpha_1                               0.70118      0.00228     0.70479      0.69679
alpha_2                               0.41535      0.00041     0.41603      0.41471
alpha_3                               0.26723      0.00189     0.27015      0.26390
alpha_4                               0.36200      0.00114     0.36378      0.36011
alpha_5                               0.51731      0.00077     0.51869      0.51619
alpha_6                               0.26827      0.00179     0.27126      0.26511
alpha_7                               0.30523      0.00157     0.30808      0.30263
alpha_8                               0.41024      0.00157     0.41266      0.40734
alpha_9                               0.30128      0.00161     0.30405      0.29854
Alpha_loss                            -0.10156     0.11241     0.12268      -0.36002
Training/policy_loss                  181.88215    17.34040    217.97549    132.48178
Training/qf1_loss                     10311.79657  4033.46921  21489.19336  3410.46948
Training/qf2_loss                     1478.84340   453.29999   3052.06226   855.93115
Training/pf_norm                      12.88576     4.41442     24.25978     6.10372
Training/qf1_norm                     8414.37916   3995.26053  23740.64844  2314.38794
Training/qf2_norm                     4495.65956   2194.06832  11179.55859  1404.73999
log_std/mean                          -0.84442     0.01108     -0.82441     -0.87404
log_std/std                           0.38507      0.00407     0.39691      0.37133
log_std/max                           0.15751      0.07732     0.36447      0.02674
log_std/min                           -2.76530     0.14056     -2.26918     -2.95183
log_probs/mean                        3.87019      0.13297     4.21077      3.56582
log_probs/std                         3.60702      0.09075     3.83942      3.41114
log_probs/max                         22.68393     1.58231     24.93703     16.74647
log_probs/min                         -6.59818     1.19541     -4.53108     -10.42328
mean/mean                             0.27550      0.03072     0.37129      0.21327
mean/std                              1.46293      0.01641     1.50215      1.42303
mean/max                              6.22242      0.32812     6.88442      4.97611
mean/min                              -5.34017     0.62454     -4.28905     -6.15416
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 9, 5, 6, 8, 1, 4, 7, 2, 3]
replay_buffer._size: [43350 43350 43350 43350 43350 43350 43350 43350 43350 43350]
2023-08-12 12:21:57,675 MainThread INFO: EPOCH:267
2023-08-12 12:21:57,676 MainThread INFO: Time Consumed:8.944355249404907s
2023-08-12 12:21:57,676 MainThread INFO: Total Frames:432000s
  3%|▎         | 268/10000 [40:36<24:46:57,  9.17s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               956.80306
Train_Epoch_Reward                    9889.63588
Running_Training_Average_Rewards      917.52169
Explore_Time                          0.00968
Train___Time                          8.92928
Eval____Time                          0.00468
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.63269
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.11458
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.95167
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -82.20400
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.29121
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.43886
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.84308
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10308.15579
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.96734
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.68171
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.58993      1.49722     11.27582     3.74617
alpha_0                               3.89362      0.00809     3.90476      3.87795
alpha_1                               0.69235      0.00262     0.69669      0.68779
alpha_2                               0.41462      0.00009     0.41471      0.41441
alpha_3                               0.26016      0.00227     0.26382      0.25596
alpha_4                               0.35844      0.00100     0.36007      0.35678
alpha_5                               0.51420      0.00109     0.51617      0.51263
alpha_6                               0.27406      0.00158     0.27672      0.27132
alpha_7                               0.31153      0.00209     0.31543      0.30814
alpha_8                               0.41490      0.00128     0.41711      0.41271
alpha_9                               0.29630      0.00124     0.29849      0.29427
Alpha_loss                            -0.10198     0.10741     0.18988      -0.34369
Training/policy_loss                  179.93085    18.46102    224.92354    133.00438
Training/qf1_loss                     10533.95438  4204.55499  21414.46484  4647.83057
Training/qf2_loss                     1503.25556   467.83232   3436.92456   726.22656
Training/pf_norm                      15.54188     6.79293     35.85428     5.50220
Training/qf1_norm                     8857.08571   4641.99290  23532.22461  2846.11963
Training/qf2_norm                     4715.16405   2444.10117  12904.15039  1485.12317
log_std/mean                          -0.83958     0.01123     -0.81522     -0.86277
log_std/std                           0.37927      0.00384     0.38742      0.36925
log_std/max                           0.20532      0.08415     0.36975      0.03235
log_std/min                           -2.72414     0.19687     -2.19316     -2.94944
log_probs/mean                        3.87916      0.11413     4.10200      3.60656
log_probs/std                         3.58939      0.09998     3.84657      3.34161
log_probs/max                         21.39581     1.84567     23.94337     17.09578
log_probs/min                         -6.65936     1.40692     -4.36063     -12.76241
mean/mean                             0.29504      0.03240     0.34942      0.21168
mean/std                              1.46014      0.01428     1.48965      1.42125
mean/max                              5.99143      0.30380     6.60027      4.53808
mean/min                              -5.22885     0.73482     -4.09260     -6.21593
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 4, 9, 8, 3, 5, 1, 2, 7, 6]
replay_buffer._size: [43500 43500 43500 43500 43500 43500 43500 43500 43500 43500]
2023-08-12 12:22:06,447 MainThread INFO: EPOCH:268
2023-08-12 12:22:06,447 MainThread INFO: Time Consumed:8.575069427490234s
2023-08-12 12:22:06,447 MainThread INFO: Total Frames:433500s
  3%|▎         | 269/10000 [40:45<24:27:26,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               951.23829
Train_Epoch_Reward                    9212.31180
Running_Training_Average_Rewards      950.63518
Explore_Time                          0.01682
Train___Time                          8.55307
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -111.75421
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.05334
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.58736
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -82.03689
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.79561
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -134.31568
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.19313
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10260.13169
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.11776
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.89483
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.57958      1.26832     9.23053      3.47523
alpha_0                               3.90790      0.00172     3.91010      3.90476
alpha_1                               0.68291      0.00270     0.68768      0.67838
alpha_2                               0.41431      0.00011     0.41446      0.41409
alpha_3                               0.25116      0.00277     0.25586      0.24634
alpha_4                               0.35521      0.00082     0.35674      0.35380
alpha_5                               0.51124      0.00086     0.51261      0.50950
alpha_6                               0.27938      0.00149     0.28179      0.27677
alpha_7                               0.31912      0.00205     0.32253      0.31552
alpha_8                               0.41875      0.00101     0.42070      0.41715
alpha_9                               0.29220      0.00119     0.29424      0.29031
Alpha_loss                            -0.16693     0.12035     0.17835      -0.52583
Training/policy_loss                  180.15907    17.87037    224.73006    138.80162
Training/qf1_loss                     10118.75243  3980.27537  21262.77930  4012.48096
Training/qf2_loss                     1401.34058   413.21163   2584.94727   616.04230
Training/pf_norm                      14.64914     5.07278     33.67649     7.18589
Training/qf1_norm                     7920.68927   3539.80252  23952.06836  2747.13330
Training/qf2_norm                     5565.17097   2673.45005  16845.65430  1727.96619
log_std/mean                          -0.83220     0.00946     -0.80429     -0.85828
log_std/std                           0.38017      0.00454     0.39076      0.36819
log_std/max                           0.23407      0.07796     0.36717      0.08169
log_std/min                           -2.77328     0.20175     -2.19902     -2.99113
log_probs/mean                        3.79551      0.14011     4.15717      3.41905
log_probs/std                         3.56382      0.09700     3.80635      3.34002
log_probs/max                         21.39969     1.46109     23.41368     16.13239
log_probs/min                         -6.55929     1.39966     -4.03903     -11.63025
mean/mean                             0.29756      0.03759     0.37212      0.19905
mean/std                              1.44915      0.01857     1.49038      1.39653
mean/max                              6.00630      0.27818     6.38608      4.39474
mean/min                              -5.42423     0.76815     -4.41498     -6.37407
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 2, 0, 5, 8, 6, 7, 3, 4]
replay_buffer._size: [43650 43650 43650 43650 43650 43650 43650 43650 43650 43650]
2023-08-12 12:22:15,017 MainThread INFO: EPOCH:269
2023-08-12 12:22:15,017 MainThread INFO: Time Consumed:8.403724908828735s
2023-08-12 12:22:15,017 MainThread INFO: Total Frames:435000s
  3%|▎         | 270/10000 [40:54<24:03:55,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               915.58008
Train_Epoch_Reward                    10086.96841
Running_Training_Average_Rewards      972.96387
Explore_Time                          0.00448
Train___Time                          8.39411
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.77186
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.93199
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.02180
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -78.55756
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.09143
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -133.83923
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.23739
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9895.95708
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.00745
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.69760
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.73643      1.24813     9.97315      3.74423
alpha_0                               3.91241      0.00374     3.91833      3.90752
alpha_1                               0.67337      0.00277     0.67827      0.66858
alpha_2                               0.41380      0.00023     0.41408      0.41323
alpha_3                               0.24150      0.00276     0.24624      0.23667
alpha_4                               0.35188      0.00103     0.35375      0.35008
alpha_5                               0.50731      0.00125     0.50946      0.50493
alpha_6                               0.28357      0.00102     0.28521      0.28182
alpha_7                               0.32546      0.00185     0.32882      0.32259
alpha_8                               0.42283      0.00149     0.42560      0.42073
alpha_9                               0.28831      0.00120     0.29028      0.28623
Alpha_loss                            -0.29495     0.11857     0.06137      -0.58408
Training/policy_loss                  178.65048    15.50846    218.92188    142.19897
Training/qf1_loss                     10528.30354  4451.53979  24216.39648  3807.06836
Training/qf2_loss                     1414.33673   340.85849   2607.81909   768.10120
Training/pf_norm                      16.43198     6.67610     36.39810     5.72927
Training/qf1_norm                     8018.22604   3601.79136  24751.54297  2979.10767
Training/qf2_norm                     4570.17413   1964.84082  9277.75781   1438.85242
log_std/mean                          -0.83752     0.01115     -0.80524     -0.85272
log_std/std                           0.38449      0.00444     0.39638      0.37507
log_std/max                           0.25475      0.08430     0.43142      0.12808
log_std/min                           -2.83184     0.20752     -2.33748     -3.04841
log_probs/mean                        3.71533      0.11595     3.99044      3.39923
log_probs/std                         3.48579      0.08707     3.72163      3.24374
log_probs/max                         20.85965     1.62481     23.31846     16.03288
log_probs/min                         -6.69350     1.41981     -4.35052     -10.94896
mean/mean                             0.28160      0.03988     0.39271      0.21158
mean/std                              1.43512      0.01473     1.47306      1.40385
mean/max                              5.90144      0.26887     6.18066      4.55894
mean/min                              -5.31970     0.80049     -4.44617     -6.36030
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 8, 6, 2, 0, 7, 3, 4, 5]
replay_buffer._size: [43800 43800 43800 43800 43800 43800 43800 43800 43800 43800]
2023-08-12 12:22:24,236 MainThread INFO: EPOCH:270
2023-08-12 12:22:24,236 MainThread INFO: Time Consumed:8.999789237976074s
2023-08-12 12:22:24,236 MainThread INFO: Total Frames:436500s
  3%|▎         | 271/10000 [41:03<24:18:58,  9.00s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               856.64862
Train_Epoch_Reward                    10008.63797
Running_Training_Average_Rewards      976.93061
Explore_Time                          0.00487
Train___Time                          8.99031
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -105.20714
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.73524
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.76957
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -73.20782
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.00674
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -133.42452
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.21472
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9303.63847
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.64523
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.94126
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.50494      1.38138     11.98731     3.42562
alpha_0                               3.92104      0.00233     3.92589      3.91797
alpha_1                               0.66326      0.00322     0.66848      0.65765
alpha_2                               0.41298      0.00018     0.41322      0.41262
alpha_3                               0.23229      0.00248     0.23658      0.22799
alpha_4                               0.34874      0.00074     0.35005      0.34752
alpha_5                               0.50292      0.00105     0.50488      0.50130
alpha_6                               0.28666      0.00077     0.28791      0.28524
alpha_7                               0.33222      0.00198     0.33571      0.32888
alpha_8                               0.42793      0.00140     0.43025      0.42565
alpha_9                               0.28411      0.00124     0.28619      0.28199
Alpha_loss                            -0.29780     0.12884     0.01344      -0.59876
Training/policy_loss                  181.00494    17.77415    224.92204    140.62332
Training/qf1_loss                     9958.64799   3854.38936  21766.05273  4345.35303
Training/qf2_loss                     1412.72424   410.97813   3249.45239   760.85638
Training/pf_norm                      15.93492     5.67248     32.56553     7.82713
Training/qf1_norm                     7809.51120   3678.90565  21837.41406  2262.70703
Training/qf2_norm                     4937.56727   2409.59014  12846.83105  1386.20825
log_std/mean                          -0.82870     0.00769     -0.80891     -0.84763
log_std/std                           0.38901      0.00374     0.39774      0.37844
log_std/max                           0.31116      0.08843     0.50845      0.18355
log_std/min                           -2.84261     0.21743     -2.39984     -3.09845
log_probs/mean                        3.71430      0.12534     4.08307      3.38693
log_probs/std                         3.52422      0.09609     3.69613      3.28895
log_probs/max                         20.68669     1.75621     24.30630     14.56797
log_probs/min                         -6.62002     1.55517     -4.11685     -12.22549
mean/mean                             0.27592      0.02836     0.33686      0.21803
mean/std                              1.44092      0.01622     1.48535      1.40336
mean/max                              5.92292      0.23263     6.20394      4.45374
mean/min                              -5.39971     0.74838     -4.33567     -6.49311
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 5, 2, 4, 9, 3, 1, 6, 7]
replay_buffer._size: [43950 43950 43950 43950 43950 43950 43950 43950 43950 43950]
2023-08-12 12:22:32,769 MainThread INFO: EPOCH:271
2023-08-12 12:22:32,769 MainThread INFO: Time Consumed:8.375694036483765s
2023-08-12 12:22:32,769 MainThread INFO: Total Frames:438000s
  3%|▎         | 272/10000 [41:12<24:00:21,  8.88s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               932.38131
Train_Epoch_Reward                    7832.17624
Running_Training_Average_Rewards      930.92609
Explore_Time                          0.00364
Train___Time                          8.36773
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -114.42303
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.69241
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.96117
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.96110
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.63520
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -131.00700
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -86.03502
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10070.51538
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.69272
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.29465
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.55399      1.28121     9.57300      3.56148
alpha_0                               3.93479      0.00434     3.93994      3.92602
alpha_1                               0.65209      0.00318     0.65753      0.64655
alpha_2                               0.41191      0.00043     0.41261      0.41120
alpha_3                               0.22356      0.00259     0.22789      0.21921
alpha_4                               0.34610      0.00092     0.34750      0.34443
alpha_5                               0.49983      0.00082     0.50127      0.49849
alpha_6                               0.28875      0.00045     0.28955      0.28793
alpha_7                               0.33896      0.00187     0.34229      0.33578
alpha_8                               0.43224      0.00120     0.43432      0.43029
alpha_9                               0.27992      0.00122     0.28194      0.27780
Alpha_loss                            -0.38858     0.11785     -0.06278     -0.64256
Training/policy_loss                  180.10499    17.12545    228.86368    133.42101
Training/qf1_loss                     9184.07302   3206.42896  21019.72266  4561.88135
Training/qf2_loss                     1409.87183   366.74394   2499.77368   747.52295
Training/pf_norm                      15.61334     5.62199     35.30748     6.45153
Training/qf1_norm                     7405.65432   3059.38731  17545.65039  2081.28467
Training/qf2_norm                     5011.63458   1976.97872  9580.84863   1944.44836
log_std/mean                          -0.82762     0.00628     -0.81284     -0.84411
log_std/std                           0.40076      0.00710     0.41663      0.38416
log_std/max                           0.33676      0.09845     0.51862      0.11696
log_std/min                           -2.89627     0.22358     -2.49029     -3.14717
log_probs/mean                        3.65889      0.12374     3.93774      3.40380
log_probs/std                         3.48601      0.08593     3.66505      3.27805
log_probs/max                         20.65224     1.83673     23.77267     15.40078
log_probs/min                         -6.85004     1.49778     -4.43917     -12.12451
mean/mean                             0.30993      0.03203     0.38397      0.25352
mean/std                              1.42428      0.01645     1.46249      1.37760
mean/max                              5.91825      0.19263     6.14519      4.91852
mean/min                              -5.37109     0.82713     -4.27148     -6.47937
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 8, 7, 0, 6, 9, 3, 1, 2]
replay_buffer._size: [44100 44100 44100 44100 44100 44100 44100 44100 44100 44100]
2023-08-12 12:22:41,630 MainThread INFO: EPOCH:272
2023-08-12 12:22:41,631 MainThread INFO: Time Consumed:8.679491519927979s
2023-08-12 12:22:41,631 MainThread INFO: Total Frames:439500s
  3%|▎         | 273/10000 [41:20<23:56:42,  8.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               955.76932
Train_Epoch_Reward                    10527.04759
Running_Training_Average_Rewards      945.59539
Explore_Time                          0.00732
Train___Time                          8.66628
Eval____Time                          0.00509
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -111.61144
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.79063
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.18288
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.30198
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.72104
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -120.68676
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.63575
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10286.80210
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.95864
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.21980
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.59336      1.42240     10.87428     3.64092
alpha_0                               3.94891      0.00478     3.95635      3.94004
alpha_1                               0.64150      0.00269     0.64642      0.63715
alpha_2                               0.41043      0.00048     0.41119      0.40959
alpha_3                               0.21496      0.00247     0.21913      0.21082
alpha_4                               0.34286      0.00084     0.34439      0.34179
alpha_5                               0.49726      0.00064     0.49845      0.49625
alpha_6                               0.29033      0.00043     0.29100      0.28956
alpha_7                               0.34587      0.00206     0.34928      0.34236
alpha_8                               0.43650      0.00126     0.43856      0.43436
alpha_9                               0.27621      0.00090     0.27776      0.27457
Alpha_loss                            -0.36795     0.10447     -0.14355     -0.63521
Training/policy_loss                  178.26315    15.72426    210.87190    138.16313
Training/qf1_loss                     10507.00463  4359.99249  24787.01562  3359.46411
Training/qf2_loss                     1449.56384   414.51621   2861.12964   736.86841
Training/pf_norm                      15.53353     6.68632     37.89618     7.18350
Training/qf1_norm                     8367.09094   3424.37465  18253.34375  3303.11353
Training/qf2_norm                     5114.45271   2288.07339  11917.87988  1298.36243
log_std/mean                          -0.83511     0.00833     -0.82109     -0.86061
log_std/std                           0.40566      0.00492     0.42134      0.39294
log_std/max                           0.42970      0.12815     0.69831      0.19625
log_std/min                           -2.83937     0.22956     -2.28836     -3.11066
log_probs/mean                        3.71272      0.10926     3.93031      3.50551
log_probs/std                         3.46528      0.08713     3.69223      3.27950
log_probs/max                         20.24518     2.14248     24.25548     14.74114
log_probs/min                         -6.65068     1.29347     -4.58270     -10.27943
mean/mean                             0.28140      0.02096     0.34522      0.22475
mean/std                              1.43505      0.01540     1.47534      1.40120
mean/max                              5.92862      0.29147     6.29287      4.46888
mean/min                              -5.52276     0.76976     -4.35399     -6.57810
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 0, 4, 5, 7, 6, 2, 9, 8]
replay_buffer._size: [44250 44250 44250 44250 44250 44250 44250 44250 44250 44250]
2023-08-12 12:22:50,195 MainThread INFO: EPOCH:273
2023-08-12 12:22:50,195 MainThread INFO: Time Consumed:8.425814867019653s
2023-08-12 12:22:50,195 MainThread INFO: Total Frames:441000s
  3%|▎         | 274/10000 [41:29<23:40:33,  8.76s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               959.32050
Train_Epoch_Reward                    9094.18684
Running_Training_Average_Rewards      915.11369
Explore_Time                          0.00896
Train___Time                          8.41184
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -112.64428
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.53706
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.18423
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.96093
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.90648
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.42059
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.67540
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10311.11071
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.11203
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.46472
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.50302      1.30456     9.48716      3.42411
alpha_0                               3.95758      0.00313     3.96269      3.95260
alpha_1                               0.63304      0.00222     0.63707      0.62919
alpha_2                               0.40881      0.00031     0.40957      0.40826
alpha_3                               0.20684      0.00226     0.21075      0.20310
alpha_4                               0.34058      0.00060     0.34178      0.33951
alpha_5                               0.49439      0.00110     0.49622      0.49206
alpha_6                               0.29131      0.00015     0.29151      0.29101
alpha_7                               0.35257      0.00185     0.35560      0.34934
alpha_8                               0.44073      0.00113     0.44273      0.43860
alpha_9                               0.27278      0.00102     0.27453      0.27099
Alpha_loss                            -0.40787     0.13080     -0.10689     -0.74330
Training/policy_loss                  178.14116    16.70402    218.47046    140.33066
Training/qf1_loss                     9731.33913   4201.13728  27989.78125  3254.98120
Training/qf2_loss                     1382.75148   377.96368   2646.81836   742.24384
Training/pf_norm                      15.41122     7.01675     43.46379     6.81416
Training/qf1_norm                     8166.67833   4482.40739  33157.79297  3419.65747
Training/qf2_norm                     4777.84950   2238.97984  12304.36035  1359.94617
log_std/mean                          -0.82328     0.00618     -0.80609     -0.83904
log_std/std                           0.41006      0.00406     0.41839      0.40192
log_std/max                           0.48100      0.09859     0.72705      0.30179
log_std/min                           -2.86782     0.21486     -2.28640     -3.13471
log_probs/mean                        3.65753      0.12214     4.04709      3.29654
log_probs/std                         3.46164      0.07712     3.64695      3.25559
log_probs/max                         20.73266     1.88397     23.97431     16.04375
log_probs/min                         -6.52468     1.38323     -4.39855     -10.66393
mean/mean                             0.23877      0.02257     0.29625      0.17893
mean/std                              1.44016      0.01611     1.47987      1.40054
mean/max                              5.97849      0.35037     6.41246      4.64937
mean/min                              -5.52549     0.79083     -3.68311     -6.57925
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 5, 9, 4, 1, 2, 6, 7, 3]
replay_buffer._size: [44400 44400 44400 44400 44400 44400 44400 44400 44400 44400]
2023-08-12 12:22:59,448 MainThread INFO: EPOCH:274
2023-08-12 12:22:59,449 MainThread INFO: Time Consumed:9.093337774276733s
2023-08-12 12:22:59,449 MainThread INFO: Total Frames:442500s
  3%|▎         | 275/10000 [41:38<24:08:10,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               882.74703
Train_Epoch_Reward                    9484.26577
Running_Training_Average_Rewards      970.18334
Explore_Time                          0.00575
Train___Time                          9.08263
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.76970
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.89143
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.15611
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -78.83637
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.05262
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.02726
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.02519
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9516.02014
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.17778
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.61338
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65851      1.19440     10.25134     4.21073
alpha_0                               3.96350      0.00339     3.96742      3.95599
alpha_1                               0.62645      0.00122     0.62911      0.62465
alpha_2                               0.40689      0.00091     0.40825      0.40518
alpha_3                               0.19971      0.00196     0.20303      0.19632
alpha_4                               0.33888      0.00032     0.33948      0.33816
alpha_5                               0.48925      0.00140     0.49199      0.48687
alpha_6                               0.29085      0.00027     0.29137      0.29027
alpha_7                               0.35905      0.00198     0.36256      0.35568
alpha_8                               0.44573      0.00172     0.44893      0.44279
alpha_9                               0.26931      0.00089     0.27095      0.26786
Alpha_loss                            -0.40196     0.10853     -0.14049     -0.59719
Training/policy_loss                  174.19311    18.06361    217.51285    128.83388
Training/qf1_loss                     10451.42927  4112.53487  22838.96680  4020.45508
Training/qf2_loss                     1374.40919   373.04876   2701.58667   734.62762
Training/pf_norm                      15.38421     5.73024     30.29536     6.42835
Training/qf1_norm                     8131.90333   3174.75604  18340.45508  2371.64160
Training/qf2_norm                     5109.70141   2466.59916  12268.12012  1238.05151
log_std/mean                          -0.83922     0.00686     -0.81720     -0.85340
log_std/std                           0.40826      0.00428     0.41853      0.39791
log_std/max                           0.59866      0.10117     0.81383      0.30104
log_std/min                           -2.81612     0.21429     -2.20243     -3.01564
log_probs/mean                        3.69503      0.10565     3.98564      3.39581
log_probs/std                         3.45032      0.08980     3.70110      3.17558
log_probs/max                         19.95544     2.46171     24.36800     15.09509
log_probs/min                         -6.53575     1.38253     -4.32496     -11.91514
mean/mean                             0.24964      0.02790     0.31446      0.17684
mean/std                              1.43240      0.01468     1.47283      1.40119
mean/max                              5.91972      0.45009     6.39384      4.40329
mean/min                              -5.60108     0.64082     -3.58592     -6.51484
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 3, 7, 6, 4, 8, 5, 1, 9]
replay_buffer._size: [44550 44550 44550 44550 44550 44550 44550 44550 44550 44550]
2023-08-12 12:23:08,483 MainThread INFO: EPOCH:275
2023-08-12 12:23:08,484 MainThread INFO: Time Consumed:8.837002515792847s
2023-08-12 12:23:08,484 MainThread INFO: Total Frames:444000s
  3%|▎         | 276/10000 [41:47<24:09:04,  8.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1024.38346
Train_Epoch_Reward                    8103.58704
Running_Training_Average_Rewards      889.40132
Explore_Time                          0.00511
Train___Time                          8.82683
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.87771
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.62695
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.41693
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.16777
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.44884
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.81361
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.63593
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10935.94399
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.94665
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.17499
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.44193      1.32419     10.02321     3.61741
alpha_0                               3.94599      0.00692     3.96275      3.93631
alpha_1                               0.62331      0.00056     0.62461      0.62271
alpha_2                               0.40389      0.00054     0.40514      0.40314
alpha_3                               0.19311      0.00176     0.19624      0.19014
alpha_4                               0.33843      0.00026     0.33877      0.33802
alpha_5                               0.48518      0.00097     0.48682      0.48357
alpha_6                               0.28912      0.00067     0.29025      0.28799
alpha_7                               0.36599      0.00190     0.36892      0.36264
alpha_8                               0.45255      0.00235     0.45674      0.44899
alpha_9                               0.26629      0.00087     0.26784      0.26486
Alpha_loss                            -0.31694     0.10407     -0.08155     -0.57818
Training/policy_loss                  176.50472    16.60961    215.07182    143.59801
Training/qf1_loss                     10311.19126  4156.78337  21275.49023  4556.54785
Training/qf2_loss                     1372.56032   397.24685   2722.13818   725.64032
Training/pf_norm                      17.83387     6.58399     42.01621     7.52676
Training/qf1_norm                     8675.06182   3614.76022  21431.16016  3542.61597
Training/qf2_norm                     4808.56193   2346.97532  12934.66309  1498.35828
log_std/mean                          -0.84055     0.00994     -0.81199     -0.86073
log_std/std                           0.41143      0.00486     0.42188      0.40029
log_std/max                           0.82677      0.10740     0.96654      0.32931
log_std/min                           -2.81271     0.19081     -2.35577     -3.04492
log_probs/mean                        3.76914      0.11912     4.02290      3.44032
log_probs/std                         3.43354      0.08490     3.64778      3.20670
log_probs/max                         19.68272     2.43137     24.14588     14.54854
log_probs/min                         -6.59869     1.46032     -4.49654     -10.58764
mean/mean                             0.27414      0.02485     0.33488      0.23098
mean/std                              1.44031      0.01464     1.47055      1.41004
mean/max                              5.84945      0.51489     6.46331      4.14993
mean/min                              -5.58305     0.51434     -3.64740     -6.32927
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 6, 9, 1, 3, 7, 8, 0, 5]
replay_buffer._size: [44700 44700 44700 44700 44700 44700 44700 44700 44700 44700]
2023-08-12 12:23:17,092 MainThread INFO: EPOCH:276
2023-08-12 12:23:17,092 MainThread INFO: Time Consumed:8.407506704330444s
2023-08-12 12:23:17,092 MainThread INFO: Total Frames:445500s
  3%|▎         | 277/10000 [41:56<23:52:32,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1070.99086
Train_Epoch_Reward                    9117.88048
Running_Training_Average_Rewards      890.19111
Explore_Time                          0.00366
Train___Time                          8.39923
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.38950
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.15244
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.05052
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.51209
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.34690
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.25972
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.97025
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11398.24914
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.10171
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.55738
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.53770      1.27583     10.87134     3.68457
alpha_0                               3.93083      0.00278     3.93639      3.92701
alpha_1                               0.62276      0.00034     0.62365      0.62237
alpha_2                               0.40263      0.00029     0.40313      0.40220
alpha_3                               0.18715      0.00165     0.19008      0.18434
alpha_4                               0.33762      0.00048     0.33846      0.33683
alpha_5                               0.48264      0.00036     0.48354      0.48227
alpha_6                               0.28647      0.00092     0.28796      0.28482
alpha_7                               0.37245      0.00230     0.37687      0.36897
alpha_8                               0.46070      0.00242     0.46508      0.45681
alpha_9                               0.26311      0.00096     0.26483      0.26150
Alpha_loss                            -0.33373     0.11752     -0.04849     -0.63547
Training/policy_loss                  174.29066    20.69045    220.52173    118.13836
Training/qf1_loss                     10054.00378  3903.90913  25690.98242  3911.11011
Training/qf2_loss                     1423.28858   356.33183   2124.51636   804.41547
Training/pf_norm                      15.80202     6.52391     39.80194     7.00025
Training/qf1_norm                     7956.33908   3844.39326  25606.96094  2523.21899
Training/qf2_norm                     5098.15571   2619.15999  16198.53809  1348.56897
log_std/mean                          -0.84588     0.01122     -0.82683     -0.87171
log_std/std                           0.41673      0.00507     0.42906      0.40367
log_std/max                           0.92187      0.12793     1.05360      0.31232
log_std/min                           -2.76723     0.19087     -2.45219     -3.01710
log_probs/mean                        3.81203      0.12653     4.14420      3.52757
log_probs/std                         3.41328      0.09209     3.63114      3.16047
log_probs/max                         19.64382     2.01871     24.06609     14.26596
log_probs/min                         -6.21768     1.26103     -3.86201     -12.40132
mean/mean                             0.25186      0.03455     0.34670      0.17179
mean/std                              1.45076      0.01411     1.49091      1.41525
mean/max                              5.93327      0.45625     6.49780      4.47656
mean/min                              -5.48236     0.49524     -3.89221     -6.25181
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 6, 3, 4, 8, 1, 9, 0, 5]
replay_buffer._size: [44850 44850 44850 44850 44850 44850 44850 44850 44850 44850]
2023-08-12 12:23:25,935 MainThread INFO: EPOCH:277
2023-08-12 12:23:25,936 MainThread INFO: Time Consumed:8.694265842437744s
2023-08-12 12:23:25,936 MainThread INFO: Total Frames:447000s
  3%|▎         | 278/10000 [42:05<23:53:58,  8.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               993.28973
Train_Epoch_Reward                    10717.62758
Running_Training_Average_Rewards      931.30317
Explore_Time                          0.00456
Train___Time                          8.68453
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.71641
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.64236
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.86234
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.27364
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.49780
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.15702
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.67375
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10627.22829
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.03241
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.47524
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68609      1.28689     10.78653     4.07083
alpha_0                               3.91440      0.01264     3.92997      3.89235
alpha_1                               0.62460      0.00043     0.62517      0.62368
alpha_2                               0.40133      0.00062     0.40219      0.40009
alpha_3                               0.18174      0.00143     0.18428      0.17946
alpha_4                               0.33597      0.00061     0.33682      0.33478
alpha_5                               0.48162      0.00049     0.48233      0.48059
alpha_6                               0.28306      0.00112     0.28479      0.28110
alpha_7                               0.38174      0.00251     0.38592      0.37699
alpha_8                               0.47038      0.00316     0.47594      0.46519
alpha_9                               0.26024      0.00066     0.26147      0.25926
Alpha_loss                            -0.27538     0.10719     0.01452      -0.51074
Training/policy_loss                  173.90529    17.80853    215.36038    130.49702
Training/qf1_loss                     10271.38185  4398.93404  28335.43750  3833.07227
Training/qf2_loss                     1424.11487   374.32459   2846.22339   722.58795
Training/pf_norm                      20.76685     7.71875     44.18713     8.73840
Training/qf1_norm                     8058.18051   3300.94069  19029.63477  2257.98096
Training/qf2_norm                     4467.85422   2065.04598  12113.08398  1482.25500
log_std/mean                          -0.84960     0.00852     -0.83203     -0.86706
log_std/std                           0.42418      0.00470     0.43602      0.41382
log_std/max                           1.07516      0.11215     1.18828      0.53837
log_std/min                           -2.65124     0.17296     -2.32123     -2.89187
log_probs/mean                        3.80580      0.11627     4.04345      3.49979
log_probs/std                         3.43076      0.09257     3.71532      3.21880
log_probs/max                         20.31710     2.46012     24.38926     14.85239
log_probs/min                         -6.43320     1.22643     -4.23509     -10.02115
mean/mean                             0.25919      0.02642     0.32257      0.19009
mean/std                              1.44539      0.01636     1.48334      1.40628
mean/max                              5.95493      0.46621     6.46514      4.48748
mean/min                              -5.76093     0.36844     -4.57103     -6.21526
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 6, 3, 4, 8, 0, 9, 7, 5, 1]
replay_buffer._size: [45000 45000 45000 45000 45000 45000 45000 45000 45000 45000]
2023-08-12 12:23:34,890 MainThread INFO: EPOCH:278
2023-08-12 12:23:34,890 MainThread INFO: Time Consumed:8.798616409301758s
2023-08-12 12:23:34,890 MainThread INFO: Total Frames:448500s
  3%|▎         | 279/10000 [42:14<23:59:21,  8.88s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1044.62836
Train_Epoch_Reward                    10002.25682
Running_Training_Average_Rewards      994.59216
Explore_Time                          0.00548
Train___Time                          8.78729
Eval____Time                          0.00485
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.33104
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.97584
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.99746
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -77.25590
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.56146
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.25683
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.24828
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11145.14943
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.84932
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.38975
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.37635      1.09256     9.21127      3.58656
alpha_0                               3.86277      0.01425     3.89150      3.84463
alpha_1                               0.62599      0.00061     0.62719      0.62511
alpha_2                               0.39865      0.00084     0.40006      0.39732
alpha_3                               0.17751      0.00111     0.17942      0.17569
alpha_4                               0.33365      0.00071     0.33475      0.33257
alpha_5                               0.47984      0.00038     0.48055      0.47913
alpha_6                               0.27907      0.00127     0.28107      0.27675
alpha_7                               0.38986      0.00211     0.39345      0.38600
alpha_8                               0.48095      0.00282     0.48593      0.47605
alpha_9                               0.25803      0.00073     0.25924      0.25682
Alpha_loss                            -0.25709     0.12849     0.04714      -0.54562
Training/policy_loss                  175.93505    18.31139    218.58134    131.15179
Training/qf1_loss                     9629.83384   4237.10795  29813.96680  4715.32910
Training/qf2_loss                     1416.22325   416.29161   2822.63403   819.37909
Training/pf_norm                      15.97653     5.42674     31.77730     6.81479
Training/qf1_norm                     8035.02224   3740.08000  27598.55664  2745.95874
Training/qf2_norm                     4571.50134   2200.95949  12122.89062  934.20563
log_std/mean                          -0.84525     0.01148     -0.82256     -0.86850
log_std/std                           0.43025      0.00461     0.44431      0.42066
log_std/max                           1.20300      0.14655     1.33429      0.47774
log_std/min                           -2.56999     0.16136     -2.25721     -2.81313
log_probs/mean                        3.81508      0.11466     4.08437      3.49622
log_probs/std                         3.40797      0.06971     3.57928      3.23807
log_probs/max                         19.91525     2.18528     23.86232     14.34987
log_probs/min                         -6.52201     1.40062     -3.77452     -11.25807
mean/mean                             0.25542      0.02322     0.30465      0.19427
mean/std                              1.44910      0.01496     1.47971      1.41087
mean/max                              5.82835      0.49693     6.41670      4.41609
mean/min                              -5.79025     0.30886     -4.28424     -6.11832
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 4, 3, 0, 7, 1, 6, 5, 8, 2]
replay_buffer._size: [45150 45150 45150 45150 45150 45150 45150 45150 45150 45150]
2023-08-12 12:23:44,022 MainThread INFO: EPOCH:279
2023-08-12 12:23:44,023 MainThread INFO: Time Consumed:8.949589490890503s
2023-08-12 12:23:44,023 MainThread INFO: Total Frames:450000s
  3%|▎         | 280/10000 [42:23<24:11:31,  8.96s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1095.12246
Train_Epoch_Reward                    10708.31416
Running_Training_Average_Rewards      1047.60662
Explore_Time                          0.00504
Train___Time                          8.93942
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -105.72927
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.60455
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.36041
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -76.21117
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.66055
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.02173
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.00482
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11653.70898
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.52342
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.36844
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60700      1.31525     10.53000     3.93287
alpha_0                               3.82717      0.01153     3.84413      3.80702
alpha_1                               0.62985      0.00162     0.63292      0.62724
alpha_2                               0.39625      0.00073     0.39730      0.39498
alpha_3                               0.17400      0.00099     0.17565      0.17234
alpha_4                               0.33215      0.00032     0.33259      0.33156
alpha_5                               0.47879      0.00019     0.47909      0.47838
alpha_6                               0.27497      0.00092     0.27670      0.27339
alpha_7                               0.39741      0.00197     0.40049      0.39354
alpha_8                               0.49106      0.00307     0.49668      0.48604
alpha_9                               0.25594      0.00051     0.25680      0.25500
Alpha_loss                            -0.18178     0.12220     0.07358      -0.46345
Training/policy_loss                  173.01263    16.92664    222.69298    116.23814
Training/qf1_loss                     10655.93240  3670.89456  22523.36914  4195.01562
Training/qf2_loss                     1446.72437   377.90162   3121.80835   872.96283
Training/pf_norm                      18.26181     6.73279     44.77835     8.81330
Training/qf1_norm                     8259.17072   4002.67408  25791.25000  2402.02319
Training/qf2_norm                     4460.79018   2098.71945  11719.50586  1408.13672
log_std/mean                          -0.85281     0.00619     -0.83866     -0.86615
log_std/std                           0.42945      0.00427     0.44107      0.41845
log_std/max                           1.19594      0.08901     1.26163      0.61025
log_std/min                           -2.53312     0.13563     -2.24853     -2.75293
log_probs/mean                        3.91093      0.10873     4.15926      3.63144
log_probs/std                         3.46773      0.09818     3.72112      3.26731
log_probs/max                         20.25826     2.38878     25.03738     14.82592
log_probs/min                         -6.60728     1.65071     -4.21854     -14.01011
mean/mean                             0.21384      0.03207     0.30492      0.13560
mean/std                              1.47195      0.01383     1.50399      1.44131
mean/max                              5.86286      0.50236     6.41029      4.21009
mean/min                              -5.89715     0.52121     -3.60789     -6.44461
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 8, 9, 1, 6, 3, 4, 0, 2, 5]
replay_buffer._size: [45300 45300 45300 45300 45300 45300 45300 45300 45300 45300]
2023-08-12 12:23:53,665 MainThread INFO: EPOCH:280
2023-08-12 12:23:53,666 MainThread INFO: Time Consumed:9.471151351928711s
2023-08-12 12:23:53,666 MainThread INFO: Total Frames:451500s
  3%|▎         | 281/10000 [42:32<24:42:30,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1098.04373
Train_Epoch_Reward                    10361.99687
Running_Training_Average_Rewards      1035.75226
Explore_Time                          0.01679
Train___Time                          9.44985
Eval____Time                          0.00394
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -106.57306
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.52919
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.82246
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -77.75666
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.09726
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.14618
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.02489
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11681.62962
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.52090
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.72169
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60100      1.25115     9.82751      3.66966
alpha_0                               3.78529      0.01350     3.80671      3.75793
alpha_1                               0.63576      0.00131     0.63811      0.63300
alpha_2                               0.39344      0.00089     0.39496      0.39177
alpha_3                               0.17052      0.00097     0.17230      0.16895
alpha_4                               0.33068      0.00061     0.33154      0.32962
alpha_5                               0.47828      0.00011     0.47844      0.47803
alpha_6                               0.27161      0.00120     0.27335      0.26929
alpha_7                               0.40335      0.00179     0.40670      0.40054
alpha_8                               0.50339      0.00384     0.51010      0.49680
alpha_9                               0.25415      0.00046     0.25498      0.25340
Alpha_loss                            -0.20801     0.11664     0.02938      -0.55314
Training/policy_loss                  173.11503    18.48620    219.22037    121.55039
Training/qf1_loss                     9171.20282   3167.13221  19767.59766  4508.76172
Training/qf2_loss                     1375.65308   365.85456   2973.62378   762.58350
Training/pf_norm                      18.81021     6.52909     37.46662     5.86749
Training/qf1_norm                     7573.70341   2937.54326  15156.89648  2548.25854
Training/qf2_norm                     4699.02495   2362.76985  14363.65430  1312.74292
log_std/mean                          -0.85145     0.00753     -0.83538     -0.86643
log_std/std                           0.42820      0.00436     0.43611      0.41733
log_std/max                           1.15775      0.13806     1.26743      0.42849
log_std/min                           -2.51197     0.09473     -2.25302     -2.80764
log_probs/mean                        3.86999      0.10685     4.12280      3.57961
log_probs/std                         3.48366      0.08915     3.71064      3.25529
log_probs/max                         19.63514     2.46753     24.24651     14.77869
log_probs/min                         -6.60110     1.55214     -4.20765     -12.40650
mean/mean                             0.21330      0.02990     0.29127      0.13391
mean/std                              1.46310      0.01591     1.50088      1.42138
mean/max                              5.77173      0.58061     6.37543      4.00224
mean/min                              -6.33161     0.52713     -4.05941     -6.81548
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 1, 4, 2, 9, 5, 6, 3, 8, 7]
replay_buffer._size: [45450 45450 45450 45450 45450 45450 45450 45450 45450 45450]
2023-08-12 12:24:03,074 MainThread INFO: EPOCH:281
2023-08-12 12:24:03,074 MainThread INFO: Time Consumed:9.230121612548828s
2023-08-12 12:24:03,074 MainThread INFO: Total Frames:453000s
  3%|▎         | 282/10000 [42:42<24:55:54,  9.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1096.09901
Train_Epoch_Reward                    9796.31148
Running_Training_Average_Rewards      1028.88742
Explore_Time                          0.01004
Train___Time                          9.21504
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.39253
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.83927
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.63662
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.40658
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.89540
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.33002
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.11258
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11660.04445
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.33497
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.10642
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56547      1.52299     11.39347     3.47944
alpha_0                               3.73613      0.00963     3.75719      3.72713
alpha_1                               0.64018      0.00097     0.64177      0.63817
alpha_2                               0.39024      0.00085     0.39174      0.38856
alpha_3                               0.16738      0.00090     0.16892      0.16581
alpha_4                               0.32836      0.00079     0.32960      0.32673
alpha_5                               0.47757      0.00024     0.47801      0.47717
alpha_6                               0.26660      0.00153     0.26923      0.26397
alpha_7                               0.41107      0.00266     0.41548      0.40677
alpha_8                               0.51660      0.00377     0.52301      0.51023
alpha_9                               0.25258      0.00041     0.25338      0.25204
Alpha_loss                            -0.25307     0.11107     -0.02117     -0.52031
Training/policy_loss                  172.38013    17.90696    209.06583    126.70906
Training/qf1_loss                     10054.51895  3984.62959  25676.06836  3471.59058
Training/qf2_loss                     1380.20151   396.28528   3910.85742   747.81219
Training/pf_norm                      18.05108     6.82005     36.17771     5.68162
Training/qf1_norm                     8649.50919   4420.61520  28827.00586  1967.59656
Training/qf2_norm                     4500.82725   2574.85374  15535.62988  1342.58008
log_std/mean                          -0.85012     0.00653     -0.82834     -0.86799
log_std/std                           0.42823      0.00509     0.44050      0.41393
log_std/max                           1.20166      0.14723     1.29543      0.45143
log_std/min                           -2.55032     0.12053     -2.32003     -2.85620
log_probs/mean                        3.86147      0.09310     4.12122      3.64040
log_probs/std                         3.45385      0.09284     3.66508      3.16932
log_probs/max                         19.46061     2.40562     23.59510     13.67998
log_probs/min                         -6.35716     1.38759     -3.53306     -10.64084
mean/mean                             0.24646      0.02662     0.30467      0.18204
mean/std                              1.45734      0.01346     1.49037      1.42389
mean/max                              5.63538      0.60198     6.38216      4.17028
mean/min                              -6.53370     0.51580     -3.68948     -6.87133
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 1, 3, 6, 8, 7, 9, 2, 4, 5]
replay_buffer._size: [45600 45600 45600 45600 45600 45600 45600 45600 45600 45600]
2023-08-12 12:24:12,696 MainThread INFO: EPOCH:282
2023-08-12 12:24:12,696 MainThread INFO: Time Consumed:9.457098722457886s
2023-08-12 12:24:12,696 MainThread INFO: Total Frames:454500s
  3%|▎         | 283/10000 [42:51<25:14:40,  9.35s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1124.50104
Train_Epoch_Reward                    10871.64398
Running_Training_Average_Rewards      1034.33174
Explore_Time                          0.01505
Train___Time                          9.43716
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -107.49863
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.12868
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.42593
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.65236
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.05506
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.51853
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.30639
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11945.63433
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.97285
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.06546
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.57050      1.35845     10.62621     3.68935
alpha_0                               3.71546      0.00919     3.72844      3.70032
alpha_1                               0.64476      0.00174     0.64766      0.64180
alpha_2                               0.38551      0.00164     0.38851      0.38325
alpha_3                               0.16411      0.00099     0.16578      0.16232
alpha_4                               0.32426      0.00135     0.32668      0.32234
alpha_5                               0.47679      0.00016     0.47715      0.47650
alpha_6                               0.26092      0.00173     0.26392      0.25798
alpha_7                               0.41905      0.00191     0.42231      0.41557
alpha_8                               0.52992      0.00369     0.53579      0.52315
alpha_9                               0.25184      0.00010     0.25203      0.25170
Alpha_loss                            -0.29694     0.13521     -0.03103     -0.66901
Training/policy_loss                  169.91377    16.59945    208.98051    126.89796
Training/qf1_loss                     9052.00428   3188.60750  16744.01562  3048.53638
Training/qf2_loss                     1447.78288   469.08338   4276.00244   875.40149
Training/pf_norm                      18.56146     7.21580     38.45534     7.02270
Training/qf1_norm                     8519.26153   3785.75796  21335.21680  2431.04688
Training/qf2_norm                     4999.87657   2174.35035  13350.41895  1389.30676
log_std/mean                          -0.83973     0.01189     -0.81107     -0.85598
log_std/std                           0.42094      0.00381     0.42791      0.41224
log_std/max                           1.13275      0.16246     1.24411      0.39388
log_std/min                           -2.47821     0.11038     -2.25886     -2.76038
log_probs/mean                        3.82979      0.12747     4.20349      3.57163
log_probs/std                         3.46339      0.07767     3.67688      3.28604
log_probs/max                         20.11837     2.27653     24.45869     15.11524
log_probs/min                         -6.51740     1.19968     -3.90194     -11.20164
mean/mean                             0.24012      0.03244     0.33201      0.17899
mean/std                              1.46234      0.01373     1.49764      1.43419
mean/max                              5.76197      0.56272     6.42141      4.17245
mean/min                              -6.77369     0.53825     -3.83438     -7.15714
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 7, 6, 4, 2, 9, 1, 0, 5]
replay_buffer._size: [45750 45750 45750 45750 45750 45750 45750 45750 45750 45750]
2023-08-12 12:24:21,704 MainThread INFO: EPOCH:283
2023-08-12 12:24:21,705 MainThread INFO: Time Consumed:8.833288192749023s
2023-08-12 12:24:21,705 MainThread INFO: Total Frames:456000s
  3%|▎         | 284/10000 [43:00<24:58:23,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1135.55886
Train_Epoch_Reward                    11267.58021
Running_Training_Average_Rewards      1064.51786
Explore_Time                          0.01146
Train___Time                          8.81681
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.79575
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.30766
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.45035
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -76.10314
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.02610
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.66888
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.65999
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12008.49884
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.10935
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.78899
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.51477      1.34575     10.38809     3.73365
alpha_0                               3.68219      0.00964     3.69987      3.66833
alpha_1                               0.65038      0.00172     0.65365      0.64771
alpha_2                               0.38167      0.00095     0.38322      0.37984
alpha_3                               0.16053      0.00108     0.16229      0.15860
alpha_4                               0.32145      0.00035     0.32232      0.32108
alpha_5                               0.47748      0.00021     0.47774      0.47694
alpha_6                               0.25580      0.00103     0.25792      0.25437
alpha_7                               0.42585      0.00195     0.42814      0.42239
alpha_8                               0.54117      0.00293     0.54606      0.53592
alpha_9                               0.25177      0.00017     0.25225      0.25159
Alpha_loss                            -0.20736     0.10936     0.09391      -0.52869
Training/policy_loss                  174.12097    19.10530    216.08072    128.20659
Training/qf1_loss                     9195.31663   3641.70698  22658.89453  3177.38184
Training/qf2_loss                     1421.15484   325.96945   2567.72852   727.44104
Training/pf_norm                      19.31858     7.23548     36.88253     6.12640
Training/qf1_norm                     7440.42773   3595.23718  27000.80273  2833.36255
Training/qf2_norm                     4278.70285   1928.62598  12543.58984  1303.13013
log_std/mean                          -0.84193     0.00503     -0.82527     -0.85309
log_std/std                           0.41341      0.00515     0.42389      0.39570
log_std/max                           1.06204      0.12443     1.12274      0.34860
log_std/min                           -2.44033     0.10816     -2.23398     -2.75270
log_probs/mean                        3.90111      0.11258     4.15648      3.63375
log_probs/std                         3.41031      0.09269     3.62237      3.17538
log_probs/max                         19.78759     3.00473     25.50335     14.18002
log_probs/min                         -6.47769     1.31496     -3.92911     -11.63797
mean/mean                             0.27430      0.02755     0.35917      0.21516
mean/std                              1.46644      0.01606     1.50897      1.43315
mean/max                              5.82420      0.55590     6.43535      3.99246
mean/min                              -6.76889     0.60089     -3.93132     -7.32350
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 1, 4, 6, 5, 0, 3, 7, 9, 8]
replay_buffer._size: [45900 45900 45900 45900 45900 45900 45900 45900 45900 45900]
2023-08-12 12:24:30,956 MainThread INFO: EPOCH:284
2023-08-12 12:24:30,957 MainThread INFO: Time Consumed:9.094305992126465s
2023-08-12 12:24:30,957 MainThread INFO: Total Frames:457500s
  3%|▎         | 285/10000 [43:10<24:58:00,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1108.47665
Train_Epoch_Reward                    11644.15867
Running_Training_Average_Rewards      1126.11276
Explore_Time                          0.00719
Train___Time                          9.08185
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.04334
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.96731
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -34.96415
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -77.95474
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.55920
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.13398
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.15184
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11739.69649
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.03227
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.12312
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65251      1.24868     9.81336      3.92224
alpha_0                               3.65181      0.01164     3.66827      3.63470
alpha_1                               0.65556      0.00110     0.65764      0.65371
alpha_2                               0.37697      0.00153     0.37979      0.37486
alpha_3                               0.15636      0.00132     0.15856      0.15404
alpha_4                               0.32076      0.00021     0.32125      0.32053
alpha_5                               0.47672      0.00027     0.47699      0.47601
alpha_6                               0.25271      0.00096     0.25435      0.25110
alpha_7                               0.42877      0.00055     0.42985      0.42814
alpha_8                               0.55108      0.00277     0.55485      0.54617
alpha_9                               0.25347      0.00081     0.25502      0.25227
Alpha_loss                            -0.25339     0.12026     0.01602      -0.58115
Training/policy_loss                  173.01839    16.22844    216.47832    135.76436
Training/qf1_loss                     9277.66970   3473.89086  19958.63477  3616.88135
Training/qf2_loss                     1475.51764   412.22561   3057.21313   899.59131
Training/pf_norm                      22.57865     8.13176     43.05926     7.85647
Training/qf1_norm                     7210.73343   3684.29799  25783.91602  2611.47754
Training/qf2_norm                     5192.57491   1960.17980  11499.80078  1564.57361
log_std/mean                          -0.82887     0.00549     -0.81697     -0.84337
log_std/std                           0.40707      0.00384     0.41671      0.39888
log_std/max                           1.07092      0.13870     1.15945      0.46272
log_std/min                           -2.41566     0.11910     -2.20733     -2.73550
log_probs/mean                        3.84479      0.10484     4.04213      3.61406
log_probs/std                         3.44650      0.09050     3.70132      3.19880
log_probs/max                         19.90262     2.94042     28.03850     14.08531
log_probs/min                         -6.36031     1.20455     -4.27121     -10.59729
mean/mean                             0.26283      0.03994     0.34944      0.17004
mean/std                              1.46659      0.01557     1.50678      1.42379
mean/max                              5.85339      0.56058     6.42090      4.05922
mean/min                              -7.03141     0.50637     -4.48352     -7.38484
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 1, 8, 0, 5, 9, 7, 2, 6]
replay_buffer._size: [46050 46050 46050 46050 46050 46050 46050 46050 46050 46050]
2023-08-12 12:24:40,119 MainThread INFO: EPOCH:285
2023-08-12 12:24:40,119 MainThread INFO: Time Consumed:8.974187135696411s
2023-08-12 12:24:40,119 MainThread INFO: Total Frames:459000s
  3%|▎         | 286/10000 [43:19<24:51:42,  9.21s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1111.77004
Train_Epoch_Reward                    11040.70577
Running_Training_Average_Rewards      1131.74816
Explore_Time                          0.00592
Train___Time                          8.96309
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.51631
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.65554
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.03384
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -77.27339
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.31109
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.45688
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.52713
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11780.43288
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.24740
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.71094
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.40151      1.25871     9.23807      3.37847
alpha_0                               3.63598      0.00155     3.63894      3.63364
alpha_1                               0.65888      0.00064     0.65973      0.65767
alpha_2                               0.37246      0.00185     0.37485      0.36901
alpha_3                               0.15160      0.00142     0.15399      0.14907
alpha_4                               0.32038      0.00023     0.32068      0.32000
alpha_5                               0.47482      0.00055     0.47598      0.47426
alpha_6                               0.24961      0.00086     0.25107      0.24798
alpha_7                               0.43101      0.00060     0.43210      0.42987
alpha_8                               0.55727      0.00120     0.55928      0.55489
alpha_9                               0.25772      0.00174     0.26096      0.25505
Alpha_loss                            -0.28616     0.13215     0.17361      -0.60507
Training/policy_loss                  170.85266    17.64478    208.53072    127.66532
Training/qf1_loss                     9380.51596   3271.81817  19733.19531  4679.37061
Training/qf2_loss                     1356.72560   319.53537   2852.63989   794.11542
Training/pf_norm                      20.29493     8.73240     42.30107     5.38651
Training/qf1_norm                     7940.35357   3516.57518  24454.77734  2452.85742
Training/qf2_norm                     4879.73602   2632.66784  15101.36328  1489.15759
log_std/mean                          -0.82569     0.01286     -0.80335     -0.84976
log_std/std                           0.40755      0.00403     0.41623      0.39359
log_std/max                           1.05298      0.15024     1.14526      0.38024
log_std/min                           -2.42042     0.11854     -2.21421     -2.74896
log_probs/mean                        3.85017      0.11558     4.19245      3.61379
log_probs/std                         3.55002      0.09628     3.77765      3.32839
log_probs/max                         21.21191     2.88064     25.62495     15.72551
log_probs/min                         -6.71816     1.25996     -4.78000     -11.12062
mean/mean                             0.27273      0.02792     0.32788      0.21445
mean/std                              1.47350      0.01602     1.52275      1.43668
mean/max                              5.80992      0.60421     6.53770      4.19598
mean/min                              -6.86224     0.49578     -3.89876     -7.35891
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 1, 2, 6, 7, 9, 0, 8, 3]
replay_buffer._size: [46200 46200 46200 46200 46200 46200 46200 46200 46200 46200]
2023-08-12 12:24:49,721 MainThread INFO: EPOCH:286
2023-08-12 12:24:49,721 MainThread INFO: Time Consumed:9.427072286605835s
2023-08-12 12:24:49,721 MainThread INFO: Total Frames:460500s
  3%|▎         | 287/10000 [43:28<25:10:36,  9.33s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1079.63622
Train_Epoch_Reward                    11268.62616
Running_Training_Average_Rewards      1131.78302
Explore_Time                          0.01226
Train___Time                          9.40939
Eval____Time                          0.00478
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.29351
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.19720
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.32920
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.66359
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.98593
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.26660
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.05006
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11482.71601
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.42028
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.14745
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75856      1.43890     10.85033     4.00807
alpha_0                               3.63877      0.00201     3.64162      3.63575
alpha_1                               0.66097      0.00058     0.66232      0.65977
alpha_2                               0.36575      0.00170     0.36893      0.36315
alpha_3                               0.14664      0.00134     0.14902      0.14431
alpha_4                               0.31931      0.00063     0.31999      0.31799
alpha_5                               0.47392      0.00018     0.47430      0.47357
alpha_6                               0.24561      0.00135     0.24794      0.24343
alpha_7                               0.43432      0.00127     0.43624      0.43213
alpha_8                               0.56101      0.00076     0.56209      0.55933
alpha_9                               0.26492      0.00225     0.26879      0.26104
Alpha_loss                            -0.28869     0.12791     0.02779      -0.60988
Training/policy_loss                  169.75012    21.35429    209.53336    100.18467
Training/qf1_loss                     9359.49898   3549.69891  18129.01172  3084.22266
Training/qf2_loss                     1533.87505   441.89575   3281.07983   792.04053
Training/pf_norm                      21.24059     8.72455     47.18462     7.72045
Training/qf1_norm                     7902.71920   3234.46237  17590.41992  2669.89917
Training/qf2_norm                     5011.11554   1969.69105  10914.99121  1778.65393
log_std/mean                          -0.83802     0.00686     -0.82366     -0.85387
log_std/std                           0.41033      0.00475     0.42365      0.39864
log_std/max                           0.96163      0.14989     1.09615      0.25344
log_std/min                           -2.48987     0.14484     -2.25885     -2.82494
log_probs/mean                        3.85368      0.11032     4.21629      3.65578
log_probs/std                         3.53693      0.08882     3.76501      3.36614
log_probs/max                         21.45355     3.08042     29.28506     15.48568
log_probs/min                         -6.91313     1.46238     -4.30013     -11.23767
mean/mean                             0.27013      0.03026     0.35391      0.20718
mean/std                              1.46371      0.01739     1.50546      1.42878
mean/max                              5.95194      0.58262     6.64381      4.10733
mean/min                              -7.32975     0.52846     -4.30264     -7.65217
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 8, 2, 7, 6, 1, 3, 0, 5, 4]
replay_buffer._size: [46350 46350 46350 46350 46350 46350 46350 46350 46350 46350]
2023-08-12 12:24:59,326 MainThread INFO: EPOCH:287
2023-08-12 12:24:59,327 MainThread INFO: Time Consumed:9.419399499893188s
2023-08-12 12:24:59,327 MainThread INFO: Total Frames:462000s
  3%|▎         | 288/10000 [43:38<25:24:21,  9.42s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1065.24407
Train_Epoch_Reward                    10378.01525
Running_Training_Average_Rewards      1089.57824
Explore_Time                          0.00602
Train___Time                          9.40883
Eval____Time                          0.00371
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.06287
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.84827
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.85853
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -79.13728
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.42732
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.82965
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.99212
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11311.17374
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.99955
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.57744
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.38118      1.32092     9.76721      3.49871
alpha_0                               3.63727      0.00417     3.64330      3.63207
alpha_1                               0.66131      0.00091     0.66239      0.65951
alpha_2                               0.36111      0.00155     0.36312      0.35748
alpha_3                               0.14205      0.00127     0.14426      0.13991
alpha_4                               0.31798      0.00052     0.31846      0.31670
alpha_5                               0.47237      0.00112     0.47394      0.47042
alpha_6                               0.24084      0.00154     0.24340      0.23828
alpha_7                               0.43900      0.00154     0.44107      0.43629
alpha_8                               0.56059      0.00101     0.56201      0.55892
alpha_9                               0.27259      0.00229     0.27692      0.26888
Alpha_loss                            -0.34304     0.13171     0.07902      -0.68211
Training/policy_loss                  170.68840    18.32379    211.61052    126.61578
Training/qf1_loss                     9473.36096   3693.96902  22395.11523  3589.46753
Training/qf2_loss                     1437.14406   372.86387   2924.10400   783.28912
Training/pf_norm                      19.91771     8.36013     48.83983     7.75226
Training/qf1_norm                     7594.17805   4048.04135  26148.99805  2356.83179
Training/qf2_norm                     4881.60673   2213.82111  11929.91797  1543.78931
log_std/mean                          -0.84174     0.00557     -0.83107     -0.85614
log_std/std                           0.40673      0.00471     0.41676      0.39569
log_std/max                           0.88135      0.14319     0.98922      0.20238
log_std/min                           -2.51321     0.11963     -2.28397     -2.83572
log_probs/mean                        3.76613      0.10228     4.02688      3.55361
log_probs/std                         3.54510      0.07638     3.72610      3.40427
log_probs/max                         21.43649     3.24969     28.84702     15.78316
log_probs/min                         -6.68880     1.30173     -4.10717     -11.60561
mean/mean                             0.29490      0.03926     0.38181      0.20729
mean/std                              1.44543      0.01396     1.48251      1.41042
mean/max                              5.78003      0.64628     6.65556      4.10409
mean/min                              -7.40189     0.54887     -5.68995     -7.77050
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 9, 5, 7, 1, 0, 6, 3, 4]
replay_buffer._size: [46500 46500 46500 46500 46500 46500 46500 46500 46500 46500]
2023-08-12 12:25:08,678 MainThread INFO: EPOCH:288
2023-08-12 12:25:08,678 MainThread INFO: Time Consumed:9.133964538574219s
2023-08-12 12:25:08,678 MainThread INFO: Total Frames:463500s
  3%|▎         | 289/10000 [43:47<25:20:45,  9.40s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1079.61466
Train_Epoch_Reward                    11054.81081
Running_Training_Average_Rewards      1090.04841
Explore_Time                          0.00467
Train___Time                          9.12359
Eval____Time                          0.00502
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.44013
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.33002
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.94202
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.40565
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.58758
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.55390
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.06757
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11462.52827
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.37007
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.68477
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75354      1.25195     9.24487      3.42418
alpha_0                               3.64620      0.00623     3.65295      3.63323
alpha_1                               0.65905      0.00061     0.65959      0.65732
alpha_2                               0.35251      0.00248     0.35736      0.34840
alpha_3                               0.13811      0.00102     0.13987      0.13641
alpha_4                               0.31618      0.00039     0.31667      0.31496
alpha_5                               0.46911      0.00089     0.47039      0.46760
alpha_6                               0.23625      0.00130     0.23824      0.23389
alpha_7                               0.44055      0.00037     0.44101      0.43989
alpha_8                               0.55663      0.00143     0.55889      0.55448
alpha_9                               0.28242      0.00305     0.28718      0.27703
Alpha_loss                            -0.32343     0.11113     -0.12287     -0.58271
Training/policy_loss                  169.72702    18.39584    210.73613    129.77954
Training/qf1_loss                     8932.74270   3571.69188  20565.31055  3497.25073
Training/qf2_loss                     1546.05905   390.43233   2767.05273   776.00092
Training/pf_norm                      19.38459     8.11094     49.37010     6.84639
Training/qf1_norm                     7503.78189   3336.45039  20400.82422  2378.02100
Training/qf2_norm                     5425.85887   2505.18943  12438.01758  1263.57886
log_std/mean                          -0.84735     0.00864     -0.83198     -0.87619
log_std/std                           0.41312      0.00415     0.42373      0.40371
log_std/max                           0.84457      0.12072     0.92930      0.20008
log_std/min                           -2.57417     0.06582     -2.46011     -2.78244
log_probs/mean                        3.78695      0.10878     4.00343      3.48642
log_probs/std                         3.53973      0.09706     3.76458      3.26489
log_probs/max                         21.40175     3.05556     28.85052     15.76683
log_probs/min                         -6.63544     1.43039     -3.96410     -11.98158
mean/mean                             0.29236      0.02602     0.36014      0.22741
mean/std                              1.44771      0.01712     1.50012      1.40160
mean/max                              5.80013      0.64744     6.41471      4.24623
mean/min                              -7.74660     0.60074     -3.90635     -8.10962
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 6, 3, 7, 1, 0, 9, 2, 5, 4]
replay_buffer._size: [46650 46650 46650 46650 46650 46650 46650 46650 46650 46650]
2023-08-12 12:25:17,578 MainThread INFO: EPOCH:289
2023-08-12 12:25:17,578 MainThread INFO: Time Consumed:8.732997179031372s
2023-08-12 12:25:17,579 MainThread INFO: Total Frames:465000s
  3%|▎         | 290/10000 [43:56<24:56:02,  9.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1089.25048
Train_Epoch_Reward                    10677.42336
Running_Training_Average_Rewards      1070.34165
Explore_Time                          0.00624
Train___Time                          8.72124
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.70917
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.55712
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.06537
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.33117
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.71672
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.37712
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.83008
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11483.77568
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.86056
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.82352
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.66516      1.34854     9.92395      3.23287
alpha_0                               3.66407      0.00754     3.67707      3.65260
alpha_1                               0.65455      0.00173     0.65728      0.65124
alpha_2                               0.34558      0.00140     0.34832      0.34323
alpha_3                               0.13495      0.00082     0.13638      0.13356
alpha_4                               0.31428      0.00023     0.31492      0.31393
alpha_5                               0.46757      0.00037     0.46824      0.46707
alpha_6                               0.23150      0.00147     0.23385      0.22886
alpha_7                               0.44008      0.00041     0.44106      0.43955
alpha_8                               0.55226      0.00143     0.55445      0.55020
alpha_9                               0.29131      0.00211     0.29468      0.28727
Alpha_loss                            -0.28097     0.12133     0.00032      -0.52922
Training/policy_loss                  167.17775    18.76356    218.68970    126.08801
Training/qf1_loss                     8889.04124   3686.08144  24927.60742  3395.61719
Training/qf2_loss                     1467.70750   348.31865   2732.18750   862.89648
Training/pf_norm                      24.54678     12.55055    69.58607     8.04436
Training/qf1_norm                     7962.90777   3919.63063  24619.66602  2196.16724
Training/qf2_norm                     5059.12201   2492.42151  12242.18848  1618.69263
log_std/mean                          -0.87020     0.00914     -0.85603     -0.89245
log_std/std                           0.41925      0.00463     0.42737      0.40479
log_std/max                           0.74180      0.13331     0.87579      0.16443
log_std/min                           -2.74155     0.04711     -2.61367     -2.92032
log_probs/mean                        3.82911      0.11079     4.12489      3.59367
log_probs/std                         3.51512      0.09594     3.79840      3.30359
log_probs/max                         21.35079     3.52527     31.23067     15.49214
log_probs/min                         -6.81370     1.49503     -4.17902     -11.78360
mean/mean                             0.30806      0.03073     0.37292      0.22366
mean/std                              1.44077      0.01721     1.48445      1.40104
mean/max                              5.89270      0.65849     6.61318      4.22730
mean/min                              -7.96175     0.67545     -4.52306     -8.41341
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 0, 9, 6, 7, 2, 5, 1, 8]
replay_buffer._size: [46800 46800 46800 46800 46800 46800 46800 46800 46800 46800]
2023-08-12 12:25:27,004 MainThread INFO: EPOCH:290
2023-08-12 12:25:27,004 MainThread INFO: Time Consumed:9.235804796218872s
2023-08-12 12:25:27,004 MainThread INFO: Total Frames:466500s
  3%|▎         | 291/10000 [44:06<25:06:38,  9.31s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1075.57728
Train_Epoch_Reward                    10680.69443
Running_Training_Average_Rewards      1080.43095
Explore_Time                          0.01610
Train___Time                          9.21486
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.32332
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.60921
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.39979
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.21906
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.52830
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.81397
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.28709
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11357.14937
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.75302
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.44276
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.54404      1.35929     9.79123      3.35037
alpha_0                               3.68970      0.00643     3.69719      3.67703
alpha_1                               0.64753      0.00178     0.65115      0.64520
alpha_2                               0.33882      0.00264     0.34316      0.33397
alpha_3                               0.13219      0.00075     0.13353      0.13090
alpha_4                               0.31490      0.00037     0.31544      0.31436
alpha_5                               0.46778      0.00063     0.46924      0.46706
alpha_6                               0.22668      0.00121     0.22881      0.22447
alpha_7                               0.44116      0.00015     0.44144      0.44090
alpha_8                               0.54898      0.00051     0.55016      0.54846
alpha_9                               0.29766      0.00163     0.30030      0.29475
Alpha_loss                            -0.32610     0.12316     -0.00229     -0.57550
Training/policy_loss                  168.95592    17.79703    206.84233    118.63251
Training/qf1_loss                     8724.09849   3149.43465  18659.99023  3851.43677
Training/qf2_loss                     1509.52613   364.53225   2911.44214   935.02850
Training/pf_norm                      20.59816     8.65132     43.95067     7.81184
Training/qf1_norm                     8007.82126   3693.59216  22293.08789  1835.81946
Training/qf2_norm                     4888.53398   2075.24064  12859.53906  1914.09424
log_std/mean                          -0.86977     0.00820     -0.85449     -0.89473
log_std/std                           0.42512      0.00411     0.43498      0.41249
log_std/max                           0.72783      0.09269     0.83723      0.19250
log_std/min                           -2.84050     0.04450     -2.77627     -2.95926
log_probs/mean                        3.79306      0.11521     4.04039      3.51328
log_probs/std                         3.53933      0.09667     3.79114      3.29229
log_probs/max                         21.81179     3.24199     30.49041     14.38093
log_probs/min                         -6.52398     1.34816     -4.25044     -11.56903
mean/mean                             0.25784      0.02909     0.32490      0.19971
mean/std                              1.44403      0.02043     1.50793      1.40365
mean/max                              5.86962      0.72645     6.68142      4.31387
mean/min                              -7.89253     0.83354     -4.37344     -8.43579
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 7, 4, 1, 5, 3, 2, 9, 8]
replay_buffer._size: [46950 46950 46950 46950 46950 46950 46950 46950 46950 46950]
2023-08-12 12:25:36,126 MainThread INFO: EPOCH:291
2023-08-12 12:25:36,127 MainThread INFO: Time Consumed:8.924558877944946s
2023-08-12 12:25:36,127 MainThread INFO: Total Frames:468000s
  3%|▎         | 292/10000 [44:15<24:57:51,  9.26s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1096.28714
Train_Epoch_Reward                    9579.45270
Running_Training_Average_Rewards      1031.25235
Explore_Time                          0.01560
Train___Time                          8.90319
Eval____Time                          0.00481
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.53875
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.37037
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.41886
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.11114
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.50291
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.73138
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.80461
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11581.19997
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.06713
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.78337
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.69900      1.34067     10.22345     3.66425
alpha_0                               3.71750      0.01379     3.74582      3.69733
alpha_1                               0.64050      0.00277     0.64517      0.63620
alpha_2                               0.32829      0.00319     0.33386      0.32294
alpha_3                               0.12981      0.00058     0.13088      0.12886
alpha_4                               0.31418      0.00049     0.31506      0.31366
alpha_5                               0.47227      0.00198     0.47618      0.46930
alpha_6                               0.22225      0.00128     0.22442      0.22008
alpha_7                               0.44043      0.00045     0.44098      0.43943
alpha_8                               0.54854      0.00013     0.54877      0.54838
alpha_9                               0.30294      0.00148     0.30528      0.30036
Alpha_loss                            -0.35762     0.10501     -0.11126     -0.58600
Training/policy_loss                  167.84046    19.91098    216.27820    116.38401
Training/qf1_loss                     9270.21976   3531.33342  18800.00586  3741.11719
Training/qf2_loss                     1595.30179   423.09487   3321.55078   917.23114
Training/pf_norm                      23.47854     9.32343     62.81802     8.31511
Training/qf1_norm                     8374.31359   3738.65901  20728.59375  2518.55273
Training/qf2_norm                     5548.04850   2852.03984  16312.33203  1886.03918
log_std/mean                          -0.87246     0.00793     -0.85033     -0.88943
log_std/std                           0.42920      0.00468     0.44294      0.41789
log_std/max                           0.64696      0.07116     0.75529      0.37336
log_std/min                           -2.95011     0.03646     -2.85357     -3.03871
log_probs/mean                        3.78930      0.09580     4.05843      3.46300
log_probs/std                         3.52954      0.09608     3.78596      3.27026
log_probs/max                         22.11936     3.29889     32.51923     15.52516
log_probs/min                         -6.67509     1.22022     -4.65994     -10.41597
mean/mean                             0.26479      0.02428     0.32699      0.19838
mean/std                              1.44208      0.01606     1.48223      1.39050
mean/max                              5.83570      0.76979     6.71567      4.22077
mean/min                              -8.23882     0.66054     -4.57087     -8.66978
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 0, 7, 8, 1, 4, 5, 6, 3]
replay_buffer._size: [47100 47100 47100 47100 47100 47100 47100 47100 47100 47100]
2023-08-12 12:25:45,171 MainThread INFO: EPOCH:292
2023-08-12 12:25:45,172 MainThread INFO: Time Consumed:8.844806671142578s
2023-08-12 12:25:45,172 MainThread INFO: Total Frames:469500s
  3%|▎         | 293/10000 [44:24<24:46:26,  9.19s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1098.78926
Train_Epoch_Reward                    10939.80903
Running_Training_Average_Rewards      1039.99854
Explore_Time                          0.02250
Train___Time                          8.81761
Eval____Time                          0.00406
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.87053
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.11080
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.53629
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.63808
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.21062
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.82569
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.15720
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11578.23926
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.33209
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.66538
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.49060      1.20613     9.87110      3.78112
alpha_0                               3.76417      0.01024     3.77822      3.74666
alpha_1                               0.63050      0.00320     0.63611      0.62500
alpha_2                               0.31758      0.00283     0.32283      0.31321
alpha_3                               0.12790      0.00056     0.12884      0.12695
alpha_4                               0.31252      0.00066     0.31363      0.31142
alpha_5                               0.47859      0.00098     0.48013      0.47630
alpha_6                               0.21689      0.00196     0.22004      0.21352
alpha_7                               0.43808      0.00091     0.43941      0.43685
alpha_8                               0.54829      0.00040     0.54895      0.54762
alpha_9                               0.30728      0.00109     0.30902      0.30533
Alpha_loss                            -0.43096     0.11804     -0.12830     -0.71731
Training/policy_loss                  167.78828    15.65001    208.37935    128.95508
Training/qf1_loss                     8438.20026   3637.61133  20201.88281  3290.52588
Training/qf2_loss                     1547.18943   387.71372   3142.61597   749.30756
Training/pf_norm                      24.66948     10.79717    51.14579     6.86841
Training/qf1_norm                     7838.57363   3572.06228  19560.53711  2492.31909
Training/qf2_norm                     5053.92280   2064.67944  12093.94824  1677.87866
log_std/mean                          -0.86875     0.00696     -0.85136     -0.88348
log_std/std                           0.43359      0.00374     0.44273      0.42300
log_std/max                           0.59302      0.06625     0.68167      0.19502
log_std/min                           -3.04459     0.04519     -2.97175     -3.14820
log_probs/mean                        3.70089      0.10352     3.98674      3.49369
log_probs/std                         3.56987      0.09056     3.78772      3.33404
log_probs/max                         22.27286     3.29308     30.70988     15.47180
log_probs/min                         -6.67550     1.20703     -4.11968     -10.21404
mean/mean                             0.28894      0.02891     0.33984      0.22152
mean/std                              1.42797      0.01498     1.47956      1.38539
mean/max                              5.83641      0.83885     6.71658      4.47167
mean/min                              -8.86027     1.04459     -3.83388     -9.49450
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 0, 9, 2, 1, 8, 6, 7, 5, 4]
replay_buffer._size: [47250 47250 47250 47250 47250 47250 47250 47250 47250 47250]
2023-08-12 12:25:54,770 MainThread INFO: EPOCH:293
2023-08-12 12:25:54,770 MainThread INFO: Time Consumed:9.402753829956055s
2023-08-12 12:25:54,770 MainThread INFO: Total Frames:471000s
  3%|▎         | 294/10000 [44:33<25:05:02,  9.30s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1109.60180
Train_Epoch_Reward                    10485.44171
Running_Training_Average_Rewards      1033.49011
Explore_Time                          0.00469
Train___Time                          9.39190
Eval____Time                          0.00542
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.12585
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.32221
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.65765
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.72325
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.21660
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.17313
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.63008
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11690.84393
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.81091
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.16625
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75842      1.25090     10.07711     4.11774
alpha_0                               3.78434      0.00450     3.79352      3.77810
alpha_1                               0.62000      0.00312     0.62488      0.61392
alpha_2                               0.30995      0.00189     0.31314      0.30622
alpha_3                               0.12618      0.00038     0.12693      0.12557
alpha_4                               0.31087      0.00023     0.31139      0.31051
alpha_5                               0.48108      0.00042     0.48211      0.48017
alpha_6                               0.21124      0.00123     0.21346      0.20926
alpha_7                               0.43465      0.00179     0.43689      0.43048
alpha_8                               0.54695      0.00148     0.54889      0.54420
alpha_9                               0.31014      0.00054     0.31098      0.30905
Alpha_loss                            -0.34074     0.13913     -0.00179     -0.66279
Training/policy_loss                  161.59417    16.33053    200.23161    119.18855
Training/qf1_loss                     8800.97715   3417.58776  21599.35742  3404.46924
Training/qf2_loss                     1548.72533   370.24657   3268.69873   1020.68378
Training/pf_norm                      24.27058     9.04397     50.52631     9.21619
Training/qf1_norm                     7856.05634   3827.04758  20627.00977  2947.22559
Training/qf2_norm                     5161.87464   2150.82178  13038.92480  1884.47827
log_std/mean                          -0.87470     0.00755     -0.85984     -0.89897
log_std/std                           0.43860      0.00480     0.45349      0.42221
log_std/max                           0.52961      0.05497     0.62643      0.28846
log_std/min                           -3.11433     0.03317     -3.00489     -3.19686
log_probs/mean                        3.72956      0.12175     4.05169      3.41275
log_probs/std                         3.51929      0.11229     3.97153      3.24733
log_probs/max                         22.52558     3.66589     33.10678     16.69475
log_probs/min                         -6.56443     1.23694     -4.45909     -12.06474
mean/mean                             0.27375      0.03687     0.36060      0.19909
mean/std                              1.43554      0.01967     1.49753      1.38704
mean/max                              5.90068      0.82713     6.84122      4.30568
mean/min                              -9.30456     0.97184     -4.39948     -9.75030
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 6, 8, 5, 9, 1, 7, 0, 3]
replay_buffer._size: [47400 47400 47400 47400 47400 47400 47400 47400 47400 47400]
2023-08-12 12:26:04,668 MainThread INFO: EPOCH:294
2023-08-12 12:26:04,669 MainThread INFO: Time Consumed:9.748948574066162s
2023-08-12 12:26:04,669 MainThread INFO: Total Frames:472500s
  3%|▎         | 295/10000 [44:43<25:35:45,  9.49s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1095.36850
Train_Epoch_Reward                    10757.07938
Running_Training_Average_Rewards      1072.74434
Explore_Time                          0.00925
Train___Time                          9.73509
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.97263
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.78046
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.43222
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.48352
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.23729
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.82509
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.76077
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11558.55555
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.25353
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.12501
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61838      1.35482     10.30534     3.78800
alpha_0                               3.80726      0.00941     3.82672      3.79384
alpha_1                               0.60826      0.00323     0.61380      0.60277
alpha_2                               0.30122      0.00262     0.30611      0.29680
alpha_3                               0.12500      0.00031     0.12556      0.12445
alpha_4                               0.31036      0.00020     0.31066      0.31001
alpha_5                               0.48250      0.00049     0.48394      0.48203
alpha_6                               0.20775      0.00091     0.20923      0.20594
alpha_7                               0.42367      0.00379     0.43033      0.41795
alpha_8                               0.54001      0.00285     0.54414      0.53469
alpha_9                               0.31177      0.00035     0.31220      0.31099
Alpha_loss                            -0.40276     0.13832     -0.11878     -0.77532
Training/policy_loss                  166.93569    18.77561    213.13451    108.46124
Training/qf1_loss                     8409.88827   3565.40230  17542.36523  2651.35815
Training/qf2_loss                     1510.73879   405.65086   2997.69360   904.45898
Training/pf_norm                      25.61598     11.14303    58.85806     8.46068
Training/qf1_norm                     7331.01533   3646.99613  17465.15234  1835.27747
Training/qf2_norm                     4876.04785   2270.05822  13810.49805  1348.50623
log_std/mean                          -0.86869     0.00477     -0.85432     -0.88037
log_std/std                           0.44457      0.00533     0.45785      0.42928
log_std/max                           0.44135      0.07985     0.53881      0.07906
log_std/min                           -3.15396     0.04506     -3.08153     -3.25014
log_probs/mean                        3.67913      0.11010     3.93381      3.42373
log_probs/std                         3.54696      0.09893     3.78731      3.33477
log_probs/max                         23.17446     3.38959     32.32584     15.86724
log_probs/min                         -6.73406     1.27636     -4.31615     -10.03386
mean/mean                             0.25105      0.02143     0.32032      0.20571
mean/std                              1.43458      0.01982     1.48409      1.37922
mean/max                              5.66664      0.95396     6.91910      4.21232
mean/min                              -9.48174     0.94007     -5.61291     -10.00933
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 3, 5, 1, 8, 4, 9, 6, 0, 7]
replay_buffer._size: [47550 47550 47550 47550 47550 47550 47550 47550 47550 47550]
2023-08-12 12:26:13,509 MainThread INFO: EPOCH:295
2023-08-12 12:26:13,509 MainThread INFO: Time Consumed:8.673367261886597s
2023-08-12 12:26:13,509 MainThread INFO: Total Frames:474000s
  3%|▎         | 296/10000 [44:52<25:03:43,  9.30s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1080.81412
Train_Epoch_Reward                    10926.70616
Running_Training_Average_Rewards      1072.30757
Explore_Time                          0.00664
Train___Time                          8.66199
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.94761
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.64973
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.39941
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -81.31080
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.00277
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.55367
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.87157
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11413.01853
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.61087
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.53090
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70290      1.18079     9.84241      3.45995
alpha_0                               3.84875      0.01040     3.86528      3.82724
alpha_1                               0.59754      0.00273     0.60262      0.59330
alpha_2                               0.29159      0.00292     0.29669      0.28665
alpha_3                               0.12409      0.00018     0.12443      0.12381
alpha_4                               0.30873      0.00057     0.30997      0.30783
alpha_5                               0.48791      0.00223     0.49055      0.48400
alpha_6                               0.20351      0.00131     0.20588      0.20156
alpha_7                               0.41448      0.00213     0.41789      0.41059
alpha_8                               0.52761      0.00405     0.53456      0.52043
alpha_9                               0.31225      0.00029     0.31279      0.31189
Alpha_loss                            -0.40506     0.12900     -0.01006     -0.74413
Training/policy_loss                  163.89006    18.15950    213.23843    117.29675
Training/qf1_loss                     8377.43631   3436.04706  23100.64453  2177.76611
Training/qf2_loss                     1550.92620   380.66781   2885.47461   939.19086
Training/pf_norm                      24.68064     9.61120     52.12449     8.99269
Training/qf1_norm                     7277.92760   3542.67007  21284.05078  2394.75684
Training/qf2_norm                     4552.61009   2078.50256  11055.72266  1057.34399
log_std/mean                          -0.87440     0.00820     -0.85849     -0.89353
log_std/std                           0.44645      0.00467     0.45833      0.43501
log_std/max                           0.39075      0.04527     0.44297      0.11886
log_std/min                           -3.21002     0.03750     -3.13776     -3.29500
log_probs/mean                        3.68336      0.10320     3.90640      3.41818
log_probs/std                         3.59378      0.09361     3.80503      3.35746
log_probs/max                         23.17466     2.87816     32.91296     17.02818
log_probs/min                         -6.70355     1.18002     -4.44774     -12.02834
mean/mean                             0.25322      0.02480     0.32046      0.19934
mean/std                              1.43228      0.01848     1.47697      1.38621
mean/max                              5.94075      0.99209     6.77607      4.09124
mean/min                              -9.79484     0.88943     -4.81361     -10.67045
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 2, 9, 8, 5, 1, 4, 7, 3]
replay_buffer._size: [47700 47700 47700 47700 47700 47700 47700 47700 47700 47700]
2023-08-12 12:26:23,295 MainThread INFO: EPOCH:296
2023-08-12 12:26:23,296 MainThread INFO: Time Consumed:9.615610837936401s
2023-08-12 12:26:23,296 MainThread INFO: Total Frames:475500s
  3%|▎         | 297/10000 [45:02<25:24:53,  9.43s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1091.55287
Train_Epoch_Reward                    10723.86156
Running_Training_Average_Rewards      1080.25490
Explore_Time                          0.01676
Train___Time                          9.59392
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.08126
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.73870
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.27817
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -80.98934
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.99152
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.66541
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.86240
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11501.88823
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.61293
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.13984
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.51689      1.21271     9.53041      3.60279
alpha_0                               3.89137      0.01475     3.90998      3.86532
alpha_1                               0.58636      0.00439     0.59323      0.57940
alpha_2                               0.28093      0.00337     0.28654      0.27520
alpha_3                               0.12357      0.00013     0.12381      0.12333
alpha_4                               0.30454      0.00241     0.30782      0.30023
alpha_5                               0.49263      0.00163     0.49588      0.49056
alpha_6                               0.20039      0.00072     0.20153      0.19885
alpha_7                               0.40608      0.00208     0.41050      0.40368
alpha_8                               0.51319      0.00413     0.52029      0.50617
alpha_9                               0.31277      0.00008     0.31286      0.31256
Alpha_loss                            -0.49190     0.12558     -0.17798     -0.85796
Training/policy_loss                  161.41069    16.99629    208.50279    120.10526
Training/qf1_loss                     8524.93391   3728.85719  22020.13867  3222.22852
Training/qf2_loss                     1490.70986   369.87955   2801.24341   832.65625
Training/pf_norm                      23.50754     10.58850    60.27147     5.33868
Training/qf1_norm                     7659.74572   3330.47907  22361.81641  2504.36938
Training/qf2_norm                     5219.18353   2434.48492  12840.31934  1487.63232
log_std/mean                          -0.87761     0.00723     -0.86069     -0.89269
log_std/std                           0.44496      0.00470     0.45728      0.43446
log_std/max                           0.36890      0.04497     0.43789      0.22703
log_std/min                           -3.24942     0.04657     -3.04315     -3.33770
log_probs/mean                        3.60305      0.11122     3.83830      3.33840
log_probs/std                         3.63096      0.09948     3.87001      3.39087
log_probs/max                         23.86925     3.21796     32.87537     16.70387
log_probs/min                         -6.68244     1.17884     -4.72076     -10.67328
mean/mean                             0.18820      0.02964     0.25503      0.12050
mean/std                              1.42950      0.02062     1.47277      1.38057
mean/max                              5.99804      0.99628     6.81950      4.21644
mean/min                              -9.99319     1.15532     -5.79082     -10.69415
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 3, 5, 6, 4, 2, 8, 7, 0]
replay_buffer._size: [47850 47850 47850 47850 47850 47850 47850 47850 47850 47850]
2023-08-12 12:26:32,150 MainThread INFO: EPOCH:297
2023-08-12 12:26:32,150 MainThread INFO: Time Consumed:8.661218643188477s
2023-08-12 12:26:32,150 MainThread INFO: Total Frames:477000s
  3%|▎         | 298/10000 [45:11<24:58:19,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1071.03236
Train_Epoch_Reward                    11016.61340
Running_Training_Average_Rewards      1088.90604
Explore_Time                          0.00892
Train___Time                          8.64718
Eval____Time                          0.00449
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.43449
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.63230
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.99657
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -83.60542
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.61911
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.54631
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.35981
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11310.87547
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.51672
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.84115
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.38873      1.29781     9.96033      3.84632
alpha_0                               3.91028      0.00623     3.92818      3.90530
alpha_1                               0.57276      0.00441     0.57932      0.56546
alpha_2                               0.27112      0.00199     0.27510      0.26803
alpha_3                               0.12286      0.00021     0.12332      0.12267
alpha_4                               0.29757      0.00140     0.30016      0.29502
alpha_5                               0.49748      0.00103     0.49905      0.49593
alpha_6                               0.19617      0.00171     0.19881      0.19320
alpha_7                               0.40393      0.00052     0.40507      0.40337
alpha_8                               0.49918      0.00386     0.50602      0.49280
alpha_9                               0.31228      0.00049     0.31287      0.31149
Alpha_loss                            -0.45537     0.14470     -0.15435     -0.98250
Training/policy_loss                  164.71028    17.56050    197.68295    118.02278
Training/qf1_loss                     7908.76536   2973.44091  13932.04688  2883.51489
Training/qf2_loss                     1562.42804   410.17940   2658.35840   949.15070
Training/pf_norm                      24.09159     9.24947     51.60120     8.85486
Training/qf1_norm                     7270.40081   3388.48168  27227.73828  2859.87036
Training/qf2_norm                     5020.75377   2233.70535  13444.68750  1116.15430
log_std/mean                          -0.88090     0.01611     -0.85318     -0.91139
log_std/std                           0.44717      0.00606     0.46107      0.43273
log_std/max                           0.36946      0.06695     0.45215      0.19614
log_std/min                           -3.29868     0.05421     -3.21015     -3.43390
log_probs/mean                        3.64362      0.11645     3.91232      3.33927
log_probs/std                         3.66717      0.09585     3.91400      3.44402
log_probs/max                         23.33024     3.34906     32.54152     16.48791
log_probs/min                         -6.68485     1.44223     -4.67929     -13.31847
mean/mean                             0.25424      0.02902     0.32842      0.18911
mean/std                              1.42526      0.01960     1.46993      1.38102
mean/max                              5.71052      0.99151     6.79712      4.13931
mean/min                              -10.32033    1.35953     -4.38186     -11.07922
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 2, 4, 1, 8, 0, 7, 5, 3, 6]
replay_buffer._size: [48000 48000 48000 48000 48000 48000 48000 48000 48000 48000]
2023-08-12 12:26:41,675 MainThread INFO: EPOCH:298
2023-08-12 12:26:41,676 MainThread INFO: Time Consumed:9.361525297164917s
2023-08-12 12:26:41,676 MainThread INFO: Total Frames:478500s
  3%|▎         | 299/10000 [45:20<25:09:22,  9.34s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1091.27941
Train_Epoch_Reward                    10134.80237
Running_Training_Average_Rewards      1062.50924
Explore_Time                          0.01120
Train___Time                          9.34371
Eval____Time                          0.00405
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.10320
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.54707
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.00419
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -83.13746
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.03774
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.08895
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.34291
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11525.04355
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.39813
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.58977
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.71718      1.23788     9.68258      3.35551
alpha_0                               3.94630      0.01316     3.96934      3.92848
alpha_1                               0.55809      0.00400     0.56531      0.55184
alpha_2                               0.26396      0.00241     0.26796      0.25972
alpha_3                               0.12254      0.00006     0.12267      0.12247
alpha_4                               0.29502      0.00024     0.29546      0.29467
alpha_5                               0.49920      0.00089     0.50082      0.49815
alpha_6                               0.19117      0.00101     0.19316      0.18984
alpha_7                               0.40336      0.00120     0.40508      0.40127
alpha_8                               0.48640      0.00381     0.49269      0.47980
alpha_9                               0.31072      0.00030     0.31148      0.31044
Alpha_loss                            -0.38021     0.14254     -0.02767     -0.73860
Training/policy_loss                  160.41218    17.34980    201.17168    122.66576
Training/qf1_loss                     8195.70910   3101.17761  17614.15430  2677.88354
Training/qf2_loss                     1505.09108   286.44055   2441.40332   1054.08398
Training/pf_norm                      26.86177     10.66284    52.14071     10.52971
Training/qf1_norm                     7937.57864   3658.67785  19876.53516  2808.62012
Training/qf2_norm                     4818.97162   1936.27682  11516.03027  1572.63098
log_std/mean                          -0.89277     0.01014     -0.87529     -0.91459
log_std/std                           0.44724      0.00489     0.45827      0.43675
log_std/max                           0.28763      0.07591     0.40558      0.12240
log_std/min                           -3.37496     0.04657     -3.27650     -3.50184
log_probs/mean                        3.69889      0.12205     3.96940      3.41081
log_probs/std                         3.74373      0.09806     3.96655      3.50059
log_probs/max                         23.95944     2.98799     34.36047     17.73617
log_probs/min                         -6.66572     1.23538     -4.24069     -10.81190
mean/mean                             0.22699      0.02849     0.29500      0.14295
mean/std                              1.43572      0.02159     1.49522      1.38950
mean/max                              5.94182      0.97965     6.89480      4.29721
mean/min                              -10.09783    1.10093     -5.82598     -10.86623
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 2, 1, 7, 0, 9, 4, 3, 5]
replay_buffer._size: [48150 48150 48150 48150 48150 48150 48150 48150 48150 48150]
2023-08-12 12:26:50,709 MainThread INFO: EPOCH:299
2023-08-12 12:26:50,710 MainThread INFO: Time Consumed:8.852533340454102s
2023-08-12 12:26:50,710 MainThread INFO: Total Frames:480000s
  3%|▎         | 300/10000 [45:29<24:54:38,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1071.35543
Train_Epoch_Reward                    10724.09086
Running_Training_Average_Rewards      1062.51689
Explore_Time                          0.00482
Train___Time                          8.84311
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -94.86210
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.99655
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.49893
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -82.84824
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.77710
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.91181
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.23746
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11334.33401
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.06715
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.58034
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.47556      1.16056     9.70481      4.12625
alpha_0                               3.98446      0.01368     4.01187      3.96884
alpha_1                               0.54603      0.00357     0.55172      0.53945
alpha_2                               0.25565      0.00222     0.25963      0.25207
alpha_3                               0.12271      0.00011     0.12295      0.12252
alpha_4                               0.29513      0.00032     0.29549      0.29465
alpha_5                               0.50067      0.00017     0.50093      0.50042
alpha_6                               0.18968      0.00005     0.18982      0.18954
alpha_7                               0.39885      0.00132     0.40124      0.39651
alpha_8                               0.47301      0.00402     0.47966      0.46564
alpha_9                               0.31023      0.00016     0.31060      0.31003
Alpha_loss                            -0.28493     0.15331     0.09845      -0.65579
Training/policy_loss                  163.09459    19.07036    207.47375    112.86517
Training/qf1_loss                     8282.71639   3234.58229  15366.11230  3493.58130
Training/qf2_loss                     1585.73629   377.32556   3401.80664   1020.20599
Training/pf_norm                      24.71185     9.86380     55.78146     8.15092
Training/qf1_norm                     7954.34801   3813.53422  18555.30469  2648.91553
Training/qf2_norm                     5350.38025   2660.89019  15112.01758  1985.31641
log_std/mean                          -0.90340     0.00833     -0.88404     -0.91874
log_std/std                           0.44988      0.00537     0.46181      0.43747
log_std/max                           0.28149      0.05780     0.37254      0.13844
log_std/min                           -3.41577     0.04424     -3.27261     -3.51919
log_probs/mean                        3.75292      0.12666     4.10566      3.41695
log_probs/std                         3.69130      0.11720     3.98681      3.46414
log_probs/max                         24.03245     2.76158     32.56963     18.51830
log_probs/min                         -6.74337     1.15066     -4.29217     -10.14501
mean/mean                             0.22923      0.02738     0.29006      0.17056
mean/std                              1.43666      0.02194     1.50475      1.39583
mean/max                              5.86616      1.04888     7.03326      4.20895
mean/min                              -10.52018    0.89149     -5.89315     -11.07495
------------------------------------  -----------  ----------  -----------  ----------
start to update mask
sample: [6, 3, 0, 2, 1, 7, 5, 8, 4, 9]
replay_buffer._size: [48300 48300 48300 48300 48300 48300 48300 48300 48300 48300]
2023-08-12 12:26:59,502 MainThread INFO: EPOCH:300
2023-08-12 12:26:59,503 MainThread INFO: Time Consumed:7.303045034408569s
2023-08-12 12:26:59,503 MainThread INFO: Total Frames:481500s
  3%|▎         | 301/10000 [45:40<25:49:06,  9.58s/it]------------------------------------  -----------  -----------  ------------  ----------
Name                                  Value
Running_Average_Rewards               1063.15928
Train_Epoch_Reward                    10082.33919
Running_Training_Average_Rewards      1031.37441
Explore_Time                          0.00328
Train___Time                          7.29468
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.67498
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.73705
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.58033
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -84.15173
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.49104
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.83264
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.64744
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11256.44563
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.80931
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.92834
mean_success_rate                     0.10000

Name                                  Mean         Std          Max           Min
Reward_Mean                           6.72105      1.41364      10.89203      3.89766
alpha_0                               4.04975      0.02642      4.10205       4.01256
alpha_1                               0.56453      0.02011      0.60006       0.53930
alpha_2                               0.25942      0.00708      0.27338       0.25192
alpha_3                               0.12779      0.00265      0.13143       0.12297
alpha_4                               0.30783      0.00795      0.31657       0.29478
alpha_5                               0.50255      0.00281      0.51074       0.49889
alpha_6                               0.19739      0.00492      0.20510       0.18955
alpha_7                               0.38683      0.00683      0.39645       0.37365
alpha_8                               0.46131      0.00151      0.46547       0.45964
alpha_9                               0.31268      0.00514      0.32359       0.30721
Alpha_loss                            2.44619      0.62057      3.53046       1.22567
Training/policy_loss                  330.10723    26.40912     398.02499     260.37448
Training/qf1_loss                     18155.40591  10059.25905  45384.82812   6271.86914
Training/qf2_loss                     4839.29120   3484.20314   15954.57227   1901.07703
Training/pf_norm                      40.88788     17.99492     90.88142      13.57002
Training/qf1_norm                     26478.90217  25695.30869  99922.57031   4822.11523
Training/qf2_norm                     24270.35256  32036.02086  134758.42188  3240.09399
log_std/mean                          -0.87135     0.04380      -0.79839      -0.95475
log_std/std                           0.43063      0.01088      0.45038       0.40719
log_std/max                           0.42054      0.06121      0.66194       0.23790
log_std/min                           -3.10856     0.16987      -2.82814      -3.44990
log_probs/mean                        6.06542      0.68157      7.01771       4.71912
log_probs/std                         5.63364      0.39386      6.33370       4.71909
log_probs/max                         33.81590     3.44521      39.42949      26.55618
log_probs/min                         -6.41106     1.26393      -4.32881      -9.23920
mean/mean                             0.29201      0.20282      0.59929       -0.03447
mean/std                              1.86629      0.11486      2.02938       1.65948
mean/max                              6.34846      0.24629      6.91124       5.93755
mean/min                              -8.95853     0.76766      -6.56063      -10.47984
------------------------------------  -----------  -----------  ------------  ----------
snapshot at 300
history save at ./log/must_mtsac/mt10/12/model
sample: [2, 3, 6, 4, 8, 7, 1, 9, 5, 0]
replay_buffer._size: [48450 48450 48450 48450 48450 48450 48450 48450 48450 48450]
2023-08-12 12:27:09,266 MainThread INFO: EPOCH:301
2023-08-12 12:27:09,267 MainThread INFO: Time Consumed:8.09830904006958s
2023-08-12 12:27:09,267 MainThread INFO: Total Frames:483000s
  3%|▎         | 302/10000 [45:48<24:44:39,  9.19s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1082.80174
Train_Epoch_Reward                    10923.77330
Running_Training_Average_Rewards      1057.67344
Explore_Time                          0.00428
Train___Time                          8.08923
Eval____Time                          0.00423
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.16368
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.52057
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.27132
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -83.92693
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.28801
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.48921
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.57811
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11454.96470
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.46474
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.24470
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.55918      1.25757     9.55070      3.00648
alpha_0                               4.13624      0.01980     4.16120      4.10332
alpha_1                               0.62174      0.01052     0.63757      0.60067
alpha_2                               0.28082      0.00354     0.28672      0.27363
alpha_3                               0.13142      0.00021     0.13170      0.13097
alpha_4                               0.30983      0.00412     0.31582      0.30143
alpha_5                               0.51857      0.00495     0.52948      0.51111
alpha_6                               0.21215      0.00443     0.22008      0.20523
alpha_7                               0.36282      0.00454     0.37334      0.35805
alpha_8                               0.45446      0.00203     0.45953      0.45237
alpha_9                               0.33635      0.00669     0.34672      0.32386
Alpha_loss                            1.21828      0.17721     1.63480      0.80747
Training/policy_loss                  304.28211    21.77120    348.63303    256.96085
Training/qf1_loss                     9321.70798   2726.95010  17494.28125  4503.22852
Training/qf2_loss                     2045.99157   450.28944   3683.59497   1150.87500
Training/pf_norm                      22.41842     8.05650     48.48195     9.17124
Training/qf1_norm                     7764.14607   3698.69716  19854.05469  3527.20288
Training/qf2_norm                     6070.36166   2660.97438  17034.77344  1811.67432
log_std/mean                          -0.88220     0.03876     -0.79955     -0.91925
log_std/std                           0.42305      0.00446     0.43467      0.40994
log_std/max                           0.35324      0.10291     0.64980      0.14995
log_std/min                           -3.02882     0.07863     -2.87408     -3.19344
log_probs/mean                        5.23361      0.14015     5.64663      4.83639
log_probs/std                         4.77138      0.18844     5.17712      4.35203
log_probs/max                         31.24905     2.95437     38.75560     23.39838
log_probs/min                         -6.30212     1.29212     -3.92242     -10.76325
mean/mean                             -0.18392     0.05945     -0.00772     -0.26650
mean/std                              1.73856      0.03969     1.85058      1.63383
mean/max                              5.17532      0.34772     6.04747      4.58960
mean/min                              -11.72824    1.48202     -6.32545     -12.91201
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 5, 3, 9, 6, 8, 0, 4, 1]
replay_buffer._size: [48600 48600 48600 48600 48600 48600 48600 48600 48600 48600]
2023-08-12 12:27:18,394 MainThread INFO: EPOCH:302
2023-08-12 12:27:18,394 MainThread INFO: Time Consumed:8.950194835662842s
2023-08-12 12:27:18,394 MainThread INFO: Total Frames:484500s
  3%|▎         | 303/10000 [45:57<24:38:15,  9.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1017.76282
Train_Epoch_Reward                    10016.51326
Running_Training_Average_Rewards      1034.08752
Explore_Time                          0.00883
Train___Time                          8.93687
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.68589
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.73149
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.09520
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.41958
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.01075
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -133.15678
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.90059
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10886.86773
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.30505
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.93422
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80256      1.38342     10.79395     3.54486
alpha_0                               4.17986      0.01236     4.20100      4.16067
alpha_1                               0.64698      0.00454     0.65374      0.63782
alpha_2                               0.29390      0.00436     0.30155      0.28685
alpha_3                               0.13103      0.00037     0.13198      0.13070
alpha_4                               0.29072      0.00576     0.30120      0.28142
alpha_5                               0.54500      0.00910     0.55976      0.52979
alpha_6                               0.22823      0.00457     0.23574      0.22024
alpha_7                               0.36040      0.00247     0.36557      0.35776
alpha_8                               0.46688      0.00771     0.48081      0.45536
alpha_9                               0.35277      0.00300     0.35707      0.34688
Alpha_loss                            1.37048      0.19209     1.84701      0.77198
Training/policy_loss                  295.89869    19.40579    337.38937    238.42957
Training/qf1_loss                     8608.90662   2720.31544  15446.54102  4212.44971
Training/qf2_loss                     1976.01703   432.80968   3230.90796   1355.84436
Training/pf_norm                      22.43953     7.36451     44.60185     8.75170
Training/qf1_norm                     7209.31100   3110.07286  18854.27344  2461.97412
Training/qf2_norm                     5496.98483   1982.25707  12528.37500  1812.24524
log_std/mean                          -0.93337     0.01370     -0.90542     -0.95964
log_std/std                           0.41244      0.00449     0.42183      0.40083
log_std/max                           0.29771      0.12068     0.50561      0.08415
log_std/min                           -2.99477     0.06577     -2.87643     -3.12497
log_probs/mean                        5.28188      0.13780     5.69686      4.91240
log_probs/std                         4.64880      0.15153     5.01851      4.33899
log_probs/max                         31.12153     3.11894     40.16458     24.29869
log_probs/min                         -6.20104     1.24149     -4.04899     -10.28799
mean/mean                             -0.19522     0.02342     -0.14055     -0.25490
mean/std                              1.71108      0.02530     1.78796      1.64336
mean/max                              5.06952      0.21202     5.42394      4.71990
mean/min                              -12.18769    1.30885     -6.52370     -13.45935
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 2, 9, 1, 0, 8, 6, 7, 5, 4]
replay_buffer._size: [48750 48750 48750 48750 48750 48750 48750 48750 48750 48750]
2023-08-12 12:27:27,562 MainThread INFO: EPOCH:303
2023-08-12 12:27:27,562 MainThread INFO: Time Consumed:9.000741958618164s
2023-08-12 12:27:27,562 MainThread INFO: Total Frames:486000s
  3%|▎         | 304/10000 [46:06<24:40:44,  9.16s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1109.73768
Train_Epoch_Reward                    10353.71210
Running_Training_Average_Rewards      1043.13329
Explore_Time                          0.00453
Train___Time                          8.99226
Eval____Time                          0.00338
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.66772
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.37137
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.05754
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -73.00853
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.38162
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.22613
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.83724
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11746.63335
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.46561
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.24079
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.66629      1.35031     10.41035     3.51552
alpha_0                               4.20749      0.00620     4.21727      4.19946
alpha_1                               0.65832      0.00237     0.66166      0.65386
alpha_2                               0.30998      0.00477     0.31803      0.30171
alpha_3                               0.13467      0.00174     0.13781      0.13202
alpha_4                               0.27374      0.00415     0.28126      0.26692
alpha_5                               0.57218      0.00654     0.58283      0.56000
alpha_6                               0.24255      0.00388     0.24910      0.23587
alpha_7                               0.37198      0.00366     0.37883      0.36571
alpha_8                               0.49453      0.00767     0.50743      0.48110
alpha_9                               0.35905      0.00097     0.36022      0.35713
Alpha_loss                            1.52017      0.14044     1.86466      1.08635
Training/policy_loss                  291.59024    19.23098    339.24411    232.86646
Training/qf1_loss                     8780.37135   3174.38275  20175.23438  3533.57495
Training/qf2_loss                     1917.54441   431.92315   3412.10083   1208.97058
Training/pf_norm                      20.66243     7.95675     46.99869     7.62892
Training/qf1_norm                     7670.37328   3513.86305  19997.86328  2255.11597
Training/qf2_norm                     6512.77598   3194.40382  18415.48828  1592.07239
log_std/mean                          -0.93878     0.00926     -0.91960     -0.95877
log_std/std                           0.40781      0.00479     0.41859      0.39729
log_std/max                           0.58039      0.11655     0.68723      0.11764
log_std/min                           -2.91089     0.06249     -2.72925     -3.05114
log_probs/mean                        5.29741      0.12371     5.66996      4.99992
log_probs/std                         4.53942      0.15399     4.90768      4.19251
log_probs/max                         30.83675     2.74964     40.91851     23.61465
log_probs/min                         -6.13021     1.35163     -3.82176     -10.66992
mean/mean                             -0.13379     0.02564     -0.06091     -0.19749
mean/std                              1.70334      0.02589     1.76145      1.63912
mean/max                              5.10203      0.36162     5.55792      4.55910
mean/min                              -12.43031    1.20228     -7.32928     -13.59061
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 7, 5, 3, 4, 2, 6, 9, 1]
replay_buffer._size: [48900 48900 48900 48900 48900 48900 48900 48900 48900 48900]
2023-08-12 12:27:36,119 MainThread INFO: EPOCH:304
2023-08-12 12:27:36,119 MainThread INFO: Time Consumed:8.370391845703125s
2023-08-12 12:27:36,119 MainThread INFO: Total Frames:487500s
  3%|▎         | 305/10000 [46:15<24:09:38,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1082.63819
Train_Epoch_Reward                    11351.22926
Running_Training_Average_Rewards      1057.38182
Explore_Time                          0.00402
Train___Time                          8.36157
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -101.05629
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.08446
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.93811
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.05687
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.70224
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.75833
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.60581
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11431.91059
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.75531
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -66.57130
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.86213      1.38105     12.21097     3.60649
alpha_0                               4.21167      0.00297     4.21498      4.20411
alpha_1                               0.66391      0.00128     0.66599      0.66170
alpha_2                               0.32570      0.00426     0.33281      0.31819
alpha_3                               0.14164      0.00218     0.14529      0.13788
alpha_4                               0.26081      0.00338     0.26679      0.25514
alpha_5                               0.59086      0.00407     0.59633      0.58302
alpha_6                               0.25486      0.00319     0.26008      0.24923
alpha_7                               0.38591      0.00376     0.39140      0.37898
alpha_8                               0.51782      0.00578     0.52745      0.50766
alpha_9                               0.35900      0.00075     0.35997      0.35749
Alpha_loss                            1.28270      0.18091     1.68000      0.81373
Training/policy_loss                  285.58254    18.16563    327.75717    246.55940
Training/qf1_loss                     8190.80629   2868.00242  15972.65332  3476.52271
Training/qf2_loss                     1838.09525   392.59116   2916.32251   1244.85840
Training/pf_norm                      22.56472     9.01032     58.90523     10.84940
Training/qf1_norm                     7182.53484   3937.03273  27332.97461  2636.03369
Training/qf2_norm                     5531.43939   2575.00881  13457.41113  1822.08655
log_std/mean                          -0.94298     0.00877     -0.92865     -0.96445
log_std/std                           0.40659      0.00425     0.41730      0.39492
log_std/max                           0.68166      0.11604     0.77100      0.18179
log_std/min                           -2.83900     0.05504     -2.68879     -2.95351
log_probs/mean                        5.05354      0.16534     5.39087      4.59834
log_probs/std                         4.34448      0.13326     4.63061      3.99726
log_probs/max                         29.82420     2.86108     39.50153     23.29436
log_probs/min                         -6.01898     1.20719     -4.19428     -10.83252
mean/mean                             -0.06129     0.03160     0.02712      -0.11969
mean/std                              1.65793      0.02884     1.72221      1.58035
mean/max                              5.09868      0.45298     5.59663      4.50184
mean/min                              -12.42245    1.41358     -5.49288     -13.72744
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 8, 4, 2, 0, 3, 6, 7, 1, 9]
replay_buffer._size: [49050 49050 49050 49050 49050 49050 49050 49050 49050 49050]
2023-08-12 12:27:45,085 MainThread INFO: EPOCH:305
2023-08-12 12:27:45,087 MainThread INFO: Time Consumed:8.834587574005127s
2023-08-12 12:27:45,087 MainThread INFO: Total Frames:489000s
  3%|▎         | 306/10000 [46:24<24:11:12,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1120.52557
Train_Epoch_Reward                    11135.39122
Running_Training_Average_Rewards      1094.67775
Explore_Time                          0.00983
Train___Time                          8.81996
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -101.74217
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.06792
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.51782
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.46522
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.60537
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.25935
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.45043
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11793.93218
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.99258
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -64.57563
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.45298      1.32513     10.24581     3.14905
alpha_0                               4.19713      0.00327     4.20476      4.19199
alpha_1                               0.66692      0.00040     0.66755      0.66602
alpha_2                               0.33921      0.00351     0.34492      0.33294
alpha_3                               0.14898      0.00216     0.15272      0.14536
alpha_4                               0.24974      0.00298     0.25503      0.24486
alpha_5                               0.59667      0.00075     0.59755      0.59455
alpha_6                               0.26438      0.00237     0.26832      0.26017
alpha_7                               0.39657      0.00322     0.40236      0.39146
alpha_8                               0.53231      0.00226     0.53515      0.52761
alpha_9                               0.35504      0.00129     0.35744      0.35303
Alpha_loss                            0.92934      0.15035     1.27658      0.49390
Training/policy_loss                  288.10671    18.25271    343.71918    234.83862
Training/qf1_loss                     7622.24895   2837.62862  17448.50195  2900.61499
Training/qf2_loss                     1799.34269   391.54951   3048.24585   1119.69507
Training/pf_norm                      23.68986     10.07911    61.60096     8.70166
Training/qf1_norm                     7477.50152   3632.34181  21920.39648  2709.22119
Training/qf2_norm                     5545.94533   2981.63043  15345.40527  1699.60107
log_std/mean                          -0.94410     0.00905     -0.92391     -0.96427
log_std/std                           0.39810      0.00614     0.41159      0.38415
log_std/max                           0.55400      0.14888     0.76537      0.08463
log_std/min                           -2.79151     0.05726     -2.67872     -2.88960
log_probs/mean                        4.71241      0.13132     4.95592      4.37116
log_probs/std                         4.12186      0.14590     4.52440      3.79420
log_probs/max                         29.11312     2.66614     39.42078     23.09798
log_probs/min                         -6.38357     1.40976     -3.88108     -10.82093
mean/mean                             0.03012      0.04366     0.11604      -0.08611
mean/std                              1.59403      0.02576     1.65569      1.53254
mean/max                              5.19676      0.59033     5.85033      4.33732
mean/min                              -12.04642    1.48419     -5.44774     -13.66893
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 9, 5, 1, 4, 7, 2, 6, 3]
replay_buffer._size: [49200 49200 49200 49200 49200 49200 49200 49200 49200 49200]
2023-08-12 12:27:53,993 MainThread INFO: EPOCH:306
2023-08-12 12:27:53,994 MainThread INFO: Time Consumed:8.742219686508179s
2023-08-12 12:27:53,994 MainThread INFO: Total Frames:490500s
  3%|▎         | 307/10000 [46:33<24:05:51,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1037.13103
Train_Epoch_Reward                    11603.14345
Running_Training_Average_Rewards      1136.32546
Explore_Time                          0.00377
Train___Time                          8.73388
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.90787
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.55783
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.11410
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.57086
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.34602
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.50665
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.25392
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10968.77643
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.39541
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.81351
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.45402      1.31615     10.65677     3.99834
alpha_0                               4.18370      0.00351     4.19170      4.17945
alpha_1                               0.66746      0.00033     0.66788      0.66698
alpha_2                               0.34974      0.00271     0.35452      0.34502
alpha_3                               0.15639      0.00208     0.15993      0.15280
alpha_4                               0.24033      0.00251     0.24477      0.23619
alpha_5                               0.59172      0.00124     0.59443      0.58974
alpha_6                               0.27118      0.00153     0.27365      0.26839
alpha_7                               0.40788      0.00296     0.41240      0.40247
alpha_8                               0.53362      0.00146     0.53526      0.53060
alpha_9                               0.34988      0.00193     0.35300      0.34639
Alpha_loss                            0.59001      0.12864     0.95649      0.27706
Training/policy_loss                  287.53180    17.99260    337.46609    246.55859
Training/qf1_loss                     7413.18512   2633.56946  15909.39551  3047.27319
Training/qf2_loss                     1735.63086   361.85428   3078.91162   1132.62390
Training/pf_norm                      24.43845     9.81914     49.69429     9.73428
Training/qf1_norm                     7720.12379   3463.93074  17772.75977  2657.51611
Training/qf2_norm                     6045.37645   2475.16048  15697.27441  2510.96631
log_std/mean                          -0.93807     0.00687     -0.92286     -0.95462
log_std/std                           0.39317      0.00396     0.40215      0.38551
log_std/max                           0.36995      0.07072     0.43755      -0.00065
log_std/min                           -2.65012     0.05107     -2.55987     -2.85069
log_probs/mean                        4.40737      0.11080     4.64667      4.13972
log_probs/std                         3.90537      0.13094     4.22654      3.60280
log_probs/max                         28.50115     3.14031     38.00335     18.56089
log_probs/min                         -6.32077     1.42783     -3.71833     -10.53099
mean/mean                             0.07616      0.02166     0.12132      0.02239
mean/std                              1.54169      0.02310     1.60198      1.47739
mean/max                              5.07925      0.68115     5.96840      4.17425
mean/min                              -11.73798    1.06362     -4.83960     -13.08616
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 9, 1, 7, 4, 2, 0, 5, 3, 8]
replay_buffer._size: [49350 49350 49350 49350 49350 49350 49350 49350 49350 49350]
2023-08-12 12:28:03,049 MainThread INFO: EPOCH:307
2023-08-12 12:28:03,049 MainThread INFO: Time Consumed:8.848722219467163s
2023-08-12 12:28:03,049 MainThread INFO: Total Frames:492000s
  3%|▎         | 308/10000 [46:42<24:11:25,  8.99s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1106.19778
Train_Epoch_Reward                    10659.36135
Running_Training_Average_Rewards      1113.26320
Explore_Time                          0.00710
Train___Time                          8.83768
Eval____Time                          0.00335
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.41663
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.75140
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.74613
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.30724
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.88182
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.43041
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -90.32560
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11672.60936
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.63049
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -62.14188
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.52581      1.45748     10.80352     3.67952
alpha_0                               4.18162      0.00270     4.18611      4.17559
alpha_1                               0.66572      0.00070     0.66712      0.66441
alpha_2                               0.35865      0.00203     0.36179      0.35462
alpha_3                               0.16374      0.00223     0.16752      0.16000
alpha_4                               0.23245      0.00203     0.23611      0.22917
alpha_5                               0.59033      0.00049     0.59102      0.58949
alpha_6                               0.27533      0.00097     0.27698      0.27369
alpha_7                               0.41665      0.00228     0.41989      0.41246
alpha_8                               0.52421      0.00413     0.53052      0.51654
alpha_9                               0.34112      0.00309     0.34630      0.33575
Alpha_loss                            0.37439      0.12888     0.68175      0.06440
Training/policy_loss                  283.65802    20.44118    328.70224    215.89417
Training/qf1_loss                     7863.85333   2524.69604  15268.33496  3223.19092
Training/qf2_loss                     1750.42783   328.63946   3146.21533   1203.71716
Training/pf_norm                      22.29419     8.70632     46.85254     9.19640
Training/qf1_norm                     7545.84735   3235.93618  17390.33008  2435.05103
Training/qf2_norm                     5342.42011   2649.95395  16277.96680  1698.10413
log_std/mean                          -0.93587     0.00555     -0.92282     -0.94991
log_std/std                           0.39705      0.00570     0.41413      0.38561
log_std/max                           0.40226      0.08400     0.56384      0.16483
log_std/min                           -2.62306     0.08869     -2.52186     -2.92994
log_probs/mean                        4.20288      0.12058     4.53129      3.90645
log_probs/std                         3.74096      0.13760     4.07446      3.46115
log_probs/max                         27.76845     2.80982     35.76009     20.82130
log_probs/min                         -6.17339     1.17737     -4.11878     -9.73014
mean/mean                             0.09279      0.03591     0.16426      0.00578
mean/std                              1.50479      0.02561     1.57406      1.44847
mean/max                              5.21781      0.79492     6.05324      3.91123
mean/min                              -11.42350    1.05711     -6.49574     -13.00366
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 0, 7, 8, 5, 3, 4, 2, 9, 6]
replay_buffer._size: [49500 49500 49500 49500 49500 49500 49500 49500 49500 49500]
2023-08-12 12:28:11,438 MainThread INFO: EPOCH:308
2023-08-12 12:28:11,438 MainThread INFO: Time Consumed:8.201948165893555s
2023-08-12 12:28:11,439 MainThread INFO: Total Frames:493500s
  3%|▎         | 309/10000 [46:50<23:42:19,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1115.18421
Train_Epoch_Reward                    10798.52435
Running_Training_Average_Rewards      1102.03431
Explore_Time                          0.00991
Train___Time                          8.18770
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -101.01333
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.11480
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.37106
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.28331
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.22247
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.63464
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.85117
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11747.59089
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.19693
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.06112
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.99492      1.38813     10.78827     3.42187
alpha_0                               4.18352      0.00268     4.19113      4.17584
alpha_1                               0.66230      0.00129     0.66437      0.65974
alpha_2                               0.36404      0.00112     0.36601      0.36185
alpha_3                               0.17101      0.00199     0.17438      0.16759
alpha_4                               0.22650      0.00143     0.22911      0.22414
alpha_5                               0.58956      0.00031     0.59005      0.58901
alpha_6                               0.27807      0.00057     0.27901      0.27701
alpha_7                               0.42229      0.00139     0.42496      0.41995
alpha_8                               0.50650      0.00580     0.51637      0.49653
alpha_9                               0.32981      0.00334     0.33563      0.32397
Alpha_loss                            0.15879      0.11176     0.47975      -0.13473
Training/policy_loss                  276.87657    20.58378    328.95807    229.43460
Training/qf1_loss                     7939.80176   2984.20135  16087.04980  2714.49463
Training/qf2_loss                     1798.54398   389.13628   3243.42456   1074.30750
Training/pf_norm                      26.67752     11.07300    67.84431     7.23680
Training/qf1_norm                     7030.48911   3173.29085  16361.78125  2808.87866
Training/qf2_norm                     5014.31690   2536.02701  13612.48242  1471.53259
log_std/mean                          -0.93974     0.00634     -0.92704     -0.95338
log_std/std                           0.39909      0.00421     0.40948      0.38800
log_std/max                           0.31344      0.05135     0.38670      0.10470
log_std/min                           -2.66108     0.12930     -2.48691     -3.00263
log_probs/mean                        4.02298      0.08715     4.28381      3.76748
log_probs/std                         3.58283      0.11594     3.93374      3.36044
log_probs/max                         27.55644     3.34930     37.27646     19.47261
log_probs/min                         -6.34650     1.44640     -3.88647     -10.82556
mean/mean                             0.12107      0.02747     0.18331      0.06759
mean/std                              1.46774      0.01943     1.51897      1.42510
mean/max                              5.31063      0.82580     6.09478      3.76422
mean/min                              -10.90458    1.16327     -6.01506     -12.42400
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 2, 9, 8, 3, 6, 5, 1, 7]
replay_buffer._size: [49650 49650 49650 49650 49650 49650 49650 49650 49650 49650]
2023-08-12 12:28:19,845 MainThread INFO: EPOCH:309
2023-08-12 12:28:19,845 MainThread INFO: Time Consumed:8.226662874221802s
2023-08-12 12:28:19,845 MainThread INFO: Total Frames:495000s
  3%|▎         | 310/10000 [46:59<23:23:01,  8.69s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1119.16661
Train_Epoch_Reward                    10868.04489
Running_Training_Average_Rewards      1077.53102
Explore_Time                          0.01300
Train___Time                          8.20907
Eval____Time                          0.00397
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.91191
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.28372
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.04782
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.91312
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.16613
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.13702
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.35212
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11793.00630
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.03207
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.49629
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75742      1.33903     9.81438      2.86614
alpha_0                               4.19004      0.00393     4.19670      4.18439
alpha_1                               0.65853      0.00098     0.65971      0.65640
alpha_2                               0.36753      0.00065     0.36840      0.36606
alpha_3                               0.17752      0.00177     0.18057      0.17445
alpha_4                               0.22203      0.00113     0.22409      0.22010
alpha_5                               0.58977      0.00052     0.59051      0.58909
alpha_6                               0.27984      0.00042     0.28057      0.27903
alpha_7                               0.42529      0.00027     0.42601      0.42500
alpha_8                               0.48531      0.00617     0.49633      0.47541
alpha_9                               0.31787      0.00345     0.32385      0.31200
Alpha_loss                            0.02483      0.11745     0.25593      -0.26461
Training/policy_loss                  274.40294    19.14949    324.26584    221.82988
Training/qf1_loss                     7889.78984   2972.27994  14414.30957  2664.10742
Training/qf2_loss                     1781.99811   416.08021   3534.09766   1169.18616
Training/pf_norm                      24.27273     8.49435     55.33133     10.23915
Training/qf1_norm                     7673.71328   3558.68556  18478.55859  2951.86475
Training/qf2_norm                     5555.83785   2808.64938  14755.47852  1463.26099
log_std/mean                          -0.92549     0.01176     -0.90229     -0.95136
log_std/std                           0.39865      0.00415     0.40813      0.39020
log_std/max                           0.34514      0.07012     0.44368      0.10232
log_std/min                           -2.58989     0.12285     -2.40049     -2.93116
log_probs/mean                        3.89132      0.12128     4.22914      3.55728
log_probs/std                         3.47442      0.13043     3.86698      3.16860
log_probs/max                         26.17466     3.85392     36.45283     16.25551
log_probs/min                         -6.50795     1.27165     -4.38525     -10.15129
mean/mean                             0.14202      0.02964     0.21225      0.07181
mean/std                              1.45179      0.02474     1.52448      1.38071
mean/max                              4.97836      0.88562     6.16768      3.61693
mean/min                              -10.69567    1.05669     -5.80275     -12.02273
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 1, 2, 3, 4, 0, 9, 7, 5, 8]
replay_buffer._size: [49800 49800 49800 49800 49800 49800 49800 49800 49800 49800]
2023-08-12 12:28:28,928 MainThread INFO: EPOCH:310
2023-08-12 12:28:28,928 MainThread INFO: Time Consumed:8.87513279914856s
2023-08-12 12:28:28,929 MainThread INFO: Total Frames:496500s
  3%|▎         | 311/10000 [47:08<23:41:23,  8.80s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1099.72230
Train_Epoch_Reward                    10817.96895
Running_Training_Average_Rewards      1082.81794
Explore_Time                          0.01193
Train___Time                          8.85936
Eval____Time                          0.00326
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.76985
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.72064
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.72594
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.43142
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.14564
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.23832
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.84093
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11581.89751
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.92029
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.88150
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60403      1.55387     12.04484     3.30398
alpha_0                               4.20991      0.01261     4.23618      4.19279
alpha_1                               0.65273      0.00207     0.65634      0.64959
alpha_2                               0.36776      0.00053     0.36841      0.36675
alpha_3                               0.18368      0.00171     0.18655      0.18063
alpha_4                               0.21841      0.00090     0.22006      0.21683
alpha_5                               0.58997      0.00063     0.59128      0.58891
alpha_6                               0.28104      0.00026     0.28137      0.28058
alpha_7                               0.42588      0.00037     0.42635      0.42525
alpha_8                               0.46621      0.00512     0.47522      0.45795
alpha_9                               0.30614      0.00333     0.31188      0.30055
Alpha_loss                            -0.14410     0.13505     0.22686      -0.45371
Training/policy_loss                  276.08183    17.23353    320.00449    238.30042
Training/qf1_loss                     6947.44801   2570.71333  16302.94727  2709.80396
Training/qf2_loss                     1755.47810   500.23878   4283.50146   1044.05432
Training/pf_norm                      24.57274     10.21491    56.19981     8.69794
Training/qf1_norm                     7367.76731   3239.18063  16538.40820  2655.04321
Training/qf2_norm                     5683.78276   2580.29133  15812.99023  1831.75281
log_std/mean                          -0.93250     0.01028     -0.91223     -0.95398
log_std/std                           0.40913      0.00513     0.42134      0.39751
log_std/max                           0.24281      0.05380     0.31739      0.05371
log_std/min                           -2.59547     0.09954     -2.38770     -3.02679
log_probs/mean                        3.78315      0.11142     4.07071      3.53691
log_probs/std                         3.34808      0.12585     3.66008      2.99922
log_probs/max                         25.09426     3.53448     36.04814     19.01365
log_probs/min                         -6.44714     1.44437     -3.81574     -12.00803
mean/mean                             0.15197      0.02467     0.21567      0.10529
mean/std                              1.42120      0.01800     1.46842      1.37904
mean/max                              5.20936      0.94400     6.12972      3.71614
mean/min                              -10.02836    1.08626     -4.22452     -11.40525
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 1, 6, 3, 5, 9, 8, 0, 2, 7]
replay_buffer._size: [49950 49950 49950 49950 49950 49950 49950 49950 49950 49950]
2023-08-12 12:28:37,442 MainThread INFO: EPOCH:311
2023-08-12 12:28:37,442 MainThread INFO: Time Consumed:8.351088523864746s
2023-08-12 12:28:37,442 MainThread INFO: Total Frames:498000s
  3%|▎         | 312/10000 [47:16<23:26:59,  8.71s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1062.41440
Train_Epoch_Reward                    11119.77200
Running_Training_Average_Rewards      1093.52619
Explore_Time                          0.00881
Train___Time                          8.33713
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.61958
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.58200
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -53.89213
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.15470
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.42803
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -87.63826
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.38664
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11233.58197
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.31040
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.42621
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.58949      1.36231     9.95690      3.89705
alpha_0                               4.26175      0.01022     4.27534      4.23696
alpha_1                               0.64599      0.00210     0.64955      0.64278
alpha_2                               0.36522      0.00097     0.36673      0.36354
alpha_3                               0.18918      0.00144     0.19158      0.18661
alpha_4                               0.21516      0.00094     0.21680      0.21355
alpha_5                               0.59380      0.00073     0.59466      0.59140
alpha_6                               0.28114      0.00018     0.28136      0.28076
alpha_7                               0.42343      0.00144     0.42540      0.42074
alpha_8                               0.45085      0.00410     0.45781      0.44377
alpha_9                               0.29524      0.00300     0.30044      0.29022
Alpha_loss                            -0.29569     0.11806     0.02715      -0.60719
Training/policy_loss                  275.02690    17.86663    314.36603    229.91637
Training/qf1_loss                     7011.52567   2558.17741  13733.21094  3011.41235
Training/qf2_loss                     1727.48219   355.60796   2893.25513   980.95160
Training/pf_norm                      26.96342     13.32614    69.88426     6.69127
Training/qf1_norm                     7066.84035   2734.04062  16258.78711  2305.95483
Training/qf2_norm                     4776.30052   2100.65092  11926.96680  1624.49390
log_std/mean                          -0.92644     0.00747     -0.91084     -0.94208
log_std/std                           0.42305      0.00500     0.43337      0.40972
log_std/max                           0.24914      0.04353     0.31983      0.05820
log_std/min                           -2.66432     0.14314     -2.38769     -3.10025
log_probs/mean                        3.66330      0.11129     3.97213      3.31913
log_probs/std                         3.27256      0.11835     3.57770      2.98490
log_probs/max                         25.01808     4.03080     35.24300     17.02010
log_probs/min                         -6.42757     1.36710     -4.07683     -11.30814
mean/mean                             0.14657      0.02320     0.20490      0.08936
mean/std                              1.40101      0.02057     1.46310      1.35861
mean/max                              5.20221      0.93102     6.14606      3.42628
mean/min                              -9.57143     1.04394     -5.39352     -10.87594
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 9, 0, 5, 4, 7, 3, 8, 6, 2]
replay_buffer._size: [50100 50100 50100 50100 50100 50100 50100 50100 50100 50100]
2023-08-12 12:28:45,564 MainThread INFO: EPOCH:312
2023-08-12 12:28:45,564 MainThread INFO: Time Consumed:7.966686487197876s
2023-08-12 12:28:45,564 MainThread INFO: Total Frames:499500s
  3%|▎         | 313/10000 [47:24<22:58:25,  8.54s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1015.68214
Train_Epoch_Reward                    10483.30296
Running_Training_Average_Rewards      1080.70146
Explore_Time                          0.01121
Train___Time                          7.95045
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.08116
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.23343
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.22122
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.95200
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.09998
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.80180
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.11845
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10728.58581
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.44426
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.81212
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80015      1.38830     10.15220     4.21526
alpha_0                               4.27771      0.00525     4.29104      4.27113
alpha_1                               0.63938      0.00225     0.64275      0.63568
alpha_2                               0.36149      0.00118     0.36351      0.35948
alpha_3                               0.19368      0.00119     0.19580      0.19163
alpha_4                               0.21197      0.00095     0.21352      0.21045
alpha_5                               0.59328      0.00023     0.59410      0.59303
alpha_6                               0.28025      0.00032     0.28075      0.27959
alpha_7                               0.41724      0.00198     0.42068      0.41435
alpha_8                               0.43660      0.00387     0.44362      0.43018
alpha_9                               0.28510      0.00295     0.29012      0.28024
Alpha_loss                            -0.38421     0.11932     -0.11242     -0.68818
Training/policy_loss                  270.21272    19.20967    324.53516    224.78667
Training/qf1_loss                     6917.79070   2558.40790  15723.81934  3323.33911
Training/qf2_loss                     1780.61590   408.73348   3361.02856   1198.34961
Training/pf_norm                      28.25619     11.11504    60.53722     9.87731
Training/qf1_norm                     6978.22019   3058.87953  16503.44336  2405.78979
Training/qf2_norm                     5801.16627   2437.08630  12554.37500  2111.74023
log_std/mean                          -0.92965     0.00851     -0.91403     -0.95282
log_std/std                           0.42618      0.00546     0.44102      0.41293
log_std/max                           0.17230      0.03178     0.26285      0.11714
log_std/min                           -2.68034     0.14592     -2.36578     -3.16090
log_probs/mean                        3.59203      0.10537     3.96148      3.38001
log_probs/std                         3.20212      0.10900     3.43588      2.91845
log_probs/max                         23.77344     3.91650     34.98116     17.06978
log_probs/min                         -6.43551     1.36430     -4.13436     -13.28055
mean/mean                             0.15595      0.02470     0.20804      0.07802
mean/std                              1.38347      0.01762     1.42778      1.33574
mean/max                              5.31123      0.83719     6.09167      3.53851
mean/min                              -9.40941     0.84476     -5.18188     -10.65359
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 2, 0, 4, 5, 7, 3, 6, 9, 8]
replay_buffer._size: [50250 50250 50250 50250 50250 50250 50250 50250 50250 50250]
2023-08-12 12:28:54,866 MainThread INFO: EPOCH:313
2023-08-12 12:28:54,867 MainThread INFO: Time Consumed:9.13828444480896s
2023-08-12 12:28:54,867 MainThread INFO: Total Frames:501000s
  3%|▎         | 314/10000 [47:34<23:34:55,  8.76s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1097.02130
Train_Epoch_Reward                    9896.20457
Running_Training_Average_Rewards      1049.97598
Explore_Time                          0.01699
Train___Time                          9.11729
Eval____Time                          0.00337
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.94336
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.81954
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.10964
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.83118
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.33329
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.07899
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.46760
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11563.77635
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.10843
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.87133
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65548      1.25902     9.86356      4.30655
alpha_0                               4.30572      0.01002     4.32012      4.29159
alpha_1                               0.63250      0.00185     0.63562      0.62902
alpha_2                               0.35736      0.00118     0.35943      0.35538
alpha_3                               0.19763      0.00097     0.19918      0.19584
alpha_4                               0.20922      0.00072     0.21042      0.20796
alpha_5                               0.59077      0.00105     0.59312      0.58874
alpha_6                               0.27862      0.00050     0.27957      0.27785
alpha_7                               0.41108      0.00165     0.41430      0.40849
alpha_8                               0.42332      0.00369     0.43005      0.41753
alpha_9                               0.27592      0.00251     0.28016      0.27156
Alpha_loss                            -0.41089     0.08790     -0.20827     -0.61318
Training/policy_loss                  270.15945    18.57478    309.26260    220.40674
Training/qf1_loss                     6891.03665   2426.36356  15890.43945  2575.93042
Training/qf2_loss                     1687.98143   405.83532   3016.01831   1007.43817
Training/pf_norm                      24.14918     9.13178     49.53176     8.27097
Training/qf1_norm                     7177.80714   3156.52429  14125.23828  2152.21606
Training/qf2_norm                     5229.98113   2156.23278  12239.23145  2074.64233
log_std/mean                          -0.94015     0.01009     -0.92177     -0.96521
log_std/std                           0.42930      0.00385     0.43727      0.41990
log_std/max                           0.16805      0.03232     0.21742      0.08486
log_std/min                           -2.66575     0.15783     -2.31918     -3.12780
log_probs/mean                        3.58519      0.09531     3.79544      3.34405
log_probs/std                         3.15973      0.11972     3.57592      2.90761
log_probs/max                         24.04085     3.85760     34.08308     17.24998
log_probs/min                         -6.48379     1.33179     -4.06464     -11.17941
mean/mean                             0.12963      0.02759     0.19534      0.07064
mean/std                              1.37920      0.01836     1.44910      1.33024
mean/max                              5.19621      0.88729     6.10097      3.18890
mean/min                              -9.18375     0.90820     -5.02116     -10.51851
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 9, 5, 8, 2, 7, 6, 1, 3, 4]
replay_buffer._size: [50400 50400 50400 50400 50400 50400 50400 50400 50400 50400]
2023-08-12 12:29:04,260 MainThread INFO: EPOCH:314
2023-08-12 12:29:04,260 MainThread INFO: Time Consumed:9.19242000579834s
2023-08-12 12:29:04,260 MainThread INFO: Total Frames:502500s
  3%|▎         | 315/10000 [47:43<24:05:13,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1093.97232
Train_Epoch_Reward                    11141.30876
Running_Training_Average_Rewards      1050.69388
Explore_Time                          0.00973
Train___Time                          9.17809
Eval____Time                          0.00394
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.92435
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.33696
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.16182
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.56232
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.38918
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.04919
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.29335
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11512.25546
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.64821
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.16692
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.52338      1.19092     9.67026      4.02214
alpha_0                               4.32735      0.00378     4.33364      4.31624
alpha_1                               0.62539      0.00218     0.62895      0.62150
alpha_2                               0.35327      0.00130     0.35534      0.35106
alpha_3                               0.20065      0.00081     0.20201      0.19922
alpha_4                               0.20651      0.00085     0.20793      0.20495
alpha_5                               0.58448      0.00329     0.58867      0.57840
alpha_6                               0.27652      0.00084     0.27783      0.27509
alpha_7                               0.40639      0.00114     0.40842      0.40505
alpha_8                               0.41279      0.00275     0.41744      0.40819
alpha_9                               0.26766      0.00221     0.27148      0.26395
Alpha_loss                            -0.46187     0.11159     -0.13890     -0.77977
Training/policy_loss                  270.02425    17.42441    313.13632    225.33690
Training/qf1_loss                     6585.13032   2783.26017  14697.27539  2236.97363
Training/qf2_loss                     1743.76223   321.37542   2905.42529   1116.32190
Training/pf_norm                      28.61809     12.83875    66.27725     9.43353
Training/qf1_norm                     6522.96650   3073.33106  15532.95605  2711.70923
Training/qf2_norm                     4506.47525   2099.72137  12236.58301  1598.49927
log_std/mean                          -0.94634     0.00707     -0.92636     -0.96320
log_std/std                           0.43677      0.00556     0.45000      0.42007
log_std/max                           0.19359      0.03484     0.23812      0.09805
log_std/min                           -2.65056     0.14307     -2.36341     -3.12792
log_probs/mean                        3.55020      0.11659     3.80894      3.24386
log_probs/std                         3.07584      0.10574     3.33744      2.84607
log_probs/max                         23.16150     3.96193     33.76450     16.83226
log_probs/min                         -6.08037     1.11974     -3.78836     -8.78160
mean/mean                             0.13419      0.02223     0.19150      0.07562
mean/std                              1.36329      0.01745     1.41931      1.30916
mean/max                              5.00427      0.88670     6.11174      3.32239
mean/min                              -8.80254     0.97135     -4.57064     -10.20540
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 6, 5, 7, 4, 0, 8, 1, 3]
replay_buffer._size: [50550 50550 50550 50550 50550 50550 50550 50550 50550 50550]
2023-08-12 12:29:12,768 MainThread INFO: EPOCH:315
2023-08-12 12:29:12,769 MainThread INFO: Time Consumed:8.339734554290771s
2023-08-12 12:29:12,769 MainThread INFO: Total Frames:504000s
  3%|▎         | 316/10000 [47:51<23:44:06,  8.82s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1113.60884
Train_Epoch_Reward                    9882.56469
Running_Training_Average_Rewards      1030.66927
Explore_Time                          0.00987
Train___Time                          8.32467
Eval____Time                          0.00461
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.66058
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.09785
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -39.70978
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.54230
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.43270
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.94964
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.21151
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11722.34876
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.62293
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.03307
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.71523      1.38900     11.10974     3.54734
alpha_0                               4.33568      0.00459     4.34095      4.32609
alpha_1                               0.61868      0.00182     0.62144      0.61508
alpha_2                               0.34891      0.00126     0.35102      0.34682
alpha_3                               0.20321      0.00068     0.20426      0.20203
alpha_4                               0.20320      0.00099     0.20491      0.20144
alpha_5                               0.56906      0.00552     0.57826      0.56019
alpha_6                               0.27374      0.00081     0.27507      0.27228
alpha_7                               0.40372      0.00053     0.40501      0.40329
alpha_8                               0.40326      0.00276     0.40809      0.39856
alpha_9                               0.26042      0.00200     0.26388      0.25695
Alpha_loss                            -0.49818     0.10975     -0.23245     -0.76609
Training/policy_loss                  263.96928    20.54975    318.45712    211.85664
Training/qf1_loss                     6844.53836   2753.63601  15360.39355  2445.51855
Training/qf2_loss                     1783.63217   411.55560   3419.85010   1033.90759
Training/pf_norm                      25.80496     11.88068    65.65450     7.43720
Training/qf1_norm                     6907.61763   2978.65298  15816.46973  2426.38892
Training/qf2_norm                     5254.19174   2586.42398  16409.31836  2153.20386
log_std/mean                          -0.94127     0.00684     -0.92675     -0.95660
log_std/std                           0.44234      0.00416     0.45501      0.43300
log_std/max                           0.21124      0.02852     0.25330      0.11192
log_std/min                           -2.65149     0.14937     -2.38765     -3.13761
log_probs/mean                        3.52694      0.08603     3.75655      3.27994
log_probs/std                         3.07636      0.09339     3.33443      2.86204
log_probs/max                         23.40294     3.72574     34.03530     15.68682
log_probs/min                         -6.35233     1.19739     -4.46561     -11.03274
mean/mean                             0.12024      0.01951     0.16022      0.06506
mean/std                              1.36222      0.01558     1.40657      1.33059
mean/max                              5.16480      0.80258     5.95606      3.31011
mean/min                              -8.64644     1.11043     -4.39441     -10.09601
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 4, 0, 2, 7, 6, 5, 3, 1]
replay_buffer._size: [50706 50708 50708 50708 50708 50708 50706 50708 50704 50707]
2023-08-12 12:29:22,215 MainThread INFO: EPOCH:316
2023-08-12 12:29:22,216 MainThread INFO: Time Consumed:9.258531093597412s
2023-08-12 12:29:22,216 MainThread INFO: Total Frames:505500s
  3%|▎         | 317/10000 [48:01<24:14:23,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1040.00256
Train_Epoch_Reward                    11059.78635
Running_Training_Average_Rewards      1069.45533
Explore_Time                          0.14810
Train___Time                          9.10583
Eval____Time                          0.00393
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.74286
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.23142
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -40.27549
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.70139
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.29104
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.81297
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.35449
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10995.61037
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.96603
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.20907
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.78368      1.35954     10.24825     3.74971
alpha_0                               4.31671      0.00702     4.33016      4.29927
alpha_1                               0.61155      0.00203     0.61500      0.60824
alpha_2                               0.34559      0.00079     0.34680      0.34421
alpha_3                               0.20498      0.00042     0.20565      0.20428
alpha_4                               0.19930      0.00125     0.20140      0.19698
alpha_5                               0.55169      0.00559     0.56005      0.54184
alpha_6                               0.27056      0.00103     0.27225      0.26883
alpha_7                               0.40228      0.00092     0.40342      0.40111
alpha_8                               0.39356      0.00279     0.39847      0.38912
alpha_9                               0.25355      0.00183     0.25687      0.25052
Alpha_loss                            -0.53159     0.10146     -0.26653     -0.79356
Training/policy_loss                  261.74903    19.29119    298.99689    214.82271
Training/qf1_loss                     6749.16241   2691.34446  19722.45117  2283.91895
Training/qf2_loss                     1697.99770   384.48092   3107.37769   1062.55872
Training/pf_norm                      25.53961     9.41612     53.38084     7.66718
Training/qf1_norm                     7129.88031   3658.03641  26270.53711  2659.07690
Training/qf2_norm                     5515.04361   2147.58289  11628.37207  2112.05176
log_std/mean                          -0.93005     0.01239     -0.90342     -0.95290
log_std/std                           0.43627      0.00369     0.44538      0.42620
log_std/max                           0.22425      0.03251     0.28080      0.12296
log_std/min                           -2.59609     0.16458     -2.34048     -3.08973
log_probs/mean                        3.49908      0.09450     3.78186      3.26983
log_probs/std                         3.08001      0.09287     3.30977      2.90143
log_probs/max                         22.69578     3.94974     33.22262     15.63738
log_probs/min                         -6.61304     1.30097     -4.23862     -9.81001
mean/mean                             0.13200      0.02726     0.19944      0.06832
mean/std                              1.35788      0.01387     1.40380      1.32568
mean/max                              5.12805      0.84422     5.94381      3.29281
mean/min                              -8.16131     0.98369     -4.83392     -9.67444
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 7, 8, 6, 2, 0, 5, 3, 4, 9]
replay_buffer._size: [50850 50850 50850 50850 50850 50850 50850 50850 50850 50850]
2023-08-12 12:29:31,445 MainThread INFO: EPOCH:317
2023-08-12 12:29:31,445 MainThread INFO: Time Consumed:9.029595136642456s
2023-08-12 12:29:31,445 MainThread INFO: Total Frames:507000s
  3%|▎         | 318/10000 [48:10<24:23:57,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1074.40409
Train_Epoch_Reward                    10627.35337
Running_Training_Average_Rewards      1052.32348
Explore_Time                          0.00389
Train___Time                          9.02188
Eval____Time                          0.00329
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.81636
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.93190
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.67340
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.64758
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.70093
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.90138
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.92492
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11339.20779
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.53528
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.03515
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.45504      1.33832     9.91241      2.60590
alpha_0                               4.28314      0.00735     4.29856      4.27199
alpha_1                               0.60257      0.00321     0.60814      0.59770
alpha_2                               0.34275      0.00096     0.34419      0.34088
alpha_3                               0.20636      0.00044     0.20706      0.20566
alpha_4                               0.19456      0.00131     0.19693      0.19241
alpha_5                               0.53267      0.00511     0.54163      0.52412
alpha_6                               0.26645      0.00149     0.26879      0.26381
alpha_7                               0.40060      0.00041     0.40159      0.40011
alpha_8                               0.38519      0.00210     0.38904      0.38177
alpha_9                               0.24787      0.00137     0.25046      0.24567
Alpha_loss                            -0.56019     0.10296     -0.30668     -0.76950
Training/policy_loss                  262.91082    18.09260    301.79971    214.77901
Training/qf1_loss                     5817.23764   1964.32343  12166.54102  2362.48096
Training/qf2_loss                     1699.82551   393.53315   3255.04565   1078.64001
Training/pf_norm                      21.53010     10.54778    58.90140     5.59503
Training/qf1_norm                     6584.86318   2564.93107  14407.33398  2235.05151
Training/qf2_norm                     5351.90140   2684.87782  14067.82812  1474.65601
log_std/mean                          -0.93722     0.01417     -0.91438     -0.96818
log_std/std                           0.44911      0.00720     0.46401      0.43658
log_std/max                           0.26573      0.03373     0.32596      0.16328
log_std/min                           -2.65331     0.17951     -2.33542     -3.17451
log_probs/mean                        3.48308      0.09700     3.75295      3.31462
log_probs/std                         3.03878      0.10191     3.37063      2.82837
log_probs/max                         21.80131     3.51908     31.51786     15.42942
log_probs/min                         -6.62792     1.31022     -4.49592     -11.47587
mean/mean                             0.16818      0.02330     0.21962      0.12133
mean/std                              1.34710      0.01509     1.39135      1.31579
mean/max                              5.21156      0.85341     6.14875      3.45749
mean/min                              -7.73644     1.15548     -4.15792     -9.25741
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 1, 2, 8, 4, 5, 9, 0, 7]
replay_buffer._size: [51000 51000 51000 51000 51000 51000 51000 51000 51000 51000]
2023-08-12 12:29:40,829 MainThread INFO: EPOCH:318
2023-08-12 12:29:40,829 MainThread INFO: Time Consumed:9.199009656906128s
2023-08-12 12:29:40,830 MainThread INFO: Total Frames:508500s
  3%|▎         | 319/10000 [48:20<24:39:57,  9.17s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1097.45313
Train_Epoch_Reward                    9823.13077
Running_Training_Average_Rewards      1050.34235
Explore_Time                          0.00520
Train___Time                          9.18957
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.37863
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.42268
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.90031
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.21632
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.11810
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.01670
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.88929
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11561.27694
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.70284
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.10076
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80933      1.51343     11.07914     3.95345
alpha_0                               4.26483      0.00444     4.27700      4.25208
alpha_1                               0.59280      0.00270     0.59762      0.58857
alpha_2                               0.33853      0.00134     0.34084      0.33609
alpha_3                               0.20740      0.00021     0.20770      0.20707
alpha_4                               0.19035      0.00114     0.19236      0.18848
alpha_5                               0.51625      0.00403     0.52396      0.50950
alpha_6                               0.26104      0.00155     0.26375      0.25826
alpha_7                               0.40203      0.00030     0.40258      0.40161
alpha_8                               0.37828      0.00188     0.38170      0.37517
alpha_9                               0.24351      0.00125     0.24563      0.24145
Alpha_loss                            -0.58923     0.12145     -0.27636     -0.84743
Training/policy_loss                  259.06601    19.53124    305.26575    219.05630
Training/qf1_loss                     6250.87272   2314.76368  11739.76074  1993.92664
Training/qf2_loss                     1795.31894   411.16980   3266.98022   1156.53088
Training/pf_norm                      22.01478     10.70167    71.41017     8.02280
Training/qf1_norm                     7097.21625   2992.76958  16399.14844  1851.71484
Training/qf2_norm                     4919.32301   2102.61831  11755.30566  1597.27014
log_std/mean                          -0.93584     0.00862     -0.91423     -0.95936
log_std/std                           0.45261      0.00492     0.46270      0.43993
log_std/max                           0.27522      0.03340     0.31865      0.18701
log_std/min                           -2.64793     0.18007     -2.33679     -3.24620
log_probs/mean                        3.46677      0.11226     3.73298      3.18390
log_probs/std                         3.01835      0.08365     3.23346      2.86065
log_probs/max                         20.52279     3.25287     30.29803     14.93228
log_probs/min                         -6.74696     1.43468     -3.78941     -11.20594
mean/mean                             0.20718      0.03321     0.27751      0.14642
mean/std                              1.33808      0.01429     1.38277      1.30578
mean/max                              5.15774      0.84604     6.19196      3.24359
mean/min                              -7.25837     1.08072     -3.61315     -8.76544
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 2, 9, 5, 6, 0, 4, 3, 8, 7]
replay_buffer._size: [51156 51158 51155 51158 51158 51158 51158 51158 51156 51157]
2023-08-12 12:29:50,242 MainThread INFO: EPOCH:319
2023-08-12 12:29:50,243 MainThread INFO: Time Consumed:9.207624912261963s
2023-08-12 12:29:50,243 MainThread INFO: Total Frames:510000s
  3%|▎         | 320/10000 [48:29<24:50:30,  9.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1063.17224
Train_Epoch_Reward                    11295.23134
Running_Training_Average_Rewards      1058.19052
Explore_Time                          0.15819
Train___Time                          9.04522
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.99955
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.87415
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.57018
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.12948
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.65646
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.99443
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.09896
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11194.58917
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.53279
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.01076
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68185      1.49058     10.98406     3.87590
alpha_0                               4.23486      0.00723     4.25089      4.22048
alpha_1                               0.58430      0.00215     0.58848      0.58100
alpha_2                               0.33290      0.00179     0.33602      0.32981
alpha_3                               0.20767      0.00006     0.20774      0.20753
alpha_4                               0.18630      0.00131     0.18844      0.18389
alpha_5                               0.50086      0.00477     0.50934      0.49317
alpha_6                               0.25518      0.00173     0.25820      0.25222
alpha_7                               0.40108      0.00087     0.40258      0.39995
alpha_8                               0.37065      0.00269     0.37509      0.36587
alpha_9                               0.23924      0.00125     0.24141      0.23708
Alpha_loss                            -0.73624     0.10459     -0.46136     -0.97578
Training/policy_loss                  258.42718    19.60962    295.36734    186.10243
Training/qf1_loss                     6361.91123   2694.02683  13839.69434  1930.83752
Training/qf2_loss                     1730.21465   354.14885   3670.86133   1197.85925
Training/pf_norm                      21.99706     8.50508     53.95241     6.43336
Training/qf1_norm                     6844.29246   3138.51192  18228.91797  1899.07751
Training/qf2_norm                     5607.15962   3019.45367  19820.47266  1816.98560
log_std/mean                          -0.92609     0.00902     -0.90609     -0.94259
log_std/std                           0.45565      0.00470     0.46657      0.44295
log_std/max                           0.24557      0.02946     0.31939      0.18125
log_std/min                           -2.61675     0.18824     -2.32948     -3.29670
log_probs/mean                        3.36653      0.08826     3.62689      3.17401
log_probs/std                         3.05225      0.08215     3.28515      2.83102
log_probs/max                         20.14028     2.74816     29.74028     13.37558
log_probs/min                         -6.55353     1.44144     -4.11766     -12.61674
mean/mean                             0.17658      0.02394     0.23060      0.09916
mean/std                              1.33170      0.01198     1.36540      1.30685
mean/max                              5.24058      0.84091     6.12776      3.16225
mean/min                              -7.12742     0.95711     -3.84675     -8.58203
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 3, 1, 7, 4, 9, 0, 6, 8, 2]
replay_buffer._size: [51308 51305 51308 51308 51306 51305 51307 51308 51307 51305]
2023-08-12 12:29:59,576 MainThread INFO: EPOCH:320
2023-08-12 12:29:59,576 MainThread INFO: Time Consumed:9.159640789031982s
2023-08-12 12:29:59,576 MainThread INFO: Total Frames:511500s
  3%|▎         | 321/10000 [48:38<24:54:44,  9.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1087.42659
Train_Epoch_Reward                    9553.44563
Running_Training_Average_Rewards      1022.39359
Explore_Time                          0.14518
Train___Time                          9.01004
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.36098
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.69027
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.92118
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.58774
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.95080
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.28657
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.05046
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11388.46491
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.39838
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.95259
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.72562      1.22953     9.69776      3.95088
alpha_0                               4.19901      0.01192     4.21993      4.17694
alpha_1                               0.57554      0.00294     0.58091      0.57041
alpha_2                               0.32641      0.00194     0.32974      0.32297
alpha_3                               0.20751      0.00006     0.20765      0.20740
alpha_4                               0.18142      0.00132     0.18384      0.17937
alpha_5                               0.48646      0.00376     0.49303      0.48038
alpha_6                               0.24941      0.00160     0.25216      0.24659
alpha_7                               0.39850      0.00100     0.39992      0.39731
alpha_8                               0.36189      0.00215     0.36577      0.35827
alpha_9                               0.23504      0.00110     0.23704      0.23317
Alpha_loss                            -0.69213     0.11724     -0.42430     -1.03112
Training/policy_loss                  253.62877    19.66374    300.94711    205.77290
Training/qf1_loss                     6641.44839   2427.09874  15584.14062  2676.67358
Training/qf2_loss                     1715.76108   384.73980   3104.89941   1135.21680
Training/pf_norm                      22.14846     9.12572     53.77323     8.15632
Training/qf1_norm                     6722.01847   2919.21759  15583.94336  1807.13879
Training/qf2_norm                     5428.03890   2363.46116  12447.54492  1705.06970
log_std/mean                          -0.91607     0.00928     -0.89500     -0.93612
log_std/std                           0.45174      0.00496     0.46411      0.43906
log_std/max                           0.19809      0.02881     0.24053      0.12061
log_std/min                           -2.56096     0.19630     -2.35008     -3.20820
log_probs/mean                        3.38998      0.08849     3.68735      3.17608
log_probs/std                         3.03168      0.08136     3.29769      2.84687
log_probs/max                         20.65548     3.45725     30.42297     13.41557
log_probs/min                         -6.60489     1.34456     -4.13685     -10.86182
mean/mean                             0.18308      0.03136     0.26054      0.07908
mean/std                              1.33770      0.01146     1.36995      1.31440
mean/max                              5.22141      0.84284     6.10647      3.32588
mean/min                              -6.58841     1.07371     -3.53630     -8.30804
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 6, 7, 4, 5, 3, 9, 1, 0, 8]
replay_buffer._size: [51450 51450 51450 51450 51450 51450 51450 51450 51450 51450]
2023-08-12 12:30:07,979 MainThread INFO: EPOCH:321
2023-08-12 12:30:07,979 MainThread INFO: Time Consumed:8.238662004470825s
2023-08-12 12:30:07,979 MainThread INFO: Total Frames:513000s
  3%|▎         | 322/10000 [48:47<24:13:45,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1052.32226
Train_Epoch_Reward                    11328.67913
Running_Training_Average_Rewards      1072.57854
Explore_Time                          0.00414
Train___Time                          8.22973
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.30897
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.34411
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -40.44673
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.80281
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.23168
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.09043
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.93759
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11063.16978
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.05938
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.72542
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.62769      1.32730     9.87658      3.85388
alpha_0                               4.16679      0.00380     4.17637      4.15757
alpha_1                               0.56541      0.00265     0.57031      0.56078
alpha_2                               0.31969      0.00179     0.32290      0.31660
alpha_3                               0.20799      0.00024     0.20836      0.20766
alpha_4                               0.17722      0.00118     0.17933      0.17528
alpha_5                               0.47677      0.00187     0.48028      0.47305
alpha_6                               0.24374      0.00164     0.24653      0.24077
alpha_7                               0.39765      0.00042     0.39824      0.39680
alpha_8                               0.35548      0.00164     0.35821      0.35255
alpha_9                               0.23106      0.00113     0.23313      0.22929
Alpha_loss                            -0.65107     0.13582     -0.24969     -0.97272
Training/policy_loss                  252.99455    18.23493    300.40826    202.86761
Training/qf1_loss                     5866.18232   2369.73274  12270.86426  2349.06006
Training/qf2_loss                     1741.68799   450.92401   3754.58667   925.83850
Training/pf_norm                      21.83452     9.58893     54.64272     7.00418
Training/qf1_norm                     6851.49586   3685.55554  20653.66992  1965.88818
Training/qf2_norm                     5574.05591   2539.66387  15038.23633  1604.00598
log_std/mean                          -0.92869     0.01286     -0.89749     -0.94527
log_std/std                           0.45182      0.00417     0.46283      0.44239
log_std/max                           0.13485      0.04674     0.26130      0.03202
log_std/min                           -2.64740     0.21883     -2.37237     -3.28263
log_probs/mean                        3.46358      0.11945     3.80725      3.20299
log_probs/std                         3.04012      0.10274     3.27172      2.75249
log_probs/max                         20.67543     3.43340     32.09293     13.07804
log_probs/min                         -6.63398     1.19611     -4.51652     -10.10586
mean/mean                             0.19246      0.03167     0.26085      0.12546
mean/std                              1.34149      0.01446     1.37491      1.31229
mean/max                              5.26475      0.75447     6.11284      3.60897
mean/min                              -6.37660     1.04377     -3.91647     -8.19103
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 4, 8, 7, 9, 6, 1, 0, 3, 5]
replay_buffer._size: [51600 51600 51600 51600 51600 51600 51600 51600 51600 51600]
2023-08-12 12:30:16,404 MainThread INFO: EPOCH:322
2023-08-12 12:30:16,405 MainThread INFO: Time Consumed:8.225211143493652s
2023-08-12 12:30:16,405 MainThread INFO: Total Frames:514500s
  3%|▎         | 323/10000 [48:55<23:44:51,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1072.38618
Train_Epoch_Reward                    11002.43453
Running_Training_Average_Rewards      1062.81864
Explore_Time                          0.00477
Train___Time                          8.21619
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.47074
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.65159
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.27926
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.12790
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.30377
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.58977
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.04080
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11255.57593
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.41904
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.83122
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65880      1.33929     10.09247     3.51027
alpha_0                               4.15434      0.00313     4.15927      4.14792
alpha_1                               0.55519      0.00296     0.56067      0.55071
alpha_2                               0.31322      0.00190     0.31653      0.30998
alpha_3                               0.20859      0.00014     0.20885      0.20837
alpha_4                               0.17368      0.00089     0.17524      0.17215
alpha_5                               0.46921      0.00181     0.47295      0.46630
alpha_6                               0.23747      0.00194     0.24070      0.23420
alpha_7                               0.39841      0.00155     0.40147      0.39670
alpha_8                               0.34977      0.00144     0.35248      0.34766
alpha_9                               0.22830      0.00040     0.22925      0.22776
Alpha_loss                            -0.57441     0.11059     -0.20960     -0.87056
Training/policy_loss                  248.76335    19.04684    290.27768    204.29785
Training/qf1_loss                     5945.99294   2237.86569  13042.35645  2318.54614
Training/qf2_loss                     1757.15471   400.33433   2941.87329   1058.46912
Training/pf_norm                      21.87680     9.60301     51.69888     8.05757
Training/qf1_norm                     6511.17935   2775.45547  15818.81250  2303.16650
Training/qf2_norm                     5646.93147   2588.87506  16531.91602  1742.31934
log_std/mean                          -0.95023     0.01202     -0.92479     -0.97421
log_std/std                           0.45348      0.00408     0.46371      0.44521
log_std/max                           0.10659      0.05884     0.22363      -0.02103
log_std/min                           -2.68048     0.24736     -2.34752     -3.41040
log_probs/mean                        3.53784      0.10635     3.82452      3.28291
log_probs/std                         3.01225      0.08434     3.26011      2.78620
log_probs/max                         20.36896     3.92816     31.96791     13.37490
log_probs/min                         -6.48568     1.50288     -4.02329     -13.02597
mean/mean                             0.21622      0.02019     0.25390      0.15780
mean/std                              1.33698      0.01407     1.37157      1.29989
mean/max                              5.23351      0.81899     6.25895      3.44486
mean/min                              -6.02666     1.01622     -3.76203     -7.76533
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 3, 6, 0, 2, 8, 1, 9, 7]
replay_buffer._size: [51750 51750 51750 51750 51750 51750 51750 51750 51750 51750]
2023-08-12 12:30:25,917 MainThread INFO: EPOCH:323
2023-08-12 12:30:25,917 MainThread INFO: Time Consumed:9.344178438186646s
2023-08-12 12:30:25,918 MainThread INFO: Total Frames:516000s
  3%|▎         | 324/10000 [49:05<24:17:06,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1069.39405
Train_Epoch_Reward                    10483.96110
Running_Training_Average_Rewards      1093.83583
Explore_Time                          0.00977
Train___Time                          9.32902
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.76442
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.12574
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.37147
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.71940
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.92770
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.51705
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.91869
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11204.75030
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.35039
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.11491
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.63328      1.47170     11.30888     3.75592
alpha_0                               4.14977      0.00913     4.15923      4.13197
alpha_1                               0.54612      0.00288     0.55062      0.54092
alpha_2                               0.30639      0.00205     0.30991      0.30303
alpha_3                               0.20849      0.00032     0.20885      0.20776
alpha_4                               0.17063      0.00082     0.17211      0.16931
alpha_5                               0.46216      0.00255     0.46621      0.45721
alpha_6                               0.23113      0.00183     0.23414      0.22783
alpha_7                               0.39983      0.00169     0.40165      0.39614
alpha_8                               0.34465      0.00180     0.34761      0.34144
alpha_9                               0.22576      0.00133     0.22774      0.22327
Alpha_loss                            -0.73901     0.12703     -0.45262     -1.00664
Training/policy_loss                  248.30911    17.71864    292.71893    206.16238
Training/qf1_loss                     5979.72586   2860.50507  15521.03418  1744.95044
Training/qf2_loss                     1783.41202   463.24656   3731.46729   1068.82764
Training/pf_norm                      22.53718     9.60847     55.28324     7.28375
Training/qf1_norm                     6779.16250   3377.15302  21693.69922  2410.47632
Training/qf2_norm                     5680.80706   2923.14867  15288.52734  1674.23840
log_std/mean                          -0.93464     0.00782     -0.91753     -0.95394
log_std/std                           0.44979      0.00488     0.46260      0.43410
log_std/max                           0.10764      0.04612     0.21623      -0.00072
log_std/min                           -2.66455     0.23196     -2.43266     -3.33992
log_probs/mean                        3.39317      0.10509     3.63340      3.15340
log_probs/std                         3.02054      0.08288     3.26996      2.79335
log_probs/max                         20.35856     3.77098     31.45878     13.72680
log_probs/min                         -6.82395     1.41825     -4.40837     -12.27719
mean/mean                             0.19975      0.01829     0.24102      0.15281
mean/std                              1.32752      0.01356     1.36543      1.29180
mean/max                              5.32322      0.80221     6.29679      3.98180
mean/min                              -5.97129     1.01242     -3.59014     -7.74328
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 4, 0, 1, 6, 7, 8, 5, 2]
replay_buffer._size: [51900 51900 51900 51900 51900 51900 51900 51900 51900 51900]
2023-08-12 12:30:35,223 MainThread INFO: EPOCH:324
2023-08-12 12:30:35,223 MainThread INFO: Time Consumed:9.149740934371948s
2023-08-12 12:30:35,223 MainThread INFO: Total Frames:517500s
  3%|▎         | 325/10000 [49:14<24:32:36,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1078.50833
Train_Epoch_Reward                    10107.38832
Running_Training_Average_Rewards      1053.12613
Explore_Time                          0.01379
Train___Time                          9.13169
Eval____Time                          0.00359
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.21786
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.12404
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.58820
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.97140
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.01207
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.05969
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.69564
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11286.73315
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.94687
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.03411
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.81384      1.33459     10.61721     3.85970
alpha_0                               4.11043      0.01243     4.13164      4.09103
alpha_1                               0.53646      0.00255     0.54085      0.53240
alpha_2                               0.29970      0.00195     0.30297      0.29631
alpha_3                               0.20673      0.00060     0.20774      0.20577
alpha_4                               0.16833      0.00051     0.16929      0.16756
alpha_5                               0.45359      0.00239     0.45712      0.44913
alpha_6                               0.22431      0.00203     0.22775      0.22077
alpha_7                               0.39229      0.00246     0.39605      0.38782
alpha_8                               0.33715      0.00252     0.34138      0.33273
alpha_9                               0.22093      0.00129     0.22322      0.21875
Alpha_loss                            -0.74324     0.11672     -0.38730     -1.02712
Training/policy_loss                  240.44608    18.25206    285.22104    186.30173
Training/qf1_loss                     6250.47394   2662.10458  15937.91309  2603.77759
Training/qf2_loss                     1754.85049   412.04392   3261.71387   1029.94409
Training/pf_norm                      23.19735     9.70650     53.66886     8.45007
Training/qf1_norm                     6924.71913   3173.42282  18517.22266  2739.61157
Training/qf2_norm                     5103.28014   2177.98554  13859.23047  1749.96912
log_std/mean                          -0.94578     0.00881     -0.92599     -0.96524
log_std/std                           0.45211      0.00359     0.46117      0.44362
log_std/max                           0.08748      0.04462     0.19997      -0.01196
log_std/min                           -2.66314     0.20593     -2.46366     -3.50356
log_probs/mean                        3.38709      0.08785     3.66319      3.12555
log_probs/std                         3.00350      0.09103     3.21451      2.80219
log_probs/max                         20.28192     3.12531     31.97717     14.17120
log_probs/min                         -6.42226     1.25655     -4.23004     -10.23611
mean/mean                             0.20940      0.02110     0.26679      0.16682
mean/std                              1.32060      0.01325     1.35709      1.28467
mean/max                              5.51417      0.87304     6.34165      3.75490
mean/min                              -5.95623     1.09168     -3.66745     -7.73983
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 5, 7, 2, 9, 1, 4, 6, 3, 8]
replay_buffer._size: [52050 52050 52050 52050 52050 52050 52050 52050 52050 52050]
2023-08-12 12:30:43,687 MainThread INFO: EPOCH:325
2023-08-12 12:30:43,688 MainThread INFO: Time Consumed:8.299758195877075s
2023-08-12 12:30:43,688 MainThread INFO: Total Frames:519000s
  3%|▎         | 326/10000 [49:22<24:00:25,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1067.35898
Train_Epoch_Reward                    10908.21788
Running_Training_Average_Rewards      1049.98558
Explore_Time                          0.00662
Train___Time                          8.28853
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.51262
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.41686
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.65757
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.38905
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.73773
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.67225
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.94384
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11195.38763
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.33770
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.13022
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.75084      1.56266     11.28424     3.57967
alpha_0                               4.08211      0.00464     4.09098      4.07760
alpha_1                               0.52916      0.00199     0.53236      0.52562
alpha_2                               0.29286      0.00183     0.29624      0.29001
alpha_3                               0.20431      0.00085     0.20575      0.20296
alpha_4                               0.16647      0.00061     0.16755      0.16562
alpha_5                               0.44511      0.00232     0.44905      0.44170
alpha_6                               0.21742      0.00191     0.22070      0.21423
alpha_7                               0.38146      0.00415     0.38774      0.37423
alpha_8                               0.32783      0.00282     0.33263      0.32301
alpha_9                               0.21583      0.00187     0.21871      0.21255
Alpha_loss                            -0.83876     0.12800     -0.53644     -1.15733
Training/policy_loss                  240.21594    18.64724    274.80371    181.82249
Training/qf1_loss                     6200.67867   2627.74314  16357.74707  2000.08557
Training/qf2_loss                     1771.12360   479.79777   3872.06250   1111.54895
Training/pf_norm                      23.57738     9.53926     65.67896     10.52326
Training/qf1_norm                     6709.36869   3301.88430  19704.50195  2011.61853
Training/qf2_norm                     6174.97143   2790.36485  13402.00586  1885.11475
log_std/mean                          -0.94088     0.01113     -0.91671     -0.96819
log_std/std                           0.44934      0.00417     0.45808      0.43878
log_std/max                           0.11726      0.05486     0.23734      0.01415
log_std/min                           -2.73619     0.22623     -2.44126     -3.48944
log_probs/mean                        3.35571      0.10232     3.61783      3.11508
log_probs/std                         2.98930      0.08980     3.22478      2.77277
log_probs/max                         20.59118     3.46591     31.87171     13.91911
log_probs/min                         -6.76788     1.43992     -4.30904     -11.73627
mean/mean                             0.19321      0.04223     0.28207      0.10017
mean/std                              1.31953      0.01367     1.35047      1.29030
mean/max                              5.33131      0.91493     6.24499      3.23162
mean/min                              -5.99565     0.98298     -3.61044     -7.75757
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 1, 4, 7, 6, 9, 3, 5, 8]
replay_buffer._size: [52200 52200 52200 52200 52200 52200 52200 52200 52200 52200]
2023-08-12 12:30:52,353 MainThread INFO: EPOCH:326
2023-08-12 12:30:52,354 MainThread INFO: Time Consumed:8.495821952819824s
2023-08-12 12:30:52,354 MainThread INFO: Total Frames:520500s
  3%|▎         | 327/10000 [49:31<23:45:41,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1050.54449
Train_Epoch_Reward                    10412.00383
Running_Training_Average_Rewards      1047.58700
Explore_Time                          0.01625
Train___Time                          8.47496
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.40038
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.82889
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.16430
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.81664
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.59270
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.25874
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.11882
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11032.10464
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.78281
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.69651
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.72233      1.52540     10.43558     3.94466
alpha_0                               4.05749      0.01097     4.07856      4.03713
alpha_1                               0.52163      0.00247     0.52555      0.51777
alpha_2                               0.28666      0.00211     0.28996      0.28289
alpha_3                               0.20204      0.00054     0.20294      0.20104
alpha_4                               0.16507      0.00039     0.16561      0.16437
alpha_5                               0.43918      0.00120     0.44167      0.43737
alpha_6                               0.21137      0.00173     0.21418      0.20818
alpha_7                               0.36877      0.00244     0.37408      0.36471
alpha_8                               0.31792      0.00274     0.32290      0.31346
alpha_9                               0.20983      0.00144     0.21248      0.20750
Alpha_loss                            -0.76805     0.12808     -0.35521     -1.06786
Training/policy_loss                  236.81142    18.32362    281.45859    196.64360
Training/qf1_loss                     5976.13884   2273.98225  14755.52246  2549.27222
Training/qf2_loss                     1740.59347   438.90441   3432.96948   995.71332
Training/pf_norm                      20.60882     7.85854     45.14125     8.59853
Training/qf1_norm                     7045.09935   2953.45289  16275.75098  2641.49805
Training/qf2_norm                     5467.77456   2395.79130  12107.48438  1979.34375
log_std/mean                          -0.95942     0.00829     -0.94672     -0.98642
log_std/std                           0.46817      0.00615     0.48459      0.45217
log_std/max                           0.08829      0.04394     0.21325      0.00826
log_std/min                           -2.77131     0.24642     -2.49890     -3.58631
log_probs/mean                        3.38914      0.08571     3.65425      3.14627
log_probs/std                         3.02268      0.09135     3.34701      2.80518
log_probs/max                         20.67190     3.32445     32.29313     13.86457
log_probs/min                         -6.56425     1.37507     -3.95732     -11.86353
mean/mean                             0.21097      0.03140     0.26015      0.13270
mean/std                              1.31175      0.01337     1.34065      1.27870
mean/max                              5.49822      0.85725     6.27903      3.64078
mean/min                              -5.72355     1.07197     -3.62948     -7.50459
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 3, 8, 5, 9, 6, 0, 7, 1, 4]
replay_buffer._size: [52350 52350 52350 52350 52350 52350 52350 52350 52350 52350]
2023-08-12 12:31:01,091 MainThread INFO: EPOCH:327
2023-08-12 12:31:01,091 MainThread INFO: Time Consumed:8.587049007415771s
2023-08-12 12:31:01,091 MainThread INFO: Total Frames:522000s
  3%|▎         | 328/10000 [49:40<23:39:23,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1039.24150
Train_Epoch_Reward                    10698.02173
Running_Training_Average_Rewards      1067.27478
Explore_Time                          0.01478
Train___Time                          8.56726
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.29170
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.88377
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -46.75215
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.04692
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.52212
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.81061
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.12185
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10922.09569
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -13.41380
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.83779
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.71599      1.47963     10.83394     3.84573
alpha_0                               4.02231      0.00578     4.03693      4.01718
alpha_1                               0.51322      0.00241     0.51770      0.51069
alpha_2                               0.27839      0.00260     0.28281      0.27403
alpha_3                               0.20001      0.00060     0.20102      0.19895
alpha_4                               0.16372      0.00043     0.16436      0.16284
alpha_5                               0.43535      0.00112     0.43731      0.43344
alpha_6                               0.20498      0.00182     0.20811      0.20191
alpha_7                               0.36036      0.00249     0.36461      0.35520
alpha_8                               0.30975      0.00206     0.31338      0.30604
alpha_9                               0.20514      0.00141     0.20746      0.20249
Alpha_loss                            -0.85064     0.13765     -0.46974     -1.20993
Training/policy_loss                  239.03135    17.55129    290.48056    205.08614
Training/qf1_loss                     5835.18692   2414.07117  12265.92285  2224.00854
Training/qf2_loss                     1742.90231   434.89184   3559.11255   1121.86133
Training/pf_norm                      20.25567     7.32293     47.47578     6.04708
Training/qf1_norm                     6392.93278   3114.45418  18928.01367  2045.48450
Training/qf2_norm                     5641.78381   2729.86794  19624.81055  1340.78027
log_std/mean                          -0.96767     0.00999     -0.94897     -0.98915
log_std/std                           0.47086      0.00551     0.48147      0.45787
log_std/max                           0.10814      0.04514     0.21239      0.01540
log_std/min                           -2.85813     0.23785     -2.52846     -3.68593
log_probs/mean                        3.36175      0.09184     3.64179      3.13720
log_probs/std                         3.04062      0.10536     3.31507      2.79208
log_probs/max                         20.09869     2.95781     31.61750     14.55526
log_probs/min                         -6.53405     1.24623     -4.47026     -10.60488
mean/mean                             0.18443      0.02547     0.25796      0.10499
mean/std                              1.30640      0.01328     1.34313      1.26533
mean/max                              5.39358      0.95739     6.37657      3.65710
mean/min                              -5.63993     1.00133     -3.30013     -7.47317
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 9, 5, 1, 4, 6, 3, 7, 8, 2]
replay_buffer._size: [52500 52500 52500 52500 52500 52500 52500 52500 52500 52500]
2023-08-12 12:31:09,920 MainThread INFO: EPOCH:328
2023-08-12 12:31:09,920 MainThread INFO: Time Consumed:8.670599460601807s
2023-08-12 12:31:09,920 MainThread INFO: Total Frames:523500s
  3%|▎         | 329/10000 [49:49<23:40:09,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1037.66820
Train_Epoch_Reward                    10218.89732
Running_Training_Average_Rewards      1044.29743
Explore_Time                          0.00907
Train___Time                          8.65721
Eval____Time                          0.00366
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.59992
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.11206
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.22873
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.01473
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.54849
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.11458
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.08584
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10891.60365
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -14.95100
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.26626
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.64490      1.46339     10.76919     3.14901
alpha_0                               3.99428      0.01470     4.01742      3.96789
alpha_1                               0.50799      0.00137     0.51067      0.50630
alpha_2                               0.26939      0.00267     0.27394      0.26487
alpha_3                               0.19796      0.00059     0.19893      0.19674
alpha_4                               0.16184      0.00054     0.16282      0.16089
alpha_5                               0.43031      0.00161     0.43336      0.42753
alpha_6                               0.19878      0.00178     0.20185      0.19571
alpha_7                               0.34750      0.00393     0.35503      0.34139
alpha_8                               0.30171      0.00260     0.30595      0.29702
alpha_9                               0.19922      0.00176     0.20242      0.19624
Alpha_loss                            -0.95950     0.12665     -0.65921     -1.24735
Training/policy_loss                  236.16533    18.55985    294.26974    181.75790
Training/qf1_loss                     5563.95838   2376.37039  16557.31250  2169.38550
Training/qf2_loss                     1711.40931   372.20574   3069.57544   1180.45374
Training/pf_norm                      19.44839     6.09800     35.47016     8.61857
Training/qf1_norm                     7142.54071   3365.25552  18931.61719  2120.47437
Training/qf2_norm                     5551.13529   2552.08714  14155.76758  1727.08704
log_std/mean                          -0.96114     0.00929     -0.94017     -0.98087
log_std/std                           0.47329      0.00580     0.48517      0.45774
log_std/max                           0.10829      0.04598     0.23398      0.01430
log_std/min                           -2.91583     0.35029     -2.48784     -3.74266
log_probs/mean                        3.27546      0.10653     3.49979      3.01322
log_probs/std                         3.06672      0.09651     3.37580      2.85852
log_probs/max                         21.43698     4.06923     31.68122     14.71628
log_probs/min                         -6.89982     1.48274     -4.65718     -12.23762
mean/mean                             0.16811      0.02514     0.23064      0.09890
mean/std                              1.30070      0.01279     1.32943      1.26344
mean/max                              5.41077      1.01682     6.46567      3.83677
mean/min                              -5.78642     1.00433     -3.57315     -7.52064
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 6, 8, 7, 1, 5, 9, 3, 4, 2]
replay_buffer._size: [52650 52650 52650 52650 52650 52650 52650 52650 52650 52650]
2023-08-12 12:31:18,656 MainThread INFO: EPOCH:329
2023-08-12 12:31:18,656 MainThread INFO: Time Consumed:8.540107250213623s
2023-08-12 12:31:18,657 MainThread INFO: Total Frames:525000s
  3%|▎         | 330/10000 [49:57<23:36:37,  8.79s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1043.30721
Train_Epoch_Reward                    10931.83677
Running_Training_Average_Rewards      1061.62519
Explore_Time                          0.01410
Train___Time                          8.52099
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.20174
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.71573
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -41.70664
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.12428
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.56240
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.52717
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.07945
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10964.29065
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.12781
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -61.17335
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.76099      1.19687     10.51290     3.73353
alpha_0                               3.92917      0.01713     3.96707      3.90097
alpha_1                               0.50262      0.00213     0.50627      0.49905
alpha_2                               0.26054      0.00239     0.26478      0.25661
alpha_3                               0.19543      0.00069     0.19671      0.19431
alpha_4                               0.15967      0.00068     0.16087      0.15848
alpha_5                               0.42473      0.00150     0.42747      0.42168
alpha_6                               0.19296      0.00149     0.19565      0.19048
alpha_7                               0.33474      0.00378     0.34127      0.32831
alpha_8                               0.29244      0.00250     0.29691      0.28818
alpha_9                               0.19292      0.00188     0.19617      0.18962
Alpha_loss                            -0.96714     0.10911     -0.73922     -1.25088
Training/policy_loss                  229.74640    19.88662    280.09933    176.14465
Training/qf1_loss                     5648.56353   2117.94240  13550.71289  1877.45508
Training/qf2_loss                     1665.59149   350.67601   3080.91479   908.96973
Training/pf_norm                      21.78293     8.22434     43.66713     7.41537
Training/qf1_norm                     6572.76045   2843.54492  17187.53516  2489.68335
Training/qf2_norm                     4351.07749   1813.49948  13318.94141  1471.68542
log_std/mean                          -0.96441     0.01170     -0.93616     -0.98467
log_std/std                           0.46919      0.00495     0.48137      0.45741
log_std/max                           0.13254      0.04677     0.24531      0.02882
log_std/min                           -2.78938     0.24421     -2.39835     -3.61085
log_probs/mean                        3.26754      0.10459     3.46163      2.96831
log_probs/std                         3.05558      0.08996     3.29571      2.86615
log_probs/max                         21.03400     3.11360     32.53822     14.86691
log_probs/min                         -6.61392     1.28753     -4.30402     -9.83619
mean/mean                             0.16117      0.03073     0.23641      0.09582
mean/std                              1.29806      0.01331     1.33355      1.26633
mean/max                              5.33746      0.91727     6.32022      3.61102
mean/min                              -5.81676     1.06655     -3.63139     -7.63567
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 2, 8, 1, 9, 4, 6, 5, 7, 3]
replay_buffer._size: [52800 52800 52800 52800 52800 52800 52800 52800 52800 52800]
2023-08-12 12:31:27,143 MainThread INFO: EPOCH:330
2023-08-12 12:31:27,144 MainThread INFO: Time Consumed:8.298715829849243s
2023-08-12 12:31:27,144 MainThread INFO: Total Frames:526500s
  3%|▎         | 331/10000 [50:06<23:21:37,  8.70s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1055.71799
Train_Epoch_Reward                    10591.10295
Running_Training_Average_Rewards      1058.06123
Explore_Time                          0.00404
Train___Time                          8.29023
Eval____Time                          0.00389
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.17984
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.17241
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.90039
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.75652
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.81536
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.74808
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.06094
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11136.14377
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.14511
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.18521
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.63304      1.27831     10.27779     2.81506
alpha_0                               3.86497      0.02012     3.90000      3.83374
alpha_1                               0.49601      0.00166     0.49897      0.49349
alpha_2                               0.25290      0.00213     0.25653      0.24913
alpha_3                               0.19339      0.00050     0.19428      0.19258
alpha_4                               0.15741      0.00045     0.15845      0.15674
alpha_5                               0.42042      0.00053     0.42160      0.41970
alpha_6                               0.18805      0.00137     0.19043      0.18578
alpha_7                               0.32185      0.00338     0.32818      0.31708
alpha_8                               0.28473      0.00180     0.28810      0.28185
alpha_9                               0.18623      0.00180     0.18955      0.18339
Alpha_loss                            -0.83402     0.15666     -0.46924     -1.16144
Training/policy_loss                  229.36868    18.75941    270.99020    168.35265
Training/qf1_loss                     5374.64318   2105.69065  11069.74219  1792.10388
Training/qf2_loss                     1615.39297   362.39093   2660.90112   1002.46106
Training/pf_norm                      21.64991     8.08859     50.50909     9.03566
Training/qf1_norm                     5981.14393   2676.26869  19068.43164  1678.43506
Training/qf2_norm                     5236.52838   2131.99325  11386.41895  2016.03369
log_std/mean                          -0.98672     0.01256     -0.96102     -1.01551
log_std/std                           0.47254      0.00557     0.48451      0.45846
log_std/max                           0.11505      0.04393     0.24114      0.04424
log_std/min                           -2.86847     0.30995     -2.45237     -3.75772
log_probs/mean                        3.38448      0.12521     3.67676      3.13631
log_probs/std                         3.07848      0.09969     3.32975      2.81758
log_probs/max                         21.96951     3.66398     33.08476     14.48684
log_probs/min                         -6.59502     1.35272     -4.43623     -11.08668
mean/mean                             0.19008      0.04073     0.27696      0.10890
mean/std                              1.30178      0.01577     1.34703      1.26377
mean/max                              5.46706      0.87853     6.28856      3.65310
mean/min                              -5.87237     1.03845     -3.96822     -7.55136
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 4, 5, 0, 3, 1, 8, 6, 7]
replay_buffer._size: [52950 52950 52950 52950 52950 52950 52950 52950 52950 52950]
2023-08-12 12:31:36,424 MainThread INFO: EPOCH:331
2023-08-12 12:31:36,424 MainThread INFO: Time Consumed:9.109388828277588s
2023-08-12 12:31:36,424 MainThread INFO: Total Frames:528000s
  3%|▎         | 332/10000 [50:15<23:52:00,  8.89s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1030.56244
Train_Epoch_Reward                    10958.63779
Running_Training_Average_Rewards      1082.71925
Explore_Time                          0.00357
Train___Time                          9.10103
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.86731
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.34224
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.64774
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.30959
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.96129
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.25834
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.74599
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10894.50115
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -16.78268
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.96161
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56504      1.19971     9.18482      2.88837
alpha_0                               3.82168      0.00803     3.83332      3.80728
alpha_1                               0.49028      0.00204     0.49346      0.48677
alpha_2                               0.24477      0.00263     0.24905      0.24018
alpha_3                               0.19173      0.00040     0.19256      0.19124
alpha_4                               0.15580      0.00078     0.15674      0.15441
alpha_5                               0.42127      0.00063     0.42228      0.42022
alpha_6                               0.18394      0.00110     0.18575      0.18211
alpha_7                               0.31311      0.00206     0.31699      0.30971
alpha_8                               0.27870      0.00175     0.28179      0.27600
alpha_9                               0.18059      0.00164     0.18334      0.17783
Alpha_loss                            -0.89451     0.14582     -0.44420     -1.20882
Training/policy_loss                  226.16935    19.09425    265.70883    181.74352
Training/qf1_loss                     5348.97937   2383.53193  16013.88184  2042.08875
Training/qf2_loss                     1679.78724   406.78922   3126.00317   1024.94263
Training/pf_norm                      19.87370     7.99645     43.59174     6.48589
Training/qf1_norm                     6248.25690   2741.57865  15941.53125  2023.98547
Training/qf2_norm                     5120.34778   2376.98772  12806.48730  1958.23572
log_std/mean                          -0.98235     0.00999     -0.96138     -1.00571
log_std/std                           0.48048      0.00647     0.49662      0.46423
log_std/max                           0.13961      0.04186     0.29847      0.05895
log_std/min                           -2.92678     0.30878     -2.56190     -3.79738
log_probs/mean                        3.37358      0.11289     3.70775      3.13944
log_probs/std                         3.15332      0.08886     3.48191      2.96102
log_probs/max                         20.95213     3.73843     32.44407     13.89978
log_probs/min                         -6.80221     1.41393     -4.36489     -12.53432
mean/mean                             0.18478      0.04144     0.28558      0.09079
mean/std                              1.30459      0.01436     1.34197      1.27035
mean/max                              5.28800      0.86346     6.29065      3.82149
mean/min                              -5.80993     0.95481     -3.75050     -7.55898
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 7, 1, 8, 6, 2, 0, 3, 5, 4]
replay_buffer._size: [53100 53100 53100 53100 53100 53100 53100 53100 53100 53100]
2023-08-12 12:31:45,077 MainThread INFO: EPOCH:332
2023-08-12 12:31:45,077 MainThread INFO: Time Consumed:8.464370012283325s
2023-08-12 12:31:45,077 MainThread INFO: Total Frames:529500s
  3%|▎         | 333/10000 [50:24<23:38:08,  8.80s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1044.99309
Train_Epoch_Reward                    10160.95783
Running_Training_Average_Rewards      1057.02329
Explore_Time                          0.01537
Train___Time                          8.44337
Eval____Time                          0.00501
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.28962
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.14307
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -70.51940
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.28864
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.73423
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.67027
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.06392
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10997.35993
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.21887
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -62.50105
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.79143      1.33595     11.61481     4.02319
alpha_0                               3.78891      0.01049     3.80677      3.76502
alpha_1                               0.48383      0.00132     0.48668      0.48174
alpha_2                               0.23579      0.00238     0.24009      0.23191
alpha_3                               0.19067      0.00029     0.19123      0.19019
alpha_4                               0.15306      0.00079     0.15439      0.15174
alpha_5                               0.42046      0.00020     0.42084      0.42011
alpha_6                               0.18052      0.00094     0.18208      0.17887
alpha_7                               0.30485      0.00292     0.30962      0.29982
alpha_8                               0.27427      0.00093     0.27595      0.27270
alpha_9                               0.17480      0.00174     0.17778      0.17179
Alpha_loss                            -0.87618     0.12128     -0.39956     -1.10709
Training/policy_loss                  225.49145    18.64740    274.16153    171.49719
Training/qf1_loss                     5493.40609   2329.62267  13085.17480  1835.37390
Training/qf2_loss                     1664.42364   440.15587   3417.70239   954.75861
Training/pf_norm                      21.15105     8.43978     53.96893     6.15750
Training/qf1_norm                     5985.39365   2852.41912  16400.60938  2367.45557
Training/qf2_norm                     5147.23224   2621.02010  13730.29785  1454.90271
log_std/mean                          -1.00321     0.01148     -0.98057     -1.02641
log_std/std                           0.48410      0.00516     0.49917      0.47296
log_std/max                           0.16241      0.02562     0.23382      0.09330
log_std/min                           -2.98797     0.26585     -2.58348     -3.85437
log_probs/mean                        3.39388      0.09005     3.69673      3.14403
log_probs/std                         3.16690      0.09378     3.51763      2.98257
log_probs/max                         21.06472     2.55487     30.58554     15.53739
log_probs/min                         -6.59455     1.48503     -3.91699     -14.19559
mean/mean                             0.20053      0.02649     0.27813      0.14684
mean/std                              1.29591      0.01363     1.33085      1.26037
mean/max                              5.55635      0.72266     6.30114      3.74201
mean/min                              -6.01889     0.85943     -3.77052     -8.06141
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 4, 5, 6, 2, 3, 1, 0, 8, 9]
replay_buffer._size: [53250 53250 53250 53250 53250 53250 53250 53250 53250 53250]
2023-08-12 12:31:54,292 MainThread INFO: EPOCH:333
2023-08-12 12:31:54,293 MainThread INFO: Time Consumed:9.053634643554688s
2023-08-12 12:31:54,293 MainThread INFO: Total Frames:531000s
  3%|▎         | 334/10000 [50:33<23:58:13,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1054.46767
Train_Epoch_Reward                    10527.65621
Running_Training_Average_Rewards      1054.90839
Explore_Time                          0.00521
Train___Time                          9.04388
Eval____Time                          0.00387
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.73799
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.56517
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.95826
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.01754
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.47830
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.22791
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.83646
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11099.28491
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.62955
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -62.15702
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56141      1.28114     9.78279      4.05069
alpha_0                               3.72928      0.02111     3.76403      3.70134
alpha_1                               0.47986      0.00086     0.48173      0.47871
alpha_2                               0.22784      0.00238     0.23184      0.22373
alpha_3                               0.18960      0.00035     0.19018      0.18913
alpha_4                               0.14990      0.00111     0.15171      0.14801
alpha_5                               0.42074      0.00048     0.42153      0.42012
alpha_6                               0.17752      0.00073     0.17884      0.17643
alpha_7                               0.29628      0.00190     0.29972      0.29352
alpha_8                               0.27125      0.00089     0.27267      0.26946
alpha_9                               0.16887      0.00161     0.17173      0.16617
Alpha_loss                            -0.87062     0.12989     -0.54516     -1.29877
Training/policy_loss                  221.30775    20.16554    264.75183    165.01802
Training/qf1_loss                     5439.87273   2114.96643  10770.40332  2149.17505
Training/qf2_loss                     1664.95395   351.80955   3117.84497   1098.60632
Training/pf_norm                      18.52182     6.76578     48.18526     8.45775
Training/qf1_norm                     6228.18558   2735.65656  16943.03906  2347.07007
Training/qf2_norm                     5406.04659   2280.04550  11478.91992  2129.68140
log_std/mean                          -1.01401     0.00863     -1.00034     -1.03950
log_std/std                           0.48787      0.00503     0.49985      0.47880
log_std/max                           0.19762      0.04510     0.25074      0.07332
log_std/min                           -2.91546     0.24154     -2.60487     -3.91755
log_probs/mean                        3.41490      0.11164     3.65743      3.11145
log_probs/std                         3.17722      0.09521     3.38825      2.95151
log_probs/max                         21.03176     2.18972     31.33405     15.71379
log_probs/min                         -6.78138     1.38366     -4.50215     -12.54356
mean/mean                             0.18163      0.02676     0.24656      0.12033
mean/std                              1.29519      0.01519     1.32909      1.25999
mean/max                              5.40789      0.76117     6.25132      3.99700
mean/min                              -6.24782     1.01719     -3.99185     -7.92995
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 3, 9, 0, 8, 4, 6, 5, 1]
replay_buffer._size: [53400 53400 53400 53400 53400 53400 53400 53400 53400 53400]
2023-08-12 12:32:02,898 MainThread INFO: EPOCH:334
2023-08-12 12:32:02,899 MainThread INFO: Time Consumed:8.411316394805908s
2023-08-12 12:32:02,899 MainThread INFO: Total Frames:532500s
  3%|▎         | 335/10000 [50:42<23:42:20,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               997.73172
Train_Epoch_Reward                    10866.77212
Running_Training_Average_Rewards      1051.84621
Explore_Time                          0.00410
Train___Time                          8.40256
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.90070
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.38517
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.30779
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.65353
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.76647
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.77652
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.91350
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10540.75708
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -18.14228
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -60.59394
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.78558      1.17186     10.38375     4.35776
alpha_0                               3.68393      0.00986     3.70268      3.66624
alpha_1                               0.47636      0.00184     0.47871      0.47339
alpha_2                               0.21937      0.00244     0.22364      0.21539
alpha_3                               0.18819      0.00067     0.18913      0.18695
alpha_4                               0.14613      0.00117     0.14798      0.14403
alpha_5                               0.42133      0.00030     0.42191      0.42092
alpha_6                               0.17484      0.00097     0.17640      0.17320
alpha_7                               0.29224      0.00098     0.29351      0.28994
alpha_8                               0.26768      0.00095     0.26941      0.26571
alpha_9                               0.16344      0.00156     0.16611      0.16073
Alpha_loss                            -0.99325     0.14507     -0.59661     -1.40664
Training/policy_loss                  221.47757    17.29420    257.61685    156.10620
Training/qf1_loss                     5231.30114   1889.31160  9946.26367   1862.39026
Training/qf2_loss                     1664.12587   389.45407   3085.79761   983.06464
Training/pf_norm                      20.25041     8.82538     52.46756     7.45583
Training/qf1_norm                     6154.23098   2806.81066  16751.99023  1989.80713
Training/qf2_norm                     4812.69827   2266.43435  12771.06738  1486.27332
log_std/mean                          -1.00417     0.00783     -0.98306     -1.02380
log_std/std                           0.49335      0.00521     0.50636      0.48383
log_std/max                           0.27416      0.05183     0.34050      0.12882
log_std/min                           -2.96662     0.31399     -2.56867     -3.91493
log_probs/mean                        3.35254      0.09819     3.60008      3.07883
log_probs/std                         3.21767      0.09486     3.52677      2.99761
log_probs/max                         21.95018     3.12363     32.77558     16.98317
log_probs/min                         -6.59151     1.37747     -4.30146     -12.12963
mean/mean                             0.14548      0.03035     0.22359      0.07248
mean/std                              1.29722      0.01554     1.34260      1.25444
mean/max                              5.47163      0.72230     6.18426      4.18994
mean/min                              -6.32973     1.00157     -3.98346     -8.12282
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 5, 8, 0, 6, 2, 4, 3, 7, 9]
replay_buffer._size: [53550 53550 53550 53550 53550 53550 53550 53550 53550 53550]
2023-08-12 12:32:12,706 MainThread INFO: EPOCH:335
2023-08-12 12:32:12,706 MainThread INFO: Time Consumed:9.626126289367676s
2023-08-12 12:32:12,706 MainThread INFO: Total Frames:534000s
  3%|▎         | 336/10000 [50:51<24:29:27,  9.12s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1063.68801
Train_Epoch_Reward                    9700.29686
Running_Training_Average_Rewards      1036.49084
Explore_Time                          0.00980
Train___Time                          9.61170
Eval____Time                          0.00410
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.46401
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.15257
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.54318
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.26209
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.33350
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.97304
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.16762
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11201.59257
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.44278
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.37367
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.87679      1.28177     9.29757      3.70964
alpha_0                               3.64526      0.01005     3.66566      3.62978
alpha_1                               0.47244      0.00083     0.47359      0.47097
alpha_2                               0.21230      0.00167     0.21532      0.20958
alpha_3                               0.18633      0.00021     0.18693      0.18616
alpha_4                               0.14214      0.00117     0.14399      0.14001
alpha_5                               0.42408      0.00165     0.42582      0.42156
alpha_6                               0.17216      0.00044     0.17317      0.17141
alpha_7                               0.28600      0.00241     0.28987      0.28156
alpha_8                               0.26407      0.00090     0.26564      0.26219
alpha_9                               0.15809      0.00155     0.16068      0.15532
Alpha_loss                            -0.81394     0.14853     -0.50249     -1.22911
Training/policy_loss                  217.03742    19.48639    265.76678    161.94359
Training/qf1_loss                     5695.44500   2239.05470  13400.44043  2418.37817
Training/qf2_loss                     1711.39149   415.04001   3022.44897   1031.82422
Training/pf_norm                      21.92676     7.44150     47.34397     9.59473
Training/qf1_norm                     6964.63625   3276.19032  20676.10938  2130.98242
Training/qf2_norm                     4992.06281   2103.20539  11753.16992  1643.23486
log_std/mean                          -1.01781     0.00937     -0.99035     -1.03861
log_std/std                           0.49375      0.00545     0.50797      0.48045
log_std/max                           0.30056      0.07656     0.40444      0.10056
log_std/min                           -2.96534     0.33446     -2.51708     -3.91167
log_probs/mean                        3.48591      0.10158     3.72770      3.25579
log_probs/std                         3.23131      0.11062     3.63915      2.97263
log_probs/max                         22.04102     3.30314     33.32593     15.08790
log_probs/min                         -6.64047     1.23802     -4.46090     -10.35855
mean/mean                             0.14383      0.03567     0.22232      0.06969
mean/std                              1.31122      0.01509     1.35857      1.27739
mean/max                              5.39252      0.65027     6.19785      4.22756
mean/min                              -6.81426     0.92680     -4.03863     -8.33299
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 7, 3, 4, 1, 5, 8, 6, 0]
replay_buffer._size: [53700 53700 53700 53700 53700 53700 53700 53700 53700 53700]
2023-08-12 12:32:21,245 MainThread INFO: EPOCH:336
2023-08-12 12:32:21,245 MainThread INFO: Time Consumed:8.327036619186401s
2023-08-12 12:32:21,245 MainThread INFO: Total Frames:535500s
  3%|▎         | 337/10000 [51:00<24:02:36,  8.96s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1029.50962
Train_Epoch_Reward                    10810.96201
Running_Training_Average_Rewards      1045.93437
Explore_Time                          0.00518
Train___Time                          8.31706
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.60476
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.63188
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.22039
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.41855
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.20112
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.74378
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.17787
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10864.26415
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.66881
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.50078
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.48473      1.21390     10.09596     3.58373
alpha_0                               3.61009      0.00967     3.62910      3.59768
alpha_1                               0.46952      0.00120     0.47109      0.46756
alpha_2                               0.20693      0.00160     0.20953      0.20408
alpha_3                               0.18557      0.00047     0.18616      0.18474
alpha_4                               0.13746      0.00144     0.13996      0.13511
alpha_5                               0.42693      0.00111     0.42971      0.42584
alpha_6                               0.17064      0.00041     0.17139      0.17009
alpha_7                               0.27672      0.00259     0.28147      0.27262
alpha_8                               0.26070      0.00087     0.26214      0.25927
alpha_9                               0.15267      0.00146     0.15527      0.15026
Alpha_loss                            -0.85455     0.16034     -0.29681     -1.16975
Training/policy_loss                  216.34943    20.10568    268.65744    162.87454
Training/qf1_loss                     5081.20122   1953.83196  12326.61133  1951.67578
Training/qf2_loss                     1571.74921   330.97497   3115.78052   1011.26935
Training/pf_norm                      17.65782     6.39527     34.78066     6.99161
Training/qf1_norm                     5968.55862   2893.10916  14962.04590  1942.96460
Training/qf2_norm                     5760.17132   2777.04644  14258.70605  1681.84863
log_std/mean                          -1.02032     0.01465     -0.99942     -1.06617
log_std/std                           0.49447      0.00596     0.50735      0.48147
log_std/max                           0.35788      0.08726     0.44076      0.11069
log_std/min                           -2.88793     0.31707     -2.48875     -3.88237
log_probs/mean                        3.47870      0.11360     3.90765      3.28596
log_probs/std                         3.21991      0.09193     3.45690      2.99692
log_probs/max                         21.79575     3.06559     33.21001     17.15455
log_probs/min                         -6.64655     1.30465     -4.70260     -10.47672
mean/mean                             0.13244      0.03748     0.22880      0.05170
mean/std                              1.30869      0.01501     1.34485      1.27311
mean/max                              5.34515      0.65838     6.08813      4.21229
mean/min                              -6.63083     1.04796     -3.84371     -8.37171
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 5, 2, 3, 1, 0, 7, 4, 9, 8]
replay_buffer._size: [53850 53850 53850 53850 53850 53850 53850 53850 53850 53850]
2023-08-12 12:32:30,079 MainThread INFO: EPOCH:337
2023-08-12 12:32:30,079 MainThread INFO: Time Consumed:8.649465560913086s
2023-08-12 12:32:30,080 MainThread INFO: Total Frames:537000s
  3%|▎         | 338/10000 [51:09<23:55:05,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1024.71368
Train_Epoch_Reward                    8934.07469
Running_Training_Average_Rewards      981.51112
Explore_Time                          0.01153
Train___Time                          8.63277
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.22145
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.84493
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.44696
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.25587
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.35235
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.55682
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.06985
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10835.69429
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -19.86344
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.94585
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.44690      1.29260     10.03615     3.68000
alpha_0                               3.59201      0.00453     3.59856      3.58626
alpha_1                               0.46555      0.00194     0.46787      0.46190
alpha_2                               0.20126      0.00154     0.20403      0.19869
alpha_3                               0.18404      0.00055     0.18474      0.18294
alpha_4                               0.13279      0.00136     0.13507      0.13051
alpha_5                               0.43334      0.00122     0.43469      0.42982
alpha_6                               0.17004      0.00034     0.17042      0.16928
alpha_7                               0.26874      0.00248     0.27255      0.26475
alpha_8                               0.25849      0.00068     0.25926      0.25740
alpha_9                               0.14833      0.00114     0.15022      0.14641
Alpha_loss                            -0.83569     0.17335     -0.28766     -1.19721
Training/policy_loss                  216.69073    23.16495    266.85904    154.72478
Training/qf1_loss                     4905.80027   1947.56460  12005.54590  2058.27417
Training/qf2_loss                     1570.96449   271.25638   2383.95142   1099.41162
Training/pf_norm                      20.03140     8.02692     44.36478     8.90409
Training/qf1_norm                     6236.56639   3095.67119  15978.45508  1854.63000
Training/qf2_norm                     5325.90368   2466.39386  13580.30273  1732.31641
log_std/mean                          -1.02073     0.01421     -0.99619     -1.06409
log_std/std                           0.50261      0.00643     0.51535      0.48682
log_std/max                           0.40930      0.11182     0.55117      0.08851
log_std/min                           -2.96025     0.27813     -2.55106     -3.89947
log_probs/mean                        3.49632      0.13304     3.83496      3.20814
log_probs/std                         3.23759      0.10378     3.49491      2.94815
log_probs/max                         21.55631     2.95062     33.74737     15.62580
log_probs/min                         -6.50069     1.30321     -3.59547     -10.88662
mean/mean                             0.12743      0.03483     0.21267      0.05681
mean/std                              1.30929      0.01702     1.34553      1.27518
mean/max                              5.39286      0.60874     6.08836      4.10630
mean/min                              -6.57492     1.09049     -3.73285     -8.52869
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 6, 9, 4, 0, 7, 1, 5, 8, 3]
replay_buffer._size: [54000 54000 54000 54000 54000 54000 54000 54000 54000 54000]
2023-08-12 12:32:38,993 MainThread INFO: EPOCH:338
2023-08-12 12:32:38,993 MainThread INFO: Time Consumed:8.719367265701294s
2023-08-12 12:32:38,993 MainThread INFO: Total Frames:538500s
  3%|▎         | 339/10000 [51:18<23:55:05,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1025.44552
Train_Epoch_Reward                    9455.36744
Running_Training_Average_Rewards      973.34680
Explore_Time                          0.01935
Train___Time                          8.69538
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.23580
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.79821
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.45731
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.45144
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.11156
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.61993
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.13909
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10840.77757
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -21.70332
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -62.80568
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.39567      1.13605     9.87034      2.79006
alpha_0                               3.56807      0.00801     3.58813      3.55999
alpha_1                               0.45863      0.00177     0.46184      0.45541
alpha_2                               0.19619      0.00140     0.19864      0.19384
alpha_3                               0.18186      0.00048     0.18290      0.18106
alpha_4                               0.12864      0.00098     0.13047      0.12703
alpha_5                               0.43493      0.00095     0.43633      0.43361
alpha_6                               0.16790      0.00072     0.16926      0.16689
alpha_7                               0.26174      0.00133     0.26467      0.26016
alpha_8                               0.25683      0.00030     0.25738      0.25648
alpha_9                               0.14492      0.00078     0.14638      0.14369
Alpha_loss                            -0.71778     0.16881     -0.32264     -1.19466
Training/policy_loss                  216.58889    21.42578    268.45346    163.85283
Training/qf1_loss                     5150.79275   2001.23125  10301.57031  1701.22205
Training/qf2_loss                     1632.89703   340.94979   2946.12793   1097.90247
Training/pf_norm                      19.64611     7.08622     44.33113     7.61527
Training/qf1_norm                     6200.69178   2895.13397  14484.12500  1618.82361
Training/qf2_norm                     5288.38083   2269.74625  13751.35449  1403.90613
log_std/mean                          -1.04193     0.01211     -1.01029     -1.06586
log_std/std                           0.51175      0.00648     0.52779      0.49404
log_std/max                           0.41390      0.09407     0.48889      0.07368
log_std/min                           -3.05140     0.33296     -2.52759     -3.97861
log_probs/mean                        3.55947      0.11992     3.85566      3.19664
log_probs/std                         3.17486      0.10049     3.44228      2.98349
log_probs/max                         22.23480     3.40774     34.27525     15.30209
log_probs/min                         -6.46248     1.15217     -4.28274     -10.87292
mean/mean                             0.14905      0.02143     0.21296      0.09866
mean/std                              1.30380      0.01544     1.33674      1.26944
mean/max                              5.31416      0.61965     6.02081      4.17612
mean/min                              -6.77079     0.96939     -3.87321     -8.23558
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 2, 1, 7, 6, 4, 5, 0, 8, 3]
replay_buffer._size: [54150 54150 54150 54150 54150 54150 54150 54150 54150 54150]
2023-08-12 12:32:47,745 MainThread INFO: EPOCH:339
2023-08-12 12:32:47,745 MainThread INFO: Time Consumed:8.590001821517944s
2023-08-12 12:32:47,745 MainThread INFO: Total Frames:540000s
  3%|▎         | 340/10000 [51:26<23:46:59,  8.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1017.14586
Train_Epoch_Reward                    10193.34831
Running_Training_Average_Rewards      952.75968
Explore_Time                          0.00594
Train___Time                          8.57932
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.39004
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.74919
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.96564
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.79133
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.77849
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.52589
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.01665
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10742.82986
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -18.70479
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.44925
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.52303      1.24383     9.49161      3.82715
alpha_0                               3.55496      0.00643     3.56147      3.54162
alpha_1                               0.45406      0.00079     0.45534      0.45263
alpha_2                               0.19172      0.00113     0.19379      0.18982
alpha_3                               0.18017      0.00057     0.18104      0.17919
alpha_4                               0.12469      0.00145     0.12699      0.12210
alpha_5                               0.43855      0.00116     0.44052      0.43639
alpha_6                               0.16635      0.00024     0.16688      0.16599
alpha_7                               0.25807      0.00145     0.26012      0.25509
alpha_8                               0.25528      0.00097     0.25652      0.25338
alpha_9                               0.14241      0.00076     0.14367      0.14110
Alpha_loss                            -0.72283     0.12568     -0.37218     -1.08684
Training/policy_loss                  210.58820    19.54962    252.01622    163.87889
Training/qf1_loss                     4803.90666   1617.18499  10436.57812  1445.90601
Training/qf2_loss                     1616.88530   346.27821   2817.12476   1067.34753
Training/pf_norm                      16.85940     5.48984     30.71964     7.33389
Training/qf1_norm                     5817.07001   2782.48899  13932.19238  1417.99768
Training/qf2_norm                     4632.49667   1773.40608  10105.65332  1467.01379
log_std/mean                          -1.03760     0.00956     -1.01236     -1.06013
log_std/std                           0.51312      0.00575     0.52458      0.50157
log_std/max                           0.38322      0.08066     0.45977      0.12347
log_std/min                           -3.03749     0.31164     -2.54469     -3.99722
log_probs/mean                        3.58185      0.08236     3.81291      3.34299
log_probs/std                         3.23346      0.09418     3.49735      3.00853
log_probs/max                         22.54485     3.24880     34.11482     17.18668
log_probs/min                         -6.75116     1.41226     -4.64901     -10.87330
mean/mean                             0.10485      0.02560     0.15642      0.03305
mean/std                              1.31540      0.01208     1.33655      1.27549
mean/max                              5.17220      0.57003     5.87040      4.02850
mean/min                              -6.69746     0.94597     -4.07635     -8.26915
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 0, 3, 5, 6, 4, 1, 7, 8]
replay_buffer._size: [54301 54300 54300 54300 54302 54304 54300 54300 54304 54300]
2023-08-12 12:32:56,727 MainThread INFO: EPOCH:340
2023-08-12 12:32:56,727 MainThread INFO: Time Consumed:8.786806583404541s
2023-08-12 12:32:56,727 MainThread INFO: Total Frames:541500s
  3%|▎         | 341/10000 [51:35<23:52:35,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1044.11847
Train_Epoch_Reward                    10934.01662
Running_Training_Average_Rewards      1019.42441
Explore_Time                          0.03628
Train___Time                          8.74545
Eval____Time                          0.00443
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.08948
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.59762
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.80584
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.66663
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.88530
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.54774
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.98551
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11023.57754
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.76778
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.04695
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.79936      1.28384     9.73780      3.96157
alpha_0                               3.53055      0.00596     3.54116      3.51922
alpha_1                               0.44845      0.00238     0.45259      0.44551
alpha_2                               0.18768      0.00127     0.18978      0.18538
alpha_3                               0.17824      0.00043     0.17916      0.17750
alpha_4                               0.11952      0.00147     0.12205      0.11690
alpha_5                               0.44250      0.00184     0.44633      0.44033
alpha_6                               0.16562      0.00031     0.16599      0.16498
alpha_7                               0.25294      0.00119     0.25505      0.25090
alpha_8                               0.25280      0.00018     0.25334      0.25243
alpha_9                               0.14001      0.00069     0.14108      0.13870
Alpha_loss                            -0.77891     0.15912     -0.43942     -1.18444
Training/policy_loss                  206.76188    21.20730    260.83212    143.86880
Training/qf1_loss                     4678.01708   1705.86553  10123.54785  1732.74609
Training/qf2_loss                     1587.51701   317.36770   2483.32104   1075.08411
Training/pf_norm                      20.94550     7.28897     42.66678     7.62363
Training/qf1_norm                     5884.82285   2428.46259  12736.69141  2135.07886
Training/qf2_norm                     6213.95568   2883.18795  14857.82520  1365.40149
log_std/mean                          -1.04074     0.01039     -1.01641     -1.07061
log_std/std                           0.52133      0.00549     0.53649      0.51042
log_std/max                           0.37252      0.08841     0.47368      0.10439
log_std/min                           -3.06502     0.27750     -2.67299     -4.01759
log_probs/mean                        3.56323      0.10831     3.85829      3.27056
log_probs/std                         3.22481      0.10222     3.50209      2.97999
log_probs/max                         21.86386     2.77658     32.60509     17.16952
log_probs/min                         -6.47152     1.35389     -4.70375     -10.92438
mean/mean                             0.07978      0.03765     0.13686      -0.00173
mean/std                              1.30858      0.01561     1.34693      1.26391
mean/max                              5.18994      0.60964     5.88966      3.96446
mean/min                              -6.60194     0.84719     -4.17162     -8.03661
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 7, 9, 3, 6, 8, 5, 4, 0, 2]
replay_buffer._size: [54450 54450 54450 54450 54450 54450 54450 54450 54450 54450]
2023-08-12 12:33:06,328 MainThread INFO: EPOCH:341
2023-08-12 12:33:06,328 MainThread INFO: Time Consumed:9.397393226623535s
2023-08-12 12:33:06,328 MainThread INFO: Total Frames:543000s
  3%|▎         | 342/10000 [51:45<24:26:22,  9.11s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1048.79355
Train_Epoch_Reward                    10150.40064
Running_Training_Average_Rewards      1042.59219
Explore_Time                          0.00488
Train___Time                          9.38600
Eval____Time                          0.00493
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.54495
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.38732
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.76444
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.07610
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.64026
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.65420
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.87978
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11085.02775
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.86556
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -64.27960
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61638      1.35791     11.76106     3.79533
alpha_0                               3.51149      0.00599     3.52063      3.50174
alpha_1                               0.44494      0.00049     0.44570      0.44440
alpha_2                               0.18345      0.00109     0.18533      0.18153
alpha_3                               0.17696      0.00043     0.17750      0.17624
alpha_4                               0.11460      0.00123     0.11684      0.11247
alpha_5                               0.44852      0.00203     0.45245      0.44646
alpha_6                               0.16454      0.00016     0.16497      0.16431
alpha_7                               0.24907      0.00097     0.25087      0.24700
alpha_8                               0.25149      0.00070     0.25242      0.24986
alpha_9                               0.13770      0.00053     0.13867      0.13675
Alpha_loss                            -0.66472     0.18118     -0.25428     -1.11405
Training/policy_loss                  205.61576    21.72583    253.76750    124.85044
Training/qf1_loss                     5009.78776   2194.44401  12644.47949  1693.05664
Training/qf2_loss                     1579.17290   368.15856   3277.10400   987.26562
Training/pf_norm                      21.80881     7.93610     49.87242     7.88837
Training/qf1_norm                     6089.81769   2815.24458  17063.28516  2360.91064
Training/qf2_norm                     5554.52704   2416.00449  14444.26074  1890.01379
log_std/mean                          -1.04915     0.00808     -1.02428     -1.07045
log_std/std                           0.51098      0.00539     0.52525      0.49368
log_std/max                           0.35896      0.07395     0.43834      0.03134
log_std/min                           -3.04856     0.27324     -2.57338     -3.90423
log_probs/mean                        3.63497      0.10256     3.85206      3.38264
log_probs/std                         3.24453      0.10099     3.45541      2.94937
log_probs/max                         21.74999     2.90731     32.68646     15.86688
log_probs/min                         -6.51541     1.36466     -3.93060     -10.11171
mean/mean                             0.09991      0.02713     0.14787      0.02344
mean/std                              1.31534      0.01642     1.35429      1.27908
mean/max                              5.24704      0.51530     5.79598      4.08056
mean/min                              -6.55901     0.98532     -4.14853     -8.10226
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 4, 7, 3, 8, 6, 1, 0, 9, 5]
replay_buffer._size: [54600 54600 54600 54600 54600 54600 54600 54600 54600 54600]
2023-08-12 12:33:14,937 MainThread INFO: EPOCH:342
2023-08-12 12:33:14,937 MainThread INFO: Time Consumed:8.48805046081543s
2023-08-12 12:33:14,937 MainThread INFO: Total Frames:544500s
  3%|▎         | 343/10000 [51:54<24:02:56,  8.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1046.04567
Train_Epoch_Reward                    11084.43565
Running_Training_Average_Rewards      1072.29510
Explore_Time                          0.00521
Train___Time                          8.47774
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.94645
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.75374
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.86608
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.96777
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.12368
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.41780
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.06859
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11049.64488
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.45292
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -66.59118
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.81999      1.24182     9.91741      4.42983
alpha_0                               3.49428      0.00570     3.50185      3.47851
alpha_1                               0.44569      0.00070     0.44682      0.44481
alpha_2                               0.17977      0.00099     0.18149      0.17812
alpha_3                               0.17531      0.00040     0.17621      0.17475
alpha_4                               0.11043      0.00116     0.11243      0.10844
alpha_5                               0.45623      0.00269     0.46120      0.45247
alpha_6                               0.16353      0.00027     0.16428      0.16333
alpha_7                               0.24368      0.00192     0.24692      0.24028
alpha_8                               0.24843      0.00079     0.24981      0.24700
alpha_9                               0.13590      0.00045     0.13673      0.13512
Alpha_loss                            -0.62780     0.16563     -0.27276     -1.03173
Training/policy_loss                  203.88885    19.00832    237.87698    133.21049
Training/qf1_loss                     5259.34006   2181.16022  11948.61426  1784.52332
Training/qf2_loss                     1617.84735   343.12870   2768.53589   993.18695
Training/pf_norm                      20.26809     8.71297     59.12388     8.41570
Training/qf1_norm                     6475.03217   2679.81185  15187.30469  1699.35669
Training/qf2_norm                     5534.99979   2272.97990  12656.98242  1942.42273
log_std/mean                          -1.05380     0.01109     -1.03374     -1.08356
log_std/std                           0.51258      0.00542     0.52641      0.49961
log_std/max                           0.39154      0.10057     0.47509      -0.02597
log_std/min                           -3.01905     0.23251     -2.71432     -3.89921
log_probs/mean                        3.66716      0.10177     3.92485      3.45900
log_probs/std                         3.26495      0.09980     3.52659      2.97266
log_probs/max                         21.03953     2.71963     32.68115     15.40970
log_probs/min                         -6.40484     1.26463     -4.41974     -11.01502
mean/mean                             0.11303      0.03755     0.18739      0.00814
mean/std                              1.31624      0.01391     1.34704      1.27802
mean/max                              5.00614      0.54678     5.74139      3.87733
mean/min                              -6.43147     1.04723     -4.12581     -8.29177
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 2, 7, 9, 1, 5, 6, 8, 0, 4]
replay_buffer._size: [54750 54750 54750 54750 54750 54750 54750 54750 54750 54750]
2023-08-12 12:33:24,000 MainThread INFO: EPOCH:343
2023-08-12 12:33:24,001 MainThread INFO: Time Consumed:8.876470565795898s
2023-08-12 12:33:24,001 MainThread INFO: Total Frames:546000s
  3%|▎         | 344/10000 [52:03<24:07:03,  8.99s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1015.41166
Train_Epoch_Reward                    9802.15623
Running_Training_Average_Rewards      1034.56642
Explore_Time                          0.00681
Train___Time                          8.86532
Eval____Time                          0.00376
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.67739
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.88971
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.86703
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.61744
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.04209
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.99561
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.11623
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10741.38499
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.61309
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.44979
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.52818      1.19321     9.66362      3.91512
alpha_0                               3.47419      0.00360     3.47949      3.46842
alpha_1                               0.44482      0.00115     0.44639      0.44271
alpha_2                               0.17676      0.00079     0.17810      0.17535
alpha_3                               0.17358      0.00074     0.17474      0.17229
alpha_4                               0.10667      0.00100     0.10840      0.10500
alpha_5                               0.46700      0.00325     0.47185      0.46136
alpha_6                               0.16324      0.00008     0.16342      0.16316
alpha_7                               0.23607      0.00248     0.24021      0.23188
alpha_8                               0.24521      0.00111     0.24697      0.24313
alpha_9                               0.13454      0.00032     0.13511      0.13404
Alpha_loss                            -0.61572     0.14829     -0.08348     -0.96422
Training/policy_loss                  201.64428    20.58019    266.73941    161.10713
Training/qf1_loss                     4788.82547   1529.68933  10891.13574  1838.36523
Training/qf2_loss                     1599.40707   390.58576   2659.26831   940.84827
Training/pf_norm                      20.23744     7.87932     53.35127     8.02868
Training/qf1_norm                     6070.29419   2795.34114  15857.87891  1813.55469
Training/qf2_norm                     4748.84175   2132.05364  11892.36816  1525.43408
log_std/mean                          -1.04586     0.00884     -1.02759     -1.06633
log_std/std                           0.50804      0.00494     0.52177      0.49505
log_std/max                           0.44446      0.05228     0.49609      0.21191
log_std/min                           -3.00017     0.29321     -2.53896     -3.83633
log_probs/mean                        3.67147      0.09420     3.91823      3.44886
log_probs/std                         3.29519      0.11044     3.58596      3.05045
log_probs/max                         21.82008     3.37245     33.31017     15.57976
log_probs/min                         -6.54498     1.45542     -3.91367     -11.30071
mean/mean                             0.12708      0.02963     0.18026      0.04451
mean/std                              1.32124      0.01518     1.35300      1.28230
mean/max                              5.00507      0.44574     5.48188      3.57636
mean/min                              -6.72931     0.89666     -4.19428     -8.16629
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 7, 4, 6, 5, 8, 2, 0, 1]
replay_buffer._size: [54900 54900 54900 54900 54900 54900 54900 54900 54900 54900]
2023-08-12 12:33:33,607 MainThread INFO: EPOCH:344
2023-08-12 12:33:33,608 MainThread INFO: Time Consumed:9.425008296966553s
2023-08-12 12:33:33,608 MainThread INFO: Total Frames:547500s
  3%|▎         | 345/10000 [52:12<24:36:43,  9.18s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1042.79004
Train_Epoch_Reward                    11191.27205
Running_Training_Average_Rewards      1069.26213
Explore_Time                          0.01317
Train___Time                          9.40651
Eval____Time                          0.00460
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.15761
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.46758
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.43210
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.76822
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.18062
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.61579
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.99068
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10959.53468
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.60405
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.41758
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.60283      1.32317     9.43203      4.08635
alpha_0                               3.44844      0.01253     3.47204      3.43160
alpha_1                               0.43961      0.00139     0.44266      0.43807
alpha_2                               0.17341      0.00117     0.17532      0.17136
alpha_3                               0.17159      0.00032     0.17226      0.17123
alpha_4                               0.10354      0.00079     0.10497      0.10222
alpha_5                               0.47373      0.00105     0.47556      0.47190
alpha_6                               0.16279      0.00026     0.16316      0.16217
alpha_7                               0.22770      0.00220     0.23180      0.22421
alpha_8                               0.24046      0.00147     0.24309      0.23807
alpha_9                               0.13356      0.00031     0.13403      0.13302
Alpha_loss                            -0.65971     0.15301     -0.33656     -1.10705
Training/policy_loss                  201.72452    21.38438    251.40083    131.20544
Training/qf1_loss                     4865.48662   2079.71324  11769.29590  1710.05359
Training/qf2_loss                     1511.70835   355.69435   3004.58252   901.51709
Training/pf_norm                      18.38713     6.28392     38.05023     9.28600
Training/qf1_norm                     6826.65230   3186.34846  16121.37207  1888.67871
Training/qf2_norm                     4880.03880   2463.19137  13417.63477  1552.16260
log_std/mean                          -1.03919     0.00807     -1.01873     -1.05854
log_std/std                           0.51006      0.00607     0.52257      0.49703
log_std/max                           0.40271      0.09865     0.48044      0.03059
log_std/min                           -3.02163     0.25103     -2.67169     -3.72213
log_probs/mean                        3.61340      0.10677     3.85961      3.34413
log_probs/std                         3.28456      0.09427     3.59470      3.02445
log_probs/max                         20.94619     2.83897     32.41977     15.14595
log_probs/min                         -6.44210     1.14651     -4.54598     -10.85859
mean/mean                             0.06133      0.03015     0.11816      -0.02281
mean/std                              1.31752      0.01583     1.35637      1.28093
mean/max                              5.05693      0.43068     5.51796      4.03609
mean/min                              -6.28579     0.93732     -4.14610     -8.08355
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 1, 0, 8, 2, 9, 5, 3, 6, 7]
replay_buffer._size: [55050 55050 55050 55050 55050 55050 55050 55050 55050 55050]
2023-08-12 12:33:42,548 MainThread INFO: EPOCH:345
2023-08-12 12:33:42,548 MainThread INFO: Time Consumed:8.755244016647339s
2023-08-12 12:33:42,548 MainThread INFO: Total Frames:549000s
  3%|▎         | 346/10000 [52:21<24:25:01,  9.11s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1005.19628
Train_Epoch_Reward                    10803.52871
Running_Training_Average_Rewards      1059.89857
Explore_Time                          0.01288
Train___Time                          8.73645
Eval____Time                          0.00532
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.82900
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.30471
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.18996
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.82733
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.02253
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.70668
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.71300
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10593.01056
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.58914
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -64.86537
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.57477      1.30678     10.13873     2.90500
alpha_0                               3.43976      0.00406     3.44609      3.43119
alpha_1                               0.43641      0.00121     0.43830      0.43471
alpha_2                               0.16922      0.00129     0.17132      0.16696
alpha_3                               0.17181      0.00034     0.17241      0.17131
alpha_4                               0.10109      0.00058     0.10219      0.10022
alpha_5                               0.47893      0.00208     0.48167      0.47562
alpha_6                               0.16067      0.00077     0.16214      0.15978
alpha_7                               0.22156      0.00125     0.22415      0.21953
alpha_8                               0.23573      0.00126     0.23801      0.23358
alpha_9                               0.13235      0.00031     0.13301      0.13193
Alpha_loss                            -0.58293     0.20761     -0.02982     -1.05608
Training/policy_loss                  195.87403    18.14580    236.80522    150.90007
Training/qf1_loss                     4972.61728   2083.00951  14441.63281  1985.29065
Training/qf2_loss                     1550.97186   325.76553   2640.71704   974.95129
Training/pf_norm                      18.21682     6.27336     40.11120     7.31772
Training/qf1_norm                     6089.09313   3033.43739  16705.60547  1527.01355
Training/qf2_norm                     5245.71919   2357.73532  11865.32812  2067.73950
log_std/mean                          -1.06700     0.01322     -1.03272     -1.09174
log_std/std                           0.51299      0.00581     0.52571      0.49922
log_std/max                           0.42817      0.09984     0.51607      0.06623
log_std/min                           -3.07938     0.28296     -2.66767     -3.86072
log_probs/mean                        3.67634      0.12042     3.91469      3.44135
log_probs/std                         3.28227      0.10070     3.61516      3.05475
log_probs/max                         21.48413     3.23655     32.82174     16.19092
log_probs/min                         -6.37387     1.36637     -3.94151     -13.05242
mean/mean                             0.08662      0.03144     0.15178      -0.00306
mean/std                              1.31024      0.01470     1.34458      1.27400
mean/max                              4.99343      0.43090     5.61450      3.72142
mean/min                              -6.31765     1.03957     -4.00060     -8.03549
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 7, 8, 3, 5, 2, 4, 9, 1]
replay_buffer._size: [55200 55200 55200 55200 55200 55200 55200 55200 55200 55200]
2023-08-12 12:33:52,287 MainThread INFO: EPOCH:346
2023-08-12 12:33:52,287 MainThread INFO: Time Consumed:9.547973871231079s
2023-08-12 12:33:52,287 MainThread INFO: Total Frames:550500s
  3%|▎         | 347/10000 [52:31<24:57:24,  9.31s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1060.80921
Train_Epoch_Reward                    9397.40076
Running_Training_Average_Rewards      1046.40672
Explore_Time                          0.00992
Train___Time                          9.53268
Eval____Time                          0.00478
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.34485
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92356
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.63631
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -17.51502
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.77911
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.91010
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.95658
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11139.76275
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.24270
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.36244
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.66293      1.31416     11.15646     4.09403
alpha_0                               3.41676      0.00912     3.43037      3.40050
alpha_1                               0.43380      0.00057     0.43485      0.43281
alpha_2                               0.16498      0.00110     0.16691      0.16307
alpha_3                               0.17252      0.00013     0.17273      0.17233
alpha_4                               0.09962      0.00032     0.10020      0.09907
alpha_5                               0.47930      0.00154     0.48140      0.47579
alpha_6                               0.15936      0.00047     0.15996      0.15871
alpha_7                               0.21697      0.00142     0.21949      0.21481
alpha_8                               0.23172      0.00125     0.23355      0.22915
alpha_9                               0.13139      0.00035     0.13192      0.13081
Alpha_loss                            -0.52378     0.21252     0.05898      -1.06501
Training/policy_loss                  196.71718    21.11114    238.79399    145.13634
Training/qf1_loss                     4880.40496   1944.60118  12283.18262  1570.88049
Training/qf2_loss                     1576.70622   424.86039   3315.80078   1023.71143
Training/pf_norm                      17.55343     6.34154     35.12773     7.75635
Training/qf1_norm                     5978.89417   2663.03335  14773.38477  1813.04126
Training/qf2_norm                     4783.35615   2091.01110  10446.46191  1482.41528
log_std/mean                          -1.05333     0.01413     -1.02614     -1.08337
log_std/std                           0.51718      0.00708     0.53436      0.50225
log_std/max                           0.47121      0.07037     0.53570      0.18254
log_std/min                           -3.09808     0.23180     -2.65975     -3.71281
log_probs/mean                        3.68342      0.13184     4.10434      3.42246
log_probs/std                         3.34361      0.10362     3.67745      3.08424
log_probs/max                         20.90005     2.88794     32.41813     15.42473
log_probs/min                         -6.37079     1.14504     -4.33081     -9.78644
mean/mean                             0.07212      0.03645     0.15734      -0.00079
mean/std                              1.32284      0.01808     1.38175      1.28632
mean/max                              5.00736      0.42362     5.52459      3.87546
mean/min                              -6.19535     0.91585     -4.21669     -7.71350
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 7, 3, 9, 5, 0, 2, 1, 4]
replay_buffer._size: [55350 55350 55350 55350 55350 55350 55350 55350 55350 55350]
2023-08-12 12:34:01,799 MainThread INFO: EPOCH:347
2023-08-12 12:34:01,799 MainThread INFO: Time Consumed:9.32829761505127s
2023-08-12 12:34:01,799 MainThread INFO: Total Frames:552000s
  3%|▎         | 348/10000 [52:40<25:04:40,  9.35s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1035.52599
Train_Epoch_Reward                    11371.75954
Running_Training_Average_Rewards      1052.42297
Explore_Time                          0.01587
Train___Time                          9.30713
Eval____Time                          0.00468
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.47597
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.97292
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.59283
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.15204
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.54398
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.74842
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.92029
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10902.07983
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.28638
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.12713
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.74468      1.29358     11.30878     3.46662
alpha_0                               3.38670      0.00606     3.40064      3.37975
alpha_1                               0.43279      0.00079     0.43403      0.43118
alpha_2                               0.16096      0.00114     0.16302      0.15906
alpha_3                               0.17333      0.00056     0.17445      0.17249
alpha_4                               0.09825      0.00042     0.09906      0.09758
alpha_5                               0.46994      0.00378     0.47565      0.46292
alpha_6                               0.15726      0.00093     0.15869      0.15543
alpha_7                               0.21196      0.00171     0.21475      0.20884
alpha_8                               0.22435      0.00277     0.22907      0.21972
alpha_9                               0.12960      0.00071     0.13079      0.12829
Alpha_loss                            -0.73721     0.14555     -0.39475     -1.08298
Training/policy_loss                  189.07937    20.43988    261.54599    131.10106
Training/qf1_loss                     4719.10922   1852.33753  11213.15527  2134.03369
Training/qf2_loss                     1613.89723   412.65880   3299.34302   1031.70862
Training/pf_norm                      19.98760     6.54658     40.36947     7.39495
Training/qf1_norm                     5863.32595   2634.88246  13328.90430  1823.93066
Training/qf2_norm                     4748.03643   2085.05400  11674.16406  1499.68530
log_std/mean                          -1.05290     0.00949     -1.02965     -1.07208
log_std/std                           0.51771      0.00610     0.53150      0.50357
log_std/max                           0.49534      0.09318     0.56925      0.05207
log_std/min                           -3.09750     0.24004     -2.74551     -3.83958
log_probs/mean                        3.55879      0.08957     3.73881      3.31470
log_probs/std                         3.32533      0.08497     3.58180      3.14065
log_probs/max                         20.79492     2.40536     30.22353     15.49843
log_probs/min                         -6.51775     1.36198     -3.95723     -10.28731
mean/mean                             0.04713      0.03335     0.11298      -0.03584
mean/std                              1.30319      0.01355     1.33960      1.27365
mean/max                              5.06601      0.41488     5.79574      3.91023
mean/min                              -6.13876     0.91359     -3.84323     -7.69512
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 1, 7, 8, 4, 9, 5, 2, 6, 3]
replay_buffer._size: [55500 55500 55500 55500 55500 55500 55500 55500 55500 55500]
2023-08-12 12:34:11,083 MainThread INFO: EPOCH:348
2023-08-12 12:34:11,084 MainThread INFO: Time Consumed:9.117356061935425s
2023-08-12 12:34:11,084 MainThread INFO: Total Frames:553500s
  3%|▎         | 349/10000 [52:50<25:02:43,  9.34s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1134.09867
Train_Epoch_Reward                    10147.06912
Running_Training_Average_Rewards      1030.54098
Explore_Time                          0.00478
Train___Time                          9.10802
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.66651
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.60808
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.50454
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1101.66335
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.59946
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.55111
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.90664
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10787.08836
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.37746
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.55119
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.70667      1.30884     10.47769     3.90802
alpha_0                               3.38303      0.00304     3.38866      3.37718
alpha_1                               0.42987      0.00086     0.43113      0.42816
alpha_2                               0.15706      0.00115     0.15902      0.15522
alpha_3                               0.17501      0.00025     0.17529      0.17447
alpha_4                               0.09730      0.00010     0.09757      0.09722
alpha_5                               0.46111      0.00135     0.46281      0.45817
alpha_6                               0.15391      0.00067     0.15539      0.15315
alpha_7                               0.20625      0.00145     0.20877      0.20364
alpha_8                               0.21669      0.00159     0.21964      0.21379
alpha_9                               0.12740      0.00044     0.12827      0.12681
Alpha_loss                            -0.51092     0.18159     -0.07428     -0.89512
Training/policy_loss                  191.96766    18.58705    232.06006    150.36433
Training/qf1_loss                     4789.02833   2059.00102  10838.05664  1444.32153
Training/qf2_loss                     1632.28644   426.39654   3184.32324   1009.52386
Training/pf_norm                      20.30966     8.47316     43.82008     8.14944
Training/qf1_norm                     6112.29484   2710.03019  16013.34473  1925.30847
Training/qf2_norm                     5385.62209   2197.60278  11546.34668  1604.05920
log_std/mean                          -1.06977     0.01275     -1.04205     -1.09996
log_std/std                           0.51590      0.00627     0.53337      0.50265
log_std/max                           0.49089      0.08487     0.58510      0.20434
log_std/min                           -3.20779     0.28996     -2.79118     -3.88590
log_probs/mean                        3.70786      0.12518     3.98835      3.45508
log_probs/std                         3.35633      0.10409     3.58358      3.09664
log_probs/max                         21.17489     3.22635     31.67394     15.48482
log_probs/min                         -6.43317     1.27884     -4.02708     -11.88577
mean/mean                             0.08283      0.03271     0.16034      -0.00317
mean/std                              1.31402      0.01925     1.35707      1.26099
mean/max                              4.98801      0.46541     5.70838      3.69345
mean/min                              -5.90363     0.85012     -4.15361     -7.50979
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 4, 9, 2, 6, 7, 0, 1, 3, 5]
replay_buffer._size: [55650 55650 55650 55650 55650 55650 55650 55650 55650 55650]
2023-08-12 12:34:20,878 MainThread INFO: EPOCH:349
2023-08-12 12:34:20,878 MainThread INFO: Time Consumed:9.627636671066284s
2023-08-12 12:34:20,878 MainThread INFO: Total Frames:555000s
  4%|▎         | 350/10000 [53:00<25:22:51,  9.47s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1228.52777
Train_Epoch_Reward                    9791.14294
Running_Training_Average_Rewards      1043.66572
Explore_Time                          0.02045
Train___Time                          9.60252
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.92682
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.37884
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.00939
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2172.65132
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.20182
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.20142
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.92726
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10660.10867
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.17204
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.66472
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61965      1.43303     10.14313     3.19368
alpha_0                               3.38918      0.00262     3.39506      3.38444
alpha_1                               0.42501      0.00120     0.42812      0.42336
alpha_2                               0.15315      0.00123     0.15519      0.15101
alpha_3                               0.17503      0.00018     0.17525      0.17452
alpha_4                               0.09770      0.00035     0.09840      0.09724
alpha_5                               0.45591      0.00152     0.45811      0.45183
alpha_6                               0.15377      0.00034     0.15427      0.15320
alpha_7                               0.20171      0.00101     0.20360      0.20000
alpha_8                               0.20997      0.00226     0.21372      0.20591
alpha_9                               0.12638      0.00020     0.12681      0.12619
Alpha_loss                            -0.36696     0.20256     0.11332      -0.88529
Training/policy_loss                  187.78125    21.08732    253.84151    105.50249
Training/qf1_loss                     4895.04278   2272.57727  13204.28613  1569.59656
Training/qf2_loss                     1543.11423   405.90599   3228.24194   920.53174
Training/pf_norm                      18.13819     6.90817     36.55384     7.65118
Training/qf1_norm                     6882.24738   3009.17692  16353.93652  2086.10815
Training/qf2_norm                     5501.71994   2780.18808  15392.03613  1632.02686
log_std/mean                          -1.05751     0.01172     -1.03310     -1.08078
log_std/std                           0.51587      0.00823     0.53377      0.49582
log_std/max                           0.45633      0.05074     0.51410      0.25485
log_std/min                           -3.17057     0.26905     -2.84127     -3.93597
log_probs/mean                        3.75336      0.14229     4.13764      3.39796
log_probs/std                         3.37533      0.10659     3.61043      3.06920
log_probs/max                         20.26975     3.07678     31.28606     15.64511
log_probs/min                         -6.32673     1.10399     -4.15218     -9.15796
mean/mean                             0.08308      0.03354     0.17737      0.00381
mean/std                              1.32595      0.02090     1.37781      1.27796
mean/max                              4.83916      0.48947     5.70738      3.80637
mean/min                              -5.71601     0.70995     -3.98503     -7.17094
------------------------------------  -----------  ----------  -----------  ----------
start to update mask
sample: [5, 6, 0, 2, 4, 3, 7, 8, 9, 1]
replay_buffer._size: [55800 55800 55800 55800 55800 55800 55800 55800 55800 55800]
2023-08-12 12:34:29,700 MainThread INFO: EPOCH:350
2023-08-12 12:34:29,700 MainThread INFO: Time Consumed:7.2719244956970215s
2023-08-12 12:34:29,700 MainThread INFO: Total Frames:556500s
  4%|▎         | 351/10000 [53:08<24:52:34,  9.28s/it]------------------------------------  -----------  -----------  ------------  ----------
Name                                  Value
Running_Average_Rewards               1065.94730
Train_Epoch_Reward                    10500.98148
Running_Training_Average_Rewards      1014.63978
Explore_Time                          0.00472
Train___Time                          7.26201
Eval____Time                          0.00454
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.14749
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.68478
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.03536
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.09804
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.19981
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.78880
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.05325
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11180.52282
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.69495
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.34733
mean_success_rate                     0.00000

Name                                  Mean         Std          Max           Min
Reward_Mean                           6.59573      1.40044      10.00666      2.78769
alpha_0                               3.48365      0.06767      3.56961       3.38426
alpha_1                               0.42709      0.00588      0.44273       0.42286
alpha_2                               0.14937      0.00085      0.15096       0.14825
alpha_3                               0.17577      0.00261      0.18264       0.17321
alpha_4                               0.09865      0.00018      0.09899       0.09835
alpha_5                               0.46531      0.01575      0.49775       0.45066
alpha_6                               0.15538      0.00060      0.15657       0.15414
alpha_7                               0.20527      0.00397      0.21210       0.19998
alpha_8                               0.20090      0.00313      0.20582       0.19578
alpha_9                               0.13250      0.00421      0.13914       0.12623
Alpha_loss                            1.40375      0.96346      3.12625       0.14902
Training/policy_loss                  275.10775    25.37811     346.42358     221.17632
Training/qf1_loss                     17861.50556  11973.42152  50548.69141   5162.87891
Training/qf2_loss                     4566.75316   3344.09405   15541.43164   1696.53406
Training/pf_norm                      72.01073     46.74372     214.92404     16.57294
Training/qf1_norm                     47516.92528  49816.60506  165407.85938  5515.24268
Training/qf2_norm                     33264.22448  36048.34174  156562.34375  4385.24902
log_std/mean                          -1.00702     0.05001      -0.94101      -1.10122
log_std/std                           0.48059      0.02492      0.52267       0.42874
log_std/max                           0.69399      0.22901      1.05913       0.00943
log_std/min                           -3.21351     0.28275      -2.52580      -3.78950
log_probs/mean                        5.21662      0.73823      6.49915       4.20895
log_probs/std                         4.37919      0.28605      4.82602       3.67794
log_probs/max                         25.45474     2.40524      33.74277      20.09875
log_probs/min                         -6.25791     1.37528      -3.69771      -11.37870
mean/mean                             0.19971      0.33157      0.69308       -0.23499
mean/std                              1.60192      0.10986      1.76535       1.41161
mean/max                              5.91482      0.80319      7.24075       4.48425
mean/min                              -6.39382     0.73341      -4.21943      -7.86634
------------------------------------  -----------  -----------  ------------  ----------
sample: [6, 2, 0, 7, 4, 3, 9, 8, 5, 1]
replay_buffer._size: [55950 55950 55950 55950 55950 55950 55950 55950 55950 55950]
2023-08-12 12:34:38,093 MainThread INFO: EPOCH:351
2023-08-12 12:34:38,093 MainThread INFO: Time Consumed:8.182945489883423s
2023-08-12 12:34:38,093 MainThread INFO: Total Frames:558000s
  4%|▎         | 352/10000 [53:17<24:08:28,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1076.38558
Train_Epoch_Reward                    10821.94760
Running_Training_Average_Rewards      1037.13573
Explore_Time                          0.01374
Train___Time                          8.16094
Eval____Time                          0.00761
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.34126
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.83487
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.49528
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.54332
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.60750
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.63987
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.39937
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11290.81993
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.51889
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.58374
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.44249      1.32315     10.45314     3.91105
alpha_0                               3.58983      0.00540     3.59780      3.57130
alpha_1                               0.45308      0.00303     0.45544      0.44323
alpha_2                               0.15018      0.00037     0.15049      0.14899
alpha_3                               0.18801      0.00200     0.19018      0.18285
alpha_4                               0.10223      0.00251     0.10683      0.09901
alpha_5                               0.51543      0.00649     0.52107      0.49842
alpha_6                               0.16390      0.00458     0.17238      0.15666
alpha_7                               0.22004      0.00439     0.22755      0.21226
alpha_8                               0.19525      0.00041     0.19642      0.19472
alpha_9                               0.14360      0.00263     0.14846      0.13924
Alpha_loss                            2.63900      0.26765     3.35493      2.04629
Training/policy_loss                  260.27268    19.12639    306.62460    217.53239
Training/qf1_loss                     6965.32378   1898.75195  12243.03809  3355.90283
Training/qf2_loss                     1902.58471   380.82663   3173.29858   1378.85779
Training/pf_norm                      24.24196     10.01187    67.12170     9.39637
Training/qf1_norm                     7472.70741   3077.74176  15675.47363  2433.70776
Training/qf2_norm                     5839.82271   2213.02863  13909.93750  2287.76440
log_std/mean                          -0.95550     0.01465     -0.91583     -0.98275
log_std/std                           0.43912      0.00973     0.46043      0.41437
log_std/max                           0.86707      0.12105     1.07186      0.44444
log_std/min                           -3.06001     0.30878     -2.50046     -3.91318
log_probs/mean                        5.53558      0.28562     6.40284      5.12207
log_probs/std                         4.06761      0.17491     4.51993      3.73728
log_probs/max                         23.02208     3.30385     34.79955     17.78846
log_probs/min                         -6.29158     1.47122     -3.64993     -10.48222
mean/mean                             0.32443      0.16517     0.64870      0.12473
mean/std                              1.68638      0.02384     1.75311      1.63336
mean/max                              6.20292      0.56783     7.24695      5.23982
mean/min                              -5.95960     0.47993     -4.71698     -7.03692
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 8, 7, 9, 2, 0, 1, 4, 6, 3]
replay_buffer._size: [56100 56100 56100 56100 56100 56100 56100 56100 56100 56100]
2023-08-12 12:34:46,577 MainThread INFO: EPOCH:352
2023-08-12 12:34:46,578 MainThread INFO: Time Consumed:8.283164978027344s
2023-08-12 12:34:46,578 MainThread INFO: Total Frames:559500s
  4%|▎         | 353/10000 [53:25<23:44:39,  8.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1248.51238
Train_Epoch_Reward                    10712.08119
Running_Training_Average_Rewards      1067.83368
Explore_Time                          0.00503
Train___Time                          8.27326
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.41068
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -16.50021
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.20297
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.30261
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.59614
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.15161
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.78961
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12969.39407
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.89854
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -73.41787
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.51139      1.14251     10.52832     4.01010
alpha_0                               3.60097      0.00248     3.60588      3.59707
alpha_1                               0.45672      0.00213     0.46132      0.45406
alpha_2                               0.15027      0.00028     0.15058      0.14970
alpha_3                               0.19027      0.00048     0.19082      0.18928
alpha_4                               0.11087      0.00218     0.11425      0.10692
alpha_5                               0.51247      0.00324     0.51868      0.50756
alpha_6                               0.18078      0.00435     0.18769      0.17258
alpha_7                               0.23742      0.00619     0.24772      0.22770
alpha_8                               0.20161      0.00341     0.20745      0.19648
alpha_9                               0.15387      0.00306     0.15897      0.14857
Alpha_loss                            2.80021      0.30492     3.29653      1.89695
Training/policy_loss                  252.06965    17.91175    287.13248    210.83653
Training/qf1_loss                     6608.71192   1808.00469  13296.36230  3343.73755
Training/qf2_loss                     1721.36739   402.58909   3724.85596   1088.18127
Training/pf_norm                      26.36367     12.03686    64.46527     10.39543
Training/qf1_norm                     6693.40558   2966.68876  15239.37891  2569.96802
Training/qf2_norm                     6588.71230   2665.15349  14735.63086  2140.27588
log_std/mean                          -0.95916     0.01338     -0.92610     -0.97896
log_std/std                           0.44804      0.00732     0.47072      0.43091
log_std/max                           0.88115      0.10066     0.96218      0.40592
log_std/min                           -3.12512     0.33820     -2.52892     -3.76238
log_probs/mean                        5.51518      0.14626     5.85201      5.10201
log_probs/std                         4.26793      0.13867     4.60787      3.93930
log_probs/max                         24.06751     4.10535     34.44846     18.49421
log_probs/min                         -6.12369     1.43239     -3.87038     -12.40889
mean/mean                             0.18676      0.02906     0.24864      0.10432
mean/std                              1.70262      0.02382     1.74715      1.64230
mean/max                              6.01339      0.60704     6.81700      5.03394
mean/min                              -5.89055     0.44598     -4.86460     -6.73893
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 3, 9, 6, 5, 4, 7, 2, 1]
replay_buffer._size: [56250 56250 56250 56250 56250 56250 56250 56250 56250 56250]
2023-08-12 12:34:55,731 MainThread INFO: EPOCH:353
2023-08-12 12:34:55,732 MainThread INFO: Time Consumed:8.976007223129272s
2023-08-12 12:34:55,732 MainThread INFO: Total Frames:561000s
  4%|▎         | 354/10000 [53:34<23:57:13,  8.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1047.81899
Train_Epoch_Reward                    15221.28720
Running_Training_Average_Rewards      1225.17720
Explore_Time                          0.01515
Train___Time                          8.95501
Eval____Time                          0.00475
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.84138
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.24011
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.99352
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.15802
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.18184
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.51369
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.77188
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11018.59964
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.20256
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.50676
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.40522      1.18856     9.52044      3.55148
alpha_0                               3.61308      0.00371     3.62313      3.60610
alpha_1                               0.47108      0.00618     0.48188      0.46146
alpha_2                               0.14943      0.00015     0.14969      0.14906
alpha_3                               0.18907      0.00015     0.18928      0.18885
alpha_4                               0.11588      0.00081     0.11727      0.11430
alpha_5                               0.50483      0.00134     0.50748      0.50253
alpha_6                               0.19367      0.00344     0.19951      0.18780
alpha_7                               0.25464      0.00377     0.26127      0.24790
alpha_8                               0.21129      0.00176     0.21381      0.20756
alpha_9                               0.16297      0.00214     0.16650      0.15906
Alpha_loss                            2.01448      0.21047     2.55731      1.41418
Training/policy_loss                  248.19609    18.62499    295.46860    204.12892
Training/qf1_loss                     6251.98728   2329.02897  13040.24121  2406.29663
Training/qf2_loss                     1548.96166   387.60860   3183.99097   1084.36194
Training/pf_norm                      37.44067     22.14785    109.80418    7.07814
Training/qf1_norm                     6942.05525   3862.64684  24075.55859  2814.23901
Training/qf2_norm                     5740.71327   2492.95273  12204.26270  2115.32202
log_std/mean                          -0.99306     0.01198     -0.96367     -1.01731
log_std/std                           0.45477      0.00801     0.47203      0.43679
log_std/max                           0.76425      0.11693     0.92964      0.21250
log_std/min                           -3.15136     0.31395     -2.53953     -3.95446
log_probs/mean                        5.24256      0.12015     5.52697      4.97669
log_probs/std                         3.99303      0.07391     4.18048      3.81171
log_probs/max                         22.37119     2.32079     27.78767     16.77453
log_probs/min                         -6.15415     1.38367     -2.77794     -10.27789
mean/mean                             0.22975      0.02790     0.29036      0.16828
mean/std                              1.62824      0.01960     1.68819      1.58057
mean/max                              5.98470      0.61168     6.70547      4.89226
mean/min                              -6.41447     0.56265     -4.52442     -7.50099
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 5, 9, 4, 2, 7, 1, 0, 8]
replay_buffer._size: [56400 56400 56400 56400 56400 56400 56400 56400 56400 56400]
2023-08-12 12:35:04,738 MainThread INFO: EPOCH:354
2023-08-12 12:35:04,739 MainThread INFO: Time Consumed:8.843739032745361s
2023-08-12 12:35:04,739 MainThread INFO: Total Frames:562500s
  4%|▎         | 355/10000 [53:43<24:00:08,  8.96s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1037.53473
Train_Epoch_Reward                    9104.52637
Running_Training_Average_Rewards      1167.92983
Explore_Time                          0.00922
Train___Time                          8.82953
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.52167
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.47190
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.51451
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.71324
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.58517
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.99085
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.46771
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10986.76401
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.85472
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.29692
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.74980      1.49885     10.72631     3.56066
alpha_0                               3.62698      0.00211     3.62996      3.62333
alpha_1                               0.49215      0.00584     0.50200      0.48207
alpha_2                               0.14821      0.00050     0.14904      0.14738
alpha_3                               0.18912      0.00016     0.18929      0.18874
alpha_4                               0.11902      0.00107     0.12084      0.11730
alpha_5                               0.50001      0.00154     0.50248      0.49718
alpha_6                               0.20508      0.00308     0.21017      0.19963
alpha_7                               0.26800      0.00379     0.27415      0.26139
alpha_8                               0.21412      0.00041     0.21460      0.21317
alpha_9                               0.16958      0.00170     0.17235      0.16657
Alpha_loss                            1.67204      0.24109     2.29251      1.04174
Training/policy_loss                  242.93604    20.50475    299.60001    194.46922
Training/qf1_loss                     6187.78320   2161.33983  12919.25488  2246.87280
Training/qf2_loss                     1519.64230   422.96015   2868.35522   874.65979
Training/pf_norm                      25.42415     9.88060     49.02070     8.66879
Training/qf1_norm                     7313.13371   3117.84355  15735.39551  3010.38965
Training/qf2_norm                     5426.22938   2273.81379  13901.19336  1434.49634
log_std/mean                          -0.97628     0.01143     -0.95380     -0.99969
log_std/std                           0.47170      0.00644     0.48377      0.45224
log_std/max                           0.67239      0.07896     0.77123      0.23209
log_std/min                           -3.10611     0.27531     -2.52456     -4.00400
log_probs/mean                        5.04846      0.17071     5.46511      4.64050
log_probs/std                         3.98302      0.08929     4.25407      3.73860
log_probs/max                         21.36199     2.15416     28.88918     16.78908
log_probs/min                         -6.43622     1.72040     -4.01616     -13.92195
mean/mean                             0.22249      0.03145     0.28808      0.14964
mean/std                              1.60083      0.02284     1.66168      1.54511
mean/max                              5.81560      0.35836     6.21943      4.92102
mean/min                              -6.36310     0.63292     -4.41261     -7.52139
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 8, 5, 7, 1, 4, 0, 6, 3]
replay_buffer._size: [56550 56550 56550 56550 56550 56550 56550 56550 56550 56550]
2023-08-12 12:35:13,349 MainThread INFO: EPOCH:355
2023-08-12 12:35:13,349 MainThread INFO: Time Consumed:8.417679071426392s
2023-08-12 12:35:13,349 MainThread INFO: Total Frames:564000s
  4%|▎         | 356/10000 [53:52<23:47:07,  8.88s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1221.84806
Train_Epoch_Reward                    10590.06689
Running_Training_Average_Rewards      1163.86268
Explore_Time                          0.00458
Train___Time                          8.40795
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.79301
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.90806
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.37047
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           1651.77870
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.24951
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.55654
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.69894
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11155.26776
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.88412
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.10525
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.65691      1.39611     10.60459     2.17405
alpha_0                               3.62322      0.00794     3.63145      3.60845
alpha_1                               0.51001      0.00460     0.51789      0.50218
alpha_2                               0.14633      0.00062     0.14736      0.14533
alpha_3                               0.18836      0.00020     0.18874      0.18802
alpha_4                               0.12282      0.00118     0.12494      0.12088
alpha_5                               0.49306      0.00251     0.49710      0.48843
alpha_6                               0.21520      0.00286     0.21997      0.21027
alpha_7                               0.27836      0.00219     0.28171      0.27426
alpha_8                               0.21051      0.00162     0.21313      0.20738
alpha_9                               0.17473      0.00128     0.17688      0.17240
Alpha_loss                            1.27479      0.16534     1.64362      0.86304
Training/policy_loss                  240.84397    20.21032    294.34692    172.26512
Training/qf1_loss                     5494.62881   1965.59588  12449.01270  2071.22632
Training/qf2_loss                     1432.59144   345.13943   2890.59741   915.19061
Training/pf_norm                      27.87912     10.89015    61.24390     9.03627
Training/qf1_norm                     6590.29917   3010.61522  16029.07520  2005.84265
Training/qf2_norm                     5345.66780   2418.60751  16605.71875  1778.70630
log_std/mean                          -0.96327     0.00734     -0.94755     -0.98113
log_std/std                           0.47645      0.00488     0.48743      0.46263
log_std/max                           0.64567      0.13377     0.79325      0.20360
log_std/min                           -3.13084     0.30703     -2.54702     -4.00496
log_probs/mean                        4.75414      0.11672     5.00806      4.46991
log_probs/std                         3.96172      0.08471     4.16597      3.72090
log_probs/max                         21.03306     1.97099     26.47253     17.08294
log_probs/min                         -6.44496     1.33842     -4.51222     -11.30620
mean/mean                             0.23501      0.03136     0.31356      0.15078
mean/std                              1.55777      0.01662     1.59884      1.51974
mean/max                              5.76743      0.58084     6.58146      4.71621
mean/min                              -6.13249     0.49170     -4.51426     -6.93679
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 5, 1, 4, 2, 9, 3, 6, 0, 7]
replay_buffer._size: [56700 56700 56700 56700 56700 56700 56700 56700 56700 56700]
2023-08-12 12:35:21,898 MainThread INFO: EPOCH:356
2023-08-12 12:35:21,899 MainThread INFO: Time Consumed:8.37064266204834s
2023-08-12 12:35:21,899 MainThread INFO: Total Frames:565500s
  4%|▎         | 357/10000 [54:01<23:27:36,  8.76s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1107.25174
Train_Epoch_Reward                    13213.58222
Running_Training_Average_Rewards      1096.93918
Explore_Time                          0.01218
Train___Time                          8.35345
Eval____Time                          0.00423
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.69164
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.34030
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.89477
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           939.63874
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.73449
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.23752
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.49892
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10706.32088
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.90033
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.14427
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.67997      1.31209     10.00054     4.26226
alpha_0                               3.59901      0.00480     3.60930      3.59125
alpha_1                               0.52655      0.00485     0.53488      0.51806
alpha_2                               0.14436      0.00054     0.14531      0.14348
alpha_3                               0.18844      0.00041     0.18927      0.18798
alpha_4                               0.12760      0.00159     0.13041      0.12499
alpha_5                               0.48297      0.00321     0.48832      0.47723
alpha_6                               0.22456      0.00257     0.22884      0.22006
alpha_7                               0.28285      0.00037     0.28318      0.28177
alpha_8                               0.20452      0.00159     0.20730      0.20138
alpha_9                               0.17908      0.00129     0.18124      0.17692
Alpha_loss                            1.15713      0.16837     1.51184      0.73756
Training/policy_loss                  236.76256    22.53411    290.61197    162.88744
Training/qf1_loss                     5389.81642   1750.26079  10089.74219  2453.11816
Training/qf2_loss                     1430.93505   362.48917   2615.78223   806.39502
Training/pf_norm                      24.49837     12.23735    61.14190     8.32304
Training/qf1_norm                     5978.00905   2689.30068  17414.01758  2125.59814
Training/qf2_norm                     5555.11302   2221.20266  12365.26953  2031.93262
log_std/mean                          -0.98259     0.00873     -0.96153     -1.00287
log_std/std                           0.48673      0.00509     0.49919      0.47600
log_std/max                           0.58221      0.14359     0.72577      0.20684
log_std/min                           -3.07495     0.32481     -2.57819     -3.96882
log_probs/mean                        4.64319      0.12846     4.95991      4.30746
log_probs/std                         3.96106      0.10093     4.18505      3.70729
log_probs/max                         21.46660     1.66093     27.70475     18.43256
log_probs/min                         -6.26956     1.45879     -3.48606     -12.04831
mean/mean                             0.20052      0.03355     0.28729      0.12711
mean/std                              1.53550      0.01807     1.56701      1.48725
mean/max                              5.76409      0.69278     6.79977      4.60467
mean/min                              -5.81056     0.40198     -4.64438     -6.50780
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 7, 5, 8, 9, 2, 3, 1, 6, 4]
replay_buffer._size: [56850 56850 56850 56850 56850 56850 56850 56850 56850 56850]
2023-08-12 12:35:30,864 MainThread INFO: EPOCH:357
2023-08-12 12:35:30,865 MainThread INFO: Time Consumed:8.806115865707397s
2023-08-12 12:35:30,865 MainThread INFO: Total Frames:567000s
  4%|▎         | 358/10000 [54:10<23:37:09,  8.82s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1018.78886
Train_Epoch_Reward                    9565.75507
Running_Training_Average_Rewards      1112.31347
Explore_Time                          0.01607
Train___Time                          8.78445
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.06447
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.96159
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.22315
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.57413
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.24593
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.58265
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.84794
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10765.78238
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.77059
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.62338
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.72965      1.23969     10.64907     3.65135
alpha_0                               3.57453      0.01004     3.59072      3.55226
alpha_1                               0.54142      0.00327     0.54704      0.53504
alpha_2                               0.14321      0.00012     0.14351      0.14308
alpha_3                               0.19009      0.00047     0.19078      0.18928
alpha_4                               0.13302      0.00145     0.13545      0.13047
alpha_5                               0.47085      0.00360     0.47711      0.46472
alpha_6                               0.23259      0.00200     0.23573      0.22892
alpha_7                               0.28000      0.00160     0.28252      0.27707
alpha_8                               0.19735      0.00222     0.20129      0.19357
alpha_9                               0.18341      0.00128     0.18567      0.18128
Alpha_loss                            0.87250      0.15255     1.35717      0.55923
Training/policy_loss                  234.12045    18.73158    274.57056    184.19049
Training/qf1_loss                     5242.27269   1768.70134  12755.35059  2031.25000
Training/qf2_loss                     1424.56694   364.93268   3205.12378   934.55225
Training/pf_norm                      21.11739     8.63520     46.77405     7.05930
Training/qf1_norm                     6380.93499   2934.80619  19285.96484  2184.44385
Training/qf2_norm                     5278.51797   2212.44418  14702.68457  1583.70520
log_std/mean                          -0.97187     0.00688     -0.95617     -0.99338
log_std/std                           0.48428      0.00721     0.49858      0.46808
log_std/max                           0.45754      0.15007     0.69044      0.10205
log_std/min                           -2.93438     0.22061     -2.59130     -3.69640
log_probs/mean                        4.40843      0.11752     4.76648      4.16645
log_probs/std                         3.84935      0.11015     4.17576      3.59681
log_probs/max                         21.10248     1.21560     24.34797     19.13250
log_probs/min                         -6.60838     1.37200     -4.05529     -11.54687
mean/mean                             0.17124      0.03688     0.24676      0.08312
mean/std                              1.50518      0.02020     1.55586      1.46130
mean/max                              5.65957      0.62109     6.72745      3.99926
mean/min                              -5.83512     0.29024     -4.82474     -6.32282
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 1, 8, 5, 0, 6, 9, 2, 7, 3]
replay_buffer._size: [57000 57000 57000 57000 57000 57000 57000 57000 57000 57000]
2023-08-12 12:35:40,189 MainThread INFO: EPOCH:358
2023-08-12 12:35:40,189 MainThread INFO: Time Consumed:9.128499507904053s
2023-08-12 12:35:40,189 MainThread INFO: Total Frames:568500s
  4%|▎         | 359/10000 [54:19<24:08:55,  9.02s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1077.51158
Train_Epoch_Reward                    8753.23434
Running_Training_Average_Rewards      1051.08572
Explore_Time                          0.01809
Train___Time                          9.10563
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.10949
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.83835
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.17220
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -9.58742
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.19371
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.88017
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.69326
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11349.30285
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.00359
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.70882
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.93957      1.34566     10.73806     4.08707
alpha_0                               3.53264      0.00865     3.55141      3.52347
alpha_1                               0.55095      0.00190     0.55346      0.54715
alpha_2                               0.14443      0.00062     0.14560      0.14353
alpha_3                               0.19106      0.00013     0.19125      0.19079
alpha_4                               0.13781      0.00136     0.14021      0.13549
alpha_5                               0.45912      0.00304     0.46459      0.45410
alpha_6                               0.23850      0.00155     0.24116      0.23580
alpha_7                               0.27377      0.00186     0.27700      0.27074
alpha_8                               0.18883      0.00277     0.19348      0.18429
alpha_9                               0.18818      0.00146     0.19073      0.18572
Alpha_loss                            0.77155      0.18625     1.36096      0.40567
Training/policy_loss                  226.67756    18.67874    272.96759    174.07608
Training/qf1_loss                     5401.39639   1973.47500  11609.97949  2125.40088
Training/qf2_loss                     1500.91208   402.84885   3272.97778   839.99213
Training/pf_norm                      19.61913     7.91154     39.54176     7.99720
Training/qf1_norm                     6166.74791   2983.79869  15158.64844  2172.16797
Training/qf2_norm                     5824.88939   2751.81832  14956.12305  2077.72461
log_std/mean                          -0.99208     0.01423     -0.95973     -1.01888
log_std/std                           0.46891      0.00893     0.48687      0.44935
log_std/max                           0.39820      0.12391     0.57042      0.13720
log_std/min                           -3.01092     0.25226     -2.71693     -3.66311
log_probs/mean                        4.35576      0.13069     4.64759      4.09354
log_probs/std                         3.72511      0.10833     3.93443      3.35031
log_probs/max                         20.61961     1.05056     25.32395     18.26794
log_probs/min                         -6.23179     1.31298     -4.26372     -11.49019
mean/mean                             0.18577      0.04606     0.29062      0.10072
mean/std                              1.47838      0.01826     1.51934      1.43412
mean/max                              5.41245      0.61690     6.42250      4.24091
mean/min                              -5.76170     0.27122     -4.86151     -6.06067
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 6, 4, 8, 9, 3, 5, 0, 1]
replay_buffer._size: [57150 57150 57150 57150 57150 57150 57150 57150 57150 57150]
2023-08-12 12:35:49,460 MainThread INFO: EPOCH:359
2023-08-12 12:35:49,461 MainThread INFO: Time Consumed:9.007306575775146s
2023-08-12 12:35:49,461 MainThread INFO: Total Frames:570000s
  4%|▎         | 360/10000 [54:28<24:14:45,  9.05s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1326.08221
Train_Epoch_Reward                    13706.19362
Running_Training_Average_Rewards      1067.50610
Explore_Time                          0.00529
Train___Time                          8.99641
Eval____Time                          0.00467
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.76290
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.47714
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.45851
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2250.68525
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.95058
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.13370
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.39708
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11567.09808
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.76119
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.02013
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.52130      1.47985     10.45782     3.76691
alpha_0                               3.49955      0.01477     3.52327      3.47457
alpha_1                               0.55408      0.00025     0.55443      0.55348
alpha_2                               0.14664      0.00060     0.14767      0.14563
alpha_3                               0.19078      0.00015     0.19105      0.19056
alpha_4                               0.14293      0.00152     0.14548      0.14026
alpha_5                               0.44955      0.00268     0.45400      0.44475
alpha_6                               0.24336      0.00112     0.24515      0.24122
alpha_7                               0.26875      0.00119     0.27069      0.26654
alpha_8                               0.17959      0.00279     0.18420      0.17478
alpha_9                               0.19339      0.00149     0.19589      0.19079
Alpha_loss                            0.65619      0.19574     1.30335      0.30907
Training/policy_loss                  232.01583    18.45596    271.98383    184.73683
Training/qf1_loss                     4972.12138   1564.11398  10529.93262  2521.63818
Training/qf2_loss                     1419.12453   340.43713   2685.39526   858.78876
Training/pf_norm                      18.23273     7.27906     44.06133     7.86421
Training/qf1_norm                     6389.43273   2656.27176  13917.89844  1751.84290
Training/qf2_norm                     5396.66168   2353.24996  14686.45605  1393.61719
log_std/mean                          -0.98952     0.01359     -0.96337     -1.01344
log_std/std                           0.45806      0.00623     0.47211      0.44210
log_std/max                           0.37332      0.08696     0.50818      0.08494
log_std/min                           -3.05828     0.21385     -2.81161     -3.57393
log_probs/mean                        4.26752      0.12828     4.59332      4.01464
log_probs/std                         3.70463      0.11143     3.98952      3.35218
log_probs/max                         20.93110     1.22806     25.63948     18.50338
log_probs/min                         -6.85557     1.49765     -4.01679     -11.93184
mean/mean                             0.21001      0.03213     0.28418      0.14291
mean/std                              1.46547      0.01767     1.50187      1.40911
mean/max                              5.53400      0.65313     6.38695      3.97405
mean/min                              -5.66682     0.33076     -4.81942     -6.02210
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 7, 9, 1, 0, 8, 2, 5, 3, 4]
replay_buffer._size: [57300 57300 57300 57300 57300 57300 57300 57300 57300 57300]
2023-08-12 12:35:58,386 MainThread INFO: EPOCH:360
2023-08-12 12:35:58,386 MainThread INFO: Time Consumed:8.749155044555664s
2023-08-12 12:35:58,387 MainThread INFO: Total Frames:571500s
  4%|▎         | 361/10000 [54:37<24:07:07,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1100.60378
Train_Epoch_Reward                    10627.06242
Running_Training_Average_Rewards      1102.88301
Explore_Time                          0.00539
Train___Time                          8.73891
Eval____Time                          0.00413
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.95482
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.70889
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.14864
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.61712
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.41659
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.40845
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.01253
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11580.25557
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.15368
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.79701
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89637      1.23598     9.93314      3.79099
alpha_0                               3.45921      0.00955     3.47475      3.44747
alpha_1                               0.55193      0.00097     0.55397      0.55037
alpha_2                               0.14837      0.00036     0.14886      0.14769
alpha_3                               0.19048      0.00030     0.19092      0.19000
alpha_4                               0.14832      0.00168     0.15121      0.14553
alpha_5                               0.43957      0.00269     0.44465      0.43499
alpha_6                               0.24687      0.00097     0.24844      0.24519
alpha_7                               0.26462      0.00098     0.26649      0.26317
alpha_8                               0.17041      0.00229     0.17468      0.16672
alpha_9                               0.19829      0.00139     0.20062      0.19593
Alpha_loss                            0.52846      0.18871     1.14372      -0.03737
Training/policy_loss                  224.88395    16.53231    262.14297    180.92688
Training/qf1_loss                     5226.09133   2074.24497  11363.34863  1590.27344
Training/qf2_loss                     1452.89783   427.34243   3069.14526   839.91766
Training/pf_norm                      19.75367     7.80884     46.88767     8.68438
Training/qf1_norm                     6284.91780   2882.15129  17800.85547  2112.96021
Training/qf2_norm                     5045.77776   2212.05827  14194.27051  1738.00879
log_std/mean                          -0.97363     0.01461     -0.94128     -1.00168
log_std/std                           0.45338      0.00461     0.46464      0.44235
log_std/max                           0.41145      0.08065     0.54649      0.15357
log_std/min                           -3.00621     0.19584     -2.76051     -3.34648
log_probs/mean                        4.20789      0.13265     4.54283      3.79388
log_probs/std                         3.80861      0.10048     4.12503      3.54108
log_probs/max                         21.87846     0.91970     26.75029     18.98531
log_probs/min                         -6.46619     1.20562     -3.99948     -10.58870
mean/mean                             0.18537      0.03900     0.26277      0.08199
mean/std                              1.47265      0.01729     1.52206      1.42954
mean/max                              5.54701      0.50544     6.26347      4.60872
mean/min                              -5.73579     0.32753     -4.83762     -6.15963
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 2, 3, 6, 5, 7, 4, 1, 0, 8]
replay_buffer._size: [57450 57450 57450 57450 57450 57450 57450 57450 57450 57450]
2023-08-12 12:36:07,426 MainThread INFO: EPOCH:361
2023-08-12 12:36:07,427 MainThread INFO: Time Consumed:8.864266157150269s
2023-08-12 12:36:07,427 MainThread INFO: Total Frames:573000s
  4%|▎         | 362/10000 [54:46<24:10:55,  9.03s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1344.12543
Train_Epoch_Reward                    10843.19294
Running_Training_Average_Rewards      1172.54830
Explore_Time                          0.01415
Train___Time                          8.84490
Eval____Time                          0.00410
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.03475
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.14768
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.49452
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2445.23360
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.89113
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.94948
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.79872
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11520.68560
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.04530
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.30336
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.71331      1.59706     10.78346     3.49011
alpha_0                               3.43627      0.01320     3.45037      3.40978
alpha_1                               0.54634      0.00252     0.55031      0.54184
alpha_2                               0.14932      0.00024     0.14957      0.14886
alpha_3                               0.18812      0.00140     0.18998      0.18520
alpha_4                               0.15414      0.00171     0.15714      0.15127
alpha_5                               0.42996      0.00276     0.43488      0.42541
alpha_6                               0.24961      0.00067     0.25066      0.24845
alpha_7                               0.26159      0.00092     0.26314      0.26010
alpha_8                               0.16309      0.00193     0.16664      0.16021
alpha_9                               0.20307      0.00147     0.20572      0.20067
Alpha_loss                            0.41372      0.18583     0.86530      -0.11159
Training/policy_loss                  224.29559    22.33642    271.95071    163.48103
Training/qf1_loss                     4833.90538   1623.77045  10047.09277  2151.11206
Training/qf2_loss                     1435.24531   368.37583   2804.37622   882.36981
Training/pf_norm                      17.93297     5.87327     31.73536     8.56581
Training/qf1_norm                     6745.73091   3118.99166  18841.49609  2116.28052
Training/qf2_norm                     5200.09450   2163.89287  11467.59375  2020.54993
log_std/mean                          -0.94997     0.01296     -0.91871     -0.98075
log_std/std                           0.44523      0.00501     0.45555      0.43524
log_std/max                           0.37468      0.07902     0.52535      0.15680
log_std/min                           -3.01577     0.19954     -2.77545     -3.36942
log_probs/mean                        4.11857      0.12004     4.36723      3.88466
log_probs/std                         3.81329      0.09766     4.05705      3.55989
log_probs/max                         21.71562     0.95636     25.81254     19.74117
log_probs/min                         -6.68126     1.45262     -4.27277     -11.50021
mean/mean                             0.21890      0.03572     0.30469      0.12608
mean/std                              1.46373      0.01830     1.50883      1.42620
mean/max                              5.47265      0.56898     6.31153      4.33323
mean/min                              -5.64944     0.35639     -4.78087     -6.09684
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 7, 9, 2, 3, 0, 6, 1, 4, 5]
replay_buffer._size: [57600 57600 57600 57600 57600 57600 57600 57600 57600 57600]
2023-08-12 12:36:16,319 MainThread INFO: EPOCH:362
2023-08-12 12:36:16,320 MainThread INFO: Time Consumed:8.734688758850098s
2023-08-12 12:36:16,320 MainThread INFO: Total Frames:574500s
  4%|▎         | 363/10000 [54:55<24:01:38,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1260.29704
Train_Epoch_Reward                    13170.66930
Running_Training_Average_Rewards      1154.69749
Explore_Time                          0.00657
Train___Time                          8.72315
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.43164
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.79464
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.58033
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2446.20544
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.49744
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.94314
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.37778
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10699.05499
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.16507
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.49997
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.56195      1.24215     10.02229     3.21230
alpha_0                               3.38792      0.00880     3.40900      3.37833
alpha_1                               0.53614      0.00398     0.54177      0.52859
alpha_2                               0.14936      0.00029     0.15023      0.14908
alpha_3                               0.18167      0.00225     0.18512      0.17754
alpha_4                               0.16044      0.00193     0.16385      0.15720
alpha_5                               0.42124      0.00235     0.42533      0.41726
alpha_6                               0.25157      0.00037     0.25191      0.25068
alpha_7                               0.26005      0.00026     0.26063      0.25980
alpha_8                               0.15834      0.00094     0.16016      0.15676
alpha_9                               0.20848      0.00160     0.21124      0.20577
Alpha_loss                            0.56137      0.17612     0.92732      0.12101
Training/policy_loss                  223.11808    18.45758    272.70929    179.67142
Training/qf1_loss                     5063.31776   1993.30673  11673.20605  2156.74292
Training/qf2_loss                     1433.62060   380.27341   2829.88452   835.72137
Training/pf_norm                      15.91338     4.91926     28.73595     7.98473
Training/qf1_norm                     6103.13949   2342.13198  15443.42578  2327.32935
Training/qf2_norm                     4885.35458   1781.23682  9157.64160   1834.63953
log_std/mean                          -0.94729     0.00931     -0.92731     -0.96898
log_std/std                           0.44580      0.00528     0.45878      0.43395
log_std/max                           0.38092      0.07551     0.52609      0.14779
log_std/min                           -2.89202     0.14196     -2.64616     -3.32667
log_probs/mean                        4.23154      0.12762     4.55140      3.87808
log_probs/std                         3.75846      0.09762     4.00337      3.50124
log_probs/max                         21.41043     0.87792     25.16481     19.43731
log_probs/min                         -6.26306     1.27747     -3.75815     -10.59861
mean/mean                             0.21964      0.02619     0.27346      0.16769
mean/std                              1.47910      0.01948     1.52792      1.43303
mean/max                              5.42062      0.45043     6.20782      4.24967
mean/min                              -5.58655     0.25787     -4.60137     -6.04311
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 4, 1, 6, 5, 9, 2, 8, 3, 7]
replay_buffer._size: [57750 57750 57750 57750 57750 57750 57750 57750 57750 57750]
2023-08-12 12:36:25,324 MainThread INFO: EPOCH:363
2023-08-12 12:36:25,324 MainThread INFO: Time Consumed:8.823169231414795s
2023-08-12 12:36:25,324 MainThread INFO: Total Frames:576000s
  4%|▎         | 364/10000 [55:04<24:02:55,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1086.83898
Train_Epoch_Reward                    12559.10619
Running_Training_Average_Rewards      1219.09895
Explore_Time                          0.01367
Train___Time                          8.80435
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.27258
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.03596
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.90740
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           172.80786
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.80115
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.64567
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.35705
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11236.99079
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.86411
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.52491
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.54536      1.20840     10.13912     4.13576
alpha_0                               3.37837      0.00334     3.38576      3.37108
alpha_1                               0.52059      0.00418     0.52839      0.51340
alpha_2                               0.15197      0.00074     0.15273      0.15027
alpha_3                               0.17359      0.00200     0.17744      0.17039
alpha_4                               0.16710      0.00183     0.17018      0.16392
alpha_5                               0.41290      0.00251     0.41719      0.40879
alpha_6                               0.25124      0.00042     0.25180      0.25040
alpha_7                               0.26133      0.00038     0.26179      0.26064
alpha_8                               0.15518      0.00083     0.15673      0.15392
alpha_9                               0.21351      0.00130     0.21575      0.21129
Alpha_loss                            0.37708      0.20604     0.86583      -0.13698
Training/policy_loss                  221.16659    19.09324    266.87057    178.23668
Training/qf1_loss                     4706.54989   1691.70662  8363.46777   1888.71606
Training/qf2_loss                     1375.29900   279.08419   2154.75366   891.01721
Training/pf_norm                      15.56566     6.25120     37.62516     7.76442
Training/qf1_norm                     5766.31690   2505.48258  14958.11816  1707.00513
Training/qf2_norm                     4890.13443   2461.44949  18974.27148  1526.20239
log_std/mean                          -0.93880     0.00678     -0.91581     -0.95311
log_std/std                           0.44337      0.00441     0.45513      0.43302
log_std/max                           0.36849      0.08318     0.48891      0.18406
log_std/min                           -2.82470     0.14948     -2.59834     -3.49220
log_probs/mean                        4.11143      0.13738     4.51283      3.75977
log_probs/std                         3.68298      0.11095     3.92694      3.38334
log_probs/max                         20.76034     1.48706     25.10616     18.12018
log_probs/min                         -6.56688     1.41330     -4.39112     -11.30947
mean/mean                             0.22474      0.03165     0.30545      0.14654
mean/std                              1.46536      0.02079     1.51892      1.41103
mean/max                              5.50325      0.38194     6.04587      4.11950
mean/min                              -5.56205     0.36841     -4.48984     -6.19478
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 4, 8, 1, 2, 0, 5, 7, 6]
replay_buffer._size: [57900 57900 57900 57900 57900 57900 57900 57900 57900 57900]
2023-08-12 12:36:34,157 MainThread INFO: EPOCH:364
2023-08-12 12:36:34,158 MainThread INFO: Time Consumed:8.65984559059143s
2023-08-12 12:36:34,158 MainThread INFO: Total Frames:577500s
  4%|▎         | 365/10000 [55:13<23:55:28,  8.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1309.13898
Train_Epoch_Reward                    12192.90281
Running_Training_Average_Rewards      1264.08928
Explore_Time                          0.00565
Train___Time                          8.64925
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.93856
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.08474
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.15673
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2208.57090
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.85625
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.29074
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.56164
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11417.74219
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.09974
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.93488
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85570      1.37572     10.06802     3.81665
alpha_0                               3.37754      0.01471     3.41696      3.36574
alpha_1                               0.50611      0.00419     0.51326      0.49883
alpha_2                               0.15392      0.00067     0.15507      0.15275
alpha_3                               0.16734      0.00172     0.17033      0.16431
alpha_4                               0.17333      0.00183     0.17657      0.17024
alpha_5                               0.40435      0.00244     0.40871      0.40052
alpha_6                               0.24944      0.00059     0.25039      0.24834
alpha_7                               0.26166      0.00026     0.26202      0.26114
alpha_8                               0.15333      0.00024     0.15390      0.15306
alpha_9                               0.21757      0.00102     0.21935      0.21579
Alpha_loss                            0.29286      0.16374     0.72447      -0.05342
Training/policy_loss                  215.52643    19.16522    262.59811    157.02629
Training/qf1_loss                     4940.80349   1800.82567  9329.10156   2134.95215
Training/qf2_loss                     1474.18072   449.49359   3014.75024   888.68585
Training/pf_norm                      14.28457     4.90062     31.09262     6.79305
Training/qf1_norm                     5910.25203   2331.39038  13758.23730  2434.65601
Training/qf2_norm                     5144.03757   2036.58241  11170.43750  1768.36694
log_std/mean                          -0.94403     0.01656     -0.91104     -0.97416
log_std/std                           0.43827      0.00612     0.45268      0.42499
log_std/max                           0.36359      0.07231     0.45294      0.16804
log_std/min                           -2.77538     0.20851     -2.50982     -3.61826
log_probs/mean                        4.11797      0.12330     4.38117      3.80381
log_probs/std                         3.62345      0.10232     3.86924      3.37271
log_probs/max                         20.79294     1.57053     25.80501     18.05344
log_probs/min                         -6.38002     1.16920     -4.32335     -10.14372
mean/mean                             0.20506      0.02832     0.26528      0.13431
mean/std                              1.46803      0.01584     1.50339      1.43382
mean/max                              5.62496      0.34706     5.98546      4.49352
mean/min                              -5.49296     0.29397     -4.57503     -6.03662
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 6, 7, 9, 0, 3, 1, 5, 2, 4]
replay_buffer._size: [58050 58050 58050 58050 58050 58050 58050 58050 58050 58050]
2023-08-12 12:36:43,404 MainThread INFO: EPOCH:365
2023-08-12 12:36:43,404 MainThread INFO: Time Consumed:9.09091067314148s
2023-08-12 12:36:43,404 MainThread INFO: Total Frames:579000s
  4%|▎         | 366/10000 [55:22<24:11:13,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1130.55756
Train_Epoch_Reward                    10730.99260
Running_Training_Average_Rewards      1182.76672
Explore_Time                          0.00424
Train___Time                          9.08116
Eval____Time                          0.00467
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.03589
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.96261
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.00615
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.17194
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.82704
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -55.78718
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.82714
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11799.51057
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.01257
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.30441
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.81282      1.42978     10.95978     3.78640
alpha_0                               3.45885      0.01804     3.47868      3.41845
alpha_1                               0.49148      0.00425     0.49868      0.48407
alpha_2                               0.15694      0.00124     0.15922      0.15510
alpha_3                               0.16100      0.00192     0.16425      0.15757
alpha_4                               0.18014      0.00201     0.18349      0.17664
alpha_5                               0.39674      0.00228     0.40044      0.39256
alpha_6                               0.24688      0.00080     0.24832      0.24561
alpha_7                               0.26148      0.00026     0.26177      0.26107
alpha_8                               0.15430      0.00085     0.15591      0.15310
alpha_9                               0.22117      0.00099     0.22280      0.21938
Alpha_loss                            0.47271      0.16045     0.78697      0.02715
Training/policy_loss                  214.41355    20.79297    265.62976    171.37718
Training/qf1_loss                     4550.93031   1657.80826  10594.34277  2202.58716
Training/qf2_loss                     1351.12758   305.39169   2402.55835   864.13800
Training/pf_norm                      16.31351     5.70673     32.92825     7.88458
Training/qf1_norm                     6378.70114   2712.83984  16186.86133  1971.79199
Training/qf2_norm                     4984.39302   2290.65913  13240.95703  1802.07568
log_std/mean                          -0.95917     0.00952     -0.93627     -0.97673
log_std/std                           0.42820      0.00487     0.44017      0.41510
log_std/max                           0.31402      0.07863     0.42885      0.12109
log_std/min                           -2.72851     0.18638     -2.48439     -3.58868
log_probs/mean                        4.21714      0.12580     4.54349      3.92584
log_probs/std                         3.60291      0.09540     3.81047      3.38775
log_probs/max                         21.33248     2.78087     31.79327     18.20990
log_probs/min                         -6.50838     1.51125     -4.08615     -11.46735
mean/mean                             0.21420      0.04726     0.33174      0.11393
mean/std                              1.47163      0.01804     1.51032      1.42677
mean/max                              5.64776      0.26093     6.00910      4.71675
mean/min                              -5.33279     0.31391     -4.51976     -6.08742
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 4, 9, 7, 6, 3, 1, 2, 8, 5]
replay_buffer._size: [58200 58200 58200 58200 58200 58200 58200 58200 58200 58200]
2023-08-12 12:36:52,460 MainThread INFO: EPOCH:366
2023-08-12 12:36:52,460 MainThread INFO: Time Consumed:8.883607149124146s
2023-08-12 12:36:52,460 MainThread INFO: Total Frames:580500s
  4%|▎         | 367/10000 [55:31<24:15:22,  9.06s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1288.96106
Train_Epoch_Reward                    11940.50596
Running_Training_Average_Rewards      1162.14671
Explore_Time                          0.00474
Train___Time                          8.87388
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.29164
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.60488
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -80.77219
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.80701
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.97780
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.66327
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.70175
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13458.09159
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.41525
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.24721
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89325      1.50517     11.53490     3.83395
alpha_0                               3.47283      0.00531     3.48092      3.46443
alpha_1                               0.47868      0.00276     0.48393      0.47444
alpha_2                               0.16011      0.00045     0.16126      0.15926
alpha_3                               0.15308      0.00263     0.15749      0.14888
alpha_4                               0.18700      0.00206     0.19059      0.18355
alpha_5                               0.38874      0.00215     0.39246      0.38521
alpha_6                               0.24492      0.00028     0.24559      0.24449
alpha_7                               0.26205      0.00019     0.26239      0.26165
alpha_8                               0.15864      0.00163     0.16140      0.15595
alpha_9                               0.22465      0.00106     0.22643      0.22284
Alpha_loss                            0.49476      0.17047     0.91330      0.15813
Training/policy_loss                  211.38439    24.64292    274.45248    165.08031
Training/qf1_loss                     4466.20328   1633.48099  8628.51465   1660.70996
Training/qf2_loss                     1343.88407   364.37339   3215.67920   803.24170
Training/pf_norm                      15.61858     5.19311     29.56252     7.47125
Training/qf1_norm                     5983.00420   2161.25417  11257.97461  2206.97485
Training/qf2_norm                     5041.76372   2381.46161  11764.80078  1971.17126
log_std/mean                          -0.94824     0.00961     -0.92520     -0.97041
log_std/std                           0.41729      0.00520     0.42756      0.40624
log_std/max                           0.33145      0.05224     0.40188      0.21656
log_std/min                           -2.69629     0.14790     -2.52684     -3.33761
log_probs/mean                        4.24923      0.13718     4.62048      3.98675
log_probs/std                         3.58610      0.08492     3.76617      3.34055
log_probs/max                         20.63916     1.97436     29.19590     17.85686
log_probs/min                         -6.15206     1.24328     -3.70280     -9.50020
mean/mean                             0.23327      0.03156     0.30087      0.13164
mean/std                              1.48112      0.01844     1.53446      1.44660
mean/max                              5.51945      0.23483     5.84823      4.54058
mean/min                              -5.22987     0.22670     -4.46615     -5.76003
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 2, 6, 4, 8, 3, 5, 7, 9, 0]
replay_buffer._size: [58350 58350 58350 58350 58350 58350 58350 58350 58350 58350]
2023-08-12 12:37:00,824 MainThread INFO: EPOCH:367
2023-08-12 12:37:00,824 MainThread INFO: Time Consumed:8.172869205474854s
2023-08-12 12:37:00,824 MainThread INFO: Total Frames:582000s
  4%|▎         | 368/10000 [55:39<23:36:50,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1056.64929
Train_Epoch_Reward                    12900.04247
Running_Training_Average_Rewards      1185.71803
Explore_Time                          0.01217
Train___Time                          8.15409
Eval____Time                          0.00495
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.08363
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.19265
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.40544
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.34463
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.91883
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.86072
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.75826
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11131.52201
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.88454
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.58046
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.73903      1.43102     12.17286     4.10542
alpha_0                               3.48623      0.00438     3.49266      3.47932
alpha_1                               0.46930      0.00249     0.47435      0.46566
alpha_2                               0.16161      0.00007     0.16166      0.16130
alpha_3                               0.14512      0.00220     0.14881      0.14130
alpha_4                               0.19410      0.00199     0.19751      0.19067
alpha_5                               0.38228      0.00168     0.38515      0.37951
alpha_6                               0.24412      0.00017     0.24448      0.24380
alpha_7                               0.26282      0.00031     0.26349      0.26241
alpha_8                               0.16447      0.00184     0.16783      0.16146
alpha_9                               0.22778      0.00078     0.22919      0.22646
Alpha_loss                            0.38075      0.17266     0.87627      0.01463
Training/policy_loss                  209.15143    20.10458    272.98022    156.01262
Training/qf1_loss                     4487.72098   1536.12045  8303.23828   2140.41968
Training/qf2_loss                     1276.58901   295.15803   2188.21875   826.86536
Training/pf_norm                      17.86788     7.07135     47.53308     7.47748
Training/qf1_norm                     5777.79813   2543.65192  12430.59961  2366.18286
Training/qf2_norm                     4656.58452   1972.80231  13214.14844  1696.21497
log_std/mean                          -0.93724     0.00899     -0.91388     -0.95969
log_std/std                           0.41351      0.00589     0.42892      0.39715
log_std/max                           0.32693      0.09096     0.44139      0.06472
log_std/min                           -2.65632     0.23434     -2.44457     -3.55496
log_probs/mean                        4.20534      0.10464     4.50773      3.95032
log_probs/std                         3.62027      0.10097     3.89392      3.33928
log_probs/max                         22.24311     3.06339     31.23715     17.73811
log_probs/min                         -6.38403     1.46053     -3.92304     -11.39592
mean/mean                             0.23386      0.04924     0.33808      0.12673
mean/std                              1.48047      0.01531     1.52515      1.42371
mean/max                              5.66636      0.20866     5.96493      4.83531
mean/min                              -5.19165     0.36848     -4.40158     -6.44729
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 1, 2, 5, 0, 7, 4, 9, 6]
replay_buffer._size: [58500 58500 58500 58500 58500 58500 58500 58500 58500 58500]
2023-08-12 12:37:09,892 MainThread INFO: EPOCH:368
2023-08-12 12:37:09,892 MainThread INFO: Time Consumed:8.916364431381226s
2023-08-12 12:37:09,892 MainThread INFO: Total Frames:583500s
  4%|▎         | 369/10000 [55:49<23:48:47,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1229.83281
Train_Epoch_Reward                    11730.19175
Running_Training_Average_Rewards      1219.02467
Explore_Time                          0.00475
Train___Time                          8.90661
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.74413
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.15581
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.41272
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.68627
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.77582
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.22579
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.13190
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12870.75759
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.06173
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.23536
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.61473      1.34998     9.96593      3.43254
alpha_0                               3.46349      0.01306     3.49013      3.44931
alpha_1                               0.46135      0.00230     0.46557      0.45770
alpha_2                               0.16226      0.00043     0.16331      0.16163
alpha_3                               0.13757      0.00214     0.14123      0.13386
alpha_4                               0.20075      0.00179     0.20376      0.19757
alpha_5                               0.37724      0.00132     0.37948      0.37508
alpha_6                               0.24347      0.00013     0.24379      0.24332
alpha_7                               0.26412      0.00040     0.26510      0.26351
alpha_8                               0.17192      0.00236     0.17610      0.16791
alpha_9                               0.23058      0.00072     0.23171      0.22922
Alpha_loss                            0.42684      0.15662     0.78079      0.01615
Training/policy_loss                  206.57012    18.01196    252.45020    161.21165
Training/qf1_loss                     4239.80656   1470.40935  8971.63574   1787.93970
Training/qf2_loss                     1280.48706   325.05855   2532.88135   764.39062
Training/pf_norm                      13.34408     4.51194     30.95642     4.55947
Training/qf1_norm                     5943.78655   2649.56118  12599.70020  1473.71240
Training/qf2_norm                     4786.20533   2145.17979  11287.79688  1537.84106
log_std/mean                          -0.92747     0.00599     -0.91086     -0.94277
log_std/std                           0.41057      0.00528     0.42028      0.39394
log_std/max                           0.29657      0.10664     0.45354      0.08089
log_std/min                           -2.63411     0.21324     -2.37122     -3.54163
log_probs/mean                        4.22405      0.10759     4.52757      3.97998
log_probs/std                         3.58782      0.10372     3.95949      3.31957
log_probs/max                         21.62254     3.44063     32.35658     17.69795
log_probs/min                         -6.45937     1.33710     -4.17458     -11.46612
mean/mean                             0.24811      0.04152     0.31788      0.14638
mean/std                              1.48686      0.01475     1.52652      1.45416
mean/max                              5.65581      0.12397     5.78603      5.19028
mean/min                              -5.13873     0.43888     -4.31143     -6.56957
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 6, 4, 2, 9, 0, 1, 5, 7]
replay_buffer._size: [58650 58650 58650 58650 58650 58650 58650 58650 58655 58650]
2023-08-12 12:37:19,103 MainThread INFO: EPOCH:369
2023-08-12 12:37:19,103 MainThread INFO: Time Consumed:9.032309532165527s
2023-08-12 12:37:19,103 MainThread INFO: Total Frames:585000s
  4%|▎         | 370/10000 [55:58<24:05:27,  9.01s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1254.02871
Train_Epoch_Reward                    12342.69238
Running_Training_Average_Rewards      1232.43089
Explore_Time                          0.02637
Train___Time                          9.00149
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.22409
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.09811
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.39929
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.33554
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.68513
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.02231
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.09674
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13110.48604
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.74463
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.59314
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.71863      1.09824     9.49709      3.58944
alpha_0                               3.46153      0.00442     3.47131      3.45014
alpha_1                               0.45492      0.00126     0.45763      0.45319
alpha_2                               0.16481      0.00091     0.16638      0.16334
alpha_3                               0.13038      0.00195     0.13379      0.12704
alpha_4                               0.20683      0.00173     0.20984      0.20382
alpha_5                               0.37273      0.00117     0.37503      0.37101
alpha_6                               0.24355      0.00024     0.24405      0.24331
alpha_7                               0.26635      0.00073     0.26763      0.26513
alpha_8                               0.18042      0.00246     0.18475      0.17619
alpha_9                               0.23287      0.00059     0.23380      0.23174
Alpha_loss                            0.42975      0.15300     0.80880      -0.03436
Training/policy_loss                  203.87801    21.27024    254.62877    150.05064
Training/qf1_loss                     4243.22589   1836.02782  9412.46387   1789.05139
Training/qf2_loss                     1298.48547   366.39536   2887.30273   848.74756
Training/pf_norm                      15.62747     5.68603     32.60534     7.31632
Training/qf1_norm                     5689.15506   2652.65459  19488.14648  2145.70264
Training/qf2_norm                     4966.64469   2382.37417  14112.98145  1613.04285
log_std/mean                          -0.93113     0.00957     -0.91214     -0.95502
log_std/std                           0.41487      0.00400     0.42620      0.40668
log_std/max                           0.34436      0.14738     0.52419      0.08110
log_std/min                           -2.68581     0.31615     -2.33705     -3.75252
log_probs/mean                        4.30455      0.10189     4.58559      4.06111
log_probs/std                         3.55845      0.08865     3.80882      3.33412
log_probs/max                         21.61008     3.14632     31.32217     16.98317
log_probs/min                         -6.56392     1.50709     -3.82165     -11.32228
mean/mean                             0.26981      0.04418     0.34700      0.15680
mean/std                              1.49249      0.01419     1.52694      1.45082
mean/max                              5.65211      0.12008     5.74905      5.13302
mean/min                              -5.16731     0.42666     -4.18960     -6.32860
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 4, 0, 9, 5, 3, 2, 1, 8, 7]
replay_buffer._size: [58800 58800 58800 58800 58800 58800 58800 58800 58800 58800]
2023-08-12 12:37:27,566 MainThread INFO: EPOCH:370
2023-08-12 12:37:27,567 MainThread INFO: Time Consumed:8.281043529510498s
2023-08-12 12:37:27,567 MainThread INFO: Total Frames:586500s
  4%|▎         | 371/10000 [56:06<23:37:04,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1276.46446
Train_Epoch_Reward                    12261.07339
Running_Training_Average_Rewards      1211.13192
Explore_Time                          0.01665
Train___Time                          8.25950
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.13889
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.93992
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.93510
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.22236
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.11722
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.95267
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.38291
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13360.98107
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.32547
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.32189
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.82657      1.42778     10.14687     3.83835
alpha_0                               3.48280      0.00525     3.49052      3.47181
alpha_1                               0.44824      0.00281     0.45311      0.44329
alpha_2                               0.16632      0.00021     0.16654      0.16586
alpha_3                               0.12373      0.00182     0.12697      0.12078
alpha_4                               0.21271      0.00156     0.21527      0.20990
alpha_5                               0.36843      0.00145     0.37098      0.36612
alpha_6                               0.24462      0.00038     0.24529      0.24406
alpha_7                               0.26732      0.00029     0.26779      0.26678
alpha_8                               0.18848      0.00196     0.19152      0.18484
alpha_9                               0.23443      0.00027     0.23475      0.23382
Alpha_loss                            0.03570      0.15916     0.37074      -0.34760
Training/policy_loss                  202.37678    18.36706    249.32906    146.11023
Training/qf1_loss                     4429.52067   1673.48546  10018.48242  1870.79822
Training/qf2_loss                     1286.66353   375.21841   2454.13281   689.55823
Training/pf_norm                      14.14873     4.29720     29.57519     6.78389
Training/qf1_norm                     5974.66711   2339.94965  12955.74316  1985.83313
Training/qf2_norm                     5240.16677   2232.30381  12126.45605  2247.72437
log_std/mean                          -0.90837     0.01063     -0.88682     -0.93287
log_std/std                           0.41939      0.00487     0.43140      0.40464
log_std/max                           0.35189      0.15259     0.56208      0.13381
log_std/min                           -2.67470     0.15543     -2.40797     -3.36659
log_probs/mean                        4.04102      0.11291     4.29145      3.73235
log_probs/std                         3.55235      0.10837     3.87247      3.32031
log_probs/max                         22.13703     4.02507     34.63753     16.75855
log_probs/min                         -6.30647     1.12828     -4.30048     -9.64106
mean/mean                             0.22445      0.03288     0.29266      0.14264
mean/std                              1.47251      0.01794     1.50884      1.41816
mean/max                              5.60032      0.11333     5.78206      5.20575
mean/min                              -5.35692     0.47296     -4.11271     -6.65637
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 2, 0, 1, 8, 3, 9, 7, 4, 5]
replay_buffer._size: [58950 58950 58950 58950 58950 58950 58950 58950 58950 58950]
2023-08-12 12:37:35,938 MainThread INFO: EPOCH:371
2023-08-12 12:37:35,938 MainThread INFO: Time Consumed:8.180144309997559s
2023-08-12 12:37:35,938 MainThread INFO: Total Frames:588000s
  4%|▎         | 372/10000 [56:15<23:14:43,  8.69s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1179.09137
Train_Epoch_Reward                    12393.35965
Running_Training_Average_Rewards      1233.23751
Explore_Time                          0.00697
Train___Time                          8.16861
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.01539
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.16604
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.12850
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.63380
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.81458
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.00345
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.52718
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12380.67525
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.60863
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.86401
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89935      1.65568     11.35176     3.22256
alpha_0                               3.48572      0.00441     3.49286      3.47776
alpha_1                               0.43841      0.00285     0.44319      0.43328
alpha_2                               0.16576      0.00016     0.16596      0.16532
alpha_3                               0.11801      0.00159     0.12072      0.11532
alpha_4                               0.21780      0.00145     0.22022      0.21531
alpha_5                               0.36514      0.00033     0.36608      0.36468
alpha_6                               0.24660      0.00081     0.24779      0.24532
alpha_7                               0.26592      0.00059     0.26675      0.26461
alpha_8                               0.19406      0.00152     0.19665      0.19156
alpha_9                               0.23443      0.00018     0.23470      0.23401
Alpha_loss                            -0.04141     0.18232     0.49047      -0.61591
Training/policy_loss                  201.37332    23.55559    251.24641    152.12129
Training/qf1_loss                     4316.09485   1541.34433  8619.35156   972.20770
Training/qf2_loss                     1283.69614   351.51837   2416.02808   716.21497
Training/pf_norm                      17.04796     8.04100     43.64370     7.06498
Training/qf1_norm                     6309.32193   2906.06031  13863.61035  1773.25037
Training/qf2_norm                     5059.94906   2187.35102  11853.03027  1723.47510
log_std/mean                          -0.90621     0.01542     -0.88061     -0.94037
log_std/std                           0.41723      0.00460     0.42983      0.40527
log_std/max                           0.40310      0.18283     0.63561      0.10855
log_std/min                           -2.75834     0.34948     -2.39916     -3.89995
log_probs/mean                        4.01709      0.13886     4.39396      3.74526
log_probs/std                         3.48723      0.10786     3.75514      3.20125
log_probs/max                         21.54050     3.11385     34.17620     16.90101
log_probs/min                         -6.26350     1.22940     -4.04505     -10.13205
mean/mean                             0.25306      0.02920     0.31193      0.18675
mean/std                              1.46342      0.01800     1.51042      1.42098
mean/max                              5.60337      0.11292     5.76583      5.16798
mean/min                              -5.44827     0.59342     -3.89548     -6.59421
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 0, 4, 7, 9, 2, 5, 6, 3, 8]
replay_buffer._size: [59100 59100 59100 59100 59100 59100 59100 59100 59100 59100]
2023-08-12 12:37:44,930 MainThread INFO: EPOCH:372
2023-08-12 12:37:44,931 MainThread INFO: Time Consumed:8.748752117156982s
2023-08-12 12:37:44,931 MainThread INFO: Total Frames:589500s
  4%|▎         | 373/10000 [56:24<23:29:14,  8.78s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1323.66264
Train_Epoch_Reward                    10207.31041
Running_Training_Average_Rewards      1162.05812
Explore_Time                          0.00462
Train___Time                          8.73906
Eval____Time                          0.00445
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.34117
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.02354
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.91203
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.67522
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.91213
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.24947
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.34931
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13826.32382
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.90290
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.33161
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89181      1.52764     11.73175     3.75890
alpha_0                               3.45997      0.01286     3.48369      3.44434
alpha_1                               0.42856      0.00265     0.43318      0.42435
alpha_2                               0.16284      0.00159     0.16529      0.16007
alpha_3                               0.11298      0.00134     0.11527      0.11075
alpha_4                               0.22207      0.00101     0.22375      0.22026
alpha_5                               0.36369      0.00070     0.36467      0.36222
alpha_6                               0.24912      0.00091     0.25084      0.24781
alpha_7                               0.26332      0.00071     0.26459      0.26240
alpha_8                               0.19949      0.00163     0.20231      0.19671
alpha_9                               0.23307      0.00052     0.23400      0.23226
Alpha_loss                            -0.24807     0.13578     0.09732      -0.61574
Training/policy_loss                  196.92101    21.18853    256.57843    138.28600
Training/qf1_loss                     4142.41573   1616.38676  10021.51953  1396.78638
Training/qf2_loss                     1272.90036   404.71433   2817.55640   660.48895
Training/pf_norm                      14.47792     5.06215     30.47527     6.16193
Training/qf1_norm                     5600.30263   2438.16723  16270.10352  2074.78345
Training/qf2_norm                     4918.03533   2032.64795  12590.40332  1689.31519
log_std/mean                          -0.89241     0.00932     -0.87279     -0.91885
log_std/std                           0.42037      0.00662     0.43437      0.40783
log_std/max                           0.39067      0.17089     0.62252      0.10504
log_std/min                           -2.75169     0.33931     -2.42051     -3.86580
log_probs/mean                        3.87673      0.10046     4.12347      3.60474
log_probs/std                         3.43077      0.10666     3.70519      3.11160
log_probs/max                         22.56344     3.75043     32.72181     16.42898
log_probs/min                         -6.41510     1.33797     -3.95361     -10.85411
mean/mean                             0.21784      0.03081     0.27994      0.14195
mean/std                              1.45132      0.01439     1.49051      1.42171
mean/max                              5.55877      0.11141     5.72140      5.23680
mean/min                              -5.54945     0.64622     -3.63958     -6.50386
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 4, 1, 3, 6, 9, 5, 8, 0, 2]
replay_buffer._size: [59250 59250 59250 59250 59250 59250 59250 59250 59250 59250]
2023-08-12 12:37:54,774 MainThread INFO: EPOCH:373
2023-08-12 12:37:54,776 MainThread INFO: Time Consumed:9.676694393157959s
2023-08-12 12:37:54,776 MainThread INFO: Total Frames:591000s
  4%|▎         | 374/10000 [56:33<24:22:42,  9.12s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1291.65411
Train_Epoch_Reward                    13843.11957
Running_Training_Average_Rewards      1214.79299
Explore_Time                          0.00445
Train___Time                          9.66729
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.69824
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.25314
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.56743
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.21380
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.54374
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.43065
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.60027
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13504.69825
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.88402
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.96585
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.54001      1.54719     10.88951     3.57268
alpha_0                               3.45118      0.00277     3.45618      3.44664
alpha_1                               0.41984      0.00270     0.42428      0.41528
alpha_2                               0.15743      0.00162     0.16003      0.15473
alpha_3                               0.10865      0.00117     0.11071      0.10667
alpha_4                               0.22546      0.00097     0.22703      0.22379
alpha_5                               0.36086      0.00061     0.36218      0.35977
alpha_6                               0.25279      0.00108     0.25472      0.25088
alpha_7                               0.26215      0.00010     0.26239      0.26199
alpha_8                               0.20449      0.00117     0.20631      0.20236
alpha_9                               0.23127      0.00053     0.23224      0.23043
Alpha_loss                            -0.30071     0.15312     0.09898      -0.74358
Training/policy_loss                  193.27414    20.43775    235.73965    148.41035
Training/qf1_loss                     4328.90750   1546.50782  8589.76465   1276.36951
Training/qf2_loss                     1178.50677   313.61118   2691.71460   682.83771
Training/pf_norm                      13.49182     4.81118     28.24104     5.86809
Training/qf1_norm                     5938.44519   2548.16509  14420.21680  1969.26245
Training/qf2_norm                     4916.77323   2338.59047  11456.61230  1710.70874
log_std/mean                          -0.89877     0.00994     -0.87671     -0.91929
log_std/std                           0.41911      0.00473     0.43283      0.40879
log_std/max                           0.44851      0.21413     0.68467      0.04662
log_std/min                           -2.80307     0.32202     -2.40968     -3.99821
log_probs/mean                        3.87467      0.11193     4.11204      3.54296
log_probs/std                         3.40425      0.11026     3.63339      3.12798
log_probs/max                         22.42858     3.56317     33.67032     16.19220
log_probs/min                         -6.11095     1.55009     -3.99271     -14.21588
mean/mean                             0.24251      0.03333     0.31271      0.13405
mean/std                              1.44625      0.01716     1.48760      1.40280
mean/max                              5.54962      0.09579     5.76665      5.29788
mean/min                              -5.78331     0.60487     -3.91418     -6.72665
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 4, 7, 5, 8, 2, 6, 0, 3, 1]
replay_buffer._size: [59400 59400 59400 59400 59400 59400 59400 59400 59400 59400]
2023-08-12 12:38:03,189 MainThread INFO: EPOCH:374
2023-08-12 12:38:03,189 MainThread INFO: Time Consumed:8.23841142654419s
2023-08-12 12:38:03,189 MainThread INFO: Total Frames:592500s
  4%|▍         | 375/10000 [56:42<23:45:53,  8.89s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1339.52757
Train_Epoch_Reward                    11938.05693
Running_Training_Average_Rewards      1199.61623
Explore_Time                          0.00468
Train___Time                          8.22927
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.46550
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.83938
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.65067
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.52994
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.26431
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.32466
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.75059
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13974.40311
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.25307
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.04933
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.57151      1.18169     9.38717      4.24866
alpha_0                               3.43596      0.00778     3.45164      3.41864
alpha_1                               0.41123      0.00186     0.41518      0.40867
alpha_2                               0.15292      0.00091     0.15468      0.15139
alpha_3                               0.10491      0.00098     0.10663      0.10333
alpha_4                               0.22848      0.00087     0.23011      0.22705
alpha_5                               0.35897      0.00024     0.35973      0.35873
alpha_6                               0.25685      0.00128     0.25910      0.25476
alpha_7                               0.26183      0.00018     0.26216      0.26159
alpha_8                               0.20739      0.00065     0.20864      0.20633
alpha_9                               0.22951      0.00048     0.23042      0.22883
Alpha_loss                            -0.16724     0.19782     0.36261      -0.63247
Training/policy_loss                  193.94890    18.73929    245.27950    151.52306
Training/qf1_loss                     3868.06662   1395.67949  8911.80371   1716.50684
Training/qf2_loss                     1130.32537   361.33595   3739.37183   748.29248
Training/pf_norm                      15.28556     6.03633     35.58133     5.85158
Training/qf1_norm                     5735.35938   2189.86323  11079.73828  2014.24585
Training/qf2_norm                     5224.51994   2098.19151  13679.18262  1686.44934
log_std/mean                          -0.89025     0.00780     -0.87390     -0.90728
log_std/std                           0.42004      0.00490     0.43090      0.40757
log_std/max                           0.51253      0.21222     0.73872      0.10810
log_std/min                           -2.96331     0.40490     -2.48526     -4.09061
log_probs/mean                        3.93745      0.14380     4.30025      3.53815
log_probs/std                         3.41058      0.10846     3.66624      3.19756
log_probs/max                         22.65767     3.91254     34.33855     16.86971
log_probs/min                         -6.70734     1.30069     -3.84524     -10.22235
mean/mean                             0.27394      0.04214     0.35055      0.17149
mean/std                              1.45551      0.01803     1.50202      1.41056
mean/max                              5.59136      0.18275     5.91084      5.19783
mean/min                              -6.00281     0.60553     -3.92816     -6.77387
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 3, 7, 4, 8, 9, 5, 0, 2, 1]
replay_buffer._size: [59550 59550 59550 59550 59550 59550 59550 59550 59550 59550]
2023-08-12 12:38:12,287 MainThread INFO: EPOCH:375
2023-08-12 12:38:12,288 MainThread INFO: Time Consumed:8.908923625946045s
2023-08-12 12:38:12,288 MainThread INFO: Total Frames:594000s
  4%|▍         | 376/10000 [56:51<23:57:55,  8.96s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1187.41763
Train_Epoch_Reward                    10770.20793
Running_Training_Average_Rewards      1218.37948
Explore_Time                          0.01521
Train___Time                          8.88859
Eval____Time                          0.00455
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.73588
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.65444
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.06967
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.05103
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.44587
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.58024
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.01007
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12446.18704
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.28818
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.17538
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.73749      1.28688     10.71697     3.35157
alpha_0                               3.40333      0.00990     3.41770      3.38586
alpha_1                               0.40939      0.00049     0.41015      0.40866
alpha_2                               0.14993      0.00078     0.15135      0.14874
alpha_3                               0.10223      0.00064     0.10331      0.10111
alpha_4                               0.23187      0.00092     0.23320      0.23014
alpha_5                               0.36109      0.00091     0.36223      0.35915
alpha_6                               0.26168      0.00157     0.26445      0.25914
alpha_7                               0.26225      0.00033     0.26262      0.26160
alpha_8                               0.21066      0.00118     0.21275      0.20867
alpha_9                               0.22839      0.00043     0.22883      0.22739
Alpha_loss                            0.05341      0.17261     0.41908      -0.41824
Training/policy_loss                  190.98457    20.67470    230.13635    144.08788
Training/qf1_loss                     4036.75944   1449.29251  8496.40527   1755.92896
Training/qf2_loss                     1165.26995   337.67957   2358.12427   676.73846
Training/pf_norm                      16.24487     6.03016     32.37450     6.98586
Training/qf1_norm                     5657.14990   2492.02538  12921.52832  1611.80408
Training/qf2_norm                     5077.12956   2417.90828  13084.70703  1700.22290
log_std/mean                          -0.90717     0.01275     -0.86822     -0.93738
log_std/std                           0.42290      0.00550     0.43505      0.40710
log_std/max                           0.50998      0.24457     0.75601      0.06328
log_std/min                           -2.92861     0.29954     -2.50333     -4.22802
log_probs/mean                        4.09892      0.13623     4.43985      3.74248
log_probs/std                         3.39578      0.11204     3.66955      3.10423
log_probs/max                         22.78480     3.65324     33.77444     18.15485
log_probs/min                         -6.36739     1.20988     -3.80759     -9.60556
mean/mean                             0.29197      0.04476     0.38036      0.21147
mean/std                              1.46849      0.01801     1.52478      1.42544
mean/max                              5.63252      0.19078     5.89403      5.25523
mean/min                              -5.92386     0.78607     -3.55413     -6.90550
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 5, 3, 7, 2, 9, 1, 4, 0]
replay_buffer._size: [59700 59700 59700 59700 59700 59700 59700 59700 59700 59700]
2023-08-12 12:38:20,462 MainThread INFO: EPOCH:376
2023-08-12 12:38:20,462 MainThread INFO: Time Consumed:8.02163028717041s
2023-08-12 12:38:20,462 MainThread INFO: Total Frames:595500s
  4%|▍         | 377/10000 [56:59<23:17:43,  8.71s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1298.63457
Train_Epoch_Reward                    14171.19399
Running_Training_Average_Rewards      1229.31530
Explore_Time                          0.01566
Train___Time                          8.00091
Eval____Time                          0.00427
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.83919
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.91766
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.50260
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.89746
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.57895
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.87186
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.16308
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13599.85188
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.92501
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.81033
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.79744      1.49483     10.22443     3.46550
alpha_0                               3.35985      0.01410     3.38567      3.33704
alpha_1                               0.40784      0.00103     0.40920      0.40613
alpha_2                               0.14705      0.00106     0.14872      0.14526
alpha_3                               0.09991      0.00067     0.10109      0.09884
alpha_4                               0.23415      0.00053     0.23508      0.23322
alpha_5                               0.36248      0.00037     0.36340      0.36212
alpha_6                               0.26628      0.00098     0.26786      0.26451
alpha_7                               0.26167      0.00042     0.26253      0.26120
alpha_8                               0.21332      0.00018     0.21347      0.21278
alpha_9                               0.22589      0.00082     0.22736      0.22449
Alpha_loss                            -0.27512     0.18826     0.23975      -0.72400
Training/policy_loss                  187.36143    21.13564    237.23608    134.34421
Training/qf1_loss                     3901.46233   1412.96515  7885.98584   1756.49829
Training/qf2_loss                     1076.61428   274.16913   2093.19531   662.69904
Training/pf_norm                      15.75162     6.10305     39.04850     6.40921
Training/qf1_norm                     6010.54407   3027.69724  15964.48633  1807.43201
Training/qf2_norm                     4229.55423   1819.45070  11488.07324  1730.89966
log_std/mean                          -0.88316     0.00919     -0.86367     -0.90261
log_std/std                           0.42148      0.00556     0.43935      0.40681
log_std/max                           0.60584      0.25956     0.88723      0.18265
log_std/min                           -3.02544     0.39045     -2.43895     -4.17690
log_probs/mean                        3.85247      0.12205     4.22092      3.62287
log_probs/std                         3.36758      0.11543     3.67307      3.14695
log_probs/max                         23.49186     3.71289     33.61367     18.60511
log_probs/min                         -6.32027     1.10404     -3.55089     -9.88898
mean/mean                             0.25445      0.03203     0.34927      0.18497
mean/std                              1.45132      0.01714     1.50246      1.41305
mean/max                              5.69074      0.20407     5.99071      5.38169
mean/min                              -6.12016     0.71396     -3.93740     -6.74780
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 2, 4, 6, 1, 7, 9, 0, 5, 3]
replay_buffer._size: [59850 59850 59850 59850 59850 59850 59850 59850 59850 59850]
2023-08-12 12:38:29,768 MainThread INFO: EPOCH:377
2023-08-12 12:38:29,768 MainThread INFO: Time Consumed:9.128836631774902s
2023-08-12 12:38:29,768 MainThread INFO: Total Frames:597000s
  4%|▍         | 378/10000 [57:08<23:46:03,  8.89s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1321.05924
Train_Epoch_Reward                    12997.14483
Running_Training_Average_Rewards      1264.61823
Explore_Time                          0.00839
Train___Time                          9.11527
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -86.88099
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.87414
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.52637
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.27908
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.09825
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.06156
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.83309
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13821.58501
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.77204
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.66711
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.83249      1.36353     9.84906      3.94744
alpha_0                               3.31936      0.01072     3.33671      3.29723
alpha_1                               0.40333      0.00185     0.40609      0.40036
alpha_2                               0.14299      0.00131     0.14521      0.14061
alpha_3                               0.09775      0.00063     0.09882      0.09665
alpha_4                               0.23586      0.00035     0.23637      0.23510
alpha_5                               0.36495      0.00102     0.36684      0.36341
alpha_6                               0.26943      0.00082     0.27066      0.26788
alpha_7                               0.26021      0.00083     0.26126      0.25852
alpha_8                               0.21245      0.00068     0.21338      0.21132
alpha_9                               0.22256      0.00119     0.22446      0.22040
Alpha_loss                            -0.45105     0.16498     -0.09525     -0.94404
Training/policy_loss                  186.44382    23.27491    240.04610    133.55797
Training/qf1_loss                     3934.19617   1654.42014  10414.72070  1615.47009
Training/qf2_loss                     1100.00347   369.36692   2691.69873   680.41437
Training/pf_norm                      17.83650     7.96674     44.28123     8.24181
Training/qf1_norm                     6020.24527   3012.83362  18612.11133  2232.65747
Training/qf2_norm                     4514.13302   2076.00741  12231.17188  1533.86230
log_std/mean                          -0.88015     0.01312     -0.84436     -0.90060
log_std/std                           0.42212      0.00724     0.44209      0.40889
log_std/max                           0.66194      0.21902     0.91606      0.24591
log_std/min                           -2.96730     0.32448     -2.52122     -4.20679
log_probs/mean                        3.74779      0.13530     4.02101      3.37316
log_probs/std                         3.32165      0.11449     3.61354      3.07688
log_probs/max                         22.74333     3.81671     34.98761     17.27744
log_probs/min                         -6.47746     1.49637     -3.87988     -10.77549
mean/mean                             0.22269      0.03105     0.28291      0.15096
mean/std                              1.44195      0.01744     1.48446      1.40633
mean/max                              5.63164      0.29272     6.06861      5.11737
mean/min                              -6.47055     0.78001     -3.47115     -7.20238
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 2, 4, 8, 9, 0, 3, 7, 6, 5]
replay_buffer._size: [60000 60000 60000 60000 60000 60000 60000 60000 60000 60000]
2023-08-12 12:38:38,069 MainThread INFO: EPOCH:378
2023-08-12 12:38:38,070 MainThread INFO: Time Consumed:8.104795932769775s
2023-08-12 12:38:38,070 MainThread INFO: Total Frames:598500s
  4%|▍         | 379/10000 [57:17<23:20:48,  8.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1314.29882
Train_Epoch_Reward                    12225.67306
Running_Training_Average_Rewards      1313.13373
Explore_Time                          0.01715
Train___Time                          8.08315
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.07375
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.86999
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.46842
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.33721
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.37981
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.92706
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.87014
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13739.82812
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.90894
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.00460
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.89708      1.42743     10.04504     3.57113
alpha_0                               3.26863      0.01850     3.29661      3.23971
alpha_1                               0.39913      0.00083     0.40033      0.39784
alpha_2                               0.13916      0.00076     0.14056      0.13778
alpha_3                               0.09559      0.00064     0.09663      0.09449
alpha_4                               0.23656      0.00008     0.23664      0.23637
alpha_5                               0.36980      0.00158     0.37195      0.36689
alpha_6                               0.27169      0.00063     0.27298      0.27069
alpha_7                               0.25637      0.00142     0.25848      0.25372
alpha_8                               0.20966      0.00106     0.21130      0.20785
alpha_9                               0.21749      0.00180     0.22035      0.21428
Alpha_loss                            -0.51795     0.16323     0.01006      -0.89784
Training/policy_loss                  182.51164    23.00011    233.83458    119.20050
Training/qf1_loss                     3865.02354   1559.00377  8813.25195   1284.34570
Training/qf2_loss                     1126.20360   375.99694   2794.77466   639.37891
Training/pf_norm                      14.80251     6.19605     43.88899     6.36514
Training/qf1_norm                     5919.08965   2428.18631  14309.76074  2066.91455
Training/qf2_norm                     5010.20363   2098.17965  14529.66211  1423.09119
log_std/mean                          -0.87486     0.01079     -0.85260     -0.90306
log_std/std                           0.41636      0.00516     0.42818      0.40262
log_std/max                           0.70394      0.22889     0.95316      0.17578
log_std/min                           -3.00366     0.26957     -2.57934     -4.16635
log_probs/mean                        3.69373      0.11947     3.96133      3.42434
log_probs/std                         3.32241      0.09947     3.59299      3.05688
log_probs/max                         22.94094     3.80007     34.32197     17.81242
log_probs/min                         -6.88223     1.55148     -4.39787     -12.74209
mean/mean                             0.24359      0.03770     0.32909      0.16098
mean/std                              1.43470      0.01653     1.47377      1.39276
mean/max                              5.74982      0.35263     6.25574      5.17147
mean/min                              -6.48697     1.01576     -3.90564     -7.56598
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 6, 9, 5, 1, 4, 2, 3, 7]
replay_buffer._size: [60150 60150 60150 60150 60150 60150 60150 60150 60150 60150]
2023-08-12 12:38:46,276 MainThread INFO: EPOCH:379
2023-08-12 12:38:46,276 MainThread INFO: Time Consumed:8.025828838348389s
2023-08-12 12:38:46,276 MainThread INFO: Total Frames:600000s
  4%|▍         | 380/10000 [57:25<22:51:58,  8.56s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1342.11715
Train_Epoch_Reward                    13391.13715
Running_Training_Average_Rewards      1287.13183
Explore_Time                          0.00496
Train___Time                          8.01654
Eval____Time                          0.00367
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.22960
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.06054
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.06211
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.39111
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.87431
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.41641
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.39873
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14051.26629
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.93372
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.72824
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.74329      1.35266     10.47816     3.66280
alpha_0                               3.22202      0.00740     3.23933      3.20621
alpha_1                               0.39355      0.00221     0.39780      0.39067
alpha_2                               0.13619      0.00106     0.13776      0.13412
alpha_3                               0.09349      0.00050     0.09447      0.09279
alpha_4                               0.23652      0.00016     0.23668      0.23616
alpha_5                               0.37361      0.00162     0.37728      0.37197
alpha_6                               0.27389      0.00051     0.27475      0.27301
alpha_7                               0.25004      0.00184     0.25366      0.24755
alpha_8                               0.20560      0.00119     0.20781      0.20366
alpha_9                               0.21092      0.00182     0.21421      0.20801
Alpha_loss                            -0.60814     0.17346     -0.20188     -1.01425
Training/policy_loss                  180.31806    18.85029    226.76424    141.25291
Training/qf1_loss                     3890.91614   1423.26306  7814.87988   1300.50037
Training/qf2_loss                     1084.23481   310.83774   2206.11597   636.96191
Training/pf_norm                      14.01448     5.64702     31.01172     6.69227
Training/qf1_norm                     5704.36671   2521.71280  15323.74316  2011.58569
Training/qf2_norm                     4639.38685   1940.71943  12679.90332  1755.47327
log_std/mean                          -0.87270     0.01295     -0.85120     -0.90699
log_std/std                           0.41871      0.00618     0.43957      0.40607
log_std/max                           0.66570      0.22672     0.95587      0.18856
log_std/min                           -2.98499     0.34887     -2.55411     -4.18705
log_probs/mean                        3.64079      0.12964     3.89261      3.27482
log_probs/std                         3.29870      0.10964     3.57610      3.04119
log_probs/max                         22.30294     3.30620     32.10481     18.06458
log_probs/min                         -6.24826     1.22698     -3.85911     -11.23812
mean/mean                             0.19624      0.04348     0.27960      0.08869
mean/std                              1.43465      0.01749     1.47867      1.38502
mean/max                              5.72286      0.42480     6.23598      5.13892
mean/min                              -6.86353     0.94777     -3.73880     -7.70550
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 7, 6, 0, 4, 3, 2, 5, 9, 1]
replay_buffer._size: [60300 60300 60300 60300 60300 60300 60300 60300 60300 60300]
2023-08-12 12:38:55,307 MainThread INFO: EPOCH:380
2023-08-12 12:38:55,307 MainThread INFO: Time Consumed:8.811168193817139s
2023-08-12 12:38:55,307 MainThread INFO: Total Frames:601500s
  4%|▍         | 381/10000 [57:34<23:14:33,  8.70s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1366.93126
Train_Epoch_Reward                    13477.92449
Running_Training_Average_Rewards      1303.15782
Explore_Time                          0.00526
Train___Time                          8.80075
Eval____Time                          0.00455
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.25746
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.16054
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.57123
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.20196
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.84040
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.32086
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.30326
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14257.88350
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.36528
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.54990
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.87619      1.41128     10.17052     3.52148
alpha_0                               3.18648      0.01192     3.20597      3.16949
alpha_1                               0.38962      0.00040     0.39065      0.38917
alpha_2                               0.13204      0.00122     0.13407      0.12980
alpha_3                               0.09203      0.00042     0.09278      0.09144
alpha_4                               0.23534      0.00047     0.23615      0.23441
alpha_5                               0.38102      0.00251     0.38584      0.37735
alpha_6                               0.27506      0.00019     0.27547      0.27475
alpha_7                               0.24580      0.00102     0.24752      0.24421
alpha_8                               0.20094      0.00159     0.20362      0.19827
alpha_9                               0.20506      0.00168     0.20795      0.20213
Alpha_loss                            -0.61983     0.16894     0.03077      -1.05067
Training/policy_loss                  175.10467    19.38642    223.27945    126.43938
Training/qf1_loss                     4016.94781   1611.32835  9092.17188   1961.98145
Training/qf2_loss                     1108.01540   373.15639   2640.77466   600.99457
Training/pf_norm                      15.29696     4.70831     30.96598     6.83098
Training/qf1_norm                     5967.08056   2705.49489  13673.75293  1791.48279
Training/qf2_norm                     4717.80928   1809.52606  10498.44727  1531.11646
log_std/mean                          -0.88595     0.01089     -0.86192     -0.91647
log_std/std                           0.42432      0.00555     0.43811      0.41178
log_std/max                           0.59722      0.24832     0.90965      0.09983
log_std/min                           -3.04847     0.37403     -2.58239     -4.19829
log_probs/mean                        3.65193      0.11023     4.06218      3.38523
log_probs/std                         3.33056      0.12150     3.78754      3.09904
log_probs/max                         23.75774     3.95907     35.92451     18.00086
log_probs/min                         -6.70850     1.48908     -4.30822     -12.24609
mean/mean                             0.22437      0.03385     0.29516      0.14291
mean/std                              1.42772      0.01731     1.50366      1.37798
mean/max                              5.83045      0.47722     6.38274      5.17507
mean/min                              -6.68428     0.99953     -3.50921     -7.45386
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 1, 4, 6, 2, 9, 5, 7, 0]
replay_buffer._size: [60450 60450 60450 60450 60450 60450 60450 60450 60450 60450]
2023-08-12 12:39:04,739 MainThread INFO: EPOCH:381
2023-08-12 12:39:04,740 MainThread INFO: Time Consumed:9.279613256454468s
2023-08-12 12:39:04,740 MainThread INFO: Total Frames:603000s
  4%|▍         | 382/10000 [57:43<23:51:22,  8.93s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1394.97760
Train_Epoch_Reward                    13573.69644
Running_Training_Average_Rewards      1348.09194
Explore_Time                          0.00472
Train___Time                          9.27035
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.98398
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.51153
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.75821
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.59190
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.92176
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.14091
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.14812
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14568.33109
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.73571
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.76295
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85592      1.26694     10.08259     3.87465
alpha_0                               3.16564      0.00805     3.17633      3.15053
alpha_1                               0.38894      0.00041     0.38958      0.38824
alpha_2                               0.12765      0.00136     0.12976      0.12521
alpha_3                               0.09113      0.00016     0.09143      0.09080
alpha_4                               0.23308      0.00075     0.23438      0.23172
alpha_5                               0.39059      0.00264     0.39451      0.38593
alpha_6                               0.27643      0.00049     0.27693      0.27550
alpha_7                               0.24293      0.00081     0.24418      0.24117
alpha_8                               0.19551      0.00149     0.19822      0.19287
alpha_9                               0.19916      0.00155     0.20206      0.19653
Alpha_loss                            -0.61379     0.21369     -0.12902     -1.08537
Training/policy_loss                  176.48664    21.79189    219.67935    115.04925
Training/qf1_loss                     3612.66665   1327.06915  8352.05957   1504.36755
Training/qf2_loss                     1057.84107   279.23059   2073.06665   595.05768
Training/pf_norm                      15.85274     6.83017     44.71958     6.45634
Training/qf1_norm                     5784.79445   2739.43273  16349.98438  1866.39282
Training/qf2_norm                     5134.99862   2603.81441  13950.42773  1918.97522
log_std/mean                          -0.90423     0.01571     -0.87709     -0.94247
log_std/std                           0.43603      0.00620     0.45087      0.42123
log_std/max                           0.59094      0.26390     0.90568      0.12395
log_std/min                           -3.08161     0.32797     -2.64658     -4.35147
log_probs/mean                        3.65853      0.14278     3.99818      3.39736
log_probs/std                         3.34658      0.12371     3.67428      3.03488
log_probs/max                         23.24234     3.66015     34.04601     17.63670
log_probs/min                         -6.40659     1.41052     -3.87486     -11.73253
mean/mean                             0.20629      0.03326     0.28305      0.13564
mean/std                              1.42099      0.01965     1.46763      1.37487
mean/max                              5.72078      0.48379     6.39591      5.12228
mean/min                              -7.08643     0.92460     -4.08687     -7.96572
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 9, 2, 5, 3, 1, 7, 0, 4, 8]
replay_buffer._size: [60600 60600 60600 60600 60600 60600 60600 60600 60600 60600]
2023-08-12 12:39:13,510 MainThread INFO: EPOCH:382
2023-08-12 12:39:13,510 MainThread INFO: Time Consumed:8.557344198226929s
2023-08-12 12:39:13,510 MainThread INFO: Total Frames:604500s
  4%|▍         | 383/10000 [57:52<23:41:46,  8.87s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1444.56188
Train_Epoch_Reward                    13990.29956
Running_Training_Average_Rewards      1368.06402
Explore_Time                          0.00568
Train___Time                          8.54705
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.80074
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.94935
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.32295
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.93872
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.22178
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.77327
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.49289
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15040.43792
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.22689
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.09256
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.72625      1.38214     10.42985     2.88496
alpha_0                               3.14406      0.00262     3.14988      3.13868
alpha_1                               0.38423      0.00257     0.38821      0.37972
alpha_2                               0.12287      0.00134     0.12516      0.12048
alpha_3                               0.09018      0.00030     0.09079      0.08985
alpha_4                               0.22991      0.00107     0.23169      0.22811
alpha_5                               0.39765      0.00177     0.40067      0.39458
alpha_6                               0.27687      0.00020     0.27725      0.27659
alpha_7                               0.23861      0.00140     0.24112      0.23622
alpha_8                               0.18996      0.00150     0.19280      0.18758
alpha_9                               0.19362      0.00167     0.19648      0.19074
Alpha_loss                            -0.78858     0.17038     -0.41349     -1.18370
Training/policy_loss                  172.73514    22.66844    231.85991    109.44753
Training/qf1_loss                     4001.27672   1670.23375  10126.82910  1505.60632
Training/qf2_loss                     1071.24547   374.18233   3176.49292   647.36493
Training/pf_norm                      16.32372     5.39498     34.30091     6.40810
Training/qf1_norm                     6004.01182   2779.73781  16711.65234  1570.26465
Training/qf2_norm                     5094.75377   2360.81792  12754.14844  1757.05554
log_std/mean                          -0.89610     0.00715     -0.88161     -0.91305
log_std/std                           0.43727      0.00654     0.45094      0.42008
log_std/max                           0.60087      0.29889     0.91238      0.14623
log_std/min                           -3.11030     0.29911     -2.61784     -4.25881
log_probs/mean                        3.55414      0.09399     3.76520      3.30423
log_probs/std                         3.29700      0.10818     3.57445      3.08335
log_probs/max                         24.14481     4.18088     34.46764     17.86724
log_probs/min                         -6.77980     1.26643     -4.17106     -10.85569
mean/mean                             0.16823      0.03347     0.23729      0.08515
mean/std                              1.41208      0.01743     1.44943      1.35899
mean/max                              5.65864      0.52249     6.32165      5.04214
mean/min                              -7.33245     0.97161     -4.53265     -8.04976
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 7, 3, 8, 4, 6, 1, 0, 5]
replay_buffer._size: [60750 60750 60750 60750 60750 60750 60750 60750 60750 60750]
2023-08-12 12:39:23,029 MainThread INFO: EPOCH:383
2023-08-12 12:39:23,029 MainThread INFO: Time Consumed:9.334832906723022s
2023-08-12 12:39:23,029 MainThread INFO: Total Frames:606000s
  4%|▍         | 384/10000 [58:02<24:12:53,  9.07s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1283.17010
Train_Epoch_Reward                    11278.63453
Running_Training_Average_Rewards      1294.75435
Explore_Time                          0.03114
Train___Time                          9.29769
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.27146
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.85332
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.60979
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.97660
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.26490
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.50248
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.79494
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13409.93982
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.15796
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.80735
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.77081      1.39763     10.21150     3.82069
alpha_0                               3.12924      0.00681     3.13951      3.11142
alpha_1                               0.37719      0.00113     0.37965      0.37567
alpha_2                               0.11801      0.00133     0.12043      0.11586
alpha_3                               0.08959      0.00018     0.08985      0.08929
alpha_4                               0.22661      0.00077     0.22808      0.22526
alpha_5                               0.40491      0.00231     0.40971      0.40076
alpha_6                               0.27703      0.00017     0.27726      0.27682
alpha_7                               0.23463      0.00092     0.23619      0.23325
alpha_8                               0.18512      0.00160     0.18754      0.18237
alpha_9                               0.18775      0.00187     0.19069      0.18439
Alpha_loss                            -0.71185     0.19015     -0.33941     -1.23795
Training/policy_loss                  170.29996    20.21805    220.91812    126.69900
Training/qf1_loss                     3953.57153   1511.42903  8393.09375   1663.56921
Training/qf2_loss                     992.92283    313.28044   2183.90283   610.67902
Training/pf_norm                      16.46259     6.61902     34.34938     7.46906
Training/qf1_norm                     5993.00209   2632.96483  14177.34766  1892.02295
Training/qf2_norm                     4594.80712   2012.01146  12480.91504  1804.62891
log_std/mean                          -0.88798     0.00818     -0.87150     -0.90826
log_std/std                           0.43599      0.00595     0.44929      0.42264
log_std/max                           0.62683      0.27574     0.89539      0.20786
log_std/min                           -3.16395     0.28178     -2.67323     -4.37555
log_probs/mean                        3.60286      0.11943     3.88001      3.34603
log_probs/std                         3.35026      0.12328     3.63808      3.01973
log_probs/max                         24.15805     4.42143     37.15749     16.88852
log_probs/min                         -6.67203     1.51200     -4.28437     -12.42362
mean/mean                             0.24054      0.05123     0.36460      0.12556
mean/std                              1.41396      0.01851     1.45772      1.37126
mean/max                              5.64192      0.58115     6.44429      5.01034
mean/min                              -7.18085     0.93124     -4.42450     -7.81219
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 3, 7, 9, 2, 1, 4, 8, 5, 6]
replay_buffer._size: [60900 60900 60900 60900 60900 60900 60900 60900 60900 60900]
2023-08-12 12:39:32,538 MainThread INFO: EPOCH:384
2023-08-12 12:39:32,539 MainThread INFO: Time Consumed:9.33754277229309s
2023-08-12 12:39:32,539 MainThread INFO: Total Frames:607500s
  4%|▍         | 385/10000 [58:11<24:34:19,  9.20s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1389.12211
Train_Epoch_Reward                    12560.71813
Running_Training_Average_Rewards      1260.98841
Explore_Time                          0.00427
Train___Time                          9.32817
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.32446
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.83877
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.03808
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.29958
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.74212
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.94426
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.80016
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14453.76978
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -78.59548
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.96576
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.80584      1.27945     10.28882     3.62718
alpha_0                               3.07561      0.01789     3.11056      3.05633
alpha_1                               0.37551      0.00063     0.37618      0.37428
alpha_2                               0.11359      0.00123     0.11582      0.11171
alpha_3                               0.08935      0.00009     0.08949      0.08924
alpha_4                               0.22365      0.00081     0.22523      0.22239
alpha_5                               0.41625      0.00341     0.42113      0.40987
alpha_6                               0.27727      0.00029     0.27750      0.27656
alpha_7                               0.23252      0.00052     0.23325      0.23136
alpha_8                               0.18015      0.00146     0.18232      0.17718
alpha_9                               0.18118      0.00185     0.18432      0.17793
Alpha_loss                            -0.67535     0.20747     -0.15478     -1.35118
Training/policy_loss                  170.36191    19.72072    213.93867    127.21602
Training/qf1_loss                     3663.65619   1163.79689  6872.29297   1915.01978
Training/qf2_loss                     1039.11443   306.59539   1894.78796   545.12366
Training/pf_norm                      17.47819     7.34051     48.72176     7.09211
Training/qf1_norm                     5694.16168   2330.21955  11935.12305  1852.60583
Training/qf2_norm                     4973.78803   2023.12820  10862.02734  1416.37646
log_std/mean                          -0.89623     0.00993     -0.87461     -0.92070
log_std/std                           0.44379      0.00773     0.46601      0.42691
log_std/max                           0.62219      0.27277     0.91287      0.25496
log_std/min                           -3.32376     0.37512     -2.64479     -4.62038
log_probs/mean                        3.61705      0.11320     3.97865      3.36145
log_probs/std                         3.39363      0.10710     3.69789      3.15360
log_probs/max                         25.04858     4.28758     37.46398     16.34586
log_probs/min                         -6.35517     1.46907     -4.04769     -10.98014
mean/mean                             0.20785      0.04813     0.28802      0.06984
mean/std                              1.41989      0.01754     1.45952      1.38437
mean/max                              5.65654      0.60144     6.33708      4.84691
mean/min                              -7.12319     0.95908     -3.90880     -7.81670
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 5, 1, 6, 2, 4, 7, 0, 9]
replay_buffer._size: [61050 61050 61050 61050 61050 61050 61050 61050 61050 61050]
2023-08-12 12:39:42,039 MainThread INFO: EPOCH:385
2023-08-12 12:39:42,039 MainThread INFO: Time Consumed:9.319049596786499s
2023-08-12 12:39:42,039 MainThread INFO: Total Frames:609000s
  4%|▍         | 386/10000 [58:21<24:48:21,  9.29s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1348.91578
Train_Epoch_Reward                    13024.22137
Running_Training_Average_Rewards      1228.78580
Explore_Time                          0.00546
Train___Time                          9.30832
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.74535
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.20436
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.65055
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.30131
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.55989
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.63777
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.19551
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14068.41289
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.33961
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.62080
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85085      1.26583     9.94580      3.68463
alpha_0                               3.05506      0.00584     3.06278      3.04608
alpha_1                               0.37242      0.00093     0.37427      0.37147
alpha_2                               0.11007      0.00087     0.11168      0.10873
alpha_3                               0.08911      0.00010     0.08933      0.08898
alpha_4                               0.22118      0.00065     0.22237      0.22011
alpha_5                               0.42548      0.00256     0.43016      0.42120
alpha_6                               0.27542      0.00077     0.27654      0.27399
alpha_7                               0.22979      0.00101     0.23132      0.22805
alpha_8                               0.17394      0.00182     0.17710      0.17081
alpha_9                               0.17468      0.00183     0.17786      0.17160
Alpha_loss                            -0.72699     0.18544     -0.21310     -1.15278
Training/policy_loss                  165.01498    21.86998    210.19556    103.75183
Training/qf1_loss                     3681.18433   1264.50505  6893.60547   1611.01965
Training/qf2_loss                     968.00420    251.08221   1819.17175   537.67627
Training/pf_norm                      16.94120     6.77952     36.91253     6.19374
Training/qf1_norm                     5657.45056   2325.68389  12673.29883  1498.48486
Training/qf2_norm                     4468.87059   1711.08994  8783.98145   1560.28992
log_std/mean                          -0.89628     0.01244     -0.86568     -0.92103
log_std/std                           0.44705      0.00688     0.46905      0.42834
log_std/max                           0.59011      0.25439     0.90778      0.27789
log_std/min                           -3.41404     0.39302     -2.58417     -4.75507
log_probs/mean                        3.60273      0.12023     3.94822      3.30161
log_probs/std                         3.40890      0.11774     3.65336      3.14092
log_probs/max                         25.89821     4.92554     39.16877     16.73449
log_probs/min                         -6.67067     1.39205     -3.94451     -11.63010
mean/mean                             0.20613      0.03744     0.30257      0.10165
mean/std                              1.41819      0.01697     1.45767      1.37243
mean/max                              5.61022      0.59050     6.49549      4.78165
mean/min                              -7.27271     1.01632     -3.87346     -7.97959
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 9, 0, 8, 2, 4, 6, 5, 1, 3]
replay_buffer._size: [61200 61200 61200 61200 61200 61200 61200 61200 61200 61200]
2023-08-12 12:39:51,685 MainThread INFO: EPOCH:386
2023-08-12 12:39:51,686 MainThread INFO: Time Consumed:9.479807138442993s
2023-08-12 12:39:51,686 MainThread INFO: Total Frames:610500s
  4%|▍         | 387/10000 [58:30<25:05:24,  9.40s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1418.88936
Train_Epoch_Reward                    13600.75676
Running_Training_Average_Rewards      1306.18988
Explore_Time                          0.00481
Train___Time                          9.46991
Eval____Time                          0.00445
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.34388
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.23886
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.57153
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.93792
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.06657
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.14799
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.47927
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14705.42302
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.66535
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.07805
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.93175      1.32032     10.21341     3.72943
alpha_0                               3.03454      0.01140     3.04798      3.01764
alpha_1                               0.37039      0.00052     0.37145      0.36960
alpha_2                               0.10772      0.00050     0.10870      0.10706
alpha_3                               0.08902      0.00005     0.08908      0.08891
alpha_4                               0.21883      0.00073     0.22009      0.21777
alpha_5                               0.43590      0.00301     0.44061      0.43029
alpha_6                               0.27213      0.00120     0.27397      0.26981
alpha_7                               0.22610      0.00147     0.22803      0.22336
alpha_8                               0.16769      0.00184     0.17075      0.16438
alpha_9                               0.16876      0.00163     0.17154      0.16592
Alpha_loss                            -0.68517     0.20564     -0.20909     -1.26632
Training/policy_loss                  165.59948    21.65695    242.79398    127.47756
Training/qf1_loss                     3536.90877   1529.01892  9522.26074   1125.67310
Training/qf2_loss                     1009.13645   336.47394   2639.67114   522.74756
Training/pf_norm                      15.44068     6.29772     43.59306     6.50453
Training/qf1_norm                     5049.92335   2228.54536  13680.61133  1715.53467
Training/qf2_norm                     4703.37620   1754.33311  10439.47461  1529.07117
log_std/mean                          -0.89811     0.00911     -0.87604     -0.92133
log_std/std                           0.45294      0.00569     0.46504      0.43692
log_std/max                           0.59962      0.23450     0.91478      0.32645
log_std/min                           -3.41298     0.32872     -2.63770     -4.77422
log_probs/mean                        3.60919      0.12951     3.89633      3.24657
log_probs/std                         3.45318      0.12362     3.93451      3.19601
log_probs/max                         24.94605     4.20785     36.12016     17.11163
log_probs/min                         -6.49521     1.09286     -4.11157     -9.60675
mean/mean                             0.15777      0.03230     0.24118      0.09475
mean/std                              1.42395      0.02096     1.49177      1.37312
mean/max                              5.86944      0.60211     6.54121      4.56548
mean/min                              -7.48302     1.03125     -4.61621     -8.23953
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 5, 8, 3, 1, 9, 2, 6, 0, 4]
replay_buffer._size: [61350 61350 61350 61350 61350 61350 61350 61350 61350 61350]
2023-08-12 12:40:01,020 MainThread INFO: EPOCH:387
2023-08-12 12:40:01,020 MainThread INFO: Time Consumed:9.164374113082886s
2023-08-12 12:40:01,020 MainThread INFO: Total Frames:612000s
  4%|▍         | 388/10000 [58:40<25:02:14,  9.38s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1441.56755
Train_Epoch_Reward                    14070.57910
Running_Training_Average_Rewards      1356.51857
Explore_Time                          0.00438
Train___Time                          9.15407
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.23461
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.80646
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.56364
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.20665
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.23563
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.83515
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.48072
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14968.34682
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.63683
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.67168
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.54628      1.13012     8.98907      3.38764
alpha_0                               3.01062      0.00648     3.01962      2.99804
alpha_1                               0.36945      0.00072     0.37037      0.36834
alpha_2                               0.10676      0.00015     0.10706      0.10659
alpha_3                               0.08913      0.00016     0.08939      0.08890
alpha_4                               0.21654      0.00069     0.21776      0.21534
alpha_5                               0.44599      0.00301     0.45112      0.44073
alpha_6                               0.26750      0.00136     0.26976      0.26504
alpha_7                               0.22096      0.00134     0.22330      0.21861
alpha_8                               0.16158      0.00155     0.16432      0.15893
alpha_9                               0.16326      0.00149     0.16586      0.16077
Alpha_loss                            -0.54570     0.15557     -0.21494     -0.95316
Training/policy_loss                  163.43126    21.43472    217.91621    109.85857
Training/qf1_loss                     3428.23904   1304.35360  8972.15332   1349.14783
Training/qf2_loss                     945.99776    316.41984   2012.58167   539.26215
Training/pf_norm                      15.20039     6.08968     31.23559     5.52262
Training/qf1_norm                     5229.43688   2464.86919  15416.94531  1510.34949
Training/qf2_norm                     4847.35202   1890.57709  11342.39941  2173.08618
log_std/mean                          -0.90575     0.00793     -0.88948     -0.92560
log_std/std                           0.45585      0.00882     0.47995      0.43838
log_std/max                           0.62754      0.18335     0.86392      0.35772
log_std/min                           -3.56400     0.42294     -2.65290     -4.81824
log_probs/mean                        3.68062      0.10037     3.92251      3.42796
log_probs/std                         3.49419      0.12051     3.77761      3.21451
log_probs/max                         26.15465     4.77485     36.75497     17.93883
log_probs/min                         -6.65838     1.30870     -3.90676     -10.41029
mean/mean                             0.13532      0.02463     0.19404      0.08033
mean/std                              1.43448      0.01807     1.46717      1.38352
mean/max                              5.79564      0.61970     6.54845      4.49239
mean/min                              -7.74245     0.94677     -4.22766     -8.49960
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 1, 8, 3, 5, 2, 4, 6, 9, 7]
replay_buffer._size: [61500 61500 61500 61500 61500 61500 61500 61500 61500 61500]
2023-08-12 12:40:10,498 MainThread INFO: EPOCH:388
2023-08-12 12:40:10,499 MainThread INFO: Time Consumed:9.310906887054443s
2023-08-12 12:40:10,499 MainThread INFO: Total Frames:613500s
  4%|▍         | 389/10000 [58:49<25:07:28,  9.41s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1427.55403
Train_Epoch_Reward                    13868.98840
Running_Training_Average_Rewards      1384.67748
Explore_Time                          0.00863
Train___Time                          9.29721
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.40296
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.10257
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.30379
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.25911
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.46199
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.73327
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.71798
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14853.62947
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.82538
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.28212
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.07748      1.31481     9.96024      3.74610
alpha_0                               2.97411      0.01484     3.00111      2.95287
alpha_1                               0.36768      0.00033     0.36833      0.36681
alpha_2                               0.10695      0.00021     0.10720      0.10660
alpha_3                               0.09056      0.00080     0.09182      0.08941
alpha_4                               0.21390      0.00085     0.21530      0.21245
alpha_5                               0.45651      0.00272     0.46064      0.45124
alpha_6                               0.26292      0.00113     0.26499      0.26074
alpha_7                               0.21694      0.00102     0.21857      0.21483
alpha_8                               0.15706      0.00092     0.15888      0.15545
alpha_9                               0.15865      0.00120     0.16073      0.15654
Alpha_loss                            -0.22479     0.25574     0.30431      -0.81573
Training/policy_loss                  159.19649    20.59339    198.76689    101.15806
Training/qf1_loss                     3736.95584   1517.65836  9900.20215   1346.29773
Training/qf2_loss                     975.26302    337.40573   2479.61206   518.39941
Training/pf_norm                      15.61339     4.85453     28.26709     6.70332
Training/qf1_norm                     5715.83501   2463.25482  15832.19336  2088.56128
Training/qf2_norm                     5380.79892   2239.55297  12342.34180  1666.72937
log_std/mean                          -0.89505     0.01443     -0.86667     -0.92138
log_std/std                           0.44892      0.00697     0.46424      0.42735
log_std/max                           0.64934      0.13677     0.82509      0.45884
log_std/min                           -3.48218     0.41389     -2.65192     -4.80465
log_probs/mean                        3.80313      0.14444     4.14678      3.34967
log_probs/std                         3.52372      0.12138     3.87186      3.24519
log_probs/max                         27.44290     5.07083     40.36540     16.91202
log_probs/min                         -6.47507     1.33065     -4.20852     -10.59834
mean/mean                             0.15941      0.03637     0.24543      0.08007
mean/std                              1.45609      0.01848     1.50368      1.40459
mean/max                              5.40725      0.61682     6.28970      4.57852
mean/min                              -7.76783     0.90509     -4.03873     -8.29324
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 2, 1, 4, 5, 9, 3, 0, 7, 6]
replay_buffer._size: [61650 61650 61650 61650 61650 61650 61650 61650 61650 61650]
2023-08-12 12:40:20,151 MainThread INFO: EPOCH:389
2023-08-12 12:40:20,151 MainThread INFO: Time Consumed:9.456079244613647s
2023-08-12 12:40:20,151 MainThread INFO: Total Frames:615000s
  4%|▍         | 390/10000 [58:59<25:19:48,  9.49s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1507.92525
Train_Epoch_Reward                    13743.60998
Running_Training_Average_Rewards      1389.43925
Explore_Time                          0.00455
Train___Time                          9.44648
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.87543
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  509.76029
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.45498
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.97244
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.78006
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.39578
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.23322
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15076.49684
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.09261
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.20011
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.40602      1.26737     10.19408     3.89073
alpha_0                               2.92364      0.01447     2.95204      2.90163
alpha_1                               0.36666      0.00040     0.36780      0.36617
alpha_2                               0.10784      0.00064     0.10888      0.10695
alpha_3                               0.09252      0.00041     0.09327      0.09184
alpha_4                               0.21172      0.00024     0.21242      0.21143
alpha_5                               0.46586      0.00317     0.47159      0.46073
alpha_6                               0.25763      0.00190     0.26069      0.25439
alpha_7                               0.21265      0.00105     0.21478      0.21120
alpha_8                               0.15315      0.00137     0.15541      0.15091
alpha_9                               0.15427      0.00132     0.15649      0.15205
Alpha_loss                            -0.24205     0.19974     0.27833      -0.78427
Training/policy_loss                  160.76022    21.64588    205.31372    92.43884
Training/qf1_loss                     3348.19219   1308.73043  8663.32324   1099.37988
Training/qf2_loss                     901.00614    263.57161   1969.86975   512.90936
Training/pf_norm                      13.63372     5.09640     27.16608     5.46108
Training/qf1_norm                     5351.07869   1984.19428  12092.70996  2177.63184
Training/qf2_norm                     4124.32489   1940.11933  12790.27344  1349.67090
log_std/mean                          -0.89160     0.00802     -0.87018     -0.90690
log_std/std                           0.45754      0.00647     0.47402      0.44469
log_std/max                           0.70646      0.13028     0.90632      0.51020
log_std/min                           -3.45360     0.40246     -2.60436     -4.74059
log_probs/mean                        3.81588      0.11390     4.10538      3.55894
log_probs/std                         3.63084      0.13572     4.03821      3.24521
log_probs/max                         27.81698     4.26290     36.51336     18.36595
log_probs/min                         -6.41590     1.11013     -4.33093     -9.87229
mean/mean                             0.13404      0.02883     0.21929      0.07274
mean/std                              1.46933      0.02114     1.52042      1.40979
mean/max                              5.76055      0.58447     6.50921      4.73664
mean/min                              -7.71485     0.97424     -4.77953     -8.38291
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 9, 5, 6, 1, 7, 8, 2, 0]
replay_buffer._size: [61800 61800 61800 61800 61800 61800 61800 61800 61800 61800]
2023-08-12 12:40:29,179 MainThread INFO: EPOCH:390
2023-08-12 12:40:29,179 MainThread INFO: Time Consumed:8.878255128860474s
2023-08-12 12:40:29,179 MainThread INFO: Total Frames:616500s
  4%|▍         | 391/10000 [59:08<24:56:12,  9.34s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1417.17001
Train_Epoch_Reward                    14800.74141
Running_Training_Average_Rewards      1413.77799
Explore_Time                          0.01014
Train___Time                          8.86341
Eval____Time                          0.00400
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.56526
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.68504
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.38002
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.08901
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.21528
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.43196
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.82819
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14737.08621
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.93294
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.25838
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85728      1.37760     10.37508     3.68642
alpha_0                               2.89449      0.00516     2.90104      2.88566
alpha_1                               0.37180      0.00238     0.37516      0.36786
alpha_2                               0.11021      0.00075     0.11150      0.10890
alpha_3                               0.09454      0.00083     0.09606      0.09328
alpha_4                               0.21092      0.00036     0.21142      0.21030
alpha_5                               0.47629      0.00283     0.48117      0.47169
alpha_6                               0.25184      0.00136     0.25433      0.24934
alpha_7                               0.21057      0.00019     0.21116      0.21039
alpha_8                               0.14929      0.00084     0.15087      0.14801
alpha_9                               0.14994      0.00121     0.15201      0.14785
Alpha_loss                            -0.00725     0.19001     0.44067      -0.44321
Training/policy_loss                  154.10947    20.39394    199.87479    99.07400
Training/qf1_loss                     3644.54721   1377.91623  7506.63623   999.10956
Training/qf2_loss                     1001.78924   340.44601   2481.20508   590.97437
Training/pf_norm                      15.79342     5.38103     32.91016     6.15442
Training/qf1_norm                     5437.98533   2426.17200  14619.39844  2089.10107
Training/qf2_norm                     5337.16265   2234.79134  13279.29199  1661.38013
log_std/mean                          -0.89702     0.00915     -0.87424     -0.91561
log_std/std                           0.45259      0.00553     0.46685      0.44116
log_std/max                           0.76371      0.12563     0.90599      0.52182
log_std/min                           -3.50009     0.48505     -2.61536     -4.90465
log_probs/mean                        3.98196      0.11043     4.24198      3.71415
log_probs/std                         3.66744      0.12739     3.99384      3.31404
log_probs/max                         28.79604     4.41977     41.11134     20.93967
log_probs/min                         -6.60212     1.38292     -3.89683     -12.43009
mean/mean                             0.17151      0.04003     0.24967      0.07933
mean/std                              1.48585      0.02017     1.53733      1.43825
mean/max                              5.91022      0.49316     6.49911      5.02989
mean/min                              -7.75875     0.88033     -4.83065     -8.55392
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 9, 0, 7, 6, 3, 2, 5, 4]
replay_buffer._size: [61950 61950 61950 61950 61950 61950 61950 61950 61950 61950]
2023-08-12 12:40:38,589 MainThread INFO: EPOCH:391
2023-08-12 12:40:38,589 MainThread INFO: Time Consumed:9.245816707611084s
2023-08-12 12:40:38,589 MainThread INFO: Total Frames:618000s
  4%|▍         | 392/10000 [59:17<24:59:17,  9.36s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1443.10613
Train_Epoch_Reward                    14749.46037
Running_Training_Average_Rewards      1443.12706
Explore_Time                          0.00389
Train___Time                          9.23680
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.04843
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.18478
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.24649
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.85683
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.87702
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.27897
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.98860
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14998.78555
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.95484
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.28830
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.99898      1.66784     13.80466     3.98465
alpha_0                               2.89941      0.00405     2.90788      2.89311
alpha_1                               0.37637      0.00104     0.37761      0.37495
alpha_2                               0.11304      0.00101     0.11491      0.11153
alpha_3                               0.09778      0.00096     0.09933      0.09609
alpha_4                               0.20950      0.00052     0.21030      0.20846
alpha_5                               0.48489      0.00219     0.48857      0.48125
alpha_6                               0.24625      0.00185     0.24928      0.24311
alpha_7                               0.21055      0.00011     0.21071      0.21036
alpha_8                               0.14750      0.00026     0.14799      0.14704
alpha_9                               0.14576      0.00113     0.14781      0.14381
Alpha_loss                            0.06198      0.20926     0.48209      -0.62148
Training/policy_loss                  151.45433    25.20173    209.97676    77.87782
Training/qf1_loss                     3651.45668   1481.85051  8288.92188   1345.01404
Training/qf2_loss                     933.55781    349.93643   2587.04541   511.30978
Training/pf_norm                      14.97029     5.60038     38.55563     6.82324
Training/qf1_norm                     5915.61575   3192.44420  18922.49805  2224.52808
Training/qf2_norm                     4763.14204   2221.10530  13202.61621  1301.05847
log_std/mean                          -0.89434     0.01300     -0.86159     -0.91698
log_std/std                           0.45537      0.00599     0.46942      0.44285
log_std/max                           0.74316      0.13753     0.90587      0.51514
log_std/min                           -3.50319     0.49714     -2.63494     -4.92980
log_probs/mean                        3.99577      0.12523     4.38344      3.71357
log_probs/std                         3.68925      0.15448     4.11887      3.33494
log_probs/max                         28.87841     4.90989     41.36117     18.26752
log_probs/min                         -6.44897     1.14488     -4.07721     -10.31906
mean/mean                             0.13511      0.03649     0.23310      0.05280
mean/std                              1.49302      0.02276     1.57581      1.43865
mean/max                              5.96627      0.35607     6.37469      5.37676
mean/min                              -7.76423     1.00879     -4.66250     -8.47295
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 4, 1, 6, 7, 0, 9, 3, 5, 8]
replay_buffer._size: [62100 62100 62100 62100 62100 62100 62100 62100 62100 62100]
2023-08-12 12:40:48,249 MainThread INFO: EPOCH:392
2023-08-12 12:40:48,249 MainThread INFO: Time Consumed:9.448853254318237s
2023-08-12 12:40:48,249 MainThread INFO: Total Frames:619500s
  4%|▍         | 393/10000 [59:27<25:13:26,  9.45s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1541.48927
Train_Epoch_Reward                    14710.46102
Running_Training_Average_Rewards      1475.35543
Explore_Time                          0.00895
Train___Time                          9.43471
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.60391
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.46420
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.70263
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.17308
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.24279
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.05827
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.97082
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16015.04023
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -66.42814
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.50373
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.77120      1.43260     10.74932     3.71497
alpha_0                               2.87561      0.00720     2.89298      2.86758
alpha_1                               0.38157      0.00208     0.38358      0.37763
alpha_2                               0.11721      0.00122     0.11942      0.11495
alpha_3                               0.10019      0.00064     0.10171      0.09935
alpha_4                               0.20683      0.00088     0.20844      0.20559
alpha_5                               0.49280      0.00246     0.49663      0.48863
alpha_6                               0.24047      0.00149     0.24306      0.23791
alpha_7                               0.20965      0.00045     0.21044      0.20873
alpha_8                               0.14652      0.00031     0.14704      0.14610
alpha_9                               0.14185      0.00108     0.14377      0.14005
Alpha_loss                            0.07220      0.23104     0.68836      -0.40016
Training/policy_loss                  150.30796    23.31558    197.12190    82.94505
Training/qf1_loss                     3409.05788   1402.37647  7869.20312   1422.57166
Training/qf2_loss                     932.91468    401.17487   3603.04077   494.48560
Training/pf_norm                      13.89526     4.00031     29.77499     5.96927
Training/qf1_norm                     5500.17612   2616.75346  18629.50586  1906.25647
Training/qf2_norm                     5135.15176   2411.25657  17400.08789  2058.63599
log_std/mean                          -0.90188     0.00894     -0.88295     -0.92151
log_std/std                           0.45570      0.00650     0.47451      0.43895
log_std/max                           0.75829      0.11262     0.92059      0.56707
log_std/min                           -3.50995     0.47251     -2.65238     -4.88356
log_probs/mean                        4.00953      0.13722     4.38953      3.70301
log_probs/std                         3.71427      0.13429     4.06066      3.33251
log_probs/max                         27.67396     4.05087     38.99483     19.95021
log_probs/min                         -6.48530     1.29288     -4.27330     -11.90444
mean/mean                             0.12457      0.04161     0.23898      0.04890
mean/std                              1.49274      0.02448     1.55134      1.42940
mean/max                              5.99588      0.44812     6.61318      5.01540
mean/min                              -8.20154     1.07428     -4.68244     -9.17708
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 1, 6, 2, 0, 8, 7, 4, 5]
replay_buffer._size: [62250 62250 62250 62250 62250 62250 62250 62250 62250 62250]
2023-08-12 12:40:58,006 MainThread INFO: EPOCH:393
2023-08-12 12:40:58,007 MainThread INFO: Time Consumed:9.585844039916992s
2023-08-12 12:40:58,007 MainThread INFO: Total Frames:621000s
  4%|▍         | 394/10000 [59:37<25:28:28,  9.55s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1453.48937
Train_Epoch_Reward                    15796.59096
Running_Training_Average_Rewards      1508.55041
Explore_Time                          0.01130
Train___Time                          9.56993
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.48180
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.35787
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.08223
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.13679
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.55889
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.49733
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.12416
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15128.87291
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.36055
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.37962
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.86207      1.29215     9.99025      4.25281
alpha_0                               2.87717      0.00149     2.87940      2.87397
alpha_1                               0.38480      0.00132     0.38816      0.38340
alpha_2                               0.12266      0.00177     0.12563      0.11948
alpha_3                               0.10427      0.00142     0.10675      0.10177
alpha_4                               0.20461      0.00070     0.20558      0.20328
alpha_5                               0.49845      0.00098     0.50112      0.49670
alpha_6                               0.23537      0.00157     0.23787      0.23279
alpha_7                               0.20731      0.00086     0.20872      0.20590
alpha_8                               0.14587      0.00017     0.14611      0.14567
alpha_9                               0.13817      0.00106     0.14001      0.13640
Alpha_loss                            0.32031      0.23175     0.93598      -0.16115
Training/policy_loss                  147.56617    19.88030    196.57339    106.73025
Training/qf1_loss                     3211.78633   1259.87286  7567.10791   1401.51758
Training/qf2_loss                     911.63922    358.10917   3125.83838   520.65509
Training/pf_norm                      15.49727     5.62751     35.86878     6.09020
Training/qf1_norm                     5515.21553   2452.14081  13683.12109  1911.43005
Training/qf2_norm                     4699.41431   1800.96950  10538.31250  1824.90479
log_std/mean                          -0.89269     0.01281     -0.86195     -0.92028
log_std/std                           0.45264      0.00586     0.46804      0.43723
log_std/max                           0.72970      0.08500     0.86372      0.58410
log_std/min                           -3.38734     0.38902     -2.49795     -4.83225
log_probs/mean                        4.12389      0.13664     4.55390      3.88231
log_probs/std                         3.79842      0.15581     4.13022      3.42652
log_probs/max                         30.24878     4.71649     40.38277     21.79310
log_probs/min                         -6.37656     1.35191     -3.88897     -10.83616
mean/mean                             0.09429      0.04028     0.20303      0.00623
mean/std                              1.52079      0.02361     1.58624      1.46981
mean/max                              6.28050      0.21556     6.57045      5.50200
mean/min                              -8.46277     1.20059     -4.03150     -9.29008
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 7, 0, 1, 8, 9, 5, 2, 4]
replay_buffer._size: [62400 62400 62400 62400 62400 62400 62400 62400 62400 62400]
2023-08-12 12:41:06,951 MainThread INFO: EPOCH:394
2023-08-12 12:41:06,952 MainThread INFO: Time Consumed:8.775546073913574s
2023-08-12 12:41:06,952 MainThread INFO: Total Frames:622500s
  4%|▍         | 395/10000 [59:46<24:58:47,  9.36s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1540.67780
Train_Epoch_Reward                    14220.96629
Running_Training_Average_Rewards      1490.93394
Explore_Time                          0.00886
Train___Time                          8.76153
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.77041
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.76635
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.71631
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -12.69709
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.00486
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.53356
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.41614
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16023.75649
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.46805
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.60574
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.05494      1.33603     11.75453     4.46923
alpha_0                               2.88121      0.00292     2.88684      2.87509
alpha_1                               0.39206      0.00148     0.39338      0.38828
alpha_2                               0.12829      0.00146     0.13087      0.12569
alpha_3                               0.10921      0.00151     0.11186      0.10680
alpha_4                               0.20144      0.00107     0.20325      0.19971
alpha_5                               0.50441      0.00166     0.50673      0.50122
alpha_6                               0.22995      0.00147     0.23274      0.22756
alpha_7                               0.20326      0.00152     0.20586      0.20093
alpha_8                               0.14578      0.00037     0.14648      0.14542
alpha_9                               0.13479      0.00089     0.13637      0.13329
Alpha_loss                            0.30071      0.20086     0.74747      -0.16578
Training/policy_loss                  139.90166    23.95493    193.59705    66.39815
Training/qf1_loss                     3407.26342   1455.93539  8240.71582   1156.24792
Training/qf2_loss                     902.88527    335.67139   2322.36133   536.30841
Training/pf_norm                      15.15784     5.70190     33.72780     6.57100
Training/qf1_norm                     5111.44078   2298.95960  13125.92578  1447.33301
Training/qf2_norm                     4596.55292   2184.11326  14718.31055  1596.38770
log_std/mean                          -0.89909     0.01238     -0.86972     -0.92487
log_std/std                           0.45259      0.00522     0.46600      0.44182
log_std/max                           0.73542      0.08953     0.88330      0.59857
log_std/min                           -3.38577     0.46757     -2.47633     -4.75151
log_probs/mean                        4.10841      0.11119     4.42553      3.77116
log_probs/std                         3.78299      0.11798     4.05253      3.52898
log_probs/max                         28.86548     4.89839     40.43554     21.56411
log_probs/min                         -6.19814     1.36684     -3.80026     -11.73488
mean/mean                             0.10638      0.04109     0.20927      0.00948
mean/std                              1.51411      0.01944     1.56604      1.46586
mean/max                              6.50548      0.26383     6.86057      5.62329
mean/min                              -8.61985     1.19119     -4.90477     -9.63294
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 4, 8, 7, 3, 1, 2, 6, 5, 9]
replay_buffer._size: [62550 62550 62550 62550 62550 62550 62550 62550 62550 62550]
2023-08-12 12:41:16,040 MainThread INFO: EPOCH:395
2023-08-12 12:41:16,041 MainThread INFO: Time Consumed:8.902788400650024s
2023-08-12 12:41:16,041 MainThread INFO: Total Frames:624000s
  4%|▍         | 396/10000 [59:55<24:45:33,  9.28s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1513.99915
Train_Epoch_Reward                    14950.70750
Running_Training_Average_Rewards      1498.94216
Explore_Time                          0.00535
Train___Time                          8.89114
Eval____Time                          0.00482
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.49347
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.21931
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.29852
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.01741
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.39212
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.26593
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.39970
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15733.03437
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.52674
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.42971
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.05943      1.55802     12.46314     3.49597
alpha_0                               2.85841      0.00643     2.87446      2.85051
alpha_1                               0.39547      0.00143     0.39719      0.39340
alpha_2                               0.13381      0.00168     0.13654      0.13093
alpha_3                               0.11494      0.00178     0.11789      0.11192
alpha_4                               0.19885      0.00054     0.19968      0.19762
alpha_5                               0.50830      0.00113     0.51048      0.50679
alpha_6                               0.22497      0.00145     0.22751      0.22249
alpha_7                               0.19940      0.00089     0.20090      0.19792
alpha_8                               0.14713      0.00044     0.14790      0.14649
alpha_9                               0.13151      0.00100     0.13325      0.12986
Alpha_loss                            0.42903      0.21617     0.96194      -0.09096
Training/policy_loss                  140.86898    20.55774    184.46664    76.43239
Training/qf1_loss                     3425.97130   1301.79036  7484.96094   1265.77344
Training/qf2_loss                     916.24141    370.14765   2325.33667   433.98508
Training/pf_norm                      12.19853     4.72392     38.55698     5.96191
Training/qf1_norm                     5440.87145   2590.48791  13741.02051  1941.99841
Training/qf2_norm                     5201.16225   2203.39821  11766.39648  1897.92188
log_std/mean                          -0.89168     0.01086     -0.86088     -0.91183
log_std/std                           0.45490      0.00611     0.46778      0.43671
log_std/max                           0.79175      0.06572     0.93423      0.65148
log_std/min                           -3.30415     0.46927     -2.55248     -4.71075
log_probs/mean                        4.17895      0.12934     4.48297      3.80211
log_probs/std                         3.80905      0.15884     4.18213      3.49749
log_probs/max                         29.37827     5.04322     42.82376     20.69729
log_probs/min                         -6.59248     1.34290     -3.89325     -11.90358
mean/mean                             0.10439      0.03392     0.18360      0.02375
mean/std                              1.53140      0.02275     1.59364      1.46491
mean/max                              6.63332      0.22996     6.91607      5.43136
mean/min                              -8.76073     1.40878     -4.91495     -9.70737
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 0, 8, 1, 9, 2, 3, 7, 6]
replay_buffer._size: [62700 62700 62700 62700 62700 62700 62700 62700 62700 62700]
2023-08-12 12:41:25,676 MainThread INFO: EPOCH:396
2023-08-12 12:41:25,677 MainThread INFO: Time Consumed:9.446955442428589s
2023-08-12 12:41:25,677 MainThread INFO: Total Frames:625500s
  4%|▍         | 397/10000 [1:00:04<25:05:24,  9.41s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1526.76238
Train_Epoch_Reward                    15504.91548
Running_Training_Average_Rewards      1489.21964
Explore_Time                          0.00486
Train___Time                          9.43689
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.92921
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.50466
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.91743
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.78645
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.96091
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.63142
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.99470
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15823.87990
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.83368
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.69769
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.02625      1.33173     11.22001     3.18756
alpha_0                               2.85191      0.00841     2.86015      2.83407
alpha_1                               0.39782      0.00072     0.39896      0.39668
alpha_2                               0.13936      0.00164     0.14212      0.13659
alpha_3                               0.12007      0.00133     0.12234      0.11793
alpha_4                               0.19650      0.00061     0.19759      0.19548
alpha_5                               0.51166      0.00046     0.51222      0.51052
alpha_6                               0.21975      0.00129     0.22243      0.21796
alpha_7                               0.19582      0.00111     0.19788      0.19415
alpha_8                               0.14914      0.00071     0.15027      0.14791
alpha_9                               0.12838      0.00083     0.12982      0.12694
Alpha_loss                            0.39112      0.20003     0.80138      -0.08922
Training/policy_loss                  132.30997    22.35235    204.87346    81.00999
Training/qf1_loss                     3353.88916   1342.31405  7653.50732   1157.55603
Training/qf2_loss                     830.70733    278.48854   1899.78796   431.57745
Training/pf_norm                      12.51822     4.17316     24.06245     4.47411
Training/qf1_norm                     5205.35341   2075.82056  11909.51367  1718.45276
Training/qf2_norm                     4488.90983   1826.60575  10390.25488  1341.50110
log_std/mean                          -0.89273     0.00637     -0.87664     -0.90937
log_std/std                           0.45083      0.00689     0.46636      0.43337
log_std/max                           0.79261      0.07097     0.91729      0.68624
log_std/min                           -3.26424     0.42736     -2.50555     -4.61763
log_probs/mean                        4.15928      0.12250     4.52000      3.87551
log_probs/std                         3.76394      0.14521     4.26823      3.47753
log_probs/max                         29.88075     5.28757     43.16516     21.06111
log_probs/min                         -6.34961     1.30010     -4.36299     -10.61186
mean/mean                             0.09409      0.03463     0.16242      0.01283
mean/std                              1.52559      0.02069     1.57989      1.46511
mean/max                              6.60636      0.28782     7.00248      6.10360
mean/min                              -8.90779     1.40282     -4.68676     -9.95260
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 5, 3, 9, 6, 8, 4, 1, 0, 2]
replay_buffer._size: [62850 62850 62850 62850 62850 62850 62850 62850 62850 62850]
2023-08-12 12:41:35,444 MainThread INFO: EPOCH:397
2023-08-12 12:41:35,445 MainThread INFO: Time Consumed:9.59299898147583s
2023-08-12 12:41:35,445 MainThread INFO: Total Frames:627000s
  4%|▍         | 398/10000 [1:00:14<25:19:38,  9.50s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1529.81227
Train_Epoch_Reward                    14518.71315
Running_Training_Average_Rewards      1499.14454
Explore_Time                          0.00675
Train___Time                          9.58096
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.26110
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.27333
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.97404
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.04628
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.92672
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.71410
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.02107
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15902.77211
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.76031
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.67242
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.82412      1.34139     9.47000      3.60214
alpha_0                               2.83485      0.00450     2.84039      2.82404
alpha_1                               0.39925      0.00033     0.40029      0.39881
alpha_2                               0.14487      0.00151     0.14725      0.14218
alpha_3                               0.12431      0.00101     0.12589      0.12238
alpha_4                               0.19474      0.00054     0.19547      0.19367
alpha_5                               0.51352      0.00084     0.51466      0.51224
alpha_6                               0.21632      0.00098     0.21794      0.21467
alpha_7                               0.19263      0.00074     0.19414      0.19169
alpha_8                               0.15149      0.00055     0.15208      0.15030
alpha_9                               0.12548      0.00080     0.12691      0.12418
Alpha_loss                            0.28046      0.20417     0.79910      -0.20147
Training/policy_loss                  133.10483    24.49999    195.88629    85.93255
Training/qf1_loss                     3291.12863   1204.55505  5896.32910   1278.45349
Training/qf2_loss                     835.18286    287.88396   1837.58167   472.86163
Training/pf_norm                      13.12448     5.00929     34.80718     6.03764
Training/qf1_norm                     5420.74193   2615.67310  15103.43066  1733.28418
Training/qf2_norm                     4712.67132   2146.39622  10191.40234  1472.64856
log_std/mean                          -0.88570     0.00950     -0.86371     -0.90516
log_std/std                           0.45279      0.00650     0.47169      0.43686
log_std/max                           0.82665      0.05193     0.91440      0.71856
log_std/min                           -3.18735     0.40498     -2.62353     -4.57357
log_probs/mean                        4.12142      0.12501     4.40748      3.82982
log_probs/std                         3.71982      0.14962     4.12084      3.36613
log_probs/max                         28.78250     4.30625     37.96327     20.06170
log_probs/min                         -6.53792     1.16797     -4.42469     -10.09638
mean/mean                             0.12068      0.03158     0.18348      0.02536
mean/std                              1.51996      0.02204     1.57357      1.47681
mean/max                              6.50091      0.42399     7.01010      5.61221
mean/min                              -8.89492     1.41283     -5.21014     -10.05035
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 0, 2, 1, 3, 8, 7, 9, 5, 4]
replay_buffer._size: [63000 63000 63000 63000 63000 63000 63000 63000 63000 63000]
2023-08-12 12:41:45,201 MainThread INFO: EPOCH:398
2023-08-12 12:41:45,203 MainThread INFO: Time Consumed:9.565065383911133s
2023-08-12 12:41:45,203 MainThread INFO: Total Frames:628500s
  4%|▍         | 399/10000 [1:00:24<25:34:20,  9.59s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1523.19489
Train_Epoch_Reward                    15681.22805
Running_Training_Average_Rewards      1523.49522
Explore_Time                          0.01174
Train___Time                          9.54787
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.12548
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.30771
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.64595
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.88059
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.65767
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.32792
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.99555
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15843.11971
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.43528
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.79463
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.64328      1.24022     9.44240      3.87844
alpha_0                               2.80514      0.00772     2.82338      2.79110
alpha_1                               0.40382      0.00206     0.40710      0.40037
alpha_2                               0.14952      0.00117     0.15145      0.14730
alpha_3                               0.12815      0.00136     0.13049      0.12592
alpha_4                               0.19271      0.00057     0.19364      0.19174
alpha_5                               0.51444      0.00057     0.51574      0.51359
alpha_6                               0.21329      0.00079     0.21464      0.21195
alpha_7                               0.19093      0.00029     0.19167      0.19065
alpha_8                               0.15386      0.00123     0.15614      0.15210
alpha_9                               0.12307      0.00063     0.12416      0.12195
Alpha_loss                            0.45392      0.16223     0.91195      0.00412
Training/policy_loss                  131.07173    21.87413    182.94131    74.12643
Training/qf1_loss                     3092.79113   1152.19047  6684.20459   1164.34204
Training/qf2_loss                     792.52522    321.14608   2373.39453   359.46143
Training/pf_norm                      12.57512     4.03169     23.42624     4.34863
Training/qf1_norm                     5646.90448   2550.55600  14996.33203  1642.68018
Training/qf2_norm                     4739.41609   1861.83806  12479.83105  1513.80774
log_std/mean                          -0.87064     0.01021     -0.84723     -0.89152
log_std/std                           0.44314      0.00805     0.45985      0.42647
log_std/max                           0.88666      0.04303     0.96205      0.81776
log_std/min                           -3.02557     0.30559     -2.55156     -4.32905
log_probs/mean                        4.21311      0.10267     4.44238      3.97086
log_probs/std                         3.71629      0.13196     4.05404      3.39583
log_probs/max                         28.57767     4.45154     38.51711     20.94122
log_probs/min                         -6.67305     1.39816     -4.37494     -12.38755
mean/mean                             0.12268      0.02334     0.17770      0.07407
mean/std                              1.54067      0.01931     1.58072      1.48925
mean/max                              6.35294      0.32168     6.81184      5.61820
mean/min                              -8.90326     1.60628     -5.01648     -10.08075
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 5, 2, 4, 0, 9, 1, 7, 3]
replay_buffer._size: [63150 63150 63150 63150 63150 63150 63150 63150 63150 63150]
2023-08-12 12:41:54,233 MainThread INFO: EPOCH:399
2023-08-12 12:41:54,233 MainThread INFO: Time Consumed:8.870147228240967s
2023-08-12 12:41:54,233 MainThread INFO: Total Frames:630000s
  4%|▍         | 400/10000 [1:00:33<25:05:24,  9.41s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1550.21031
Train_Epoch_Reward                    14852.98837
Running_Training_Average_Rewards      1501.76432
Explore_Time                          0.00464
Train___Time                          8.86094
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.47156
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -74.65929
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.40787
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.23214
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.40149
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.48813
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.67156
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16111.57332
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.44769
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.69045
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.96418      1.47637     11.36182     4.14189
alpha_0                               2.78695      0.00724     2.79563      2.77055
alpha_1                               0.40936      0.00100     0.41127      0.40717
alpha_2                               0.15415      0.00159     0.15695      0.15150
alpha_3                               0.13301      0.00142     0.13547      0.13054
alpha_4                               0.19206      0.00021     0.19236      0.19173
alpha_5                               0.51792      0.00100     0.52012      0.51582
alpha_6                               0.21072      0.00060     0.21192      0.20990
alpha_7                               0.19053      0.00027     0.19087      0.19002
alpha_8                               0.15760      0.00064     0.15850      0.15619
alpha_9                               0.12069      0.00071     0.12193      0.11948
Alpha_loss                            0.52998      0.17447     0.98138      0.17973
Training/policy_loss                  125.37433    23.01103    192.18680    68.68136
Training/qf1_loss                     3174.74187   1125.95422  6639.94238   1390.51367
Training/qf2_loss                     804.31033    291.16186   2181.17358   488.02548
Training/pf_norm                      16.84468     5.84501     32.92960     8.01018
Training/qf1_norm                     5559.70397   2771.05148  16935.35352  1956.21948
Training/qf2_norm                     5056.65005   2390.49108  13454.47949  1929.41833
log_std/mean                          -0.88060     0.00901     -0.85928     -0.90411
log_std/std                           0.43860      0.00561     0.45491      0.42242
log_std/max                           0.78850      0.02662     0.84177      0.74720
log_std/min                           -3.10491     0.33746     -2.47097     -4.43078
log_probs/mean                        4.27988      0.11894     4.52863      4.01989
log_probs/std                         3.72417      0.14332     4.04813      3.34272
log_probs/max                         29.23791     4.57070     41.43388     20.56741
log_probs/min                         -6.26661     1.17735     -3.91536     -10.82595
mean/mean                             0.10900      0.03658     0.18475      0.01994
mean/std                              1.54925      0.02148     1.59237      1.47008
mean/max                              6.31207      0.39680     6.90454      5.48689
mean/min                              -9.32493     1.54252     -4.38694     -10.25936
------------------------------------  -----------  ----------  -----------  ----------
start to update mask
sample: [6, 3, 2, 0, 5, 4, 7, 9, 1, 8]
replay_buffer._size: [63300 63300 63300 63300 63300 63300 63300 63300 63300 63300]
2023-08-12 12:42:03,064 MainThread INFO: EPOCH:400
2023-08-12 12:42:03,065 MainThread INFO: Time Consumed:7.505610227584839s
2023-08-12 12:42:03,065 MainThread INFO: Total Frames:631500s
  4%|▍         | 401/10000 [1:00:43<25:51:17,  9.70s/it]------------------------------------  ------------  ------------  ------------  -----------
Name                                  Value
Running_Average_Rewards               1596.39908
Train_Epoch_Reward                    15852.05304
Running_Training_Average_Rewards      1546.20898
Explore_Time                          0.01310
Train___Time                          7.48745
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.68376
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.97645
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.33442
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -15.59144
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.86525
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.34110
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.73351
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16577.09982
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.72039
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.86274
mean_success_rate                     0.00000

Name                                  Mean          Std           Max           Min
Reward_Mean                           6.85552       1.24103       10.82568      3.53259
alpha_0                               2.88242       0.04246       2.92679       2.77144
alpha_1                               0.44614       0.02001       0.47973       0.41155
alpha_2                               0.15936       0.00145       0.16198       0.15702
alpha_3                               0.13996       0.00301       0.14522       0.13552
alpha_4                               0.19444       0.00354       0.20399       0.19190
alpha_5                               0.53548       0.01178       0.55386       0.52021
alpha_6                               0.21305       0.00210       0.21781       0.20990
alpha_7                               0.19240       0.00226       0.19890       0.19002
alpha_8                               0.15983       0.00128       0.16271       0.15851
alpha_9                               0.12153       0.00302       0.12862       0.11890
Alpha_loss                            4.23074       2.70025       10.19862      0.22566
Training/policy_loss                  509.08936     28.60344      576.84674     436.68732
Training/qf1_loss                     171592.34457  94308.14881   361790.09375  51370.21875
Training/qf2_loss                     5359.03242    5911.89347    21999.33789   1063.33582
Training/pf_norm                      51.75651      23.02851      92.75513      12.22483
Training/qf1_norm                     200859.42285  128109.28673  451534.21875  55651.96484
Training/qf2_norm                     32738.03291   41526.47316   167142.89062  3552.17798
log_std/mean                          -0.82009      0.00902       -0.79895      -0.84256
log_std/std                           0.53504       0.02124       0.58937       0.50087
log_std/max                           1.24555       0.12424       1.58736       1.05357
log_std/min                           -3.13813      0.24086       -2.67064      -3.80955
log_probs/mean                        7.41480       1.57734       10.92272      5.65673
log_probs/std                         6.78258       1.09619       8.86278       5.42579
log_probs/max                         36.89664      4.01698       44.22933      30.16271
log_probs/min                         -5.73052      1.54938       -3.11699      -10.72108
mean/mean                             0.44106       0.18412       0.71589       0.09883
mean/std                              2.13606       0.22900       2.60004       1.81682
mean/max                              7.35143       0.55046       8.36267       5.84835
mean/min                              -12.70297     2.06090       -6.56462      -14.07034
------------------------------------  ------------  ------------  ------------  -----------
snapshot at 400
history save at ./log/must_mtsac/mt10/12/model
sample: [6, 7, 3, 4, 5, 2, 1, 9, 8, 0]
replay_buffer._size: [63450 63450 63450 63450 63450 63450 63450 63450 63450 63450]
2023-08-12 12:42:11,983 MainThread INFO: EPOCH:401
2023-08-12 12:42:11,984 MainThread INFO: Time Consumed:7.2887067794799805s
2023-08-12 12:42:11,984 MainThread INFO: Total Frames:633000s
  4%|▍         | 402/10000 [1:00:51<23:59:45,  9.00s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1561.58734
Train_Epoch_Reward                    15404.94596
Running_Training_Average_Rewards      1536.99958
Explore_Time                          0.00363
Train___Time                          7.28005
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.55453
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.68983
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -76.46393
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.07356
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.75725
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.02093
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.12399
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16228.38304
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.04598
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.77964
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           6.93837      1.35609      10.95019     3.75822
alpha_0                               2.91336      0.01924      2.93385      2.87748
alpha_1                               0.50088      0.00955      0.51314      0.48035
alpha_2                               0.16568      0.00269      0.17109      0.16203
alpha_3                               0.15177      0.00386      0.15850      0.14535
alpha_4                               0.21790      0.00685      0.22832      0.20433
alpha_5                               0.57774      0.01861      0.61245      0.55396
alpha_6                               0.23364      0.00915      0.24853      0.21805
alpha_7                               0.21390      0.00796      0.22687      0.19923
alpha_8                               0.17353      0.00640      0.18380      0.16284
alpha_9                               0.13649      0.00378      0.14193      0.12882
Alpha_loss                            10.15336     0.51270      11.06298     8.69228
Training/policy_loss                  479.08686    24.21544     532.57947    418.04279
Training/qf1_loss                     21235.40871  12951.64060  51748.03516  4645.75537
Training/qf2_loss                     1254.09094   409.96971    2556.87280   654.94183
Training/pf_norm                      13.14371     2.71400      20.17786     9.32946
Training/qf1_norm                     26941.63520  13863.13036  53718.00391  6137.41260
Training/qf2_norm                     5643.48624   2275.75287   12176.64648  2380.74536
log_std/mean                          -0.72908     0.05096      -0.64021     -0.82171
log_std/std                           0.53147      0.00694      0.54928      0.51757
log_std/max                           1.71350      0.32738      2.00000      0.75545
log_std/min                           -2.98600     0.26242      -2.42923     -3.39006
log_probs/mean                        10.73423     0.34870      11.49460     9.84221
log_probs/std                         6.40556      1.09546      8.92798      4.97083
log_probs/max                         36.60716     5.08132      45.92172     29.72710
log_probs/min                         -5.65637     1.60163      -3.08668     -12.41045
mean/mean                             0.47842      0.10628      0.67175      0.31029
mean/std                              2.58124      0.06741      2.71502      2.42044
mean/max                              7.13585      0.54514      8.01724      5.75888
mean/min                              -13.20909    1.68511      -7.00550     -14.44604
------------------------------------  -----------  -----------  -----------  ----------
sample: [0, 6, 2, 4, 5, 1, 9, 3, 7, 8]
replay_buffer._size: [63600 63600 63600 63600 63600 63600 63600 63600 63600 63600]
2023-08-12 12:42:20,925 MainThread INFO: EPOCH:402
2023-08-12 12:42:20,925 MainThread INFO: Time Consumed:8.751941919326782s
2023-08-12 12:42:20,926 MainThread INFO: Total Frames:634500s
  4%|▍         | 403/10000 [1:01:00<23:58:01,  8.99s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1367.48961
Train_Epoch_Reward                    1072.99597
Running_Training_Average_Rewards      1077.66650
Explore_Time                          0.00441
Train___Time                          8.74242
Eval____Time                          0.00439
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.46693
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.99496
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.11782
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.71367
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.12681
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.53484
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -91.27423
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14373.77190
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.17788
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.46869
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.85427      1.40486     11.12670     3.38093
alpha_0                               2.83962      0.02268     2.87678      2.79696
alpha_1                               0.51696      0.00201     0.52009      0.51325
alpha_2                               0.17884      0.00461     0.18711      0.17123
alpha_3                               0.16484      0.00341     0.17024      0.15863
alpha_4                               0.23327      0.00207     0.23562      0.22848
alpha_5                               0.63876      0.01201     0.65560      0.61317
alpha_6                               0.25748      0.00436     0.26422      0.24878
alpha_7                               0.23729      0.00578     0.24650      0.22709
alpha_8                               0.19141      0.00377     0.19638      0.18398
alpha_9                               0.14492      0.00143     0.14707      0.14201
Alpha_loss                            6.85511      1.15355     8.88952      5.03222
Training/policy_loss                  455.03452    23.24598    508.89972    406.67563
Training/qf1_loss                     5973.04312   1582.27784  10253.18457  2933.46753
Training/qf2_loss                     1047.44277   364.24673   2495.08252   640.04968
Training/pf_norm                      12.32854     2.92052     21.64314     7.18887
Training/qf1_norm                     6833.81950   2197.42801  15250.73730  3201.03784
Training/qf2_norm                     5524.24644   2253.61242  13259.47559  2294.28687
log_std/mean                          -0.71946     0.01725     -0.68601     -0.75170
log_std/std                           0.51100      0.01433     0.54108      0.48405
log_std/max                           1.59068      0.36790     2.00000      0.99700
log_std/min                           -2.93027     0.28556     -2.38847     -3.37853
log_probs/mean                        8.45033      0.81001     9.90109      7.16910
log_probs/std                         5.44084      0.14745     5.85900      5.03628
log_probs/max                         36.48432     3.82157     44.52740     26.18039
log_probs/min                         -5.98482     1.55260     -3.24653     -12.00599
mean/mean                             0.41780      0.04543     0.51307      0.30947
mean/std                              2.24187      0.10324     2.44468      2.08107
mean/max                              6.68012      0.70102     7.67078      5.42289
mean/min                              -10.03481    1.48228     -5.73267     -12.90382
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 3, 1, 7, 2, 8, 0, 9, 6, 4]
replay_buffer._size: [63750 63750 63750 63750 63750 63750 63750 63750 63750 63750]
2023-08-12 12:42:29,348 MainThread INFO: EPOCH:403
2023-08-12 12:42:29,348 MainThread INFO: Time Consumed:8.248639345169067s
2023-08-12 12:42:29,348 MainThread INFO: Total Frames:636000s
  4%|▍         | 404/10000 [1:01:08<23:29:26,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1416.47549
Train_Epoch_Reward                    14006.98023
Running_Training_Average_Rewards      1016.16407
Explore_Time                          0.00931
Train___Time                          8.23437
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.34632
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.13857
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.27680
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.61954
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -98.83012
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.18559
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.88985
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14923.95111
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.53348
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.37592
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.18095      1.42884     12.39830     4.26519
alpha_0                               2.76150      0.01907     2.79621      2.73262
alpha_1                               0.52251      0.00153     0.52535      0.52013
alpha_2                               0.19584      0.00483     0.20380      0.18729
alpha_3                               0.17434      0.00219     0.17787      0.17033
alpha_4                               0.23530      0.00038     0.23570      0.23458
alpha_5                               0.66629      0.00538     0.67414      0.65586
alpha_6                               0.26943      0.00282     0.27415      0.26434
alpha_7                               0.25286      0.00322     0.25777      0.24666
alpha_8                               0.19704      0.00023     0.19730      0.19642
alpha_9                               0.14884      0.00097     0.15047      0.14710
Alpha_loss                            4.27018      0.50661     5.49981      3.58991
Training/policy_loss                  444.11207    21.40430    489.14746    395.11743
Training/qf1_loss                     5580.64562   1789.88562  12761.47363  2584.30151
Training/qf2_loss                     1125.38880   462.51233   3920.13599   521.79443
Training/pf_norm                      12.19116     3.07418     22.53601     7.13146
Training/qf1_norm                     6615.95884   3427.07395  21936.23633  2882.10986
Training/qf2_norm                     5361.34384   2609.59702  17124.78906  1850.90649
log_std/mean                          -0.78730     0.04347     -0.70604     -0.88627
log_std/std                           0.48960      0.02004     0.52182      0.43732
log_std/max                           1.87828      0.20164     2.00000      0.94035
log_std/min                           -2.76014     0.24630     -2.33083     -3.13117
log_probs/mean                        6.77655      0.30839     7.46406      6.24576
log_probs/std                         5.22889      0.21143     5.73769      4.78198
log_probs/max                         37.34147     3.55996     46.03577     27.01897
log_probs/min                         -6.27274     1.34468     -3.98361     -12.20406
mean/mean                             0.27004      0.05781     0.38299      0.16537
mean/std                              1.99501      0.04581     2.10116      1.90516
mean/max                              6.41016      0.66329     7.61410      5.24872
mean/min                              -9.19222     0.76904     -5.87646     -9.85079
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 1, 3, 4, 6, 5, 0, 7, 2]
replay_buffer._size: [63900 63900 63900 63900 63900 63900 63900 63900 63900 63900]
2023-08-12 12:42:37,856 MainThread INFO: EPOCH:404
2023-08-12 12:42:37,857 MainThread INFO: Time Consumed:8.314796924591064s
2023-08-12 12:42:37,857 MainThread INFO: Total Frames:637500s
  4%|▍         | 405/10000 [1:01:17<23:14:44,  8.72s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1396.24353
Train_Epoch_Reward                    14234.22054
Running_Training_Average_Rewards      977.13989
Explore_Time                          0.00936
Train___Time                          8.30112
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -106.40320
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.58429
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.97108
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -86.94081
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -91.17661
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.08419
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.75366
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14769.81156
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.96952
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.49292
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.12377      1.36668     10.42943     4.43691
alpha_0                               2.71120      0.01160     2.73220      2.69166
alpha_1                               0.52813      0.00161     0.53086      0.52541
alpha_2                               0.21106      0.00403     0.21776      0.20395
alpha_3                               0.18148      0.00202     0.18480      0.17793
alpha_4                               0.23383      0.00035     0.23456      0.23345
alpha_5                               0.67749      0.00136     0.67889      0.67427
alpha_6                               0.27836      0.00226     0.28208      0.27424
alpha_7                               0.26101      0.00170     0.26364      0.25785
alpha_8                               0.19671      0.00020     0.19725      0.19652
alpha_9                               0.15216      0.00102     0.15395      0.15051
Alpha_loss                            3.66649      0.16332     4.11554      3.28348
Training/policy_loss                  438.52073    21.71226    484.58731    388.67886
Training/qf1_loss                     5094.41355   1367.58096  8863.76758   2755.93530
Training/qf2_loss                     1113.22042   373.58427   2583.20337   624.51154
Training/pf_norm                      13.73041     4.38141     27.80041     6.22568
Training/qf1_norm                     5905.35828   2554.98972  14626.67773  2320.35083
Training/qf2_norm                     5503.19604   2578.57008  13188.82910  1793.63208
log_std/mean                          -0.90481     0.01985     -0.86328     -0.94309
log_std/std                           0.41546      0.01319     0.45050      0.39465
log_std/max                           1.15657      0.62503     1.83512      0.15481
log_std/min                           -2.73388     0.19309     -2.31690     -3.00591
log_probs/mean                        6.35327      0.12968     6.70475      6.06966
log_probs/std                         4.96734      0.18508     5.39657      4.51102
log_probs/max                         36.25430     2.52907     43.51080     24.67356
log_probs/min                         -5.89460     1.24137     -3.61081     -10.29359
mean/mean                             0.11521      0.04891     0.21611      -0.01117
mean/std                              1.91368      0.02930     1.98555      1.85210
mean/max                              6.28404      0.72613     7.47113      4.95234
mean/min                              -8.68636     0.78859     -6.07830     -9.42441
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 5, 7, 4, 9, 0, 6, 3, 8, 1]
replay_buffer._size: [64057 64058 64057 64056 64058 64056 64059 64058 64057 64057]
2023-08-12 12:42:46,856 MainThread INFO: EPOCH:405
2023-08-12 12:42:46,857 MainThread INFO: Time Consumed:8.873406648635864s
2023-08-12 12:42:46,857 MainThread INFO: Total Frames:639000s
  4%|▍         | 406/10000 [1:01:26<23:27:59,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1116.59849
Train_Epoch_Reward                    14131.18179
Running_Training_Average_Rewards      1412.41275
Explore_Time                          0.13596
Train___Time                          8.72974
Eval____Time                          0.00706
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -105.77539
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -109.77247
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.22533
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.00572
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.53488
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.53516
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.02517
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11967.79224
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.68111
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -83.25209
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.16481      1.36610     10.71157     4.62299
alpha_0                               2.67715      0.00806     2.69129      2.66332
alpha_1                               0.53314      0.00120     0.53509      0.53092
alpha_2                               0.22379      0.00336     0.22945      0.21789
alpha_3                               0.18788      0.00175     0.19093      0.18487
alpha_4                               0.23359      0.00009     0.23375      0.23345
alpha_5                               0.67485      0.00273     0.67832      0.66946
alpha_6                               0.28519      0.00163     0.28767      0.28215
alpha_7                               0.26610      0.00146     0.26866      0.26368
alpha_8                               0.19862      0.00082     0.20012      0.19728
alpha_9                               0.15556      0.00089     0.15700      0.15399
Alpha_loss                            3.16853      0.20531     3.71554      2.59821
Training/policy_loss                  435.97703    23.61024    478.28757    341.91373
Training/qf1_loss                     4796.33423   1460.95669  9744.05371   2337.11035
Training/qf2_loss                     1062.10260   387.02863   2300.21069   588.48322
Training/pf_norm                      14.36165     5.02556     30.75861     5.95717
Training/qf1_norm                     6454.47604   2762.03385  15357.34180  2305.64307
Training/qf2_norm                     5107.63148   2419.16119  12450.23828  1701.30237
log_std/mean                          -0.92019     0.00918     -0.89912     -0.94263
log_std/std                           0.40550      0.00683     0.42153      0.38872
log_std/max                           1.11205      0.67853     1.78439      0.15132
log_std/min                           -2.78704     0.19329     -2.46603     -3.24690
log_probs/mean                        5.99492      0.15816     6.41749      5.56345
log_probs/std                         4.70266      0.13755     4.99470      4.37792
log_probs/max                         35.52532     2.51959     43.76733     28.55717
log_probs/min                         -5.85955     1.16504     -3.89239     -9.30272
mean/mean                             0.07611      0.02836     0.15036      0.01007
mean/std                              1.83411      0.02643     1.91251      1.76478
mean/max                              6.10108      0.73638     7.30817      4.54447
mean/min                              -8.71141     0.68157     -6.96958     -9.22380
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 6, 4, 8, 3, 0, 7, 1, 2, 5]
replay_buffer._size: [64200 64200 64200 64200 64200 64200 64200 64200 64200 64200]
2023-08-12 12:42:56,008 MainThread INFO: EPOCH:406
2023-08-12 12:42:56,009 MainThread INFO: Time Consumed:8.953502655029297s
2023-08-12 12:42:56,009 MainThread INFO: Total Frames:640500s
  4%|▍         | 407/10000 [1:01:35<23:44:46,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1126.15613
Train_Epoch_Reward                    11064.32781
Running_Training_Average_Rewards      1314.32434
Explore_Time                          0.00484
Train___Time                          8.94366
Eval____Time                          0.00431
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.18825
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -107.39926
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.00063
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.09798
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.99766
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.37030
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.22755
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12062.54201
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.52666
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -86.17243
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.87161      1.30193     9.75577      4.22115
alpha_0                               2.64488      0.01131     2.66309      2.62838
alpha_1                               0.53657      0.00081     0.53796      0.53512
alpha_2                               0.23478      0.00300     0.23983      0.22956
alpha_3                               0.19401      0.00173     0.19692      0.19099
alpha_4                               0.23414      0.00029     0.23473      0.23375
alpha_5                               0.66037      0.00549     0.66932      0.65087
alpha_6                               0.28915      0.00076     0.29032      0.28770
alpha_7                               0.27130      0.00147     0.27380      0.26871
alpha_8                               0.20182      0.00102     0.20366      0.20015
alpha_9                               0.15787      0.00041     0.15842      0.15703
Alpha_loss                            2.53807      0.22707     3.04317      2.08358
Training/policy_loss                  432.66261    20.75248    477.35147    383.23022
Training/qf1_loss                     4656.64790   1337.75262  8955.63770   1842.91833
Training/qf2_loss                     916.52712    309.64750   1871.15100   499.32007
Training/pf_norm                      14.32659     4.93883     30.30717     6.27742
Training/qf1_norm                     6064.95132   2831.25497  20223.81836  2572.37549
Training/qf2_norm                     4794.04753   2111.74950  13314.32617  1544.28137
log_std/mean                          -0.92041     0.01181     -0.89534     -0.94729
log_std/std                           0.42165      0.00726     0.44143      0.40933
log_std/max                           1.17848      0.54508     1.78992      0.34017
log_std/min                           -2.77597     0.15642     -2.48643     -3.16878
log_probs/mean                        5.53645      0.13285     5.86196      5.21701
log_probs/std                         4.45664      0.18447     4.87719      3.93806
log_probs/max                         33.79976     2.24180     41.37092     28.06398
log_probs/min                         -5.85284     1.38513     -3.86677     -10.24149
mean/mean                             -0.04611     0.04804     0.06812      -0.13294
mean/std                              1.75036      0.02891     1.81649      1.68227
mean/max                              5.98036      0.82631     7.20813      4.46265
mean/min                              -8.48296     0.76524     -6.66359     -9.03383
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 4, 3, 9, 5, 7, 6, 0, 2]
replay_buffer._size: [64350 64350 64350 64350 64350 64350 64350 64350 64350 64350]
2023-08-12 12:43:04,284 MainThread INFO: EPOCH:407
2023-08-12 12:43:04,284 MainThread INFO: Time Consumed:8.128813982009888s
2023-08-12 12:43:04,284 MainThread INFO: Total Frames:642000s
  4%|▍         | 408/10000 [1:01:43<23:13:44,  8.72s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1175.89612
Train_Epoch_Reward                    11424.67986
Running_Training_Average_Rewards      1220.67298
Explore_Time                          0.00918
Train___Time                          8.11502
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.57814
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.26215
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -82.38778
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.89336
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.16088
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.04125
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.41027
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12523.28058
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.92183
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -86.66373
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.88779      1.23072     10.07554     4.17193
alpha_0                               2.62014      0.00569     2.62818      2.60706
alpha_1                               0.53906      0.00061     0.54007      0.53799
alpha_2                               0.24498      0.00297     0.24993      0.23993
alpha_3                               0.19941      0.00138     0.20176      0.19698
alpha_4                               0.23553      0.00044     0.23626      0.23474
alpha_5                               0.64147      0.00519     0.65067      0.63285
alpha_6                               0.29083      0.00021     0.29105      0.29033
alpha_7                               0.27656      0.00158     0.27920      0.27386
alpha_8                               0.20607      0.00141     0.20839      0.20370
alpha_9                               0.15867      0.00012     0.15878      0.15842
Alpha_loss                            2.10663      0.24714     2.66133      1.59525
Training/policy_loss                  427.96963    19.17126    473.76462    389.06915
Training/qf1_loss                     4452.66833   1456.91799  9355.28027   1869.24963
Training/qf2_loss                     891.23386    331.73236   2549.60596   416.47849
Training/pf_norm                      12.50817     4.06746     28.56270     6.41870
Training/qf1_norm                     5801.91367   2147.59026  13079.41992  2182.59204
Training/qf2_norm                     4447.54662   1853.74865  10209.74707  1783.67676
log_std/mean                          -0.92324     0.01493     -0.89753     -0.96011
log_std/std                           0.44003      0.00538     0.45479      0.42558
log_std/max                           1.00297      0.41042     1.56584      0.56388
log_std/min                           -2.84047     0.18492     -2.40821     -3.09859
log_probs/mean                        5.31234      0.19085     5.70560      4.84326
log_probs/std                         4.32568      0.15619     4.74069      3.99407
log_probs/max                         34.19620     2.09346     41.30527     27.74509
log_probs/min                         -6.30707     1.33930     -3.84083     -10.45225
mean/mean                             -0.09693     0.03241     -0.02267     -0.16863
mean/std                              1.70177      0.02909     1.75986      1.64013
mean/max                              5.74552      0.69763     7.06106      4.48548
mean/min                              -8.28284     0.85121     -6.42322     -9.02923
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 2, 1, 0, 9, 7, 5, 8, 3, 4]
replay_buffer._size: [64500 64500 64500 64500 64500 64500 64500 64500 64500 64500]
2023-08-12 12:43:13,377 MainThread INFO: EPOCH:408
2023-08-12 12:43:13,378 MainThread INFO: Time Consumed:8.94460940361023s
2023-08-12 12:43:13,378 MainThread INFO: Total Frames:643500s
  4%|▍         | 409/10000 [1:01:52<23:31:32,  8.83s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1279.02215
Train_Epoch_Reward                    12095.65355
Running_Training_Average_Rewards      1152.82204
Explore_Time                          0.00959
Train___Time                          8.93061
Eval____Time                          0.00366
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.47332
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.86521
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -44.12163
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.01006
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.26622
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.89688
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.00581
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13517.42032
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.82744
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -85.73225
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.13226      1.34706     11.55329     4.25332
alpha_0                               2.59647      0.00538     2.60666      2.58848
alpha_1                               0.54111      0.00047     0.54174      0.54009
alpha_2                               0.25408      0.00234     0.25815      0.25001
alpha_3                               0.20366      0.00098     0.20529      0.20181
alpha_4                               0.23734      0.00065     0.23841      0.23627
alpha_5                               0.62429      0.00470     0.63268      0.61668
alpha_6                               0.28984      0.00056     0.29070      0.28870
alpha_7                               0.28181      0.00156     0.28458      0.27925
alpha_8                               0.21061      0.00132     0.21296      0.20843
alpha_9                               0.15873      0.00002     0.15877      0.15868
Alpha_loss                            1.56735      0.15495     1.89179      1.18163
Training/policy_loss                  419.16257    22.55775    470.62851    373.82016
Training/qf1_loss                     4319.73985   1323.61967  9319.47559   2189.02222
Training/qf2_loss                     837.64014    280.17073   2427.43042   486.05209
Training/pf_norm                      14.31551     4.77295     27.85671     6.73098
Training/qf1_norm                     5497.90814   2188.99317  14817.63281  2195.28882
Training/qf2_norm                     4972.83724   2034.10157  11748.77246  2135.80493
log_std/mean                          -0.91698     0.01063     -0.89002     -0.93853
log_std/std                           0.45054      0.00722     0.46825      0.43593
log_std/max                           1.02214      0.32528     1.41456      0.60731
log_std/min                           -2.91366     0.20894     -2.43178     -3.20279
log_probs/mean                        4.98653      0.13126     5.29919      4.64145
log_probs/std                         4.11809      0.17018     4.55959      3.76631
log_probs/max                         32.88537     1.87783     39.92109     28.42090
log_probs/min                         -6.18403     1.49655     -3.28993     -11.83910
mean/mean                             -0.11726     0.03983     -0.02198     -0.21277
mean/std                              1.64303      0.02233     1.69321      1.58648
mean/max                              5.70960      0.74325     6.82206      4.35857
mean/min                              -8.26320     1.00046     -5.82683     -9.03382
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 8, 4, 5, 6, 1, 7, 0, 2]
replay_buffer._size: [64650 64650 64650 64650 64650 64650 64650 64650 64650 64650]
2023-08-12 12:43:22,670 MainThread INFO: EPOCH:409
2023-08-12 12:43:22,671 MainThread INFO: Time Consumed:9.168150663375854s
2023-08-12 12:43:22,671 MainThread INFO: Total Frames:645000s
  4%|▍         | 410/10000 [1:02:01<23:54:30,  8.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1386.97153
Train_Epoch_Reward                    13437.90685
Running_Training_Average_Rewards      1231.94134
Explore_Time                          0.00552
Train___Time                          9.15805
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.74850
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -106.36120
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.35132
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.39523
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.83544
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -109.34069
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -87.13163
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14576.39352
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.63763
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -85.87663
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.46133      1.49490     11.40474     3.45183
alpha_0                               2.57931      0.00421     2.58836      2.57415
alpha_1                               0.54196      0.00032     0.54262      0.54157
alpha_2                               0.26181      0.00196     0.26509      0.25824
alpha_3                               0.20672      0.00078     0.20801      0.20532
alpha_4                               0.23937      0.00056     0.24042      0.23843
alpha_5                               0.60897      0.00432     0.61654      0.60165
alpha_6                               0.28723      0.00086     0.28867      0.28576
alpha_7                               0.28733      0.00152     0.28989      0.28464
alpha_8                               0.21542      0.00150     0.21808      0.21300
alpha_9                               0.15842      0.00017     0.15868      0.15813
Alpha_loss                            1.17449      0.17138     1.62883      0.75586
Training/policy_loss                  412.75264    21.52057    476.50803    368.17935
Training/qf1_loss                     4386.45344   1528.05445  9572.10742   1945.76746
Training/qf2_loss                     889.33469    367.77047   2318.86060   426.49289
Training/pf_norm                      14.10690     4.72082     30.22681     6.11166
Training/qf1_norm                     5829.79218   2461.16620  13834.10449  2259.06128
Training/qf2_norm                     5162.40357   2093.12979  12290.52051  1633.35315
log_std/mean                          -0.91552     0.01011     -0.89932     -0.94614
log_std/std                           0.45947      0.00457     0.47111      0.44880
log_std/max                           0.90892      0.32584     1.31924      0.37568
log_std/min                           -3.02022     0.20417     -2.49827     -3.30090
log_probs/mean                        4.73637      0.11746     5.10734      4.47811
log_probs/std                         3.99283      0.18562     4.53976      3.55049
log_probs/max                         31.62046     2.25188     39.50515     26.55498
log_probs/min                         -6.21656     1.42059     -3.88797     -10.20487
mean/mean                             -0.13756     0.03240     -0.06968     -0.20900
mean/std                              1.59630      0.01873     1.64606      1.56285
mean/max                              5.46593      0.55526     6.70395      4.69491
mean/min                              -8.71794     1.02086     -5.54842     -9.34016
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 5, 2, 4, 8, 7, 3, 1, 0, 6]
replay_buffer._size: [64800 64800 64800 64800 64800 64800 64800 64800 64800 64800]
2023-08-12 12:43:31,130 MainThread INFO: EPOCH:410
2023-08-12 12:43:31,131 MainThread INFO: Time Consumed:8.299770832061768s
2023-08-12 12:43:31,131 MainThread INFO: Total Frames:646500s
  4%|▍         | 411/10000 [1:02:10<23:29:57,  8.82s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1374.91069
Train_Epoch_Reward                    14188.34422
Running_Training_Average_Rewards      1324.06349
Explore_Time                          0.02477
Train___Time                          8.26895
Eval____Time                          0.00521
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.63724
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.95900
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -37.84720
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.57096
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.38349
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.34015
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.32398
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14464.90207
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.00426
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -83.72892
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.68907      1.17726     9.75152      4.36072
alpha_0                               2.56293      0.00553     2.57401      2.55578
alpha_1                               0.54283      0.00010     0.54301      0.54264
alpha_2                               0.26859      0.00195     0.27185      0.26516
alpha_3                               0.20901      0.00052     0.20975      0.20803
alpha_4                               0.24123      0.00039     0.24177      0.24044
alpha_5                               0.59373      0.00477     0.60151      0.58534
alpha_6                               0.28416      0.00093     0.28573      0.28256
alpha_7                               0.29253      0.00143     0.29499      0.28995
alpha_8                               0.22060      0.00149     0.22320      0.21813
alpha_9                               0.15775      0.00020     0.15812      0.15744
Alpha_loss                            0.92497      0.16743     1.33221      0.58525
Training/policy_loss                  411.74863    22.01233    456.83316    369.40988
Training/qf1_loss                     3969.83797   1304.44494  8313.56738   1723.89343
Training/qf2_loss                     762.37470    260.54537   1698.98950   382.50577
Training/pf_norm                      14.29933     4.71697     27.87442     6.50522
Training/qf1_norm                     5665.25434   2297.40765  13673.26758  1998.86584
Training/qf2_norm                     4135.09054   1732.57123  9101.91992   1639.56238
log_std/mean                          -0.90764     0.00805     -0.88594     -0.92793
log_std/std                           0.45213      0.00553     0.46310      0.43921
log_std/max                           0.77973      0.36194     1.26354      0.33555
log_std/min                           -3.04361     0.18506     -2.56814     -3.26426
log_probs/mean                        4.55989      0.11772     4.84305      4.22987
log_probs/std                         3.97707      0.17049     4.37106      3.52903
log_probs/max                         30.53957     1.90361     40.00826     24.39820
log_probs/min                         -6.38800     1.48249     -3.94111     -12.20221
mean/mean                             -0.11310     0.03112     -0.05178     -0.18285
mean/std                              1.57218      0.02290     1.63107      1.52356
mean/max                              5.59628      0.56271     6.51272      4.98558
mean/min                              -8.39279     1.34612     -5.59426     -9.38379
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 2, 1, 4, 6, 8, 9, 5, 3, 7]
replay_buffer._size: [64950 64950 64950 64950 64950 64950 64950 64950 64950 64950]
2023-08-12 12:43:39,689 MainThread INFO: EPOCH:411
2023-08-12 12:43:39,689 MainThread INFO: Time Consumed:8.364248037338257s
2023-08-12 12:43:39,689 MainThread INFO: Total Frames:648000s
  4%|▍         | 412/10000 [1:02:18<23:18:05,  8.75s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1458.19441
Train_Epoch_Reward                    12581.06538
Running_Training_Average_Rewards      1340.24388
Explore_Time                          0.00470
Train___Time                          8.35416
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.26429
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.87670
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -40.65279
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.65116
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.29086
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.57493
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.99465
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15276.05751
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.58877
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -84.21923
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.90623      1.27564     10.24252     3.96966
alpha_0                               2.54881      0.00601     2.55627      2.53751
alpha_1                               0.54293      0.00015     0.54317      0.54263
alpha_2                               0.27486      0.00155     0.27717      0.27192
alpha_3                               0.21018      0.00024     0.21061      0.20976
alpha_4                               0.24175      0.00015     0.24190      0.24140
alpha_5                               0.57670      0.00494     0.58517      0.56844
alpha_6                               0.28094      0.00101     0.28254      0.27908
alpha_7                               0.29756      0.00147     0.29992      0.29504
alpha_8                               0.22574      0.00146     0.22819      0.22324
alpha_9                               0.15708      0.00025     0.15744      0.15658
Alpha_loss                            0.48946      0.23994     0.99190      -0.06952
Training/policy_loss                  413.40606    20.83091    500.70889    361.59790
Training/qf1_loss                     3889.57872   1270.92768  7681.57910   1889.23340
Training/qf2_loss                     748.88964    282.59973   2616.54199   397.57571
Training/pf_norm                      15.66840     7.48931     42.91390     4.20247
Training/qf1_norm                     5551.28908   2190.61643  14288.30176  2081.24170
Training/qf2_norm                     5435.79626   2150.04237  10691.55664  2287.59204
log_std/mean                          -0.88953     0.00795     -0.87217     -0.91428
log_std/std                           0.44408      0.00559     0.45934      0.43261
log_std/max                           0.69380      0.34264     1.12656      0.24155
log_std/min                           -3.00621     0.20164     -2.44325     -3.25371
log_probs/mean                        4.24206      0.19038     4.71887      3.83872
log_probs/std                         3.88324      0.16971     4.37063      3.52670
log_probs/max                         29.90610     2.64379     40.22794     23.47057
log_probs/min                         -6.63702     1.40122     -4.29295     -11.85966
mean/mean                             -0.06929     0.02865     -0.00349     -0.12917
mean/std                              1.53191      0.03130     1.59760      1.45722
mean/max                              5.51570      0.42424     6.40665      4.65907
mean/min                              -8.57014     1.27388     -4.72373     -9.42807
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 2, 1, 3, 9, 6, 0, 7, 8, 4]
replay_buffer._size: [65100 65100 65100 65100 65100 65100 65100 65100 65100 65100]
2023-08-12 12:43:48,147 MainThread INFO: EPOCH:412
2023-08-12 12:43:48,148 MainThread INFO: Time Consumed:8.309910774230957s
2023-08-12 12:43:48,148 MainThread INFO: Total Frames:649500s
  4%|▍         | 413/10000 [1:02:27<23:03:40,  8.66s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1436.39758
Train_Epoch_Reward                    14813.42572
Running_Training_Average_Rewards      1386.09451
Explore_Time                          0.00362
Train___Time                          8.30115
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.90025
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -105.96678
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.16230
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.96896
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.19912
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.55010
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -85.01635
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15067.20239
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -74.05178
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -82.41092
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.01372      1.20734     9.87691      4.89510
alpha_0                               2.52718      0.00518     2.53711      2.52121
alpha_1                               0.54253      0.00013     0.54268      0.54225
alpha_2                               0.27819      0.00038     0.27848      0.27720
alpha_3                               0.21129      0.00042     0.21196      0.21061
alpha_4                               0.24055      0.00053     0.24139      0.23967
alpha_5                               0.56055      0.00437     0.56828      0.55327
alpha_6                               0.27695      0.00122     0.27904      0.27487
alpha_7                               0.30169      0.00085     0.30292      0.29996
alpha_8                               0.23066      0.00148     0.23327      0.22823
alpha_9                               0.15602      0.00031     0.15657      0.15553
Alpha_loss                            0.02167      0.18951     0.41919      -0.40786
Training/policy_loss                  404.44407    21.79243    469.10406    338.28873
Training/qf1_loss                     4128.36969   1292.42988  7589.91650   1724.39880
Training/qf2_loss                     849.17273    348.93580   2206.11499   420.90817
Training/pf_norm                      13.43965     5.54567     29.57910     5.31305
Training/qf1_norm                     5682.64336   2463.22566  14211.30664  1935.15906
Training/qf2_norm                     4822.84683   2086.53863  12337.89453  1514.10303
log_std/mean                          -0.89155     0.00960     -0.87162     -0.92074
log_std/std                           0.43742      0.00533     0.45221      0.42303
log_std/max                           0.67868      0.32583     1.04086      0.19819
log_std/min                           -3.03695     0.19115     -2.62493     -3.28974
log_probs/mean                        3.92387      0.13119     4.24745      3.63765
log_probs/std                         3.71674      0.15748     4.20285      3.32742
log_probs/max                         28.24276     1.96231     35.07528     23.00727
log_probs/min                         -6.51446     1.55653     -3.98001     -12.47781
mean/mean                             -0.06802     0.03031     0.01327      -0.13977
mean/std                              1.47492      0.02614     1.55589      1.42511
mean/max                              5.39674      0.37648     5.99881      3.93867
mean/min                              -8.51436     1.51033     -4.16856     -9.43274
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 2, 3, 1, 9, 4, 5, 7, 6, 8]
replay_buffer._size: [65250 65250 65250 65250 65250 65250 65250 65250 65250 65250]
2023-08-12 12:43:57,117 MainThread INFO: EPOCH:413
2023-08-12 12:43:57,118 MainThread INFO: Time Consumed:8.813974857330322s
2023-08-12 12:43:57,118 MainThread INFO: Total Frames:651000s
  4%|▍         | 414/10000 [1:02:36<23:17:05,  8.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1416.42078
Train_Epoch_Reward                    13678.28504
Running_Training_Average_Rewards      1369.09254
Explore_Time                          0.02183
Train___Time                          8.78696
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.94998
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.53916
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -60.56356
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.06280
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.87596
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.67687
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.10393
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14873.67010
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.21332
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -81.47675
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.82017      1.22012     10.44879     3.65419
alpha_0                               2.52435      0.00264     2.52763      2.52081
alpha_1                               0.54217      0.00012     0.54233      0.54195
alpha_2                               0.27851      0.00013     0.27879      0.27835
alpha_3                               0.21243      0.00024     0.21279      0.21197
alpha_4                               0.23921      0.00029     0.23966      0.23876
alpha_5                               0.54618      0.00383     0.55311      0.53965
alpha_6                               0.27278      0.00122     0.27484      0.27067
alpha_7                               0.30380      0.00058     0.30474      0.30294
alpha_8                               0.23637      0.00183     0.23953      0.23332
alpha_9                               0.15504      0.00029     0.15552      0.15459
Alpha_loss                            -0.00993     0.15039     0.49848      -0.37374
Training/policy_loss                  398.04179    23.16944    455.21994    342.43237
Training/qf1_loss                     3705.30601   1314.88533  8872.02832   1610.05627
Training/qf2_loss                     708.48322    233.23236   1597.66809   348.26175
Training/pf_norm                      12.61715     5.80687     40.51231     5.11773
Training/qf1_norm                     5214.89396   2279.73711  13786.61426  1571.17114
Training/qf2_norm                     4421.97682   1832.68349  11476.45215  1123.05823
log_std/mean                          -0.91454     0.01165     -0.88903     -0.94023
log_std/std                           0.42059      0.00796     0.44264      0.40425
log_std/max                           0.52868      0.32152     0.90241      0.07849
log_std/min                           -3.00903     0.16100     -2.77082     -3.26319
log_probs/mean                        3.91060      0.13099     4.36785      3.57720
log_probs/std                         3.72645      0.16367     4.05828      3.22812
log_probs/max                         28.53033     1.96448     36.92446     24.61609
log_probs/min                         -6.57964     1.35007     -4.07684     -9.89644
mean/mean                             -0.08155     0.03470     -0.00637     -0.15828
mean/std                              1.46159      0.02500     1.53674      1.40104
mean/max                              5.39314      0.26618     6.30370      5.05509
mean/min                              -8.33022     1.39350     -4.28195     -9.27291
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 6, 0, 3, 9, 1, 8, 7, 5, 2]
replay_buffer._size: [65400 65400 65400 65400 65400 65400 65400 65400 65400 65400]
2023-08-12 12:44:05,762 MainThread INFO: EPOCH:414
2023-08-12 12:44:05,762 MainThread INFO: Time Consumed:8.432625532150269s
2023-08-12 12:44:05,762 MainThread INFO: Total Frames:652500s
  4%|▍         | 415/10000 [1:02:44<23:11:47,  8.71s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1495.31324
Train_Epoch_Reward                    14547.10965
Running_Training_Average_Rewards      1434.62735
Explore_Time                          0.00428
Train___Time                          8.42308
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.97293
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -103.38065
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.78791
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.02987
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.68615
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.16328
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.27610
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15666.36387
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.19413
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -76.74045
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.91099      1.41135     11.48191     3.94478
alpha_0                               2.51083      0.00746     2.52092      2.49685
alpha_1                               0.54139      0.00038     0.54194      0.54072
alpha_2                               0.27969      0.00052     0.28059      0.27880
alpha_3                               0.21411      0.00085     0.21565      0.21281
alpha_4                               0.23745      0.00088     0.23875      0.23580
alpha_5                               0.53358      0.00340     0.53953      0.52803
alpha_6                               0.26884      0.00105     0.27063      0.26705
alpha_7                               0.30573      0.00049     0.30645      0.30477
alpha_8                               0.24305      0.00203     0.24647      0.23959
alpha_9                               0.15405      0.00032     0.15458      0.15347
Alpha_loss                            0.13417      0.15208     0.46065      -0.21067
Training/policy_loss                  397.60129    21.24154    451.42551    354.00821
Training/qf1_loss                     3562.50112   1313.14875  9275.36133   1685.80371
Training/qf2_loss                     738.28861    396.57280   3527.12671   397.87152
Training/pf_norm                      13.57784     5.62308     32.45737     5.04188
Training/qf1_norm                     5144.88226   2267.16003  15063.19141  2115.37964
Training/qf2_norm                     4348.43153   2028.35951  12475.12207  1682.67615
log_std/mean                          -0.89666     0.00800     -0.87354     -0.92046
log_std/std                           0.41296      0.00463     0.42545      0.40252
log_std/max                           0.51018      0.32912     0.83600      0.06244
log_std/min                           -2.99557     0.16228     -2.55743     -3.23200
log_probs/mean                        3.99765      0.11837     4.30306      3.69543
log_probs/std                         3.81337      0.14811     4.21187      3.49643
log_probs/max                         28.80765     2.42017     37.01063     24.25805
log_probs/min                         -6.49168     1.45986     -4.00348     -11.57659
mean/mean                             -0.09451     0.03720     0.00196      -0.16580
mean/std                              1.48962      0.01951     1.55197      1.44288
mean/max                              5.32358      0.32674     6.30161      4.84117
mean/min                              -8.16634     1.53461     -4.35155     -9.28511
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 8, 7, 3, 4, 1, 9, 6, 2, 0]
replay_buffer._size: [65550 65550 65550 65550 65550 65550 65550 65550 65550 65550]
2023-08-12 12:44:14,009 MainThread INFO: EPOCH:415
2023-08-12 12:44:14,013 MainThread INFO: Time Consumed:8.053883790969849s
2023-08-12 12:44:14,013 MainThread INFO: Total Frames:654000s
  4%|▍         | 416/10000 [1:02:53<22:51:06,  8.58s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1472.20725
Train_Epoch_Reward                    14916.64292
Running_Training_Average_Rewards      1438.06792
Explore_Time                          0.00469
Train___Time                          8.04394
Eval____Time                          0.00448
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.97847
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -96.78790
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.72455
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.25449
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.09884
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.15923
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.73889
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15418.80230
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.51109
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -78.47632
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.04709      1.37555     10.07986     3.71238
alpha_0                               2.49094      0.00167     2.49665      2.48889
alpha_1                               0.53977      0.00058     0.54070      0.53862
alpha_2                               0.28134      0.00037     0.28190      0.28061
alpha_3                               0.21711      0.00083     0.21852      0.21568
alpha_4                               0.23425      0.00075     0.23576      0.23322
alpha_5                               0.52184      0.00380     0.52793      0.51510
alpha_6                               0.26496      0.00119     0.26701      0.26287
alpha_7                               0.30696      0.00025     0.30726      0.30646
alpha_8                               0.25009      0.00225     0.25415      0.24653
alpha_9                               0.15290      0.00030     0.15346      0.15239
Alpha_loss                            0.05661      0.13574     0.37233      -0.26030
Training/policy_loss                  390.15238    22.37851    435.71149    334.61264
Training/qf1_loss                     3732.62163   1337.86437  8328.76270   1508.51355
Training/qf2_loss                     714.93736    241.77142   1749.80798   381.46829
Training/pf_norm                      14.42568     6.63377     44.26100     5.96491
Training/qf1_norm                     5088.05538   1998.85389  12058.24512  2269.27026
Training/qf2_norm                     4229.51778   1779.32534  10170.34082  1332.88867
log_std/mean                          -0.88961     0.00742     -0.87062     -0.90738
log_std/std                           0.40534      0.00550     0.41886      0.39358
log_std/max                           0.47920      0.28644     0.83664      0.03746
log_std/min                           -2.93691     0.15729     -2.49457     -3.16496
log_probs/mean                        3.95455      0.10514     4.22158      3.73219
log_probs/std                         3.75474      0.15441     4.14608      3.42786
log_probs/max                         27.38149     2.40571     33.84264     20.77260
log_probs/min                         -6.38416     1.33787     -4.21222     -11.52904
mean/mean                             -0.06762     0.04513     0.00099      -0.19021
mean/std                              1.48200      0.02100     1.54599      1.43643
mean/max                              5.08692      0.31600     6.01991      4.68020
mean/min                              -8.37800     1.27480     -4.41982     -9.17358
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 6, 1, 0, 2, 8, 3, 7, 5, 9]
replay_buffer._size: [65700 65700 65700 65700 65700 65700 65700 65700 65700 65700]
2023-08-12 12:44:23,507 MainThread INFO: EPOCH:416
2023-08-12 12:44:23,507 MainThread INFO: Time Consumed:9.307314395904541s
2023-08-12 12:44:23,507 MainThread INFO: Total Frames:655500s
  4%|▍         | 417/10000 [1:03:02<23:37:01,  8.87s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1524.77974
Train_Epoch_Reward                    14904.64694
Running_Training_Average_Rewards      1478.94665
Explore_Time                          0.00943
Train___Time                          9.29213
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.91579
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.54791
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.83135
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.88704
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.91061
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.67788
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.02712
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15908.01542
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.73883
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -76.68149
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.06988      1.48398     11.44081     3.77133
alpha_0                               2.48977      0.00211     2.49215      2.48500
alpha_1                               0.53710      0.00090     0.53860      0.53579
alpha_2                               0.28279      0.00059     0.28396      0.28191
alpha_3                               0.22039      0.00119     0.22240      0.21854
alpha_4                               0.23181      0.00093     0.23321      0.23012
alpha_5                               0.50815      0.00372     0.51494      0.50222
alpha_6                               0.26088      0.00106     0.26283      0.25909
alpha_7                               0.30733      0.00004     0.30739      0.30725
alpha_8                               0.25838      0.00236     0.26227      0.25424
alpha_9                               0.15181      0.00039     0.15238      0.15101
Alpha_loss                            0.07586      0.13416     0.49862      -0.16777
Training/policy_loss                  388.43319    19.73009    451.10773    347.80801
Training/qf1_loss                     3730.40700   1175.08185  7826.52734   1641.20349
Training/qf2_loss                     669.83528    255.49247   1871.87695   318.26782
Training/pf_norm                      11.11780     3.57707     24.73036     5.70845
Training/qf1_norm                     5505.53523   1996.90449  11126.81543  1989.59985
Training/qf2_norm                     4798.07292   2039.26894  10594.00488  1512.55225
log_std/mean                          -0.88639     0.01355     -0.85614     -0.91241
log_std/std                           0.39847      0.00550     0.41087      0.38151
log_std/max                           0.41317      0.21320     0.68309      0.00852
log_std/min                           -2.86407     0.16402     -2.31232     -3.09343
log_probs/mean                        3.98317      0.11272     4.26156      3.71401
log_probs/std                         3.75635      0.13066     4.06110      3.41453
log_probs/max                         27.08033     2.44258     32.77058     20.69520
log_probs/min                         -6.88267     1.55343     -4.31674     -12.17959
mean/mean                             -0.07002     0.02697     -0.00795     -0.14089
mean/std                              1.49309      0.02179     1.53537      1.43941
mean/max                              5.03033      0.31379     5.79535      4.65751
mean/min                              -8.56146     1.18562     -4.63676     -9.34695
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 5, 2, 0, 4, 6, 8, 7, 9]
replay_buffer._size: [65850 65850 65850 65850 65850 65850 65850 65850 65850 65850]
2023-08-12 12:44:32,295 MainThread INFO: EPOCH:417
2023-08-12 12:44:32,295 MainThread INFO: Time Consumed:8.588621854782104s
2023-08-12 12:44:32,296 MainThread INFO: Total Frames:657000s
  4%|▍         | 418/10000 [1:03:11<23:28:52,  8.82s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1513.29807
Train_Epoch_Reward                    15644.69665
Running_Training_Average_Rewards      1515.53288
Explore_Time                          0.03416
Train___Time                          8.54930
Eval____Time                          0.00406
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.82041
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.90708
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.31205
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.20535
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.79079
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.36234
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.87356
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15789.07074
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.58931
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -72.22915
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94192      1.29903     10.38758     4.02682
alpha_0                               2.47500      0.00565     2.48485      2.46312
alpha_1                               0.53414      0.00112     0.53578      0.53224
alpha_2                               0.28541      0.00079     0.28679      0.28399
alpha_3                               0.22411      0.00101     0.22598      0.22244
alpha_4                               0.22830      0.00112     0.23008      0.22619
alpha_5                               0.49607      0.00369     0.50214      0.49033
alpha_6                               0.25703      0.00119     0.25906      0.25510
alpha_7                               0.30731      0.00015     0.30743      0.30678
alpha_8                               0.26607      0.00228     0.27013      0.26235
alpha_9                               0.14998      0.00058     0.15099      0.14896
Alpha_loss                            -0.06803     0.11864     0.17134      -0.38762
Training/policy_loss                  386.45604    23.74356    437.87994    322.68301
Training/qf1_loss                     3388.73633   960.47555   5870.73389   1597.75085
Training/qf2_loss                     647.25322    214.99838   1984.71570   297.49142
Training/pf_norm                      11.72256     4.39866     25.37015     5.28594
Training/qf1_norm                     5710.22732   2479.00470  13863.84961  1567.86401
Training/qf2_norm                     4818.49110   2086.68505  12206.37500  1417.83435
log_std/mean                          -0.86048     0.00569     -0.84455     -0.87196
log_std/std                           0.39310      0.00647     0.40677      0.37778
log_std/max                           0.42343      0.22494     0.69205      0.01455
log_std/min                           -2.78271     0.15482     -2.22018     -2.98458
log_probs/mean                        3.87144      0.11570     4.14495      3.56322
log_probs/std                         3.69656      0.12546     4.01553      3.48303
log_probs/max                         26.51472     2.72924     30.86607     20.08614
log_probs/min                         -6.68721     1.61165     -4.13344     -11.67302
mean/mean                             -0.08551     0.04925     0.02866      -0.20022
mean/std                              1.48520      0.01993     1.52939      1.44525
mean/max                              4.81901      0.29878     5.43797      4.32890
mean/min                              -8.56700     1.11913     -4.87779     -9.40043
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 7, 9, 0, 4, 6, 3, 5, 1]
replay_buffer._size: [66000 66000 66000 66000 66000 66000 66000 66000 66000 66000]
2023-08-12 12:44:41,723 MainThread INFO: EPOCH:418
2023-08-12 12:44:41,723 MainThread INFO: Time Consumed:9.249140501022339s
2023-08-12 12:44:41,723 MainThread INFO: Total Frames:658500s
  4%|▍         | 419/10000 [1:03:20<23:57:43,  9.00s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1523.35231
Train_Epoch_Reward                    15417.51803
Running_Training_Average_Rewards      1532.22872
Explore_Time                          0.00774
Train___Time                          9.23663
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.31862
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.25956
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -73.54197
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.08972
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.09537
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.08185
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.84365
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15878.80304
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -69.65629
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -76.39290
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.25658      1.42646     10.96499     3.57974
alpha_0                               2.46045      0.00139     2.46283      2.45781
alpha_1                               0.53054      0.00091     0.53220      0.52929
alpha_2                               0.28828      0.00089     0.28989      0.28682
alpha_3                               0.22785      0.00116     0.23000      0.22602
alpha_4                               0.22381      0.00138     0.22615      0.22146
alpha_5                               0.48583      0.00249     0.49023      0.48196
alpha_6                               0.25309      0.00105     0.25506      0.25144
alpha_7                               0.30525      0.00083     0.30675      0.30370
alpha_8                               0.27417      0.00230     0.27826      0.27022
alpha_9                               0.14777      0.00070     0.14894      0.14651
Alpha_loss                            -0.14843     0.14065     0.17480      -0.55336
Training/policy_loss                  384.37772    22.88257    436.94122    326.04761
Training/qf1_loss                     3527.51369   1333.65369  10006.37793  1482.40076
Training/qf2_loss                     752.68434    291.18475   1714.16589   335.30362
Training/pf_norm                      11.83601     4.45326     24.23587     4.97874
Training/qf1_norm                     5722.20517   2743.38468  17406.47461  2341.46973
Training/qf2_norm                     4616.46195   2077.87690  13115.10156  1676.12451
log_std/mean                          -0.85597     0.00605     -0.84479     -0.86814
log_std/std                           0.38737      0.00587     0.40464      0.37528
log_std/max                           0.39997      0.21623     0.67420      0.01323
log_std/min                           -2.67275     0.14146     -2.27932     -2.90541
log_probs/mean                        3.89912      0.12008     4.22395      3.62459
log_probs/std                         3.64773      0.11322     3.91327      3.38564
log_probs/max                         26.30810     3.03186     30.76041     19.86491
log_probs/min                         -6.50604     1.29086     -4.39202     -10.78754
mean/mean                             -0.16417     0.05584     -0.08288     -0.30257
mean/std                              1.48489      0.02270     1.54464      1.44338
mean/max                              4.70105      0.36505     5.44405      4.20281
mean/min                              -8.48135     1.35958     -4.77125     -9.46886
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 9, 6, 3, 7, 1, 5, 4, 2]
replay_buffer._size: [66150 66150 66150 66150 66150 66150 66150 66150 66150 66150]
2023-08-12 12:44:50,346 MainThread INFO: EPOCH:419
2023-08-12 12:44:50,347 MainThread INFO: Time Consumed:8.448975563049316s
2023-08-12 12:44:50,347 MainThread INFO: Total Frames:660000s
  4%|▍         | 420/10000 [1:03:29<23:40:43,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1557.17836
Train_Epoch_Reward                    14567.60562
Running_Training_Average_Rewards      1520.99401
Explore_Time                          0.00408
Train___Time                          8.43946
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.79887
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.79690
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.80536
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.84871
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.22443
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.53309
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.98313
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16203.03269
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -70.37052
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -78.88807
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94183      1.51825     10.61555     3.29851
alpha_0                               2.46431      0.00257     2.46920      2.46056
alpha_1                               0.52742      0.00122     0.52927      0.52521
alpha_2                               0.29150      0.00091     0.29314      0.28993
alpha_3                               0.23177      0.00091     0.23347      0.23005
alpha_4                               0.21916      0.00125     0.22141      0.21698
alpha_5                               0.47691      0.00316     0.48189      0.47151
alpha_6                               0.24910      0.00140     0.25141      0.24692
alpha_7                               0.30190      0.00085     0.30365      0.30060
alpha_8                               0.28207      0.00222     0.28606      0.27834
alpha_9                               0.14516      0.00075     0.14648      0.14386
Alpha_loss                            -0.28353     0.16052     0.11085      -0.60700
Training/policy_loss                  378.47071    24.17547    439.11301    304.31525
Training/qf1_loss                     3460.89270   1291.14470  6794.10938   1310.37122
Training/qf2_loss                     680.83944    287.39592   1960.35767   329.11713
Training/pf_norm                      13.97209     7.02141     37.72271     4.59450
Training/qf1_norm                     5550.29097   2061.54687  11467.57910  1897.21887
Training/qf2_norm                     4493.71143   1562.09935  10367.51855  2009.86438
log_std/mean                          -0.85452     0.01404     -0.82554     -0.88439
log_std/std                           0.38488      0.00581     0.39797      0.37183
log_std/max                           0.34839      0.19206     0.56339      -0.02971
log_std/min                           -2.61156     0.13816     -2.16733     -2.81628
log_probs/mean                        3.78498      0.12131     4.05828      3.52612
log_probs/std                         3.64549      0.12860     4.05189      3.41002
log_probs/max                         26.17339     2.99112     30.50585     18.23920
log_probs/min                         -6.72115     1.29699     -4.12002     -10.32574
mean/mean                             -0.09910     0.03440     -0.02805     -0.22528
mean/std                              1.47585      0.02158     1.53449      1.43074
mean/max                              4.62551      0.43842     5.57147      4.01685
mean/min                              -8.58963     1.23186     -5.11682     -9.47652
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 5, 2, 8, 0, 4, 7, 6, 9]
replay_buffer._size: [66300 66300 66300 66300 66300 66300 66300 66300 66300 66300]
2023-08-12 12:44:59,168 MainThread INFO: EPOCH:420
2023-08-12 12:44:59,168 MainThread INFO: Time Consumed:8.648659944534302s
2023-08-12 12:44:59,168 MainThread INFO: Total Frames:661500s
  4%|▍         | 421/10000 [1:03:38<23:37:31,  8.88s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1562.76944
Train_Epoch_Reward                    15753.24289
Running_Training_Average_Rewards      1524.61222
Explore_Time                          0.01158
Train___Time                          8.63246
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.28804
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.09563
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.66922
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -62.71241
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.05544
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.95170
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.54609
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16251.88547
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.68431
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.18825
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.88924      1.39824     11.38953     3.63148
alpha_0                               2.45356      0.00530     2.46237      2.44458
alpha_1                               0.52306      0.00122     0.52516      0.52097
alpha_2                               0.29477      0.00086     0.29609      0.29318
alpha_3                               0.23492      0.00070     0.23595      0.23351
alpha_4                               0.21476      0.00121     0.21693      0.21275
alpha_5                               0.46533      0.00356     0.47140      0.45925
alpha_6                               0.24482      0.00128     0.24688      0.24255
alpha_7                               0.29843      0.00125     0.30056      0.29625
alpha_8                               0.29006      0.00227     0.29400      0.28615
alpha_9                               0.14258      0.00073     0.14384      0.14134
Alpha_loss                            -0.39041     0.13682     -0.14090     -0.77006
Training/policy_loss                  373.31978    20.00233    420.50363    330.29404
Training/qf1_loss                     3462.31840   1204.50702  7446.67969   1454.30750
Training/qf2_loss                     756.68920    382.67368   2968.18481   351.17715
Training/pf_norm                      12.15853     4.52748     27.71230     5.08710
Training/qf1_norm                     5399.80454   2252.81739  17422.90234  2266.75024
Training/qf2_norm                     5368.36683   2347.91294  12316.01172  1644.84387
log_std/mean                          -0.83940     0.01062     -0.81365     -0.86509
log_std/std                           0.38484      0.00557     0.39981      0.37310
log_std/max                           0.35148      0.15022     0.53666      -0.01548
log_std/min                           -2.63475     0.12507     -2.24096     -2.79188
log_probs/mean                        3.68911      0.13024     3.94705      3.38588
log_probs/std                         3.59700      0.13134     3.88088      3.26045
log_probs/max                         26.69683     2.96079     30.99134     17.67592
log_probs/min                         -6.48325     1.19678     -4.41792     -9.47102
mean/mean                             -0.07779     0.05014     0.03316      -0.17897
mean/std                              1.46521      0.01896     1.51036      1.42417
mean/max                              4.64015      0.44758     5.55518      4.05377
mean/min                              -8.83693     0.93037     -5.47257     -9.45284
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 5, 2, 1, 7, 3, 8, 9, 0, 4]
replay_buffer._size: [66450 66450 66450 66450 66450 66450 66450 66450 66450 66450]
2023-08-12 12:45:07,628 MainThread INFO: EPOCH:421
2023-08-12 12:45:07,628 MainThread INFO: Time Consumed:8.214433908462524s
2023-08-12 12:45:07,628 MainThread INFO: Total Frames:663000s
  4%|▍         | 422/10000 [1:03:46<23:15:20,  8.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1588.89979
Train_Epoch_Reward                    16233.78185
Running_Training_Average_Rewards      1551.82101
Explore_Time                          0.00401
Train___Time                          8.20541
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.85178
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.42796
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.51015
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.82217
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.49103
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -51.60802
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.48277
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16468.52206
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.46982
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -75.86042
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94599      1.38891     10.67872     3.57957
alpha_0                               2.44177      0.00561     2.44690      2.42738
alpha_1                               0.51932      0.00080     0.52094      0.51794
alpha_2                               0.29669      0.00022     0.29691      0.29611
alpha_3                               0.23740      0.00080     0.23863      0.23597
alpha_4                               0.21043      0.00137     0.21271      0.20796
alpha_5                               0.45361      0.00315     0.45913      0.44812
alpha_6                               0.24060      0.00104     0.24250      0.23890
alpha_7                               0.29412      0.00127     0.29621      0.29202
alpha_8                               0.29807      0.00225     0.30184      0.29408
alpha_9                               0.14011      0.00071     0.14132      0.13887
Alpha_loss                            -0.47515     0.15183     -0.15589     -0.80657
Training/policy_loss                  369.10713    19.54937    415.73248    323.70016
Training/qf1_loss                     3447.22217   1137.09445  7538.58936   1435.71411
Training/qf2_loss                     765.64788    366.78089   2117.29810   377.61432
Training/pf_norm                      11.42094     3.74603     25.31788     3.67617
Training/qf1_norm                     5218.14655   2456.16109  14171.40918  1754.60376
Training/qf2_norm                     5351.79352   2442.44029  12870.50977  1832.22607
log_std/mean                          -0.84019     0.00904     -0.82209     -0.86350
log_std/std                           0.38676      0.00732     0.40935      0.37247
log_std/max                           0.30792      0.13035     0.47711      -0.03973
log_std/min                           -2.56561     0.13295     -2.16371     -2.75282
log_probs/mean                        3.63964      0.14041     3.95734      3.38231
log_probs/std                         3.58896      0.12980     3.85836      3.28451
log_probs/max                         26.73282     3.18601     31.13571     17.86495
log_probs/min                         -6.60715     1.42294     -4.27530     -12.63926
mean/mean                             -0.11727     0.03098     -0.06052     -0.20034
mean/std                              1.45638      0.02093     1.51065      1.40314
mean/max                              4.66571      0.49808     5.58815      3.96277
mean/min                              -8.84596     1.03398     -5.27290     -9.52153
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 0, 8, 3, 6, 9, 7, 4, 2, 5]
replay_buffer._size: [66600 66600 66600 66600 66600 66600 66600 66600 66600 66600]
2023-08-12 12:45:16,572 MainThread INFO: EPOCH:422
2023-08-12 12:45:16,573 MainThread INFO: Time Consumed:8.799983978271484s
2023-08-12 12:45:16,573 MainThread INFO: Total Frames:664500s
  4%|▍         | 423/10000 [1:03:55<23:26:42,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1615.15786
Train_Epoch_Reward                    17265.76602
Running_Training_Average_Rewards      1641.75969
Explore_Time                          0.00365
Train___Time                          8.79107
Eval____Time                          0.00414
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.52633
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.70285
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.45582
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.53853
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -41.33660
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -36.99647
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.07809
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16691.35570
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.62584
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.51657
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.12737      1.44279     11.83673     3.76124
alpha_0                               2.41603      0.00422     2.42695      2.40726
alpha_1                               0.51691      0.00067     0.51792      0.51570
alpha_2                               0.29607      0.00029     0.29661      0.29551
alpha_3                               0.23971      0.00069     0.24095      0.23865
alpha_4                               0.20490      0.00177     0.20790      0.20188
alpha_5                               0.44305      0.00302     0.44802      0.43753
alpha_6                               0.23690      0.00122     0.23887      0.23481
alpha_7                               0.29010      0.00115     0.29198      0.28820
alpha_8                               0.30603      0.00235     0.30988      0.30193
alpha_9                               0.13744      0.00083     0.13884      0.13604
Alpha_loss                            -0.68417     0.13099     -0.38796     -0.96700
Training/policy_loss                  367.17068    23.11384    429.84189    284.83560
Training/qf1_loss                     3281.94477   1003.08570  7057.35938   1632.65906
Training/qf2_loss                     722.97842    287.18857   2025.26099   338.25977
Training/pf_norm                      13.45333     4.56231     26.36466     6.07895
Training/qf1_norm                     5278.16268   2450.76324  16516.12891  2232.47852
Training/qf2_norm                     5589.36476   2628.09485  14292.87402  2029.28467
log_std/mean                          -0.82491     0.00840     -0.80518     -0.85170
log_std/std                           0.37993      0.00597     0.39418      0.36470
log_std/max                           0.32933      0.09412     0.41452      -0.06443
log_std/min                           -2.49726     0.12279     -2.17905     -2.65708
log_probs/mean                        3.51460      0.10449     3.76794      3.25618
log_probs/std                         3.63133      0.13116     3.91067      3.34834
log_probs/max                         26.69481     3.06456     32.33073     18.14659
log_probs/min                         -6.99096     1.39702     -4.89652     -12.66721
mean/mean                             -0.11491     0.03222     -0.03515     -0.19754
mean/std                              1.44783      0.01943     1.49403      1.40770
mean/max                              4.69358      0.53980     5.62086      3.98840
mean/min                              -8.75259     1.11784     -4.91095     -9.47543
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 4, 7, 2, 9, 8, 6, 1, 0, 3]
replay_buffer._size: [66750 66750 66750 66750 66750 66750 66750 66750 66750 66750]
2023-08-12 12:45:25,128 MainThread INFO: EPOCH:423
2023-08-12 12:45:25,129 MainThread INFO: Time Consumed:8.377655029296875s
2023-08-12 12:45:25,129 MainThread INFO: Total Frames:666000s
  4%|▍         | 424/10000 [1:04:04<23:12:31,  8.73s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1595.74966
Train_Epoch_Reward                    15552.89442
Running_Training_Average_Rewards      1635.08141
Explore_Time                          0.00394
Train___Time                          8.36871
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.12321
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.77445
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.82390
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.82939
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.75283
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.93339
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.50407
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16561.25311
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.27329
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -77.74199
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.95893      1.40723     10.59673     4.39255
alpha_0                               2.39819      0.00383     2.40678      2.39281
alpha_1                               0.51425      0.00086     0.51568      0.51288
alpha_2                               0.29449      0.00064     0.29549      0.29322
alpha_3                               0.24157      0.00051     0.24257      0.24096
alpha_4                               0.19894      0.00171     0.20182      0.19603
alpha_5                               0.43095      0.00365     0.43740      0.42437
alpha_6                               0.23262      0.00118     0.23477      0.23064
alpha_7                               0.28636      0.00101     0.28816      0.28458
alpha_8                               0.31411      0.00243     0.31810      0.30997
alpha_9                               0.13463      0.00082     0.13601      0.13324
Alpha_loss                            -0.80754     0.14670     -0.39428     -1.11833
Training/policy_loss                  363.81956    22.16789    421.78806    299.28946
Training/qf1_loss                     3390.54882   1187.85616  6879.98682   1194.64197
Training/qf2_loss                     760.54517    315.03902   1813.90259   350.81027
Training/pf_norm                      11.89533     4.61031     30.71824     5.52772
Training/qf1_norm                     5520.01281   2537.42875  17383.57031  1773.54358
Training/qf2_norm                     4710.96860   1816.24233  10084.82812  1624.79065
log_std/mean                          -0.82539     0.01128     -0.80263     -0.85015
log_std/std                           0.38450      0.00520     0.39580      0.36750
log_std/max                           0.33483      0.12538     0.45757      -0.01482
log_std/min                           -2.50954     0.12626     -2.17546     -2.69759
log_probs/mean                        3.43248      0.12748     3.69398      3.14594
log_probs/std                         3.62063      0.13942     3.92597      3.26544
log_probs/max                         26.24943     3.90381     32.40029     17.26208
log_probs/min                         -6.96206     1.54673     -4.41503     -14.26356
mean/mean                             -0.12737     0.03619     -0.05220     -0.20722
mean/std                              1.43206      0.02436     1.48760      1.37229
mean/max                              4.67715      0.59639     5.68284      3.97103
mean/min                              -8.48649     1.45856     -4.76569     -9.68184
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 1, 9, 7, 0, 6, 2, 3, 4, 5]
replay_buffer._size: [66900 66900 66900 66900 66900 66900 66900 66900 66900 66900]
2023-08-12 12:45:34,146 MainThread INFO: EPOCH:424
2023-08-12 12:45:34,146 MainThread INFO: Time Consumed:8.848688125610352s
2023-08-12 12:45:34,146 MainThread INFO: Total Frames:667500s
  4%|▍         | 425/10000 [1:04:13<23:26:20,  8.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1513.13134
Train_Epoch_Reward                    15459.78471
Running_Training_Average_Rewards      1609.28151
Explore_Time                          0.01044
Train___Time                          8.83307
Eval____Time                          0.00414
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.98843
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.51219
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.23796
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.30837
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.57367
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -107.66582
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.51628
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15687.48843
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.26121
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -66.11112
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.12694      1.33773     10.70123     4.05698
alpha_0                               2.39564      0.00110     2.39764      2.39337
alpha_1                               0.51164      0.00053     0.51284      0.51091
alpha_2                               0.29150      0.00101     0.29318      0.28981
alpha_3                               0.24401      0.00078     0.24532      0.24260
alpha_4                               0.19328      0.00156     0.19597      0.19059
alpha_5                               0.41761      0.00367     0.42421      0.41130
alpha_6                               0.22926      0.00070     0.23060      0.22811
alpha_7                               0.28250      0.00130     0.28454      0.28019
alpha_8                               0.32178      0.00205     0.32497      0.31816
alpha_9                               0.13195      0.00072     0.13321      0.13071
Alpha_loss                            -0.75029     0.16544     -0.39463     -1.17594
Training/policy_loss                  358.38721    21.63363    419.63058    314.79846
Training/qf1_loss                     3333.89802   1253.42854  8047.41406   1403.10388
Training/qf2_loss                     742.07862    325.03008   2143.77148   373.84363
Training/pf_norm                      11.22449     4.14179     31.52105     5.58549
Training/qf1_norm                     5875.14661   2545.76337  15847.17090  1926.89221
Training/qf2_norm                     4744.37022   2058.87190  10600.01758  1704.72705
log_std/mean                          -0.83603     0.00937     -0.81316     -0.86138
log_std/std                           0.38302      0.00875     0.40196      0.36327
log_std/max                           0.34518      0.11430     0.47465      -0.06935
log_std/min                           -2.55924     0.11355     -2.19415     -2.72019
log_probs/mean                        3.47944      0.14175     3.73508      3.17787
log_probs/std                         3.60988      0.12797     3.91044      3.27113
log_probs/max                         26.54867     3.75523     33.02195     17.34557
log_probs/min                         -6.71499     1.39438     -3.83434     -11.49741
mean/mean                             -0.12955     0.03143     -0.05890     -0.19986
mean/std                              1.43034      0.02257     1.47415      1.36985
mean/max                              4.64014      0.58642     5.70149      3.98138
mean/min                              -8.72702     1.30348     -5.35887     -9.80199
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 6, 2, 0, 4, 3, 5, 1, 7, 9]
replay_buffer._size: [67050 67050 67050 67050 67050 67050 67050 67050 67050 67050]
2023-08-12 12:45:42,698 MainThread INFO: EPOCH:425
2023-08-12 12:45:42,698 MainThread INFO: Time Consumed:8.360790491104126s
2023-08-12 12:45:42,698 MainThread INFO: Total Frames:669000s
  4%|▍         | 426/10000 [1:04:21<23:15:00,  8.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1627.31615
Train_Epoch_Reward                    14817.66265
Running_Training_Average_Rewards      1527.67806
Explore_Time                          0.01236
Train___Time                          8.34305
Eval____Time                          0.00476
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.50170
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.84044
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -81.43450
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.36924
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.92736
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -108.42633
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.02214
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16857.72620
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.53889
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.50407
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.94291      1.38663     10.82909     4.19387
alpha_0                               2.38479      0.00247     2.39292      2.38290
alpha_1                               0.51028      0.00034     0.51089      0.50984
alpha_2                               0.28825      0.00093     0.28978      0.28662
alpha_3                               0.24604      0.00029     0.24639      0.24535
alpha_4                               0.18785      0.00156     0.19053      0.18518
alpha_5                               0.40404      0.00423     0.41117      0.39691
alpha_6                               0.22671      0.00095     0.22809      0.22511
alpha_7                               0.27729      0.00180     0.28014      0.27448
alpha_8                               0.32808      0.00183     0.33123      0.32503
alpha_9                               0.12939      0.00074     0.13069      0.12816
Alpha_loss                            -0.90759     0.19413     -0.34231     -1.35651
Training/policy_loss                  359.40372    25.04860    424.33554    307.15482
Training/qf1_loss                     3032.01926   1145.87610  6407.49170   1002.97913
Training/qf2_loss                     719.88416    292.11675   1615.68445   351.92551
Training/pf_norm                      10.57376     3.66711     23.40910     4.78988
Training/qf1_norm                     5140.02419   2198.80215  13795.46875  1756.48730
Training/qf2_norm                     4632.91264   2042.03080  11415.69336  1551.65820
log_std/mean                          -0.82366     0.01370     -0.79594     -0.85519
log_std/std                           0.37589      0.00709     0.39447      0.35755
log_std/max                           0.43141      0.11726     0.55888      -0.03869
log_std/min                           -2.53744     0.10363     -2.15261     -2.65544
log_probs/mean                        3.38103      0.16285     3.81660      3.03555
log_probs/std                         3.59033      0.12311     3.93904      3.25825
log_probs/max                         27.45135     3.46652     32.50039     16.25241
log_probs/min                         -6.79661     1.23227     -5.07204     -11.43201
mean/mean                             -0.13481     0.03861     -0.05426     -0.22580
mean/std                              1.42064      0.02644     1.47483      1.35454
mean/max                              4.60896      0.58429     5.63934      3.98928
mean/min                              -9.12516     1.13384     -4.41021     -9.77162
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 0, 8, 1, 7, 6, 2, 4, 5]
replay_buffer._size: [67200 67200 67200 67200 67200 67200 67200 67200 67200 67200]
2023-08-12 12:45:52,006 MainThread INFO: EPOCH:426
2023-08-12 12:45:52,006 MainThread INFO: Time Consumed:9.103586435317993s
2023-08-12 12:45:52,006 MainThread INFO: Total Frames:670500s
  4%|▍         | 427/10000 [1:04:31<23:43:03,  8.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1438.55149
Train_Epoch_Reward                    15479.19410
Running_Training_Average_Rewards      1525.22138
Explore_Time                          0.01570
Train___Time                          9.08306
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.65416
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.29776
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -73.80220
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.99858
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.56175
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.56562
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.27381
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14966.80456
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.97320
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -66.16258
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.17854      1.32861     12.32975     4.75094
alpha_0                               2.38124      0.00370     2.38683      2.37100
alpha_1                               0.50990      0.00013     0.51006      0.50964
alpha_2                               0.28482      0.00120     0.28660      0.28267
alpha_3                               0.24829      0.00099     0.24950      0.24637
alpha_4                               0.18262      0.00144     0.18513      0.18021
alpha_5                               0.38974      0.00427     0.39679      0.38253
alpha_6                               0.22397      0.00072     0.22509      0.22283
alpha_7                               0.27206      0.00156     0.27445      0.26947
alpha_8                               0.33353      0.00123     0.33574      0.33129
alpha_9                               0.12695      0.00070     0.12814      0.12578
Alpha_loss                            -0.87298     0.19780     -0.41599     -1.22224
Training/policy_loss                  353.75105    22.78681    412.37509    300.52032
Training/qf1_loss                     3152.13223   1190.97715  7053.50146   1254.34961
Training/qf2_loss                     728.71643    346.29176   2078.30981   374.52634
Training/pf_norm                      10.82080     4.11445     24.01653     5.06017
Training/qf1_norm                     5235.57702   1954.91785  10436.68164  1954.00867
Training/qf2_norm                     4190.51823   1754.68775  10245.48828  1495.54944
log_std/mean                          -0.81606     0.01319     -0.79173     -0.84550
log_std/std                           0.37819      0.00678     0.39344      0.36006
log_std/max                           0.39056      0.13305     0.56163      -0.00717
log_std/min                           -2.60714     0.08419     -2.37978     -2.75118
log_probs/mean                        3.37683      0.13426     3.65562      3.03879
log_probs/std                         3.60717      0.13235     3.97445      3.37971
log_probs/max                         26.94394     3.41764     33.69974     17.26975
log_probs/min                         -6.85686     1.31814     -4.60471     -11.49243
mean/mean                             -0.17223     0.03415     -0.10482     -0.24571
mean/std                              1.41900      0.02681     1.51056      1.36570
mean/max                              4.58299      0.64316     5.68239      3.68206
mean/min                              -8.99421     1.26824     -4.57207     -9.98349
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 7, 9, 3, 4, 0, 5, 2, 1]
replay_buffer._size: [67350 67350 67350 67350 67350 67350 67350 67350 67350 67350]
2023-08-12 12:46:01,462 MainThread INFO: EPOCH:427
2023-08-12 12:46:01,462 MainThread INFO: Time Consumed:9.280100584030151s
2023-08-12 12:46:01,462 MainThread INFO: Total Frames:672000s
  4%|▍         | 428/10000 [1:04:40<24:07:56,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1595.26582
Train_Epoch_Reward                    15171.46117
Running_Training_Average_Rewards      1515.61060
Explore_Time                          0.00494
Train___Time                          9.26879
Eval____Time                          0.00565
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.41869
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.53240
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -75.50123
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.31332
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.22861
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.24217
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.10200
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16538.45397
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.49979
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.95758
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.77993      1.24568     9.86367      4.23006
alpha_0                               2.37534      0.00411     2.38141      2.36996
alpha_1                               0.51017      0.00030     0.51080      0.50964
alpha_2                               0.28078      0.00093     0.28262      0.27930
alpha_3                               0.25107      0.00099     0.25241      0.24950
alpha_4                               0.17794      0.00124     0.18016      0.17589
alpha_5                               0.37601      0.00366     0.38238      0.36997
alpha_6                               0.22135      0.00085     0.22281      0.21995
alpha_7                               0.26743      0.00105     0.26941      0.26570
alpha_8                               0.33751      0.00103     0.33939      0.33579
alpha_9                               0.12463      0.00066     0.12576      0.12350
Alpha_loss                            -0.79150     0.20139     -0.30843     -1.46571
Training/policy_loss                  352.00573    23.13302    411.18457    293.80841
Training/qf1_loss                     2947.53523   1064.92367  6429.56396   1187.70898
Training/qf2_loss                     683.04467    288.03674   1971.65369   296.05246
Training/pf_norm                      11.99741     4.11345     23.71095     5.81985
Training/qf1_norm                     5527.53265   2515.68122  15111.04688  1705.75830
Training/qf2_norm                     5276.92092   2202.28940  11912.49219  1619.23267
log_std/mean                          -0.83111     0.01359     -0.80309     -0.85841
log_std/std                           0.37876      0.00667     0.39933      0.36111
log_std/max                           0.44462      0.14312     0.55873      -0.00133
log_std/min                           -2.61741     0.09266     -2.24052     -2.74502
log_probs/mean                        3.49617      0.15923     3.93991      3.07327
log_probs/std                         3.63035      0.13915     4.04976      3.17311
log_probs/max                         26.51949     3.68415     32.23558     15.94642
log_probs/min                         -6.72044     1.33036     -4.43550     -10.66383
mean/mean                             -0.16592     0.04016     -0.05220     -0.24457
mean/std                              1.43442      0.02670     1.52701      1.36173
mean/max                              4.57448      0.70669     5.84508      3.60159
mean/min                              -9.06027     1.08339     -5.33653     -9.70566
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 7, 0, 3, 8, 5, 4, 1, 6, 2]
replay_buffer._size: [67500 67500 67500 67500 67500 67500 67500 67500 67500 67500]
2023-08-12 12:46:11,058 MainThread INFO: EPOCH:428
2023-08-12 12:46:11,059 MainThread INFO: Time Consumed:9.412506818771362s
2023-08-12 12:46:11,059 MainThread INFO: Total Frames:673500s
  4%|▍         | 429/10000 [1:04:50<24:31:30,  9.22s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1633.54099
Train_Epoch_Reward                    15367.50359
Running_Training_Average_Rewards      1533.93863
Explore_Time                          0.00509
Train___Time                          9.39232
Eval____Time                          0.00367
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.86832
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.61798
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -74.80080
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.60641
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.10069
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.11242
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.51389
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16904.65902
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.56447
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -61.06413
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.32731      1.37139     11.91920     4.89024
alpha_0                               2.37483      0.00674     2.38270      2.36129
alpha_1                               0.51086      0.00007     0.51096      0.51075
alpha_2                               0.27785      0.00083     0.27927      0.27650
alpha_3                               0.25316      0.00030     0.25370      0.25243
alpha_4                               0.17378      0.00120     0.17585      0.17177
alpha_5                               0.36410      0.00337     0.36986      0.35857
alpha_6                               0.21830      0.00104     0.21992      0.21651
alpha_7                               0.26304      0.00158     0.26566      0.26031
alpha_8                               0.34089      0.00077     0.34218      0.33942
alpha_9                               0.12243      0.00060     0.12347      0.12142
Alpha_loss                            -0.85001     0.21069     -0.36121     -1.39192
Training/policy_loss                  341.74237    21.75163    392.74118    285.58237
Training/qf1_loss                     3230.20699   1155.83837  7940.15771   1460.74695
Training/qf2_loss                     688.78731    264.45803   1994.00769   366.72354
Training/pf_norm                      11.49593     4.19711     26.09380     6.13752
Training/qf1_norm                     5151.05513   1941.85598  12856.67188  1600.33350
Training/qf2_norm                     4731.70630   1844.78051  9969.99121   1963.41907
log_std/mean                          -0.82785     0.01456     -0.80123     -0.86205
log_std/std                           0.38362      0.00731     0.40987      0.36844
log_std/max                           0.45934      0.17837     0.64025      -0.02342
log_std/min                           -2.64880     0.08508     -2.26698     -2.80685
log_probs/mean                        3.40531      0.16747     3.76241      2.92047
log_probs/std                         3.59628      0.12221     3.95943      3.29173
log_probs/max                         25.90884     3.61230     33.01261     15.53631
log_probs/min                         -6.74123     1.24906     -3.73289     -10.52562
mean/mean                             -0.16260     0.03793     -0.08886     -0.23629
mean/std                              1.41795      0.02584     1.47509      1.34354
mean/max                              4.52851      0.69768     5.89760      3.64451
mean/min                              -8.67727     1.37731     -5.07139     -9.71339
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 7, 8, 9, 5, 3, 6, 1, 4]
replay_buffer._size: [67650 67650 67650 67650 67650 67650 67650 67650 67650 67650]
2023-08-12 12:46:20,482 MainThread INFO: EPOCH:429
2023-08-12 12:46:20,483 MainThread INFO: Time Consumed:9.241661787033081s
2023-08-12 12:46:20,483 MainThread INFO: Total Frames:675000s
  4%|▍         | 430/10000 [1:04:59<24:40:21,  9.28s/it]  4%|▍         | 430/10000 [1:05:03<24:07:55,  9.08s/it]
------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1657.62839
Train_Epoch_Reward                    15466.14765
Running_Training_Average_Rewards      1533.50375
Explore_Time                          0.00401
Train___Time                          9.21461
Eval____Time                          0.00393
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.90483
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.46971
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -69.03131
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -14.84748
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.56037
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.87326
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -47.81425
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17133.81339
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.15318
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -60.87514
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.90361      1.23787     10.15741     3.43450
alpha_0                               2.35093      0.00490     2.36076      2.34008
alpha_1                               0.51144      0.00037     0.51185      0.51080
alpha_2                               0.27512      0.00082     0.27647      0.27376
alpha_3                               0.25490      0.00063     0.25623      0.25373
alpha_4                               0.17005      0.00102     0.17174      0.16837
alpha_5                               0.35269      0.00325     0.35845      0.34740
alpha_6                               0.21511      0.00076     0.21648      0.21387
alpha_7                               0.25762      0.00147     0.26025      0.25535
alpha_8                               0.34370      0.00088     0.34533      0.34221
alpha_9                               0.12041      0.00057     0.12140      0.11946
Alpha_loss                            -0.71877     0.17535     -0.25031     -1.09415
Training/policy_loss                  342.75648    22.71549    409.78427    290.71286
Training/qf1_loss                     2957.78708   1156.62079  6303.63135   1298.99634
Training/qf2_loss                     640.02615    200.20314   1352.40662   323.34082
Training/pf_norm                      11.05951     3.14321     24.22611     5.99766
Training/qf1_norm                     5680.33757   2535.66352  13602.37598  2185.31128
Training/qf2_norm                     4558.82907   1888.44143  11853.34082  1962.10632
log_std/mean                          -0.83142     0.01162     -0.80984     -0.86119
log_std/std                           0.38471      0.00670     0.40023      0.36821
log_std/max                           0.46567      0.18250     0.67932      0.00210
log_std/min                           -2.68658     0.10608     -2.30014     -2.80588
log_probs/mean                        3.51228      0.12767     3.83862      3.24288
log_probs/std                         3.62615      0.12882     4.01731      3.36450
log_probs/max                         26.36491     3.83369     32.98985     18.05184
log_probs/min                         -6.89346     1.31232     -4.47946     -10.86411
mean/mean                             -0.18463     0.03249     -0.11899     -0.26853
mean/std                              1.42968      0.02366     1.49292      1.37988
mean/max                              4.45702      0.71726     5.87494      3.44654
mean/min                              -8.91143     1.25809     -5.17527     -9.80474
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 8, 6, 3, 1, 9, 7, 0, 2, 5]
replay_buffer._size: [67800 67800 67800 67800 67800 67800 67800 67800 67800 67800]
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 303, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 298, in experiment
    agent.train(env.num_tasks,params)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 363, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 307, in update_per_epoch
    all_info = self.update(batch, task_sample_index, task_scheduler, mask_buffer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 128, in update
    q2_device_masks = self.concat_mask_tensors(task_scheduler.task_sample_num,
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 47, in concat_mask_tensors
    single_mask = [each.expand(task_batch_size, -1).to(device) for each in specific_mask_buffer[i]]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
