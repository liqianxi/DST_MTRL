W&B enabled.
2023-09-06 13:29:54,135 MainThread INFO: Experiment Name:testing_must_mtsac
2023-09-06 13:29:54,135 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      20,
      20
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      24,
      24
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      24,
      24
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 400,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "success_traj_update_only": 1,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 10,
    "mask_update_interval": 25,
    "update_end_epoch": 20,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
wandb: Currently logged in as: liqianxi. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: WARNING Serializing object of type str that is 890656 bytes
wandb: wandb version 0.15.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/qianxi/t3s/t3s_code/wandb/run-20230906_133053-u0e84re1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-pyramid-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/liqianxi/dst_mtrl
wandb: üöÄ View run at https://wandb.ai/liqianxi/dst_mtrl/runs/u0e84re1
2023-09-06 13:31:01,617 MainThread INFO: Finished Pretrain
  0%|          | 0/400 [00:00<?, ?it/s]sample: [6, 5, 0, 3, 9, 8, 4, 2, 1, 7]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.5295538902282715 0.002179861068725586
train_time 1.5330922603607178
snapshot at best
2023-09-06 13:31:05,410 MainThread INFO: EPOCH:0
2023-09-06 13:31:05,412 MainThread INFO: Time Consumed:3.733110189437866s
2023-09-06 13:31:05,413 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:374: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/400 [00:04<31:25,  4.73s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.07370
Train_Epoch_Reward                    18508.01307
Running_Training_Average_Rewards      1850.80131
Explore_Time                          0.01097
Train___Time                          1.53309
Eval____Time                          1.29047
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.60273
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70519
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54909
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.31825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46967
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17711
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.17461
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11269.03066
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97876
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.31828
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.01330     0.45654    10.80010    9.17306
alpha_0                               0.99835      0.00086    0.99970     0.99700
alpha_1                               0.99835      0.00086    0.99970     0.99700
alpha_2                               0.99835      0.00086    0.99970     0.99700
alpha_3                               0.99835      0.00086    0.99970     0.99700
alpha_4                               0.99835      0.00086    0.99970     0.99700
alpha_5                               0.99835      0.00086    0.99970     0.99700
alpha_6                               0.99835      0.00086    0.99970     0.99700
alpha_7                               0.99835      0.00086    0.99970     0.99701
alpha_8                               0.99835      0.00086    0.99970     0.99700
alpha_9                               0.99835      0.00086    0.99970     0.99700
Alpha_loss                            -0.00902     0.00576    -0.00000    -0.01804
Training/policy_loss                  -2.67936     0.00863    -2.66753    -2.69321
Training/qf1_loss                     1283.48792   111.65726  1450.53906  1091.17114
Training/qf2_loss                     1283.54996   111.65562  1450.59436  1091.23242
Training/pf_norm                      0.45512      0.02320    0.50188     0.42286
Training/qf1_norm                     27.84650     0.98115    29.54997    26.03043
Training/qf2_norm                     27.34112     0.94425    28.92131    25.54452
log_std/mean                          -0.00234     0.00200    0.00078     -0.00549
log_std/std                           0.00197      0.00006    0.00207     0.00190
log_std/max                           0.00046      0.00182    0.00340     -0.00237
log_std/min                           -0.00627     0.00198    -0.00329    -0.00960
log_probs/mean                        -2.68238     0.00864    -2.67068    -2.69640
log_probs/std                         0.43140      0.01052    0.44894     0.41645
log_probs/max                         -1.28875     0.08437    -1.16988    -1.41670
log_probs/min                         -4.45871     0.89959    -3.68894    -6.38592
mean/mean                             -0.00055     0.00031    -0.00002    -0.00091
mean/std                              0.00205      0.00045    0.00280     0.00134
mean/max                              0.00257      0.00034    0.00327     0.00211
mean/min                              -0.00395     0.00114    -0.00241    -0.00592
------------------------------------  -----------  ---------  ----------  ----------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [6, 2, 0, 9, 3, 5, 7, 8, 4, 1]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1280944347381592 0.0022344589233398438
train_time 1.131636619567871
snapshot at best
2023-09-06 13:31:08,025 MainThread INFO: EPOCH:1
2023-09-06 13:31:08,026 MainThread INFO: Time Consumed:1.6449267864227295s
2023-09-06 13:31:08,026 MainThread INFO: Total Frames:3000s
  0%|          | 2/400 [00:06<19:50,  2.99s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.27373
Train_Epoch_Reward                    14304.16517
Running_Training_Average_Rewards      1640.60891
Explore_Time                          0.00449
Train___Time                          1.13164
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.60207
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70519
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54909
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.31825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46967
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17711
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.17461
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11269.03066
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97876
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.31828
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           12.41937     1.35623    14.38481    10.00399
alpha_0                               0.99536      0.00086    0.99670     0.99402
alpha_1                               0.99536      0.00086    0.99670     0.99401
alpha_2                               0.99536      0.00086    0.99670     0.99401
alpha_3                               0.99536      0.00086    0.99671     0.99402
alpha_4                               0.99536      0.00086    0.99671     0.99402
alpha_5                               0.99536      0.00086    0.99671     0.99402
alpha_6                               0.99536      0.00086    0.99671     0.99402
alpha_7                               0.99536      0.00086    0.99671     0.99402
alpha_8                               0.99536      0.00086    0.99671     0.99402
alpha_9                               0.99536      0.00086    0.99671     0.99402
Alpha_loss                            -0.02910     0.00576    -0.02009    -0.03817
Training/policy_loss                  -2.68652     0.00675    -2.67350    -2.69463
Training/qf1_loss                     2533.17289   711.94635  3500.23950  1283.13086
Training/qf2_loss                     2533.27554   711.96075  3500.37427  1283.20996
Training/pf_norm                      0.42570      0.01882    0.45560     0.39595
Training/qf1_norm                     33.58766     3.17598    38.46067    27.89173
Training/qf2_norm                     32.87744     3.07270    37.36027    27.35240
log_std/mean                          -0.00954     0.00216    -0.00620    -0.01298
log_std/std                           0.00228      0.00013    0.00249     0.00210
log_std/max                           -0.00597     0.00190    -0.00304    -0.00899
log_std/min                           -0.01448     0.00261    -0.01046    -0.01865
log_probs/mean                        -2.68991     0.00676    -2.67688    -2.69806
log_probs/std                         0.41680      0.01271    0.43996     0.39528
log_probs/max                         -1.33208     0.10653    -1.16975    -1.46353
log_probs/min                         -4.63393     0.96680    -3.77265    -7.37184
mean/mean                             -0.00128     0.00019    -0.00096    -0.00154
mean/std                              0.00345      0.00030    0.00390     0.00298
mean/max                              0.00395      0.00015    0.00414     0.00373
mean/min                              -0.00885     0.00142    -0.00655    -0.01090
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 3, 2, 4, 5, 0, 6, 1, 8, 9]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1241095066070557 0.003683328628540039
train_time 1.129218578338623
2023-09-06 13:31:09,337 MainThread INFO: EPOCH:2
2023-09-06 13:31:09,338 MainThread INFO: Time Consumed:1.160161018371582s
2023-09-06 13:31:09,338 MainThread INFO: Total Frames:4500s
  1%|          | 3/400 [00:07<14:55,  2.25s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.20266
Train_Epoch_Reward                    10550.35440
Running_Training_Average_Rewards      1445.41775
Explore_Time                          0.00942
Train___Time                          1.12922
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.73439
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70519
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54909
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.31825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46967
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17711
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.17461
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11269.03066
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97876
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.31828
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           12.43189     0.87089    13.72403    10.94742
alpha_0                               0.99238      0.00086    0.99372     0.99104
alpha_1                               0.99237      0.00086    0.99372     0.99103
alpha_2                               0.99238      0.00085    0.99372     0.99104
alpha_3                               0.99238      0.00085    0.99372     0.99104
alpha_4                               0.99238      0.00086    0.99372     0.99104
alpha_5                               0.99238      0.00086    0.99372     0.99104
alpha_6                               0.99238      0.00086    0.99372     0.99104
alpha_7                               0.99238      0.00086    0.99372     0.99104
alpha_8                               0.99238      0.00085    0.99372     0.99104
alpha_9                               0.99238      0.00086    0.99372     0.99104
Alpha_loss                            -0.04921     0.00582    -0.04011    -0.05829
Training/policy_loss                  -2.69013     0.01225    -2.67010    -2.70608
Training/qf1_loss                     2548.88472   411.95973  3148.62451  1935.91431
Training/qf2_loss                     2549.01588   411.97201  3148.76709  1936.02234
Training/pf_norm                      0.41346      0.03089    0.46682     0.36276
Training/qf1_norm                     34.04872     2.09367    37.14576    30.39378
Training/qf2_norm                     33.29949     1.98101    36.20525    29.97852
log_std/mean                          -0.01755     0.00245    -0.01377    -0.02145
log_std/std                           0.00289      0.00024    0.00328     0.00255
log_std/max                           -0.01264     0.00192    -0.00967    -0.01568
log_std/min                           -0.02429     0.00306    -0.01962    -0.02917
log_probs/mean                        -2.69344     0.01228    -2.67340    -2.70937
log_probs/std                         0.40298      0.00615    0.41321     0.39230
log_probs/max                         -1.42456     0.06056    -1.34063    -1.55547
log_probs/min                         -4.40885     0.48822    -3.72980    -5.25701
mean/mean                             -0.00177     0.00007    -0.00163    -0.00188
mean/std                              0.00450      0.00027    0.00487     0.00402
mean/max                              0.00501      0.00069    0.00583     0.00386
mean/min                              -0.01294     0.00088    -0.01139    -0.01422
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 2, 7, 4, 3, 8, 0, 1, 6, 9]
replay_buffer._size: [758 750 750 752 753 758 755 755 758 752]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1353061199188232 0.002149820327758789
train_time 1.1387896537780762
2023-09-06 13:31:10,763 MainThread INFO: EPOCH:3
2023-09-06 13:31:10,763 MainThread INFO: Time Consumed:1.2107322216033936s
2023-09-06 13:31:10,764 MainThread INFO: Total Frames:6000s
  1%|          | 4/400 [00:09<12:29,  1.89s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1091.18349
Train_Epoch_Reward                    32792.64420
Running_Training_Average_Rewards      1921.57213
Explore_Time                          0.06243
Train___Time                          1.13879
Eval____Time                          0.00323
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.50783
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.15868
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.32704
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.62179
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43733
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14134
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.99069
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10962.22946
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.38095
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.50195
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.85705     0.66904    12.90582    10.71233
alpha_0                               0.98940      0.00085    0.99074     0.98806
alpha_1                               0.98940      0.00085    0.99074     0.98806
alpha_2                               0.98941      0.00085    0.99074     0.98807
alpha_3                               0.98941      0.00085    0.99075     0.98807
alpha_4                               0.98941      0.00085    0.99074     0.98807
alpha_5                               0.98941      0.00085    0.99074     0.98807
alpha_6                               0.98940      0.00085    0.99074     0.98806
alpha_7                               0.98940      0.00085    0.99074     0.98807
alpha_8                               0.98941      0.00085    0.99074     0.98807
alpha_9                               0.98940      0.00085    0.99074     0.98807
Alpha_loss                            -0.06940     0.00586    -0.06033    -0.07864
Training/policy_loss                  -2.70046     0.01130    -2.68221    -2.71780
Training/qf1_loss                     2256.24623   335.93535  2750.07666  1711.71619
Training/qf2_loss                     2256.41140   335.93711  2750.26367  1711.87402
Training/pf_norm                      0.35747      0.03679    0.41710     0.28446
Training/qf1_norm                     33.44765     1.48405    36.09317    30.85669
Training/qf2_norm                     32.48284     1.44925    34.76955    29.94598
log_std/mean                          -0.02657     0.00272    -0.02236    -0.03087
log_std/std                           0.00382      0.00029    0.00429     0.00337
log_std/max                           -0.01965     0.00212    -0.01637    -0.02304
log_std/min                           -0.03533     0.00325    -0.03027    -0.04045
log_probs/mean                        -2.70287     0.01110    -2.68471    -2.71965
log_probs/std                         0.37938      0.00800    0.39006     0.36513
log_probs/max                         -1.44837     0.05931    -1.36934    -1.55697
log_probs/min                         -4.42616     0.45196    -4.01903    -5.19320
mean/mean                             -0.00207     0.00006    -0.00195    -0.00213
mean/std                              0.00455      0.00032    0.00492     0.00403
mean/max                              0.00613      0.00008    0.00622     0.00594
mean/min                              -0.01382     0.00068    -0.01263    -0.01453
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 2, 6, 0, 5, 1, 9, 3, 8, 7]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.3189072608947754 0.002677440643310547
train_time 1.322988510131836
2023-09-06 13:31:12,269 MainThread INFO: EPOCH:4
2023-09-06 13:31:12,269 MainThread INFO: Time Consumed:1.3501017093658447s
2023-09-06 13:31:12,270 MainThread INFO: Total Frames:7500s
  1%|‚ñè         | 5/400 [00:10<11:32,  1.75s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1072.32636
Train_Epoch_Reward                    14415.75912
Running_Training_Average_Rewards      1925.29192
Explore_Time                          0.01661
Train___Time                          1.32299
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.63359
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.27830
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.28441
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.76407
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43934
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16129
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.85981
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10699.66943
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.42354
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.80133
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.15834     0.55712    12.06290    10.45791
alpha_0                               0.98643      0.00085    0.98776     0.98509
alpha_1                               0.98643      0.00085    0.98776     0.98509
alpha_2                               0.98644      0.00085    0.98777     0.98511
alpha_3                               0.98645      0.00085    0.98778     0.98511
alpha_4                               0.98644      0.00085    0.98778     0.98511
alpha_5                               0.98644      0.00085    0.98778     0.98511
alpha_6                               0.98643      0.00085    0.98777     0.98510
alpha_7                               0.98644      0.00085    0.98777     0.98510
alpha_8                               0.98644      0.00085    0.98777     0.98510
alpha_9                               0.98644      0.00085    0.98777     0.98510
Alpha_loss                            -0.08959     0.00580    -0.08058    -0.09867
Training/policy_loss                  -2.70776     0.00582    -2.69785    -2.71569
Training/qf1_loss                     1946.84502   277.73243  2361.12085  1473.13745
Training/qf2_loss                     1947.03655   277.73540  2361.29565  1473.30090
Training/pf_norm                      0.34988      0.01591    0.38305     0.32480
Training/qf1_norm                     32.40826     1.21078    34.24028    30.52347
Training/qf2_norm                     31.40441     1.21231    33.32121    29.73975
log_std/mean                          -0.03649     0.00301    -0.03185    -0.04131
log_std/std                           0.00496      0.00037    0.00555     0.00440
log_std/max                           -0.02737     0.00233    -0.02379    -0.03111
log_std/min                           -0.04722     0.00366    -0.04160    -0.05311
log_probs/mean                        -2.70789     0.00570    -2.69892    -2.71678
log_probs/std                         0.36530      0.00663    0.37491     0.35103
log_probs/max                         -1.55310     0.08221    -1.43098    -1.68649
log_probs/min                         -4.35781     0.48525    -3.53449    -5.19440
mean/mean                             -0.00230     0.00011    -0.00206    -0.00241
mean/std                              0.00366      0.00015    0.00395     0.00348
mean/max                              0.00525      0.00048    0.00611     0.00473
mean/min                              -0.01151     0.00072    -0.01022    -0.01251
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 8, 5, 7, 4, 3, 2, 1, 6, 0]
replay_buffer._size: [1054 1052 1057 1052 1052 1062 1055 1055 1055 1054]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.2094132900238037 0.002335071563720703
train_time 1.2130746841430664
2023-09-06 13:31:13,710 MainThread INFO: EPOCH:5
2023-09-06 13:31:13,710 MainThread INFO: Time Consumed:1.320741891860962s
2023-09-06 13:31:13,710 MainThread INFO: Total Frames:9000s
  2%|‚ñè         | 6/400 [00:12<11:00,  1.68s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1058.66230
Train_Epoch_Reward                    13379.00532
Running_Training_Average_Rewards      2019.58029
Explore_Time                          0.09892
Train___Time                          1.21307
Eval____Time                          0.00311
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.84715
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.29953
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.37127
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.53878
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.35037
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.08202
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.68107
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10858.70167
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.39422
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.45382
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.81837     0.71814    11.63089    9.34134
alpha_0                               0.98347      0.00085    0.98480     0.98214
alpha_1                               0.98347      0.00085    0.98480     0.98214
alpha_2                               0.98348      0.00085    0.98481     0.98215
alpha_3                               0.98349      0.00085    0.98482     0.98216
alpha_4                               0.98349      0.00085    0.98482     0.98216
alpha_5                               0.98348      0.00085    0.98481     0.98215
alpha_6                               0.98347      0.00085    0.98480     0.98214
alpha_7                               0.98348      0.00085    0.98481     0.98215
alpha_8                               0.98348      0.00085    0.98481     0.98215
alpha_9                               0.98348      0.00085    0.98481     0.98215
Alpha_loss                            -0.10979     0.00577    -0.10071    -0.11893
Training/policy_loss                  -2.71476     0.00931    -2.69777    -2.73200
Training/qf1_loss                     1917.76934   358.58043  2390.36401  1157.22266
Training/qf2_loss                     1917.99840   358.60398  2390.63330  1157.39954
Training/pf_norm                      0.31572      0.03002    0.36632     0.27333
Training/qf1_norm                     32.35750     1.93295    34.78452    28.30790
Training/qf2_norm                     31.23994     1.77050    33.57545    27.58434
log_std/mean                          -0.04773     0.00342    -0.04244    -0.05318
log_std/std                           0.00637      0.00044    0.00707     0.00570
log_std/max                           -0.03617     0.00265    -0.03200    -0.04038
log_std/min                           -0.06125     0.00437    -0.05454    -0.06828
log_probs/mean                        -2.71092     0.00951    -2.69257    -2.72966
log_probs/std                         0.33995      0.00711    0.35287     0.32947
log_probs/max                         -1.70231     0.05990    -1.62073    -1.84044
log_probs/min                         -4.20271     0.38602    -3.53422    -4.84625
mean/mean                             -0.00085     0.00072    0.00028     -0.00187
mean/std                              0.00325      0.00007    0.00342     0.00318
mean/max                              0.00570      0.00050    0.00653     0.00498
mean/min                              -0.00782     0.00128    -0.00607    -0.00983
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 7, 9, 5, 0, 3, 1, 2, 6, 4]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.3872134685516357 0.003770112991333008
train_time 1.3923931121826172
2023-09-06 13:31:15,339 MainThread INFO: EPOCH:6
2023-09-06 13:31:15,340 MainThread INFO: Time Consumed:1.4068584442138672s
2023-09-06 13:31:15,340 MainThread INFO: Total Frames:10500s
  2%|‚ñè         | 7/400 [00:13<10:57,  1.67s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1065.54671
Train_Epoch_Reward                    10682.66303
Running_Training_Average_Rewards      1282.58092
Explore_Time                          0.00551
Train___Time                          1.39239
Eval____Time                          0.00423
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.72032
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.37122
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.63009
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34524
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43450
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22138
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.76270
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11166.57658
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.40151
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.99555
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.90067      0.56698    10.76185    9.10585
alpha_0                               0.98051      0.00085    0.98184     0.97919
alpha_1                               0.98052      0.00085    0.98184     0.97919
alpha_2                               0.98053      0.00085    0.98186     0.97921
alpha_3                               0.98054      0.00085    0.98187     0.97921
alpha_4                               0.98054      0.00085    0.98186     0.97922
alpha_5                               0.98053      0.00085    0.98186     0.97921
alpha_6                               0.98052      0.00085    0.98184     0.97919
alpha_7                               0.98052      0.00085    0.98185     0.97920
alpha_8                               0.98053      0.00085    0.98185     0.97921
alpha_9                               0.98052      0.00085    0.98185     0.97920
Alpha_loss                            -0.13006     0.00587    -0.12087    -0.13946
Training/policy_loss                  -2.72565     0.00849    -2.71249    -2.74460
Training/qf1_loss                     1566.99648   273.27695  2010.87268  1177.91980
Training/qf2_loss                     1567.26904   273.29075  2011.14673  1178.16504
Training/pf_norm                      0.27624      0.03807    0.31715     0.18404
Training/qf1_norm                     31.12119     1.38441    33.33258    29.02060
Training/qf2_norm                     29.73038     1.26759    31.49472    27.86430
log_std/mean                          -0.06026     0.00374    -0.05444    -0.06615
log_std/std                           0.00794      0.00046    0.00868     0.00725
log_std/max                           -0.04623     0.00314    -0.04133    -0.05116
log_std/min                           -0.07707     0.00468    -0.06987    -0.08449
log_probs/mean                        -2.71586     0.00750    -2.70420    -2.73168
log_probs/std                         0.31988      0.00706    0.33230     0.30757
log_probs/max                         -1.72696     0.05934    -1.60358    -1.81350
log_probs/min                         -4.41003     0.31416    -4.02329    -4.96088
mean/mean                             0.00107      0.00033    0.00157     0.00049
mean/std                              0.00350      0.00026    0.00391     0.00318
mean/max                              0.00799      0.00084    0.00923     0.00681
mean/min                              -0.00754     0.00107    -0.00621    -0.00922
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 2, 4, 7, 5, 6, 9, 3, 1, 8]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6063904762268066 0.0024194717407226562
train_time 1.6102094650268555
snapshot at best
2023-09-06 13:31:17,780 MainThread INFO: EPOCH:7
2023-09-06 13:31:17,780 MainThread INFO: Time Consumed:2.1971402168273926s
2023-09-06 13:31:17,781 MainThread INFO: Total Frames:12000s
  2%|‚ñè         | 8/400 [00:16<12:16,  1.88s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1095.05365
Train_Epoch_Reward                    13493.43089
Running_Training_Average_Rewards      1251.83664
Explore_Time                          0.02206
Train___Time                          1.61021
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.92657
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.05554
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.06748
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04445
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.56210
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.37960
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.83403
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11578.82526
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.12352
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.60004
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.76333      0.66472    10.98654    8.63941
alpha_0                               0.97757      0.00084    0.97890     0.97625
alpha_1                               0.97757      0.00084    0.97889     0.97625
alpha_2                               0.97759      0.00084    0.97891     0.97627
alpha_3                               0.97759      0.00085    0.97892     0.97627
alpha_4                               0.97760      0.00084    0.97892     0.97628
alpha_5                               0.97759      0.00084    0.97891     0.97626
alpha_6                               0.97757      0.00084    0.97890     0.97625
alpha_7                               0.97758      0.00084    0.97890     0.97626
alpha_8                               0.97759      0.00084    0.97891     0.97627
alpha_9                               0.97758      0.00084    0.97890     0.97626
Alpha_loss                            -0.15036     0.00586    -0.14115    -0.15941
Training/policy_loss                  -2.73917     0.00877    -2.72334    -2.75316
Training/qf1_loss                     1587.21322   347.14234  2364.31323  1109.16895
Training/qf2_loss                     1587.51515   347.16249  2364.64697  1109.42859
Training/pf_norm                      0.25910      0.03403    0.30479     0.19147
Training/qf1_norm                     31.56445     1.75461    34.76543    28.54793
Training/qf2_norm                     30.20085     1.66296    33.31712    27.44980
log_std/mean                          -0.07339     0.00385    -0.06739    -0.07946
log_std/std                           0.00949      0.00042    0.01013     0.00881
log_std/max                           -0.05713     0.00323    -0.05211    -0.06233
log_std/min                           -0.09346     0.00472    -0.08615    -0.10097
log_probs/mean                        -2.72122     0.00760    -2.70568    -2.73295
log_probs/std                         0.29729      0.00780    0.30698     0.28584
log_probs/max                         -1.79042     0.08386    -1.61096    -1.89704
log_probs/min                         -4.28738     0.34800    -3.77460    -5.04819
mean/mean                             0.00137      0.00017    0.00158     0.00103
mean/std                              0.00458      0.00033    0.00499     0.00402
mean/max                              0.00992      0.00028    0.01023     0.00937
mean/min                              -0.01179     0.00142    -0.00963    -0.01398
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 1, 3, 0, 8, 2, 5, 4, 7, 9]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1458146572113037 0.0022993087768554688
train_time 1.1494479179382324
snapshot at best
2023-09-06 13:31:19,798 MainThread INFO: EPOCH:8
2023-09-06 13:31:19,799 MainThread INFO: Time Consumed:1.8791780471801758s
2023-09-06 13:31:19,799 MainThread INFO: Total Frames:13500s
  2%|‚ñè         | 9/400 [00:18<12:31,  1.92s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1136.84560
Train_Epoch_Reward                    4694.80994
Running_Training_Average_Rewards      962.36346
Explore_Time                          0.01170
Train___Time                          1.14945
Eval____Time                          0.00319
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.15638
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.01493
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47487
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.86591
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.75562
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.57330
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.00787
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12113.32339
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00454
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.02802
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.50651      0.63476    10.64011    8.61516
alpha_0                               0.97464      0.00084    0.97596     0.97332
alpha_1                               0.97463      0.00084    0.97595     0.97332
alpha_2                               0.97466      0.00084    0.97597     0.97334
alpha_3                               0.97465      0.00084    0.97598     0.97333
alpha_4                               0.97467      0.00084    0.97599     0.97335
alpha_5                               0.97465      0.00084    0.97597     0.97333
alpha_6                               0.97464      0.00084    0.97596     0.97332
alpha_7                               0.97465      0.00084    0.97596     0.97333
alpha_8                               0.97465      0.00084    0.97597     0.97333
alpha_9                               0.97465      0.00084    0.97597     0.97333
Alpha_loss                            -0.17070     0.00584    -0.16163    -0.17977
Training/policy_loss                  -2.75481     0.00725    -2.74382    -2.76617
Training/qf1_loss                     1596.06759   328.76828  2256.34766  1124.89758
Training/qf2_loss                     1596.43907   328.78924  2256.76489  1125.22009
Training/pf_norm                      0.21686      0.03284    0.28334     0.17221
Training/qf1_norm                     32.29208     1.75578    35.44641    29.69733
Training/qf2_norm                     30.59782     1.60272    33.47808    28.28421
log_std/mean                          -0.08714     0.00399    -0.08087    -0.09337
log_std/std                           0.01101      0.00043    0.01161     0.01031
log_std/max                           -0.06894     0.00339    -0.06357    -0.07421
log_std/min                           -0.11039     0.00500    -0.10258    -0.11805
log_probs/mean                        -2.72629     0.00568    -2.71836    -2.73484
log_probs/std                         0.28192      0.00946    0.30518     0.26736
log_probs/max                         -1.89191     0.04868    -1.79266    -1.97098
log_probs/min                         -4.89920     0.67934    -4.02204    -6.43809
mean/mean                             0.00091      0.00012    0.00119     0.00078
mean/std                              0.00502      0.00007    0.00514     0.00489
mean/max                              0.00871      0.00047    0.00958     0.00792
mean/min                              -0.01519     0.00049    -0.01433    -0.01569
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 2, 6, 9, 5, 8, 7, 3, 0, 4]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1839430332183838 0.0024559497833251953
train_time 1.1877331733703613
snapshot at best
2023-09-06 13:31:21,667 MainThread INFO: EPOCH:9
2023-09-06 13:31:21,668 MainThread INFO: Time Consumed:1.754608392715454s
2023-09-06 13:31:21,668 MainThread INFO: Total Frames:15000s
  2%|‚ñé         | 10/400 [00:20<12:23,  1.91s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1171.53825
Train_Epoch_Reward                    8268.23416
Running_Training_Average_Rewards      881.88250
Explore_Time                          0.00886
Train___Time                          1.18773
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.86692
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.32878
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40214
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.98176
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.71565
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.48192
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98291
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12211.33286
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.23253
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.86658
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.11065      0.70693    10.39975    7.77974
alpha_0                               0.97171      0.00084    0.97302     0.97039
alpha_1                               0.97171      0.00084    0.97302     0.97039
alpha_2                               0.97173      0.00084    0.97304     0.97041
alpha_3                               0.97172      0.00084    0.97304     0.97041
alpha_4                               0.97175      0.00084    0.97306     0.97043
alpha_5                               0.97173      0.00084    0.97304     0.97041
alpha_6                               0.97171      0.00084    0.97303     0.97039
alpha_7                               0.97172      0.00084    0.97303     0.97040
alpha_8                               0.97172      0.00084    0.97304     0.97041
alpha_9                               0.97172      0.00084    0.97304     0.97040
Alpha_loss                            -0.19105     0.00588    -0.18195    -0.20019
Training/policy_loss                  -2.77268     0.01010    -2.75975    -2.78989
Training/qf1_loss                     1385.25751   269.99063  1778.34119  778.42737
Training/qf2_loss                     1385.68845   270.00911  1778.78711  778.83575
Training/pf_norm                      0.16519      0.04258    0.24608     0.11381
Training/qf1_norm                     32.60370     2.00729    35.69051    29.17063
Training/qf2_norm                     30.62137     1.90776    33.68998    27.14147
log_std/mean                          -0.10041     0.00357    -0.09470    -0.10591
log_std/std                           0.01226      0.00032    0.01274     0.01176
log_std/max                           -0.08039     0.00311    -0.07531    -0.08526
log_std/min                           -0.12729     0.00461    -0.12025    -0.13440
log_probs/mean                        -2.73051     0.00829    -2.71843    -2.74763
log_probs/std                         0.26580      0.01214    0.28449     0.24635
log_probs/max                         -1.96814     0.05149    -1.89565    -2.07670
log_probs/min                         -4.95781     0.55659    -3.99271    -5.98296
mean/mean                             0.00155      0.00007    0.00161     0.00138
mean/std                              0.00484      0.00017    0.00508     0.00453
mean/max                              0.00998      0.00015    0.01015     0.00975
mean/min                              -0.01364     0.00087    -0.01224    -0.01501
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 8, 2, 3, 4, 1, 9, 5, 0, 7]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1562886238098145 0.0026237964630126953
train_time 1.160226583480835
snapshot at best
2023-09-06 13:31:23,912 MainThread INFO: EPOCH:10
2023-09-06 13:31:23,913 MainThread INFO: Time Consumed:2.0640816688537598s
2023-09-06 13:31:23,913 MainThread INFO: Total Frames:16500s
  3%|‚ñé         | 11/400 [00:22<13:00,  2.01s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1206.51270
Train_Epoch_Reward                    8828.65460
Running_Training_Average_Rewards      726.38996
Explore_Time                          0.00533
Train___Time                          1.16023
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.11855
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.19026
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56849
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.72131
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.48090
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20022
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.77094
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12630.13259
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.10658
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.51000
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.55178      0.49477    10.27032    8.78778
alpha_0                               0.96879      0.00084    0.97010     0.96747
alpha_1                               0.96879      0.00084    0.97010     0.96748
alpha_2                               0.96881      0.00084    0.97012     0.96750
alpha_3                               0.96880      0.00084    0.97011     0.96749
alpha_4                               0.96883      0.00084    0.97014     0.96752
alpha_5                               0.96881      0.00084    0.97012     0.96750
alpha_6                               0.96879      0.00084    0.97010     0.96748
alpha_7                               0.96880      0.00084    0.97011     0.96749
alpha_8                               0.96880      0.00084    0.97012     0.96749
alpha_9                               0.96880      0.00084    0.97011     0.96749
Alpha_loss                            -0.21127     0.00580    -0.20216    -0.22046
Training/policy_loss                  -2.78880     0.00650    -2.78090    -2.79989
Training/qf1_loss                     1469.35858   226.38242  1832.75610  1125.75793
Training/qf2_loss                     1469.85077   226.38589  1833.19177  1126.25977
Training/pf_norm                      0.14816      0.02822    0.19727     0.10591
Training/qf1_norm                     35.41083     1.34040    37.33767    33.50786
Training/qf2_norm                     33.11750     1.27888    34.92502    31.09527
log_std/mean                          -0.11201     0.00308    -0.10717    -0.11685
log_std/std                           0.01323      0.00022    0.01353     0.01285
log_std/max                           -0.09025     0.00299    -0.08571    -0.09541
log_std/min                           -0.14133     0.00362    -0.13585    -0.14690
log_probs/mean                        -2.72962     0.00456    -2.72118    -2.74037
log_probs/std                         0.24590      0.01263    0.27740     0.22814
log_probs/max                         -2.02914     0.04392    -1.96923    -2.11254
log_probs/min                         -4.60774     0.51050    -4.07460    -5.69331
mean/mean                             0.00105      0.00031    0.00138     0.00048
mean/std                              0.00428      0.00008    0.00448     0.00419
mean/max                              0.01035      0.00014    0.01061     0.01016
mean/min                              -0.01154     0.00030    -0.01124    -0.01210
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 5, 1, 2, 4, 7, 9, 8, 6, 0]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1958060264587402 0.002546072006225586
train_time 1.19966459274292
2023-09-06 13:31:25,231 MainThread INFO: EPOCH:11
2023-09-06 13:31:25,232 MainThread INFO: Time Consumed:1.213132381439209s
2023-09-06 13:31:25,232 MainThread INFO: Total Frames:18000s
  3%|‚ñé         | 12/400 [00:23<11:37,  1.80s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1224.07059
Train_Epoch_Reward                    11272.68804
Running_Training_Average_Rewards      945.65256
Explore_Time                          0.00496
Train___Time                          1.19966
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.28556
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02995
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.51058
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.58411
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19607
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92068
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.46224
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12637.72898
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.94574
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.61545
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.36089      0.48955    10.18733    8.46791
alpha_0                               0.96587      0.00084    0.96718     0.96456
alpha_1                               0.96588      0.00083    0.96719     0.96457
alpha_2                               0.96590      0.00083    0.96721     0.96460
alpha_3                               0.96589      0.00083    0.96720     0.96458
alpha_4                               0.96592      0.00083    0.96723     0.96461
alpha_5                               0.96590      0.00083    0.96721     0.96460
alpha_6                               0.96588      0.00083    0.96719     0.96457
alpha_7                               0.96589      0.00083    0.96720     0.96458
alpha_8                               0.96589      0.00083    0.96720     0.96459
alpha_9                               0.96589      0.00083    0.96720     0.96458
Alpha_loss                            -0.23151     0.00579    -0.22242    -0.24025
Training/policy_loss                  -2.80928     0.00781    -2.79995    -2.82384
Training/qf1_loss                     1425.60211   168.04252  1705.03540  1141.89551
Training/qf2_loss                     1426.12968   168.05445  1705.60144  1142.41467
Training/pf_norm                      0.12604      0.02127    0.16671     0.09383
Training/qf1_norm                     36.62520     1.50718    39.42739    34.16631
Training/qf2_norm                     34.18544     1.43332    36.80541    31.99232
log_std/mean                          -0.12155     0.00220    -0.11779    -0.12472
log_std/std                           0.01372      0.00006    0.01382     0.01360
log_std/max                           -0.09891     0.00159    -0.09604    -0.10094
log_std/min                           -0.15077     0.00188    -0.14718    -0.15355
log_probs/mean                        -2.72935     0.00571    -2.71918    -2.73604
log_probs/std                         0.23526      0.01507    0.25759     0.20444
log_probs/max                         -2.05203     0.05178    -1.96319    -2.14443
log_probs/min                         -4.68134     0.77371    -3.84984    -6.43619
mean/mean                             -0.00033     0.00036    0.00032     -0.00072
mean/std                              0.00461      0.00025    0.00504     0.00426
mean/max                              0.01179      0.00068    0.01281     0.01063
mean/min                              -0.01275     0.00013    -0.01250    -0.01293
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 6, 4, 8, 9, 2, 0, 5, 3, 7]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6625335216522217 0.0022351741790771484
train_time 1.666100025177002
2023-09-06 13:31:27,062 MainThread INFO: EPOCH:12
2023-09-06 13:31:27,063 MainThread INFO: Time Consumed:1.6854307651519775s
2023-09-06 13:31:27,063 MainThread INFO: Total Frames:19500s
  3%|‚ñé         | 13/400 [00:25<11:39,  1.81s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1221.19899
Train_Epoch_Reward                    22162.02386
Running_Training_Average_Rewards      1408.77888
Explore_Time                          0.01059
Train___Time                          1.66610
Eval____Time                          0.00307
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.06027
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.29286
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.18612
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.87217
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.08337
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.71416
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.36765
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12118.00780
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.07676
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.02878
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.72290      0.67575    10.22424    7.83813
alpha_0                               0.96297      0.00083    0.96427     0.96166
alpha_1                               0.96298      0.00083    0.96428     0.96167
alpha_2                               0.96300      0.00083    0.96431     0.96170
alpha_3                               0.96299      0.00083    0.96429     0.96169
alpha_4                               0.96301      0.00083    0.96432     0.96171
alpha_5                               0.96300      0.00083    0.96431     0.96170
alpha_6                               0.96298      0.00083    0.96428     0.96167
alpha_7                               0.96299      0.00083    0.96429     0.96169
alpha_8                               0.96300      0.00083    0.96430     0.96169
alpha_9                               0.96299      0.00083    0.96429     0.96168
Alpha_loss                            -0.25202     0.00576    -0.24310    -0.26106
Training/policy_loss                  -2.84145     0.00777    -2.82933    -2.85522
Training/qf1_loss                     1262.69796   231.14334  1711.84375  978.67236
Training/qf2_loss                     1263.22117   231.17296  1712.45984  979.25745
Training/pf_norm                      0.11912      0.02164    0.17515     0.09264
Training/qf1_norm                     36.44919     2.25850    40.85140    33.73802
Training/qf2_norm                     33.94782     2.07418    38.00592    31.21370
log_std/mean                          -0.12736     0.00122    -0.12530    -0.12913
log_std/std                           0.01360      0.00012    0.01376     0.01339
log_std/max                           -0.10338     0.00089    -0.10165    -0.10474
log_std/min                           -0.15536     0.00077    -0.15425    -0.15667
log_probs/mean                        -2.73665     0.00550    -2.72757    -2.74485
log_probs/std                         0.23824      0.00641    0.25019     0.23048
log_probs/max                         -2.11450     0.05084    -2.03268    -2.18965
log_probs/min                         -4.71396     0.34635    -4.13934    -5.19938
mean/mean                             -0.00039     0.00011    -0.00021    -0.00053
mean/std                              0.00625      0.00083    0.00761     0.00519
mean/max                              0.01450      0.00092    0.01610     0.01315
mean/min                              -0.01303     0.00109    -0.01163    -0.01498
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 8, 6, 9, 2, 7, 1, 0, 4, 3]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.815399408340454 0.002122163772583008
train_time 1.8188276290893555
2023-09-06 13:31:29,082 MainThread INFO: EPOCH:13
2023-09-06 13:31:29,083 MainThread INFO: Time Consumed:1.8426270484924316s
2023-09-06 13:31:29,083 MainThread INFO: Total Frames:21000s
  4%|‚ñé         | 14/400 [00:27<12:01,  1.87s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1180.86915
Train_Epoch_Reward                    6059.85646
Running_Training_Average_Rewards      1316.48561
Explore_Time                          0.00667
Train___Time                          1.81883
Eval____Time                          0.00644
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.55808
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.60989
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.77341
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.22857
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.11365
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.64583
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.52141
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11427.92189
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.27771
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.62300
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.48443      0.48291    9.14852     7.80639
alpha_0                               0.96007      0.00083    0.96137     0.95877
alpha_1                               0.96008      0.00083    0.96139     0.95878
alpha_2                               0.96011      0.00083    0.96141     0.95881
alpha_3                               0.96010      0.00083    0.96140     0.95880
alpha_4                               0.96012      0.00083    0.96142     0.95882
alpha_5                               0.96011      0.00083    0.96141     0.95881
alpha_6                               0.96008      0.00083    0.96139     0.95879
alpha_7                               0.96010      0.00083    0.96140     0.95880
alpha_8                               0.96010      0.00083    0.96140     0.95881
alpha_9                               0.96009      0.00083    0.96139     0.95879
Alpha_loss                            -0.27231     0.00590    -0.26352    -0.28198
Training/policy_loss                  -2.87154     0.01463    -2.85273    -2.89957
Training/qf1_loss                     1193.53641   158.24119  1419.21094  892.74658
Training/qf2_loss                     1194.05195   158.25569  1419.72522  893.23285
Training/pf_norm                      0.13289      0.02389    0.17544     0.10566
Training/qf1_norm                     37.55665     1.88414    40.41894    34.48690
Training/qf2_norm                     34.95971     1.74116    37.96022    32.34262
log_std/mean                          -0.13069     0.00069    -0.12949    -0.13168
log_std/std                           0.01314      0.00017    0.01338     0.01292
log_std/max                           -0.10562     0.00064    -0.10457    -0.10678
log_std/min                           -0.15703     0.00039    -0.15639    -0.15760
log_probs/mean                        -2.73706     0.00992    -2.72204    -2.75019
log_probs/std                         0.24042      0.01146    0.25335     0.21735
log_probs/max                         -2.10858     0.05545    -2.02933    -2.18790
log_probs/min                         -5.01674     0.46622    -4.29161    -5.95878
mean/mean                             -0.00057     0.00015    -0.00027    -0.00072
mean/std                              0.00840      0.00022    0.00862     0.00787
mean/max                              0.01774      0.00069    0.01870     0.01653
mean/min                              -0.01618     0.00090    -0.01444    -0.01719
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 7, 3, 6, 2, 5, 9, 0, 8, 1]
replay_buffer._size: [2406 2408 2416 2409 2409 2409 2408 2423 2407 2407]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.992924451828003 0.0024182796478271484
train_time 1.9967420101165771
2023-09-06 13:31:31,310 MainThread INFO: EPOCH:14
2023-09-06 13:31:31,311 MainThread INFO: Time Consumed:2.1229071617126465s
2023-09-06 13:31:31,311 MainThread INFO: Total Frames:22500s
  4%|‚ñç         | 15/400 [00:29<12:44,  1.99s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1112.75531
Train_Epoch_Reward                    4493.64724
Running_Training_Average_Rewards      1090.51759
Explore_Time                          0.11710
Train___Time                          1.99674
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.63750
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.75019
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.26375
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.48868
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.86712
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.41881
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.41756
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10591.28445
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.40764
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.27002
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.45606      0.67390    9.51522     7.55875
alpha_0                               0.95719      0.00083    0.95848     0.95589
alpha_1                               0.95720      0.00083    0.95850     0.95590
alpha_2                               0.95722      0.00083    0.95852     0.95593
alpha_3                               0.95722      0.00083    0.95851     0.95592
alpha_4                               0.95724      0.00083    0.95853     0.95594
alpha_5                               0.95723      0.00083    0.95852     0.95593
alpha_6                               0.95720      0.00083    0.95850     0.95591
alpha_7                               0.95721      0.00083    0.95851     0.95592
alpha_8                               0.95722      0.00083    0.95852     0.95593
alpha_9                               0.95721      0.00083    0.95850     0.95591
Alpha_loss                            -0.29238     0.00573    -0.28386    -0.30143
Training/policy_loss                  -2.90197     0.01034    -2.89021    -2.92051
Training/qf1_loss                     1207.08015   287.12883  1569.06702  811.45038
Training/qf2_loss                     1207.61295   287.16844  1569.50867  811.89606
Training/pf_norm                      0.13281      0.03407    0.19093     0.08043
Training/qf1_norm                     39.80786     2.21659    43.39763    36.86503
Training/qf2_norm                     36.96695     2.01019    39.83368    33.96732
log_std/mean                          -0.13149     0.00011    -0.13132    -0.13171
log_std/std                           0.01243      0.00020    0.01281     0.01213
log_std/max                           -0.10684     0.00060    -0.10585    -0.10766
log_std/min                           -0.15863     0.00075    -0.15742    -0.15968
log_probs/mean                        -2.73260     0.00564    -2.72610    -2.74655
log_probs/std                         0.23618      0.01157    0.25781     0.21282
log_probs/max                         -2.12514     0.04443    -2.03960    -2.20087
log_probs/min                         -4.92319     0.50840    -4.18995    -6.01148
mean/mean                             -0.00028     0.00004    -0.00022    -0.00036
mean/std                              0.00747      0.00046    0.00827     0.00676
mean/max                              0.01646      0.00135    0.01871     0.01450
mean/min                              -0.01235     0.00059    -0.01166    -0.01375
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 5, 9, 6, 4, 0, 3, 2, 8, 1]
replay_buffer._size: [2555 2550 2550 2551 2555 2550 2550 2550 2550 2552]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.920013666152954 0.005088090896606445
train_time 1.9282176494598389
2023-09-06 13:31:33,422 MainThread INFO: EPOCH:15
2023-09-06 13:31:33,423 MainThread INFO: Time Consumed:1.9786977767944336s
2023-09-06 13:31:33,424 MainThread INFO: Total Frames:24000s
  4%|‚ñç         | 16/400 [00:31<12:56,  2.02s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1069.35872
Train_Epoch_Reward                    14313.50685
Running_Training_Average_Rewards      828.90035
Explore_Time                          0.03714
Train___Time                          1.92822
Eval____Time                          0.00637
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.64588
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.75116
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.25212
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.24093
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.59990
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.16158
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.08042
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10820.46550
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.31612
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.98940
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.57445      0.44684    9.24245     7.77371
alpha_0                               0.95431      0.00082    0.95560     0.95302
alpha_1                               0.95432      0.00082    0.95562     0.95303
alpha_2                               0.95435      0.00082    0.95564     0.95306
alpha_3                               0.95434      0.00082    0.95564     0.95305
alpha_4                               0.95436      0.00082    0.95565     0.95307
alpha_5                               0.95435      0.00082    0.95564     0.95306
alpha_6                               0.95433      0.00082    0.95562     0.95304
alpha_7                               0.95434      0.00082    0.95563     0.95305
alpha_8                               0.95435      0.00082    0.95564     0.95306
alpha_9                               0.95433      0.00082    0.95562     0.95304
Alpha_loss                            -0.31267     0.00577    -0.30378    -0.32186
Training/policy_loss                  -2.94347     0.01214    -2.92458    -2.96527
Training/qf1_loss                     1266.23318   201.54796  1583.42383  940.16467
Training/qf2_loss                     1266.73890   201.57809  1583.89319  940.52960
Training/pf_norm                      0.12085      0.02384    0.15171     0.07226
Training/qf1_norm                     42.77564     1.76021    45.66257    39.78744
Training/qf2_norm                     39.86862     1.53159    42.46330    37.45984
log_std/mean                          -0.13160     0.00004    -0.13152    -0.13167
log_std/std                           0.01171      0.00025    0.01209     0.01129
log_std/max                           -0.10880     0.00080    -0.10734    -0.11003
log_std/min                           -0.15925     0.00041    -0.15874    -0.15979
log_probs/mean                        -2.73339     0.00399    -2.72659    -2.74073
log_probs/std                         0.24501      0.01353    0.27384     0.21824
log_probs/max                         -2.10012     0.03985    -2.05079    -2.18288
log_probs/min                         -5.34641     0.85456    -4.14759    -7.49250
mean/mean                             0.00051      0.00055    0.00147     -0.00016
mean/std                              0.00556      0.00046    0.00648     0.00514
mean/max                              0.01147      0.00113    0.01364     0.01000
mean/min                              -0.01136     0.00042    -0.01087    -0.01206
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 3, 9, 8, 1, 7, 5, 6, 2, 0]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2701 2700 2700 2700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.1455583572387695 0.0024247169494628906
train_time 2.1493515968322754
2023-09-06 13:31:35,762 MainThread INFO: EPOCH:16
2023-09-06 13:31:35,762 MainThread INFO: Time Consumed:2.179826498031616s
2023-09-06 13:31:35,763 MainThread INFO: Total Frames:25500s
  4%|‚ñç         | 17/400 [00:34<13:28,  2.11s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1070.34391
Train_Epoch_Reward                    4609.59127
Running_Training_Average_Rewards      780.55818
Explore_Time                          0.02022
Train___Time                          2.14935
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.43146
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.32529
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.70394
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.72069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.39359
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.98720
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.85064
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11445.88860
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.91539
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.43428
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.06769      0.32614    8.75055     7.50227
alpha_0                               0.95144      0.00082    0.95273     0.95016
alpha_1                               0.95146      0.00082    0.95275     0.95017
alpha_2                               0.95149      0.00082    0.95277     0.95020
alpha_3                               0.95148      0.00082    0.95277     0.95019
alpha_4                               0.95150      0.00082    0.95278     0.95021
alpha_5                               0.95149      0.00082    0.95277     0.95020
alpha_6                               0.95147      0.00082    0.95275     0.95018
alpha_7                               0.95148      0.00082    0.95276     0.95019
alpha_8                               0.95148      0.00082    0.95277     0.95020
alpha_9                               0.95147      0.00082    0.95275     0.95018
Alpha_loss                            -0.33301     0.00584    -0.32378    -0.34205
Training/policy_loss                  -2.99142     0.01542    -2.96667    -3.01484
Training/qf1_loss                     1096.55232   142.70808  1386.59009  920.52972
Training/qf2_loss                     1096.97908   142.72524  1387.01428  920.97296
Training/pf_norm                      0.13594      0.03675    0.19426     0.08620
Training/qf1_norm                     43.09807     1.18912    45.24409    41.31686
Training/qf2_norm                     40.27890     1.15579    42.47721    38.40503
log_std/mean                          -0.13137     0.00012    -0.13118    -0.13163
log_std/std                           0.01092      0.00020    0.01123     0.01058
log_std/max                           -0.11073     0.00066    -0.10941    -0.11189
log_std/min                           -0.15753     0.00073    -0.15631    -0.15882
log_probs/mean                        -2.73521     0.00461    -2.72662    -2.74179
log_probs/std                         0.23817      0.02198    0.30250     0.22411
log_probs/max                         -2.14572     0.03297    -2.06751    -2.17996
log_probs/min                         -5.15934     1.42066    -4.07648    -9.24189
mean/mean                             0.00143      0.00030    0.00183     0.00095
mean/std                              0.00545      0.00008    0.00555     0.00530
mean/max                              0.01378      0.00037    0.01419     0.01292
mean/min                              -0.01240     0.00115    -0.01072    -0.01383
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 9, 1, 5, 6, 8, 0, 2, 4, 3]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.749983310699463 0.0022401809692382812
train_time 1.7535877227783203
2023-09-06 13:31:37,708 MainThread INFO: EPOCH:17
2023-09-06 13:31:37,709 MainThread INFO: Time Consumed:1.7667834758758545s
2023-09-06 13:31:37,709 MainThread INFO: Total Frames:27000s
  4%|‚ñç         | 18/400 [00:36<13:07,  2.06s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1131.04752
Train_Epoch_Reward                    14313.11312
Running_Training_Average_Rewards      1107.87371
Explore_Time                          0.00464
Train___Time                          1.75359
Eval____Time                          0.00332
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.33087
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.76113
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.49329
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.07932
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.63860
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.26408
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.26043
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12399.76988
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.32441
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.74611
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.20397      0.66103    9.11880     6.93514
alpha_0                               0.94859      0.00082    0.94987     0.94730
alpha_1                               0.94860      0.00082    0.94989     0.94732
alpha_2                               0.94863      0.00082    0.94992     0.94735
alpha_3                               0.94862      0.00082    0.94990     0.94734
alpha_4                               0.94864      0.00082    0.94992     0.94735
alpha_5                               0.94863      0.00082    0.94991     0.94735
alpha_6                               0.94861      0.00082    0.94989     0.94732
alpha_7                               0.94862      0.00082    0.94990     0.94734
alpha_8                               0.94863      0.00082    0.94991     0.94734
alpha_9                               0.94861      0.00082    0.94989     0.94732
Alpha_loss                            -0.35329     0.00600    -0.34351    -0.36270
Training/policy_loss                  -3.04457     0.02003    -3.00647    -3.07518
Training/qf1_loss                     1187.07095   199.55817  1389.49438  817.82983
Training/qf2_loss                     1187.52642   199.50530  1389.87988  818.40198
Training/pf_norm                      0.11240      0.02061    0.14945     0.08631
Training/qf1_norm                     46.90233     3.02616    50.82216    41.24910
Training/qf2_norm                     43.58794     3.23061    47.65967    37.75701
log_std/mean                          -0.13132     0.00026    -0.13104    -0.13179
log_std/std                           0.01015      0.00018    0.01045     0.00986
log_std/max                           -0.11240     0.00053    -0.11149    -0.11312
log_std/min                           -0.15529     0.00052    -0.15443    -0.15611
log_probs/mean                        -2.73585     0.00678    -2.72273    -2.74376
log_probs/std                         0.24821      0.02444    0.30226     0.21839
log_probs/max                         -2.15715     0.03755    -2.06127    -2.19622
log_probs/min                         -5.38247     0.91011    -4.16719    -7.43628
mean/mean                             0.00086      0.00005    0.00095     0.00077
mean/std                              0.00570      0.00013    0.00594     0.00555
mean/max                              0.01285      0.00023    0.01332     0.01259
mean/min                              -0.01306     0.00032    -0.01270    -0.01367
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 3, 2, 8, 7, 5, 1, 4, 9, 0]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7885701656341553 0.0025098323822021484
train_time 1.7926990985870361
2023-09-06 13:31:39,707 MainThread INFO: EPOCH:18
2023-09-06 13:31:39,707 MainThread INFO: Time Consumed:1.8416593074798584s
2023-09-06 13:31:39,708 MainThread INFO: Total Frames:28500s
  5%|‚ñç         | 19/400 [00:38<13:06,  2.07s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1188.85597
Train_Epoch_Reward                    1298.32046
Running_Training_Average_Rewards      674.03416
Explore_Time                          0.04040
Train___Time                          1.79270
Eval____Time                          0.00358
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.53658
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.86103
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.52629
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.91220
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.65017
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.17178
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.48346
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12551.68605
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.46965
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.39345
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.12927      0.38180    8.62608     7.59164
alpha_0                               0.94574      0.00082    0.94702     0.94446
alpha_1                               0.94576      0.00082    0.94704     0.94448
alpha_2                               0.94579      0.00082    0.94707     0.94451
alpha_3                               0.94577      0.00082    0.94705     0.94449
alpha_4                               0.94579      0.00082    0.94707     0.94451
alpha_5                               0.94579      0.00082    0.94707     0.94451
alpha_6                               0.94576      0.00082    0.94704     0.94448
alpha_7                               0.94577      0.00082    0.94705     0.94450
alpha_8                               0.94578      0.00082    0.94706     0.94450
alpha_9                               0.94576      0.00082    0.94704     0.94448
Alpha_loss                            -0.37343     0.00581    -0.36457    -0.38258
Training/policy_loss                  -3.10142     0.01910    -3.07166    -3.13006
Training/qf1_loss                     1167.76114   202.17140  1486.61792  866.73547
Training/qf2_loss                     1168.03959   202.17385  1486.90686  866.92053
Training/pf_norm                      0.12898      0.02302    0.16210     0.08191
Training/qf1_norm                     49.00973     2.35198    53.40028    45.75598
Training/qf2_norm                     46.12817     2.40368    50.86803    42.55919
log_std/mean                          -0.13200     0.00004    -0.13195    -0.13208
log_std/std                           0.00940      0.00029    0.00988     0.00904
log_std/max                           -0.11317     0.00038    -0.11238    -0.11379
log_std/min                           -0.15275     0.00065    -0.15197    -0.15394
log_probs/mean                        -2.73375     0.00731    -2.72007    -2.74174
log_probs/std                         0.24319      0.01580    0.27240     0.22180
log_probs/max                         -2.13281     0.04803    -2.05076    -2.20053
log_probs/min                         -5.18494     0.76615    -4.16903    -6.42466
mean/mean                             0.00013      0.00063    0.00088     -0.00090
mean/std                              0.00625      0.00012    0.00640     0.00603
mean/max                              0.01223      0.00056    0.01295     0.01122
mean/min                              -0.01654     0.00186    -0.01413    -0.01978
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 3, 7, 8, 0, 9, 2, 6, 4, 5]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.9201452732086182 0.0022153854370117188
train_time 1.9237289428710938
2023-09-06 13:31:41,870 MainThread INFO: EPOCH:19
2023-09-06 13:31:41,870 MainThread INFO: Time Consumed:1.9369933605194092s
2023-09-06 13:31:41,870 MainThread INFO: Total Frames:30000s
  5%|‚ñå         | 20/400 [00:40<13:07,  2.07s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1227.26606
Train_Epoch_Reward                    9437.79854
Running_Training_Average_Rewards      834.97440
Explore_Time                          0.00471
Train___Time                          1.92373
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.65624
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.84957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46332
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.80776
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.57511
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.00129
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.64571
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12604.08217
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.45710
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.19723
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.83033      0.53449    8.59203     6.99886
alpha_0                               0.94290      0.00081    0.94417     0.94162
alpha_1                               0.94292      0.00081    0.94419     0.94164
alpha_2                               0.94295      0.00081    0.94423     0.94168
alpha_3                               0.94293      0.00081    0.94421     0.94166
alpha_4                               0.94295      0.00081    0.94422     0.94167
alpha_5                               0.94295      0.00081    0.94422     0.94168
alpha_6                               0.94292      0.00081    0.94420     0.94165
alpha_7                               0.94294      0.00081    0.94421     0.94166
alpha_8                               0.94294      0.00081    0.94422     0.94167
alpha_9                               0.94292      0.00081    0.94419     0.94164
Alpha_loss                            -0.39356     0.00594    -0.38440    -0.40298
Training/policy_loss                  -3.16487     0.02218    -3.13214    -3.20218
Training/qf1_loss                     987.79280    173.44085  1252.86609  751.50958
Training/qf2_loss                     988.01824    173.44308  1253.02771  751.74109
Training/pf_norm                      0.13330      0.02135    0.16718     0.10218
Training/qf1_norm                     50.36041     2.68168    54.07232    46.04650
Training/qf2_norm                     47.32005     2.68994    50.51355    43.19635
log_std/mean                          -0.13197     0.00018    -0.13167    -0.13219
log_std/std                           0.00851      0.00025    0.00886     0.00811
log_std/max                           -0.11352     0.00050    -0.11258    -0.11439
log_std/min                           -0.15129     0.00067    -0.15022    -0.15209
log_probs/mean                        -2.73192     0.00668    -2.72328    -2.74835
log_probs/std                         0.22820      0.01843    0.26888     0.20472
log_probs/max                         -2.12362     0.02989    -2.08452    -2.17785
log_probs/min                         -4.50151     0.56457    -3.72971    -5.34130
mean/mean                             -0.00178     0.00039    -0.00107    -0.00234
mean/std                              0.00663      0.00008    0.00678     0.00648
mean/max                              0.00938      0.00119    0.01108     0.00736
mean/min                              -0.02266     0.00110    -0.02057    -0.02410
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 4, 0, 5, 6, 9, 8, 1, 2, 7]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.05118989944458 0.002172708511352539
train_time 2.054687738418579
snapshot at best
2023-09-06 13:31:44,920 MainThread INFO: EPOCH:20
2023-09-06 13:31:44,921 MainThread INFO: Time Consumed:2.8672707080841064s
2023-09-06 13:31:44,921 MainThread INFO: Total Frames:31500s
  5%|‚ñå         | 21/400 [00:43<14:56,  2.37s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1240.53561
Train_Epoch_Reward                    13311.91110
Running_Training_Average_Rewards      801.60100
Explore_Time                          0.00683
Train___Time                          2.05469
Eval____Time                          0.00326
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.18467
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.47931
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27788
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.95825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.65823
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.14058
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.75468
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12804.37373
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97859
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.98367
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.43707      0.27846    8.84556     8.02977
alpha_0                               0.94007      0.00081    0.94134     0.93879
alpha_1                               0.94009      0.00081    0.94136     0.93881
alpha_2                               0.94013      0.00081    0.94140     0.93886
alpha_3                               0.94010      0.00081    0.94137     0.93883
alpha_4                               0.94012      0.00081    0.94139     0.93884
alpha_5                               0.94012      0.00081    0.94139     0.93885
alpha_6                               0.94009      0.00081    0.94136     0.93882
alpha_7                               0.94011      0.00081    0.94138     0.93884
alpha_8                               0.94011      0.00081    0.94138     0.93884
alpha_9                               0.94009      0.00081    0.94136     0.93882
Alpha_loss                            -0.41399     0.00565    -0.40510    -0.42284
Training/policy_loss                  -3.24101     0.01976    -3.20990    -3.27130
Training/qf1_loss                     1228.26174   176.73252  1645.02185  1053.23291
Training/qf2_loss                     1228.39050   176.77730  1645.25378  1053.22083
Training/pf_norm                      0.11272      0.01848    0.14430     0.08181
Training/qf1_norm                     57.08172     2.36812    61.02574    53.34252
Training/qf2_norm                     54.00035     2.06674    57.26979    50.54551
log_std/mean                          -0.13134     0.00020    -0.13107    -0.13163
log_std/std                           0.00760      0.00022    0.00794     0.00732
log_std/max                           -0.11532     0.00029    -0.11477    -0.11584
log_std/min                           -0.14901     0.00060    -0.14810    -0.14982
log_probs/mean                        -2.73520     0.00784    -2.72171    -2.74880
log_probs/std                         0.23681      0.01322    0.25452     0.20902
log_probs/max                         -2.17329     0.03360    -2.10898    -2.22569
log_probs/min                         -5.01612     0.76696    -3.79168    -6.02037
mean/mean                             -0.00250     0.00006    -0.00243    -0.00263
mean/std                              0.00732      0.00023    0.00770     0.00691
mean/max                              0.00897      0.00068    0.01009     0.00771
mean/min                              -0.02513     0.00042    -0.02438    -0.02592
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 8, 3, 2, 9, 1, 0, 5, 4, 7]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.494852066040039 0.002343416213989258
train_time 1.4985766410827637
2023-09-06 13:31:46,534 MainThread INFO: EPOCH:21
2023-09-06 13:31:46,535 MainThread INFO: Time Consumed:1.5120611190795898s
2023-09-06 13:31:46,535 MainThread INFO: Total Frames:33000s
  6%|‚ñå         | 22/400 [00:45<13:32,  2.15s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1241.88845
Train_Epoch_Reward                    13431.66013
Running_Training_Average_Rewards      1206.04566
Explore_Time                          0.00406
Train___Time                          1.49858
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.09651
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.24026
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.97313
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.37794
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.91171
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.53362
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.91366
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12589.31751
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.62959
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.37424
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.74433      0.58156    8.53069     6.43902
alpha_0                               0.93724      0.00081    0.93851     0.93597
alpha_1                               0.93727      0.00081    0.93853     0.93600
alpha_2                               0.93731      0.00081    0.93858     0.93604
alpha_3                               0.93728      0.00081    0.93855     0.93602
alpha_4                               0.93729      0.00081    0.93856     0.93603
alpha_5                               0.93730      0.00081    0.93857     0.93604
alpha_6                               0.93727      0.00081    0.93854     0.93600
alpha_7                               0.93729      0.00081    0.93856     0.93602
alpha_8                               0.93729      0.00081    0.93856     0.93602
alpha_9                               0.93727      0.00081    0.93854     0.93600
Alpha_loss                            -0.43411     0.00570    -0.42493    -0.44334
Training/policy_loss                  -3.31750     0.02195    -3.28199    -3.35620
Training/qf1_loss                     978.24976    134.92661  1197.89612  729.54242
Training/qf2_loss                     978.26875    134.96740  1198.05066  729.45941
Training/pf_norm                      0.11961      0.02277    0.14833     0.07713
Training/qf1_norm                     56.46399     3.62183    62.16236    48.05992
Training/qf2_norm                     53.59779     3.30919    58.12218    45.93823
log_std/mean                          -0.13141     0.00011    -0.13117    -0.13158
log_std/std                           0.00695      0.00018    0.00721     0.00661
log_std/max                           -0.11620     0.00079    -0.11468    -0.11739
log_std/min                           -0.14756     0.00028    -0.14700    -0.14794
log_probs/mean                        -2.73336     0.00475    -2.72722    -2.74470
log_probs/std                         0.22986      0.01351    0.25766     0.21204
log_probs/max                         -2.14069     0.02708    -2.10258    -2.19536
log_probs/min                         -4.71820     0.42399    -4.16753    -5.50948
mean/mean                             -0.00245     0.00012    -0.00223    -0.00257
mean/std                              0.00776      0.00012    0.00788     0.00749
mean/max                              0.01109      0.00057    0.01218     0.01045
mean/min                              -0.02550     0.00073    -0.02393    -0.02617
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 8, 2, 7, 4, 6, 1, 9, 0, 5]
replay_buffer._size: [3606 3608 3608 3609 3608 3608 3607 3608 3607 3607]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.2911086082458496 0.002851247787475586
train_time 2.295375347137451
2023-09-06 13:31:49,128 MainThread INFO: EPOCH:22
2023-09-06 13:31:49,129 MainThread INFO: Time Consumed:2.4557409286499023s
2023-09-06 13:31:49,129 MainThread INFO: Total Frames:34500s
  6%|‚ñå         | 23/400 [00:47<14:26,  2.30s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1242.04418
Train_Epoch_Reward                    9137.88147
Running_Training_Average_Rewards      1196.04842
Explore_Time                          0.14376
Train___Time                          2.29538
Eval____Time                          0.00927
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.57372
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.47980
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.90860
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.51106
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.99534
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.76500
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97926
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12610.68813
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.91016
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.46455
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.28654      0.40970    8.90779     7.63223
alpha_0                               0.93443      0.00081    0.93569     0.93317
alpha_1                               0.93445      0.00081    0.93572     0.93319
alpha_2                               0.93450      0.00081    0.93576     0.93323
alpha_3                               0.93447      0.00081    0.93573     0.93321
alpha_4                               0.93448      0.00081    0.93575     0.93322
alpha_5                               0.93449      0.00081    0.93576     0.93323
alpha_6                               0.93446      0.00081    0.93572     0.93319
alpha_7                               0.93448      0.00081    0.93574     0.93321
alpha_8                               0.93448      0.00081    0.93574     0.93322
alpha_9                               0.93445      0.00081    0.93572     0.93319
Alpha_loss                            -0.45452     0.00582    -0.44553    -0.46362
Training/policy_loss                  -3.40205     0.02508    -3.36551    -3.44044
Training/qf1_loss                     1158.11554   125.34780  1331.29431  987.39935
Training/qf2_loss                     1157.90931   125.38763  1331.02527  987.04572
Training/pf_norm                      0.11991      0.01810    0.15167     0.09925
Training/qf1_norm                     62.77502     3.04661    67.59315    58.33267
Training/qf2_norm                     60.19635     2.79785    65.02012    56.45943
log_std/mean                          -0.13216     0.00035    -0.13164    -0.13272
log_std/std                           0.00631      0.00014    0.00656     0.00612
log_std/max                           -0.11766     0.00045    -0.11701    -0.11828
log_std/min                           -0.14854     0.00040    -0.14802    -0.14927
log_probs/mean                        -2.73590     0.00564    -2.72339    -2.74459
log_probs/std                         0.23241      0.01553    0.25642     0.20936
log_probs/max                         -2.13981     0.02626    -2.09743    -2.16816
log_probs/min                         -4.97891     0.66728    -4.02257    -5.82881
mean/mean                             -0.00264     0.00023    -0.00230    -0.00304
mean/std                              0.00716      0.00015    0.00740     0.00693
mean/max                              0.01341      0.00036    0.01385     0.01263
mean/min                              -0.02267     0.00061    -0.02164    -0.02364
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 4, 6, 1, 3, 2, 0, 7, 5, 8]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.1231353282928467 0.003442049026489258
train_time 2.1279141902923584
2023-09-06 13:31:51,467 MainThread INFO: EPOCH:23
2023-09-06 13:31:51,468 MainThread INFO: Time Consumed:2.140871047973633s
2023-09-06 13:31:51,468 MainThread INFO: Total Frames:36000s
  6%|‚ñå         | 24/400 [00:49<14:21,  2.29s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1233.12008
Train_Epoch_Reward                    7223.36373
Running_Training_Average_Rewards      993.09684
Explore_Time                          0.00430
Train___Time                          2.12791
Eval____Time                          0.00341
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.80330
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.30895
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.88699
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.44601
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.80597
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.58063
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.74272
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12534.32727
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.84769
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.67019
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.44748      0.69521    10.01048    7.24979
alpha_0                               0.93162      0.00081    0.93288     0.93036
alpha_1                               0.93165      0.00080    0.93291     0.93039
alpha_2                               0.93169      0.00080    0.93295     0.93043
alpha_3                               0.93167      0.00080    0.93293     0.93041
alpha_4                               0.93168      0.00080    0.93294     0.93042
alpha_5                               0.93169      0.00080    0.93295     0.93043
alpha_6                               0.93166      0.00080    0.93291     0.93040
alpha_7                               0.93167      0.00080    0.93293     0.93041
alpha_8                               0.93168      0.00080    0.93294     0.93042
alpha_9                               0.93165      0.00080    0.93291     0.93038
Alpha_loss                            -0.47473     0.00587    -0.46548    -0.48391
Training/policy_loss                  -3.49089     0.02671    -3.45055    -3.53180
Training/qf1_loss                     1205.10379   242.01010  1742.69885  779.52692
Training/qf2_loss                     1204.86950   241.94170  1742.35437  779.50592
Training/pf_norm                      0.12935      0.02011    0.17231     0.09474
Training/qf1_norm                     67.73038     4.32541    76.32721    59.66809
Training/qf2_norm                     64.84841     4.56244    73.63129    56.28297
log_std/mean                          -0.13318     0.00016    -0.13282    -0.13336
log_std/std                           0.00594      0.00008    0.00607     0.00581
log_std/max                           -0.11891     0.00043    -0.11816    -0.11943
log_std/min                           -0.14938     0.00049    -0.14817    -0.15004
log_probs/mean                        -2.73542     0.00235    -2.73174    -2.73927
log_probs/std                         0.23176      0.01269    0.25662     0.21744
log_probs/max                         -2.15296     0.04555    -2.08648    -2.21704
log_probs/min                         -4.89233     0.42185    -4.26859    -5.88101
mean/mean                             -0.00351     0.00016    -0.00322    -0.00370
mean/std                              0.00694      0.00006    0.00703     0.00688
mean/max                              0.01451      0.00039    0.01517     0.01390
mean/min                              -0.02111     0.00020    -0.02086    -0.02149
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 3, 2, 5, 9, 7, 1, 8, 0, 4]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.939631700515747 0.002374887466430664
train_time 1.943356990814209
2023-09-06 13:31:53,598 MainThread INFO: EPOCH:24
2023-09-06 13:31:53,599 MainThread INFO: Time Consumed:1.9592463970184326s
2023-09-06 13:31:53,599 MainThread INFO: Total Frames:37500s
  6%|‚ñã         | 25/400 [00:52<14:04,  2.25s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1222.02243
Train_Epoch_Reward                    25312.24007
Running_Training_Average_Rewards      1389.11618
Explore_Time                          0.00735
Train___Time                          1.94336
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.83953
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.20868
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.56880
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.49138
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.36727
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.14798
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.34232
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12259.08547
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.81083
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.97121
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.26586      0.50279    9.09387     7.69757
alpha_0                               0.92882      0.00080    0.93008     0.92757
alpha_1                               0.92886      0.00080    0.93011     0.92760
alpha_2                               0.92890      0.00080    0.93015     0.92764
alpha_3                               0.92888      0.00080    0.93013     0.92762
alpha_4                               0.92888      0.00080    0.93014     0.92762
alpha_5                               0.92889      0.00080    0.93015     0.92764
alpha_6                               0.92886      0.00080    0.93012     0.92761
alpha_7                               0.92888      0.00080    0.93013     0.92762
alpha_8                               0.92888      0.00080    0.93014     0.92763
alpha_9                               0.92885      0.00080    0.93011     0.92759
Alpha_loss                            -0.49476     0.00562    -0.48606    -0.50293
Training/policy_loss                  -3.58189     0.02681    -3.54505    -3.61506
Training/qf1_loss                     1089.76776   109.41766  1276.76892  897.29877
Training/qf2_loss                     1089.20140   109.53520  1276.40552  896.48975
Training/pf_norm                      0.13224      0.02992    0.17793     0.07593
Training/qf1_norm                     69.84670     4.00320    78.39336    65.33279
Training/qf2_norm                     67.72776     3.76143    75.91406    62.79988
log_std/mean                          -0.13382     0.00067    -0.13313    -0.13506
log_std/std                           0.00601      0.00007    0.00612     0.00591
log_std/max                           -0.11810     0.00061    -0.11684    -0.11882
log_std/min                           -0.15088     0.00109    -0.14916    -0.15273
log_probs/mean                        -2.73268     0.00624    -2.72017    -2.74269
log_probs/std                         0.24371      0.02112    0.28279     0.20853
log_probs/max                         -2.15105     0.02437    -2.10734    -2.19649
log_probs/min                         -5.05632     0.66683    -4.03204    -6.18286
mean/mean                             -0.00326     0.00015    -0.00309    -0.00349
mean/std                              0.00798      0.00078    0.00939     0.00705
mean/max                              0.01753      0.00183    0.02094     0.01527
mean/min                              -0.02304     0.00134    -0.02128    -0.02533
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 0, 7, 8, 3, 4, 6, 2, 1, 5]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.1383984088897705 0.0022864341735839844
train_time 2.142035722732544
2023-09-06 13:31:55,954 MainThread INFO: EPOCH:25
2023-09-06 13:31:55,955 MainThread INFO: Time Consumed:2.1579811573028564s
2023-09-06 13:31:55,955 MainThread INFO: Total Frames:39000s
  6%|‚ñã         | 26/400 [00:54<14:12,  2.28s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1201.08705
Train_Epoch_Reward                    8041.20428
Running_Training_Average_Rewards      1352.56027
Explore_Time                          0.00747
Train___Time                          2.14204
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.42822
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.28945
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.28970
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70698
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.24709
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.03261
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.38275
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11989.60512
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.90391
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.28512
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.07947      0.63171    9.30064     7.28164
alpha_0                               0.92604      0.00080    0.92729     0.92478
alpha_1                               0.92607      0.00080    0.92732     0.92482
alpha_2                               0.92611      0.00080    0.92736     0.92486
alpha_3                               0.92609      0.00080    0.92734     0.92484
alpha_4                               0.92609      0.00080    0.92734     0.92484
alpha_5                               0.92611      0.00080    0.92736     0.92485
alpha_6                               0.92608      0.00080    0.92733     0.92483
alpha_7                               0.92609      0.00080    0.92734     0.92484
alpha_8                               0.92610      0.00080    0.92735     0.92485
alpha_9                               0.92606      0.00080    0.92731     0.92481
Alpha_loss                            -0.51530     0.00607    -0.50598    -0.52477
Training/policy_loss                  -3.68493     0.03234    -3.63794    -3.73526
Training/qf1_loss                     1048.90836   236.43640  1452.36536  817.02924
Training/qf2_loss                     1048.25883   236.33619  1451.33533  816.18188
Training/pf_norm                      0.12053      0.02161    0.15157     0.08369
Training/qf1_norm                     72.08540     5.25324    82.30820    65.68410
Training/qf2_norm                     69.84635     5.26957    79.37615    64.38011
log_std/mean                          -0.13603     0.00039    -0.13537    -0.13659
log_std/std                           0.00638      0.00012    0.00656     0.00621
log_std/max                           -0.11887     0.00051    -0.11788    -0.11986
log_std/min                           -0.15389     0.00085    -0.15241    -0.15500
log_probs/mean                        -2.73672     0.00654    -2.72446    -2.74733
log_probs/std                         0.23338      0.01049    0.24520     0.21175
log_probs/max                         -2.16263     0.01887    -2.12975    -2.18934
log_probs/min                         -4.80451     0.51937    -3.76714    -5.52701
mean/mean                             -0.00353     0.00011    -0.00326    -0.00362
mean/std                              0.01058      0.00045    0.01113     0.00972
mean/max                              0.02342      0.00098    0.02451     0.02156
mean/min                              -0.02753     0.00119    -0.02546    -0.02919
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 5, 3, 7, 2, 1, 8, 4, 0, 9]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.1167521476745605 0.002161741256713867
train_time 2.120232582092285
2023-09-06 13:31:58,252 MainThread INFO: EPOCH:26
2023-09-06 13:31:58,253 MainThread INFO: Time Consumed:2.1338582038879395s
2023-09-06 13:31:58,253 MainThread INFO: Total Frames:40500s
  7%|‚ñã         | 27/400 [00:56<14:11,  2.28s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1183.36285
Train_Epoch_Reward                    14669.97675
Running_Training_Average_Rewards      1600.78070
Explore_Time                          0.00512
Train___Time                          2.12023
Eval____Time                          0.00304
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.02015
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.81215
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.05986
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.98490
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.41379
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.33336
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.66867
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12008.63221
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.40659
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.42393
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.69322      0.58116    8.53638     6.60646
alpha_0                               0.92325      0.00080    0.92450     0.92201
alpha_1                               0.92329      0.00080    0.92454     0.92205
alpha_2                               0.92333      0.00080    0.92458     0.92208
alpha_3                               0.92331      0.00080    0.92456     0.92206
alpha_4                               0.92331      0.00080    0.92456     0.92206
alpha_5                               0.92333      0.00080    0.92458     0.92208
alpha_6                               0.92331      0.00080    0.92456     0.92206
alpha_7                               0.92331      0.00080    0.92456     0.92207
alpha_8                               0.92332      0.00080    0.92457     0.92207
alpha_9                               0.92328      0.00080    0.92453     0.92203
Alpha_loss                            -0.53549     0.00604    -0.52593    -0.54452
Training/policy_loss                  -3.78862     0.03415    -3.73185    -3.83818
Training/qf1_loss                     973.93286    150.47146  1245.92346  715.31934
Training/qf2_loss                     973.11474    150.53944  1245.17310  714.35645
Training/pf_norm                      0.14428      0.02916    0.20710     0.10658
Training/qf1_norm                     72.48321     4.85233    79.82201    63.44739
Training/qf2_norm                     70.57970     4.46563    77.50113    61.89632
log_std/mean                          -0.13661     0.00004    -0.13653    -0.13670
log_std/std                           0.00697      0.00025    0.00739     0.00662
log_std/max                           -0.11878     0.00061    -0.11794    -0.11974
log_std/min                           -0.15584     0.00064    -0.15510    -0.15719
log_probs/mean                        -2.73609     0.00663    -2.72434    -2.75043
log_probs/std                         0.23277      0.01317    0.25619     0.20986
log_probs/max                         -2.16050     0.03689    -2.09336    -2.20811
log_probs/min                         -5.08246     0.69183    -4.24156    -6.64258
mean/mean                             -0.00420     0.00036    -0.00370    -0.00483
mean/std                              0.01220      0.00068    0.01343     0.01124
mean/max                              0.02517      0.00034    0.02590     0.02472
mean/min                              -0.03409     0.00276    -0.02990    -0.03890
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 9, 2, 6, 0, 7, 5, 4, 3, 8]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.3149607181549072 0.002662181854248047
train_time 2.31898832321167
2023-09-06 13:32:00,771 MainThread INFO: EPOCH:27
2023-09-06 13:32:00,772 MainThread INFO: Time Consumed:2.3339240550994873s
2023-09-06 13:32:00,772 MainThread INFO: Total Frames:42000s
  7%|‚ñã         | 28/400 [00:59<14:38,  2.36s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1186.77549
Train_Epoch_Reward                    3665.91024
Running_Training_Average_Rewards      879.23638
Explore_Time                          0.00497
Train___Time                          2.31899
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.54910
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.96378
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.10825
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.85353
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.23924
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.28803
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.48680
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12362.81609
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.46947
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.14139
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.51753      0.38747    8.09700     6.78685
alpha_0                               0.92048      0.00080    0.92173     0.91923
alpha_1                               0.92053      0.00079    0.92177     0.91928
alpha_2                               0.92056      0.00079    0.92181     0.91932
alpha_3                               0.92054      0.00079    0.92178     0.91930
alpha_4                               0.92054      0.00080    0.92179     0.91930
alpha_5                               0.92056      0.00079    0.92180     0.91932
alpha_6                               0.92054      0.00079    0.92178     0.91930
alpha_7                               0.92055      0.00079    0.92179     0.91930
alpha_8                               0.92055      0.00079    0.92180     0.91931
alpha_9                               0.92050      0.00080    0.92175     0.91926
Alpha_loss                            -0.55547     0.00542    -0.54734    -0.56407
Training/policy_loss                  -3.89577     0.02743    -3.85561    -3.93779
Training/qf1_loss                     948.00253    131.00575  1223.11584  737.94446
Training/qf2_loss                     946.80233    130.81727  1221.83862  737.18011
Training/pf_norm                      0.11239      0.01966    0.14385     0.09030
Training/qf1_norm                     74.18074     3.49158    79.42146    69.50684
Training/qf2_norm                     73.10502     3.85435    77.98582    67.69849
log_std/mean                          -0.13695     0.00015    -0.13677    -0.13722
log_std/std                           0.00727      0.00022    0.00746     0.00680
log_std/max                           -0.11967     0.00091    -0.11844    -0.12148
log_std/min                           -0.15657     0.00102    -0.15441    -0.15772
log_probs/mean                        -2.73296     0.00648    -2.72068    -2.74493
log_probs/std                         0.23256      0.01462    0.26696     0.21432
log_probs/max                         -2.15402     0.04621    -2.07433    -2.23826
log_probs/min                         -4.73055     0.45943    -4.34458    -5.77969
mean/mean                             -0.00525     0.00025    -0.00489    -0.00554
mean/std                              0.01529      0.00093    0.01665     0.01379
mean/max                              0.02794      0.00116    0.02977     0.02604
mean/min                              -0.04351     0.00211    -0.03978    -0.04643
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 9, 5, 4, 6, 1, 3, 7, 2, 0]
replay_buffer._size: [4508 4508 4507 4508 4512 4508 4508 4508 4507 4507]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.2780380249023438 0.002382516860961914
train_time 2.281796932220459
snapshot at best
2023-09-06 13:32:04,244 MainThread INFO: EPOCH:28
2023-09-06 13:32:04,244 MainThread INFO: Time Consumed:3.2888972759246826s
2023-09-06 13:32:04,245 MainThread INFO: Total Frames:43500s
  7%|‚ñã         | 29/400 [01:02<16:34,  2.68s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1218.40929
Train_Epoch_Reward                    3277.97108
Running_Training_Average_Rewards      720.46194
Explore_Time                          0.09637
Train___Time                          2.28180
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.86852
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.52293
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.29378
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.89249
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.53097
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.75296
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.73285
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12940.20721
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.90837
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.65087
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.68053      0.71279    8.43161     6.17462
alpha_0                               0.91772      0.00079    0.91896     0.91648
alpha_1                               0.91777      0.00079    0.91901     0.91653
alpha_2                               0.91780      0.00079    0.91904     0.91656
alpha_3                               0.91778      0.00079    0.91902     0.91654
alpha_4                               0.91778      0.00079    0.91902     0.91654
alpha_5                               0.91780      0.00079    0.91904     0.91656
alpha_6                               0.91778      0.00079    0.91902     0.91654
alpha_7                               0.91779      0.00079    0.91903     0.91655
alpha_8                               0.91779      0.00079    0.91903     0.91655
alpha_9                               0.91774      0.00079    0.91898     0.91650
Alpha_loss                            -0.57598     0.00570    -0.56691    -0.58504
Training/policy_loss                  -4.01223     0.03300    -3.95903    -4.06584
Training/qf1_loss                     1054.37996   300.31555  1455.78699  564.37811
Training/qf2_loss                     1053.08875   300.37073  1454.59241  563.31122
Training/pf_norm                      0.13083      0.01976    0.15804     0.10421
Training/qf1_norm                     79.35518     6.90443    87.00665    64.32741
Training/qf2_norm                     78.13771     6.74447    84.76796    63.23631
log_std/mean                          -0.13694     0.00013    -0.13672    -0.13716
log_std/std                           0.00621      0.00028    0.00670     0.00585
log_std/max                           -0.12223     0.00096    -0.12042    -0.12392
log_std/min                           -0.15309     0.00088    -0.15194    -0.15465
log_probs/mean                        -2.73628     0.00515    -2.73116    -2.74925
log_probs/std                         0.23964      0.01523    0.25944     0.20823
log_probs/max                         -2.15423     0.03227    -2.09686    -2.21864
log_probs/min                         -4.93193     0.56438    -3.95367    -5.96586
mean/mean                             -0.00476     0.00044    -0.00407    -0.00545
mean/std                              0.01845      0.00101    0.02024     0.01695
mean/max                              0.03358      0.00210    0.03721     0.03049
mean/min                              -0.04984     0.00182    -0.04701    -0.05284
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 7, 5, 2, 1, 9, 8, 3, 0, 4]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.534712314605713 0.0022895336151123047
train_time 1.5383689403533936
snapshot at best
2023-09-06 13:32:06,775 MainThread INFO: EPOCH:29
2023-09-06 13:32:06,775 MainThread INFO: Time Consumed:2.428217649459839s
2023-09-06 13:32:06,776 MainThread INFO: Total Frames:45000s
  8%|‚ñä         | 30/400 [01:05<16:17,  2.64s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1258.22552
Train_Epoch_Reward                    8204.54768
Running_Training_Average_Rewards      504.94763
Explore_Time                          0.00512
Train___Time                          1.53837
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.08179
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.17193
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.27112
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.25627
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.81984
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19012
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.09618
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13215.73846
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.32227
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.53340
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.52056      0.59857    8.74952     6.82230
alpha_0                               0.91496      0.00079    0.91620     0.91373
alpha_1                               0.91502      0.00079    0.91625     0.91378
alpha_2                               0.91505      0.00079    0.91629     0.91381
alpha_3                               0.91502      0.00079    0.91626     0.91379
alpha_4                               0.91502      0.00079    0.91626     0.91379
alpha_5                               0.91504      0.00079    0.91628     0.91381
alpha_6                               0.91503      0.00079    0.91626     0.91379
alpha_7                               0.91503      0.00079    0.91627     0.91380
alpha_8                               0.91504      0.00079    0.91628     0.91381
alpha_9                               0.91499      0.00079    0.91622     0.91375
Alpha_loss                            -0.59591     0.00572    -0.58755    -0.60426
Training/policy_loss                  -4.12736     0.03363    -4.07893    -4.17091
Training/qf1_loss                     948.71526    178.51005  1298.82910  720.98749
Training/qf2_loss                     947.17780    178.34733  1296.61780  719.83319
Training/pf_norm                      0.11421      0.02092    0.15327     0.09179
Training/qf1_norm                     81.35063     5.70334    91.29620    73.53947
Training/qf2_norm                     80.50170     5.75831    91.87874    73.70502
log_std/mean                          -0.13707     0.00014    -0.13678    -0.13724
log_std/std                           0.00575      0.00003    0.00580     0.00568
log_std/max                           -0.12257     0.00066    -0.12143    -0.12370
log_std/min                           -0.15304     0.00074    -0.15190    -0.15429
log_probs/mean                        -2.73289     0.00930    -2.71850    -2.75103
log_probs/std                         0.23449      0.01096    0.25516     0.21651
log_probs/max                         -2.12112     0.02873    -2.08175    -2.16109
log_probs/min                         -4.69194     0.33986    -4.14082    -5.32377
mean/mean                             -0.00322     0.00037    -0.00273    -0.00394
mean/std                              0.02198      0.00071    0.02297     0.02068
mean/max                              0.04117      0.00155    0.04330     0.03825
mean/min                              -0.05580     0.00116    -0.05366    -0.05736
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 4, 9, 3, 2, 5, 7, 0, 8, 6]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.5690138339996338 0.00263214111328125
train_time 1.5730137825012207
snapshot at best
2023-09-06 13:32:09,109 MainThread INFO: EPOCH:30
2023-09-06 13:32:09,110 MainThread INFO: Time Consumed:2.194887638092041s
2023-09-06 13:32:09,110 MainThread INFO: Total Frames:46500s
  8%|‚ñä         | 31/400 [01:07<15:41,  2.55s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1311.99694
Train_Epoch_Reward                    12651.34653
Running_Training_Average_Rewards      804.46218
Explore_Time                          0.00495
Train___Time                          1.57301
Eval____Time                          0.00488
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.20650
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.49525
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.60771
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.25321
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.12515
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.34298
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.57554
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13981.18119
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.45186
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.26371
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.72801      0.35544    8.39550     7.10198
alpha_0                               0.91222      0.00079    0.91345     0.91099
alpha_1                               0.91228      0.00079    0.91351     0.91105
alpha_2                               0.91231      0.00079    0.91354     0.91107
alpha_3                               0.91228      0.00079    0.91351     0.91104
alpha_4                               0.91228      0.00079    0.91351     0.91105
alpha_5                               0.91230      0.00079    0.91353     0.91106
alpha_6                               0.91228      0.00079    0.91352     0.91105
alpha_7                               0.91229      0.00079    0.91352     0.91106
alpha_8                               0.91230      0.00079    0.91353     0.91106
alpha_9                               0.91224      0.00079    0.91348     0.91101
Alpha_loss                            -0.61625     0.00554    -0.60743    -0.62497
Training/policy_loss                  -4.24682     0.03042    -4.19625    -4.29108
Training/qf1_loss                     978.34448    117.23781  1147.96313  801.88715
Training/qf2_loss                     976.64615    117.09281  1146.09009  799.95935
Training/pf_norm                      0.11733      0.01963    0.15825     0.09707
Training/qf1_norm                     87.31682     4.27691    95.47235    80.19952
Training/qf2_norm                     86.47435     4.34682    94.88411    80.27985
log_std/mean                          -0.13643     0.00015    -0.13616    -0.13669
log_std/std                           0.00556      0.00019    0.00578     0.00525
log_std/max                           -0.12143     0.00054    -0.12045    -0.12223
log_std/min                           -0.15268     0.00064    -0.15140    -0.15364
log_probs/mean                        -2.73410     0.00632    -2.72402    -2.74599
log_probs/std                         0.23685      0.01318    0.26063     0.21440
log_probs/max                         -2.13223     0.04779    -2.05703    -2.22820
log_probs/min                         -4.93872     0.43387    -4.47195    -5.84308
mean/mean                             -0.00285     0.00029    -0.00260    -0.00352
mean/std                              0.02381      0.00042    0.02443     0.02316
mean/max                              0.04503      0.00072    0.04610     0.04399
mean/min                              -0.05952     0.00111    -0.05818    -0.06152
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 4, 7, 0, 1, 2, 9, 3, 6, 5]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.714186668395996 0.0021495819091796875
train_time 1.7176432609558105
snapshot at best
2023-09-06 13:32:12,296 MainThread INFO: EPOCH:31
2023-09-06 13:32:12,297 MainThread INFO: Time Consumed:2.592501163482666s
2023-09-06 13:32:12,297 MainThread INFO: Total Frames:48000s
  8%|‚ñä         | 32/400 [01:10<16:46,  2.73s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1369.81231
Train_Epoch_Reward                    2895.51761
Running_Training_Average_Rewards      791.71373
Explore_Time                          0.00506
Train___Time                          1.71764
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.79598
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.68744
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.96290
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.19845
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.74459
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22999
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.97558
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14675.79761
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.52865
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.15969
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.10747      0.37416    8.55613     7.16961
alpha_0                               0.90949      0.00078    0.91072     0.90826
alpha_1                               0.90954      0.00078    0.91077     0.90832
alpha_2                               0.90957      0.00079    0.91080     0.90834
alpha_3                               0.90954      0.00078    0.91077     0.90831
alpha_4                               0.90954      0.00078    0.91077     0.90831
alpha_5                               0.90956      0.00078    0.91079     0.90833
alpha_6                               0.90955      0.00078    0.91078     0.90832
alpha_7                               0.90956      0.00078    0.91079     0.90833
alpha_8                               0.90956      0.00078    0.91079     0.90833
alpha_9                               0.90950      0.00079    0.91073     0.90827
Alpha_loss                            -0.63658     0.00565    -0.62716    -0.64607
Training/policy_loss                  -4.36900     0.03446    -4.30823    -4.42993
Training/qf1_loss                     1213.14218   161.76456  1480.80847  916.57001
Training/qf2_loss                     1211.16481   161.80860  1478.70520  914.52130
Training/pf_norm                      0.14406      0.02386    0.18771     0.11705
Training/qf1_norm                     95.24073     4.78343    100.01601   83.40826
Training/qf2_norm                     94.49381     4.50394    99.56506    83.50815
log_std/mean                          -0.13671     0.00025    -0.13614    -0.13701
log_std/std                           0.00506      0.00008    0.00517     0.00493
log_std/max                           -0.12341     0.00071    -0.12258    -0.12472
log_std/min                           -0.15181     0.00064    -0.15087    -0.15277
log_probs/mean                        -2.73524     0.00675    -2.72790    -2.75238
log_probs/std                         0.23838      0.01659    0.27961     0.21718
log_probs/max                         -2.10911     0.02951    -2.05778    -2.15973
log_probs/min                         -4.95304     0.67291    -4.05974    -6.52052
mean/mean                             -0.00452     0.00037    -0.00378    -0.00487
mean/std                              0.02506      0.00026    0.02546     0.02456
mean/max                              0.04708      0.00077    0.04827     0.04596
mean/min                              -0.06317     0.00078    -0.06209    -0.06438
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 6, 3, 0, 7, 1, 2, 5, 9, 4]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.662806510925293 0.0021615028381347656
train_time 1.6663038730621338
2023-09-06 13:32:14,138 MainThread INFO: EPOCH:32
2023-09-06 13:32:14,138 MainThread INFO: Time Consumed:1.6806225776672363s
2023-09-06 13:32:14,139 MainThread INFO: Total Frames:49500s
  8%|‚ñä         | 33/400 [01:12<15:09,  2.48s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1417.20964
Train_Epoch_Reward                    20813.72885
Running_Training_Average_Rewards      1212.01977
Explore_Time                          0.00508
Train___Time                          1.66630
Eval____Time                          0.00446
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.06995
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.00125
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.74449
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.35188
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.34508
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16471
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.98163
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14635.66166
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.82709
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.26002
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.28286      0.53850    9.27383     7.67144
alpha_0                               0.90676      0.00078    0.90799     0.90554
alpha_1                               0.90682      0.00078    0.90804     0.90559
alpha_2                               0.90684      0.00078    0.90807     0.90561
alpha_3                               0.90681      0.00078    0.90804     0.90559
alpha_4                               0.90682      0.00078    0.90804     0.90559
alpha_5                               0.90683      0.00078    0.90806     0.90561
alpha_6                               0.90682      0.00078    0.90805     0.90560
alpha_7                               0.90683      0.00078    0.90806     0.90561
alpha_8                               0.90683      0.00078    0.90806     0.90561
alpha_9                               0.90677      0.00078    0.90800     0.90555
Alpha_loss                            -0.65674     0.00592    -0.64668    -0.66607
Training/policy_loss                  -4.48880     0.03547    -4.42747    -4.54638
Training/qf1_loss                     1232.70101   221.25574  1698.50818  949.50958
Training/qf2_loss                     1230.44028   220.94060  1695.10120  947.46057
Training/pf_norm                      0.12023      0.01887    0.14873     0.08761
Training/qf1_norm                     101.74715    7.44618    116.14115   91.54044
Training/qf2_norm                     101.30939    7.74126    115.60075   92.12879
log_std/mean                          -0.13753     0.00049    -0.13696    -0.13843
log_std/std                           0.00493      0.00009    0.00503     0.00471
log_std/max                           -0.12476     0.00079    -0.12352    -0.12585
log_std/min                           -0.15180     0.00029    -0.15126    -0.15233
log_probs/mean                        -2.73457     0.00705    -2.72031    -2.74374
log_probs/std                         0.24291      0.01419    0.26264     0.22665
log_probs/max                         -2.08364     0.05113    -2.01529    -2.15941
log_probs/min                         -5.11670     0.49281    -4.31591    -5.60746
mean/mean                             -0.00512     0.00032    -0.00469    -0.00565
mean/std                              0.02553      0.00017    0.02592     0.02537
mean/max                              0.04875      0.00026    0.04911     0.04821
mean/min                              -0.06507     0.00045    -0.06421    -0.06580
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 0, 2, 9, 4, 8, 7, 1, 6, 5]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.4300949573516846 0.0022406578063964844
train_time 2.4336884021759033
snapshot at best
2023-09-06 13:32:17,616 MainThread INFO: EPOCH:33
2023-09-06 13:32:17,616 MainThread INFO: Time Consumed:3.247047185897827s
2023-09-06 13:32:17,617 MainThread INFO: Total Frames:51000s
  8%|‚ñä         | 34/400 [01:16<16:54,  2.77s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1443.03468
Train_Epoch_Reward                    36492.02867
Running_Training_Average_Rewards      2006.70917
Explore_Time                          0.01794
Train___Time                          2.43369
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.52491
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.16027
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.62882
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.39078
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.17210
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.28405
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.90747
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14762.96198
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.96941
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.31374
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.45446      0.45907    8.97277     7.26383
alpha_0                               0.90404      0.00078    0.90526     0.90282
alpha_1                               0.90410      0.00078    0.90532     0.90288
alpha_2                               0.90412      0.00078    0.90534     0.90290
alpha_3                               0.90409      0.00078    0.90531     0.90287
alpha_4                               0.90410      0.00078    0.90532     0.90287
alpha_5                               0.90411      0.00078    0.90534     0.90289
alpha_6                               0.90410      0.00078    0.90532     0.90288
alpha_7                               0.90411      0.00078    0.90534     0.90289
alpha_8                               0.90412      0.00078    0.90534     0.90290
alpha_9                               0.90406      0.00078    0.90528     0.90284
Alpha_loss                            -0.67671     0.00589    -0.66672    -0.68643
Training/policy_loss                  -4.60754     0.03645    -4.53930    -4.66861
Training/qf1_loss                     1222.26060   185.52609  1429.00964  812.16125
Training/qf2_loss                     1220.00059   185.29030  1426.78247  810.29089
Training/pf_norm                      0.11613      0.01949    0.14317     0.08242
Training/qf1_norm                     108.14854    5.80282    116.37326   93.80946
Training/qf2_norm                     107.16707    5.89635    115.05414   92.54395
log_std/mean                          -0.13863     0.00027    -0.13815    -0.13901
log_std/std                           0.00456      0.00009    0.00470     0.00444
log_std/max                           -0.12705     0.00038    -0.12665    -0.12775
log_std/min                           -0.15063     0.00079    -0.14895    -0.15179
log_probs/mean                        -2.73204     0.00492    -2.72305    -2.74000
log_probs/std                         0.24109      0.01700    0.26683     0.21655
log_probs/max                         -2.09858     0.03737    -2.02793    -2.15891
log_probs/min                         -5.14904     0.72628    -3.99388    -6.59050
mean/mean                             -0.00602     0.00011    -0.00582    -0.00614
mean/std                              0.02673      0.00027    0.02700     0.02614
mean/max                              0.04957      0.00028    0.04996     0.04912
mean/min                              -0.06868     0.00083    -0.06665    -0.06950
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 1, 5, 6, 2, 4, 7, 9, 3, 8]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6551449298858643 0.0022749900817871094
train_time 1.6587860584259033
2023-09-06 13:32:19,547 MainThread INFO: EPOCH:34
2023-09-06 13:32:19,548 MainThread INFO: Time Consumed:1.6748955249786377s
2023-09-06 13:32:19,548 MainThread INFO: Total Frames:52500s
  9%|‚ñâ         | 35/400 [01:17<15:17,  2.51s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1440.29943
Train_Epoch_Reward                    26194.52083
Running_Training_Average_Rewards      2783.34261
Explore_Time                          0.00636
Train___Time                          1.65879
Eval____Time                          0.00522
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.21211
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.43764
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.51517
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.70528
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.09930
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.30527
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.13740
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14593.58918
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.20621
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.51399
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.31325      0.58003    9.14781     7.25253
alpha_0                               0.90133      0.00078    0.90255     0.90011
alpha_1                               0.90139      0.00078    0.90261     0.90017
alpha_2                               0.90141      0.00078    0.90263     0.90019
alpha_3                               0.90138      0.00078    0.90260     0.90016
alpha_4                               0.90138      0.00078    0.90260     0.90017
alpha_5                               0.90140      0.00078    0.90262     0.90019
alpha_6                               0.90139      0.00078    0.90261     0.90018
alpha_7                               0.90140      0.00078    0.90262     0.90018
alpha_8                               0.90141      0.00078    0.90263     0.90019
alpha_9                               0.90135      0.00078    0.90257     0.90013
Alpha_loss                            -0.69678     0.00539    -0.68879    -0.70535
Training/policy_loss                  -4.72574     0.03065    -4.67934    -4.77605
Training/qf1_loss                     1256.13143   352.67101  1771.95703  817.04907
Training/qf2_loss                     1253.69391   352.28248  1768.66309  815.31213
Training/pf_norm                      0.12112      0.02570    0.16988     0.09213
Training/qf1_norm                     111.01105    7.36786    120.37418   97.84695
Training/qf2_norm                     110.25800    8.00006    121.04955   96.07230
log_std/mean                          -0.13765     0.00033    -0.13706    -0.13803
log_std/std                           0.00445      0.00004    0.00453     0.00439
log_std/max                           -0.12661     0.00035    -0.12581    -0.12703
log_std/min                           -0.14909     0.00077    -0.14791    -0.15013
log_probs/mean                        -2.73063     0.00629    -2.72243    -2.74142
log_probs/std                         0.23204      0.01356    0.24996     0.20510
log_probs/max                         -2.09378     0.05445    -1.98385    -2.17883
log_probs/min                         -4.72030     0.50287    -4.02361    -5.70037
mean/mean                             -0.00552     0.00009    -0.00542    -0.00572
mean/std                              0.02750      0.00040    0.02831     0.02705
mean/max                              0.05064      0.00083    0.05219     0.04950
mean/min                              -0.07061     0.00098    -0.06938    -0.07259
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 0, 1, 3, 8, 5, 6, 2, 9, 7]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.7385692596435547 0.0021517276763916016
train_time 2.7420334815979004
snapshot at best
2023-09-06 13:32:23,108 MainThread INFO: EPOCH:35
2023-09-06 13:32:23,109 MainThread INFO: Time Consumed:3.397066593170166s
2023-09-06 13:32:23,109 MainThread INFO: Total Frames:54000s
  9%|‚ñâ         | 36/400 [01:21<17:12,  2.84s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1457.19719
Train_Epoch_Reward                    20051.59545
Running_Training_Average_Rewards      2757.93817
Explore_Time                          0.00451
Train___Time                          2.74203
Eval____Time                          0.00503
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.30616
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.40311
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.71840
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.73433
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.04676
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.31568
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.45025
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15140.41085
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.20984
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.37780
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.19292      0.73378    9.48136     7.25299
alpha_0                               0.89863      0.00078    0.89984     0.89741
alpha_1                               0.89869      0.00077    0.89990     0.89747
alpha_2                               0.89871      0.00077    0.89992     0.89750
alpha_3                               0.89868      0.00078    0.89989     0.89746
alpha_4                               0.89868      0.00077    0.89990     0.89747
alpha_5                               0.89870      0.00077    0.89992     0.89749
alpha_6                               0.89869      0.00077    0.89991     0.89748
alpha_7                               0.89870      0.00078    0.89991     0.89748
alpha_8                               0.89871      0.00077    0.89992     0.89749
alpha_9                               0.89864      0.00078    0.89986     0.89743
Alpha_loss                            -0.71705     0.00558    -0.70907    -0.72450
Training/policy_loss                  -4.84647     0.03586    -4.79189    -4.89487
Training/qf1_loss                     1221.10607   309.42875  1625.00964  785.11591
Training/qf2_loss                     1218.56533   309.22906  1621.81433  782.68719
Training/pf_norm                      0.12028      0.01622    0.14485     0.09135
Training/qf1_norm                     113.90350    9.49287    129.95782   100.08160
Training/qf2_norm                     113.24112    9.74453    130.13513   99.73599
log_std/mean                          -0.13629     0.00029    -0.13596    -0.13682
log_std/std                           0.00439      0.00007    0.00446     0.00423
log_std/max                           -0.12482     0.00079    -0.12367    -0.12630
log_std/min                           -0.14830     0.00046    -0.14752    -0.14894
log_probs/mean                        -2.73130     0.00916    -2.71600    -2.74720
log_probs/std                         0.23741      0.01673    0.28131     0.21553
log_probs/max                         -2.07532     0.05134    -1.93663    -2.12742
log_probs/min                         -4.73880     0.73715    -3.99746    -6.72187
mean/mean                             -0.00520     0.00016    -0.00502    -0.00546
mean/std                              0.02940      0.00053    0.03027     0.02853
mean/max                              0.05346      0.00072    0.05439     0.05221
mean/min                              -0.07419     0.00084    -0.07275    -0.07555
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 9, 2, 6, 4, 1, 7, 5, 0, 8]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7334482669830322 0.0023953914642333984
train_time 1.7372047901153564
snapshot at best
2023-09-06 13:32:26,081 MainThread INFO: EPOCH:36
2023-09-06 13:32:26,081 MainThread INFO: Time Consumed:2.5464608669281006s
2023-09-06 13:32:26,082 MainThread INFO: Total Frames:55500s
  9%|‚ñâ         | 37/400 [01:24<17:22,  2.87s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1486.41572
Train_Epoch_Reward                    8549.02952
Running_Training_Average_Rewards      1826.50486
Explore_Time                          0.00518
Train___Time                          1.73720
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.17722
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.44467
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.88779
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.79498
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.04023
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.32884
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.78630
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15646.05505
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.18979
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.23912
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.47300      0.43950    9.22911     7.48040
alpha_0                               0.89593      0.00077    0.89714     0.89472
alpha_1                               0.89599      0.00077    0.89720     0.89478
alpha_2                               0.89602      0.00077    0.89723     0.89481
alpha_3                               0.89598      0.00077    0.89719     0.89477
alpha_4                               0.89599      0.00077    0.89720     0.89478
alpha_5                               0.89601      0.00077    0.89722     0.89480
alpha_6                               0.89600      0.00077    0.89721     0.89479
alpha_7                               0.89600      0.00077    0.89722     0.89480
alpha_8                               0.89601      0.00077    0.89722     0.89481
alpha_9                               0.89595      0.00077    0.89716     0.89474
Alpha_loss                            -0.73683     0.00556    -0.72802    -0.74578
Training/policy_loss                  -4.96764     0.03427    -4.91393    -5.02543
Training/qf1_loss                     1338.76221   227.00273  1737.18103  874.69629
Training/qf2_loss                     1335.99285   227.00309  1734.51599  872.07275
Training/pf_norm                      0.12474      0.03028    0.16933     0.08577
Training/qf1_norm                     122.47824    5.95710    132.61929   110.11272
Training/qf2_norm                     121.82274    5.60917    131.10091   109.73873
log_std/mean                          -0.13677     0.00061    -0.13605    -0.13791
log_std/std                           0.00434      0.00010    0.00450     0.00423
log_std/max                           -0.12525     0.00098    -0.12394    -0.12646
log_std/min                           -0.15027     0.00155    -0.14816    -0.15254
log_probs/mean                        -2.72744     0.00849    -2.71209    -2.74078
log_probs/std                         0.23926      0.01931    0.27737     0.22107
log_probs/max                         -2.08597     0.04727    -2.00000    -2.15450
log_probs/min                         -5.00704     1.01874    -4.04708    -7.20752
mean/mean                             -0.00527     0.00031    -0.00496    -0.00586
mean/std                              0.03094      0.00024    0.03126     0.03043
mean/max                              0.05532      0.00028    0.05593     0.05482
mean/min                              -0.07715     0.00085    -0.07585    -0.07886
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 0, 5, 1, 8, 2, 7, 9, 4, 6]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8163185119628906 0.002212047576904297
train_time 1.8198459148406982
snapshot at best
2023-09-06 13:32:28,870 MainThread INFO: EPOCH:37
2023-09-06 13:32:28,870 MainThread INFO: Time Consumed:2.5750229358673096s
2023-09-06 13:32:28,871 MainThread INFO: Total Frames:57000s
 10%|‚ñâ         | 38/400 [01:27<17:09,  2.84s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1540.79515
Train_Epoch_Reward                    6399.49554
Running_Training_Average_Rewards      1166.67068
Explore_Time                          0.00553
Train___Time                          1.81985
Eval____Time                          0.00525
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.86983
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.57277
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.16199
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.81720
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.07126
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.27437
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.30169
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16233.37694
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.25408
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.21381
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.14731      0.70445    10.71848    8.28106
alpha_0                               0.89325      0.00077    0.89445     0.89204
alpha_1                               0.89331      0.00077    0.89452     0.89210
alpha_2                               0.89333      0.00077    0.89454     0.89213
alpha_3                               0.89330      0.00077    0.89450     0.89209
alpha_4                               0.89330      0.00077    0.89451     0.89209
alpha_5                               0.89333      0.00077    0.89454     0.89212
alpha_6                               0.89332      0.00077    0.89453     0.89212
alpha_7                               0.89332      0.00077    0.89453     0.89211
alpha_8                               0.89333      0.00077    0.89454     0.89213
alpha_9                               0.89327      0.00077    0.89447     0.89206
Alpha_loss                            -0.75732     0.00593    -0.74821    -0.76656
Training/policy_loss                  -5.08841     0.03435    -5.03590    -5.14059
Training/qf1_loss                     1516.18828   305.79871  2153.75586  1138.79102
Training/qf2_loss                     1512.97030   305.85439  2150.44067  1135.73694
Training/pf_norm                      0.13386      0.02230    0.16522     0.09401
Training/qf1_norm                     136.91204    10.76893   161.99182   124.67464
Training/qf2_norm                     136.55405    10.27705   160.73590   124.33707
log_std/mean                          -0.13884     0.00022    -0.13833    -0.13903
log_std/std                           0.00465      0.00011    0.00487     0.00453
log_std/max                           -0.12697     0.00073    -0.12571    -0.12795
log_std/min                           -0.15480     0.00086    -0.15311    -0.15569
log_probs/mean                        -2.73011     0.00454    -2.72132    -2.73876
log_probs/std                         0.23305      0.01137    0.25093     0.21040
log_probs/max                         -2.09547     0.04079    -2.02435    -2.13913
log_probs/min                         -4.65472     0.27057    -4.08830    -5.03220
mean/mean                             -0.00635     0.00027    -0.00602    -0.00694
mean/std                              0.03065      0.00046    0.03132     0.02999
mean/max                              0.05466      0.00093    0.05581     0.05305
mean/min                              -0.07799     0.00072    -0.07665    -0.07898
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 2, 9, 0, 5, 8, 4, 7, 1, 6]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.786348819732666 0.0021102428436279297
train_time 1.7897708415985107
snapshot at best
2023-09-06 13:32:31,838 MainThread INFO: EPOCH:38
2023-09-06 13:32:31,839 MainThread INFO: Time Consumed:2.537740468978882s
2023-09-06 13:32:31,839 MainThread INFO: Total Frames:58500s
 10%|‚ñâ         | 39/400 [01:30<17:21,  2.88s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1595.57660
Train_Epoch_Reward                    27447.92989
Running_Training_Average_Rewards      1413.21517
Explore_Time                          0.00499
Train___Time                          1.78977
Eval____Time                          0.00474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.86993
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.68459
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.23339
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.86495
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.20565
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.54878
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.33454
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16782.61928
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.31872
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.26670
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.47582      0.56242    9.23596     7.45559
alpha_0                               0.89057      0.00077    0.89178     0.88937
alpha_1                               0.89063      0.00077    0.89184     0.88943
alpha_2                               0.89066      0.00077    0.89186     0.88945
alpha_3                               0.89062      0.00077    0.89182     0.88942
alpha_4                               0.89062      0.00077    0.89183     0.88942
alpha_5                               0.89065      0.00077    0.89185     0.88945
alpha_6                               0.89064      0.00077    0.89185     0.88944
alpha_7                               0.89064      0.00077    0.89184     0.88943
alpha_8                               0.89066      0.00077    0.89186     0.88946
alpha_9                               0.89059      0.00077    0.89179     0.88938
Alpha_loss                            -0.77839     0.00580    -0.76886    -0.78729
Training/policy_loss                  -5.21283     0.03413    -5.15481    -5.26288
Training/qf1_loss                     1279.38056   248.57440  1620.37048  805.05090
Training/qf2_loss                     1275.96435   248.39446  1616.88501  802.11670
Training/pf_norm                      0.12768      0.01627    0.15393     0.09596
Training/qf1_norm                     131.55260    9.01813    142.71513   115.81593
Training/qf2_norm                     131.70012    8.87941    142.45366   115.64844
log_std/mean                          -0.13939     0.00042    -0.13885    -0.14025
log_std/std                           0.00514      0.00012    0.00528     0.00495
log_std/max                           -0.12738     0.00053    -0.12674    -0.12832
log_std/min                           -0.15674     0.00099    -0.15487    -0.15823
log_probs/mean                        -2.73767     0.00438    -2.73066    -2.74637
log_probs/std                         0.25707      0.01901    0.28790     0.23396
log_probs/max                         -2.09187     0.05922    -2.03339    -2.25021
log_probs/min                         -5.54471     0.71963    -4.50262    -6.50697
mean/mean                             -0.00756     0.00018    -0.00714    -0.00775
mean/std                              0.03113      0.00098    0.03276     0.02992
mean/max                              0.05462      0.00175    0.05767     0.05256
mean/min                              -0.08098     0.00255    -0.07796    -0.08517
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 4, 1, 0, 3, 5, 9, 7, 2, 8]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6848907470703125 0.002125263214111328
train_time 1.6883420944213867
2023-09-06 13:32:34,024 MainThread INFO: EPOCH:39
2023-09-06 13:32:34,024 MainThread INFO: Time Consumed:1.7026209831237793s
2023-09-06 13:32:34,025 MainThread INFO: Total Frames:60000s
 10%|‚ñà         | 40/400 [01:32<16:08,  2.69s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1632.67679
Train_Epoch_Reward                    15775.46243
Running_Training_Average_Rewards      1654.09626
Explore_Time                          0.00434
Train___Time                          1.68834
Eval____Time                          0.00544
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.44802
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.55653
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.99707
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.90030
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.25253
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.55044
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.18420
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16759.85326
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.15929
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.63306
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.13783      0.54568    8.72797     6.87752
alpha_0                               0.88790      0.00077    0.88910     0.88670
alpha_1                               0.88796      0.00077    0.88916     0.88676
alpha_2                               0.88799      0.00077    0.88919     0.88679
alpha_3                               0.88795      0.00077    0.88915     0.88675
alpha_4                               0.88795      0.00077    0.88915     0.88675
alpha_5                               0.88798      0.00077    0.88918     0.88678
alpha_6                               0.88797      0.00077    0.88918     0.88678
alpha_7                               0.88797      0.00076    0.88917     0.88677
alpha_8                               0.88799      0.00077    0.88919     0.88679
alpha_9                               0.88792      0.00077    0.88912     0.88672
Alpha_loss                            -0.79779     0.00545    -0.78945    -0.80750
Training/policy_loss                  -5.32420     0.03141    -5.27732    -5.38477
Training/qf1_loss                     1156.38019   230.23661  1633.43262  782.64337
Training/qf2_loss                     1152.77275   229.85330  1629.10559  779.90332
Training/pf_norm                      0.13263      0.02305    0.16509     0.09564
Training/qf1_norm                     130.41348    8.43058    140.31212   112.18948
Training/qf2_norm                     130.85323    8.63120    141.30542   111.91296
log_std/mean                          -0.14144     0.00046    -0.14057    -0.14203
log_std/std                           0.00495      0.00018    0.00521     0.00469
log_std/max                           -0.12951     0.00082    -0.12825    -0.13067
log_std/min                           -0.15828     0.00052    -0.15740    -0.15887
log_probs/mean                        -2.73071     0.00690    -2.71517    -2.73878
log_probs/std                         0.24058      0.01703    0.27464     0.21744
log_probs/max                         -2.09514     0.05246    -1.97716    -2.18158
log_probs/min                         -4.81250     0.75220    -3.91255    -6.60271
mean/mean                             -0.00752     0.00016    -0.00732    -0.00788
mean/std                              0.03503      0.00116    0.03673     0.03317
mean/max                              0.06147      0.00217    0.06416     0.05768
mean/min                              -0.08906     0.00239    -0.08531    -0.09267
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 5, 3, 8, 1, 0, 2, 9, 4, 6]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.627802848815918 0.0021791458129882812
train_time 2.6313273906707764
snapshot at best
2023-09-06 13:32:37,724 MainThread INFO: EPOCH:40
2023-09-06 13:32:37,725 MainThread INFO: Time Consumed:3.514716863632202s
2023-09-06 13:32:37,725 MainThread INFO: Total Frames:61500s
 10%|‚ñà         | 41/400 [01:36<17:48,  2.98s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1668.52788
Train_Epoch_Reward                    9295.60500
Running_Training_Average_Rewards      1750.63324
Explore_Time                          0.00446
Train___Time                          2.63133
Eval____Time                          0.00517
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.78658
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.95553
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.00688
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.10967
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.48555
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.76375
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.49120
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17301.14288
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.43246
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.73884
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.83721      0.35483    9.40786     8.37937
alpha_0                               0.88524      0.00076    0.88644     0.88405
alpha_1                               0.88530      0.00076    0.88650     0.88411
alpha_2                               0.88532      0.00076    0.88652     0.88413
alpha_3                               0.88529      0.00076    0.88648     0.88409
alpha_4                               0.88528      0.00076    0.88648     0.88409
alpha_5                               0.88532      0.00076    0.88651     0.88412
alpha_6                               0.88531      0.00076    0.88651     0.88412
alpha_7                               0.88531      0.00076    0.88650     0.88411
alpha_8                               0.88533      0.00076    0.88653     0.88414
alpha_9                               0.88525      0.00076    0.88645     0.88406
Alpha_loss                            -0.81780     0.00626    -0.80889    -0.82796
Training/policy_loss                  -5.44335     0.03809    -5.38696    -5.50284
Training/qf1_loss                     1300.05319   213.50047  1753.94531  1019.34003
Training/qf2_loss                     1296.33577   213.33198  1750.14490  1015.30316
Training/pf_norm                      0.12821      0.02396    0.16043     0.08482
Training/qf1_norm                     147.65986    6.15788    158.32906   140.42381
Training/qf2_norm                     147.62308    6.19876    158.19868   140.61380
log_std/mean                          -0.14249     0.00030    -0.14208    -0.14297
log_std/std                           0.00484      0.00013    0.00510     0.00470
log_std/max                           -0.13086     0.00073    -0.12959    -0.13187
log_std/min                           -0.15734     0.00050    -0.15658    -0.15821
log_probs/mean                        -2.72906     0.00742    -2.71252    -2.74012
log_probs/std                         0.24773      0.01231    0.26814     0.22815
log_probs/max                         -2.06186     0.03716    -2.00443    -2.14377
log_probs/min                         -5.28871     0.68324    -4.55895    -6.44192
mean/mean                             -0.00908     0.00065    -0.00807    -0.01022
mean/std                              0.03763      0.00031    0.03797     0.03698
mean/max                              0.06471      0.00061    0.06519     0.06312
mean/min                              -0.09534     0.00067    -0.09396    -0.09608
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 1, 7, 0, 2, 5, 4, 8, 6, 9]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6264631748199463 0.002163410186767578
train_time 1.6299419403076172
snapshot at best
2023-09-06 13:32:40,167 MainThread INFO: EPOCH:41
2023-09-06 13:32:40,168 MainThread INFO: Time Consumed:2.165404796600342s
2023-09-06 13:32:40,168 MainThread INFO: Total Frames:63000s
 10%|‚ñà         | 42/400 [01:38<16:49,  2.82s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1710.94302
Train_Epoch_Reward                    15898.40139
Running_Training_Average_Rewards      1365.64896
Explore_Time                          0.00594
Train___Time                          1.62994
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.70596
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.31138
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.22966
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.29637
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.00452
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.34722
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.89859
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18063.75115
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.63226
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.57871
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.95006      0.57605    10.28098    8.14263
alpha_0                               0.88259      0.00076    0.88378     0.88140
alpha_1                               0.88265      0.00076    0.88384     0.88146
alpha_2                               0.88267      0.00076    0.88386     0.88148
alpha_3                               0.88264      0.00076    0.88383     0.88144
alpha_4                               0.88263      0.00076    0.88382     0.88144
alpha_5                               0.88266      0.00076    0.88386     0.88147
alpha_6                               0.88266      0.00076    0.88386     0.88147
alpha_7                               0.88266      0.00076    0.88385     0.88146
alpha_8                               0.88268      0.00076    0.88388     0.88149
alpha_9                               0.88260      0.00076    0.88379     0.88141
Alpha_loss                            -0.83788     0.00567    -0.82859    -0.84593
Training/policy_loss                  -5.55874     0.03216    -5.51083    -5.60878
Training/qf1_loss                     1467.17037   406.72718  2600.05713  1030.66235
Training/qf2_loss                     1463.15797   406.41389  2595.17700  1026.79199
Training/pf_norm                      0.12891      0.03018    0.18720     0.08861
Training/qf1_norm                     155.50263    10.94900   182.80746   141.59415
Training/qf2_norm                     155.61363    11.18079   183.29263   141.79489
log_std/mean                          -0.14328     0.00012    -0.14306    -0.14342
log_std/std                           0.00577      0.00034    0.00627     0.00521
log_std/max                           -0.12903     0.00089    -0.12738    -0.13012
log_std/min                           -0.15654     0.00070    -0.15525    -0.15740
log_probs/mean                        -2.72814     0.00652    -2.71414    -2.73605
log_probs/std                         0.24694      0.01113    0.26387     0.22566
log_probs/max                         -2.08704     0.03725    -2.02585    -2.15028
log_probs/min                         -5.22307     0.60237    -4.37149    -6.44120
mean/mean                             -0.01146     0.00050    -0.01050    -0.01199
mean/std                              0.03759      0.00016    0.03779     0.03734
mean/max                              0.05970      0.00240    0.06348     0.05638
mean/min                              -0.09634     0.00056    -0.09552    -0.09714
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 4, 7, 8, 2, 9, 3, 0, 6, 1]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7281885147094727 0.0026242733001708984
train_time 1.7321925163269043
snapshot at best
2023-09-06 13:32:43,568 MainThread INFO: EPOCH:42
2023-09-06 13:32:43,568 MainThread INFO: Time Consumed:2.5598371028900146s
2023-09-06 13:32:43,569 MainThread INFO: Total Frames:64500s
 11%|‚ñà         | 43/400 [01:42<17:46,  2.99s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1766.57632
Train_Epoch_Reward                    15305.27757
Running_Training_Average_Rewards      1349.97613
Explore_Time                          0.00511
Train___Time                          1.73219
Eval____Time                          0.00408
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.19119
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.31531
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.23713
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.23515
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.90556
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.42605
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.72896
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18435.25486
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.59465
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.45019
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.17078      0.38843    9.88751     8.58823
alpha_0                               0.87995      0.00076    0.88113     0.87876
alpha_1                               0.88001      0.00076    0.88120     0.87882
alpha_2                               0.88003      0.00076    0.88121     0.87884
alpha_3                               0.87999      0.00076    0.88118     0.87880
alpha_4                               0.87998      0.00076    0.88117     0.87880
alpha_5                               0.88002      0.00076    0.88121     0.87883
alpha_6                               0.88002      0.00076    0.88121     0.87883
alpha_7                               0.88001      0.00076    0.88120     0.87883
alpha_8                               0.88004      0.00076    0.88123     0.87885
alpha_9                               0.87995      0.00076    0.88114     0.87877
Alpha_loss                            -0.85794     0.00588    -0.84913    -0.86744
Training/policy_loss                  -5.67510     0.03490    -5.61574    -5.73150
Training/qf1_loss                     1394.35319   181.43531  1657.04004  1139.53223
Training/qf2_loss                     1390.66541   181.02565  1652.55469  1136.48376
Training/pf_norm                      0.12592      0.02366    0.16263     0.08222
Training/qf1_norm                     165.50552    7.64168    178.25677   151.70071
Training/qf2_norm                     164.77407    7.81171    178.71634   151.84859
log_std/mean                          -0.14297     0.00011    -0.14271    -0.14310
log_std/std                           0.00628      0.00009    0.00636     0.00607
log_std/max                           -0.12794     0.00070    -0.12734    -0.12954
log_std/min                           -0.15736     0.00107    -0.15588    -0.15899
log_probs/mean                        -2.72718     0.00296    -2.72278    -2.73057
log_probs/std                         0.24220      0.01532    0.27369     0.21766
log_probs/max                         -2.04808     0.05910    -1.96434    -2.14017
log_probs/min                         -4.80390     0.40060    -4.29702    -5.73723
mean/mean                             -0.01212     0.00005    -0.01202    -0.01219
mean/std                              0.03747      0.00012    0.03760     0.03722
mean/max                              0.05544      0.00049    0.05651     0.05458
mean/min                              -0.09782     0.00082    -0.09630    -0.09875
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 0, 1, 2, 4, 3, 8, 6, 9, 5]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8252880573272705 0.0022125244140625
train_time 1.8288154602050781
snapshot at best
2023-09-06 13:32:46,301 MainThread INFO: EPOCH:43
2023-09-06 13:32:46,302 MainThread INFO: Time Consumed:2.3422813415527344s
2023-09-06 13:32:46,302 MainThread INFO: Total Frames:66000s
 11%|‚ñà         | 44/400 [01:44<17:18,  2.92s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1838.27045
Train_Epoch_Reward                    17217.23836
Running_Training_Average_Rewards      1614.03058
Explore_Time                          0.00473
Train___Time                          1.82882
Eval____Time                          0.00522
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.44021
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.86269
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56028
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.84322
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.62077
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.11388
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.37349
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19457.19391
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.19641
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.98658
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.29932      0.50270    10.03725    8.40055
alpha_0                               0.87731      0.00076    0.87850     0.87613
alpha_1                               0.87738      0.00076    0.87856     0.87619
alpha_2                               0.87739      0.00076    0.87858     0.87621
alpha_3                               0.87735      0.00076    0.87854     0.87617
alpha_4                               0.87735      0.00076    0.87853     0.87616
alpha_5                               0.87738      0.00076    0.87857     0.87620
alpha_6                               0.87738      0.00076    0.87857     0.87620
alpha_7                               0.87738      0.00076    0.87856     0.87620
alpha_8                               0.87740      0.00076    0.87859     0.87622
alpha_9                               0.87732      0.00076    0.87850     0.87613
Alpha_loss                            -0.87846     0.00623    -0.86885    -0.88899
Training/policy_loss                  -5.79180     0.03584    -5.73488    -5.85148
Training/qf1_loss                     1567.40500   289.60065  1995.06018  1048.51184
Training/qf2_loss                     1563.76284   289.05768  1990.23853  1046.06543
Training/pf_norm                      0.12217      0.02331    0.15982     0.08948
Training/qf1_norm                     174.06553    10.76870   188.47418   155.36057
Training/qf2_norm                     172.73342    11.25435   188.13293   152.65524
log_std/mean                          -0.14182     0.00053    -0.14115    -0.14264
log_std/std                           0.00592      0.00004    0.00600     0.00586
log_std/max                           -0.12674     0.00125    -0.12507    -0.12862
log_std/min                           -0.15978     0.00104    -0.15752    -0.16072
log_probs/mean                        -2.72973     0.00598    -2.72148    -2.74070
log_probs/std                         0.24772      0.01786    0.28265     0.22534
log_probs/max                         -2.06284     0.05466    -1.97198    -2.11515
log_probs/min                         -4.97886     0.56886    -4.14924    -5.93253
mean/mean                             -0.01249     0.00031    -0.01210    -0.01306
mean/std                              0.03633      0.00048    0.03711     0.03579
mean/max                              0.05443      0.00066    0.05560     0.05301
mean/min                              -0.09781     0.00036    -0.09712    -0.09852
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 6, 9, 4, 0, 2, 8, 5, 1, 3]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.777531623840332 0.0021507740020751953
train_time 1.7834150791168213
snapshot at best
2023-09-06 13:32:49,436 MainThread INFO: EPOCH:44
2023-09-06 13:32:49,436 MainThread INFO: Time Consumed:2.3266804218292236s
2023-09-06 13:32:49,437 MainThread INFO: Total Frames:67500s
 11%|‚ñà‚ñè        | 45/400 [01:47<17:36,  2.98s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1912.84844
Train_Epoch_Reward                    26712.08805
Running_Training_Average_Rewards      1974.48680
Explore_Time                          0.00486
Train___Time                          1.78342
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.49491
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.23223
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.14044
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.30353
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.98213
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.40755
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.01515
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20301.83379
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.54759
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.62423
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.74830      0.55631    10.46057    8.68594
alpha_0                               0.87469      0.00075    0.87587     0.87350
alpha_1                               0.87475      0.00075    0.87593     0.87356
alpha_2                               0.87476      0.00075    0.87595     0.87358
alpha_3                               0.87472      0.00075    0.87590     0.87354
alpha_4                               0.87471      0.00075    0.87590     0.87353
alpha_5                               0.87475      0.00075    0.87593     0.87357
alpha_6                               0.87475      0.00075    0.87594     0.87357
alpha_7                               0.87475      0.00075    0.87594     0.87357
alpha_8                               0.87478      0.00075    0.87596     0.87360
alpha_9                               0.87469      0.00075    0.87587     0.87350
Alpha_loss                            -0.89891     0.00502    -0.89088    -0.90769
Training/policy_loss                  -5.90862     0.03341    -5.85743    -5.96300
Training/qf1_loss                     1806.89263   227.43635  2160.76367  1427.81616
Training/qf2_loss                     1802.80613   227.75037  2156.76514  1423.05371
Training/pf_norm                      0.12051      0.02714    0.18627     0.08667
Training/qf1_norm                     189.05360    12.27118   204.43567   164.69128
Training/qf2_norm                     188.05449    12.14315   203.47260   165.63420
log_std/mean                          -0.14069     0.00033    -0.14024    -0.14119
log_std/std                           0.00609      0.00005    0.00615     0.00599
log_std/max                           -0.12339     0.00067    -0.12223    -0.12432
log_std/min                           -0.16064     0.00067    -0.15916    -0.16151
log_probs/mean                        -2.73170     0.00733    -2.72211    -2.74441
log_probs/std                         0.24422      0.01115    0.26672     0.22588
log_probs/max                         -2.06521     0.06319    -1.92498    -2.15383
log_probs/min                         -4.83778     0.41740    -4.24517    -5.48694
mean/mean                             -0.01427     0.00054    -0.01331    -0.01485
mean/std                              0.03641      0.00051    0.03733     0.03581
mean/max                              0.05617      0.00122    0.05829     0.05448
mean/min                              -0.10139     0.00235    -0.09875    -0.10577
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 9, 6, 7, 4, 1, 2, 5, 0, 3]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.095771551132202 0.0022478103637695312
train_time 2.099369764328003
2023-09-06 13:32:52,345 MainThread INFO: EPOCH:45
2023-09-06 13:32:52,346 MainThread INFO: Time Consumed:2.115429162979126s
2023-09-06 13:32:52,346 MainThread INFO: Total Frames:69000s
 12%|‚ñà‚ñè        | 46/400 [01:50<17:33,  2.98s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1964.69659
Train_Epoch_Reward                    50816.29010
Running_Training_Average_Rewards      3158.18722
Explore_Time                          0.00446
Train___Time                          2.09937
Eval____Time                          0.00537
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.21555
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.89142
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.99627
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.38159
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.00347
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.19452
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.69040
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19985.19761
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.29714
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.91204
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.41068      0.59771    10.54808    8.43093
alpha_0                               0.87207      0.00075    0.87324     0.87089
alpha_1                               0.87212      0.00075    0.87330     0.87095
alpha_2                               0.87214      0.00075    0.87332     0.87097
alpha_3                               0.87210      0.00075    0.87328     0.87092
alpha_4                               0.87209      0.00075    0.87327     0.87091
alpha_5                               0.87213      0.00075    0.87331     0.87095
alpha_6                               0.87213      0.00075    0.87331     0.87096
alpha_7                               0.87213      0.00075    0.87331     0.87096
alpha_8                               0.87216      0.00075    0.87334     0.87098
alpha_9                               0.87206      0.00075    0.87324     0.87089
Alpha_loss                            -0.91868     0.00523    -0.91128    -0.92624
Training/policy_loss                  -6.02389     0.02887    -5.98587    -6.06934
Training/qf1_loss                     1669.92389   355.10239  2378.76440  1184.95410
Training/qf2_loss                     1666.24237   354.89552  2374.86450  1181.83777
Training/pf_norm                      0.13300      0.01397    0.15671     0.11831
Training/qf1_norm                     188.95488    12.60210   213.24930   170.08743
Training/qf2_norm                     187.23934    12.33179   211.10306   167.94675
log_std/mean                          -0.13917     0.00057    -0.13847    -0.14009
log_std/std                           0.00616      0.00010    0.00635     0.00606
log_std/max                           -0.12191     0.00085    -0.12091    -0.12325
log_std/min                           -0.15941     0.00050    -0.15844    -0.16020
log_probs/mean                        -2.72854     0.00725    -2.71749    -2.74098
log_probs/std                         0.25610      0.01360    0.27943     0.23983
log_probs/max                         -2.05130     0.05501    -1.95821    -2.14155
log_probs/min                         -5.30414     0.46330    -4.41379    -6.00569
mean/mean                             -0.01457     0.00015    -0.01438    -0.01484
mean/std                              0.03889      0.00082    0.04014     0.03762
mean/max                              0.06313      0.00211    0.06575     0.05936
mean/min                              -0.10938     0.00261    -0.10575    -0.11311
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 2, 1, 0, 5, 3, 9, 7, 8, 6]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.859010696411133 0.0022253990173339844
train_time 2.8625969886779785
2023-09-06 13:32:55,432 MainThread INFO: EPOCH:46
2023-09-06 13:32:55,433 MainThread INFO: Time Consumed:2.891655683517456s
2023-09-06 13:32:55,433 MainThread INFO: Total Frames:70500s
 12%|‚ñà‚ñè        | 47/400 [01:53<17:35,  2.99s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1969.22241
Train_Epoch_Reward                    33408.59644
Running_Training_Average_Rewards      3697.89915
Explore_Time                          0.01706
Train___Time                          2.86260
Eval____Time                          0.00599
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.27993
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.95868
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.85792
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.66513
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.67214
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.73069
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.52396
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19598.36059
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.50186
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.19907
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.03492     0.79271    11.31304    8.82563
alpha_0                               0.86945      0.00075    0.87063     0.86828
alpha_1                               0.86951      0.00075    0.87069     0.86834
alpha_2                               0.86953      0.00075    0.87070     0.86836
alpha_3                               0.86948      0.00075    0.87066     0.86831
alpha_4                               0.86948      0.00075    0.87065     0.86830
alpha_5                               0.86952      0.00075    0.87069     0.86835
alpha_6                               0.86952      0.00075    0.87069     0.86835
alpha_7                               0.86952      0.00075    0.87070     0.86835
alpha_8                               0.86955      0.00075    0.87072     0.86837
alpha_9                               0.86945      0.00075    0.87063     0.86828
Alpha_loss                            -0.93890     0.00574    -0.93086    -0.94681
Training/policy_loss                  -6.14015     0.03328    -6.08978    -6.18438
Training/qf1_loss                     2016.24951   448.73672  2571.32227  1362.57092
Training/qf2_loss                     2011.82118   448.50064  2567.41406  1358.09949
Training/pf_norm                      0.12777      0.02155    0.15787     0.08088
Training/qf1_norm                     208.23545    16.45975   233.56499   180.01317
Training/qf2_norm                     207.01907    16.34439   231.42793   180.03749
log_std/mean                          -0.13989     0.00059    -0.13890    -0.14072
log_std/std                           0.00703      0.00041    0.00772     0.00646
log_std/max                           -0.12326     0.00077    -0.12164    -0.12424
log_std/min                           -0.16348     0.00209    -0.16001    -0.16638
log_probs/mean                        -2.72876     0.00969    -2.71251    -2.74920
log_probs/std                         0.25248      0.01579    0.27660     0.22175
log_probs/max                         -1.97412     0.07349    -1.83337    -2.10099
log_probs/min                         -5.09792     0.62573    -4.18491    -6.08099
mean/mean                             -0.01507     0.00040    -0.01451    -0.01579
mean/std                              0.04119      0.00053    0.04200     0.04038
mean/max                              0.06797      0.00107    0.06971     0.06618
mean/min                              -0.11649     0.00189    -0.11364    -0.11944
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 2, 3, 5, 4, 6, 1, 7, 0, 9]
replay_buffer._size: [7356 7359 7350 7358 7356 7350 7350 7350 7356 7350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.004983901977539 0.0022249221801757812
train_time 3.0085692405700684
2023-09-06 13:32:58,703 MainThread INFO: EPOCH:47
2023-09-06 13:32:58,704 MainThread INFO: Time Consumed:3.094559669494629s
2023-09-06 13:32:58,704 MainThread INFO: Total Frames:72000s
 12%|‚ñà‚ñè        | 48/400 [01:57<18:03,  3.08s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1958.54346
Train_Epoch_Reward                    12294.34600
Running_Training_Average_Rewards      3217.30775
Explore_Time                          0.07444
Train___Time                          3.00857
Eval____Time                          0.00584
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.92076
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.82517
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.10992
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.66701
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.48454
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.51819
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.70431
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19988.69280
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.45117
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.29434
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.02958     0.85292    11.25768    8.85042
alpha_0                               0.86685      0.00075    0.86802     0.86568
alpha_1                               0.86691      0.00075    0.86808     0.86574
alpha_2                               0.86693      0.00075    0.86810     0.86576
alpha_3                               0.86688      0.00075    0.86805     0.86571
alpha_4                               0.86687      0.00075    0.86804     0.86570
alpha_5                               0.86692      0.00075    0.86809     0.86575
alpha_6                               0.86692      0.00075    0.86809     0.86575
alpha_7                               0.86692      0.00075    0.86809     0.86576
alpha_8                               0.86694      0.00075    0.86811     0.86577
alpha_9                               0.86684      0.00075    0.86802     0.86567
Alpha_loss                            -0.95859     0.00571    -0.94800    -0.96644
Training/policy_loss                  -6.25656     0.03351    -6.19408    -6.30155
Training/qf1_loss                     1942.58593   424.32833  2706.32495  1328.72681
Training/qf2_loss                     1938.32874   423.97755  2701.29028  1324.82739
Training/pf_norm                      0.13529      0.01647    0.15758     0.11140
Training/qf1_norm                     215.17733    18.77155   245.13213   188.63437
Training/qf2_norm                     213.49881    18.57948   243.33829   187.44907
log_std/mean                          -0.14106     0.00017    -0.14077    -0.14128
log_std/std                           0.00809      0.00011    0.00824     0.00784
log_std/max                           -0.12360     0.00063    -0.12242    -0.12450
log_std/min                           -0.16736     0.00066    -0.16655    -0.16850
log_probs/mean                        -2.72525     0.00679    -2.71454    -2.73429
log_probs/std                         0.25383      0.01247    0.27762     0.23288
log_probs/max                         -1.99939     0.05289    -1.89359    -2.07102
log_probs/min                         -5.11572     0.69605    -4.24781    -6.81692
mean/mean                             -0.01695     0.00047    -0.01605    -0.01744
mean/std                              0.04257      0.00025    0.04298     0.04216
mean/max                              0.06894      0.00052    0.06948     0.06776
mean/min                              -0.12296     0.00138    -0.12024    -0.12508
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 2, 8, 7, 5, 4, 6, 0, 9, 1]
replay_buffer._size: [7508 7508 7507 7508 7508 7505 7508 7505 7507 7507]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.8919272422790527 0.002105236053466797
train_time 2.895359992980957
2023-09-06 13:33:01,925 MainThread INFO: EPOCH:48
2023-09-06 13:33:01,926 MainThread INFO: Time Consumed:3.046657085418701s
2023-09-06 13:33:01,926 MainThread INFO: Total Frames:73500s
 12%|‚ñà‚ñè        | 49/400 [02:00<18:15,  3.12s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1943.46033
Train_Epoch_Reward                    11306.59612
Running_Training_Average_Rewards      1900.31795
Explore_Time                          0.13951
Train___Time                          2.89536
Eval____Time                          0.00590
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.00714
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.77205
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.15765
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.79414
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.35089
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -26.07156
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.51103
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19531.92107
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.48840
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.64690
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.65636      1.13700    11.55323    8.09022
alpha_0                               0.86426      0.00074    0.86542     0.86309
alpha_1                               0.86431      0.00074    0.86548     0.86314
alpha_2                               0.86433      0.00074    0.86550     0.86316
alpha_3                               0.86428      0.00074    0.86545     0.86311
alpha_4                               0.86427      0.00075    0.86544     0.86310
alpha_5                               0.86432      0.00074    0.86549     0.86316
alpha_6                               0.86432      0.00074    0.86549     0.86315
alpha_7                               0.86433      0.00074    0.86550     0.86317
alpha_8                               0.86435      0.00074    0.86551     0.86318
alpha_9                               0.86424      0.00075    0.86541     0.86307
Alpha_loss                            -0.97899     0.00549    -0.97040    -0.98842
Training/policy_loss                  -6.37215     0.03031    -6.32664    -6.42894
Training/qf1_loss                     1730.94756   549.87633  2618.40234  907.05780
Training/qf2_loss                     1726.73920   549.25435  2612.83374  904.01855
Training/pf_norm                      0.12848      0.01641    0.15102     0.09717
Training/qf1_norm                     213.41149    26.57536   257.00122   178.59091
Training/qf2_norm                     211.69201    26.86920   255.49396   176.21136
log_std/mean                          -0.14201     0.00066    -0.14106    -0.14299
log_std/std                           0.00879      0.00024    0.00907     0.00835
log_std/max                           -0.12161     0.00073    -0.12053    -0.12295
log_std/min                           -0.17017     0.00194    -0.16741    -0.17304
log_probs/mean                        -2.72683     0.00437    -2.72066    -2.73570
log_probs/std                         0.25634      0.01620    0.28863     0.23821
log_probs/max                         -1.98749     0.05569    -1.87355    -2.05046
log_probs/min                         -4.85697     0.47469    -4.21382    -5.62857
mean/mean                             -0.01846     0.00077    -0.01731    -0.01958
mean/std                              0.04465      0.00102    0.04640     0.04324
mean/max                              0.07005      0.00126    0.07193     0.06837
mean/min                              -0.13118     0.00417    -0.12535    -0.13774
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 8, 6, 2, 7, 3, 1, 9, 5, 0]
replay_buffer._size: [7659 7656 7658 7658 7655 7658 7658 7658 7655 7657]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.049298048019409 0.0022611618041992188
train_time 3.05291748046875
2023-09-06 13:33:05,250 MainThread INFO: EPOCH:49
2023-09-06 13:33:05,251 MainThread INFO: Time Consumed:3.1992526054382324s
2023-09-06 13:33:05,251 MainThread INFO: Total Frames:75000s
 12%|‚ñà‚ñé        | 50/400 [02:03<18:35,  3.19s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1941.34846
Train_Epoch_Reward                    10948.34282
Running_Training_Average_Rewards      1151.64283
Explore_Time                          0.13573
Train___Time                          3.05292
Eval____Time                          0.00569
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.94833
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.67353
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.09569
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.91123
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.85197
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.75420
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.59424
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19533.93240
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.53399
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.95402
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.68281      0.65119    10.37276    8.47202
alpha_0                               0.86167      0.00074    0.86283     0.86051
alpha_1                               0.86172      0.00074    0.86288     0.86056
alpha_2                               0.86174      0.00074    0.86291     0.86058
alpha_3                               0.86169      0.00074    0.86285     0.86052
alpha_4                               0.86168      0.00074    0.86284     0.86051
alpha_5                               0.86173      0.00074    0.86290     0.86057
alpha_6                               0.86173      0.00074    0.86290     0.86057
alpha_7                               0.86175      0.00074    0.86291     0.86059
alpha_8                               0.86176      0.00074    0.86292     0.86060
alpha_9                               0.86165      0.00074    0.86281     0.86049
Alpha_loss                            -0.99948     0.00548    -0.99194    -1.00875
Training/policy_loss                  -6.49591     0.03261    -6.45318    -6.55631
Training/qf1_loss                     1725.49585   345.70412  2297.19971  1227.79968
Training/qf2_loss                     1721.72935   345.13290  2290.68628  1224.50391
Training/pf_norm                      0.12117      0.01890    0.14437     0.09219
Training/qf1_norm                     221.21478    15.46928   239.72800   191.34348
Training/qf2_norm                     218.58201    15.65538   236.74460   189.53018
log_std/mean                          -0.14339     0.00032    -0.14294    -0.14404
log_std/std                           0.00910      0.00004    0.00916     0.00903
log_std/max                           -0.12055     0.00053    -0.11986    -0.12133
log_std/min                           -0.17495     0.00118    -0.17213    -0.17631
log_probs/mean                        -2.72894     0.00523    -2.72179    -2.73941
log_probs/std                         0.26282      0.01228    0.28746     0.24605
log_probs/max                         -1.95291     0.07954    -1.82834    -2.09950
log_probs/min                         -5.16089     0.38698    -4.36706    -5.68816
mean/mean                             -0.02037     0.00039    -0.01975    -0.02105
mean/std                              0.04904      0.00149    0.05151     0.04686
mean/max                              0.07524      0.00163    0.07797     0.07319
mean/min                              -0.14659     0.00493    -0.13944    -0.15450
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 4, 8, 0, 6, 3, 1, 7, 9, 5]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.91926908493042 0.0021309852600097656
train_time 2.9227161407470703
2023-09-06 13:33:08,376 MainThread INFO: EPOCH:50
2023-09-06 13:33:08,377 MainThread INFO: Time Consumed:2.9537527561187744s
2023-09-06 13:33:08,377 MainThread INFO: Total Frames:76500s
 13%|‚ñà‚ñé        | 51/400 [02:06<18:23,  3.16s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1908.86563
Train_Epoch_Reward                    11048.91111
Running_Training_Average_Rewards      1110.12833
Explore_Time                          0.01979
Train___Time                          2.92272
Eval____Time                          0.00505
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.15547
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.03791
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.19142
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.09184
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -26.13794
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.58109
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.83773
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19019.16282
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.91467
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.98237
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.68001      0.69450    10.56060    8.63550
alpha_0                               0.85909      0.00074    0.86025     0.85794
alpha_1                               0.85914      0.00074    0.86030     0.85798
alpha_2                               0.85916      0.00074    0.86032     0.85800
alpha_3                               0.85911      0.00074    0.86027     0.85795
alpha_4                               0.85909      0.00074    0.86026     0.85793
alpha_5                               0.85915      0.00074    0.86031     0.85800
alpha_6                               0.85915      0.00074    0.86031     0.85800
alpha_7                               0.85917      0.00074    0.86033     0.85801
alpha_8                               0.85918      0.00074    0.86034     0.85802
alpha_9                               0.85907      0.00074    0.86023     0.85791
Alpha_loss                            -1.01810     0.00570    -1.00858    -1.02527
Training/policy_loss                  -6.60867     0.03289    -6.55361    -6.65068
Training/qf1_loss                     1612.53835   215.68872  1829.88403  1179.38013
Training/qf2_loss                     1608.45568   215.32708  1826.11230  1174.91882
Training/pf_norm                      0.12431      0.01789    0.15311     0.09157
Training/qf1_norm                     228.34870    16.97937   251.28944   202.69592
Training/qf2_norm                     225.97410    17.27510   249.63315   200.91084
log_std/mean                          -0.14425     0.00017    -0.14397    -0.14446
log_std/std                           0.00919      0.00006    0.00931     0.00911
log_std/max                           -0.12158     0.00070    -0.12079    -0.12283
log_std/min                           -0.17840     0.00083    -0.17699    -0.17955
log_probs/mean                        -2.71866     0.00903    -2.70626    -2.73302
log_probs/std                         0.25916      0.00878    0.27744     0.24791
log_probs/max                         -1.92232     0.08985    -1.76646    -2.02590
log_probs/min                         -4.84851     0.43867    -4.40641    -5.83575
mean/mean                             -0.02163     0.00015    -0.02132    -0.02181
mean/std                              0.05444      0.00140    0.05649     0.05208
mean/max                              0.08141      0.00231    0.08482     0.07714
mean/min                              -0.16283     0.00364    -0.15648    -0.16772
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 8, 7, 4, 5, 6, 9, 1, 2, 0]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.0161826610565186 0.002161741256713867
train_time 3.0196690559387207
2023-09-06 13:33:11,594 MainThread INFO: EPOCH:51
2023-09-06 13:33:11,594 MainThread INFO: Time Consumed:3.0445399284362793s
2023-09-06 13:33:11,595 MainThread INFO: Total Frames:78000s
 13%|‚ñà‚ñé        | 52/400 [02:10<18:30,  3.19s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1886.37607
Train_Epoch_Reward                    10887.97441
Running_Training_Average_Rewards      1096.17428
Explore_Time                          0.01415
Train___Time                          3.01967
Eval____Time                          0.00519
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.51530
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.44549
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.53032
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.15635
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.66576
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -31.83428
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.27324
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18868.92685
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.25209
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.81950
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.42916     0.97256    12.10684    8.82035
alpha_0                               0.85653      0.00074    0.85768     0.85538
alpha_1                               0.85657      0.00074    0.85772     0.85541
alpha_2                               0.85659      0.00074    0.85774     0.85543
alpha_3                               0.85653      0.00074    0.85769     0.85538
alpha_4                               0.85652      0.00074    0.85768     0.85536
alpha_5                               0.85658      0.00074    0.85774     0.85543
alpha_6                               0.85658      0.00074    0.85774     0.85543
alpha_7                               0.85660      0.00074    0.85776     0.85545
alpha_8                               0.85661      0.00074    0.85776     0.85545
alpha_9                               0.85650      0.00074    0.85765     0.85534
Alpha_loss                            -1.03872     0.00578    -1.03082    -1.04749
Training/policy_loss                  -6.73141     0.03574    -6.67649    -6.78909
Training/qf1_loss                     2260.50144   687.40435  3332.30933  1215.72546
Training/qf2_loss                     2255.87979   686.49409  3326.29370  1211.99536
Training/pf_norm                      0.14401      0.02309    0.19191     0.10317
Training/qf1_norm                     254.31232    26.22269   300.89966   210.16371
Training/qf2_norm                     251.77003    26.69376   299.00888   207.72044
log_std/mean                          -0.14396     0.00005    -0.14385    -0.14408
log_std/std                           0.00901      0.00006    0.00909     0.00890
log_std/max                           -0.12396     0.00085    -0.12223    -0.12546
log_std/min                           -0.17860     0.00067    -0.17743    -0.17953
log_probs/mean                        -2.72173     0.00734    -2.71061    -2.73571
log_probs/std                         0.26738      0.00784    0.27783     0.25308
log_probs/max                         -1.96372     0.05011    -1.87351    -2.04220
log_probs/min                         -5.01027     0.56400    -4.26663    -6.20039
mean/mean                             -0.02108     0.00027    -0.02062    -0.02142
mean/std                              0.05899      0.00126    0.06078     0.05685
mean/max                              0.08869      0.00209    0.09212     0.08507
mean/min                              -0.17441     0.00387    -0.16847    -0.17956
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 9, 5, 3, 7, 4, 6, 2, 1, 8]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.1276497840881348 0.002142667770385742
train_time 3.131115198135376
2023-09-06 13:33:14,916 MainThread INFO: EPOCH:52
2023-09-06 13:33:14,916 MainThread INFO: Time Consumed:3.1539719104766846s
2023-09-06 13:33:14,917 MainThread INFO: Total Frames:79500s
 13%|‚ñà‚ñé        | 53/400 [02:13<18:41,  3.23s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1876.30681
Train_Epoch_Reward                    17976.99060
Running_Training_Average_Rewards      1330.46254
Explore_Time                          0.01169
Train___Time                          3.13112
Eval____Time                          0.00524
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.88517
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.47178
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.00566
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.76446
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -29.16145
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -34.67812
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.41563
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19246.49621
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.12504
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.45141
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.55434     0.70009    11.92842    9.61639
alpha_0                               0.85397      0.00073    0.85512     0.85282
alpha_1                               0.85400      0.00074    0.85515     0.85285
alpha_2                               0.85402      0.00074    0.85518     0.85287
alpha_3                               0.85397      0.00074    0.85512     0.85281
alpha_4                               0.85395      0.00074    0.85511     0.85280
alpha_5                               0.85402      0.00074    0.85517     0.85287
alpha_6                               0.85402      0.00074    0.85517     0.85287
alpha_7                               0.85404      0.00073    0.85519     0.85289
alpha_8                               0.85404      0.00073    0.85520     0.85289
alpha_9                               0.85393      0.00074    0.85508     0.85278
Alpha_loss                            -1.05869     0.00487    -1.05138    -1.06697
Training/policy_loss                  -6.85688     0.02966    -6.81102    -6.90474
Training/qf1_loss                     2224.06382   444.97321  2823.69531  1289.17908
Training/qf2_loss                     2219.22622   444.73570  2817.35596  1284.91174
Training/pf_norm                      0.13537      0.02798    0.18225     0.07861
Training/qf1_norm                     264.07872    19.57111   297.72873   234.66089
Training/qf2_norm                     261.58993    18.99890   295.33911   232.30592
log_std/mean                          -0.14309     0.00047    -0.14257    -0.14386
log_std/std                           0.00916      0.00022    0.00961     0.00894
log_std/max                           -0.12466     0.00054    -0.12368    -0.12532
log_std/min                           -0.17674     0.00095    -0.17541    -0.17820
log_probs/mean                        -2.72064     0.00765    -2.70902    -2.73185
log_probs/std                         0.27694      0.01311    0.29620     0.25494
log_probs/max                         -1.83597     0.08548    -1.63934    -1.94752
log_probs/min                         -5.06519     0.56006    -3.87752    -5.86323
mean/mean                             -0.01936     0.00061    -0.01854    -0.02038
mean/std                              0.06235      0.00080    0.06360     0.06105
mean/max                              0.09613      0.00244    0.09993     0.09250
mean/min                              -0.18623     0.00361    -0.18050    -0.19180
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 6, 3, 2, 5, 1, 0, 4, 7, 9]
replay_buffer._size: [8250 8250 8250 8250 8250 8250 8250 8250 8250 8250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.2013585567474365 0.0024576187133789062
train_time 3.2051262855529785
2023-09-06 13:33:18,309 MainThread INFO: EPOCH:53
2023-09-06 13:33:18,309 MainThread INFO: Time Consumed:3.2232038974761963s
2023-09-06 13:33:18,310 MainThread INFO: Total Frames:81000s
 14%|‚ñà‚ñé        | 54/400 [02:16<18:51,  3.27s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1911.00569
Train_Epoch_Reward                    69111.98105
Running_Training_Average_Rewards      3265.89820
Explore_Time                          0.00780
Train___Time                          3.20513
Eval____Time                          0.00443
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.12601
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.18417
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.30339
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04189
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -30.30252
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -36.83565
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.66741
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20073.42877
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.75311
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.01600
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.48500     0.84839    11.52320    9.24894
alpha_0                               0.85142      0.00073    0.85256     0.85027
alpha_1                               0.85144      0.00073    0.85259     0.85030
alpha_2                               0.85146      0.00073    0.85261     0.85032
alpha_3                               0.85141      0.00073    0.85256     0.85026
alpha_4                               0.85139      0.00073    0.85254     0.85024
alpha_5                               0.85146      0.00073    0.85261     0.85031
alpha_6                               0.85146      0.00073    0.85261     0.85031
alpha_7                               0.85149      0.00073    0.85264     0.85034
alpha_8                               0.85149      0.00073    0.85264     0.85034
alpha_9                               0.85137      0.00073    0.85252     0.85022
Alpha_loss                            -1.07936     0.00625    -1.06850    -1.08887
Training/policy_loss                  -6.98274     0.03719    -6.92486    -7.03723
Training/qf1_loss                     2181.72148   544.67707  3174.87720  1550.75330
Training/qf2_loss                     2178.29857   543.81946  3168.78955  1548.53516
Training/pf_norm                      0.13366      0.02427    0.17189     0.09919
Training/qf1_norm                     271.95836    23.56449   303.21234   238.40631
Training/qf2_norm                     267.10546    23.80472   296.44333   233.62120
log_std/mean                          -0.14248     0.00011    -0.14233    -0.14274
log_std/std                           0.01017      0.00026    0.01050     0.00972
log_std/max                           -0.12226     0.00069    -0.12120    -0.12318
log_std/min                           -0.17922     0.00138    -0.17704    -0.18146
log_probs/mean                        -2.72390     0.00648    -2.71265    -2.73611
log_probs/std                         0.28744      0.01299    0.30922     0.26739
log_probs/max                         -1.82333     0.10490    -1.67788    -1.96173
log_probs/min                         -5.46406     1.08221    -4.41366    -8.02627
mean/mean                             -0.01935     0.00073    -0.01855    -0.02056
mean/std                              0.06504      0.00083    0.06637     0.06389
mean/max                              0.10114      0.00033    0.10156     0.10052
mean/min                              -0.19870     0.00463    -0.19296    -0.20668
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 0, 6, 8, 1, 4, 3, 5, 2, 9]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.938227653503418 0.0021147727966308594
train_time 2.941652774810791
snapshot at best
2023-09-06 13:33:22,352 MainThread INFO: EPOCH:54
2023-09-06 13:33:22,352 MainThread INFO: Time Consumed:3.876892328262329s
2023-09-06 13:33:22,353 MainThread INFO: Total Frames:82500s
 14%|‚ñà‚ñç        | 55/400 [02:20<20:06,  3.50s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1960.76895
Train_Epoch_Reward                    22297.40702
Running_Training_Average_Rewards      3646.21262
Explore_Time                          0.03760
Train___Time                          2.94165
Eval____Time                          0.00538
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.84891
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.78712
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.40865
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.82354
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -30.89250
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -37.57655
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.15171
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20373.23420
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.44146
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.97147
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.02965     0.79188    12.49105    10.01774
alpha_0                               0.84887      0.00073    0.85002     0.84773
alpha_1                               0.84889      0.00073    0.85004     0.84775
alpha_2                               0.84892      0.00073    0.85006     0.84777
alpha_3                               0.84886      0.00073    0.85001     0.84772
alpha_4                               0.84884      0.00073    0.84999     0.84769
alpha_5                               0.84891      0.00073    0.85006     0.84777
alpha_6                               0.84891      0.00073    0.85006     0.84777
alpha_7                               0.84895      0.00073    0.85009     0.84780
alpha_8                               0.84894      0.00073    0.85009     0.84780
alpha_9                               0.84882      0.00073    0.84997     0.84768
Alpha_loss                            -1.09963     0.00603    -1.08968    -1.10924
Training/policy_loss                  -7.10974     0.03619    -7.04632    -7.16077
Training/qf1_loss                     2476.48938   484.75193  3373.32349  1890.90320
Training/qf2_loss                     2472.08584   484.71178  3368.60474  1887.47754
Training/pf_norm                      0.13987      0.03226    0.19301     0.07970
Training/qf1_norm                     294.07860    23.07549   332.32196   261.66721
Training/qf2_norm                     290.04019    21.81048   327.44489   260.54797
log_std/mean                          -0.14389     0.00083    -0.14272    -0.14530
log_std/std                           0.01067      0.00024    0.01116     0.01044
log_std/max                           -0.12414     0.00162    -0.12182    -0.12699
log_std/min                           -0.18180     0.00107    -0.17981    -0.18402
log_probs/mean                        -2.72462     0.00726    -2.71331    -2.74013
log_probs/std                         0.29219      0.01456    0.32812     0.27332
log_probs/max                         -1.81566     0.07971    -1.61946    -1.88799
log_probs/min                         -5.18262     0.70541    -4.45897    -7.03686
mean/mean                             -0.02213     0.00075    -0.02083    -0.02329
mean/std                              0.06907      0.00158    0.07180     0.06684
mean/max                              0.10178      0.00151    0.10488     0.09940
mean/min                              -0.21884     0.00784    -0.20664    -0.23199
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 8, 7, 0, 1, 5, 2, 9, 6, 3]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.0511412620544434 0.0021436214447021484
train_time 2.0545921325683594
2023-09-06 13:33:24,853 MainThread INFO: EPOCH:55
2023-09-06 13:33:24,853 MainThread INFO: Time Consumed:2.067929267883301s
2023-09-06 13:33:24,854 MainThread INFO: Total Frames:84000s
 14%|‚ñà‚ñç        | 56/400 [02:23<18:26,  3.22s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1959.64969
Train_Epoch_Reward                    8340.30933
Running_Training_Average_Rewards      3324.98991
Explore_Time                          0.00365
Train___Time                          2.05459
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.27582
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.84745
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.47720
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.02824
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -31.84586
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -39.24081
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.18970
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19221.84961
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.63271
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.35194
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.80493     1.09375    12.94614    9.13743
alpha_0                               0.84634      0.00073    0.84748     0.84520
alpha_1                               0.84635      0.00073    0.84749     0.84521
alpha_2                               0.84638      0.00073    0.84752     0.84523
alpha_3                               0.84632      0.00073    0.84746     0.84518
alpha_4                               0.84630      0.00073    0.84744     0.84515
alpha_5                               0.84637      0.00073    0.84751     0.84523
alpha_6                               0.84637      0.00073    0.84751     0.84523
alpha_7                               0.84641      0.00073    0.84755     0.84527
alpha_8                               0.84640      0.00073    0.84755     0.84526
alpha_9                               0.84628      0.00073    0.84742     0.84513
Alpha_loss                            -1.11864     0.00573    -1.11012    -1.12594
Training/policy_loss                  -7.24005     0.03802    -7.18736    -7.30113
Training/qf1_loss                     2364.06886   551.99011  3486.76611  1523.57544
Training/qf2_loss                     2359.67505   551.66249  3480.52930  1519.66077
Training/pf_norm                      0.13669      0.01603    0.16842     0.11392
Training/qf1_norm                     294.72807    32.03715   354.82510   243.70131
Training/qf2_norm                     290.74172    31.31280   351.30835   242.07594
log_std/mean                          -0.14656     0.00051    -0.14572    -0.14727
log_std/std                           0.01171      0.00026    0.01204     0.01130
log_std/max                           -0.12659     0.00043    -0.12585    -0.12729
log_std/min                           -0.18550     0.00075    -0.18446    -0.18663
log_probs/mean                        -2.71769     0.00658    -2.70721    -2.72785
log_probs/std                         0.29695      0.01248    0.31623     0.27814
log_probs/max                         -1.72840     0.11037    -1.51197    -1.84704
log_probs/min                         -5.07179     0.71312    -4.09357    -6.36986
mean/mean                             -0.02445     0.00071    -0.02353    -0.02565
mean/std                              0.07550      0.00174    0.07804     0.07258
mean/max                              0.10912      0.00227    0.11238     0.10537
mean/min                              -0.24756     0.00806    -0.23566    -0.25941
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 4, 8, 2, 3, 1, 5, 6, 9, 7]
replay_buffer._size: [8700 8700 8700 8700 8700 8700 8700 8700 8700 8700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.2553317546844482 0.0021369457244873047
train_time 3.2588000297546387
2023-09-06 13:33:28,396 MainThread INFO: EPOCH:56
2023-09-06 13:33:28,396 MainThread INFO: Time Consumed:3.279402017593384s
2023-09-06 13:33:28,397 MainThread INFO: Total Frames:85500s
 14%|‚ñà‚ñç        | 57/400 [02:26<18:56,  3.31s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1874.02485
Train_Epoch_Reward                    57037.65339
Running_Training_Average_Rewards      2922.51232
Explore_Time                          0.01090
Train___Time                          3.25880
Eval____Time                          0.00477
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.20873
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.28922
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.73620
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.43636
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.79689
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -41.91281
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.70510
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17512.22042
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.08095
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.60074
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.79444     0.77127    12.08745    9.42136
alpha_0                               0.84382      0.00072    0.84495     0.84269
alpha_1                               0.84382      0.00073    0.84496     0.84268
alpha_2                               0.84384      0.00073    0.84498     0.84271
alpha_3                               0.84378      0.00073    0.84492     0.84265
alpha_4                               0.84376      0.00073    0.84490     0.84262
alpha_5                               0.84384      0.00073    0.84498     0.84270
alpha_6                               0.84383      0.00073    0.84497     0.84269
alpha_7                               0.84388      0.00073    0.84502     0.84274
alpha_8                               0.84387      0.00073    0.84501     0.84273
alpha_9                               0.84374      0.00073    0.84488     0.84260
Alpha_loss                            -1.13811     0.00503    -1.12979    -1.14552
Training/policy_loss                  -7.36934     0.03614    -7.30273    -7.42054
Training/qf1_loss                     2357.44604   440.11706  3123.59448  1504.55786
Training/qf2_loss                     2352.99119   440.35206  3120.64795  1500.27417
Training/pf_norm                      0.14259      0.01611    0.17215     0.11007
Training/qf1_norm                     304.06450    24.06610   348.94315   263.33643
Training/qf2_norm                     299.75560    22.97206   341.22079   259.62424
log_std/mean                          -0.14692     0.00010    -0.14674    -0.14716
log_std/std                           0.01191      0.00007    0.01200     0.01178
log_std/max                           -0.12681     0.00056    -0.12572    -0.12744
log_std/min                           -0.18462     0.00088    -0.18321    -0.18630
log_probs/mean                        -2.71384     0.00763    -2.70144    -2.72716
log_probs/std                         0.30122      0.01135    0.31627     0.28075
log_probs/max                         -1.71165     0.10113    -1.58078    -1.89053
log_probs/min                         -5.04720     0.56783    -4.24945    -6.26255
mean/mean                             -0.02695     0.00070    -0.02595    -0.02812
mean/std                              0.08014      0.00103    0.08141     0.07837
mean/max                              0.11480      0.00151    0.11656     0.11249
mean/min                              -0.27065     0.00523    -0.26279    -0.27722
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 6, 0, 3, 2, 1, 8, 7, 5, 9]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.579660654067993 0.0021886825561523438
train_time 2.5831634998321533
2023-09-06 13:33:31,744 MainThread INFO: EPOCH:57
2023-09-06 13:33:31,744 MainThread INFO: Time Consumed:3.0960123538970947s
2023-09-06 13:33:31,744 MainThread INFO: Total Frames:87000s
 14%|‚ñà‚ñç        | 58/400 [02:30<18:51,  3.31s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1720.10687
Train_Epoch_Reward                    52705.66532
Running_Training_Average_Rewards      3936.12093
Explore_Time                          0.49232
Train___Time                          2.58316
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.05891
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.01915
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.83220
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.94881
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.39175
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -44.70093
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.09842
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15766.08269
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.38748
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.85219
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.32232     1.34233    13.33885    9.39206
alpha_0                               0.84131      0.00072    0.84244     0.84018
alpha_1                               0.84130      0.00072    0.84243     0.84016
alpha_2                               0.84132      0.00072    0.84245     0.84019
alpha_3                               0.84126      0.00072    0.84239     0.84012
alpha_4                               0.84124      0.00072    0.84237     0.84010
alpha_5                               0.84132      0.00072    0.84245     0.84018
alpha_6                               0.84130      0.00072    0.84244     0.84017
alpha_7                               0.84136      0.00072    0.84249     0.84022
alpha_8                               0.84135      0.00072    0.84248     0.84021
alpha_9                               0.84121      0.00072    0.84235     0.84008
Alpha_loss                            -1.15799     0.00675    -1.14673    -1.16801
Training/policy_loss                  -7.50415     0.04367    -7.43690    -7.56724
Training/qf1_loss                     2481.46470   728.61220  3539.39575  1390.78113
Training/qf2_loss                     2477.32280   728.93360  3536.30005  1386.90503
Training/pf_norm                      0.14631      0.02904    0.21044     0.09072
Training/qf1_norm                     328.49413    43.47790   395.73755   269.19846
Training/qf2_norm                     323.21910    41.90958   388.15466   265.71683
log_std/mean                          -0.14743     0.00026    -0.14700    -0.14776
log_std/std                           0.01194      0.00007    0.01208     0.01183
log_std/max                           -0.12772     0.00070    -0.12683    -0.12884
log_std/min                           -0.18400     0.00143    -0.18182    -0.18565
log_probs/mean                        -2.71246     0.00701    -2.69951    -2.72282
log_probs/std                         0.30503      0.01384    0.33074     0.28204
log_probs/max                         -1.74287     0.09841    -1.53408    -1.86489
log_probs/min                         -5.12829     0.48559    -4.40349    -6.02900
mean/mean                             -0.02802     0.00037    -0.02741    -0.02848
mean/std                              0.08291      0.00105    0.08484     0.08165
mean/max                              0.11686      0.00152    0.11985     0.11492
mean/min                              -0.28485     0.00419    -0.27944    -0.29263
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 8, 7, 3, 5, 9, 6, 1, 2, 4]
replay_buffer._size: [9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.4854114055633545 0.002139568328857422
train_time 3.4888691902160645
2023-09-06 13:33:35,444 MainThread INFO: EPOCH:58
2023-09-06 13:33:35,444 MainThread INFO: Time Consumed:3.502436399459839s
2023-09-06 13:33:35,445 MainThread INFO: Total Frames:88500s
 15%|‚ñà‚ñç        | 59/400 [02:33<19:28,  3.43s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1567.22531
Train_Epoch_Reward                    22873.90258
Running_Training_Average_Rewards      4420.57404
Explore_Time                          0.00377
Train___Time                          3.48887
Eval____Time                          0.00472
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.36086
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.48912
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.85845
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.55031
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.88722
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -45.95091
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.16049
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14655.16423
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.77705
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.61683
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.07583     0.77408    12.15395    10.12555
alpha_0                               0.83881      0.00072    0.83993     0.83768
alpha_1                               0.83878      0.00072    0.83991     0.83765
alpha_2                               0.83881      0.00072    0.83994     0.83768
alpha_3                               0.83874      0.00072    0.83987     0.83761
alpha_4                               0.83872      0.00072    0.83985     0.83759
alpha_5                               0.83880      0.00072    0.83993     0.83767
alpha_6                               0.83878      0.00072    0.83992     0.83765
alpha_7                               0.83884      0.00072    0.83997     0.83772
alpha_8                               0.83883      0.00072    0.83996     0.83770
alpha_9                               0.83869      0.00072    0.83983     0.83756
Alpha_loss                            -1.17753     0.00630    -1.16904    -1.18809
Training/policy_loss                  -7.63937     0.03884    -7.58197    -7.70064
Training/qf1_loss                     2387.70463   417.35552  3116.34253  1936.16882
Training/qf2_loss                     2384.08392   416.96303  3113.88428  1932.49438
Training/pf_norm                      0.15818      0.02655    0.19315     0.11339
Training/qf1_norm                     329.86369    24.05812   362.36432   302.38147
Training/qf2_norm                     323.87354    24.02079   358.81134   296.19418
log_std/mean                          -0.14707     0.00016    -0.14679    -0.14732
log_std/std                           0.01228      0.00028    0.01273     0.01194
log_std/max                           -0.12597     0.00108    -0.12392    -0.12767
log_std/min                           -0.18449     0.00185    -0.18184    -0.18741
log_probs/mean                        -2.70933     0.00860    -2.69734    -2.72933
log_probs/std                         0.30988      0.00952    0.32371     0.29490
log_probs/max                         -1.69350     0.11974    -1.53519    -1.87096
log_probs/min                         -5.00235     0.53605    -4.24397    -6.15966
mean/mean                             -0.02774     0.00017    -0.02749    -0.02816
mean/std                              0.08839      0.00191    0.09146     0.08544
mean/max                              0.12360      0.00202    0.12624     0.12087
mean/min                              -0.30700     0.00826    -0.29385    -0.31954
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 2, 5, 8, 3, 6, 0, 1, 7, 4]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.259849786758423 0.002117156982421875
train_time 3.2632715702056885
2023-09-06 13:33:38,894 MainThread INFO: EPOCH:59
2023-09-06 13:33:38,899 MainThread INFO: Time Consumed:3.28004789352417s
2023-09-06 13:33:38,899 MainThread INFO: Total Frames:90000s
 15%|‚ñà‚ñå        | 60/400 [02:37<19:26,  3.43s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1474.65789
Train_Epoch_Reward                    23166.91674
Running_Training_Average_Rewards      3291.54949
Explore_Time                          0.00729
Train___Time                          3.26327
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.81907
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.42065
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.92442
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.67326
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.30474
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -47.12443
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.56615
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14743.62803
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.87711
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.48744
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.14324     0.73851    12.66599    9.70656
alpha_0                               0.83631      0.00071    0.83743     0.83520
alpha_1                               0.83627      0.00072    0.83740     0.83514
alpha_2                               0.83630      0.00072    0.83743     0.83518
alpha_3                               0.83623      0.00072    0.83736     0.83510
alpha_4                               0.83621      0.00072    0.83734     0.83509
alpha_5                               0.83630      0.00072    0.83742     0.83517
alpha_6                               0.83627      0.00072    0.83740     0.83515
alpha_7                               0.83634      0.00072    0.83747     0.83522
alpha_8                               0.83632      0.00072    0.83745     0.83520
alpha_9                               0.83618      0.00072    0.83731     0.83506
Alpha_loss                            -1.19612     0.00553    -1.18817    -1.20597
Training/policy_loss                  -7.78105     0.04196    -7.71108    -7.84432
Training/qf1_loss                     2418.36237   553.34048  3500.60229  1486.80542
Training/qf2_loss                     2414.21544   553.51064  3498.05322  1482.91833
Training/pf_norm                      0.13921      0.02561    0.17852     0.10300
Training/qf1_norm                     339.97520    25.36737   391.03687   288.77390
Training/qf2_norm                     334.46042    24.39060   382.03635   284.32709
log_std/mean                          -0.14551     0.00050    -0.14468    -0.14638
log_std/std                           0.01333      0.00028    0.01368     0.01287
log_std/max                           -0.12073     0.00126    -0.11921    -0.12319
log_std/min                           -0.19014     0.00127    -0.18804    -0.19218
log_probs/mean                        -2.70100     0.01260    -2.67508    -2.72511
log_probs/std                         0.32294      0.01160    0.34686     0.30555
log_probs/max                         -1.54038     0.13630    -1.32675    -1.80293
log_probs/min                         -4.96912     0.49807    -4.27678    -6.01839
mean/mean                             -0.02924     0.00040    -0.02850    -0.02975
mean/std                              0.09565      0.00212    0.09871     0.09217
mean/max                              0.13033      0.00259    0.13455     0.12643
mean/min                              -0.33837     0.00776    -0.32494    -0.34857
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 2, 5, 9, 7, 4, 6, 8, 3, 0]
replay_buffer._size: [9300 9300 9300 9300 9300 9300 9300 9300 9300 9300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.1788413524627686 0.002107858657836914
train_time 3.1822595596313477
2023-09-06 13:33:42,251 MainThread INFO: EPOCH:60
2023-09-06 13:33:42,251 MainThread INFO: Time Consumed:3.1982991695404053s
2023-09-06 13:33:42,251 MainThread INFO: Total Frames:91500s
 15%|‚ñà‚ñå        | 61/400 [02:40<19:17,  3.41s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1416.63476
Train_Epoch_Reward                    34855.56341
Running_Training_Average_Rewards      2696.54609
Explore_Time                          0.00538
Train___Time                          3.18226
Eval____Time                          0.00531
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.40480
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.87238
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.01785
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.14257
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.77699
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -49.12845
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.55147
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14047.76379
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.22243
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.54785
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.73883     1.31026    14.59849    10.41981
alpha_0                               0.83384      0.00071    0.83495     0.83272
alpha_1                               0.83376      0.00072    0.83489     0.83264
alpha_2                               0.83380      0.00072    0.83493     0.83268
alpha_3                               0.83373      0.00072    0.83485     0.83261
alpha_4                               0.83371      0.00072    0.83484     0.83259
alpha_5                               0.83380      0.00072    0.83492     0.83267
alpha_6                               0.83377      0.00072    0.83490     0.83265
alpha_7                               0.83385      0.00071    0.83497     0.83273
alpha_8                               0.83382      0.00072    0.83495     0.83270
alpha_9                               0.83368      0.00072    0.83481     0.83256
Alpha_loss                            -1.21696     0.00605    -1.20809    -1.22617
Training/policy_loss                  -7.92711     0.04474    -7.85464    -7.98994
Training/qf1_loss                     2783.89352   849.03270  4677.28955  1926.04578
Training/qf2_loss                     2780.19939   848.14111  4671.82373  1923.16956
Training/pf_norm                      0.15685      0.02012    0.19465     0.12696
Training/qf1_norm                     368.43253    44.93802   465.27243   319.90036
Training/qf2_norm                     361.58514    44.40393   457.24136   314.26019
log_std/mean                          -0.14362     0.00044    -0.14317    -0.14444
log_std/std                           0.01393      0.00009    0.01407     0.01374
log_std/max                           -0.11861     0.00044    -0.11805    -0.11924
log_std/min                           -0.19216     0.00124    -0.19088    -0.19466
log_probs/mean                        -2.70533     0.00595    -2.69715    -2.71752
log_probs/std                         0.33304      0.00946    0.35030     0.32097
log_probs/max                         -1.44733     0.09605    -1.29277    -1.58985
log_probs/min                         -4.96707     0.49155    -4.41314    -6.01589
mean/mean                             -0.02801     0.00079    -0.02681    -0.02931
mean/std                              0.10233      0.00218    0.10618     0.09924
mean/max                              0.14441      0.00582    0.15496     0.13536
mean/min                              -0.36161     0.00653    -0.35108    -0.37231
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 1, 8, 5, 4, 2, 3, 7, 6, 0]
replay_buffer._size: [9450 9450 9450 9450 9450 9450 9450 9450 9450 9450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.529933214187622 0.0021409988403320312
train_time 3.533397912979126
2023-09-06 13:33:45,984 MainThread INFO: EPOCH:61
2023-09-06 13:33:45,985 MainThread INFO: Time Consumed:3.550855875015259s
2023-09-06 13:33:45,985 MainThread INFO: Total Frames:93000s
 16%|‚ñà‚ñå        | 62/400 [02:44<19:45,  3.51s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1367.09816
Train_Epoch_Reward                    20218.22041
Running_Training_Average_Rewards      2608.02335
Explore_Time                          0.00649
Train___Time                          3.53340
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.66311
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.27005
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.12852
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.65276
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.75343
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -51.75397
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.95346
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13182.75866
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.52491
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.64338
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.08821     0.82884    12.76741    9.64952
alpha_0                               0.83137      0.00071    0.83248     0.83026
alpha_1                               0.83127      0.00072    0.83239     0.83015
alpha_2                               0.83131      0.00071    0.83243     0.83019
alpha_3                               0.83124      0.00072    0.83236     0.83011
alpha_4                               0.83122      0.00072    0.83234     0.83010
alpha_5                               0.83130      0.00072    0.83242     0.83018
alpha_6                               0.83128      0.00071    0.83240     0.83016
alpha_7                               0.83137      0.00071    0.83248     0.83025
alpha_8                               0.83133      0.00072    0.83245     0.83021
alpha_9                               0.83119      0.00072    0.83231     0.83007
Alpha_loss                            -1.23610     0.00553    -1.22641    -1.24481
Training/policy_loss                  -8.07298     0.03887    -8.00557    -8.13542
Training/qf1_loss                     2419.30668   576.12157  3295.93335  1510.70142
Training/qf2_loss                     2415.59773   575.53582  3291.91992  1508.30042
Training/pf_norm                      0.14981      0.02659    0.19581     0.10474
Training/qf1_norm                     354.36353    30.33530   416.78391   303.95279
Training/qf2_norm                     347.96971    30.09174   409.36194   297.66077
log_std/mean                          -0.14390     0.00069    -0.14295    -0.14517
log_std/std                           0.01452      0.00032    0.01505     0.01408
log_std/max                           -0.11866     0.00027    -0.11836    -0.11917
log_std/min                           -0.19304     0.00197    -0.19005    -0.19572
log_probs/mean                        -2.70042     0.00968    -2.68709    -2.71657
log_probs/std                         0.35605      0.00849    0.36712     0.33855
log_probs/max                         -1.46550     0.09182    -1.31706    -1.61432
log_probs/min                         -5.22180     0.68000    -4.39744    -6.86669
mean/mean                             -0.02517     0.00101    -0.02380    -0.02661
mean/std                              0.11217      0.00308    0.11697     0.10722
mean/max                              0.16780      0.00693    0.17827     0.15575
mean/min                              -0.38824     0.00887    -0.37432    -0.40244
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 9, 5, 2, 0, 8, 1, 4, 3, 6]
replay_buffer._size: [9600 9600 9600 9600 9600 9600 9600 9600 9600 9600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.4512486457824707 0.002107858657836914
train_time 3.454678535461426
2023-09-06 13:33:49,664 MainThread INFO: EPOCH:62
2023-09-06 13:33:49,665 MainThread INFO: Time Consumed:3.497954845428467s
2023-09-06 13:33:49,665 MainThread INFO: Total Frames:94500s
 16%|‚ñà‚ñå        | 63/400 [02:48<20:06,  3.58s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1307.46274
Train_Epoch_Reward                    6538.65427
Running_Training_Average_Rewards      2053.74794
Explore_Time                          0.03225
Train___Time                          3.45468
Eval____Time                          0.00495
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.03043
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.20669
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.25220
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.51797
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.10835
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -54.92977
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.24890
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12985.13643
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.37711
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.09693
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.64846     0.91614    13.79583    10.47532
alpha_0                               0.82892      0.00070    0.83002     0.82782
alpha_1                               0.82878      0.00071    0.82990     0.82767
alpha_2                               0.82883      0.00071    0.82994     0.82771
alpha_3                               0.82875      0.00071    0.82986     0.82763
alpha_4                               0.82873      0.00071    0.82985     0.82761
alpha_5                               0.82882      0.00071    0.82993     0.82770
alpha_6                               0.82880      0.00071    0.82991     0.82768
alpha_7                               0.82890      0.00071    0.83001     0.82779
alpha_8                               0.82884      0.00071    0.82996     0.82773
alpha_9                               0.82870      0.00071    0.82982     0.82758
Alpha_loss                            -1.25562     0.00477    -1.24615    -1.26400
Training/policy_loss                  -8.22215     0.04071    -8.16179    -8.29026
Training/qf1_loss                     2611.73722   612.86585  4241.28613  1900.58948
Training/qf2_loss                     2607.98778   612.62527  4235.68701  1896.23230
Training/pf_norm                      0.16080      0.03859    0.24202     0.11142
Training/qf1_norm                     382.97034    33.77060   462.83740   342.64709
Training/qf2_norm                     375.87000    33.09273   455.57809   337.85489
log_std/mean                          -0.14710     0.00063    -0.14576    -0.14784
log_std/std                           0.01589      0.00040    0.01647     0.01522
log_std/max                           -0.12007     0.00058    -0.11904    -0.12111
log_std/min                           -0.20190     0.00262    -0.19706    -0.20463
log_probs/mean                        -2.69770     0.01015    -2.68441    -2.72203
log_probs/std                         0.38022      0.01358    0.40564     0.35783
log_probs/max                         -1.24886     0.13683    -1.03939    -1.51687
log_probs/min                         -6.01228     1.10018    -4.61363    -8.07159
mean/mean                             -0.02401     0.00082    -0.02326    -0.02577
mean/std                              0.12254      0.00270    0.12632     0.11806
mean/max                              0.18673      0.00401    0.19275     0.17879
mean/min                              -0.42350     0.01076    -0.40674    -0.43864
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 9, 4, 6, 0, 1, 3, 2, 8, 7]
replay_buffer._size: [9750 9750 9750 9750 9750 9750 9750 9750 9750 9750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.5043115615844727 0.0021088123321533203
train_time 3.5077364444732666
2023-09-06 13:33:53,568 MainThread INFO: EPOCH:63
2023-09-06 13:33:53,569 MainThread INFO: Time Consumed:3.529986619949341s
2023-09-06 13:33:53,569 MainThread INFO: Total Frames:96000s
 16%|‚ñà‚ñå        | 64/400 [02:52<20:27,  3.65s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1266.52365
Train_Epoch_Reward                    6911.57072
Running_Training_Average_Rewards      1122.28151
Explore_Time                          0.01214
Train___Time                          3.50774
Eval____Time                          0.00428
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.29509
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.59111
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.39085
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.66679
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.20434
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -58.20918
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.25187
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12840.66420
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.40816
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.72037
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.40926     1.27810    13.30528    9.38171
alpha_0                               0.82648      0.00070    0.82757     0.82539
alpha_1                               0.82630      0.00071    0.82742     0.82519
alpha_2                               0.82635      0.00071    0.82746     0.82524
alpha_3                               0.82626      0.00071    0.82738     0.82515
alpha_4                               0.82625      0.00071    0.82737     0.82514
alpha_5                               0.82634      0.00071    0.82745     0.82522
alpha_6                               0.82632      0.00071    0.82743     0.82520
alpha_7                               0.82644      0.00071    0.82754     0.82533
alpha_8                               0.82637      0.00071    0.82748     0.82526
alpha_9                               0.82622      0.00071    0.82733     0.82510
Alpha_loss                            -1.27387     0.00597    -1.26708    -1.28540
Training/policy_loss                  -8.37422     0.04651    -8.30475    -8.44487
Training/qf1_loss                     2551.21702   808.18548  3790.88135  1511.84998
Training/qf2_loss                     2547.19531   808.03876  3787.60815  1509.83679
Training/pf_norm                      0.15744      0.01828    0.19586     0.13051
Training/qf1_norm                     383.09311    47.77617   453.35223   306.26590
Training/qf2_norm                     376.35663    47.02551   442.29126   301.67215
log_std/mean                          -0.14659     0.00060    -0.14561    -0.14727
log_std/std                           0.01674      0.00015    0.01697     0.01641
log_std/max                           -0.12069     0.00069    -0.11963    -0.12169
log_std/min                           -0.20676     0.00164    -0.20327    -0.20900
log_probs/mean                        -2.68836     0.01194    -2.67237    -2.70662
log_probs/std                         0.38533      0.01858    0.43590     0.37113
log_probs/max                         -1.26006     0.14846    -0.95822    -1.52515
log_probs/min                         -5.19276     0.71096    -4.53349    -6.58129
mean/mean                             -0.03004     0.00216    -0.02645    -0.03305
mean/std                              0.12944      0.00121    0.13083     0.12712
mean/max                              0.19486      0.00142    0.19727     0.19215
mean/min                              -0.46261     0.01022    -0.44503    -0.47660
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 9, 4, 2, 8, 0, 1, 3, 6, 7]
replay_buffer._size: [9900 9900 9900 9900 9900 9900 9900 9900 9900 9900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.536024808883667 0.0020987987518310547
train_time 3.5394287109375
2023-09-06 13:33:57,294 MainThread INFO: EPOCH:64
2023-09-06 13:33:57,294 MainThread INFO: Time Consumed:3.5614349842071533s
2023-09-06 13:33:57,295 MainThread INFO: Total Frames:97500s
 16%|‚ñà‚ñã        | 65/400 [02:55<20:32,  3.68s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1223.36832
Train_Epoch_Reward                    13689.55870
Running_Training_Average_Rewards      904.65946
Explore_Time                          0.01426
Train___Time                          3.53943
Eval____Time                          0.00356
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.28530
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.68653
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.48830
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.93146
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.98389
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.69034
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.12905
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11929.61221
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.18737
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.47482
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.12342     1.22640    13.72738    9.76680
alpha_0                               0.82406      0.00069    0.82514     0.82297
alpha_1                               0.82383      0.00071    0.82494     0.82273
alpha_2                               0.82389      0.00071    0.82499     0.82278
alpha_3                               0.82379      0.00071    0.82490     0.82268
alpha_4                               0.82378      0.00071    0.82489     0.82268
alpha_5                               0.82387      0.00071    0.82498     0.82276
alpha_6                               0.82385      0.00071    0.82496     0.82274
alpha_7                               0.82398      0.00070    0.82509     0.82288
alpha_8                               0.82390      0.00071    0.82501     0.82279
alpha_9                               0.82374      0.00071    0.82486     0.82263
Alpha_loss                            -1.29228     0.00593    -1.28256    -1.30119
Training/policy_loss                  -8.52715     0.04235    -8.46397    -8.59093
Training/qf1_loss                     2593.13456   749.41184  4210.33838  1782.57751
Training/qf2_loss                     2589.26168   748.16407  4202.10254  1779.64062
Training/pf_norm                      0.14840      0.02363    0.19989     0.11103
Training/qf1_norm                     380.67937    44.41383   472.73041   326.38443
Training/qf2_norm                     373.94890    44.64908   468.87378   321.53558
log_std/mean                          -0.14540     0.00025    -0.14503    -0.14581
log_std/std                           0.01724      0.00019    0.01755     0.01703
log_std/max                           -0.11937     0.00061    -0.11868    -0.12059
log_std/min                           -0.20990     0.00141    -0.20786    -0.21238
log_probs/mean                        -2.68032     0.01365    -2.65865    -2.70429
log_probs/std                         0.39311      0.00728    0.40360     0.38028
log_probs/max                         -1.26795     0.09361    -1.15881    -1.43548
log_probs/min                         -5.21004     0.58457    -4.71683    -6.82141
mean/mean                             -0.03491     0.00060    -0.03360    -0.03550
mean/std                              0.13313      0.00157    0.13577     0.13117
mean/max                              0.20234      0.00460    0.20959     0.19634
mean/min                              -0.48802     0.00614    -0.47834    -0.49670
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 3, 1, 6, 8, 0, 4, 5, 2, 9]
replay_buffer._size: [10050 10050 10050 10050 10050 10050 10050 10050 10050 10050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.324951171875 0.002171039581298828
train_time 3.3284783363342285
2023-09-06 13:34:01,003 MainThread INFO: EPOCH:65
2023-09-06 13:34:01,004 MainThread INFO: Time Consumed:3.352263927459717s
2023-09-06 13:34:01,004 MainThread INFO: Total Frames:99000s
 16%|‚ñà‚ñã        | 66/400 [02:59<20:30,  3.68s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1154.85152
Train_Epoch_Reward                    7733.17317
Running_Training_Average_Rewards      944.47675
Explore_Time                          0.01288
Train___Time                          3.32848
Eval____Time                          0.00453
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.97485
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.64968
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.53361
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.40413
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.07971
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.44692
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.15160
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10954.90285
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.19150
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.60686
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.13891     1.08872    12.59212    9.88740
alpha_0                               0.82165      0.00069    0.82273     0.82057
alpha_1                               0.82137      0.00071    0.82248     0.82027
alpha_2                               0.82143      0.00071    0.82253     0.82032
alpha_3                               0.82132      0.00071    0.82243     0.82022
alpha_4                               0.82133      0.00070    0.82243     0.82022
alpha_5                               0.82141      0.00071    0.82251     0.82030
alpha_6                               0.82138      0.00071    0.82249     0.82028
alpha_7                               0.82154      0.00070    0.82264     0.82045
alpha_8                               0.82144      0.00071    0.82255     0.82034
alpha_9                               0.82128      0.00071    0.82239     0.82017
Alpha_loss                            -1.31195     0.00456    -1.30567    -1.31964
Training/policy_loss                  -8.68098     0.04224    -8.61198    -8.74987
Training/qf1_loss                     2455.31083   644.08659  3711.47729  1714.38245
Training/qf2_loss                     2451.43770   643.58029  3707.16187  1712.86658
Training/pf_norm                      0.15945      0.01902    0.19379     0.13209
Training/qf1_norm                     389.75621    41.29624   444.23828   339.81628
Training/qf2_norm                     382.89030    40.33136   436.17923   335.79541
log_std/mean                          -0.14696     0.00050    -0.14609    -0.14749
log_std/std                           0.01841      0.00049    0.01917     0.01765
log_std/max                           -0.11990     0.00056    -0.11865    -0.12074
log_std/min                           -0.22071     0.00513    -0.21195    -0.22709
log_probs/mean                        -2.67903     0.01362    -2.65378    -2.70700
log_probs/std                         0.40275      0.01200    0.42474     0.38297
log_probs/max                         -1.18977     0.15222    -0.93936    -1.44225
log_probs/min                         -5.12799     0.46174    -4.56850    -6.00517
mean/mean                             -0.03517     0.00025    -0.03490    -0.03579
mean/std                              0.14038      0.00256    0.14451     0.13643
mean/max                              0.21735      0.00311    0.22246     0.21109
mean/min                              -0.52227     0.01368    -0.50037    -0.54391
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 6, 7, 2, 9, 0, 8, 5, 1, 3]
replay_buffer._size: [10200 10200 10200 10200 10200 10200 10200 10200 10200 10200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.638842821121216 0.0026674270629882812
train_time 3.6428756713867188
2023-09-06 13:34:04,885 MainThread INFO: EPOCH:66
2023-09-06 13:34:04,886 MainThread INFO: Time Consumed:3.6784749031066895s
2023-09-06 13:34:04,886 MainThread INFO: Total Frames:100500s
 17%|‚ñà‚ñã        | 67/400 [03:03<20:46,  3.74s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1088.89136
Train_Epoch_Reward                    19380.35409
Running_Training_Average_Rewards      1360.10287
Explore_Time                          0.01536
Train___Time                          3.64288
Eval____Time                          0.00845
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.93536
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.92572
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.57936
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.41160
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.48160
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.13445
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.48793
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10895.23515
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.30045
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.85702
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.86676     0.79087    12.09347    8.91704
alpha_0                               0.81925      0.00069    0.82033     0.81818
alpha_1                               0.81892      0.00070    0.82002     0.81782
alpha_2                               0.81898      0.00070    0.82008     0.81788
alpha_3                               0.81887      0.00070    0.81997     0.81777
alpha_4                               0.81888      0.00070    0.81998     0.81778
alpha_5                               0.81895      0.00070    0.82006     0.81785
alpha_6                               0.81893      0.00070    0.82003     0.81783
alpha_7                               0.81911      0.00070    0.82020     0.81802
alpha_8                               0.81899      0.00070    0.82009     0.81789
alpha_9                               0.81882      0.00070    0.81993     0.81772
Alpha_loss                            -1.33034     0.00609    -1.32116    -1.34136
Training/policy_loss                  -8.84111     0.05029    -8.76111    -8.91536
Training/qf1_loss                     2282.09218   489.72441  3035.73999  1080.98926
Training/qf2_loss                     2279.17141   490.13968  3033.78369  1077.53674
Training/pf_norm                      0.17423      0.02675    0.21498     0.11999
Training/qf1_norm                     388.24590    33.32044   435.63794   306.36819
Training/qf2_norm                     380.33844    31.82757   425.86160   301.35321
log_std/mean                          -0.14741     0.00043    -0.14640    -0.14778
log_std/std                           0.02011      0.00052    0.02084     0.01928
log_std/max                           -0.11884     0.00121    -0.11683    -0.12055
log_std/min                           -0.23226     0.00397    -0.22521    -0.23810
log_probs/mean                        -2.67135     0.00679    -2.65760    -2.68169
log_probs/std                         0.41702      0.01122    0.43072     0.39992
log_probs/max                         -1.10417     0.14072    -0.91516    -1.45368
log_probs/min                         -5.08121     0.32141    -4.52313    -5.70333
mean/mean                             -0.03716     0.00044    -0.03619    -0.03756
mean/std                              0.14890      0.00198    0.15159     0.14551
mean/max                              0.22789      0.00384    0.23294     0.22265
mean/min                              -0.56564     0.01327    -0.54420    -0.58605
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 7, 1, 2, 3, 6, 8, 5, 9, 4]
replay_buffer._size: [10350 10350 10350 10350 10350 10350 10350 10350 10350 10350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.6483428478240967 0.0021452903747558594
train_time 3.6518046855926514
2023-09-06 13:34:08,746 MainThread INFO: EPOCH:67
2023-09-06 13:34:08,746 MainThread INFO: Time Consumed:3.6810388565063477s
2023-09-06 13:34:08,746 MainThread INFO: Total Frames:102000s
 17%|‚ñà‚ñã        | 68/400 [03:07<20:56,  3.78s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1034.74304
Train_Epoch_Reward                    8022.86579
Running_Training_Average_Rewards      1171.21310
Explore_Time                          0.01799
Train___Time                          3.65180
Eval____Time                          0.00625
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.39500
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.94169
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.66635
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.35313
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.01603
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.23005
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.38059
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10321.29788
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.02885
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.98050
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.15859     0.80862    12.74793    10.16027
alpha_0                               0.81687      0.00068    0.81794     0.81580
alpha_1                               0.81647      0.00070    0.81757     0.81537
alpha_2                               0.81654      0.00070    0.81764     0.81544
alpha_3                               0.81642      0.00070    0.81752     0.81533
alpha_4                               0.81644      0.00070    0.81754     0.81534
alpha_5                               0.81651      0.00070    0.81761     0.81541
alpha_6                               0.81649      0.00070    0.81758     0.81539
alpha_7                               0.81669      0.00069    0.81777     0.81560
alpha_8                               0.81655      0.00070    0.81764     0.81545
alpha_9                               0.81637      0.00070    0.81747     0.81527
Alpha_loss                            -1.34877     0.00541    -1.34205    -1.35680
Training/policy_loss                  -9.00530     0.04993    -8.93625    -9.08112
Training/qf1_loss                     2486.16846   553.96276  3482.53052  1741.91272
Training/qf2_loss                     2483.14969   554.50440  3482.63354  1738.65820
Training/pf_norm                      0.17261      0.02922    0.22667     0.13258
Training/qf1_norm                     408.70842    36.73678   481.81247   363.35403
Training/qf2_norm                     400.48782    35.26164   468.05112   356.39713
log_std/mean                          -0.14569     0.00032    -0.14523    -0.14620
log_std/std                           0.02138      0.00038    0.02199     0.02082
log_std/max                           -0.11792     0.00074    -0.11667    -0.11927
log_std/min                           -0.23789     0.00371    -0.23221    -0.24606
log_probs/mean                        -2.66419     0.00875    -2.65387    -2.68182
log_probs/std                         0.44057      0.01570    0.46227     0.40964
log_probs/max                         -1.01876     0.17889    -0.71755    -1.33753
log_probs/min                         -5.25325     0.78559    -4.41108    -6.85910
mean/mean                             -0.03892     0.00066    -0.03763    -0.03962
mean/std                              0.15522      0.00210    0.15864     0.15203
mean/max                              0.23015      0.00190    0.23300     0.22556
mean/min                              -0.59781     0.01247    -0.57538    -0.62292
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 5, 9, 8, 1, 2, 3, 4, 0, 6]
replay_buffer._size: [10500 10500 10500 10500 10500 10500 10500 10500 10500 10500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.55749773979187 0.0021800994873046875
train_time 3.5610103607177734
2023-09-06 13:34:12,514 MainThread INFO: EPOCH:68
2023-09-06 13:34:12,514 MainThread INFO: Time Consumed:3.576322078704834s
2023-09-06 13:34:12,515 MainThread INFO: Total Frames:103500s
 17%|‚ñà‚ñã        | 69/400 [03:11<20:56,  3.80s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               986.56942
Train_Epoch_Reward                    11481.91944
Running_Training_Average_Rewards      1296.17131
Explore_Time                          0.00549
Train___Time                          3.56101
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.25753
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.49328
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.67654
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.70521
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.12023
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.65865
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.16459
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9528.88444
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.33279
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.82020
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.34791     1.32551    14.06147    9.39358
alpha_0                               0.81451      0.00068    0.81557     0.81345
alpha_1                               0.81403      0.00070    0.81513     0.81294
alpha_2                               0.81411      0.00070    0.81520     0.81302
alpha_3                               0.81399      0.00070    0.81508     0.81289
alpha_4                               0.81401      0.00070    0.81510     0.81291
alpha_5                               0.81408      0.00070    0.81517     0.81298
alpha_6                               0.81405      0.00070    0.81515     0.81296
alpha_7                               0.81428      0.00069    0.81536     0.81319
alpha_8                               0.81411      0.00070    0.81520     0.81301
alpha_9                               0.81393      0.00070    0.81503     0.81283
Alpha_loss                            -1.36724     0.00494    -1.35937    -1.37605
Training/policy_loss                  -9.17294     0.04850    -9.08801    -9.24972
Training/qf1_loss                     2592.64749   766.68581  4008.04297  1458.75781
Training/qf2_loss                     2589.01366   766.30673  4003.55640  1456.02502
Training/pf_norm                      0.15119      0.01907    0.18972     0.11876
Training/qf1_norm                     424.91133    55.70370   539.15015   341.12564
Training/qf2_norm                     417.04412    54.51836   529.28796   335.53647
log_std/mean                          -0.14662     0.00032    -0.14614    -0.14728
log_std/std                           0.02257      0.00025    0.02284     0.02208
log_std/max                           -0.11853     0.00077    -0.11734    -0.11947
log_std/min                           -0.24666     0.00296    -0.24202    -0.25110
log_probs/mean                        -2.65753     0.01004    -2.64041    -2.67283
log_probs/std                         0.45730      0.01611    0.49027     0.42900
log_probs/max                         -0.94647     0.09371    -0.80220    -1.13874
log_probs/min                         -5.47341     0.97170    -4.33819    -8.14274
mean/mean                             -0.04015     0.00050    -0.03930    -0.04065
mean/std                              0.16338      0.00250    0.16724     0.15927
mean/max                              0.23799      0.00421    0.24259     0.22902
mean/min                              -0.63663     0.01389    -0.61404    -0.65624
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 9, 8, 3, 1, 4, 0, 2, 6, 5]
replay_buffer._size: [10650 10650 10650 10650 10650 10650 10650 10650 10650 10650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.6560890674591064 0.002270221710205078
train_time 3.659684181213379
2023-09-06 13:34:16,396 MainThread INFO: EPOCH:69
2023-09-06 13:34:16,397 MainThread INFO: Time Consumed:3.674025535583496s
2023-09-06 13:34:16,397 MainThread INFO: Total Frames:105000s
 18%|‚ñà‚ñä        | 70/400 [03:14<20:56,  3.81s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               915.25467
Train_Epoch_Reward                    7712.40911
Running_Training_Average_Rewards      907.23981
Explore_Time                          0.00504
Train___Time                          3.65968
Eval____Time                          0.00403
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.36218
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.23541
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.66743
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.00261
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.14600
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.97783
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.99978
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8765.83543
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.64327
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.12193
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.53001    0.82176    11.74097    8.69768
alpha_0                               0.81216     0.00067    0.81321     0.81111
alpha_1                               0.81160     0.00070    0.81269     0.81051
alpha_2                               0.81168     0.00070    0.81277     0.81059
alpha_3                               0.81156     0.00070    0.81265     0.81047
alpha_4                               0.81158     0.00070    0.81267     0.81049
alpha_5                               0.81165     0.00070    0.81274     0.81056
alpha_6                               0.81162     0.00070    0.81271     0.81053
alpha_7                               0.81188     0.00069    0.81295     0.81080
alpha_8                               0.81168     0.00070    0.81277     0.81059
alpha_9                               0.81149     0.00070    0.81258     0.81039
Alpha_loss                            -1.38504    0.00455    -1.37605    -1.39054
Training/policy_loss                  -9.34100    0.04959    -9.25310    -9.40818
Training/qf1_loss                     2093.81444  284.98116  2414.79443  1478.51746
Training/qf2_loss                     2090.71648  284.48910  2411.25464  1475.17419
Training/pf_norm                      0.16499     0.02740    0.20787     0.12328
Training/qf1_norm                     399.36464   34.96911   448.90634   319.87961
Training/qf2_norm                     391.64153   34.10114   440.45587   314.72403
log_std/mean                          -0.14838    0.00046    -0.14747    -0.14891
log_std/std                           0.02277     0.00010    0.02292     0.02260
log_std/max                           -0.11807    0.00092    -0.11612    -0.11946
log_std/min                           -0.25417    0.00248    -0.24858    -0.25757
log_probs/mean                        -2.64791    0.01052    -2.63041    -2.67142
log_probs/std                         0.47147     0.01797    0.49818     0.43211
log_probs/max                         -0.88896    0.13627    -0.74523    -1.17995
log_probs/min                         -6.10256    1.90131    -4.24317    -10.24144
mean/mean                             -0.04070    0.00012    -0.04056    -0.04089
mean/std                              0.17177     0.00241    0.17524     0.16778
mean/max                              0.24746     0.00625    0.25853     0.23838
mean/min                              -0.68036    0.01226    -0.65223    -0.69877
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 3, 4, 9, 8, 6, 0, 7, 2, 5]
replay_buffer._size: [10800 10800 10800 10800 10800 10800 10800 10800 10800 10800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7198171615600586 0.002167940139770508
train_time 3.723316192626953
2023-09-06 13:34:20,341 MainThread INFO: EPOCH:70
2023-09-06 13:34:20,341 MainThread INFO: Time Consumed:3.74300217628479s
2023-09-06 13:34:20,341 MainThread INFO: Total Frames:106500s
 18%|‚ñà‚ñä        | 71/400 [03:18<21:08,  3.86s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               853.37361
Train_Epoch_Reward                    8778.48613
Running_Training_Average_Rewards      932.42716
Explore_Time                          0.01030
Train___Time                          3.72332
Eval____Time                          0.00380
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.26206
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.12993
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.63717
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.32212
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.26510
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.32710
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.53070
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8478.14806
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.24420
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.55564
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.78441    1.41104    12.51605    8.76773
alpha_0                               0.80983     0.00067    0.81088     0.80879
alpha_1                               0.80918     0.00069    0.81027     0.80810
alpha_2                               0.80926     0.00069    0.81035     0.80818
alpha_3                               0.80914     0.00069    0.81023     0.80806
alpha_4                               0.80916     0.00069    0.81025     0.80808
alpha_5                               0.80923     0.00069    0.81032     0.80814
alpha_6                               0.80920     0.00069    0.81029     0.80811
alpha_7                               0.80949     0.00069    0.81056     0.80842
alpha_8                               0.80927     0.00069    0.81035     0.80819
alpha_9                               0.80906     0.00070    0.81015     0.80797
Alpha_loss                            -1.40276    0.00552    -1.38925    -1.41206
Training/policy_loss                  -9.51415    0.04596    -9.44495    -9.58950
Training/qf1_loss                     2235.81559  824.67514  3304.91870  1171.58459
Training/qf2_loss                     2232.60973  823.62544  3301.95874  1169.70728
Training/pf_norm                      0.16556     0.01962    0.20270     0.12731
Training/qf1_norm                     419.00461   63.22026   502.35046   329.16394
Training/qf2_norm                     411.07914   62.54524   491.99969   322.77438
log_std/mean                          -0.14748    0.00028    -0.14709    -0.14801
log_std/std                           0.02304     0.00037    0.02372     0.02264
log_std/max                           -0.11669    0.00109    -0.11487    -0.11810
log_std/min                           -0.26162    0.00406    -0.25575    -0.26856
log_probs/mean                        -2.63828    0.01860    -2.61181    -2.66647
log_probs/std                         0.47802     0.00914    0.49143     0.45694
log_probs/max                         -0.76271    0.12312    -0.50501    -0.93402
log_probs/min                         -5.06903    0.44888    -4.60340    -5.90234
mean/mean                             -0.04158    0.00050    -0.04089    -0.04225
mean/std                              0.17848     0.00198    0.18158     0.17581
mean/max                              0.26356     0.00505    0.27126     0.25479
mean/min                              -0.70838    0.00879    -0.69390    -0.71947
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 9, 6, 7, 3, 4, 0, 1, 5, 8]
replay_buffer._size: [10950 10950 10950 10950 10950 10950 10950 10950 10950 10950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.586024522781372 0.002162933349609375
train_time 3.5895206928253174
2023-09-06 13:34:24,147 MainThread INFO: EPOCH:71
2023-09-06 13:34:24,147 MainThread INFO: Time Consumed:3.607215642929077s
2023-09-06 13:34:24,148 MainThread INFO: Total Frames:108000s
 18%|‚ñà‚ñä        | 72/400 [03:22<20:59,  3.84s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               818.21497
Train_Epoch_Reward                    9065.93705
Running_Training_Average_Rewards      851.89441
Explore_Time                          0.00863
Train___Time                          3.58952
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.23688
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.60084
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.67657
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.71747
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.33941
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.13824
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.09095
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8494.69902
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.33801
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.66453
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.90731    0.98581    12.28412    9.55120
alpha_0                               0.80752     0.00066    0.80856     0.80648
alpha_1                               0.80677     0.00069    0.80786     0.80569
alpha_2                               0.80686     0.00069    0.80794     0.80578
alpha_3                               0.80673     0.00069    0.80782     0.80565
alpha_4                               0.80676     0.00069    0.80784     0.80567
alpha_5                               0.80682     0.00069    0.80790     0.80573
alpha_6                               0.80678     0.00069    0.80787     0.80570
alpha_7                               0.80711     0.00068    0.80818     0.80604
alpha_8                               0.80686     0.00069    0.80795     0.80578
alpha_9                               0.80664     0.00069    0.80773     0.80555
Alpha_loss                            -1.42253    0.00643    -1.40947    -1.43498
Training/policy_loss                  -9.69071    0.05188    -9.60758    -9.76065
Training/qf1_loss                     2530.59636  551.93256  3273.92188  1812.72192
Training/qf2_loss                     2527.26445  552.86264  3274.50049  1808.99731
Training/pf_norm                      0.17312     0.02432    0.20687     0.13903
Training/qf1_norm                     430.16840   44.00430   494.93451   366.48911
Training/qf2_norm                     422.13676   41.89440   483.48187   361.82996
log_std/mean                          -0.14929    0.00080    -0.14822    -0.15070
log_std/std                           0.02497     0.00066    0.02601     0.02398
log_std/max                           -0.11685    0.00067    -0.11568    -0.11794
log_std/min                           -0.28119    0.00522    -0.27281    -0.28878
log_probs/mean                        -2.63854    0.01574    -2.61215    -2.66431
log_probs/std                         0.49876     0.01536    0.52080     0.47504
log_probs/max                         -0.69443    0.14482    -0.40823    -0.89075
log_probs/min                         -5.64419    0.74861    -4.82063    -7.50470
mean/mean                             -0.04180    0.00045    -0.04130    -0.04271
mean/std                              0.18795     0.00411    0.19490     0.18244
mean/max                              0.28092     0.00640    0.29058     0.27296
mean/min                              -0.74842    0.01503    -0.72827    -0.77089
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 9, 1, 7, 3, 6, 4, 0, 2, 8]
replay_buffer._size: [11100 11100 11100 11100 11100 11100 11100 11100 11100 11100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.68135929107666 0.002495288848876953
train_time 3.68518328666687
2023-09-06 13:34:28,034 MainThread INFO: EPOCH:72
2023-09-06 13:34:28,035 MainThread INFO: Time Consumed:3.6983721256256104s
2023-09-06 13:34:28,035 MainThread INFO: Total Frames:109500s
 18%|‚ñà‚ñä        | 73/400 [03:26<20:55,  3.84s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               807.94562
Train_Epoch_Reward                    9628.93960
Running_Training_Average_Rewards      915.77876
Explore_Time                          0.00452
Train___Time                          3.68518
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.28005
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.05976
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.72662
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.96081
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -60.12891
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.34004
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.04394
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8472.43826
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.60422
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.69535
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.31731    0.45088    11.12348    9.76577
alpha_0                               0.80522     0.00066    0.80625     0.80420
alpha_1                               0.80436     0.00069    0.80544     0.80328
alpha_2                               0.80447     0.00069    0.80554     0.80339
alpha_3                               0.80433     0.00069    0.80541     0.80325
alpha_4                               0.80435     0.00069    0.80543     0.80327
alpha_5                               0.80441     0.00069    0.80549     0.80334
alpha_6                               0.80438     0.00069    0.80546     0.80329
alpha_7                               0.80474     0.00068    0.80580     0.80368
alpha_8                               0.80447     0.00069    0.80554     0.80339
alpha_9                               0.80423     0.00069    0.80531     0.80314
Alpha_loss                            -1.43713    0.00558    -1.42995    -1.44694
Training/policy_loss                  -9.86758    0.05564    -9.77669    -9.95185
Training/qf1_loss                     2056.54186  478.10519  2995.23242  1325.70593
Training/qf2_loss                     2053.63583  477.58023  2992.01709  1324.77429
Training/pf_norm                      0.16637     0.02758    0.21921     0.12016
Training/qf1_norm                     410.75792   20.79172   449.88300   385.62994
Training/qf2_norm                     403.07816   20.59557   442.13095   380.14523
log_std/mean                          -0.15274    0.00128    -0.15081    -0.15467
log_std/std                           0.02752     0.00057    0.02834     0.02644
log_std/max                           -0.11792    0.00165    -0.11594    -0.12084
log_std/min                           -0.30154    0.00470    -0.29403    -0.30810
log_probs/mean                        -2.61509    0.01129    -2.59719    -2.63763
log_probs/std                         0.53247     0.01742    0.55402     0.49633
log_probs/max                         -0.41990    0.16064    -0.05662    -0.59604
log_probs/min                         -5.42280    0.40222    -4.82373    -5.95460
mean/mean                             -0.04325    0.00015    -0.04303    -0.04348
mean/std                              0.20453     0.00480    0.21182     0.19672
mean/max                              0.31356     0.00982    0.32853     0.29866
mean/min                              -0.81896    0.01869    -0.78899    -0.84646
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 5, 9, 1, 7, 2, 8, 6, 3, 4]
replay_buffer._size: [11258 11250 11250 11250 11250 11250 11250 11250 11257 11255]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.6687426567077637 0.0022134780883789062
train_time 3.672280788421631
2023-09-06 13:34:32,010 MainThread INFO: EPOCH:73
2023-09-06 13:34:32,011 MainThread INFO: Time Consumed:3.8154680728912354s
2023-09-06 13:34:32,011 MainThread INFO: Total Frames:111000s
 18%|‚ñà‚ñä        | 74/400 [03:30<21:07,  3.89s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               797.24945
Train_Epoch_Reward                    11969.11478
Running_Training_Average_Rewards      1022.13305
Explore_Time                          0.13455
Train___Time                          3.67228
Eval____Time                          0.00383
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.95592
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.76960
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.35612
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -34.91005
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.88585
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.27608
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.45861
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8180.67152
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -36.88831
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.18217
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.82174     1.42904    12.93751    8.33744
alpha_0                               0.80296      0.00065    0.80397     0.80195
alpha_1                               0.80196      0.00069    0.80304     0.80089
alpha_2                               0.80208      0.00068    0.80315     0.80101
alpha_3                               0.80193      0.00069    0.80301     0.80086
alpha_4                               0.80196      0.00069    0.80303     0.80089
alpha_5                               0.80202      0.00069    0.80310     0.80095
alpha_6                               0.80198      0.00069    0.80305     0.80090
alpha_7                               0.80239      0.00067    0.80344     0.80133
alpha_8                               0.80208      0.00068    0.80315     0.80101
alpha_9                               0.80182      0.00069    0.80290     0.80074
Alpha_loss                            -1.45325     0.00439    -1.44726    -1.46303
Training/policy_loss                  -10.05407    0.05237    -9.96404    -10.13947
Training/qf1_loss                     2309.06209   866.94209  3478.13599  973.29877
Training/qf2_loss                     2306.03298   866.82924  3473.57300  970.24750
Training/pf_norm                      0.16993      0.02762    0.20805     0.13050
Training/qf1_norm                     443.69780    67.76344   546.41010   329.16946
Training/qf2_norm                     435.41788    66.19815   537.19543   323.41110
log_std/mean                          -0.15366     0.00104    -0.15158    -0.15470
log_std/std                           0.02874      0.00017    0.02892     0.02835
log_std/max                           -0.12091     0.00145    -0.11875    -0.12300
log_std/min                           -0.31068     0.00061    -0.30973    -0.31205
log_probs/mean                        -2.59934     0.01354    -2.58469    -2.62095
log_probs/std                         0.55680      0.01718    0.58213     0.53464
log_probs/max                         -0.24945     0.15854    0.08126     -0.40929
log_probs/min                         -5.76661     0.69213    -4.56164    -6.77766
mean/mean                             -0.04390     0.00043    -0.04310    -0.04443
mean/std                              0.21769      0.00233    0.22016     0.21299
mean/max                              0.34540      0.00810    0.35704     0.33226
mean/min                              -0.86980     0.00833    -0.85434    -0.87953
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 8, 3, 2, 9, 0, 5, 7, 4, 6]
replay_buffer._size: [11400 11400 11400 11400 11400 11400 11400 11400 11400 11400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.121835947036743 0.0022568702697753906
train_time 4.125450372695923
2023-09-06 13:34:36,321 MainThread INFO: EPOCH:74
2023-09-06 13:34:36,321 MainThread INFO: Time Consumed:4.14240837097168s
2023-09-06 13:34:36,322 MainThread INFO: Total Frames:112500s
 19%|‚ñà‚ñâ        | 75/400 [03:34<21:42,  4.01s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               775.90338
Train_Epoch_Reward                    8667.83340
Running_Training_Average_Rewards      1008.86293
Explore_Time                          0.00505
Train___Time                          4.12545
Eval____Time                          0.00736
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.52907
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.52775
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.81009
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.81187
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.58002
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.04003
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.61753
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7883.79619
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.09852
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.26719
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.60528    0.80867    11.84664    9.15664
alpha_0                               0.80072     0.00064    0.80172     0.79973
alpha_1                               0.79958     0.00068    0.80065     0.79850
alpha_2                               0.79971     0.00068    0.80078     0.79864
alpha_3                               0.79955     0.00068    0.80062     0.79848
alpha_4                               0.79958     0.00068    0.80065     0.79851
alpha_5                               0.79964     0.00068    0.80071     0.79857
alpha_6                               0.79959     0.00069    0.80066     0.79851
alpha_7                               0.80004     0.00067    0.80110     0.79899
alpha_8                               0.79971     0.00068    0.80078     0.79864
alpha_9                               0.79942     0.00069    0.80050     0.79834
Alpha_loss                            -1.47169    0.00609    -1.46257    -1.48309
Training/policy_loss                  -10.23720   0.05721    -10.15528   -10.32858
Training/qf1_loss                     2360.83560  629.64227  3772.05273  1576.94861
Training/qf2_loss                     2357.66899  629.96437  3770.76953  1574.46777
Training/pf_norm                      0.15492     0.02695    0.21060     0.11743
Training/qf1_norm                     442.65776   37.96861   503.60553   376.34525
Training/qf2_norm                     434.64744   37.08687   493.11935   369.52087
log_std/mean                          -0.14968    0.00049    -0.14907    -0.15079
log_std/std                           0.02920     0.00037    0.02992     0.02873
log_std/max                           -0.12035    0.00102    -0.11828    -0.12154
log_std/min                           -0.30955    0.00122    -0.30738    -0.31143
log_probs/mean                        -2.59449    0.00953    -2.58094    -2.60744
log_probs/std                         0.57776     0.01224    0.58989     0.55328
log_probs/max                         -0.24970    0.17805    0.01680     -0.56564
log_probs/min                         -5.36585    0.43659    -4.54714    -6.18428
mean/mean                             -0.04370    0.00053    -0.04306    -0.04442
mean/std                              0.22190     0.00131    0.22413     0.22019
mean/max                              0.37119     0.00815    0.38231     0.35893
mean/min                              -0.88281    0.00380    -0.87639    -0.88803
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 5, 6, 4, 1, 9, 3, 8, 7, 0]
replay_buffer._size: [11550 11550 11550 11550 11550 11550 11550 11550 11550 11550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7007434368133545 0.002187490463256836
train_time 3.7042899131774902
2023-09-06 13:34:40,356 MainThread INFO: EPOCH:75
2023-09-06 13:34:40,356 MainThread INFO: Time Consumed:3.7323262691497803s
2023-09-06 13:34:40,356 MainThread INFO: Total Frames:114000s
 19%|‚ñà‚ñâ        | 76/400 [03:38<21:40,  4.02s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               752.54174
Train_Epoch_Reward                    10742.70439
Running_Training_Average_Rewards      1045.98842
Explore_Time                          0.00842
Train___Time                          3.70429
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.12698
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.19607
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.84479
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.88826
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.36747
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.79291
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.85235
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7790.66558
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.60954
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.23793
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.76074     0.81485    12.10004    9.30156
alpha_0                               0.79851      0.00063    0.79951     0.79752
alpha_1                               0.79720      0.00068    0.79827     0.79613
alpha_2                               0.79734      0.00068    0.79841     0.79628
alpha_3                               0.79717      0.00068    0.79824     0.79611
alpha_4                               0.79721      0.00068    0.79827     0.79614
alpha_5                               0.79726      0.00068    0.79833     0.79619
alpha_6                               0.79720      0.00068    0.79827     0.79613
alpha_7                               0.79771      0.00067    0.79876     0.79666
alpha_8                               0.79734      0.00068    0.79840     0.79627
alpha_9                               0.79703      0.00069    0.79810     0.79596
Alpha_loss                            -1.48864     0.00509    -1.47812    -1.49440
Training/policy_loss                  -10.42418    0.05542    -10.32206   -10.51791
Training/qf1_loss                     2273.23195   502.00816  3243.71216  1573.42029
Training/qf2_loss                     2270.08729   502.32715  3242.20654  1569.00330
Training/pf_norm                      0.18146      0.03044    0.23028     0.14325
Training/qf1_norm                     456.85265    39.73620   515.73059   384.65500
Training/qf2_norm                     448.49013    38.48182   508.62601   379.00861
log_std/mean                          -0.15158     0.00110    -0.15007    -0.15351
log_std/std                           0.03119      0.00090    0.03280     0.02991
log_std/max                           -0.11410     0.00222    -0.11166    -0.11738
log_std/min                           -0.32008     0.00599    -0.31081    -0.32924
log_probs/mean                        -2.58336     0.01569    -2.55459    -2.60472
log_probs/std                         0.59323      0.01691    0.62239     0.57085
log_probs/max                         -0.05275     0.20538    0.25565     -0.36054
log_probs/min                         -5.71675     0.63582    -4.77454    -7.21391
mean/mean                             -0.04388     0.00061    -0.04313    -0.04502
mean/std                              0.22848      0.00273    0.23334     0.22437
mean/max                              0.40072      0.01034    0.41590     0.38368
mean/min                              -0.90745     0.01256    -0.88607    -0.92566
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 8, 6, 5, 2, 7, 1, 3, 9, 0]
replay_buffer._size: [11700 11700 11700 11700 11700 11700 11700 11700 11700 11700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.979965925216675 0.003135204315185547
train_time 3.9845621585845947
2023-09-06 13:34:44,532 MainThread INFO: EPOCH:76
2023-09-06 13:34:44,533 MainThread INFO: Time Consumed:4.001457691192627s
2023-09-06 13:34:44,534 MainThread INFO: Total Frames:115500s
 19%|‚ñà‚ñâ        | 77/400 [03:42<21:53,  4.07s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               745.84897
Train_Epoch_Reward                    10224.89779
Running_Training_Average_Rewards      987.84785
Explore_Time                          0.00731
Train___Time                          3.98456
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.52553
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.14854
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.87077
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.69525
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.85021
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.99391
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.46132
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7989.51563
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.84344
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.92108
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.02815     0.92899    12.66105    9.79408
alpha_0                               0.79632      0.00062    0.79730     0.79534
alpha_1                               0.79482      0.00068    0.79589     0.79376
alpha_2                               0.79498      0.00068    0.79604     0.79393
alpha_3                               0.79481      0.00068    0.79587     0.79375
alpha_4                               0.79484      0.00068    0.79590     0.79378
alpha_5                               0.79489      0.00068    0.79595     0.79382
alpha_6                               0.79482      0.00068    0.79589     0.79376
alpha_7                               0.79539      0.00066    0.79643     0.79435
alpha_8                               0.79498      0.00067    0.79604     0.79392
alpha_9                               0.79465      0.00068    0.79572     0.79358
Alpha_loss                            -1.50430     0.00693    -1.49551    -1.51670
Training/policy_loss                  -10.61919    0.05044    -10.53072   -10.69934
Training/qf1_loss                     2380.23002   527.53724  3333.33130  1510.65125
Training/qf2_loss                     2378.39412   527.74146  3332.52905  1509.98767
Training/pf_norm                      0.17948      0.02332    0.22707     0.14116
Training/qf1_norm                     478.09443    49.09808   567.61847   417.83752
Training/qf2_norm                     468.20782    47.57616   553.55042   409.29483
log_std/mean                          -0.15595     0.00115    -0.15388    -0.15741
log_std/std                           0.03338      0.00017    0.03354     0.03299
log_std/max                           -0.11746     0.00293    -0.11329    -0.12107
log_std/min                           -0.34250     0.00496    -0.33242    -0.34790
log_probs/mean                        -2.56688     0.01053    -2.55018    -2.58301
log_probs/std                         0.61055      0.01335    0.63599     0.59241
log_probs/max                         -0.07091     0.12145    0.20244     -0.22038
log_probs/min                         -5.65981     0.81686    -4.79488    -7.50339
mean/mean                             -0.04613     0.00072    -0.04509    -0.04732
mean/std                              0.23659      0.00128    0.23849     0.23411
mean/max                              0.42720      0.00354    0.43146     0.41951
mean/min                              -0.95122     0.00963    -0.93153    -0.96418
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 7, 5, 2, 3, 8, 0, 4, 1]
replay_buffer._size: [11850 11850 11850 11850 11850 11850 11850 11850 11850 11850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.8267455101013184 0.0021250247955322266
train_time 3.8301796913146973
2023-09-06 13:34:48,566 MainThread INFO: EPOCH:77
2023-09-06 13:34:48,567 MainThread INFO: Time Consumed:3.843935966491699s
2023-09-06 13:34:48,567 MainThread INFO: Total Frames:117000s
 20%|‚ñà‚ñâ        | 78/400 [03:47<21:49,  4.07s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               751.60216
Train_Epoch_Reward                    10489.80900
Running_Training_Average_Rewards      1048.58037
Explore_Time                          0.00518
Train___Time                          3.83018
Eval____Time                          0.00334
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.57566
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.12816
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.68975
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -37.53979
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.79830
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.19906
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.49444
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8055.03690
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.78123
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.72061
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.86887     0.97066    12.89781    9.58756
alpha_0                               0.79416      0.00062    0.79513     0.79319
alpha_1                               0.79246      0.00068    0.79352     0.79139
alpha_2                               0.79264      0.00067    0.79369     0.79159
alpha_3                               0.79245      0.00068    0.79351     0.79139
alpha_4                               0.79248      0.00068    0.79354     0.79142
alpha_5                               0.79253      0.00068    0.79359     0.79147
alpha_6                               0.79246      0.00068    0.79352     0.79139
alpha_7                               0.79309      0.00066    0.79412     0.79205
alpha_8                               0.79264      0.00067    0.79369     0.79158
alpha_9                               0.79227      0.00068    0.79334     0.79121
Alpha_loss                            -1.52355     0.00782    -1.51334    -1.53740
Training/policy_loss                  -10.81804    0.06288    -10.71474   -10.91133
Training/qf1_loss                     2373.30052   557.67797  3489.92065  1442.44177
Training/qf2_loss                     2370.67108   557.26204  3483.60400  1437.75293
Training/pf_norm                      0.19167      0.03417    0.26529     0.12631
Training/qf1_norm                     478.05396    50.10728   578.21558   404.14432
Training/qf2_norm                     469.18746    49.01398   569.89728   399.24631
log_std/mean                          -0.15927     0.00110    -0.15781    -0.16127
log_std/std                           0.03368      0.00031    0.03435     0.03332
log_std/max                           -0.12574     0.00244    -0.12209    -0.12944
log_std/min                           -0.35436     0.00440    -0.34724    -0.36218
log_probs/mean                        -2.56651     0.02030    -2.53490    -2.59709
log_probs/std                         0.62984      0.01422    0.65035     0.61016
log_probs/max                         0.14716      0.16413    0.33748     -0.14940
log_probs/min                         -5.66290     0.52993    -4.90907    -6.94073
mean/mean                             -0.05007     0.00137    -0.04779    -0.05207
mean/std                              0.24444      0.00349    0.25055     0.23925
mean/max                              0.44216      0.00562    0.45131     0.43209
mean/min                              -0.99442     0.01941    -0.96446    -1.02730
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 1, 9, 6, 2, 8, 7, 0, 3, 5]
replay_buffer._size: [12000 12000 12000 12000 12000 12000 12000 12000 12000 12000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.271579265594482 0.002460956573486328
train_time 4.275383949279785
2023-09-06 13:34:53,049 MainThread INFO: EPOCH:78
2023-09-06 13:34:53,050 MainThread INFO: Time Consumed:4.300554037094116s
2023-09-06 13:34:53,050 MainThread INFO: Total Frames:118500s
 20%|‚ñà‚ñâ        | 79/400 [03:51<22:22,  4.18s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               759.25436
Train_Epoch_Reward                    17964.57997
Running_Training_Average_Rewards      1289.30956
Explore_Time                          0.01690
Train___Time                          4.27538
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.34302
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -62.16701
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.73414
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -38.64326
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.05338
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.64597
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.25818
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8038.83087
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.93551
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.73493
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.60134     1.00140    11.84004    8.56053
alpha_0                               0.79201      0.00061    0.79297     0.79105
alpha_1                               0.79009      0.00068    0.79115     0.78903
alpha_2                               0.79030      0.00067    0.79135     0.78926
alpha_3                               0.79010      0.00067    0.79115     0.78904
alpha_4                               0.79013      0.00067    0.79119     0.78908
alpha_5                               0.79017      0.00067    0.79123     0.78912
alpha_6                               0.79010      0.00068    0.79116     0.78904
alpha_7                               0.79078      0.00066    0.79182     0.78975
alpha_8                               0.79030      0.00067    0.79135     0.78925
alpha_9                               0.78991      0.00068    0.79097     0.78885
Alpha_loss                            -1.53672     0.00549    -1.52537    -1.54311
Training/policy_loss                  -11.01782    0.05986    -10.93366   -11.10623
Training/qf1_loss                     2302.48575   547.93662  3149.02808  1372.33618
Training/qf2_loss                     2300.95862   548.31059  3150.33276  1370.85022
Training/pf_norm                      0.18059      0.03533    0.22338     0.12194
Training/qf1_norm                     474.07609    53.48367   534.13306   366.57990
Training/qf2_norm                     464.55855    51.71167   525.81281   359.93604
log_std/mean                          -0.16250     0.00051    -0.16165    -0.16311
log_std/std                           0.03517      0.00050    0.03591     0.03444
log_std/max                           -0.12635     0.00286    -0.12069    -0.12970
log_std/min                           -0.36954     0.00376    -0.36399    -0.37514
log_probs/mean                        -2.54031     0.01752    -2.52185    -2.58287
log_probs/std                         0.64896      0.01675    0.67264     0.61654
log_probs/max                         0.06925      0.13507    0.37235     -0.13404
log_probs/min                         -5.49558     0.35589    -4.96186    -5.99370
mean/mean                             -0.05361     0.00045    -0.05258    -0.05410
mean/std                              0.25858      0.00393    0.26413     0.25234
mean/max                              0.46526      0.00783    0.47589     0.45351
mean/min                              -1.05201     0.01179    -1.03351    -1.06922
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 0, 7, 6, 4, 3, 2, 1, 9, 8]
replay_buffer._size: [12150 12150 12150 12150 12150 12150 12150 12150 12150 12150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.844257116317749 0.002195119857788086
train_time 3.847757577896118
2023-09-06 13:34:57,101 MainThread INFO: EPOCH:79
2023-09-06 13:34:57,101 MainThread INFO: Time Consumed:3.872882843017578s
2023-09-06 13:34:57,102 MainThread INFO: Total Frames:120000s
 20%|‚ñà‚ñà        | 80/400 [03:55<22:05,  4.14s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               752.60181
Train_Epoch_Reward                    6992.37757
Running_Training_Average_Rewards      1181.55888
Explore_Time                          0.00632
Train___Time                          3.84776
Eval____Time                          0.00295
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.24491
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.28458
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.69325
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.34077
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.02506
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.92625
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.25749
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7823.34154
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.71247
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.22777
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.23288    1.43309    12.06027    7.69399
alpha_0                               0.78988     0.00061    0.79083     0.78893
alpha_1                               0.78774     0.00067    0.78880     0.78669
alpha_2                               0.78798     0.00067    0.78902     0.78694
alpha_3                               0.78775     0.00067    0.78881     0.78670
alpha_4                               0.78779     0.00067    0.78884     0.78674
alpha_5                               0.78784     0.00067    0.78889     0.78679
alpha_6                               0.78775     0.00067    0.78880     0.78669
alpha_7                               0.78849     0.00066    0.78952     0.78747
alpha_8                               0.78797     0.00067    0.78902     0.78693
alpha_9                               0.78755     0.00068    0.78861     0.78649
Alpha_loss                            -1.55271    0.00672    -1.53995    -1.56140
Training/policy_loss                  -11.22306   0.05573    -11.15235   -11.31540
Training/qf1_loss                     2208.61869  871.67052  3372.09033  871.99652
Training/qf2_loss                     2206.28269  870.35749  3367.28101  871.47357
Training/pf_norm                      0.19510     0.02746    0.23829     0.14340
Training/qf1_norm                     462.11344   76.35955   557.43964   322.82092
Training/qf2_norm                     453.50859   75.62909   549.53564   316.40060
log_std/mean                          -0.16060    0.00041    -0.16012    -0.16142
log_std/std                           0.03691     0.00049    0.03790     0.03622
log_std/max                           -0.11918    0.00087    -0.11788    -0.12075
log_std/min                           -0.37983    0.00320    -0.37589    -0.38726
log_probs/mean                        -2.52673    0.01092    -2.50911    -2.54107
log_probs/std                         0.67886     0.00873    0.68958     0.66449
log_probs/max                         0.30880     0.16042    0.59868     0.02451
log_probs/min                         -5.96901    0.41980    -5.20797    -6.64127
mean/mean                             -0.05368    0.00013    -0.05356    -0.05392
mean/std                              0.26650     0.00080    0.26815     0.26542
mean/max                              0.49328     0.00629    0.50362     0.48205
mean/min                              -1.07882    0.00392    -1.07321    -1.08670
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 8, 5, 1, 0, 4, 6, 3, 2, 9]
replay_buffer._size: [12300 12300 12300 12300 12300 12300 12300 12300 12300 12300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.9818737506866455 0.0021445751190185547
train_time 3.9854609966278076
2023-09-06 13:35:01,286 MainThread INFO: EPOCH:80
2023-09-06 13:35:01,286 MainThread INFO: Time Consumed:4.012875556945801s
2023-09-06 13:35:01,287 MainThread INFO: Total Frames:121500s
 20%|‚ñà‚ñà        | 81/400 [03:59<22:06,  4.16s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               740.41044
Train_Epoch_Reward                    9635.19162
Running_Training_Average_Rewards      1153.07164
Explore_Time                          0.01898
Train___Time                          3.98546
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.44185
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.69648
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.90860
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.86502
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.09122
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.05824
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.98636
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7716.37293
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.98078
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.97563
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.72750     0.93290    10.77649    8.07775
alpha_0                               0.78778     0.00060    0.78872     0.78684
alpha_1                               0.78540     0.00067    0.78645     0.78435
alpha_2                               0.78567     0.00066    0.78671     0.78463
alpha_3                               0.78543     0.00067    0.78647     0.78438
alpha_4                               0.78546     0.00067    0.78651     0.78442
alpha_5                               0.78551     0.00067    0.78655     0.78446
alpha_6                               0.78541     0.00067    0.78646     0.78435
alpha_7                               0.78622     0.00065    0.78724     0.78519
alpha_8                               0.78566     0.00066    0.78670     0.78463
alpha_9                               0.78520     0.00067    0.78625     0.78414
Alpha_loss                            -1.56951    0.00751    -1.55384    -1.57856
Training/policy_loss                  -11.43642   0.06432    -11.33667   -11.52736
Training/qf1_loss                     1865.69646  503.35568  2657.96997  866.34473
Training/qf2_loss                     1863.85728  505.48422  2660.14136  860.63446
Training/pf_norm                      0.18288     0.02769    0.23443     0.14850
Training/qf1_norm                     444.29864   54.69094   511.41281   345.30206
Training/qf2_norm                     435.91328   51.68117   499.92010   342.64688
log_std/mean                          -0.16342    0.00093    -0.16167    -0.16444
log_std/std                           0.03978     0.00103    0.04122     0.03821
log_std/max                           -0.12595    0.00163    -0.12254    -0.12798
log_std/min                           -0.39410    0.00505    -0.38472    -0.40069
log_probs/mean                        -2.51700    0.01631    -2.48728    -2.54282
log_probs/std                         0.69297     0.01373    0.70763     0.66537
log_probs/max                         0.23504     0.13697    0.56201     0.05290
log_probs/min                         -5.68496    0.63367    -4.84910    -6.90564
mean/mean                             -0.05398    0.00040    -0.05353    -0.05489
mean/std                              0.27279     0.00250    0.27684     0.26905
mean/max                              0.51398     0.00761    0.52316     0.50004
mean/min                              -1.09467    0.01023    -1.07527    -1.10816
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 4, 6, 7, 1, 3, 5, 8, 2]
replay_buffer._size: [12450 12450 12450 12450 12450 12450 12450 12450 12450 12450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7775228023529053 0.002109050750732422
train_time 3.7809488773345947
2023-09-06 13:35:05,272 MainThread INFO: EPOCH:81
2023-09-06 13:35:05,272 MainThread INFO: Time Consumed:3.8121750354766846s
2023-09-06 13:35:05,273 MainThread INFO: Total Frames:123000s
 20%|‚ñà‚ñà        | 82/400 [04:03<21:45,  4.11s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               733.08434
Train_Epoch_Reward                    9401.46372
Running_Training_Average_Rewards      867.63443
Explore_Time                          0.02331
Train___Time                          3.78095
Eval____Time                          0.00293
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.65614
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.69368
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.10350
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.50704
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.28886
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.73249
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.91398
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7847.81377
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.88797
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.49749
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.43111    0.87108    11.93833    9.29315
alpha_0                               0.78570     0.00059    0.78663     0.78477
alpha_1                               0.78307     0.00067    0.78412     0.78202
alpha_2                               0.78335     0.00066    0.78439     0.78231
alpha_3                               0.78311     0.00066    0.78415     0.78207
alpha_4                               0.78314     0.00066    0.78418     0.78210
alpha_5                               0.78318     0.00067    0.78423     0.78214
alpha_6                               0.78307     0.00067    0.78412     0.78202
alpha_7                               0.78395     0.00065    0.78497     0.78293
alpha_8                               0.78336     0.00066    0.78440     0.78233
alpha_9                               0.78285     0.00067    0.78391     0.78180
Alpha_loss                            -1.58507    0.00469    -1.57796    -1.59064
Training/policy_loss                  -11.64579   0.05991    -11.54447   -11.73908
Training/qf1_loss                     2286.89702  576.33147  3189.26685  1278.35999
Training/qf2_loss                     2285.30284  576.11493  3184.57495  1277.03210
Training/pf_norm                      0.19464     0.02720    0.25218     0.14731
Training/qf1_norm                     488.01383   49.23095   571.85052   422.56131
Training/qf2_norm                     478.68503   47.98799   558.92700   414.93790
log_std/mean                          -0.16388    0.00030    -0.16347    -0.16445
log_std/std                           0.04195     0.00027    0.04234     0.04133
log_std/max                           -0.12472    0.00102    -0.12310    -0.12600
log_std/min                           -0.40410    0.00179    -0.40158    -0.40770
log_probs/mean                        -2.50246    0.01420    -2.47070    -2.52870
log_probs/std                         0.72179     0.02342    0.75604     0.68765
log_probs/max                         0.47626     0.12278    0.73878     0.31525
log_probs/min                         -5.83295    0.56472    -5.08343    -6.55280
mean/mean                             -0.05619    0.00047    -0.05532    -0.05682
mean/std                              0.28375     0.00386    0.29001     0.27786
mean/max                              0.54163     0.01152    0.56299     0.52740
mean/min                              -1.13630    0.01241    -1.11686    -1.15557
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 4, 7, 5, 2, 8, 1, 0, 9, 6]
replay_buffer._size: [12600 12600 12600 12600 12600 12600 12600 12600 12600 12600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.4237451553344727 0.0021181106567382812
train_time 2.427185535430908
2023-09-06 13:35:09,318 MainThread INFO: EPOCH:82
2023-09-06 13:35:09,318 MainThread INFO: Time Consumed:2.4443581104278564s
2023-09-06 13:35:09,319 MainThread INFO: Total Frames:124500s
 21%|‚ñà‚ñà        | 83/400 [04:07<21:37,  4.09s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               734.26187
Train_Epoch_Reward                    10772.23130
Running_Training_Average_Rewards      993.62955
Explore_Time                          0.00934
Train___Time                          2.42719
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.81845
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.53781
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.38584
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.58157
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.04759
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.20712
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.34294
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7871.34465
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.35475
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.11379
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.87278      1.04311    11.69056    8.13940
alpha_0                               0.78365      0.00058    0.78456     0.78273
alpha_1                               0.78075      0.00067    0.78179     0.77970
alpha_2                               0.78105      0.00066    0.78208     0.78002
alpha_3                               0.78080      0.00066    0.78184     0.77976
alpha_4                               0.78083      0.00066    0.78187     0.77980
alpha_5                               0.78086      0.00066    0.78190     0.77982
alpha_6                               0.78074      0.00067    0.78178     0.77969
alpha_7                               0.78169      0.00065    0.78270     0.78067
alpha_8                               0.78107      0.00066    0.78210     0.78005
alpha_9                               0.78052      0.00067    0.78157     0.77947
Alpha_loss                            -1.59707     0.00414    -1.58908    -1.60436
Training/policy_loss                  -11.86553    0.06918    -11.75964   -11.97032
Training/qf1_loss                     2021.65868   725.76958  3403.14844  1088.06555
Training/qf2_loss                     2019.10233   726.05356  3399.70239  1084.36328
Training/pf_norm                      0.20673      0.02872    0.26170     0.17149
Training/qf1_norm                     463.89536    58.13528   556.19281   368.83029
Training/qf2_norm                     456.33357    56.56270   546.93683   363.30493
log_std/mean                          -0.16531     0.00082    -0.16395    -0.16625
log_std/std                           0.04207      0.00018    0.04243     0.04178
log_std/max                           -0.12639     0.00129    -0.12407    -0.12831
log_std/min                           -0.40955     0.00285    -0.40340    -0.41194
log_probs/mean                        -2.47401     0.02027    -2.44884    -2.52292
log_probs/std                         0.75046      0.02345    0.78312     0.70755
log_probs/max                         0.70417      0.20674    0.99868     0.34999
log_probs/min                         -5.65669     0.65111    -4.93397    -7.34955
mean/mean                             -0.05826     0.00113    -0.05690    -0.06012
mean/std                              0.29630      0.00305    0.30017     0.29135
mean/max                              0.57709      0.00859    0.58855     0.55977
mean/min                              -1.16466     0.00936    -1.14435    -1.17371
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 1, 4, 9, 5, 3, 8, 2, 7, 0]
replay_buffer._size: [12750 12750 12750 12750 12750 12750 12750 12750 12750 12750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.059763193130493 0.002101898193359375
train_time 4.063179016113281
2023-09-06 13:35:13,578 MainThread INFO: EPOCH:83
2023-09-06 13:35:13,578 MainThread INFO: Time Consumed:4.076282739639282s
2023-09-06 13:35:13,579 MainThread INFO: Total Frames:126000s
 21%|‚ñà‚ñà        | 84/400 [04:12<21:46,  4.13s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               736.15433
Train_Epoch_Reward                    5894.34611
Running_Training_Average_Rewards      868.93470
Explore_Time                          0.00453
Train___Time                          4.06318
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.61837
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.72980
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.66914
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.35286
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.10990
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.82236
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.55201
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7802.10595
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.94780
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.16112
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.25964    0.58105    11.31912    9.17935
alpha_0                               0.78163     0.00058    0.78253     0.78073
alpha_1                               0.77843     0.00066    0.77947     0.77739
alpha_2                               0.77876     0.00066    0.77979     0.77772
alpha_3                               0.77850     0.00066    0.77953     0.77747
alpha_4                               0.77854     0.00066    0.77957     0.77751
alpha_5                               0.77856     0.00066    0.77959     0.77752
alpha_6                               0.77842     0.00066    0.77946     0.77738
alpha_7                               0.77944     0.00064    0.78045     0.77844
alpha_8                               0.77879     0.00066    0.77982     0.77776
alpha_9                               0.77819     0.00067    0.77924     0.77715
Alpha_loss                            -1.61577    0.00468    -1.60642    -1.62354
Training/policy_loss                  -12.07995   0.06596    -11.97131   -12.19504
Training/qf1_loss                     2004.49042  363.48793  2333.75439  1369.16040
Training/qf2_loss                     2002.99220  363.26284  2331.99731  1368.23474
Training/pf_norm                      0.21212     0.03627    0.29040     0.15238
Training/qf1_norm                     494.07715   34.59840   554.97815   426.57819
Training/qf2_norm                     484.73816   33.58346   542.97699   418.43927
log_std/mean                          -0.16520    0.00048    -0.16441    -0.16586
log_std/std                           0.04364     0.00093    0.04524     0.04208
log_std/max                           -0.12357    0.00129    -0.12120    -0.12506
log_std/min                           -0.41767    0.00488    -0.41096    -0.42693
log_probs/mean                        -2.47325    0.02347    -2.42962    -2.52485
log_probs/std                         0.77598     0.01358    0.79572     0.74481
log_probs/max                         0.73838     0.15722    0.95420     0.48924
log_probs/min                         -5.99883    0.89400    -5.35336    -8.49937
mean/mean                             -0.06156    0.00041    -0.06058    -0.06203
mean/std                              0.30661     0.00426    0.31442     0.30054
mean/max                              0.60422     0.01093    0.62506     0.58903
mean/min                              -1.18150    0.00898    -1.17139    -1.20094
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 8, 1, 3, 5, 2, 6, 0, 7, 4]
replay_buffer._size: [12900 12900 12900 12900 12900 12900 12900 12900 12900 12900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.228015184402466 0.002534627914428711
train_time 4.231927156448364
2023-09-06 13:35:18,002 MainThread INFO: EPOCH:84
2023-09-06 13:35:18,003 MainThread INFO: Time Consumed:4.247565746307373s
2023-09-06 13:35:18,003 MainThread INFO: Total Frames:127500s
 21%|‚ñà‚ñà‚ñè       | 85/400 [04:16<22:14,  4.24s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               725.22131
Train_Epoch_Reward                    7575.46153
Running_Training_Average_Rewards      808.06796
Explore_Time                          0.00617
Train___Time                          4.23193
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.50628
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -68.72292
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.34978
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.79104
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.99248
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.09099
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.77178
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7550.58189
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.49172
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.32301
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.26359    0.77214    11.15259    8.35721
alpha_0                               0.77963     0.00057    0.78053     0.77874
alpha_1                               0.77612     0.00066    0.77716     0.77509
alpha_2                               0.77647     0.00065    0.77750     0.77545
alpha_3                               0.77621     0.00066    0.77724     0.77518
alpha_4                               0.77625     0.00066    0.77728     0.77522
alpha_5                               0.77626     0.00066    0.77729     0.77523
alpha_6                               0.77611     0.00066    0.77715     0.77508
alpha_7                               0.77722     0.00064    0.77821     0.77622
alpha_8                               0.77651     0.00065    0.77754     0.77549
alpha_9                               0.77587     0.00066    0.77691     0.77484
Alpha_loss                            -1.62443    0.00443    -1.61743    -1.63217
Training/policy_loss                  -12.31040   0.06887    -12.21129   -12.41841
Training/qf1_loss                     2187.94204  440.08430  2797.03418  1270.37939
Training/qf2_loss                     2186.27305  440.07206  2795.44971  1267.57263
Training/pf_norm                      0.20015     0.03017    0.24456     0.13358
Training/qf1_norm                     500.66386   45.98723   553.21460   385.57419
Training/qf2_norm                     492.01898   44.67999   542.58179   380.82294
log_std/mean                          -0.16397    0.00023    -0.16351    -0.16431
log_std/std                           0.04774     0.00153    0.05013     0.04558
log_std/max                           -0.11887    0.00175    -0.11631    -0.12134
log_std/min                           -0.44086    0.00813    -0.42741    -0.45128
log_probs/mean                        -2.43267    0.02552    -2.38945    -2.47350
log_probs/std                         0.82569     0.02551    0.87377     0.77742
log_probs/max                         0.97810     0.26612    1.28929     0.53007
log_probs/min                         -6.31817    0.83017    -5.27724    -7.93084
mean/mean                             -0.06150    0.00029    -0.06108    -0.06196
mean/std                              0.32466     0.00536    0.33237     0.31596
mean/max                              0.63948     0.00795    0.64929     0.62474
mean/min                              -1.23007    0.01658    -1.20030    -1.24875
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 8, 2, 4, 0, 3, 7, 5, 9, 6]
replay_buffer._size: [13050 13050 13050 13050 13050 13050 13050 13050 13050 13050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.079519510269165 0.002260446548461914
train_time 4.083118915557861
2023-09-06 13:35:22,389 MainThread INFO: EPOCH:85
2023-09-06 13:35:22,390 MainThread INFO: Time Consumed:4.11678671836853s
2023-09-06 13:35:22,390 MainThread INFO: Total Frames:129000s
 22%|‚ñà‚ñà‚ñè       | 86/400 [04:20<22:22,  4.28s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               709.27762
Train_Epoch_Reward                    9294.82995
Running_Training_Average_Rewards      758.82125
Explore_Time                          0.01013
Train___Time                          4.08312
Eval____Time                          0.00536
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.07004
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -69.82693
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.42208
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.35708
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.98394
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.73721
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.07581
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7417.97269
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.26089
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.59459
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.16569    0.94880    12.33705    8.98025
alpha_0                               0.77767     0.00056    0.77855     0.77680
alpha_1                               0.77382     0.00066    0.77486     0.77279
alpha_2                               0.77421     0.00065    0.77522     0.77319
alpha_3                               0.77393     0.00065    0.77495     0.77290
alpha_4                               0.77397     0.00065    0.77499     0.77295
alpha_5                               0.77397     0.00066    0.77500     0.77294
alpha_6                               0.77381     0.00066    0.77485     0.77278
alpha_7                               0.77502     0.00063    0.77600     0.77403
alpha_8                               0.77425     0.00065    0.77527     0.77324
alpha_9                               0.77357     0.00066    0.77460     0.77253
Alpha_loss                            -1.63941    0.00840    -1.62892    -1.65730
Training/policy_loss                  -12.55018   0.06755    -12.43777   -12.66324
Training/qf1_loss                     2151.05302  600.89737  3665.72974  1353.63574
Training/qf2_loss                     2149.55031  600.10980  3662.43628  1354.52002
Training/pf_norm                      0.21286     0.03610    0.29095     0.14756
Training/qf1_norm                     504.56244   57.79931   634.67145   426.75378
Training/qf2_norm                     495.78043   56.33174   624.45618   420.97168
log_std/mean                          -0.16498    0.00070    -0.16413    -0.16610
log_std/std                           0.05095     0.00046    0.05164     0.05018
log_std/max                           -0.11801    0.00153    -0.11556    -0.12044
log_std/min                           -0.45680    0.00257    -0.45303    -0.46170
log_probs/mean                        -2.41810    0.03548    -2.35783    -2.47735
log_probs/std                         0.85260     0.02234    0.88681     0.81872
log_probs/max                         1.23387     0.22757    1.52021     0.70874
log_probs/min                         -5.91675    0.69297    -5.29768    -7.57864
mean/mean                             -0.05919    0.00094    -0.05802    -0.06078
mean/std                              0.33794     0.00352    0.34355     0.33261
mean/max                              0.66711     0.01146    0.68493     0.65233
mean/min                              -1.25436    0.00447    -1.24784    -1.26366
------------------------------------  ----------  ---------  ----------  ----------
sample: [7, 0, 1, 4, 6, 3, 5, 2, 9, 8]
replay_buffer._size: [13200 13200 13200 13200 13200 13200 13200 13200 13200 13200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.340948104858398 0.002123117446899414
train_time 4.344390392303467
2023-09-06 13:35:26,910 MainThread INFO: EPOCH:86
2023-09-06 13:35:26,911 MainThread INFO: Time Consumed:4.359931945800781s
2023-09-06 13:35:26,912 MainThread INFO: Total Frames:130500s
 22%|‚ñà‚ñà‚ñè       | 87/400 [04:25<22:38,  4.34s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               691.73455
Train_Epoch_Reward                    11075.71874
Running_Training_Average_Rewards      931.53367
Explore_Time                          0.00561
Train___Time                          4.34439
Eval____Time                          0.00352
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.07232
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.31556
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.17684
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.27347
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.70368
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.01784
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.05405
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7293.90061
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.21180
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.22468
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.15503     0.84670    11.79507    9.13488
alpha_0                               0.77574      0.00055    0.77661     0.77488
alpha_1                               0.77153      0.00066    0.77256     0.77050
alpha_2                               0.77195      0.00065    0.77296     0.77094
alpha_3                               0.77165      0.00065    0.77268     0.77063
alpha_4                               0.77170      0.00065    0.77272     0.77069
alpha_5                               0.77169      0.00065    0.77272     0.77067
alpha_6                               0.77151      0.00066    0.77255     0.77048
alpha_7                               0.77283      0.00063    0.77381     0.77185
alpha_8                               0.77200      0.00065    0.77301     0.77099
alpha_9                               0.77127      0.00066    0.77230     0.77024
Alpha_loss                            -1.65181     0.00593    -1.64356    -1.66340
Training/policy_loss                  -12.79014    0.07821    -12.64726   -12.89528
Training/qf1_loss                     2058.00211   483.36764  2946.08545  1393.29834
Training/qf2_loss                     2056.48744   482.44441  2942.36670  1389.95862
Training/pf_norm                      0.20149      0.02589    0.25295     0.16413
Training/qf1_norm                     509.73464    50.41914   605.78925   446.44812
Training/qf2_norm                     501.09590    49.98850   596.45221   440.43411
log_std/mean                          -0.16683     0.00084    -0.16576    -0.16828
log_std/std                           0.05158      0.00021    0.05190     0.05124
log_std/max                           -0.12255     0.00100    -0.12077    -0.12414
log_std/min                           -0.46100     0.00154    -0.45806    -0.46285
log_probs/mean                        -2.39411     0.01951    -2.37109    -2.44270
log_probs/std                         0.87008      0.01694    0.89776     0.84020
log_probs/max                         1.23884      0.33891    1.80597     0.70230
log_probs/min                         -5.98446     1.27450    -4.69931    -9.10569
mean/mean                             -0.05833     0.00039    -0.05789    -0.05920
mean/std                              0.34929      0.00390    0.35562     0.34342
mean/max                              0.70810      0.01218    0.72515     0.68612
mean/min                              -1.26866     0.01034    -1.25310    -1.28645
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 5, 8, 3, 2, 7, 9, 0, 4, 6]
replay_buffer._size: [13350 13350 13350 13350 13350 13350 13350 13350 13350 13350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.026710748672485 0.0021789073944091797
train_time 4.030191659927368
2023-09-06 13:35:31,135 MainThread INFO: EPOCH:87
2023-09-06 13:35:31,135 MainThread INFO: Time Consumed:4.044776439666748s
2023-09-06 13:35:31,136 MainThread INFO: Total Frames:132000s
 22%|‚ñà‚ñà‚ñè       | 88/400 [04:29<22:22,  4.30s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               682.25867
Train_Epoch_Reward                    9479.88883
Running_Training_Average_Rewards      995.01458
Explore_Time                          0.00562
Train___Time                          4.03019
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.88804
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.71789
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.90364
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.46008
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.16942
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.94924
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -47.24320
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7282.42021
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.68209
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.14087
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.78068     1.19008    12.40480    8.46657
alpha_0                               0.77383     0.00054    0.77469     0.77298
alpha_1                               0.76926     0.00065    0.77028     0.76824
alpha_2                               0.76971     0.00064    0.77072     0.76870
alpha_3                               0.76939     0.00065    0.77041     0.76838
alpha_4                               0.76945     0.00065    0.77046     0.76844
alpha_5                               0.76943     0.00065    0.77045     0.76842
alpha_6                               0.76922     0.00066    0.77025     0.76820
alpha_7                               0.77066     0.00062    0.77164     0.76968
alpha_8                               0.76976     0.00064    0.77077     0.76876
alpha_9                               0.76898     0.00066    0.77001     0.76795
Alpha_loss                            -1.66345    0.00645    -1.65154    -1.67083
Training/policy_loss                  -13.03450   0.07369    -12.89549   -13.13815
Training/qf1_loss                     1901.57211  427.51073  2708.96851  1172.65723
Training/qf2_loss                     1899.66655  427.78261  2706.03687  1171.01038
Training/pf_norm                      0.20478     0.02676    0.23514     0.14572
Training/qf1_norm                     490.26001   77.64212   666.27203   406.52017
Training/qf2_norm                     482.27217   74.95209   651.05145   400.29410
log_std/mean                          -0.17325    0.00290    -0.16882    -0.17764
log_std/std                           0.05249     0.00118    0.05456     0.05117
log_std/max                           -0.12330    0.00072    -0.12179    -0.12421
log_std/min                           -0.47152    0.00850    -0.45977    -0.48629
log_probs/mean                        -2.36781    0.02535    -2.32936    -2.40386
log_probs/std                         0.92012     0.02003    0.95271     0.88108
log_probs/max                         1.39220     0.25683    1.87489     1.01952
log_probs/min                         -6.49118    0.42647    -5.88578    -7.06333
mean/mean                             -0.06078    0.00117    -0.05948    -0.06306
mean/std                              0.36645     0.00638    0.37622     0.35700
mean/max                              0.74692     0.01465    0.77211     0.72417
mean/min                              -1.32002    0.02071    -1.28641    -1.35386
------------------------------------  ----------  ---------  ----------  ----------
sample: [6, 2, 1, 8, 5, 3, 9, 0, 7, 4]
replay_buffer._size: [13500 13500 13500 13500 13500 13500 13500 13500 13500 13500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.422157049179077 0.002140045166015625
train_time 4.425625562667847
2023-09-06 13:35:35,792 MainThread INFO: EPOCH:88
2023-09-06 13:35:35,792 MainThread INFO: Time Consumed:4.478001594543457s
2023-09-06 13:35:35,793 MainThread INFO: Total Frames:133500s
 22%|‚ñà‚ñà‚ñè       | 89/400 [04:34<22:51,  4.41s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               677.20114
Train_Epoch_Reward                    9881.23332
Running_Training_Average_Rewards      1014.56136
Explore_Time                          0.03377
Train___Time                          4.42563
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.42684
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -73.06088
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.90223
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.96416
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.65880
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.92962
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.86087
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7289.06160
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.87273
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.46738
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.31453    1.14839    11.99889    8.43362
alpha_0                               0.77196     0.00053    0.77279     0.77113
alpha_1                               0.76700     0.00065    0.76801     0.76598
alpha_2                               0.76747     0.00064    0.76848     0.76647
alpha_3                               0.76714     0.00064    0.76815     0.76613
alpha_4                               0.76721     0.00064    0.76822     0.76620
alpha_5                               0.76718     0.00065    0.76819     0.76617
alpha_6                               0.76695     0.00065    0.76797     0.76592
alpha_7                               0.76850     0.00061    0.76947     0.76754
alpha_8                               0.76754     0.00063    0.76854     0.76655
alpha_9                               0.76670     0.00065    0.76772     0.76568
Alpha_loss                            -1.66926    0.00768    -1.65616    -1.67969
Training/policy_loss                  -13.28335   0.07305    -13.17153   -13.38893
Training/qf1_loss                     2170.46046  496.45487  2915.79126  1385.10034
Training/qf2_loss                     2169.80647  496.34355  2911.29443  1386.92676
Training/pf_norm                      0.21453     0.04218    0.29490     0.15372
Training/qf1_norm                     536.50114   75.13696   647.52191   420.41467
Training/qf2_norm                     527.14242   73.26709   633.93884   411.91672
log_std/mean                          -0.18000    0.00079    -0.17848    -0.18106
log_std/std                           0.05584     0.00047    0.05653     0.05512
log_std/max                           -0.12173    0.00104    -0.12030    -0.12334
log_std/min                           -0.48755    0.00132    -0.48540    -0.48932
log_probs/mean                        -2.32001    0.02270    -2.27816    -2.34747
log_probs/std                         0.95758     0.01822    0.99346     0.93242
log_probs/max                         1.55313     0.26163    1.87417     1.04092
log_probs/min                         -6.32006    0.67355    -5.33444    -7.49523
mean/mean                             -0.06638    0.00151    -0.06367    -0.06833
mean/std                              0.38207     0.00192    0.38505     0.37855
mean/max                              0.79259     0.01189    0.81319     0.77579
mean/min                              -1.35744    0.00291    -1.35300    -1.36154
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 3, 8, 9, 1, 6, 2, 5, 7, 4]
replay_buffer._size: [13650 13650 13650 13650 13650 13650 13650 13650 13650 13650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.543367385864258 0.0020973682403564453
train_time 2.546752691268921
2023-09-06 13:35:40,092 MainThread INFO: EPOCH:89
2023-09-06 13:35:40,093 MainThread INFO: Time Consumed:2.560563325881958s
2023-09-06 13:35:40,093 MainThread INFO: Total Frames:135000s
 22%|‚ñà‚ñà‚ñé       | 90/400 [04:38<22:36,  4.38s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               678.79612
Train_Epoch_Reward                    5048.23546
Running_Training_Average_Rewards      813.64525
Explore_Time                          0.00497
Train___Time                          2.54675
Eval____Time                          0.00460
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.48429
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.13787
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.26618
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.07639
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.49703
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -91.32356
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.37744
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7374.77015
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.81224
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.09552
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.78694     1.07702    11.30716    7.73166
alpha_0                               0.77013     0.00052    0.77095     0.76931
alpha_1                               0.76475     0.00064    0.76576     0.76374
alpha_2                               0.76525     0.00064    0.76625     0.76426
alpha_3                               0.76491     0.00064    0.76591     0.76392
alpha_4                               0.76497     0.00064    0.76597     0.76397
alpha_5                               0.76494     0.00064    0.76595     0.76393
alpha_6                               0.76468     0.00065    0.76570     0.76366
alpha_7                               0.76637     0.00061    0.76733     0.76542
alpha_8                               0.76534     0.00063    0.76633     0.76435
alpha_9                               0.76444     0.00065    0.76546     0.76343
Alpha_loss                            -1.68158    0.00734    -1.66790    -1.69078
Training/policy_loss                  -13.53096   0.07741    -13.41684   -13.63347
Training/qf1_loss                     1841.55320  514.56047  2921.30151  1161.72498
Training/qf2_loss                     1840.45729  515.63665  2922.85596  1160.81140
Training/pf_norm                      0.21169     0.02268    0.24342     0.16815
Training/qf1_norm                     506.57039   72.89308   604.87244   366.57162
Training/qf2_norm                     498.57228   70.31115   593.77130   362.47360
log_std/mean                          -0.18051    0.00061    -0.17943    -0.18115
log_std/std                           0.05691     0.00028    0.05725     0.05646
log_std/max                           -0.12101    0.00105    -0.11933    -0.12254
log_std/min                           -0.48037    0.00257    -0.47661    -0.48520
log_probs/mean                        -2.29818    0.02750    -2.24934    -2.33611
log_probs/std                         0.98134     0.02300    1.02676     0.95024
log_probs/max                         1.72841     0.17847    1.94724     1.30335
log_probs/min                         -6.22852    0.99208    -5.29162    -8.79236
mean/mean                             -0.06798    0.00018    -0.06765    -0.06823
mean/std                              0.39066     0.00344    0.39589     0.38542
mean/max                              0.83062     0.00757    0.84084     0.81875
mean/min                              -1.35595    0.00391    -1.34922    -1.36138
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 5, 1, 7, 9, 8, 4, 3, 6, 2]
replay_buffer._size: [13800 13800 13800 13800 13800 13800 13800 13800 13800 13800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.3949668407440186 0.0022590160369873047
train_time 4.39858603477478
2023-09-06 13:35:44,691 MainThread INFO: EPOCH:90
2023-09-06 13:35:44,691 MainThread INFO: Time Consumed:4.414457082748413s
2023-09-06 13:35:44,692 MainThread INFO: Total Frames:136500s
 23%|‚ñà‚ñà‚ñé       | 91/400 [04:43<22:55,  4.45s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               679.92283
Train_Epoch_Reward                    9179.22300
Running_Training_Average_Rewards      803.62306
Explore_Time                          0.00693
Train___Time                          4.39859
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.69701
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.93528
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.25715
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.34952
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.81547
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -92.18798
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.85410
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7343.38113
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.93513
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.28227
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           10.07296    0.81778    11.56692    8.98093
alpha_0                               0.76832     0.00051    0.76913     0.76752
alpha_1                               0.76251     0.00064    0.76352     0.76151
alpha_2                               0.76304     0.00063    0.76403     0.76206
alpha_3                               0.76270     0.00063    0.76369     0.76171
alpha_4                               0.76275     0.00064    0.76375     0.76175
alpha_5                               0.76271     0.00064    0.76371     0.76171
alpha_6                               0.76242     0.00065    0.76343     0.76141
alpha_7                               0.76425     0.00061    0.76521     0.76329
alpha_8                               0.76315     0.00063    0.76413     0.76217
alpha_9                               0.76219     0.00065    0.76320     0.76118
Alpha_loss                            -1.69389    0.00456    -1.68477    -1.70210
Training/policy_loss                  -13.79916   0.06450    -13.70113   -13.92737
Training/qf1_loss                     2089.99658  414.04923  2774.20508  1374.52698
Training/qf2_loss                     2088.73824  413.69123  2771.23608  1374.87610
Training/pf_norm                      0.21428     0.03218    0.26765     0.15980
Training/qf1_norm                     529.81830   53.71937   635.57983   466.11951
Training/qf2_norm                     521.81493   52.76959   626.53687   458.17166
log_std/mean                          -0.18037    0.00073    -0.17959    -0.18194
log_std/std                           0.05809     0.00041    0.05898     0.05755
log_std/max                           -0.12499    0.00179    -0.12216    -0.12726
log_std/min                           -0.48578    0.00392    -0.47861    -0.49136
log_probs/mean                        -2.27720    0.01630    -2.25760    -2.30507
log_probs/std                         1.00521     0.02196    1.03094     0.96682
log_probs/max                         1.74257     0.23696    2.12723     1.44561
log_probs/min                         -6.59589    0.97812    -5.25097    -9.00719
mean/mean                             -0.06896    0.00107    -0.06758    -0.07102
mean/std                              0.40364     0.00410    0.41129     0.39793
mean/max                              0.85022     0.00669    0.86169     0.83941
mean/min                              -1.37282    0.01078    -1.35548    -1.39230
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 6, 5, 4, 3, 1, 0, 7, 8, 2]
replay_buffer._size: [13950 13950 13950 13950 13950 13950 13950 13950 13950 13950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.411020755767822 0.0021135807037353516
train_time 4.414450407028198
2023-09-06 13:35:49,308 MainThread INFO: EPOCH:91
2023-09-06 13:35:49,309 MainThread INFO: Time Consumed:4.442358493804932s
2023-09-06 13:35:49,309 MainThread INFO: Total Frames:138000s
 23%|‚ñà‚ñà‚ñé       | 92/400 [04:47<23:04,  4.50s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               674.16140
Train_Epoch_Reward                    7502.87796
Running_Training_Average_Rewards      724.34455
Explore_Time                          0.02067
Train___Time                          4.41445
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.40616
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -76.42142
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.39228
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.60614
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.09304
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.08675
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.16251
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7133.52118
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.86132
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.41629
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.33466     1.16700    11.16743    7.97994
alpha_0                               0.76655     0.00050    0.76734     0.76576
alpha_1                               0.76029     0.00064    0.76129     0.75929
alpha_2                               0.76085     0.00063    0.76184     0.75987
alpha_3                               0.76051     0.00063    0.76149     0.75952
alpha_4                               0.76054     0.00063    0.76153     0.75955
alpha_5                               0.76051     0.00063    0.76149     0.75952
alpha_6                               0.76017     0.00064    0.76118     0.75916
alpha_7                               0.76214     0.00060    0.76308     0.76119
alpha_8                               0.76098     0.00062    0.76195     0.76000
alpha_9                               0.75994     0.00064    0.76095     0.75894
Alpha_loss                            -1.69835    0.01264    -1.68072    -1.71839
Training/policy_loss                  -14.05102   0.07144    -13.95282   -14.16841
Training/qf1_loss                     1620.40587  601.65881  2823.21167  975.48944
Training/qf2_loss                     1617.92114  601.60577  2820.35400  971.59943
Training/pf_norm                      0.22590     0.04426    0.30243     0.16193
Training/qf1_norm                     487.38620   78.61880   608.27332   392.95944
Training/qf2_norm                     481.52259   77.13125   600.20148   389.46417
log_std/mean                          -0.18355    0.00051    -0.18265    -0.18423
log_std/std                           0.06017     0.00059    0.06091     0.05924
log_std/max                           -0.12805    0.00051    -0.12729    -0.12915
log_std/min                           -0.49936    0.00368    -0.49281    -0.50504
log_probs/mean                        -2.22743    0.03807    -2.15316    -2.28110
log_probs/std                         1.04609     0.02561    1.08368     1.00950
log_probs/max                         2.05725     0.23202    2.53554     1.63704
log_probs/min                         -6.36071    0.63017    -5.41708    -7.48571
mean/mean                             -0.07342    0.00119    -0.07168    -0.07533
mean/std                              0.41844     0.00284    0.42258     0.41353
mean/max                              0.86958     0.00547    0.88307     0.86220
mean/min                              -1.41063    0.00789    -1.39623    -1.42516
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 0, 7, 3, 5, 9, 6, 8, 4, 2]
replay_buffer._size: [14100 14100 14100 14100 14100 14100 14100 14100 14100 14100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.343961954116821 0.002109527587890625
train_time 4.347372055053711
2023-09-06 13:35:53,861 MainThread INFO: EPOCH:92
2023-09-06 13:35:53,861 MainThread INFO: Time Consumed:4.367740154266357s
2023-09-06 13:35:53,862 MainThread INFO: Total Frames:139500s
 23%|‚ñà‚ñà‚ñé       | 93/400 [04:52<23:04,  4.51s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               656.42274
Train_Epoch_Reward                    9500.51974
Running_Training_Average_Rewards      872.75402
Explore_Time                          0.01204
Train___Time                          4.34737
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.58553
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.38212
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.48269
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.29303
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.73783
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -93.86451
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -52.90983
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6864.55300
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.73548
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.02233
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.51876     1.07048    11.22122    8.57470
alpha_0                               0.76481     0.00050    0.76559     0.76403
alpha_1                               0.75807     0.00064    0.75907     0.75708
alpha_2                               0.75867     0.00062    0.75965     0.75769
alpha_3                               0.75832     0.00063    0.75930     0.75734
alpha_4                               0.75834     0.00063    0.75933     0.75735
alpha_5                               0.75832     0.00063    0.75930     0.75734
alpha_6                               0.75793     0.00064    0.75894     0.75693
alpha_7                               0.76005     0.00060    0.76099     0.75912
alpha_8                               0.75882     0.00062    0.75979     0.75785
alpha_9                               0.75771     0.00064    0.75871     0.75670
Alpha_loss                            -1.71186    0.00584    -1.70257    -1.72012
Training/policy_loss                  -14.32853   0.07925    -14.18383   -14.43075
Training/qf1_loss                     1794.31543  537.25725  2541.57861  1143.37659
Training/qf2_loss                     1792.18268  537.35394  2541.68799  1141.35071
Training/pf_norm                      0.22787     0.04315    0.31101     0.15755
Training/qf1_norm                     505.30552   76.61756   632.08136   437.69269
Training/qf2_norm                     498.97830   74.15035   620.86591   434.21793
log_std/mean                          -0.18564    0.00045    -0.18475    -0.18635
log_std/std                           0.06088     0.00053    0.06191     0.06033
log_std/max                           -0.12677    0.00109    -0.12490    -0.12806
log_std/min                           -0.50044    0.00269    -0.49626    -0.50408
log_probs/mean                        -2.21235    0.01767    -2.18208    -2.23916
log_probs/std                         1.07471     0.02479    1.12096     1.02856
log_probs/max                         2.12763     0.23852    2.56867     1.74108
log_probs/min                         -6.45334    0.81264    -5.47082    -7.89910
mean/mean                             -0.07675    0.00042    -0.07572    -0.07715
mean/std                              0.43149     0.00540    0.44044     0.42392
mean/max                              0.90414     0.01806    0.93250     0.87787
mean/min                              -1.42967    0.01100    -1.41470    -1.44655
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 4, 9, 8, 5, 2, 1, 6, 7, 0]
replay_buffer._size: [14250 14250 14250 14250 14250 14250 14250 14250 14250 14250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.627098798751831 0.002458810806274414
train_time 2.630875587463379
2023-09-06 13:35:58,453 MainThread INFO: EPOCH:93
2023-09-06 13:35:58,454 MainThread INFO: Time Consumed:2.6446924209594727s
2023-09-06 13:35:58,454 MainThread INFO: Total Frames:141000s
 24%|‚ñà‚ñà‚ñé       | 94/400 [04:56<23:11,  4.55s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               632.53964
Train_Epoch_Reward                    8786.60490
Running_Training_Average_Rewards      859.66675
Explore_Time                          0.00506
Train___Time                          2.63088
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.95526
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.09275
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.47800
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.83531
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.06491
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.32352
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.35175
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6637.21582
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.14786
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.39214
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.50522     0.68775    10.82121    8.49809
alpha_0                               0.76309     0.00049    0.76386     0.76233
alpha_1                               0.75587     0.00063    0.75686     0.75488
alpha_2                               0.75651     0.00062    0.75748     0.75553
alpha_3                               0.75615     0.00062    0.75713     0.75518
alpha_4                               0.75615     0.00063    0.75713     0.75517
alpha_5                               0.75614     0.00063    0.75712     0.75516
alpha_6                               0.75570     0.00064    0.75671     0.75470
alpha_7                               0.75800     0.00058    0.75891     0.75708
alpha_8                               0.75667     0.00061    0.75763     0.75571
alpha_9                               0.75548     0.00064    0.75648     0.75449
Alpha_loss                            -1.71204    0.00760    -1.69734    -1.72375
Training/policy_loss                  -14.60240   0.07387    -14.48278   -14.70724
Training/qf1_loss                     1837.25859  472.87543  2546.28760  1261.28381
Training/qf2_loss                     1835.46588  473.51373  2547.54468  1258.37219
Training/pf_norm                      0.21888     0.03432    0.27560     0.17046
Training/qf1_norm                     510.50114   50.10888   612.45691   439.21912
Training/qf2_norm                     504.32766   48.30522   601.63013   435.33313
log_std/mean                          -0.18728    0.00042    -0.18657    -0.18795
log_std/std                           0.06271     0.00036    0.06334     0.06225
log_std/max                           -0.12522    0.00122    -0.12341    -0.12727
log_std/min                           -0.50620    0.00098    -0.50453    -0.50804
log_probs/mean                        -2.14931    0.02840    -2.10341    -2.19793
log_probs/std                         1.11850     0.02774    1.18625     1.08754
log_probs/max                         2.33019     0.29823    2.98148     1.91810
log_probs/min                         -6.13966    0.68637    -5.43337    -7.59332
mean/mean                             -0.07583    0.00085    -0.07450    -0.07696
mean/std                              0.45045     0.00396    0.45617     0.44332
mean/max                              0.97359     0.01724    0.99866     0.94316
mean/min                              -1.45793    0.00349    -1.45035    -1.46287
------------------------------------  ----------  ---------  ----------  ----------
sample: [6, 1, 9, 4, 7, 3, 5, 8, 2, 0]
replay_buffer._size: [14400 14400 14400 14400 14400 14400 14400 14400 14400 14400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.263776540756226 0.0020978450775146484
train_time 4.267181634902954
2023-09-06 13:36:02,920 MainThread INFO: EPOCH:94
2023-09-06 13:36:02,920 MainThread INFO: Time Consumed:4.284899473190308s
2023-09-06 13:36:02,921 MainThread INFO: Total Frames:142500s
 24%|‚ñà‚ñà‚ñç       | 95/400 [05:01<22:55,  4.51s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               612.10060
Train_Epoch_Reward                    5646.76304
Running_Training_Average_Rewards      797.79626
Explore_Time                          0.00978
Train___Time                          4.26718
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.14423
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -78.92473
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.52030
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.30635
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.68123
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.46151
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -54.49840
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6536.33165
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.83590
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.05493
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.87197     1.25269    12.49495    8.72604
alpha_0                               0.76142     0.00047    0.76217     0.76069
alpha_1                               0.75367     0.00063    0.75466     0.75268
alpha_2                               0.75435     0.00062    0.75532     0.75339
alpha_3                               0.75400     0.00062    0.75496     0.75303
alpha_4                               0.75398     0.00062    0.75495     0.75301
alpha_5                               0.75397     0.00062    0.75494     0.75300
alpha_6                               0.75348     0.00064    0.75448     0.75249
alpha_7                               0.75596     0.00059    0.75688     0.75504
alpha_8                               0.75455     0.00061    0.75550     0.75359
alpha_9                               0.75327     0.00063    0.75426     0.75228
Alpha_loss                            -1.72719    0.00735    -1.71536    -1.74163
Training/policy_loss                  -14.88125   0.07921    -14.75070   -15.00108
Training/qf1_loss                     2053.14951  719.69721  3591.42969  1387.22302
Training/qf2_loss                     2053.56639  720.99858  3592.74585  1383.71814
Training/pf_norm                      0.22248     0.05292    0.30618     0.15485
Training/qf1_norm                     544.94247   94.44308   746.15851   455.18347
Training/qf2_norm                     536.23154   91.11754   731.38428   452.45425
log_std/mean                          -0.19026    0.00184    -0.18812    -0.19377
log_std/std                           0.06432     0.00086    0.06584     0.06315
log_std/max                           -0.12360    0.00118    -0.12213    -0.12607
log_std/min                           -0.51067    0.00447    -0.50538    -0.51791
log_probs/mean                        -2.14158    0.03072    -2.09562    -2.20262
log_probs/std                         1.15882     0.03203    1.22730     1.11229
log_probs/max                         2.51966     0.10537    2.66643     2.37491
log_probs/min                         -6.25416    0.52792    -5.41921    -7.00933
mean/mean                             -0.07498    0.00091    -0.07397    -0.07689
mean/std                              0.46331     0.00492    0.47194     0.45687
mean/max                              1.00797     0.00706    1.01748     0.99860
mean/min                              -1.46636    0.00792    -1.45774    -1.47818
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 5, 7, 9, 3, 8, 2, 0, 4, 6]
replay_buffer._size: [14550 14550 14550 14550 14550 14550 14550 14550 14550 14550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.553718328475952 0.0021872520446777344
train_time 2.5572147369384766
2023-09-06 13:36:07,478 MainThread INFO: EPOCH:95
2023-09-06 13:36:07,479 MainThread INFO: Time Consumed:2.7523884773254395s
2023-09-06 13:36:07,479 MainThread INFO: Total Frames:144000s
 24%|‚ñà‚ñà‚ñç       | 96/400 [05:05<22:57,  4.53s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               601.58184
Train_Epoch_Reward                    4686.79968
Running_Training_Average_Rewards      637.33892
Explore_Time                          0.18788
Train___Time                          2.55721
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.86208
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.40934
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.41855
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -51.75442
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.93958
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.07587
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.37955
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6541.37998
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.11783
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.44609
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.60612     0.65469    10.43188    8.65802
alpha_0                               0.75980     0.00046    0.76052     0.75908
alpha_1                               0.75147     0.00063    0.75246     0.75049
alpha_2                               0.75221     0.00061    0.75317     0.75125
alpha_3                               0.75186     0.00061    0.75282     0.75090
alpha_4                               0.75182     0.00062    0.75279     0.75086
alpha_5                               0.75182     0.00062    0.75278     0.75085
alpha_6                               0.75127     0.00063    0.75227     0.75028
alpha_7                               0.75393     0.00058    0.75484     0.75302
alpha_8                               0.75243     0.00061    0.75338     0.75148
alpha_9                               0.75108     0.00063    0.75206     0.75010
Alpha_loss                            -1.72809    0.01044    -1.71606    -1.75402
Training/policy_loss                  -15.17768   0.07630    -15.06119   -15.29221
Training/qf1_loss                     2002.24408  549.14610  3139.60840  1182.52576
Training/qf2_loss                     1999.74014  547.43932  3130.07031  1180.32678
Training/pf_norm                      0.22625     0.05146    0.35755     0.16782
Training/qf1_norm                     527.28869   48.83919   608.10150   456.34924
Training/qf2_norm                     521.94792   47.72173   596.42438   451.38620
log_std/mean                          -0.19621    0.00073    -0.19461    -0.19682
log_std/std                           0.06695     0.00053    0.06793     0.06617
log_std/max                           -0.12566    0.00077    -0.12398    -0.12671
log_std/min                           -0.52603    0.00327    -0.52031    -0.53059
log_probs/mean                        -2.08368    0.04144    -2.02747    -2.17291
log_probs/std                         1.19775     0.03423    1.24573     1.13745
log_probs/max                         2.64612     0.35899    3.11672     1.92321
log_probs/min                         -6.25143    0.74533    -5.09935    -7.85960
mean/mean                             -0.08046    0.00145    -0.07779    -0.08211
mean/std                              0.48097     0.00447    0.48802     0.47397
mean/max                              1.03294     0.00956    1.04829     1.02064
mean/min                              -1.50216    0.01094    -1.48520    -1.51869
------------------------------------  ----------  ---------  ----------  ----------
sample: [4, 8, 5, 2, 9, 6, 0, 3, 1, 7]
replay_buffer._size: [14700 14700 14700 14700 14700 14700 14700 14700 14700 14700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.640649318695068 0.0020949840545654297
train_time 4.644043684005737
2023-09-06 13:36:12,294 MainThread INFO: EPOCH:96
2023-09-06 13:36:12,294 MainThread INFO: Time Consumed:4.6587302684783936s
2023-09-06 13:36:12,295 MainThread INFO: Total Frames:145500s
 24%|‚ñà‚ñà‚ñç       | 97/400 [05:10<23:16,  4.61s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               594.28529
Train_Epoch_Reward                    11950.66583
Running_Training_Average_Rewards      742.80762
Explore_Time                          0.00577
Train___Time                          4.64404
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.30564
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.23469
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.51339
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.29309
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.43276
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.76377
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.49576
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6430.47673
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.24835
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.51141
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.88401      1.13854    11.62480    7.83428
alpha_0                               0.75821      0.00045    0.75892     0.75750
alpha_1                               0.74930      0.00062    0.75027     0.74832
alpha_2                               0.75007      0.00061    0.75103     0.74912
alpha_3                               0.74974      0.00061    0.75069     0.74879
alpha_4                               0.74968      0.00061    0.75064     0.74872
alpha_5                               0.74968      0.00061    0.75064     0.74872
alpha_6                               0.74907      0.00063    0.75006     0.74808
alpha_7                               0.75193      0.00057    0.75282     0.75104
alpha_8                               0.75033      0.00060    0.75127     0.74939
alpha_9                               0.74891      0.00062    0.74988     0.74793
Alpha_loss                            -1.73468     0.00587    -1.72515    -1.74582
Training/policy_loss                  -15.46245    0.08733    -15.32065   -15.59669
Training/qf1_loss                     1902.71453   504.81462  2777.80933  1137.29822
Training/qf2_loss                     1900.90842   506.05888  2774.62866  1132.81238
Training/pf_norm                      0.23195      0.03157    0.27003     0.15910
Training/qf1_norm                     555.32766    87.62279   691.81372   400.36655
Training/qf2_norm                     549.33059    83.85485   683.61676   400.33124
log_std/mean                          -0.19639     0.00063    -0.19583    -0.19780
log_std/std                           0.06873      0.00050    0.06948     0.06804
log_std/max                           -0.12297     0.00125    -0.12112    -0.12530
log_std/min                           -0.52895     0.00326    -0.52246    -0.53282
log_probs/mean                        -2.04729     0.02803    -2.01459    -2.09510
log_probs/std                         1.22376      0.02947    1.28697     1.18063
log_probs/max                         2.85289      0.27801    3.22459     2.28775
log_probs/min                         -6.93957     1.17731    -5.62854    -9.13860
mean/mean                             -0.07965     0.00156    -0.07720    -0.08187
mean/std                              0.49357      0.00316    0.49851     0.48853
mean/max                              1.05351      0.00590    1.06036     1.04248
mean/min                              -1.51382     0.00534    -1.50656    -1.52160
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 0, 2, 9, 4, 7, 5, 6, 3, 1]
replay_buffer._size: [14850 14850 14850 14850 14850 14850 14850 14850 14850 14850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.630064964294434 0.002311229705810547
train_time 4.633731842041016
2023-09-06 13:36:17,143 MainThread INFO: EPOCH:97
2023-09-06 13:36:17,144 MainThread INFO: Time Consumed:4.658971786499023s
2023-09-06 13:36:17,144 MainThread INFO: Total Frames:147000s
 24%|‚ñà‚ñà‚ñç       | 98/400 [05:15<23:34,  4.68s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               587.50952
Train_Epoch_Reward                    6177.35605
Running_Training_Average_Rewards      760.49405
Explore_Time                          0.01491
Train___Time                          4.63373
Eval____Time                          0.00553
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.99035
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.93034
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.53345
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.71700
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.79773
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.49156
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -57.43753
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6350.74390
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.95522
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.25974
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.88447     0.78319    11.34876    8.48843
alpha_0                               0.75664     0.00045    0.75734     0.75594
alpha_1                               0.74714     0.00062    0.74811     0.74617
alpha_2                               0.74795     0.00061    0.74891     0.74700
alpha_3                               0.74763     0.00060    0.74858     0.74669
alpha_4                               0.74755     0.00061    0.74851     0.74660
alpha_5                               0.74756     0.00061    0.74851     0.74661
alpha_6                               0.74688     0.00063    0.74786     0.74590
alpha_7                               0.74997     0.00056    0.75085     0.74908
alpha_8                               0.74824     0.00060    0.74918     0.74731
alpha_9                               0.74675     0.00062    0.74772     0.74578
Alpha_loss                            -1.74164    0.00671    -1.72977    -1.75198
Training/policy_loss                  -15.75901   0.10123    -15.58206   -15.89599
Training/qf1_loss                     2088.98713  511.59726  2976.15015  1381.01648
Training/qf2_loss                     2087.76002  511.62388  2975.38062  1377.98242
Training/pf_norm                      0.23521     0.03264    0.30145     0.17434
Training/qf1_norm                     563.09526   60.26350   682.98895   452.56345
Training/qf2_norm                     556.99498   58.99651   674.31372   450.08011
log_std/mean                          -0.20131    0.00190    -0.19816    -0.20386
log_std/std                           0.06853     0.00080    0.06985     0.06757
log_std/max                           -0.12618    0.00128    -0.12413    -0.12783
log_std/min                           -0.52352    0.00334    -0.51920    -0.53092
log_probs/mean                        -2.01317    0.02337    -1.96345    -2.04511
log_probs/std                         1.24832     0.03880    1.31717     1.19095
log_probs/max                         2.86787     0.21435    3.22761     2.46173
log_probs/min                         -6.66583    0.60198    -5.47979    -7.70521
mean/mean                             -0.07696    0.00061    -0.07634    -0.07830
mean/std                              0.50509     0.00445    0.51223     0.49852
mean/max                              1.07865     0.01177    1.10241     1.06408
mean/min                              -1.51619    0.00998    -1.50290    -1.53816
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 7, 5, 1, 3, 9, 2, 6, 4, 0]
replay_buffer._size: [15000 15000 15000 15000 15000 15000 15000 15000 15000 15000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.493563413619995 0.002126932144165039
train_time 4.497016429901123
2023-09-06 13:36:22,032 MainThread INFO: EPOCH:98
2023-09-06 13:36:22,032 MainThread INFO: Time Consumed:4.602758407592773s
2023-09-06 13:36:22,033 MainThread INFO: Total Frames:148500s
 25%|‚ñà‚ñà‚ñç       | 99/400 [05:20<23:48,  4.74s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               584.36707
Train_Epoch_Reward                    6613.93435
Running_Training_Average_Rewards      824.73187
Explore_Time                          0.09508
Train___Time                          4.49702
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.12010
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.16174
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.47968
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.99942
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.89934
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.81421
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.30522
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6462.63732
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.11775
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.03662
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.21734     0.91017    10.71187    7.17835
alpha_0                               0.75511     0.00043    0.75579     0.75443
alpha_1                               0.74499     0.00062    0.74595     0.74402
alpha_2                               0.74585     0.00060    0.74679     0.74490
alpha_3                               0.74554     0.00060    0.74648     0.74461
alpha_4                               0.74544     0.00060    0.74639     0.74450
alpha_5                               0.74546     0.00060    0.74640     0.74452
alpha_6                               0.74470     0.00062    0.74568     0.74372
alpha_7                               0.74801     0.00056    0.74889     0.74713
alpha_8                               0.74617     0.00059    0.74710     0.74524
alpha_9                               0.74460     0.00061    0.74556     0.74364
Alpha_loss                            -1.74498    0.00725    -1.73498    -1.75951
Training/policy_loss                  -16.07308   0.09456    -15.90820   -16.19901
Training/qf1_loss                     1867.10502  424.63637  2757.93726  1280.45154
Training/qf2_loss                     1866.19572  424.84559  2757.29590  1278.08606
Training/pf_norm                      0.22766     0.03215    0.27720     0.16795
Training/qf1_norm                     514.11898   73.38473   629.74487   350.69556
Training/qf2_norm                     509.08581   71.37752   622.37549   351.15674
log_std/mean                          -0.20522    0.00055    -0.20425    -0.20607
log_std/std                           0.06994     0.00030    0.07038     0.06954
log_std/max                           -0.13009    0.00100    -0.12879    -0.13223
log_std/min                           -0.52535    0.00169    -0.52296    -0.52825
log_probs/mean                        -1.96706    0.02501    -1.92589    -1.99934
log_probs/std                         1.29163     0.02713    1.32237     1.24241
log_probs/max                         3.18073     0.15116    3.41655     2.94799
log_probs/min                         -6.55280    0.83418    -5.30128    -8.09231
mean/mean                             -0.08027    0.00098    -0.07879    -0.08187
mean/std                              0.52101     0.00452    0.52756     0.51345
mean/max                              1.11550     0.00925    1.12734     1.09492
mean/min                              -1.53847    0.00579    -1.52635    -1.54677
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 0, 6, 7, 4, 1, 5, 9, 3, 8]
replay_buffer._size: [15150 15150 15150 15150 15150 15150 15150 15150 15150 15150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.771169662475586 0.0021598339080810547
train_time 4.774773597717285
2023-09-06 13:36:26,999 MainThread INFO: EPOCH:99
2023-09-06 13:36:26,999 MainThread INFO: Time Consumed:4.788369655609131s
2023-09-06 13:36:27,000 MainThread INFO: Total Frames:150000s
 25%|‚ñà‚ñà‚ñå       | 100/400 [05:25<24:06,  4.82s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               582.50028
Train_Epoch_Reward                    6556.84656
Running_Training_Average_Rewards      644.93790
Explore_Time                          0.00437
Train___Time                          4.77477
Eval____Time                          0.00356
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.77192
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.57865
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.58528
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.39731
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.15038
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.49389
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.00072
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6376.71706
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.13447
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.93029
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.01180     0.85664    10.50636    7.68759
alpha_0                               0.75361     0.00042    0.75428     0.75295
alpha_1                               0.74284     0.00061    0.74380     0.74188
alpha_2                               0.74376     0.00060    0.74469     0.74283
alpha_3                               0.74347     0.00059    0.74440     0.74254
alpha_4                               0.74335     0.00060    0.74429     0.74241
alpha_5                               0.74338     0.00059    0.74431     0.74246
alpha_6                               0.74253     0.00062    0.74351     0.74156
alpha_7                               0.74607     0.00055    0.74694     0.74521
alpha_8                               0.74411     0.00059    0.74503     0.74319
alpha_9                               0.74247     0.00061    0.74343     0.74152
Alpha_loss                            -1.74650    0.00970    -1.73065    -1.76288
Training/policy_loss                  -16.36981   0.10131    -16.19272   -16.49340
Training/qf1_loss                     1710.38330  426.79628  2606.98242  1225.80298
Training/qf2_loss                     1708.97725  426.47224  2606.53589  1223.43860
Training/pf_norm                      0.23701     0.04991    0.29908     0.15936
Training/qf1_norm                     506.02963   66.73647   626.54034   411.71417
Training/qf2_norm                     501.37352   65.31964   618.68085   406.23926
log_std/mean                          -0.20681    0.00085    -0.20542    -0.20785
log_std/std                           0.07181     0.00066    0.07256     0.07031
log_std/max                           -0.12372    0.00227    -0.12089    -0.12778
log_std/min                           -0.52463    0.00248    -0.52049    -0.52811
log_probs/mean                        -1.91636    0.03372    -1.85215    -1.98050
log_probs/std                         1.32601     0.03568    1.38210     1.25669
log_probs/max                         3.02545     0.36537    3.54295     2.34611
log_probs/min                         -6.34308    0.72277    -5.56196    -7.56995
mean/mean                             -0.08471    0.00140    -0.08220    -0.08630
mean/std                              0.53771     0.00497    0.54421     0.52866
mean/max                              1.13109     0.00416    1.13598     1.12320
mean/min                              -1.55683    0.00695    -1.54297    -1.56286
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 1, 6, 0, 7, 2, 8, 9, 4, 3]
replay_buffer._size: [15300 15300 15300 15300 15300 15300 15300 15300 15300 15300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.625138998031616 0.0022165775299072266
train_time 4.628700256347656
2023-09-06 13:36:31,826 MainThread INFO: EPOCH:100
2023-09-06 13:36:31,826 MainThread INFO: Time Consumed:4.647017240524292s
2023-09-06 13:36:31,827 MainThread INFO: Total Frames:151500s
 25%|‚ñà‚ñà‚ñå       | 101/400 [05:31<25:40,  5.15s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               573.84569
Train_Epoch_Reward                    5481.54869
Running_Training_Average_Rewards      621.74432
Explore_Time                          0.00874
Train___Time                          4.62870
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.56452
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.90463
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.65837
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.51950
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.50827
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.41112
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.10551
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6082.00026
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.34634
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.98855
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.25403     1.10691    10.75021    7.43356
alpha_0                               0.75215     0.00042    0.75281     0.75150
alpha_1                               0.74071     0.00061    0.74167     0.73976
alpha_2                               0.74170     0.00059    0.74262     0.74078
alpha_3                               0.74141     0.00059    0.74233     0.74048
alpha_4                               0.74126     0.00060    0.74220     0.74033
alpha_5                               0.74133     0.00059    0.74225     0.74041
alpha_6                               0.74038     0.00062    0.74134     0.73941
alpha_7                               0.74416     0.00054    0.74502     0.74331
alpha_8                               0.74207     0.00058    0.74298     0.74115
alpha_9                               0.74036     0.00060    0.74131     0.73942
Alpha_loss                            -1.74434    0.00912    -1.72873    -1.76127
Training/policy_loss                  -16.69528   0.07906    -16.57438   -16.81806
Training/qf1_loss                     1794.39116  537.34146  2486.60352  952.97913
Training/qf2_loss                     1792.01279  537.85113  2484.73071  952.10400
Training/pf_norm                      0.24341     0.04652    0.30365     0.17371
Training/qf1_norm                     526.17812   93.16521   651.09357   379.88651
Training/qf2_norm                     522.99446   90.38691   645.99939   379.62372
log_std/mean                          -0.20992    0.00067    -0.20851    -0.21055
log_std/std                           0.07416     0.00100    0.07540     0.07246
log_std/max                           -0.12112    0.00125    -0.11909    -0.12324
log_std/min                           -0.52646    0.00213    -0.52318    -0.53021
log_probs/mean                        -1.85458    0.04182    -1.77779    -1.93668
log_probs/std                         1.35984     0.03204    1.43173     1.30974
log_probs/max                         3.47249     0.15888    3.62158     3.03459
log_probs/min                         -6.80993    0.68313    -5.79245    -8.54557
mean/mean                             -0.08707    0.00055    -0.08576    -0.08768
mean/std                              0.55670     0.00560    0.56459     0.54707
mean/max                              1.16436     0.01248    1.18766     1.14725
mean/min                              -1.59131    0.00886    -1.57775    -1.60507
------------------------------------  ----------  ---------  ----------  ---------
snapshot at 100
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [9, 8, 7, 0, 3, 4, 1, 6, 5, 2]
replay_buffer._size: [15450 15450 15450 15450 15450 15450 15450 15450 15450 15450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.77708101272583 0.0022017955780029297
train_time 2.7806379795074463
2023-09-06 13:36:36,794 MainThread INFO: EPOCH:101
2023-09-06 13:36:36,794 MainThread INFO: Time Consumed:2.7927446365356445s
2023-09-06 13:36:36,795 MainThread INFO: Total Frames:153000s
 26%|‚ñà‚ñà‚ñå       | 102/400 [05:35<23:40,  4.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               556.05967
Train_Epoch_Reward                    6657.41669
Running_Training_Average_Rewards      623.19373
Explore_Time                          0.00377
Train___Time                          2.78064
Eval____Time                          0.00400
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.92749
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.38508
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.58334
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.87001
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.89400
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.05050
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.80033
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5924.63989
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.08004
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.92650
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.12439     0.86382    11.01712    8.25135
alpha_0                               0.75072     0.00041    0.75136     0.75009
alpha_1                               0.73861     0.00060    0.73955     0.73766
alpha_2                               0.73966     0.00058    0.74057     0.73874
alpha_3                               0.73936     0.00058    0.74028     0.73845
alpha_4                               0.73919     0.00059    0.74012     0.73826
alpha_5                               0.73930     0.00058    0.74021     0.73839
alpha_6                               0.73823     0.00061    0.73919     0.73727
alpha_7                               0.74228     0.00054    0.74312     0.74143
alpha_8                               0.74005     0.00058    0.74095     0.73914
alpha_9                               0.73827     0.00060    0.73921     0.73734
Alpha_loss                            -1.75341    0.01105    -1.73541    -1.77529
Training/policy_loss                  -17.01375   0.09600    -16.84605   -17.18519
Training/qf1_loss                     1634.56472  387.36523  2491.14062  991.95526
Training/qf2_loss                     1634.27192  387.48480  2488.75488  987.62469
Training/pf_norm                      0.27280     0.05466    0.38209     0.18470
Training/qf1_norm                     526.14365   71.92889   689.22937   451.32504
Training/qf2_norm                     521.34131   70.45076   682.91150   447.52301
log_std/mean                          -0.20878    0.00096    -0.20768    -0.21067
log_std/std                           0.07515     0.00073    0.07680     0.07435
log_std/max                           -0.12372    0.00046    -0.12320    -0.12486
log_std/min                           -0.51933    0.00376    -0.51497    -0.52820
log_probs/mean                        -1.83153    0.03537    -1.79002    -1.89206
log_probs/std                         1.39018     0.02648    1.43615     1.35522
log_probs/max                         3.41979     0.26314    3.90833     3.07997
log_probs/min                         -6.24988    0.45350    -5.60742    -7.03205
mean/mean                             -0.08079    0.00246    -0.07687    -0.08486
mean/std                              0.56923     0.00348    0.57672     0.56506
mean/max                              1.20511     0.01318    1.23069     1.18821
mean/min                              -1.59154    0.00547    -1.58302    -1.60459
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 7, 4, 8, 3, 1, 6, 2, 9, 0]
replay_buffer._size: [15600 15600 15600 15600 15600 15600 15600 15600 15600 15600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.729142904281616 0.0021317005157470703
train_time 4.73258900642395
2023-09-06 13:36:41,704 MainThread INFO: EPOCH:102
2023-09-06 13:36:41,704 MainThread INFO: Time Consumed:4.759747505187988s
2023-09-06 13:36:41,705 MainThread INFO: Total Frames:154500s
 26%|‚ñà‚ñà‚ñå       | 103/400 [05:40<23:50,  4.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               543.28413
Train_Epoch_Reward                    9947.54041
Running_Training_Average_Rewards      736.21686
Explore_Time                          0.01928
Train___Time                          4.73259
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.27841
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.83849
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.72112
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.36071
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.13262
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.30379
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.09581
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5977.21466
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.87979
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.19590
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.11529     1.18411    10.75778    7.42548
alpha_0                               0.74931     0.00040    0.74995     0.74869
alpha_1                               0.73651     0.00060    0.73745     0.73558
alpha_2                               0.73762     0.00058    0.73854     0.73671
alpha_3                               0.73733     0.00058    0.73824     0.73642
alpha_4                               0.73714     0.00059    0.73806     0.73622
alpha_5                               0.73728     0.00058    0.73819     0.73638
alpha_6                               0.73610     0.00061    0.73706     0.73514
alpha_7                               0.74041     0.00053    0.74124     0.73958
alpha_8                               0.73804     0.00057    0.73894     0.73715
alpha_9                               0.73620     0.00059    0.73713     0.73527
Alpha_loss                            -1.74783    0.01033    -1.72425    -1.76396
Training/policy_loss                  -17.33966   0.10953    -17.16584   -17.49618
Training/qf1_loss                     1787.75873  628.75033  2981.41455  984.57239
Training/qf2_loss                     1786.34171  628.92985  2979.50244  980.17523
Training/pf_norm                      0.24868     0.02814    0.28774     0.19748
Training/qf1_norm                     526.40326   96.07283   654.50848   383.21631
Training/qf2_norm                     522.73602   94.13803   647.49597   383.40613
log_std/mean                          -0.21853    0.00429    -0.21169    -0.22462
log_std/std                           0.08194     0.00271    0.08586     0.07765
log_std/max                           -0.12666    0.00195    -0.12379    -0.12995
log_std/min                           -0.54910    0.01484    -0.52529    -0.56832
log_probs/mean                        -1.76057    0.04470    -1.65962    -1.81604
log_probs/std                         1.43139     0.04462    1.51713     1.34687
log_probs/max                         3.59058     0.17226    3.89202     3.30556
log_probs/min                         -7.12662    0.82370    -6.11174    -8.63313
mean/mean                             -0.07421    0.00067    -0.07352    -0.07575
mean/std                              0.59202     0.00834    0.60435     0.57910
mean/max                              1.27023     0.02040    1.29770     1.23582
mean/min                              -1.62559    0.01962    -1.59423    -1.65353
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 1, 0, 9, 8, 7, 6, 5, 2, 3]
replay_buffer._size: [15750 15750 15750 15750 15750 15750 15750 15750 15750 15750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.926304817199707 0.002107381820678711
train_time 4.929717302322388
2023-09-06 13:36:46,823 MainThread INFO: EPOCH:103
2023-09-06 13:36:46,824 MainThread INFO: Time Consumed:4.949491739273071s
2023-09-06 13:36:46,824 MainThread INFO: Total Frames:156000s
 26%|‚ñà‚ñà‚ñå       | 104/400 [05:45<24:08,  4.89s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               542.59201
Train_Epoch_Reward                    7124.84188
Running_Training_Average_Rewards      790.99330
Explore_Time                          0.01078
Train___Time                          4.92972
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.92288
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -82.92036
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.65975
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.61733
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.29690
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.44462
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.91650
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6061.75959
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.60534
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.14632
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.80755     1.03874    10.53579    6.98071
alpha_0                               0.74796     0.00038    0.74856     0.74737
alpha_1                               0.73445     0.00059    0.73537     0.73352
alpha_2                               0.73560     0.00058    0.73651     0.73470
alpha_3                               0.73532     0.00057    0.73622     0.73443
alpha_4                               0.73510     0.00058    0.73601     0.73419
alpha_5                               0.73529     0.00057    0.73618     0.73440
alpha_6                               0.73398     0.00061    0.73493     0.73302
alpha_7                               0.73858     0.00052    0.73940     0.73777
alpha_8                               0.73606     0.00057    0.73695     0.73517
alpha_9                               0.73414     0.00059    0.73506     0.73322
Alpha_loss                            -1.74257    0.01097    -1.72461    -1.75663
Training/policy_loss                  -17.68289   0.10793    -17.46415   -17.82626
Training/qf1_loss                     1588.46439  458.38165  2368.18042  745.60498
Training/qf2_loss                     1587.52988  458.51626  2367.68579  744.17017
Training/pf_norm                      0.26077     0.05698    0.32676     0.15745
Training/qf1_norm                     501.97703   88.39472   649.31104   347.90472
Training/qf2_norm                     499.05929   86.16765   642.31110   349.56601
log_std/mean                          -0.22688    0.00077    -0.22505    -0.22759
log_std/std                           0.08704     0.00042    0.08770     0.08636
log_std/max                           -0.13292    0.00120    -0.13060    -0.13420
log_std/min                           -0.57415    0.00250    -0.57063    -0.57797
log_probs/mean                        -1.69180    0.03283    -1.63971    -1.75681
log_probs/std                         1.46733     0.02146    1.50187     1.43442
log_probs/max                         3.72110     0.22561    4.04326     3.36853
log_probs/min                         -6.65361    0.52885    -5.88875    -7.72370
mean/mean                             -0.07389    0.00061    -0.07310    -0.07500
mean/std                              0.60463     0.00223    0.60806     0.60064
mean/max                              1.28537     0.00753    1.29954     1.27590
mean/min                              -1.63485    0.01201    -1.61808    -1.65418
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 5, 6, 4, 8, 2, 7, 9, 3, 0]
replay_buffer._size: [15900 15900 15900 15900 15900 15900 15900 15900 15900 15900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.3884196281433105 0.0021381378173828125
train_time 3.3919010162353516
2023-09-06 13:36:51,710 MainThread INFO: EPOCH:104
2023-09-06 13:36:51,711 MainThread INFO: Time Consumed:4.740121841430664s
2023-09-06 13:36:51,711 MainThread INFO: Total Frames:157500s
 26%|‚ñà‚ñà‚ñã       | 105/400 [05:50<24:02,  4.89s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               547.55068
Train_Epoch_Reward                    9463.21282
Running_Training_Average_Rewards      884.51984
Explore_Time                          1.33923
Train___Time                          3.39190
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.37775
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.41983
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.78862
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.18471
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.58327
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.08820
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.07648
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6059.89359
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.47988
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.01211
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.13243     0.62207    10.21308    8.16880
alpha_0                               0.74664     0.00038    0.74724     0.74604
alpha_1                               0.73240     0.00059    0.73332     0.73148
alpha_2                               0.73360     0.00057    0.73450     0.73270
alpha_3                               0.73335     0.00057    0.73423     0.73246
alpha_4                               0.73308     0.00058    0.73399     0.73218
alpha_5                               0.73331     0.00057    0.73420     0.73242
alpha_6                               0.73186     0.00061    0.73281     0.73091
alpha_7                               0.73677     0.00052    0.73758     0.73596
alpha_8                               0.73409     0.00056    0.73498     0.73321
alpha_9                               0.73210     0.00058    0.73301     0.73119
Alpha_loss                            -1.76225    0.01162    -1.74844    -1.78558
Training/policy_loss                  -18.00220   0.08755    -17.88371   -18.15328
Training/qf1_loss                     1747.89562  349.15514  2311.03882  1185.88208
Training/qf2_loss                     1747.18005  348.62806  2311.62427  1185.15649
Training/pf_norm                      0.27220     0.05502    0.40809     0.21466
Training/qf1_norm                     536.98273   52.90349   627.29596   450.10995
Training/qf2_norm                     534.10618   52.40941   627.07037   450.29352
log_std/mean                          -0.22779    0.00120    -0.22667    -0.23036
log_std/std                           0.08615     0.00023    0.08667     0.08579
log_std/max                           -0.13274    0.00114    -0.13100    -0.13454
log_std/min                           -0.56621    0.00249    -0.56153    -0.57110
log_probs/mean                        -1.70773    0.03673    -1.66764    -1.77700
log_probs/std                         1.44315     0.02339    1.47357     1.39783
log_probs/max                         3.65318     0.26968    4.16353     3.18765
log_probs/min                         -7.27661    0.90856    -6.02798    -9.14025
mean/mean                             -0.07802    0.00161    -0.07551    -0.08007
mean/std                              0.60324     0.00478    0.61377     0.59901
mean/max                              1.26988     0.00820    1.28659     1.26227
mean/min                              -1.60826    0.00909    -1.59982    -1.62738
------------------------------------  ----------  ---------  ----------  ----------
sample: [7, 9, 5, 8, 1, 6, 0, 3, 4, 2]
replay_buffer._size: [16050 16050 16050 16050 16050 16050 16050 16050 16050 16050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.75850248336792 0.0022072792053222656
train_time 4.762067079544067
2023-09-06 13:36:56,664 MainThread INFO: EPOCH:105
2023-09-06 13:36:56,664 MainThread INFO: Time Consumed:4.784388542175293s
2023-09-06 13:36:56,665 MainThread INFO: Total Frames:159000s
 26%|‚ñà‚ñà‚ñã       | 106/400 [05:55<24:02,  4.91s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               549.98675
Train_Epoch_Reward                    11069.54539
Running_Training_Average_Rewards      921.92000
Explore_Time                          0.01345
Train___Time                          4.76207
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.95135
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.40418
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.82056
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.14917
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.45746
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.01419
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.04720
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6046.91469
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.82079
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.75975
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.12857      0.86028    10.74881    8.08175
alpha_0                               0.74532      0.00037    0.74591     0.74475
alpha_1                               0.73037      0.00058    0.73128     0.72946
alpha_2                               0.73161      0.00057    0.73250     0.73072
alpha_3                               0.73138      0.00056    0.73226     0.73050
alpha_4                               0.73108      0.00057    0.73198     0.73019
alpha_5                               0.73135      0.00056    0.73223     0.73048
alpha_6                               0.72975      0.00060    0.73070     0.72881
alpha_7                               0.73497      0.00051    0.73578     0.73417
alpha_8                               0.73214      0.00056    0.73302     0.73126
alpha_9                               0.73007      0.00058    0.73098     0.72917
Alpha_loss                            -1.74343     0.01467    -1.71949    -1.76170
Training/policy_loss                  -18.35974    0.11378    -18.19715   -18.55023
Training/qf1_loss                     1714.39009   422.65753  2592.87012  1224.02405
Training/qf2_loss                     1713.49004   421.66092  2585.60815  1224.66724
Training/pf_norm                      0.27532      0.05709    0.39633     0.19976
Training/qf1_norm                     544.80866    76.24514   694.87592   452.35623
Training/qf2_norm                     541.72358    74.48130   685.20636   452.68927
log_std/mean                          -0.23419     0.00162    -0.23125    -0.23577
log_std/std                           0.08914      0.00140    0.09068     0.08706
log_std/max                           -0.13490     0.00116    -0.13279    -0.13649
log_std/min                           -0.58078     0.00773    -0.56945    -0.59076
log_probs/mean                        -1.59642     0.05234    -1.50677    -1.67077
log_probs/std                         1.52920      0.03804    1.58805     1.47376
log_probs/max                         4.02093      0.22999    4.42619     3.66918
log_probs/min                         -7.05833     0.76828    -5.92300    -8.12848
mean/mean                             -0.08226     0.00136    -0.08028    -0.08419
mean/std                              0.63040      0.00695    0.63753     0.61805
mean/max                              1.31144      0.01095    1.32611     1.29591
mean/min                              -1.66802     0.01847    -1.64136    -1.69131
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 5, 3, 4, 0, 8, 7, 6, 1, 9]
replay_buffer._size: [16200 16200 16200 16206 16200 16207 16200 16200 16200 16200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.932538270950317 0.0021109580993652344
train_time 4.935968637466431
2023-09-06 13:37:01,828 MainThread INFO: EPOCH:106
2023-09-06 13:37:01,828 MainThread INFO: Time Consumed:4.990136384963989s
2023-09-06 13:37:01,829 MainThread INFO: Total Frames:160500s
 27%|‚ñà‚ñà‚ñã       | 107/400 [06:00<24:21,  4.99s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               544.78096
Train_Epoch_Reward                    6594.38938
Running_Training_Average_Rewards      904.23825
Explore_Time                          0.04432
Train___Time                          4.93597
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.92581
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.70604
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.90944
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.35535
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.68283
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.67104
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.28611
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5899.00733
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.50669
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.90796
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.80456     0.66660    9.70693     7.34772
alpha_0                               0.74406     0.00036    0.74462     0.74350
alpha_1                               0.72836     0.00058    0.72926     0.72745
alpha_2                               0.72965     0.00056    0.73053     0.72877
alpha_3                               0.72943     0.00056    0.73031     0.72856
alpha_4                               0.72910     0.00057    0.72999     0.72821
alpha_5                               0.72942     0.00055    0.73029     0.72856
alpha_6                               0.72766     0.00060    0.72860     0.72672
alpha_7                               0.73319     0.00051    0.73399     0.73240
alpha_8                               0.73019     0.00056    0.73107     0.72932
alpha_9                               0.72807     0.00057    0.72897     0.72717
Alpha_loss                            -1.74947    0.01265    -1.72925    -1.77515
Training/policy_loss                  -18.71719   0.08849    -18.61402   -18.88229
Training/qf1_loss                     1748.83341  241.35448  2171.35498  1380.04028
Training/qf2_loss                     1748.87651  242.08056  2175.16089  1380.99646
Training/pf_norm                      0.27197     0.06195    0.39173     0.17889
Training/qf1_norm                     521.57199   59.00563   607.06757   387.56424
Training/qf2_norm                     519.19435   57.54179   601.00842   386.89462
log_std/mean                          -0.23196    0.00123    -0.23054    -0.23421
log_std/std                           0.08952     0.00077    0.09070     0.08855
log_std/max                           -0.12742    0.00192    -0.12522    -0.13103
log_std/min                           -0.57223    0.00694    -0.56348    -0.58295
log_probs/mean                        -1.56908    0.04256    -1.50244    -1.65415
log_probs/std                         1.52244     0.03259    1.58029     1.47795
log_probs/max                         3.96243     0.13614    4.15932     3.67106
log_probs/min                         -6.61758    0.73048    -5.79127    -8.62401
mean/mean                             -0.08247    0.00217    -0.07835    -0.08464
mean/std                              0.64161     0.00416    0.64964     0.63750
mean/max                              1.31582     0.00420    1.32432     1.30891
mean/min                              -1.66005    0.00982    -1.64770    -1.67596
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 4, 3, 2, 1, 5, 0, 9, 6, 7]
replay_buffer._size: [16350 16350 16350 16350 16350 16350 16350 16350 16350 16350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.785187721252441 0.0021212100982666016
train_time 4.788620710372925
2023-09-06 13:37:06,817 MainThread INFO: EPOCH:107
2023-09-06 13:37:06,817 MainThread INFO: Time Consumed:4.80251407623291s
2023-09-06 13:37:06,818 MainThread INFO: Total Frames:162000s
 27%|‚ñà‚ñà‚ñã       | 108/400 [06:05<24:17,  4.99s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               532.65823
Train_Epoch_Reward                    8526.38625
Running_Training_Average_Rewards      873.01070
Explore_Time                          0.00479
Train___Time                          4.78862
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.08065
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.05154
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.77633
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.59204
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.98411
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.31134
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.28386
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5711.62956
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.32556
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.02346
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.06290     1.07259    10.77411    7.50274
alpha_0                               0.74283     0.00035    0.74338     0.74229
alpha_1                               0.72635     0.00057    0.72725     0.72546
alpha_2                               0.72770     0.00056    0.72858     0.72683
alpha_3                               0.72751     0.00055    0.72837     0.72665
alpha_4                               0.72713     0.00056    0.72802     0.72625
alpha_5                               0.72752     0.00054    0.72837     0.72667
alpha_6                               0.72558     0.00059    0.72651     0.72465
alpha_7                               0.73144     0.00049    0.73222     0.73067
alpha_8                               0.72826     0.00055    0.72913     0.72740
alpha_9                               0.72607     0.00057    0.72697     0.72518
Alpha_loss                            -1.73733    0.00869    -1.72331    -1.75012
Training/policy_loss                  -19.08164   0.11156    -18.90557   -19.27908
Training/qf1_loss                     1706.76255  566.82223  2728.54492  954.83221
Training/qf2_loss                     1705.89628  567.51510  2729.96948  953.00635
Training/pf_norm                      0.27818     0.03551    0.32257     0.20213
Training/qf1_norm                     542.99847   99.84355   705.24207   400.16980
Training/qf2_norm                     540.45063   97.19479   699.39691   402.06204
log_std/mean                          -0.23503    0.00173    -0.23194    -0.23772
log_std/std                           0.09282     0.00241    0.09662     0.08925
log_std/max                           -0.12341    0.00124    -0.12156    -0.12521
log_std/min                           -0.58646    0.01246    -0.56728    -0.60664
log_probs/mean                        -1.48339    0.03317    -1.44550    -1.54428
log_probs/std                         1.60223     0.02657    1.65692     1.56536
log_probs/max                         4.32183     0.20951    4.70914     4.05036
log_probs/min                         -7.32106    0.90839    -6.18478    -9.55101
mean/mean                             -0.07533    0.00093    -0.07441    -0.07733
mean/std                              0.66286     0.00614    0.67199     0.65188
mean/max                              1.34651     0.00955    1.35914     1.32762
mean/min                              -1.67154    0.01268    -1.64936    -1.69114
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 4, 8, 2, 5, 0, 9, 3, 6, 1]
replay_buffer._size: [16500 16500 16500 16500 16500 16500 16500 16500 16500 16500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.16948938369751 0.0025866031646728516
train_time 5.173480749130249
2023-09-06 13:37:12,155 MainThread INFO: EPOCH:108
2023-09-06 13:37:12,155 MainThread INFO: Time Consumed:5.19281268119812s
2023-09-06 13:37:12,156 MainThread INFO: Total Frames:163500s
 27%|‚ñà‚ñà‚ñã       | 109/400 [06:10<24:51,  5.12s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               517.19807
Train_Epoch_Reward                    5795.92091
Running_Training_Average_Rewards      697.22322
Explore_Time                          0.00813
Train___Time                          5.17348
Eval____Time                          0.00606
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.02383
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.07762
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.55671
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.68979
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.20354
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.70120
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.14955
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5597.88763
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.15667
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.64333
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.93672     0.50844    10.13712    8.10791
alpha_0                               0.74166     0.00033    0.74218     0.74113
alpha_1                               0.72436     0.00057    0.72526     0.72347
alpha_2                               0.72578     0.00055    0.72664     0.72492
alpha_3                               0.72561     0.00054    0.72646     0.72476
alpha_4                               0.72518     0.00056    0.72605     0.72431
alpha_5                               0.72564     0.00053    0.72648     0.72481
alpha_6                               0.72353     0.00059    0.72445     0.72260
alpha_7                               0.72973     0.00049    0.73050     0.72897
alpha_8                               0.72635     0.00054    0.72721     0.72550
alpha_9                               0.72410     0.00056    0.72498     0.72322
Alpha_loss                            -1.73495    0.01797    -1.69717    -1.75767
Training/policy_loss                  -19.44180   0.09593    -19.28028   -19.55321
Training/qf1_loss                     1737.07754  328.20488  2318.66187  1368.14832
Training/qf2_loss                     1735.62222  328.45801  2317.20581  1364.72766
Training/pf_norm                      0.28506     0.05694    0.38522     0.20501
Training/qf1_norm                     536.22660   44.17920   642.45636   463.03378
Training/qf2_norm                     534.35763   42.88309   636.76660   461.96588
log_std/mean                          -0.24023    0.00106    -0.23866    -0.24246
log_std/std                           0.09690     0.00073    0.09791     0.09572
log_std/max                           -0.13161    0.00452    -0.12505    -0.13755
log_std/min                           -0.60755    0.00253    -0.60339    -0.61135
log_probs/mean                        -1.43133    0.05028    -1.32312    -1.49329
log_probs/std                         1.60835     0.01432    1.64398     1.59394
log_probs/max                         4.43326     0.22317    4.70336     3.93789
log_probs/min                         -7.03471    0.52620    -6.10886    -8.10098
mean/mean                             -0.07612    0.00041    -0.07519    -0.07653
mean/std                              0.67562     0.00143    0.67882     0.67353
mean/max                              1.35092     0.00277    1.35459     1.34609
mean/min                              -1.67985    0.00425    -1.67312    -1.68603
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 3, 7, 6, 5, 2, 0, 1, 9, 4]
replay_buffer._size: [16650 16650 16650 16650 16650 16650 16650 16650 16650 16650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.711492300033569 0.002103567123413086
train_time 4.714904069900513
2023-09-06 13:37:17,212 MainThread INFO: EPOCH:109
2023-09-06 13:37:17,213 MainThread INFO: Time Consumed:4.730334520339966s
2023-09-06 13:37:17,213 MainThread INFO: Total Frames:165000s
 28%|‚ñà‚ñà‚ñä       | 110/400 [06:15<24:30,  5.07s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               504.92190
Train_Epoch_Reward                    5088.45305
Running_Training_Average_Rewards      647.02534
Explore_Time                          0.00598
Train___Time                          4.71490
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.15488
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.29513
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.40268
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.02945
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.33922
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.17037
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.50996
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5532.08394
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.41833
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.99296
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.93092     0.75783    11.13166    8.35684
alpha_0                               0.74050     0.00033    0.74102     0.73998
alpha_1                               0.72239     0.00057    0.72327     0.72150
alpha_2                               0.72388     0.00054    0.72473     0.72304
alpha_3                               0.72372     0.00054    0.72457     0.72287
alpha_4                               0.72325     0.00055    0.72411     0.72239
alpha_5                               0.72379     0.00053    0.72462     0.72297
alpha_6                               0.72148     0.00059    0.72240     0.72056
alpha_7                               0.72803     0.00049    0.72880     0.72726
alpha_8                               0.72448     0.00054    0.72532     0.72364
alpha_9                               0.72215     0.00056    0.72303     0.72128
Alpha_loss                            -1.72762    0.01320    -1.70685    -1.74637
Training/policy_loss                  -19.81729   0.11089    -19.67101   -19.99566
Training/qf1_loss                     1684.95681  442.41343  2771.04639  1221.23767
Training/qf2_loss                     1683.72455  444.06605  2776.32666  1220.14929
Training/pf_norm                      0.27455     0.03692    0.32454     0.22156
Training/qf1_norm                     542.90986   73.12019   754.03235   478.46545
Training/qf2_norm                     541.24844   70.45929   744.05225   479.83020
log_std/mean                          -0.24953    0.00360    -0.24387    -0.25453
log_std/std                           0.09630     0.00016    0.09648     0.09595
log_std/max                           -0.14238    0.00268    -0.13819    -0.14645
log_std/min                           -0.61141    0.00179    -0.60863    -0.61347
log_probs/mean                        -1.36459    0.05207    -1.28116    -1.43080
log_probs/std                         1.64993     0.03934    1.69891     1.56428
log_probs/max                         4.62576     0.19552    4.96091     4.36128
log_probs/min                         -7.73325    1.33924    -6.27618    -10.16814
mean/mean                             -0.07804    0.00093    -0.07679    -0.07934
mean/std                              0.69722     0.00914    0.71008     0.68320
mean/max                              1.39039     0.01499    1.41042     1.36676
mean/min                              -1.71694    0.01755    -1.68993    -1.74003
------------------------------------  ----------  ---------  ----------  ----------
sample: [4, 8, 9, 6, 7, 0, 1, 3, 2, 5]
replay_buffer._size: [16800 16800 16800 16800 16800 16800 16800 16800 16800 16800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.146785497665405 0.002151012420654297
train_time 5.150282621383667
2023-09-06 13:37:22,573 MainThread INFO: EPOCH:110
2023-09-06 13:37:22,573 MainThread INFO: Time Consumed:5.17760705947876s
2023-09-06 13:37:22,574 MainThread INFO: Total Frames:166500s
 28%|‚ñà‚ñà‚ñä       | 111/400 [06:21<24:52,  5.16s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               496.37772
Train_Epoch_Reward                    4255.25187
Running_Training_Average_Rewards      504.65419
Explore_Time                          0.01652
Train___Time                          5.15028
Eval____Time                          0.00582
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.68304
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.36885
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.25603
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.15718
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.44326
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.47331
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.56565
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5446.89778
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.07647
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.99868
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.40050     0.63009    10.47983    8.56487
alpha_0                               0.73939     0.00031    0.73987     0.73891
alpha_1                               0.72044     0.00056    0.72131     0.71957
alpha_2                               0.72202     0.00053    0.72285     0.72118
alpha_3                               0.72185     0.00053    0.72269     0.72102
alpha_4                               0.72134     0.00054    0.72220     0.72049
alpha_5                               0.72197     0.00052    0.72279     0.72115
alpha_6                               0.71944     0.00059    0.72035     0.71852
alpha_7                               0.72635     0.00047    0.72710     0.72561
alpha_8                               0.72262     0.00053    0.72345     0.72178
alpha_9                               0.72022     0.00055    0.72109     0.71936
Alpha_loss                            -1.71793    0.01101    -1.69558    -1.73602
Training/policy_loss                  -20.19612   0.10984    -20.02468   -20.38817
Training/qf1_loss                     1913.09471  369.36983  2433.75391  1263.49304
Training/qf2_loss                     1913.17777  369.03715  2432.48828  1262.35645
Training/pf_norm                      0.28797     0.06772    0.41253     0.22267
Training/qf1_norm                     587.13101   62.59858   703.40686   508.50018
Training/qf2_norm                     583.94833   61.59396   697.58551   506.60529
log_std/mean                          -0.25522    0.00018    -0.25499    -0.25546
log_std/std                           0.09477     0.00061    0.09582     0.09385
log_std/max                           -0.14598    0.00109    -0.14428    -0.14756
log_std/min                           -0.59778    0.00482    -0.59020    -0.60468
log_probs/mean                        -1.28993    0.03248    -1.22097    -1.33114
log_probs/std                         1.72031     0.02885    1.78486     1.66575
log_probs/max                         4.72716     0.27243    5.14240     4.26176
log_probs/min                         -7.46146    0.66286    -6.60301    -8.53987
mean/mean                             -0.07669    0.00106    -0.07535    -0.07845
mean/std                              0.71536     0.00164    0.71782     0.71257
mean/max                              1.41112     0.00666    1.42200     1.40139
mean/min                              -1.72534    0.00689    -1.71319    -1.73806
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 7, 1, 8, 3, 2, 9, 6, 5, 4]
replay_buffer._size: [16950 16950 16950 16950 16950 16950 16950 16950 16950 16950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.074650764465332 0.00212860107421875
train_time 5.078089952468872
2023-09-06 13:37:27,836 MainThread INFO: EPOCH:111
2023-09-06 13:37:27,837 MainThread INFO: Time Consumed:5.09808611869812s
2023-09-06 13:37:27,837 MainThread INFO: Total Frames:168000s
 28%|‚ñà‚ñà‚ñä       | 112/400 [06:26<24:54,  5.19s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               485.46507
Train_Epoch_Reward                    9302.31355
Running_Training_Average_Rewards      621.53395
Explore_Time                          0.00677
Train___Time                          5.07809
Eval____Time                          0.00722
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.39973
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.73269
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.29718
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.47484
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.88224
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.04725
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.91860
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5265.12251
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.08089
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.98321
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.00199     0.66679    10.11374    7.43974
alpha_0                               0.73835     0.00029    0.73881     0.73790
alpha_1                               0.71852     0.00055    0.71938     0.71766
alpha_2                               0.72016     0.00053    0.72099     0.71933
alpha_3                               0.72001     0.00053    0.72083     0.71918
alpha_4                               0.71945     0.00054    0.72030     0.71861
alpha_5                               0.72016     0.00051    0.72097     0.71936
alpha_6                               0.71741     0.00058    0.71832     0.71650
alpha_7                               0.72472     0.00046    0.72545     0.72400
alpha_8                               0.72076     0.00053    0.72160     0.71993
alpha_9                               0.71831     0.00055    0.71916     0.71745
Alpha_loss                            -1.71183    0.01181    -1.69243    -1.72801
Training/policy_loss                  -20.58641   0.11469    -20.43318   -20.76823
Training/qf1_loss                     1842.51569  300.97452  2227.67163  1154.18872
Training/qf2_loss                     1841.43735  300.41496  2227.53296  1155.15686
Training/pf_norm                      0.28203     0.05217    0.37732     0.21189
Training/qf1_norm                     546.90074   65.03096   660.10004   396.54883
Training/qf2_norm                     546.15930   64.03769   657.68274   397.09064
log_std/mean                          -0.25636    0.00073    -0.25552    -0.25787
log_std/std                           0.09976     0.00201    0.10239     0.09626
log_std/max                           -0.13651    0.00329    -0.13141    -0.14160
log_std/min                           -0.60540    0.00388    -0.59487    -0.60908
log_probs/mean                        -1.23058    0.03991    -1.17188    -1.28950
log_probs/std                         1.71504     0.03410    1.79990     1.66771
log_probs/max                         4.88906     0.18179    5.18535     4.59147
log_probs/min                         -6.91582    0.67000    -5.85710    -7.78379
mean/mean                             -0.07683    0.00040    -0.07595    -0.07725
mean/std                              0.72713     0.00445    0.73373     0.71992
mean/max                              1.42236     0.00552    1.43043     1.40880
mean/min                              -1.72728    0.00604    -1.71308    -1.73441
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 0, 2, 4, 6, 1, 3, 7, 5, 9]
replay_buffer._size: [17100 17100 17100 17100 17100 17100 17100 17100 17100 17100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.875093460083008 0.002183675765991211
train_time 2.87862229347229
2023-09-06 13:37:32,940 MainThread INFO: EPOCH:112
2023-09-06 13:37:32,941 MainThread INFO: Time Consumed:3.0471153259277344s
2023-09-06 13:37:32,941 MainThread INFO: Total Frames:169500s
 28%|‚ñà‚ñà‚ñä       | 113/400 [06:31<24:42,  5.16s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               475.04224
Train_Epoch_Reward                    5845.67401
Running_Training_Average_Rewards      646.77465
Explore_Time                          0.15977
Train___Time                          2.87862
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.69954
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.75070
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.32067
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.54584
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.92642
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.22882
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.02048
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5209.68573
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.10442
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.00297
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.70811     0.56809    9.66601     7.77056
alpha_0                               0.73735     0.00028    0.73780     0.73691
alpha_1                               0.71662     0.00054    0.71747     0.71577
alpha_2                               0.71832     0.00052    0.71914     0.71750
alpha_3                               0.71819     0.00052    0.71900     0.71737
alpha_4                               0.71759     0.00053    0.71842     0.71675
alpha_5                               0.71838     0.00051    0.71918     0.71759
alpha_6                               0.71539     0.00058    0.71629     0.71449
alpha_7                               0.72311     0.00046    0.72383     0.72239
alpha_8                               0.71892     0.00052    0.71975     0.71810
alpha_9                               0.71642     0.00054    0.71727     0.71557
Alpha_loss                            -1.70472    0.00985    -1.68978    -1.72270
Training/policy_loss                  -20.94909   0.09483    -20.79630   -21.08948
Training/qf1_loss                     1770.23021  359.63672  2520.83838  1162.48010
Training/qf2_loss                     1769.68616  360.82931  2526.85669  1160.71387
Training/pf_norm                      0.27848     0.02485    0.31241     0.23278
Training/qf1_norm                     532.66538   59.35574   641.79028   441.04846
Training/qf2_norm                     531.52209   58.29646   640.37274   441.96500
log_std/mean                          -0.25816    0.00053    -0.25723    -0.25893
log_std/std                           0.10117     0.00098    0.10249     0.09973
log_std/max                           -0.12839    0.00072    -0.12732    -0.12938
log_std/min                           -0.59578    0.00734    -0.58513    -0.60880
log_probs/mean                        -1.16915    0.02499    -1.12725    -1.20967
log_probs/std                         1.70858     0.04348    1.78562     1.66091
log_probs/max                         4.75821     0.25827    5.14965     4.32992
log_probs/min                         -6.98107    0.74787    -5.83218    -8.12941
mean/mean                             -0.07209    0.00242    -0.06898    -0.07568
mean/std                              0.73404     0.00099    0.73565     0.73279
mean/max                              1.40769     0.01089    1.42839     1.39096
mean/min                              -1.71538    0.01067    -1.69783    -1.73489
------------------------------------  ----------  ---------  ----------  ----------
sample: [4, 6, 2, 0, 7, 3, 5, 1, 9, 8]
replay_buffer._size: [17250 17250 17250 17250 17250 17250 17250 17250 17250 17250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.133814334869385 0.002149343490600586
train_time 5.137289762496948
2023-09-06 13:37:38,277 MainThread INFO: EPOCH:113
2023-09-06 13:37:38,277 MainThread INFO: Time Consumed:5.151864767074585s
2023-09-06 13:37:38,277 MainThread INFO: Total Frames:171000s
 28%|‚ñà‚ñà‚ñä       | 114/400 [06:36<24:53,  5.22s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               467.51406
Train_Epoch_Reward                    5603.85412
Running_Training_Average_Rewards      691.72806
Explore_Time                          0.00425
Train___Time                          5.13729
Eval____Time                          0.00461
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.64284
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.90246
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.26116
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.70872
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.00930
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.53764
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.37064
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5215.56214
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.52908
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.57037
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.88134     1.36038    11.53567    6.51664
alpha_0                               0.73635     0.00029    0.73681     0.73589
alpha_1                               0.71473     0.00054    0.71558     0.71388
alpha_2                               0.71651     0.00052    0.71733     0.71570
alpha_3                               0.71638     0.00052    0.71719     0.71556
alpha_4                               0.71573     0.00053    0.71656     0.71490
alpha_5                               0.71664     0.00050    0.71742     0.71586
alpha_6                               0.71339     0.00057    0.71429     0.71250
alpha_7                               0.72152     0.00045    0.72223     0.72082
alpha_8                               0.71710     0.00052    0.71792     0.71628
alpha_9                               0.71454     0.00054    0.71538     0.71370
Alpha_loss                            -1.71812    0.01321    -1.69571    -1.73410
Training/policy_loss                  -21.35755   0.09714    -21.18115   -21.51896
Training/qf1_loss                     2061.98987  644.33559  3459.80347  1198.18701
Training/qf2_loss                     2060.28088  644.54116  3459.62744  1194.74084
Training/pf_norm                      0.33783     0.06481    0.48092     0.25058
Training/qf1_norm                     542.87442   131.02672  788.45966   289.86316
Training/qf2_norm                     543.88527   127.78290  782.97437   298.51157
log_std/mean                          -0.26032    0.00312    -0.25723    -0.26649
log_std/std                           0.10239     0.00184    0.10524     0.09989
log_std/max                           -0.12648    0.00174    -0.12438    -0.12974
log_std/min                           -0.58914    0.00485    -0.58210    -0.59723
log_probs/mean                        -1.17132    0.04268    -1.10003    -1.22306
log_probs/std                         1.73513     0.03116    1.80492     1.69506
log_probs/max                         4.94635     0.20132    5.19984     4.62664
log_probs/min                         -7.13513    0.54324    -6.06407    -7.90087
mean/mean                             -0.07006    0.00036    -0.06926    -0.07050
mean/std                              0.74487     0.00864    0.76045     0.73412
mean/max                              1.41198     0.01934    1.44604     1.38590
mean/min                              -1.72336    0.01584    -1.70056    -1.75106
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 4, 5, 2, 6, 7, 8, 0, 1, 3]
replay_buffer._size: [17400 17400 17400 17400 17400 17400 17400 17400 17400 17400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.225667715072632 0.002192974090576172
train_time 5.229182720184326
2023-09-06 13:37:43,751 MainThread INFO: EPOCH:114
2023-09-06 13:37:43,752 MainThread INFO: Time Consumed:5.2664408683776855s
2023-09-06 13:37:43,752 MainThread INFO: Total Frames:172500s
 29%|‚ñà‚ñà‚ñâ       | 115/400 [06:42<25:14,  5.31s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               467.82564
Train_Epoch_Reward                    4058.11215
Running_Training_Average_Rewards      516.92134
Explore_Time                          0.02257
Train___Time                          5.22918
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.85644
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -84.88897
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.34033
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.71266
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.95867
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.35510
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.57604
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5276.14381
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.41572
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.38638
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.69234     1.20715    10.91805    7.37074
alpha_0                               0.73536     0.00027    0.73579     0.73493
alpha_1                               0.71285     0.00053    0.71369     0.71202
alpha_2                               0.71471     0.00051    0.71552     0.71390
alpha_3                               0.71458     0.00051    0.71539     0.71378
alpha_4                               0.71389     0.00052    0.71472     0.71307
alpha_5                               0.71491     0.00049    0.71569     0.71415
alpha_6                               0.71141     0.00057    0.71230     0.71052
alpha_7                               0.71996     0.00044    0.72066     0.71927
alpha_8                               0.71529     0.00052    0.71610     0.71448
alpha_9                               0.71268     0.00053    0.71352     0.71185
Alpha_loss                            -1.68514    0.01228    -1.66811    -1.70875
Training/policy_loss                  -21.72738   0.12681    -21.49218   -21.90458
Training/qf1_loss                     1700.45004  615.56843  2843.06177  964.10999
Training/qf2_loss                     1699.08301  614.15649  2841.77368  962.84747
Training/pf_norm                      0.31633     0.05373    0.43752     0.26376
Training/qf1_norm                     529.44907   119.45996  748.74609   400.21857
Training/qf2_norm                     529.26754   117.69990  744.06805   399.61398
log_std/mean                          -0.27348    0.00225    -0.26853    -0.27568
log_std/std                           0.10592     0.00065    0.10659     0.10452
log_std/max                           -0.13378    0.00353    -0.12837    -0.13914
log_std/min                           -0.60005    0.00376    -0.59275    -0.60560
log_probs/mean                        -1.03124    0.04032    -0.97681    -1.11698
log_probs/std                         1.80827     0.03172    1.85922     1.75514
log_probs/max                         5.33440     0.26292    5.73352     4.82071
log_probs/min                         -7.25419    0.51749    -6.48911    -8.07515
mean/mean                             -0.07136    0.00147    -0.06963    -0.07353
mean/std                              0.77668     0.00539    0.78136     0.76497
mean/max                              1.48635     0.01338    1.49689     1.45527
mean/min                              -1.78116    0.00986    -1.75758    -1.78970
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 9, 2, 8, 4, 1, 5, 0, 7, 3]
replay_buffer._size: [17550 17550 17550 17550 17550 17550 17550 17550 17550 17550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.851926326751709 0.0021085739135742188
train_time 4.855339288711548
2023-09-06 13:37:48,842 MainThread INFO: EPOCH:115
2023-09-06 13:37:48,843 MainThread INFO: Time Consumed:4.873476266860962s
2023-09-06 13:37:48,843 MainThread INFO: Total Frames:174000s
 29%|‚ñà‚ñà‚ñâ       | 116/400 [06:47<24:44,  5.23s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               467.62777
Train_Epoch_Reward                    6744.85604
Running_Training_Average_Rewards      546.89408
Explore_Time                          0.00537
Train___Time                          4.85534
Eval____Time                          0.00772
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.69186
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.18149
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.36752
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.03568
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.12517
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.82480
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.10788
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5207.95566
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.35106
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.12050
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.23296     1.10880    10.46034    6.77160
alpha_0                               0.73444     0.00026    0.73484     0.73404
alpha_1                               0.71101     0.00053    0.71183     0.71018
alpha_2                               0.71293     0.00051    0.71373     0.71214
alpha_3                               0.71281     0.00051    0.71361     0.71201
alpha_4                               0.71207     0.00052    0.71289     0.71125
alpha_5                               0.71322     0.00048    0.71398     0.71247
alpha_6                               0.70944     0.00057    0.71032     0.70855
alpha_7                               0.71842     0.00044    0.71912     0.71773
alpha_8                               0.71351     0.00050    0.71430     0.71273
alpha_9                               0.71084     0.00053    0.71167     0.71002
Alpha_loss                            -1.69440    0.01526    -1.66868    -1.71418
Training/policy_loss                  -22.08872   0.10620    -21.91112   -22.26016
Training/qf1_loss                     1530.95412  467.17801  2306.59814  758.56244
Training/qf2_loss                     1529.32493  468.39635  2306.42456  753.79950
Training/pf_norm                      0.29487     0.04648    0.37559     0.23158
Training/qf1_norm                     489.82048   118.68836  734.32397   343.77170
Training/qf2_norm                     491.07051   114.84455  729.33630   349.55399
log_std/mean                          -0.26994    0.00174    -0.26726    -0.27272
log_std/std                           0.10496     0.00080    0.10637     0.10392
log_std/max                           -0.13818    0.00111    -0.13563    -0.13952
log_std/min                           -0.59262    0.00346    -0.58887    -0.59897
log_probs/mean                        -1.02233    0.04046    -0.94902    -1.06858
log_probs/std                         1.78833     0.01983    1.82979     1.75194
log_probs/max                         5.25314     0.17869    5.57165     4.95127
log_probs/min                         -7.00543    0.56411    -6.26270    -8.10988
mean/mean                             -0.07082    0.00171    -0.06805    -0.07337
mean/std                              0.77458     0.00317    0.77924     0.77095
mean/max                              1.47974     0.00895    1.49179     1.46590
mean/min                              -1.75895    0.01030    -1.74351    -1.77398
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 6, 5, 0, 7, 9, 8, 1, 3, 4]
replay_buffer._size: [17709 17708 17708 17709 17708 17708 17708 17708 17708 17706]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.854521751403809 0.002103567123413086
train_time 4.857940196990967
2023-09-06 13:37:54,057 MainThread INFO: EPOCH:116
2023-09-06 13:37:54,058 MainThread INFO: Time Consumed:5.027694225311279s
2023-09-06 13:37:54,058 MainThread INFO: Total Frames:175500s
 29%|‚ñà‚ñà‚ñâ       | 117/400 [06:52<24:39,  5.23s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               464.77000
Train_Epoch_Reward                    5471.64062
Running_Training_Average_Rewards      542.48696
Explore_Time                          0.15943
Train___Time                          4.85794
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.20360
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.25713
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.30661
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.15740
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.16515
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.24577
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.07419
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5120.51809
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.38353
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.42801
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.45510     1.10284    10.08031    6.52936
alpha_0                               0.73355     0.00025    0.73395     0.73316
alpha_1                               0.70916     0.00053    0.70999     0.70833
alpha_2                               0.71117     0.00050    0.71196     0.71038
alpha_3                               0.71103     0.00051    0.71183     0.71024
alpha_4                               0.71026     0.00052    0.71107     0.70945
alpha_5                               0.71154     0.00048    0.71230     0.71079
alpha_6                               0.70747     0.00057    0.70835     0.70658
alpha_7                               0.71688     0.00044    0.71757     0.71619
alpha_8                               0.71176     0.00050    0.71255     0.71098
alpha_9                               0.70902     0.00052    0.70984     0.70821
Alpha_loss                            -1.70102    0.01051    -1.68706    -1.71860
Training/policy_loss                  -22.46406   0.11982    -22.25488   -22.64175
Training/qf1_loss                     1635.37222  550.78427  2432.61963  804.17224
Training/qf2_loss                     1635.50789  552.25933  2438.16675  801.18158
Training/pf_norm                      0.27159     0.04619    0.34108     0.20218
Training/qf1_norm                     519.04443   113.35553  687.81696   321.94238
Training/qf2_norm                     518.20625   110.12188  680.72375   325.11075
log_std/mean                          -0.26979    0.00177    -0.26752    -0.27267
log_std/std                           0.10715     0.00049    0.10808     0.10648
log_std/max                           -0.13598    0.00113    -0.13406    -0.13809
log_std/min                           -0.60042    0.00236    -0.59756    -0.60406
log_probs/mean                        -1.00485    0.03487    -0.95847    -1.07168
log_probs/std                         1.82927     0.03829    1.87146     1.76164
log_probs/max                         5.42682     0.22860    5.77292     4.99517
log_probs/min                         -7.51200    0.92689    -6.42004    -9.70497
mean/mean                             -0.06782    0.00068    -0.06712    -0.06928
mean/std                              0.78156     0.00630    0.79227     0.77248
mean/max                              1.48460     0.00814    1.49523     1.47225
mean/min                              -1.76978    0.01388    -1.75017    -1.79050
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 6, 7, 4, 1, 3, 9, 5, 8]
replay_buffer._size: [17850 17850 17850 17850 17850 17850 17850 17850 17850 17850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.039550065994263 0.002141237258911133
train_time 5.043016195297241
2023-09-06 13:37:59,285 MainThread INFO: EPOCH:117
2023-09-06 13:37:59,285 MainThread INFO: Time Consumed:5.062775611877441s
2023-09-06 13:37:59,286 MainThread INFO: Total Frames:177000s
 30%|‚ñà‚ñà‚ñâ       | 118/400 [06:57<24:34,  5.23s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               459.15433
Train_Epoch_Reward                    4738.94162
Running_Training_Average_Rewards      565.18128
Explore_Time                          0.01060
Train___Time                          5.04302
Eval____Time                          0.00335
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.13270
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.15990
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.32088
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.08711
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.11492
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.14942
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -64.85588
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5103.69493
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.39530
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.29530
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.35440     0.77896    10.25731    7.40278
alpha_0                               0.73269     0.00024    0.73307     0.73231
alpha_1                               0.70731     0.00053    0.70814     0.70649
alpha_2                               0.70943     0.00050    0.71021     0.70864
alpha_3                               0.70928     0.00050    0.71006     0.70851
alpha_4                               0.70846     0.00051    0.70927     0.70766
alpha_5                               0.70988     0.00047    0.71062     0.70914
alpha_6                               0.70551     0.00056    0.70638     0.70463
alpha_7                               0.71535     0.00044    0.71604     0.71467
alpha_8                               0.71002     0.00050    0.71080     0.70924
alpha_9                               0.70721     0.00052    0.70802     0.70640
Alpha_loss                            -1.68600    0.00949    -1.66821    -1.70221
Training/policy_loss                  -22.82332   0.09813    -22.65208   -22.97173
Training/qf1_loss                     1429.01393  393.35440  2407.23877  1018.21271
Training/qf2_loss                     1426.84233  392.52341  2400.75610  1010.92365
Training/pf_norm                      0.31010     0.06305    0.42165     0.23509
Training/qf1_norm                     504.86729   83.63998   706.90808   404.29749
Training/qf2_norm                     505.58916   81.91411   704.19720   410.88519
log_std/mean                          -0.27590    0.00108    -0.27342    -0.27716
log_std/std                           0.10823     0.00033    0.10865     0.10769
log_std/max                           -0.13792    0.00104    -0.13670    -0.14000
log_std/min                           -0.60756    0.00236    -0.60398    -0.61081
log_probs/mean                        -0.92528    0.02529    -0.87020    -0.96108
log_probs/std                         1.84666     0.02776    1.88213     1.80643
log_probs/max                         5.46490     0.14641    5.68088     5.10227
log_probs/min                         -7.92495    0.84240    -7.05829    -9.12757
mean/mean                             -0.07003    0.00057    -0.06890    -0.07075
mean/std                              0.80222     0.00335    0.80691     0.79499
mean/max                              1.51057     0.00791    1.52634     1.49664
mean/min                              -1.80564    0.00637    -1.79599    -1.81663
------------------------------------  ----------  ---------  ----------  ----------
sample: [9, 7, 3, 1, 6, 0, 8, 4, 5, 2]
replay_buffer._size: [18000 18000 18000 18000 18000 18000 18000 18000 18000 18000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.157331943511963 0.002103567123413086
train_time 5.160788536071777
2023-09-06 13:38:04,666 MainThread INFO: EPOCH:118
2023-09-06 13:38:04,680 MainThread INFO: Time Consumed:5.2004008293151855s
2023-09-06 13:38:04,681 MainThread INFO: Total Frames:178500s
 30%|‚ñà‚ñà‚ñâ       | 119/400 [07:03<24:42,  5.28s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               454.42980
Train_Epoch_Reward                    4586.64106
Running_Training_Average_Rewards      493.24078
Explore_Time                          0.02657
Train___Time                          5.16079
Eval____Time                          0.00706
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.57903
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.40543
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.42361
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.34191
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.32666
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.51901
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.22497
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5053.05730
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.39305
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.42997
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.94876     0.47591    9.98715     8.42562
alpha_0                               0.73185     0.00023    0.73222     0.73149
alpha_1                               0.70549     0.00052    0.70630     0.70468
alpha_2                               0.70769     0.00050    0.70847     0.70691
alpha_3                               0.70756     0.00049    0.70834     0.70679
alpha_4                               0.70668     0.00051    0.70748     0.70589
alpha_5                               0.70824     0.00047    0.70897     0.70751
alpha_6                               0.70356     0.00056    0.70444     0.70268
alpha_7                               0.71385     0.00043    0.71452     0.71318
alpha_8                               0.70829     0.00050    0.70907     0.70751
alpha_9                               0.70542     0.00051    0.70622     0.70463
Alpha_loss                            -1.67154    0.01654    -1.64335    -1.69310
Training/policy_loss                  -23.18791   0.12520    -22.98769   -23.35436
Training/qf1_loss                     1818.18385  379.90348  2348.88452  1222.26428
Training/qf2_loss                     1817.64459  380.70967  2350.71899  1222.93005
Training/pf_norm                      0.29435     0.05009    0.36728     0.23046
Training/qf1_norm                     575.49370   51.81803   690.17621   523.91602
Training/qf2_norm                     574.18237   49.82063   685.52728   526.19464
log_std/mean                          -0.27838    0.00035    -0.27774    -0.27891
log_std/std                           0.11074     0.00058    0.11136     0.10944
log_std/max                           -0.13424    0.00244    -0.13026    -0.13773
log_std/min                           -0.61219    0.00246    -0.60805    -0.61521
log_probs/mean                        -0.84654    0.05009    -0.76346    -0.91494
log_probs/std                         1.89021     0.02362    1.92790     1.84704
log_probs/max                         5.67017     0.18049    5.94171     5.27773
log_probs/min                         -7.04942    0.69912    -6.03602    -8.67729
mean/mean                             -0.06515    0.00240    -0.06102    -0.06843
mean/std                              0.81332     0.00173    0.81545     0.80938
mean/max                              1.53373     0.00630    1.54678     1.52361
mean/min                              -1.80831    0.00595    -1.79993    -1.81859
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 6, 1, 9, 7, 0, 3, 2, 5, 4]
replay_buffer._size: [18150 18150 18150 18150 18150 18150 18150 18150 18150 18150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.219014406204224 0.0021047592163085938
train_time 5.222555875778198
2023-09-06 13:38:10,073 MainThread INFO: EPOCH:119
2023-09-06 13:38:10,074 MainThread INFO: Time Consumed:5.238676071166992s
2023-09-06 13:38:10,074 MainThread INFO: Total Frames:180000s
 30%|‚ñà‚ñà‚ñà       | 120/400 [07:08<24:47,  5.31s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               449.51948
Train_Epoch_Reward                    5876.98511
Running_Training_Average_Rewards      506.75226
Explore_Time                          0.00679
Train___Time                          5.22256
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.06211
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.35878
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.42273
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.46105
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.37104
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.85278
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.26551
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4973.95057
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.56555
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.60375
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.51942     0.98290    9.89067     6.99287
alpha_0                               0.73105     0.00023    0.73141     0.73070
alpha_1                               0.70369     0.00052    0.70450     0.70288
alpha_2                               0.70596     0.00049    0.70674     0.70519
alpha_3                               0.70584     0.00049    0.70662     0.70507
alpha_4                               0.70494     0.00050    0.70572     0.70416
alpha_5                               0.70663     0.00046    0.70735     0.70590
alpha_6                               0.70161     0.00056    0.70249     0.70074
alpha_7                               0.71236     0.00043    0.71303     0.71169
alpha_8                               0.70657     0.00049    0.70734     0.70581
alpha_9                               0.70365     0.00051    0.70445     0.70285
Alpha_loss                            -1.68504    0.01305    -1.66845    -1.70992
Training/policy_loss                  -23.58290   0.14058    -23.36848   -23.86064
Training/qf1_loss                     1743.59907  449.58177  2460.87183  933.26624
Training/qf2_loss                     1742.99424  451.60515  2463.81030  928.05292
Training/pf_norm                      0.33865     0.06416    0.42477     0.24561
Training/qf1_norm                     539.45793   103.20592  682.27673   377.86792
Training/qf2_norm                     538.37970   100.74281  678.44812   379.56964
log_std/mean                          -0.28097    0.00290    -0.27791    -0.28653
log_std/std                           0.11003     0.00031    0.11044     0.10943
log_std/max                           -0.13312    0.00277    -0.12937    -0.13790
log_std/min                           -0.60523    0.00097    -0.60396    -0.60684
log_probs/mean                        -0.85208    0.04509    -0.79015    -0.93894
log_probs/std                         1.88934     0.04419    1.94337     1.78761
log_probs/max                         5.73403     0.19353    6.01296     5.24902
log_probs/min                         -7.42657    1.32611    -5.62547    -10.69243
mean/mean                             -0.06079    0.00034    -0.06021    -0.06115
mean/std                              0.81630     0.00407    0.82395     0.81187
mean/max                              1.52776     0.00467    1.53912     1.52220
mean/min                              -1.80696    0.00669    -1.79836    -1.82173
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 0, 4, 8, 7, 3, 1, 9, 6, 2]
replay_buffer._size: [18300 18300 18300 18300 18300 18300 18300 18300 18300 18300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.418647527694702 0.002114534378051758
train_time 5.4220781326293945
2023-09-06 13:38:15,658 MainThread INFO: EPOCH:120
2023-09-06 13:38:15,659 MainThread INFO: Time Consumed:5.436760187149048s
2023-09-06 13:38:15,659 MainThread INFO: Total Frames:181500s
 30%|‚ñà‚ñà‚ñà       | 121/400 [07:14<25:04,  5.39s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               445.85762
Train_Epoch_Reward                    4921.69410
Running_Training_Average_Rewards      512.84401
Explore_Time                          0.00516
Train___Time                          5.42208
Eval____Time                          0.00481
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.73777
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.30901
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.35573
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.50894
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.29928
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.81839
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.50135
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4994.26862
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.30932
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.10129
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.25463     1.20406    9.80528     6.48410
alpha_0                               0.73030     0.00021    0.73063     0.72997
alpha_1                               0.70189     0.00051    0.70270     0.70109
alpha_2                               0.70428     0.00048    0.70503     0.70353
alpha_3                               0.70413     0.00049    0.70490     0.70336
alpha_4                               0.70321     0.00049    0.70398     0.70243
alpha_5                               0.70502     0.00046    0.70574     0.70431
alpha_6                               0.69969     0.00055    0.70055     0.69882
alpha_7                               0.71088     0.00043    0.71155     0.71021
alpha_8                               0.70487     0.00049    0.70564     0.70411
alpha_9                               0.70187     0.00051    0.70267     0.70107
Alpha_loss                            -1.67166    0.01513    -1.65177    -1.69927
Training/policy_loss                  -23.96377   0.11534    -23.79736   -24.17863
Training/qf1_loss                     1499.48162  440.88097  2349.94702  854.41174
Training/qf2_loss                     1498.05778  442.01555  2354.23096  853.78754
Training/pf_norm                      0.32812     0.05145    0.46138     0.28190
Training/qf1_norm                     511.54308   136.85615  688.78552   304.34869
Training/qf2_norm                     512.19554   132.88144  685.46985   309.71924
log_std/mean                          -0.29166    0.00287    -0.28753    -0.29622
log_std/std                           0.10936     0.00076    0.11086     0.10851
log_std/max                           -0.13848    0.00063    -0.13729    -0.13923
log_std/min                           -0.60521    0.00364    -0.60066    -0.61114
log_probs/mean                        -0.77858    0.04647    -0.70361    -0.85603
log_probs/std                         1.92499     0.04044    2.00698     1.87641
log_probs/max                         5.87848     0.15203    6.05886     5.59919
log_probs/min                         -7.29525    0.86001    -6.26068    -8.79168
mean/mean                             -0.05863    0.00185    -0.05527    -0.06099
mean/std                              0.83118     0.00508    0.84081     0.82459
mean/max                              1.55073     0.01008    1.57006     1.53846
mean/min                              -1.81767    0.00694    -1.80934    -1.83152
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 4, 2, 6, 9, 1, 8, 5, 0, 3]
replay_buffer._size: [18450 18450 18450 18450 18450 18450 18450 18450 18450 18450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.837472915649414 0.0022008419036865234
train_time 4.841030836105347
2023-09-06 13:38:21,080 MainThread INFO: EPOCH:121
2023-09-06 13:38:21,080 MainThread INFO: Time Consumed:5.107203722000122s
2023-09-06 13:38:21,080 MainThread INFO: Total Frames:183000s
 30%|‚ñà‚ñà‚ñà       | 122/400 [07:19<25:05,  5.41s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               440.77594
Train_Epoch_Reward                    5951.34219
Running_Training_Average_Rewards      558.33405
Explore_Time                          0.25647
Train___Time                          4.84103
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.44507
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.40738
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.27391
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.57653
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.40373
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.15270
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.56114
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4921.44006
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.29571
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.36053
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.07650     0.60031    8.98503     7.18442
alpha_0                               0.72958     0.00020    0.72990     0.72927
alpha_1                               0.70012     0.00051    0.70091     0.69932
alpha_2                               0.70263     0.00047    0.70337     0.70190
alpha_3                               0.70242     0.00049    0.70319     0.70166
alpha_4                               0.70149     0.00049    0.70226     0.70072
alpha_5                               0.70345     0.00045    0.70415     0.70274
alpha_6                               0.69777     0.00055    0.69863     0.69690
alpha_7                               0.70940     0.00042    0.71006     0.70875
alpha_8                               0.70317     0.00049    0.70394     0.70241
alpha_9                               0.70010     0.00051    0.70089     0.69931
Alpha_loss                            -1.66076    0.01298    -1.63821    -1.67483
Training/policy_loss                  -24.35013   0.12837    -24.06720   -24.52176
Training/qf1_loss                     1369.98865  206.63300  1730.37683  986.82147
Training/qf2_loss                     1368.84694  206.73765  1730.32385  984.39319
Training/pf_norm                      0.32282     0.05550    0.40411     0.24621
Training/qf1_norm                     493.13464   72.37347   618.31531   390.92529
Training/qf2_norm                     493.59725   70.11922   614.47504   397.30441
log_std/mean                          -0.29575    0.00037    -0.29482    -0.29619
log_std/std                           0.11123     0.00061    0.11242     0.11056
log_std/max                           -0.13573    0.00143    -0.13361    -0.13796
log_std/min                           -0.60999    0.00149    -0.60814    -0.61338
log_probs/mean                        -0.71499    0.03885    -0.63902    -0.76218
log_probs/std                         1.94504     0.03646    2.00409     1.89412
log_probs/max                         5.86864     0.18982    6.15292     5.46156
log_probs/min                         -7.37679    0.86268    -5.88992    -8.86252
mean/mean                             -0.05139    0.00136    -0.04978    -0.05428
mean/std                              0.84582     0.00269    0.84941     0.84107
mean/max                              1.56112     0.00255    1.56367     1.55622
mean/min                              -1.82346    0.00377    -1.81774    -1.83073
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 6, 3, 7, 8, 4, 5, 1, 0, 9]
replay_buffer._size: [18600 18600 18600 18600 18600 18600 18600 18600 18600 18600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.518149375915527 0.002234935760498047
train_time 5.521733999252319
2023-09-06 13:38:26,801 MainThread INFO: EPOCH:122
2023-09-06 13:38:26,801 MainThread INFO: Time Consumed:5.536145210266113s
2023-09-06 13:38:26,802 MainThread INFO: Total Frames:184500s
 31%|‚ñà‚ñà‚ñà       | 123/400 [07:25<25:19,  5.49s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               437.34905
Train_Epoch_Reward                    5390.46490
Running_Training_Average_Rewards      542.11671
Explore_Time                          0.00550
Train___Time                          5.52173
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.39493
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.46393
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.36525
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.65122
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.53000
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.31853
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.69548
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4894.22571
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.26329
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.36249
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.52321     0.98794    10.22599    6.84298
alpha_0                               0.72890     0.00019    0.72920     0.72859
alpha_1                               0.69836     0.00050    0.69915     0.69758
alpha_2                               0.70101     0.00047    0.70174     0.70027
alpha_3                               0.70074     0.00048    0.70149     0.69998
alpha_4                               0.69978     0.00049    0.70055     0.69902
alpha_5                               0.70189     0.00044    0.70259     0.70119
alpha_6                               0.69585     0.00055    0.69671     0.69500
alpha_7                               0.70796     0.00041    0.70860     0.70731
alpha_8                               0.70149     0.00048    0.70224     0.70074
alpha_9                               0.69834     0.00050    0.69913     0.69755
Alpha_loss                            -1.66536    0.01862    -1.63015    -1.69684
Training/policy_loss                  -24.73430   0.12760    -24.53170   -24.96611
Training/qf1_loss                     1698.23069  350.09206  2499.00146  1277.90356
Training/qf2_loss                     1697.13313  351.52370  2501.22583  1273.23633
Training/pf_norm                      0.36572     0.07346    0.48544     0.23833
Training/qf1_norm                     541.91899   117.14167  726.08636   328.52658
Training/qf2_norm                     542.04765   112.93480  720.35657   337.37762
log_std/mean                          -0.28937    0.00294    -0.28629    -0.29467
log_std/std                           0.11202     0.00080    0.11307     0.11087
log_std/max                           -0.13247    0.00143    -0.12944    -0.13379
log_std/min                           -0.60318    0.00835    -0.59273    -0.61422
log_probs/mean                        -0.69677    0.04825    -0.60186    -0.77608
log_probs/std                         1.93269     0.03183    1.99212     1.88876
log_probs/max                         5.83605     0.17919    6.12855     5.52017
log_probs/min                         -8.07995    1.12428    -5.79820    -9.66300
mean/mean                             -0.05268    0.00053    -0.05161    -0.05333
mean/std                              0.84712     0.00225    0.85023     0.84433
mean/max                              1.55976     0.00783    1.57698     1.54511
mean/min                              -1.81775    0.01479    -1.79737    -1.84190
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 0, 5, 8, 9, 6, 4, 1, 7, 3]
replay_buffer._size: [18750 18750 18750 18750 18750 18750 18750 18750 18750 18750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.126668453216553 0.00213623046875
train_time 5.130125284194946
2023-09-06 13:38:32,138 MainThread INFO: EPOCH:123
2023-09-06 13:38:32,139 MainThread INFO: Time Consumed:5.150088548660278s
2023-09-06 13:38:32,139 MainThread INFO: Total Frames:186000s
 31%|‚ñà‚ñà‚ñà       | 124/400 [07:30<25:04,  5.45s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               434.43953
Train_Epoch_Reward                    4480.20872
Running_Training_Average_Rewards      527.40053
Explore_Time                          0.01028
Train___Time                          5.13013
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.72024
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.54250
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.46544
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.73373
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.60684
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.27962
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.79700
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4899.84539
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.23232
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.42583
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.53631     0.96990    10.11397    7.03870
alpha_0                               0.72821     0.00020    0.72852     0.72791
alpha_1                               0.69662     0.00050    0.69740     0.69584
alpha_2                               0.69938     0.00047    0.70011     0.69865
alpha_3                               0.69905     0.00048    0.69981     0.69830
alpha_4                               0.69810     0.00048    0.69885     0.69736
alpha_5                               0.70035     0.00044    0.70104     0.69966
alpha_6                               0.69395     0.00055    0.69481     0.69310
alpha_7                               0.70652     0.00041    0.70716     0.70587
alpha_8                               0.69984     0.00047    0.70058     0.69909
alpha_9                               0.69659     0.00050    0.69738     0.69580
Alpha_loss                            -1.65902    0.01112    -1.64044    -1.67731
Training/policy_loss                  -25.06958   0.11857    -24.84941   -25.26598
Training/qf1_loss                     1636.38446  437.31843  2629.33862  1041.64612
Training/qf2_loss                     1635.96742  438.41596  2630.44897  1043.05273
Training/pf_norm                      0.31636     0.03746    0.39480     0.27011
Training/qf1_norm                     559.22742   112.38414  745.18176   386.24884
Training/qf2_norm                     558.10797   109.30080  737.26160   385.02121
log_std/mean                          -0.29272    0.00358    -0.28752    -0.29872
log_std/std                           0.11431     0.00079    0.11519     0.11264
log_std/max                           -0.13759    0.00325    -0.13320    -0.14266
log_std/min                           -0.61237    0.00777    -0.60083    -0.62621
log_probs/mean                        -0.64652    0.03403    -0.59847    -0.69400
log_probs/std                         1.97894     0.05290    2.04978     1.91043
log_probs/max                         6.02440     0.18537    6.35214     5.80007
log_probs/min                         -7.98394    1.38096    -6.71195    -11.39514
mean/mean                             -0.05160    0.00036    -0.05113    -0.05212
mean/std                              0.85937     0.00651    0.86844     0.84826
mean/max                              1.59924     0.02028    1.63549     1.57000
mean/min                              -1.84042    0.01948    -1.81350    -1.87556
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 4, 1, 3, 0, 6, 5, 9, 7, 8]
replay_buffer._size: [18909 18909 18908 18909 18909 18908 18908 18908 18908 18907]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.401995897293091 0.0022361278533935547
train_time 5.405595541000366
2023-09-06 13:38:37,841 MainThread INFO: EPOCH:124
2023-09-06 13:38:37,842 MainThread INFO: Time Consumed:5.563252925872803s
2023-09-06 13:38:37,842 MainThread INFO: Total Frames:187500s
 31%|‚ñà‚ñà‚ñà‚ñè      | 125/400 [07:36<25:17,  5.52s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               434.27300
Train_Epoch_Reward                    5878.55470
Running_Training_Average_Rewards      524.97428
Explore_Time                          0.14695
Train___Time                          5.40560
Eval____Time                          0.00504
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.66456
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.51559
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.42819
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.75730
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.58166
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.21094
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.71594
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4901.29308
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.30117
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.15006
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.69649     0.89787    10.36709    7.31466
alpha_0                               0.72757     0.00017    0.72785     0.72730
alpha_1                               0.69489     0.00050    0.69567     0.69411
alpha_2                               0.69776     0.00046    0.69849     0.69704
alpha_3                               0.69739     0.00047    0.69813     0.69665
alpha_4                               0.69645     0.00048    0.69719     0.69570
alpha_5                               0.69883     0.00043    0.69951     0.69815
alpha_6                               0.69205     0.00055    0.69291     0.69119
alpha_7                               0.70508     0.00041    0.70573     0.70444
alpha_8                               0.69819     0.00047    0.69893     0.69746
alpha_9                               0.69484     0.00050    0.69563     0.69406
Alpha_loss                            -1.65189    0.01961    -1.61887    -1.67894
Training/policy_loss                  -25.48267   0.12373    -25.26421   -25.65544
Training/qf1_loss                     1765.64669  484.13395  2855.46362  1226.73511
Training/qf2_loss                     1766.51119  486.75684  2864.55078  1230.57654
Training/pf_norm                      0.34759     0.07618    0.50650     0.23798
Training/qf1_norm                     577.25927   113.05858  802.13739   411.53360
Training/qf2_norm                     575.06738   109.14117  788.82843   414.01144
log_std/mean                          -0.30204    0.00085    -0.30018    -0.30329
log_std/std                           0.11274     0.00115    0.11495     0.11148
log_std/max                           -0.14528    0.00161    -0.14279    -0.14828
log_std/min                           -0.61245    0.00419    -0.60776    -0.61914
log_probs/mean                        -0.59466    0.05554    -0.49150    -0.66671
log_probs/std                         1.99741     0.03759    2.05845     1.94521
log_probs/max                         6.09101     0.22957    6.54352     5.71209
log_probs/min                         -7.79448    1.45147    -5.68383    -10.52922
mean/mean                             -0.04838    0.00191    -0.04583    -0.05172
mean/std                              0.87025     0.00078    0.87170     0.86914
mean/max                              1.60488     0.00504    1.61334     1.59583
mean/min                              -1.84715    0.00385    -1.84166    -1.85414
------------------------------------  ----------  ---------  ----------  ----------
sample: [7, 4, 0, 1, 8, 9, 5, 3, 2, 6]
replay_buffer._size: [19050 19050 19050 19050 19050 19050 19050 19050 19050 19050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.1189754009246826 0.0021004676818847656
train_time 3.122394561767578
2023-09-06 13:38:43,171 MainThread INFO: EPOCH:125
2023-09-06 13:38:43,172 MainThread INFO: Time Consumed:3.194373846054077s
2023-09-06 13:38:43,172 MainThread INFO: Total Frames:189000s
 32%|‚ñà‚ñà‚ñà‚ñè      | 126/400 [07:41<24:58,  5.47s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               432.43669
Train_Epoch_Reward                    6612.12534
Running_Training_Average_Rewards      565.69629
Explore_Time                          0.06322
Train___Time                          3.12239
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.20703
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.68475
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.34395
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.85136
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.74837
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.51969
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.72877
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4826.99763
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.36467
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.45788
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.49025     0.69354    9.43521     7.38193
alpha_0                               0.72697     0.00017    0.72724     0.72671
alpha_1                               0.69315     0.00050    0.69393     0.69237
alpha_2                               0.69617     0.00046    0.69688     0.69545
alpha_3                               0.69574     0.00047    0.69648     0.69499
alpha_4                               0.69481     0.00047    0.69554     0.69407
alpha_5                               0.69731     0.00043    0.69800     0.69663
alpha_6                               0.69014     0.00055    0.69100     0.68928
alpha_7                               0.70367     0.00040    0.70430     0.70305
alpha_8                               0.69658     0.00046    0.69730     0.69585
alpha_9                               0.69311     0.00050    0.69389     0.69233
Alpha_loss                            -1.65561    0.01655    -1.63611    -1.68830
Training/policy_loss                  -25.83523   0.08052    -25.69062   -26.00593
Training/qf1_loss                     1664.85187  256.56076  2086.58936  1275.76843
Training/qf2_loss                     1664.54890  257.64476  2086.26953  1273.93835
Training/pf_norm                      0.31695     0.04166    0.38057     0.23098
Training/qf1_norm                     561.31405   88.69010   677.96246   436.87305
Training/qf2_norm                     559.30075   86.09338   673.10248   437.52768
log_std/mean                          -0.30052    0.00066    -0.29969    -0.30160
log_std/std                           0.11541     0.00145    0.11767     0.11271
log_std/max                           -0.13768    0.00355    -0.13187    -0.14219
log_std/min                           -0.61813    0.00276    -0.61267    -0.62169
log_probs/mean                        -0.57376    0.04404    -0.51195    -0.65690
log_probs/std                         2.01571     0.03837    2.07194     1.92503
log_probs/max                         6.16048     0.25853    6.49890     5.59265
log_probs/min                         -7.47215    0.55420    -6.83629    -8.79228
mean/mean                             -0.04367    0.00105    -0.04183    -0.04509
mean/std                              0.87452     0.00129    0.87640     0.87154
mean/max                              1.60277     0.00266    1.60838     1.59864
mean/min                              -1.85076    0.00395    -1.84214    -1.85767
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 2, 5, 8, 6, 4, 0, 9, 3, 7]
replay_buffer._size: [19200 19200 19200 19200 19200 19200 19200 19200 19200 19200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.671528577804565 0.0020961761474609375
train_time 5.674922466278076
2023-09-06 13:38:49,031 MainThread INFO: EPOCH:126
2023-09-06 13:38:49,032 MainThread INFO: Time Consumed:5.689718723297119s
2023-09-06 13:38:49,033 MainThread INFO: Total Frames:190500s
 32%|‚ñà‚ñà‚ñà‚ñè      | 127/400 [07:47<25:23,  5.58s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               429.83194
Train_Epoch_Reward                    5329.30433
Running_Training_Average_Rewards      593.99948
Explore_Time                          0.00642
Train___Time                          5.67492
Eval____Time                          0.00312
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.61642
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.64255
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.35726
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.87809
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.72998
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.46359
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.67980
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4824.59794
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.35118
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.97956
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.24396     0.78792    9.47272     7.22095
alpha_0                               0.72639     0.00017    0.72665     0.72613
alpha_1                               0.69142     0.00050    0.69220     0.69064
alpha_2                               0.69458     0.00046    0.69529     0.69386
alpha_3                               0.69408     0.00048    0.69483     0.69333
alpha_4                               0.69318     0.00046    0.69391     0.69246
alpha_5                               0.69581     0.00043    0.69648     0.69515
alpha_6                               0.68824     0.00054    0.68909     0.68739
alpha_7                               0.70229     0.00040    0.70291     0.70166
alpha_8                               0.69497     0.00046    0.69569     0.69426
alpha_9                               0.69138     0.00049    0.69216     0.69061
Alpha_loss                            -1.65290    0.01632    -1.62429    -1.67575
Training/policy_loss                  -26.24038   0.11010    -26.06331   -26.39770
Training/qf1_loss                     1591.80269  533.04505  2711.96216  1034.29431
Training/qf2_loss                     1592.81622  532.17273  2707.13550  1037.61316
Training/pf_norm                      0.30532     0.04925    0.37593     0.24271
Training/qf1_norm                     526.29411   90.76711   677.73291   402.30719
Training/qf2_norm                     524.82293   89.34229   671.92810   402.93143
log_std/mean                          -0.30320    0.00137    -0.30064    -0.30463
log_std/std                           0.12129     0.00119    0.12259     0.11879
log_std/max                           -0.13077    0.00078    -0.12957    -0.13180
log_std/min                           -0.62519    0.00203    -0.62228    -0.62840
log_probs/mean                        -0.53785    0.04875    -0.45380    -0.59958
log_probs/std                         2.03705     0.04360    2.09078     1.96908
log_probs/max                         6.23833     0.28776    6.59353     5.71545
log_probs/min                         -8.19017    0.93887    -6.80984    -9.82533
mean/mean                             -0.03955    0.00126    -0.03816    -0.04157
mean/std                              0.88384     0.00324    0.88731     0.87803
mean/max                              1.61924     0.00667    1.62724     1.60781
mean/min                              -1.85190    0.00644    -1.84618    -1.86940
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 7, 1, 4, 9, 2, 8, 3, 5, 6]
replay_buffer._size: [19350 19350 19350 19350 19350 19350 19350 19350 19350 19350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.21437406539917 0.0020956993103027344
train_time 5.217782497406006
2023-09-06 13:38:54,430 MainThread INFO: EPOCH:127
2023-09-06 13:38:54,431 MainThread INFO: Time Consumed:5.2394750118255615s
2023-09-06 13:38:54,431 MainThread INFO: Total Frames:192000s
 32%|‚ñà‚ñà‚ñà‚ñè      | 128/400 [07:52<25:02,  5.52s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               426.53651
Train_Epoch_Reward                    5490.07824
Running_Training_Average_Rewards      581.05026
Explore_Time                          0.01241
Train___Time                          5.21778
Eval____Time                          0.00372
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.26598
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.67521
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.44436
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.92901
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.64627
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.44610
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.82142
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4820.63440
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.39566
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.90581
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.18739     0.89901    10.13859    6.57095
alpha_0                               0.72583     0.00015    0.72607     0.72559
alpha_1                               0.68970     0.00049    0.69047     0.68892
alpha_2                               0.69300     0.00045    0.69370     0.69229
alpha_3                               0.69243     0.00047    0.69317     0.69168
alpha_4                               0.69157     0.00046    0.69229     0.69085
alpha_5                               0.69433     0.00043    0.69500     0.69366
alpha_6                               0.68636     0.00054    0.68720     0.68551
alpha_7                               0.70090     0.00040    0.70152     0.70027
alpha_8                               0.69339     0.00045    0.69410     0.69268
alpha_9                               0.68967     0.00049    0.69044     0.68890
Alpha_loss                            -1.65224    0.01909    -1.62141    -1.69233
Training/policy_loss                  -26.58254   0.10141    -26.38774   -26.73081
Training/qf1_loss                     1587.68662  373.97116  2288.82495  1082.01257
Training/qf2_loss                     1588.68357  375.88948  2295.10498  1079.56812
Training/pf_norm                      0.31336     0.05459    0.41928     0.24252
Training/qf1_norm                     534.95746   108.17944  765.01721   336.13937
Training/qf2_norm                     533.05125   105.10387  753.45850   337.37314
log_std/mean                          -0.30380    0.00049    -0.30322    -0.30468
log_std/std                           0.12234     0.00071    0.12336     0.12140
log_std/max                           -0.12841    0.00117    -0.12702    -0.13087
log_std/min                           -0.61870    0.00359    -0.61374    -0.62602
log_probs/mean                        -0.50576    0.04937    -0.43050    -0.62023
log_probs/std                         2.01904     0.03885    2.07535     1.93158
log_probs/max                         6.33932     0.16037    6.64331     6.10302
log_probs/min                         -7.50062    0.67738    -6.60464    -8.88772
mean/mean                             -0.03670    0.00069    -0.03600    -0.03810
mean/std                              0.88396     0.00162    0.88720     0.88223
mean/max                              1.62811     0.00447    1.63441     1.62144
mean/min                              -1.84810    0.00551    -1.83764    -1.85841
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 4, 0, 9, 3, 6, 7, 2, 8, 5]
replay_buffer._size: [19500 19500 19500 19500 19500 19500 19500 19500 19500 19500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.499286651611328 0.0020933151245117188
train_time 5.502678871154785
2023-09-06 13:39:00,098 MainThread INFO: EPOCH:128
2023-09-06 13:39:00,099 MainThread INFO: Time Consumed:5.533649444580078s
2023-09-06 13:39:00,099 MainThread INFO: Total Frames:193500s
 32%|‚ñà‚ñà‚ñà‚ñè      | 129/400 [07:58<25:09,  5.57s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               425.95633
Train_Epoch_Reward                    5326.82903
Running_Training_Average_Rewards      538.20705
Explore_Time                          0.02096
Train___Time                          5.50268
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.43179
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.77987
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.43596
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.98283
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.71852
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.53783
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.96879
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4811.10350
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.33140
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.23066
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.34532     0.82893    10.21508    7.03981
alpha_0                               0.72530     0.00015    0.72554     0.72507
alpha_1                               0.68797     0.00050    0.68875     0.68719
alpha_2                               0.69143     0.00045    0.69214     0.69072
alpha_3                               0.69078     0.00047    0.69152     0.69005
alpha_4                               0.68998     0.00046    0.69069     0.68925
alpha_5                               0.69285     0.00042    0.69351     0.69218
alpha_6                               0.68449     0.00054    0.68533     0.68365
alpha_7                               0.69950     0.00040    0.70013     0.69887
alpha_8                               0.69181     0.00045    0.69252     0.69110
alpha_9                               0.68797     0.00049    0.68873     0.68720
Alpha_loss                            -1.66128    0.01858    -1.62842    -1.69576
Training/policy_loss                  -26.95452   0.11277    -26.77370   -27.12932
Training/qf1_loss                     1687.03260  462.48801  2904.06689  1076.37036
Training/qf2_loss                     1689.39506  463.13344  2909.85815  1078.87341
Training/pf_norm                      0.36530     0.07564    0.53734     0.26702
Training/qf1_norm                     553.66042   93.48916   750.41919   383.66550
Training/qf2_norm                     552.27150   91.55207   744.49854   386.74667
log_std/mean                          -0.30775    0.00248    -0.30494    -0.31160
log_std/std                           0.12134     0.00097    0.12305     0.12025
log_std/max                           -0.13031    0.00057    -0.12951    -0.13121
log_std/min                           -0.61523    0.00241    -0.61150    -0.61953
log_probs/mean                        -0.50192    0.05136    -0.42261    -0.59963
log_probs/std                         2.02779     0.04535    2.08738     1.96531
log_probs/max                         6.38406     0.20051    6.66939     6.05702
log_probs/min                         -7.43100    0.60933    -6.29188    -8.72881
mean/mean                             -0.03442    0.00098    -0.03254    -0.03580
mean/std                              0.88666     0.00290    0.89178     0.88319
mean/max                              1.63894     0.00736    1.64950     1.62831
mean/min                              -1.85971    0.00645    -1.85104    -1.87060
------------------------------------  ----------  ---------  ----------  ----------
sample: [1, 7, 4, 3, 6, 8, 0, 2, 9, 5]
replay_buffer._size: [19659 19658 19657 19659 19658 19655 19657 19658 19655 19657]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.398021459579468 0.002176523208618164
train_time 5.401549816131592
2023-09-06 13:39:05,806 MainThread INFO: EPOCH:129
2023-09-06 13:39:05,806 MainThread INFO: Time Consumed:5.551066160202026s
2023-09-06 13:39:05,807 MainThread INFO: Total Frames:195000s
 32%|‚ñà‚ñà‚ñà‚ñé      | 130/400 [08:04<25:15,  5.61s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               426.09724
Train_Epoch_Reward                    5465.76353
Running_Training_Average_Rewards      542.75569
Explore_Time                          0.13871
Train___Time                          5.40155
Eval____Time                          0.00535
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.57595
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.78581
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.28593
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.94867
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.57735
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.47980
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.99384
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4827.03105
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.27060
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.98622
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.99781     1.14561    10.32708    6.80538
alpha_0                               0.72478     0.00015    0.72501     0.72455
alpha_1                               0.68625     0.00049    0.68702     0.68548
alpha_2                               0.68986     0.00045    0.69057     0.68915
alpha_3                               0.68915     0.00047    0.68988     0.68842
alpha_4                               0.68838     0.00045    0.68909     0.68767
alpha_5                               0.69138     0.00042    0.69203     0.69073
alpha_6                               0.68262     0.00054    0.68346     0.68178
alpha_7                               0.69810     0.00040    0.69873     0.69747
alpha_8                               0.69024     0.00045    0.69094     0.68954
alpha_9                               0.68627     0.00049    0.68703     0.68550
Alpha_loss                            -1.65106    0.01610    -1.63402    -1.68238
Training/policy_loss                  -27.32177   0.11762    -27.14512   -27.53488
Training/qf1_loss                     1510.44020  449.77665  2327.48706  904.47540
Training/qf2_loss                     1510.13934  451.11962  2329.49219  901.49280
Training/pf_norm                      0.32216     0.03795    0.37761     0.26502
Training/qf1_norm                     513.94508   145.24705  803.51581   358.72287
Training/qf2_norm                     513.89976   140.88244  793.21844   361.65823
log_std/mean                          -0.31273    0.00083    -0.31075    -0.31361
log_std/std                           0.12522     0.00086    0.12634     0.12356
log_std/max                           -0.12923    0.00187    -0.12404    -0.13058
log_std/min                           -0.62862    0.00414    -0.62275    -0.63540
log_probs/mean                        -0.44487    0.04834    -0.39047    -0.53585
log_probs/std                         2.04453     0.02202    2.08485     1.99739
log_probs/max                         6.53551     0.16219    6.83763     6.22179
log_probs/min                         -8.00245    1.21402    -6.93309    -10.73132
mean/mean                             -0.02998    0.00096    -0.02837    -0.03167
mean/std                              0.89643     0.00148    0.89827     0.89339
mean/max                              1.64655     0.00635    1.65442     1.63640
mean/min                              -1.88261    0.00602    -1.87572    -1.89330
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 8, 4, 1, 6, 2, 7, 5, 0, 3]
replay_buffer._size: [19800 19800 19800 19800 19800 19800 19800 19800 19800 19800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.434755802154541 0.002580404281616211
train_time 5.438700199127197
2023-09-06 13:39:11,438 MainThread INFO: EPOCH:130
2023-09-06 13:39:11,439 MainThread INFO: Time Consumed:5.456115007400513s
2023-09-06 13:39:11,439 MainThread INFO: Total Frames:196500s
 33%|‚ñà‚ñà‚ñà‚ñé      | 131/400 [08:09<25:10,  5.61s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               426.87181
Train_Epoch_Reward                    6623.51372
Running_Training_Average_Rewards      580.53688
Explore_Time                          0.00821
Train___Time                          5.43870
Eval____Time                          0.00380
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.10567
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.82933
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.42477
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.02745
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.65209
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.49034
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.26972
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4845.17738
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.27693
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.75959
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.32211     1.20146    9.98438     6.55320
alpha_0                               0.72428     0.00014    0.72450     0.72406
alpha_1                               0.68454     0.00049    0.68531     0.68377
alpha_2                               0.68829     0.00045    0.68900     0.68759
alpha_3                               0.68753     0.00047    0.68826     0.68680
alpha_4                               0.68681     0.00046    0.68752     0.68609
alpha_5                               0.68993     0.00042    0.69058     0.68927
alpha_6                               0.68076     0.00054    0.68160     0.67992
alpha_7                               0.69670     0.00040    0.69733     0.69607
alpha_8                               0.68868     0.00045    0.68938     0.68798
alpha_9                               0.68456     0.00049    0.68533     0.68380
Alpha_loss                            -1.67560    0.02132    -1.65593    -1.72943
Training/policy_loss                  -27.61847   0.10448    -27.45267   -27.76658
Training/qf1_loss                     1512.96640  542.50276  2523.68872  884.39893
Training/qf2_loss                     1513.11635  544.33448  2526.58203  883.35156
Training/pf_norm                      0.32109     0.06388    0.42432     0.24361
Training/qf1_norm                     566.03389   155.33536  787.59485   348.76233
Training/qf2_norm                     563.97934   151.25903  777.52411   350.10825
log_std/mean                          -0.30794    0.00073    -0.30707    -0.30950
log_std/std                           0.12678     0.00022    0.12721     0.12640
log_std/max                           -0.11614    0.00318    -0.11251    -0.12236
log_std/min                           -0.63723    0.00195    -0.63256    -0.63926
log_probs/mean                        -0.48314    0.06208    -0.41869    -0.63764
log_probs/std                         2.05999     0.02236    2.10015     2.02909
log_probs/max                         6.51938     0.12993    6.69049     6.25761
log_probs/min                         -8.11587    1.12501    -6.39293    -10.22434
mean/mean                             -0.02712    0.00095    -0.02530    -0.02826
mean/std                              0.89359     0.00124    0.89557     0.89135
mean/max                              1.62177     0.00380    1.62991     1.61625
mean/min                              -1.88969    0.00479    -1.87803    -1.89546
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 1, 7, 8, 5, 0, 2, 4, 3, 6]
replay_buffer._size: [19950 19950 19950 19950 19950 19950 19950 19950 19950 19950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.312745809555054 0.002100229263305664
train_time 5.316154718399048
2023-09-06 13:39:16,993 MainThread INFO: EPOCH:131
2023-09-06 13:39:16,994 MainThread INFO: Time Consumed:5.343647718429565s
2023-09-06 13:39:16,994 MainThread INFO: Total Frames:198000s
 33%|‚ñà‚ñà‚ñà‚ñé      | 132/400 [08:15<24:59,  5.60s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               428.97309
Train_Epoch_Reward                    6571.58576
Running_Training_Average_Rewards      622.02877
Explore_Time                          0.01053
Train___Time                          5.31615
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.34558
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.88296
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.47031
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.07068
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.67580
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.34814
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.57417
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4877.65734
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.95808
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.60725
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.17117     0.89943    9.82800     7.03725
alpha_0                               0.72379     0.00014    0.72401     0.72357
alpha_1                               0.68282     0.00049    0.68360     0.68205
alpha_2                               0.68674     0.00045    0.68744     0.68604
alpha_3                               0.68590     0.00047    0.68663     0.68516
alpha_4                               0.68523     0.00045    0.68593     0.68453
alpha_5                               0.68846     0.00042    0.68913     0.68780
alpha_6                               0.67890     0.00053    0.67973     0.67806
alpha_7                               0.69531     0.00039    0.69593     0.69470
alpha_8                               0.68714     0.00044    0.68783     0.68646
alpha_9                               0.68285     0.00049    0.68362     0.68208
Alpha_loss                            -1.66352    0.02163    -1.62494    -1.69922
Training/policy_loss                  -28.02582   0.12017    -27.84529   -28.25105
Training/qf1_loss                     1620.27746  608.95085  2546.08203  868.17279
Training/qf2_loss                     1618.93543  609.53262  2545.93555  865.35199
Training/pf_norm                      0.36263     0.04573    0.44094     0.27844
Training/qf1_norm                     544.14901   107.58768  739.70642   408.51151
Training/qf2_norm                     542.95800   105.49713  735.70526   409.57864
log_std/mean                          -0.31108    0.00188    -0.30758    -0.31328
log_std/std                           0.12687     0.00029    0.12745     0.12649
log_std/max                           -0.11827    0.00211    -0.11411    -0.12133
log_std/min                           -0.63215    0.00163    -0.62921    -0.63429
log_probs/mean                        -0.42237    0.06359    -0.31019    -0.53554
log_probs/std                         2.06079     0.03287    2.11449     1.99691
log_probs/max                         6.57232     0.17560    6.87464     6.28063
log_probs/min                         -7.58549    1.03971    -6.58291    -9.22787
mean/mean                             -0.02311    0.00075    -0.02236    -0.02459
mean/std                              0.90235     0.00321    0.90592     0.89646
mean/max                              1.64146     0.01098    1.65781     1.61996
mean/min                              -1.90032    0.00780    -1.88533    -1.91199
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 4, 6, 7, 3, 0, 2, 5, 1, 9]
replay_buffer._size: [20100 20100 20100 20100 20100 20100 20100 20100 20100 20100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.0603270530700684 0.0021457672119140625
train_time 3.0637850761413574
2023-09-06 13:39:22,450 MainThread INFO: EPOCH:132
2023-09-06 13:39:22,451 MainThread INFO: Time Consumed:3.3628547191619873s
2023-09-06 13:39:22,451 MainThread INFO: Total Frames:199500s
 33%|‚ñà‚ñà‚ñà‚ñé      | 133/400 [08:20<24:49,  5.58s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               429.80917
Train_Epoch_Reward                    4016.37750
Running_Training_Average_Rewards      573.71590
Explore_Time                          0.28828
Train___Time                          3.06379
Eval____Time                          0.00602
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.82491
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.89382
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.44155
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.06000
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.66814
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.38828
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.60056
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4870.64952
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.95587
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.60704
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.90837     0.93898    9.73835     6.61659
alpha_0                               0.72332     0.00013    0.72353     0.72311
alpha_1                               0.68112     0.00049    0.68188     0.68035
alpha_2                               0.68520     0.00044    0.68589     0.68452
alpha_3                               0.68427     0.00046    0.68500     0.68354
alpha_4                               0.68368     0.00045    0.68438     0.68298
alpha_5                               0.68701     0.00041    0.68766     0.68636
alpha_6                               0.67703     0.00054    0.67787     0.67620
alpha_7                               0.69393     0.00040    0.69456     0.69330
alpha_8                               0.68563     0.00043    0.68631     0.68495
alpha_9                               0.68113     0.00049    0.68191     0.68036
Alpha_loss                            -1.67125    0.01062    -1.65569    -1.69320
Training/policy_loss                  -28.36058   0.09916    -28.22045   -28.59527
Training/qf1_loss                     1460.74318  323.22590  2090.39404  928.94806
Training/qf2_loss                     1460.86780  325.03660  2093.63843  927.55090
Training/pf_norm                      0.34778     0.04094    0.41003     0.27172
Training/qf1_norm                     506.74226   117.56103  736.37433   344.84821
Training/qf2_norm                     505.41545   113.97055  729.33978   349.52808
log_std/mean                          -0.31028    0.00069    -0.30945    -0.31177
log_std/std                           0.12586     0.00112    0.12753     0.12396
log_std/max                           -0.11719    0.00101    -0.11557    -0.11891
log_std/min                           -0.62667    0.00343    -0.62037    -0.63137
log_probs/mean                        -0.41512    0.03420    -0.36138    -0.48697
log_probs/std                         2.06545     0.03205    2.13320     2.00110
log_probs/max                         6.50285     0.16812    6.71301     6.19173
log_probs/min                         -7.64763    0.97883    -6.57443    -9.96247
mean/mean                             -0.02117    0.00116    -0.01887    -0.02265
mean/std                              0.90326     0.00057    0.90402     0.90232
mean/max                              1.64305     0.00495    1.64999     1.63595
mean/min                              -1.90675    0.00375    -1.89985    -1.91538
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 9, 6, 3, 2, 7, 0, 8, 4, 5]
replay_buffer._size: [20250 20250 20250 20250 20250 20250 20250 20250 20250 20250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.393639802932739 0.00211334228515625
train_time 5.397063255310059
2023-09-06 13:39:28,410 MainThread INFO: EPOCH:133
2023-09-06 13:39:28,410 MainThread INFO: Time Consumed:5.414595127105713s
2023-09-06 13:39:28,411 MainThread INFO: Total Frames:201000s
 34%|‚ñà‚ñà‚ñà‚ñé      | 134/400 [08:26<25:08,  5.67s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               430.88415
Train_Epoch_Reward                    4228.96882
Running_Training_Average_Rewards      493.89774
Explore_Time                          0.00905
Train___Time                          5.39706
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.50666
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.98556
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.47830
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.12718
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.63794
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.41818
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -66.82857
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4877.84715
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.82686
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.44698
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.27934     0.93780    8.34293     4.97171
alpha_0                               0.72285     0.00014    0.72306     0.72264
alpha_1                               0.67940     0.00049    0.68017     0.67863
alpha_2                               0.68368     0.00044    0.68437     0.68299
alpha_3                               0.68266     0.00046    0.68338     0.68194
alpha_4                               0.68211     0.00045    0.68282     0.68140
alpha_5                               0.68557     0.00041    0.68621     0.68492
alpha_6                               0.67517     0.00054    0.67601     0.67433
alpha_7                               0.69253     0.00041    0.69316     0.69190
alpha_8                               0.68413     0.00043    0.68480     0.68346
alpha_9                               0.67941     0.00049    0.68019     0.67864
Alpha_loss                            -1.69110    0.01399    -1.67012    -1.71058
Training/policy_loss                  -28.62891   0.09211    -28.48885   -28.74777
Training/qf1_loss                     1209.91480  330.59082  1766.94531  611.38110
Training/qf2_loss                     1209.81544  331.21418  1765.09924  608.47394
Training/pf_norm                      0.38637     0.08813    0.57444     0.26611
Training/qf1_norm                     438.33661   126.02484  582.87921   132.03871
Training/qf2_norm                     438.59939   123.54753  579.89508   139.85078
log_std/mean                          -0.31053    0.00120    -0.30903    -0.31221
log_std/std                           0.12462     0.00102    0.12654     0.12339
log_std/max                           -0.12036    0.00109    -0.11909    -0.12213
log_std/min                           -0.62042    0.00287    -0.61609    -0.62488
log_probs/mean                        -0.44179    0.04416    -0.37757    -0.50699
log_probs/std                         2.06215     0.03616    2.11409     2.00443
log_probs/max                         6.49300     0.25360    6.78228     6.08302
log_probs/min                         -7.93140    1.02264    -6.52712    -9.69226
mean/mean                             -0.01503    0.00204    -0.01275    -0.01798
mean/std                              0.90461     0.00206    0.90721     0.90212
mean/max                              1.65066     0.00749    1.66053     1.63782
mean/min                              -1.91558    0.00602    -1.90440    -1.92344
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 7, 1, 5, 2, 6, 9, 8, 4, 0]
replay_buffer._size: [20405 20407 20407 20409 20409 20408 20408 20408 20407 20407]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.564738512039185 0.0021686553955078125
train_time 5.568244457244873
2023-09-06 13:39:34,290 MainThread INFO: EPOCH:134
2023-09-06 13:39:34,290 MainThread INFO: Time Consumed:5.720525741577148s
2023-09-06 13:39:34,291 MainThread INFO: Total Frames:202500s
 34%|‚ñà‚ñà‚ñà‚ñç      | 135/400 [08:32<25:19,  5.73s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               432.33157
Train_Epoch_Reward                    5333.72601
Running_Training_Average_Rewards      452.63574
Explore_Time                          0.14303
Train___Time                          5.56824
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.04332
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.03266
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.55000
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.23829
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.56084
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.12998
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.32304
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4914.87728
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.69827
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.15401
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.01449     0.78337    9.65306     6.67375
alpha_0                               0.72237     0.00014    0.72259     0.72215
alpha_1                               0.67769     0.00049    0.67846     0.67691
alpha_2                               0.68215     0.00044    0.68284     0.68146
alpha_3                               0.68105     0.00047    0.68177     0.68031
alpha_4                               0.68054     0.00045    0.68125     0.67983
alpha_5                               0.68413     0.00041    0.68477     0.68348
alpha_6                               0.67331     0.00053    0.67415     0.67247
alpha_7                               0.69113     0.00040    0.69176     0.69050
alpha_8                               0.68263     0.00043    0.68331     0.68196
alpha_9                               0.67771     0.00049    0.67847     0.67694
Alpha_loss                            -1.70907    0.02849    -1.66474    -1.74641
Training/policy_loss                  -28.82701   0.09665    -28.67095   -29.00037
Training/qf1_loss                     1535.27484  391.71941  2528.07788  1116.87683
Training/qf2_loss                     1535.85637  392.63941  2532.48315  1117.19666
Training/pf_norm                      0.37634     0.06309    0.50157     0.29587
Training/qf1_norm                     544.22546   105.42649  757.86859   351.48413
Training/qf2_norm                     542.01627   104.00137  752.37250   351.76492
log_std/mean                          -0.30688    0.00270    -0.30385    -0.31152
log_std/std                           0.12758     0.00057    0.12883     0.12684
log_std/max                           -0.11584    0.00218    -0.11281    -0.11869
log_std/min                           -0.62954    0.00288    -0.62536    -0.63474
log_probs/mean                        -0.46215    0.06973    -0.35132    -0.56196
log_probs/std                         2.03938     0.02538    2.07895     1.99801
log_probs/max                         6.45008     0.21155    6.75079     6.17445
log_probs/min                         -7.39862    0.56019    -6.58336    -8.53834
mean/mean                             -0.01667    0.00241    -0.01357    -0.02118
mean/std                              0.89749     0.00545    0.90623     0.89097
mean/max                              1.65854     0.01436    1.68521     1.64041
mean/min                              -1.93311    0.00860    -1.92342    -1.95029
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 9, 0, 4, 1, 3, 8, 6, 7, 2]
replay_buffer._size: [20558 20558 20559 20558 20558 20556 20592 20560 20557 20557]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.011226415634155 0.002241373062133789
train_time 6.014814615249634
2023-09-06 13:39:40,635 MainThread INFO: EPOCH:135
2023-09-06 13:39:40,635 MainThread INFO: Time Consumed:6.149534225463867s
2023-09-06 13:39:40,636 MainThread INFO: Total Frames:204000s
 34%|‚ñà‚ñà‚ñà‚ñç      | 136/400 [08:39<26:01,  5.91s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               436.85680
Train_Epoch_Reward                    4634.05020
Running_Training_Average_Rewards      473.22483
Explore_Time                          0.12367
Train___Time                          6.01481
Eval____Time                          0.00557
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.28377
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.07937
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.48919
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.38325
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.53302
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.82807
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.97163
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4947.85936
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.39130
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           39.06651
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.07589     1.07979    9.58123     6.08753
alpha_0                               0.72187     0.00015    0.72210     0.72164
alpha_1                               0.67596     0.00050    0.67674     0.67518
alpha_2                               0.68060     0.00045    0.68130     0.67990
alpha_3                               0.67941     0.00047    0.68014     0.67867
alpha_4                               0.67898     0.00045    0.67968     0.67827
alpha_5                               0.68268     0.00042    0.68334     0.68202
alpha_6                               0.67145     0.00053    0.67229     0.67062
alpha_7                               0.68972     0.00041    0.69036     0.68908
alpha_8                               0.68113     0.00043    0.68181     0.68045
alpha_9                               0.67599     0.00049    0.67677     0.67522
Alpha_loss                            -1.73453    0.02502    -1.70307    -1.78748
Training/policy_loss                  -29.15364   0.10498    -28.98182   -29.28769
Training/qf1_loss                     1766.57807  621.38570  2585.33008  666.97772
Training/qf2_loss                     1765.23934  621.76432  2583.07446  665.91644
Training/pf_norm                      0.37296     0.04296    0.44351     0.30523
Training/qf1_norm                     556.01433   141.71206  749.11462   300.11511
Training/qf2_norm                     554.10597   139.47260  743.27899   300.67487
log_std/mean                          -0.30276    0.00116    -0.30027    -0.30380
log_std/std                           0.12962     0.00025    0.12986     0.12916
log_std/max                           -0.10932    0.00194    -0.10535    -0.11233
log_std/min                           -0.63254    0.00180    -0.62897    -0.63622
log_probs/mean                        -0.50233    0.05985    -0.41870    -0.62661
log_probs/std                         1.98881     0.02967    2.04422     1.93950
log_probs/max                         6.44491     0.14568    6.62294     6.24732
log_probs/min                         -7.40163    0.67801    -6.08994    -8.30811
mean/mean                             -0.02352    0.00088    -0.02221    -0.02480
mean/std                              0.88600     0.00362    0.89050     0.88014
mean/max                              1.63861     0.00839    1.66195     1.62942
mean/min                              -1.93575    0.00643    -1.92588    -1.95177
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 4, 0, 8, 1, 2, 3, 9, 7, 5]
replay_buffer._size: [20700 20700 20700 20700 20700 20700 20700 20700 20700 20700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.443754196166992 0.002111196517944336
train_time 3.4471778869628906
2023-09-06 13:39:46,668 MainThread INFO: EPOCH:136
2023-09-06 13:39:46,669 MainThread INFO: Time Consumed:3.5212302207946777s
2023-09-06 13:39:46,669 MainThread INFO: Total Frames:205500s
 34%|‚ñà‚ñà‚ñà‚ñç      | 137/400 [08:45<26:05,  5.95s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               445.20550
Train_Epoch_Reward                    4077.39180
Running_Training_Average_Rewards      468.17227
Explore_Time                          0.06399
Train___Time                          3.44718
Eval____Time                          0.00483
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -94.59649
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.10840
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.55159
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.53025
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.34005
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -105.21348
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.90433
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5028.30545
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.75665
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           94.74772
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.87717     0.74899    8.80213     6.19446
alpha_0                               0.72135     0.00015    0.72159     0.72111
alpha_1                               0.67422     0.00050    0.67501     0.67343
alpha_2                               0.67904     0.00045    0.67975     0.67834
alpha_3                               0.67776     0.00048    0.67850     0.67701
alpha_4                               0.67742     0.00044    0.67812     0.67673
alpha_5                               0.68120     0.00043    0.68187     0.68053
alpha_6                               0.66961     0.00053    0.67044     0.66878
alpha_7                               0.68829     0.00042    0.68894     0.68763
alpha_8                               0.67961     0.00044    0.68030     0.67891
alpha_9                               0.67427     0.00050    0.67505     0.67349
Alpha_loss                            -1.75689    0.01060    -1.73514    -1.77450
Training/policy_loss                  -29.43535   0.07613    -29.32821   -29.55700
Training/qf1_loss                     1459.54269  300.06442  2062.55664  930.52667
Training/qf2_loss                     1461.19285  301.11997  2069.44458  927.20331
Training/pf_norm                      0.35538     0.05288    0.46388     0.27930
Training/qf1_norm                     536.66466   106.06449  669.36206   292.71484
Training/qf2_norm                     533.62415   104.07440  661.07062   296.36002
log_std/mean                          -0.30056    0.00130    -0.29935    -0.30323
log_std/std                           0.12832     0.00071    0.12961     0.12729
log_std/max                           -0.10907    0.00250    -0.10614    -0.11337
log_std/min                           -0.61681    0.00611    -0.61023    -0.63147
log_probs/mean                        -0.53231    0.02872    -0.48663    -0.58041
log_probs/std                         2.01095     0.04501    2.12572     1.95800
log_probs/max                         6.35464     0.21198    6.67102     5.98863
log_probs/min                         -7.59339    0.73979    -6.44676    -9.04873
mean/mean                             -0.01623    0.00277    -0.01342    -0.02135
mean/std                              0.88285     0.00288    0.88806     0.88006
mean/max                              1.65875     0.01175    1.67798     1.64391
mean/min                              -1.93025    0.00959    -1.91836    -1.94410
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 7, 5, 0, 1, 3, 4, 2, 6, 8]
replay_buffer._size: [20850 20850 20850 20850 20850 20850 20850 20850 20850 20850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 5.863606929779053 0.0021681785583496094
train_time 5.867108345031738
2023-09-06 13:39:52,726 MainThread INFO: EPOCH:137
2023-09-06 13:39:52,727 MainThread INFO: Time Consumed:5.882188558578491s
2023-09-06 13:39:52,727 MainThread INFO: Total Frames:207000s
 34%|‚ñà‚ñà‚ñà‚ñç      | 138/400 [08:51<26:07,  5.98s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               453.88103
Train_Epoch_Reward                    5672.92794
Running_Training_Average_Rewards      479.47900
Explore_Time                          0.00666
Train___Time                          5.86711
Eval____Time                          0.00359
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.12001
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.02919
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.55361
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.54508
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.15890
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.87944
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.39794
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5069.60402
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.71382
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           113.20664
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.92550     0.73271    9.37554     6.67354
alpha_0                               0.72084     0.00014    0.72106     0.72063
alpha_1                               0.67247     0.00051    0.67326     0.67167
alpha_2                               0.67748     0.00045    0.67818     0.67677
alpha_3                               0.67609     0.00048    0.67685     0.67533
alpha_4                               0.67587     0.00045    0.67657     0.67518
alpha_5                               0.67971     0.00042    0.68038     0.67905
alpha_6                               0.66777     0.00053    0.66859     0.66694
alpha_7                               0.68683     0.00042    0.68749     0.68617
alpha_8                               0.67805     0.00045    0.67875     0.67735
alpha_9                               0.67253     0.00050    0.67331     0.67174
Alpha_loss                            -1.76058    0.01590    -1.73856    -1.78510
Training/policy_loss                  -29.75702   0.10054    -29.61855   -29.94240
Training/qf1_loss                     1544.35919  468.72054  2262.60938  774.86273
Training/qf2_loss                     1543.32143  468.83139  2261.57690  773.56769
Training/pf_norm                      0.35476     0.05413    0.47556     0.28384
Training/qf1_norm                     545.86634   99.48355   746.01184   383.34537
Training/qf2_norm                     544.47608   97.52081   738.99048   383.27115
log_std/mean                          -0.30626    0.00130    -0.30414    -0.30785
log_std/std                           0.12945     0.00049    0.13025     0.12869
log_std/max                           -0.11344    0.00263    -0.10829    -0.11684
log_std/min                           -0.62261    0.00349    -0.61422    -0.62639
log_probs/mean                        -0.51128    0.04435    -0.45032    -0.57912
log_probs/std                         2.04591     0.03558    2.11726     1.99267
log_probs/max                         6.48149     0.22259    6.81962     6.02662
log_probs/min                         -7.45372    0.79672    -6.45267    -8.61114
mean/mean                             -0.01470    0.00107    -0.01339    -0.01649
mean/std                              0.89034     0.00198    0.89348     0.88669
mean/max                              1.67508     0.01266    1.69442     1.64761
mean/min                              -1.95902    0.00901    -1.93865    -1.97086
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 2, 1, 3, 8, 0, 4, 9, 6, 5]
replay_buffer._size: [21000 21000 21000 21000 21000 21000 21000 21000 21000 21000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.065516233444214 0.0021097660064697266
train_time 6.068946123123169
2023-09-06 13:39:59,021 MainThread INFO: EPOCH:138
2023-09-06 13:39:59,022 MainThread INFO: Time Consumed:6.102368116378784s
2023-09-06 13:39:59,022 MainThread INFO: Total Frames:208500s
 35%|‚ñà‚ñà‚ñà‚ñç      | 139/400 [08:57<26:27,  6.08s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               461.58833
Train_Epoch_Reward                    5258.83929
Running_Training_Average_Rewards      500.30530
Explore_Time                          0.02559
Train___Time                          6.06895
Eval____Time                          0.00326
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.89241
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.00240
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.53699
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.58508
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.19591
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.81709
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.96540
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5075.87440
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.65288
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           149.95917
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.23757     0.80107    9.36908     6.76107
alpha_0                               0.72037     0.00014    0.72058     0.72015
alpha_1                               0.67070     0.00051    0.67150     0.66991
alpha_2                               0.67591     0.00045    0.67662     0.67519
alpha_3                               0.67441     0.00048    0.67517     0.67366
alpha_4                               0.67432     0.00045    0.67502     0.67362
alpha_5                               0.67824     0.00042    0.67890     0.67757
alpha_6                               0.66594     0.00052    0.66676     0.66512
alpha_7                               0.68537     0.00042    0.68603     0.68471
alpha_8                               0.67649     0.00045    0.67719     0.67578
alpha_9                               0.67078     0.00050    0.67156     0.66999
Alpha_loss                            -1.78462    0.02310    -1.75180    -1.82740
Training/policy_loss                  -30.09345   0.09872    -29.88995   -30.20942
Training/qf1_loss                     1694.54178  290.22448  2155.10352  1064.73291
Training/qf2_loss                     1694.99855  292.03035  2159.66284  1058.80603
Training/pf_norm                      0.33204     0.02918    0.37622     0.29203
Training/qf1_norm                     593.13372   106.52071  750.74402   378.94717
Training/qf2_norm                     591.07830   104.64809  748.01251   381.79892
log_std/mean                          -0.29807    0.00208    -0.29608    -0.30224
log_std/std                           0.12912     0.00033    0.12971     0.12866
log_std/max                           -0.09896    0.00288    -0.09627    -0.10556
log_std/min                           -0.61915    0.00189    -0.61520    -0.62167
log_probs/mean                        -0.54748    0.05498    -0.47024    -0.65089
log_probs/std                         2.01783     0.03791    2.07250     1.95184
log_probs/max                         6.31974     0.27433    6.68437     5.69217
log_probs/min                         -6.97604    0.67587    -6.02528    -8.58322
mean/mean                             -0.01855    0.00174    -0.01634    -0.02139
mean/std                              0.87783     0.00387    0.88411     0.87303
mean/max                              1.63041     0.00798    1.64488     1.61218
mean/min                              -1.94444    0.00619    -1.92891    -1.95565
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 4, 5, 1, 0, 7, 6, 8, 9, 2]
replay_buffer._size: [21150 21150 21150 21150 21150 21150 21150 21150 21150 21150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.004343748092651 0.002110719680786133
train_time 6.007753372192383
2023-09-06 13:40:05,219 MainThread INFO: EPOCH:139
2023-09-06 13:40:05,220 MainThread INFO: Time Consumed:6.020806550979614s
2023-09-06 13:40:05,220 MainThread INFO: Total Frames:210000s
 35%|‚ñà‚ñà‚ñà‚ñå      | 140/400 [09:03<26:28,  6.11s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               468.83640
Train_Epoch_Reward                    5448.11006
Running_Training_Average_Rewards      545.99591
Explore_Time                          0.00534
Train___Time                          6.00775
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -101.60665
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.01592
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.49787
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.69025
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.09662
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.38239
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.66177
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5141.90082
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.46343
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           206.00792
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.67660     0.60513    8.86843     6.39908
alpha_0                               0.71987     0.00015    0.72010     0.71963
alpha_1                               0.66894     0.00051    0.66974     0.66815
alpha_2                               0.67432     0.00046    0.67504     0.67361
alpha_3                               0.67273     0.00049    0.67349     0.67196
alpha_4                               0.67276     0.00045    0.67347     0.67206
alpha_5                               0.67676     0.00042    0.67743     0.67610
alpha_6                               0.66411     0.00053    0.66494     0.66329
alpha_7                               0.68388     0.00043    0.68456     0.68321
alpha_8                               0.67491     0.00046    0.67563     0.67420
alpha_9                               0.66904     0.00050    0.66982     0.66825
Alpha_loss                            -1.79894    0.02399    -1.75784    -1.83508
Training/policy_loss                  -30.42098   0.09720    -30.25159   -30.58204
Training/qf1_loss                     1510.49837  310.43093  2115.84155  945.27911
Training/qf2_loss                     1512.04693  309.97934  2113.97021  945.94806
Training/pf_norm                      0.35189     0.06937    0.48005     0.22872
Training/qf1_norm                     524.32575   81.89760   669.76685   341.30386
Training/qf2_norm                     522.13152   79.70760   667.69501   346.41248
log_std/mean                          -0.30118    0.00348    -0.29645    -0.30653
log_std/std                           0.13254     0.00279    0.13747     0.12898
log_std/max                           -0.09848    0.00103    -0.09671    -0.10017
log_std/min                           -0.63202    0.01081    -0.61706    -0.64877
log_probs/mean                        -0.55753    0.06712    -0.44008    -0.65247
log_probs/std                         2.02565     0.03351    2.09104     1.96358
log_probs/max                         6.45826     0.20964    6.86874     6.19014
log_probs/min                         -7.39094    0.70972    -6.40997    -8.32250
mean/mean                             -0.02387    0.00174    -0.02159    -0.02716
mean/std                              0.88234     0.00603    0.89036     0.87354
mean/max                              1.65616     0.01677    1.67927     1.62582
mean/min                              -1.96214    0.01536    -1.93697    -1.98579
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 3, 2, 4, 6, 7, 8, 0, 9, 5]
replay_buffer._size: [21300 21300 21300 21300 21300 21300 21300 21300 21300 21300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.065460681915283 0.0021948814392089844
train_time 6.068983554840088
2023-09-06 13:40:11,489 MainThread INFO: EPOCH:140
2023-09-06 13:40:11,489 MainThread INFO: Time Consumed:6.08906102180481s
2023-09-06 13:40:11,490 MainThread INFO: Total Frames:211500s
 35%|‚ñà‚ñà‚ñà‚ñå      | 141/400 [09:10<26:42,  6.19s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               472.34470
Train_Epoch_Reward                    5354.04140
Running_Training_Average_Rewards      535.36636
Explore_Time                          0.01107
Train___Time                          6.06898
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.29583
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.93819
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.50929
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.69903
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.94650
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.29902
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.59601
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5151.51384
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.59985
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           151.03161
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.17888     1.24543    10.46119    5.99070
alpha_0                               0.71934     0.00015    0.71957     0.71911
alpha_1                               0.66718     0.00051    0.66797     0.66639
alpha_2                               0.67275     0.00045    0.67345     0.67205
alpha_3                               0.67104     0.00048    0.67179     0.67028
alpha_4                               0.67121     0.00044    0.67190     0.67051
alpha_5                               0.67530     0.00042    0.67595     0.67465
alpha_6                               0.66229     0.00052    0.66310     0.66147
alpha_7                               0.68239     0.00043    0.68306     0.68172
alpha_8                               0.67332     0.00046    0.67404     0.67261
alpha_9                               0.66730     0.00050    0.66808     0.66652
Alpha_loss                            -1.79495    0.01940    -1.76709    -1.82660
Training/policy_loss                  -30.75788   0.09446    -30.60887   -30.90477
Training/qf1_loss                     1745.49308  563.77438  2674.53271  671.21429
Training/qf2_loss                     1746.40928  566.28508  2681.43359  667.89301
Training/pf_norm                      0.34319     0.05855    0.44284     0.24921
Training/qf1_norm                     595.29567   174.76959  916.05951   296.75177
Training/qf2_norm                     592.99454   168.88110  900.96722   303.40848
log_std/mean                          -0.30669    0.00161    -0.30321    -0.30820
log_std/std                           0.13970     0.00064    0.14053     0.13859
log_std/max                           -0.09693    0.00148    -0.09395    -0.09876
log_std/min                           -0.66644    0.00578    -0.65644    -0.67799
log_probs/mean                        -0.51824    0.04532    -0.45114    -0.58955
log_probs/std                         2.00743     0.02743    2.05391     1.96534
log_probs/max                         6.47372     0.17840    6.69155     6.14746
log_probs/min                         -7.38420    0.98735    -6.33717    -9.71536
mean/mean                             -0.02807    0.00017    -0.02777    -0.02839
mean/std                              0.88108     0.00697    0.89015     0.86885
mean/max                              1.66614     0.01435    1.69220     1.63912
mean/min                              -1.98220    0.01351    -1.95712    -2.00962
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 8, 9, 2, 0, 4, 5, 1, 7, 6]
replay_buffer._size: [21450 21450 21450 21450 21450 21450 21450 21450 21450 21450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.5442705154418945 0.0023241043090820312
train_time 3.5479838848114014
2023-09-06 13:40:17,522 MainThread INFO: EPOCH:141
2023-09-06 13:40:17,523 MainThread INFO: Time Consumed:3.6392648220062256s
2023-09-06 13:40:17,523 MainThread INFO: Total Frames:213000s
 36%|‚ñà‚ñà‚ñà‚ñå      | 142/400 [09:15<26:17,  6.12s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               472.66892
Train_Epoch_Reward                    5560.74181
Running_Training_Average_Rewards      545.42978
Explore_Time                          0.08274
Train___Time                          3.54798
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.40232
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.07658
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.51162
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.83663
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.08799
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -104.61430
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.81066
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5080.51356
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.63709
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           169.37558
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.41064     0.70884    8.24780     6.14131
alpha_0                               0.71882     0.00015    0.71906     0.71858
alpha_1                               0.66542     0.00051    0.66621     0.66462
alpha_2                               0.67118     0.00046    0.67189     0.67047
alpha_3                               0.66935     0.00048    0.67011     0.66860
alpha_4                               0.66965     0.00045    0.67036     0.66894
alpha_5                               0.67383     0.00043    0.67450     0.67316
alpha_6                               0.66047     0.00052    0.66129     0.65965
alpha_7                               0.68089     0.00043    0.68157     0.68021
alpha_8                               0.67171     0.00047    0.67244     0.67098
alpha_9                               0.66556     0.00050    0.66634     0.66477
Alpha_loss                            -1.84496    0.01721    -1.81507    -1.87426
Training/policy_loss                  -31.09261   0.11222    -30.85822   -31.24647
Training/qf1_loss                     1260.18010  267.15725  1617.26306  724.26947
Training/qf2_loss                     1258.53781  266.35432  1612.02234  720.45056
Training/pf_norm                      0.36881     0.07461    0.50179     0.26051
Training/qf1_norm                     485.93438   105.33629  627.00757   308.74185
Training/qf2_norm                     486.35955   103.55173  622.76398   314.52875
log_std/mean                          -0.30099    0.00074    -0.30015    -0.30262
log_std/std                           0.13645     0.00084    0.13808     0.13545
log_std/max                           -0.09538    0.00127    -0.09332    -0.09801
log_std/min                           -0.65511    0.00631    -0.64890    -0.66812
log_probs/mean                        -0.61711    0.04966    -0.52117    -0.70451
log_probs/std                         1.99795     0.04125    2.06577     1.93400
log_probs/max                         6.28438     0.21466    6.59588     5.90678
log_probs/min                         -7.51586    0.71710    -6.56182    -8.65239
mean/mean                             -0.02660    0.00064    -0.02558    -0.02748
mean/std                              0.86556     0.00174    0.86871     0.86287
mean/max                              1.65423     0.01117    1.66697     1.63518
mean/min                              -1.96429    0.01047    -1.94959    -1.98322
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 2, 5, 8, 7, 4, 6, 3, 0, 1]
replay_buffer._size: [21600 21600 21600 21610 21600 21600 21600 21600 21600 21600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.140512704849243 0.0021038055419921875
train_time 6.1439220905303955
2023-09-06 13:40:24,015 MainThread INFO: EPOCH:142
2023-09-06 13:40:24,015 MainThread INFO: Time Consumed:6.292776346206665s
2023-09-06 13:40:24,016 MainThread INFO: Total Frames:214500s
 36%|‚ñà‚ñà‚ñà‚ñå      | 143/400 [09:22<26:42,  6.24s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               469.70136
Train_Epoch_Reward                    5609.59342
Running_Training_Average_Rewards      550.81255
Explore_Time                          0.13176
Train___Time                          6.14392
Eval____Time                          0.00597
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -107.34912
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -85.97878
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.54285
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.86320
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.82366
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.98628
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.28437
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5117.81506
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.51812
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           150.99858
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.68056     1.04226    9.54846     5.92973
alpha_0                               0.71830     0.00015    0.71853     0.71807
alpha_1                               0.66365     0.00051    0.66445     0.66285
alpha_2                               0.66959     0.00046    0.67031     0.66887
alpha_3                               0.66767     0.00048    0.66843     0.66691
alpha_4                               0.66807     0.00046    0.66879     0.66736
alpha_5                               0.67234     0.00043    0.67301     0.67166
alpha_6                               0.65867     0.00051    0.65947     0.65787
alpha_7                               0.67937     0.00044    0.68006     0.67869
alpha_8                               0.67007     0.00048    0.67081     0.66932
alpha_9                               0.66381     0.00050    0.66460     0.66302
Alpha_loss                            -1.84899    0.01411    -1.83339    -1.88324
Training/policy_loss                  -31.33414   0.09945    -31.14018   -31.48536
Training/qf1_loss                     1393.56281  390.22621  2256.71875  778.05902
Training/qf2_loss                     1392.20142  390.12679  2253.46484  774.97235
Training/pf_norm                      0.36267     0.07273    0.51847     0.22277
Training/qf1_norm                     541.07098   150.68622  814.36957   290.79129
Training/qf2_norm                     540.38165   147.94605  809.58215   297.99316
log_std/mean                          -0.30273    0.00074    -0.30119    -0.30360
log_std/std                           0.13594     0.00071    0.13676     0.13436
log_std/max                           -0.09744    0.00186    -0.09487    -0.10095
log_std/min                           -0.65433    0.00187    -0.65148    -0.65815
log_probs/mean                        -0.59859    0.03761    -0.54956    -0.67806
log_probs/std                         2.02727     0.06587    2.10036     1.87260
log_probs/max                         6.28932     0.15238    6.52705     6.08201
log_probs/min                         -8.26123    0.87473    -7.44005    -10.07057
mean/mean                             -0.03268    0.00329    -0.02800    -0.03838
mean/std                              0.87400     0.00260    0.87626     0.86892
mean/max                              1.66954     0.00539    1.67869     1.65918
mean/min                              -1.99536    0.01251    -1.97568    -2.01356
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 5, 6, 4, 1, 7, 2, 8, 3]
replay_buffer._size: [21750 21750 21750 21750 21750 21750 21750 21750 21750 21750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.36597204208374 0.0021173954010009766
train_time 6.369401693344116
2023-09-06 13:40:30,570 MainThread INFO: EPOCH:143
2023-09-06 13:40:30,571 MainThread INFO: Time Consumed:6.395408630371094s
2023-09-06 13:40:30,571 MainThread INFO: Total Frames:216000s
 36%|‚ñà‚ñà‚ñà‚ñå      | 144/400 [09:29<26:58,  6.32s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               469.86065
Train_Epoch_Reward                    5077.25508
Running_Training_Average_Rewards      541.58634
Explore_Time                          0.01747
Train___Time                          6.36940
Eval____Time                          0.00321
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.53554
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.08963
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.59621
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.15099
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.72704
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.74289
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.08664
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5158.23188
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.22818
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           151.36553
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.62624     0.46523    8.28056     6.66880
alpha_0                               0.71779     0.00015    0.71802     0.71756
alpha_1                               0.66188     0.00051    0.66268     0.66108
alpha_2                               0.66800     0.00045    0.66871     0.66730
alpha_3                               0.66597     0.00049    0.66674     0.66521
alpha_4                               0.66649     0.00045    0.66720     0.66578
alpha_5                               0.67084     0.00043    0.67151     0.67017
alpha_6                               0.65689     0.00051    0.65769     0.65609
alpha_7                               0.67784     0.00045    0.67853     0.67714
alpha_8                               0.66840     0.00048    0.66915     0.66765
alpha_9                               0.66206     0.00050    0.66285     0.66128
Alpha_loss                            -1.85562    0.01749    -1.82083    -1.88369
Training/policy_loss                  -31.61539   0.07509    -31.44033   -31.72122
Training/qf1_loss                     1335.35762  211.16718  1595.13647  1007.61420
Training/qf2_loss                     1335.65483  212.20061  1597.57715  1007.72864
Training/pf_norm                      0.38775     0.06520    0.48175     0.28913
Training/qf1_norm                     531.50042   69.05879   632.70544   393.28494
Training/qf2_norm                     531.14714   66.04688   633.59436   400.82608
log_std/mean                          -0.30309    0.00121    -0.30078    -0.30450
log_std/std                           0.13186     0.00105    0.13371     0.13047
log_std/max                           -0.10742    0.00233    -0.10295    -0.11028
log_std/min                           -0.63918    0.00763    -0.63012    -0.65611
log_probs/mean                        -0.58877    0.04650    -0.50902    -0.66160
log_probs/std                         2.00237     0.03919    2.04754     1.93715
log_probs/max                         6.31132     0.19992    6.62972     6.02595
log_probs/min                         -8.05811    1.09831    -6.67565    -9.59479
mean/mean                             -0.03926    0.00069    -0.03800    -0.04018
mean/std                              0.87146     0.00359    0.87607     0.86525
mean/max                              1.66800     0.00746    1.68770     1.66003
mean/min                              -2.00857    0.00911    -1.99918    -2.03302
------------------------------------  ----------  ---------  ----------  ----------
sample: [6, 2, 9, 4, 8, 3, 5, 7, 1, 0]
replay_buffer._size: [21900 21900 21900 21900 21900 21900 21900 21900 21900 21900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.081253528594971 0.0021009445190429688
train_time 6.084669828414917
2023-09-06 13:40:36,902 MainThread INFO: EPOCH:144
2023-09-06 13:40:36,903 MainThread INFO: Time Consumed:6.164226770401001s
2023-09-06 13:40:36,903 MainThread INFO: Total Frames:217500s
 36%|‚ñà‚ñà‚ñà‚ñã      | 145/400 [09:35<26:54,  6.33s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               476.04643
Train_Epoch_Reward                    6145.12996
Running_Training_Average_Rewards      561.06595
Explore_Time                          0.06900
Train___Time                          6.08467
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.38248
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.33747
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.68572
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.42476
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.71382
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -103.62317
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.59540
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5140.57694
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.51206
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           298.18338
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.46741     1.25674    8.87014     5.12327
alpha_0                               0.71727     0.00015    0.71751     0.71703
alpha_1                               0.66010     0.00051    0.66090     0.65929
alpha_2                               0.66642     0.00046    0.66714     0.66571
alpha_3                               0.66427     0.00049    0.66504     0.66350
alpha_4                               0.66492     0.00045    0.66563     0.66421
alpha_5                               0.66935     0.00043    0.67002     0.66867
alpha_6                               0.65513     0.00050    0.65592     0.65434
alpha_7                               0.67628     0.00045    0.67698     0.67557
alpha_8                               0.66673     0.00048    0.66749     0.66597
alpha_9                               0.66031     0.00050    0.66110     0.65952
Alpha_loss                            -1.89280    0.02467    -1.84259    -1.93647
Training/policy_loss                  -31.89688   0.08087    -31.76177   -32.08389
Training/qf1_loss                     1451.01462  436.15210  2247.84473  910.72980
Training/qf2_loss                     1453.91598  438.77914  2251.50708  907.94025
Training/pf_norm                      0.35391     0.07421    0.55092     0.26600
Training/qf1_norm                     521.44589   182.52525  742.12195   190.72562
Training/qf2_norm                     518.30549   176.95896  732.79346   198.67572
log_std/mean                          -0.29720    0.00110    -0.29543    -0.29972
log_std/std                           0.13060     0.00046    0.13112     0.12983
log_std/max                           -0.10636    0.00193    -0.10339    -0.11049
log_std/min                           -0.62192    0.00261    -0.61858    -0.62651
log_probs/mean                        -0.65343    0.06271    -0.53644    -0.77160
log_probs/std                         1.97300     0.02244    2.01360     1.93079
log_probs/max                         6.24260     0.12885    6.43154     5.99807
log_probs/min                         -7.46602    0.45793    -6.53992    -8.00935
mean/mean                             -0.03417    0.00271    -0.02995    -0.03774
mean/std                              0.85956     0.00171    0.86353     0.85702
mean/max                              1.66729     0.00920    1.68531     1.65465
mean/min                              -1.98593    0.00795    -1.97418    -1.99903
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 1, 2, 3, 5, 9, 6, 0, 4, 7]
replay_buffer._size: [22050 22050 22050 22050 22050 22050 22050 22050 22050 22050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.228470325469971 0.0021219253540039062
train_time 6.231914281845093
2023-09-06 13:40:43,306 MainThread INFO: EPOCH:145
2023-09-06 13:40:43,306 MainThread INFO: Time Consumed:6.2504496574401855s
2023-09-06 13:40:43,306 MainThread INFO: Total Frames:219000s
 36%|‚ñà‚ñà‚ñà‚ñã      | 146/400 [09:41<26:54,  6.35s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               483.50254
Train_Epoch_Reward                    4041.52079
Running_Training_Average_Rewards      508.79686
Explore_Time                          0.00613
Train___Time                          6.23191
Eval____Time                          0.00766
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.66903
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.66933
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.76979
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.91324
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.29344
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -102.15658
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.47839
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5271.53527
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.41936
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           221.98430
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.82813     0.52931    8.73484     7.00351
alpha_0                               0.71673     0.00016    0.71697     0.71649
alpha_1                               0.65829     0.00052    0.65911     0.65748
alpha_2                               0.66482     0.00046    0.66555     0.66410
alpha_3                               0.66255     0.00049    0.66332     0.66178
alpha_4                               0.66336     0.00045    0.66406     0.66266
alpha_5                               0.66783     0.00044    0.66852     0.66714
alpha_6                               0.65338     0.00050    0.65417     0.65260
alpha_7                               0.67471     0.00045    0.67541     0.67400
alpha_8                               0.66504     0.00049    0.66580     0.66427
alpha_9                               0.65856     0.00050    0.65935     0.65777
Alpha_loss                            -1.91072    0.01781    -1.88296    -1.95067
Training/policy_loss                  -32.16322   0.11257    -31.98314   -32.30966
Training/qf1_loss                     1560.96252  342.08468  2029.71387  861.37659
Training/qf2_loss                     1560.16124  341.96566  2031.65845  860.08087
Training/pf_norm                      0.35076     0.03201    0.40898     0.29567
Training/qf1_norm                     570.17329   77.07115   708.51495   445.57947
Training/qf2_norm                     569.22981   76.02659   705.26581   450.00598
log_std/mean                          -0.29347    0.00130    -0.29115    -0.29531
log_std/std                           0.12906     0.00099    0.13039     0.12731
log_std/max                           -0.10906    0.00345    -0.10320    -0.11395
log_std/min                           -0.62243    0.00427    -0.61748    -0.63150
log_probs/mean                        -0.66794    0.03798    -0.60871    -0.75055
log_probs/std                         1.99070     0.04523    2.06711     1.92855
log_probs/max                         6.22529     0.12386    6.40372     5.97657
log_probs/min                         -7.94848    1.09118    -6.22715    -9.58153
mean/mean                             -0.03027    0.00085    -0.02945    -0.03226
mean/std                              0.85626     0.00087    0.85757     0.85437
mean/max                              1.67660     0.01122    1.70146     1.66340
mean/min                              -1.98140    0.01257    -1.96706    -2.01031
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 5, 4, 9, 3, 1, 0, 8, 2, 7]
replay_buffer._size: [22200 22200 22200 22200 22200 22200 22200 22200 22200 22200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.481712818145752 0.0024785995483398438
train_time 6.4855217933654785
2023-09-06 13:40:49,970 MainThread INFO: EPOCH:146
2023-09-06 13:40:49,973 MainThread INFO: Time Consumed:6.507689952850342s
2023-09-06 13:40:49,973 MainThread INFO: Total Frames:220500s
 37%|‚ñà‚ñà‚ñà‚ñã      | 147/400 [09:48<27:15,  6.46s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               493.98536
Train_Epoch_Reward                    6461.11652
Running_Training_Average_Rewards      554.92558
Explore_Time                          0.01368
Train___Time                          6.48552
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.96520
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.99790
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.75796
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.49368
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.91035
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -100.36446
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.44600
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5372.95098
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.22633
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           262.13572
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.84158     1.13450    9.06741     5.37864
alpha_0                               0.71619     0.00015    0.71643     0.71595
alpha_1                               0.65648     0.00052    0.65729     0.65566
alpha_2                               0.66320     0.00047    0.66393     0.66246
alpha_3                               0.66083     0.00050    0.66160     0.66004
alpha_4                               0.66179     0.00045    0.66250     0.66109
alpha_5                               0.66629     0.00044    0.66699     0.66560
alpha_6                               0.65165     0.00050    0.65242     0.65087
alpha_7                               0.67314     0.00045    0.67385     0.67243
alpha_8                               0.66332     0.00050    0.66410     0.66254
alpha_9                               0.65680     0.00051    0.65760     0.65601
Alpha_loss                            -1.92272    0.01023    -1.90547    -1.93830
Training/policy_loss                  -32.51034   0.10275    -32.38461   -32.69645
Training/qf1_loss                     1443.37280  319.98627  1868.25977  842.70844
Training/qf2_loss                     1442.91963  319.66901  1866.99792  842.68555
Training/pf_norm                      0.34872     0.05821    0.45478     0.24571
Training/qf1_norm                     575.35640   173.75576  777.65283   202.93826
Training/qf2_norm                     574.39091   171.12215  773.78693   208.77098
log_std/mean                          -0.29414    0.00179    -0.29142    -0.29652
log_std/std                           0.12834     0.00088    0.12959     0.12719
log_std/max                           -0.11914    0.00444    -0.11329    -0.12689
log_std/min                           -0.63145    0.00728    -0.62223    -0.64606
log_probs/mean                        -0.66984    0.03042    -0.62225    -0.71900
log_probs/std                         1.97757     0.03585    2.03938     1.92463
log_probs/max                         6.27032     0.24596    6.56562     5.79281
log_probs/min                         -7.81098    1.62168    -6.03654    -11.02752
mean/mean                             -0.03836    0.00307    -0.03352    -0.04305
mean/std                              0.85690     0.00099    0.85820     0.85537
mean/max                              1.67928     0.00902    1.70220     1.66546
mean/min                              -1.99209    0.01039    -1.97694    -2.01801
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 2, 8, 5, 1, 0, 9, 6, 7, 4]
replay_buffer._size: [22350 22350 22350 22350 22350 22350 22350 22350 22350 22350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.602020740509033 0.00211334228515625
train_time 3.605437755584717
2023-09-06 13:40:56,375 MainThread INFO: EPOCH:147
2023-09-06 13:40:56,376 MainThread INFO: Time Consumed:3.621204137802124s
2023-09-06 13:40:56,376 MainThread INFO: Total Frames:222000s
 37%|‚ñà‚ñà‚ñà‚ñã      | 148/400 [09:54<27:03,  6.44s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               494.57499
Train_Epoch_Reward                    6833.06263
Running_Training_Average_Rewards      577.85666
Explore_Time                          0.00703
Train___Time                          3.60544
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.26540
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.47934
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.81160
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.07628
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.27048
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.49143
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.15499
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5421.38210
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.66053
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           42.00254
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.63116     0.79198    8.83544     6.02835
alpha_0                               0.71564     0.00016    0.71589     0.71538
alpha_1                               0.65467     0.00052    0.65548     0.65386
alpha_2                               0.66157     0.00047    0.66230     0.66084
alpha_3                               0.65908     0.00050    0.65987     0.65830
alpha_4                               0.66023     0.00045    0.66094     0.65953
alpha_5                               0.66476     0.00044    0.66545     0.66406
alpha_6                               0.64993     0.00049    0.65070     0.64917
alpha_7                               0.67156     0.00045    0.67228     0.67085
alpha_8                               0.66159     0.00050    0.66237     0.66081
alpha_9                               0.65504     0.00051    0.65583     0.65425
Alpha_loss                            -1.94019    0.02542    -1.91103    -1.98692
Training/policy_loss                  -32.80065   0.10641    -32.66979   -32.96394
Training/qf1_loss                     1501.34373  423.95178  2217.50244  798.81628
Training/qf2_loss                     1501.86246  423.04192  2216.41602  801.40356
Training/pf_norm                      0.38929     0.05113    0.44642     0.28458
Training/qf1_norm                     551.59888   116.92577  732.64771   307.92667
Training/qf2_norm                     550.20402   116.47720  727.60608   305.58524
log_std/mean                          -0.29663    0.00037    -0.29589    -0.29712
log_std/std                           0.12702     0.00109    0.12903     0.12573
log_std/max                           -0.13020    0.00164    -0.12812    -0.13330
log_std/min                           -0.62921    0.00500    -0.62110    -0.63675
log_probs/mean                        -0.68634    0.06103    -0.61655    -0.79458
log_probs/std                         1.94272     0.04850    2.03351     1.85854
log_probs/max                         6.20834     0.19661    6.42288     5.80266
log_probs/min                         -7.05854    0.57896    -6.21888    -7.99252
mean/mean                             -0.04456    0.00051    -0.04381    -0.04544
mean/std                              0.85213     0.00212    0.85590     0.84929
mean/max                              1.68046     0.01006    1.70496     1.66917
mean/min                              -1.99095    0.00788    -1.97952    -2.00858
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 8, 4, 2, 6, 5, 3, 9, 7, 0]
replay_buffer._size: [22500 22500 22500 22500 22500 22500 22500 22500 22500 22500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.56196665763855 0.002216815948486328
train_time 3.5655369758605957
2023-09-06 13:41:02,651 MainThread INFO: EPOCH:148
2023-09-06 13:41:02,652 MainThread INFO: Time Consumed:3.5882344245910645s
2023-09-06 13:41:02,652 MainThread INFO: Total Frames:223500s
 37%|‚ñà‚ñà‚ñà‚ñã      | 149/400 [10:01<26:39,  6.37s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               491.03209
Train_Epoch_Reward                    7378.09067
Running_Training_Average_Rewards      689.07566
Explore_Time                          0.00774
Train___Time                          3.56554
Eval____Time                          0.00918
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.87726
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.78532
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.87028
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.34179
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.08083
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -99.04513
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.28920
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5368.61554
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.95493
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           23.49255
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.95577     0.67333    8.99128     6.59444
alpha_0                               0.71507     0.00016    0.71532     0.71482
alpha_1                               0.65287     0.00052    0.65368     0.65205
alpha_2                               0.65995     0.00047    0.66068     0.65921
alpha_3                               0.65734     0.00050    0.65812     0.65655
alpha_4                               0.65866     0.00045    0.65937     0.65794
alpha_5                               0.66322     0.00044    0.66391     0.66253
alpha_6                               0.64824     0.00048    0.64900     0.64748
alpha_7                               0.66997     0.00047    0.67069     0.66923
alpha_8                               0.65985     0.00050    0.66064     0.65906
alpha_9                               0.65327     0.00051    0.65407     0.65248
Alpha_loss                            -1.96361    0.01680    -1.94030    -1.99396
Training/policy_loss                  -33.09093   0.11763    -32.92361   -33.26849
Training/qf1_loss                     1498.45895  247.88557  1786.92566  903.26721
Training/qf2_loss                     1499.63631  247.79336  1783.82263  905.87640
Training/pf_norm                      0.39612     0.08315    0.60135     0.29084
Training/qf1_norm                     606.18906   105.77633  761.52325   403.63629
Training/qf2_norm                     605.13510   104.60164  760.51471   404.53906
log_std/mean                          -0.29581    0.00025    -0.29555    -0.29626
log_std/std                           0.12674     0.00135    0.12928     0.12530
log_std/max                           -0.12852    0.00243    -0.12538    -0.13223
log_std/min                           -0.62530    0.00620    -0.61817    -0.63739
log_probs/mean                        -0.71157    0.03964    -0.65784    -0.78924
log_probs/std                         1.99488     0.02250    2.02832     1.96498
log_probs/max                         6.46131     0.15856    6.71517     6.06564
log_probs/min                         -7.56494    0.70873    -6.49563    -8.97421
mean/mean                             -0.05231    0.00622    -0.04451    -0.06231
mean/std                              0.84808     0.00069    0.84945     0.84709
mean/max                              1.68450     0.00889    1.70236     1.67555
mean/min                              -2.00498    0.01260    -1.99067    -2.02470
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 7, 4, 6, 1, 3, 2, 5, 8, 9]
replay_buffer._size: [22650 22650 22650 22650 22650 22650 22650 22650 22650 22650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.613266706466675 0.002197742462158203
train_time 6.616783142089844
2023-09-06 13:41:09,424 MainThread INFO: EPOCH:149
2023-09-06 13:41:09,425 MainThread INFO: Time Consumed:6.636587619781494s
2023-09-06 13:41:09,425 MainThread INFO: Total Frames:225000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 150/400 [10:07<27:02,  6.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               480.33897
Train_Epoch_Reward                    7586.05977
Running_Training_Average_Rewards      726.57377
Explore_Time                          0.01135
Train___Time                          6.61678
Eval____Time                          0.00348
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -106.81849
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.05610
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.88545
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.61299
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.68181
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.42705
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.36467
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5349.45284
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.48313
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.99186
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.84700     0.89386    9.74218     6.68560
alpha_0                               0.71452     0.00015    0.71476     0.71429
alpha_1                               0.65105     0.00052    0.65187     0.65023
alpha_2                               0.65831     0.00047    0.65905     0.65757
alpha_3                               0.65559     0.00050    0.65638     0.65482
alpha_4                               0.65706     0.00046    0.65778     0.65634
alpha_5                               0.66169     0.00044    0.66238     0.66099
alpha_6                               0.64656     0.00048    0.64731     0.64582
alpha_7                               0.66834     0.00047    0.66907     0.66760
alpha_8                               0.65809     0.00051    0.65889     0.65729
alpha_9                               0.65151     0.00051    0.65230     0.65072
Alpha_loss                            -1.96906    0.01295    -1.94075    -1.98482
Training/policy_loss                  -33.44841   0.12773    -33.20795   -33.61718
Training/qf1_loss                     1473.83994  482.03833  2626.72290  845.20502
Training/qf2_loss                     1475.34786  483.17135  2630.71460  840.97070
Training/pf_norm                      0.35646     0.04881    0.42061     0.26121
Training/qf1_norm                     592.11923   142.25075  877.04211   397.72089
Training/qf2_norm                     591.16613   139.32590  869.21716   397.99506
log_std/mean                          -0.29741    0.00102    -0.29548    -0.29870
log_std/std                           0.13206     0.00083    0.13301     0.13012
log_std/max                           -0.13104    0.00186    -0.12668    -0.13295
log_std/min                           -0.65134    0.00587    -0.63846    -0.66062
log_probs/mean                        -0.69493    0.03086    -0.63056    -0.72763
log_probs/std                         1.99036     0.03850    2.04237     1.91406
log_probs/max                         6.40031     0.24530    6.65327     5.91683
log_probs/min                         -7.12183    0.78426    -6.21460    -8.79727
mean/mean                             -0.07114    0.00364    -0.06451    -0.07613
mean/std                              0.85099     0.00102    0.85202     0.84862
mean/max                              1.67748     0.00908    1.69839     1.66355
mean/min                              -2.04066    0.01153    -2.02128    -2.06498
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 5, 1, 6, 2, 7, 9, 0, 3, 4]
replay_buffer._size: [22800 22800 22800 22800 22800 22800 22800 22800 22800 22800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.230946779251099 0.002355337142944336
train_time 6.234631299972534
2023-09-06 13:41:15,788 MainThread INFO: EPOCH:150
2023-09-06 13:41:15,788 MainThread INFO: Time Consumed:6.258117914199829s
2023-09-06 13:41:15,789 MainThread INFO: Total Frames:226500s
 38%|‚ñà‚ñà‚ñà‚ñä      | 151/400 [10:14<26:48,  6.46s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               472.09876
Train_Epoch_Reward                    4550.41162
Running_Training_Average_Rewards      650.48540
Explore_Time                          0.01457
Train___Time                          6.23463
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.86511
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.39438
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.04331
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.91847
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.34373
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.98271
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.57063
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5255.33979
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -78.84463
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.40864
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.06454     0.80243    8.32715     5.47377
alpha_0                               0.71403     0.00014    0.71424     0.71381
alpha_1                               0.64923     0.00052    0.65005     0.64841
alpha_2                               0.65667     0.00047    0.65740     0.65593
alpha_3                               0.65387     0.00050    0.65464     0.65309
alpha_4                               0.65547     0.00046    0.65618     0.65475
alpha_5                               0.66014     0.00044    0.66083     0.65944
alpha_6                               0.64492     0.00047    0.64566     0.64419
alpha_7                               0.66669     0.00048    0.66743     0.66594
alpha_8                               0.65631     0.00051    0.65712     0.65550
alpha_9                               0.64975     0.00050    0.65054     0.64896
Alpha_loss                            -1.98840    0.02986    -1.94218    -2.03129
Training/policy_loss                  -33.77985   0.14375    -33.60767   -34.02374
Training/qf1_loss                     1186.72159  270.05146  1766.42896  775.07709
Training/qf2_loss                     1189.43493  272.22580  1772.07837  775.57098
Training/pf_norm                      0.38154     0.06219    0.47527     0.29550
Training/qf1_norm                     475.59121   131.53931  690.81494   206.71490
Training/qf2_norm                     476.47806   128.94421  682.70178   211.15605
log_std/mean                          -0.29088    0.00256    -0.28771    -0.29475
log_std/std                           0.13044     0.00220    0.13309     0.12711
log_std/max                           -0.12553    0.00262    -0.12158    -0.12998
log_std/min                           -0.63818    0.01218    -0.61977    -0.65435
log_probs/mean                        -0.71320    0.06686    -0.61377    -0.80801
log_probs/std                         1.99049     0.03449    2.03521     1.93024
log_probs/max                         6.40754     0.15626    6.67508     6.16993
log_probs/min                         -7.54737    0.79779    -6.39808    -9.12806
mean/mean                             -0.07569    0.00127    -0.07380    -0.07717
mean/std                              0.84232     0.00558    0.85028     0.83482
mean/max                              1.65644     0.01258    1.67460     1.63269
mean/min                              -2.01815    0.01991    -1.98449    -2.04387
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 6, 5, 1, 4, 8, 7, 9, 2, 0]
replay_buffer._size: [22950 22950 22950 22950 22950 22950 22950 22950 22950 22950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.0614800453186035 0.0021054744720458984
train_time 6.064889907836914
2023-09-06 13:41:22,031 MainThread INFO: EPOCH:151
2023-09-06 13:41:22,031 MainThread INFO: Time Consumed:6.081114768981934s
2023-09-06 13:41:22,032 MainThread INFO: Total Frames:228000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 152/400 [10:20<26:24,  6.39s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               463.79489
Train_Epoch_Reward                    4720.10455
Running_Training_Average_Rewards      561.88586
Explore_Time                          0.00666
Train___Time                          6.06489
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -113.70231
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.52366
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.10114
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.96427
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.08904
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -98.38693
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.50382
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5192.69229
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.18967
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.48420
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.38617     0.73324    8.98341     6.37734
alpha_0                               0.71351     0.00015    0.71375     0.71328
alpha_1                               0.64741     0.00052    0.64823     0.64659
alpha_2                               0.65502     0.00048    0.65576     0.65427
alpha_3                               0.65212     0.00050    0.65291     0.65133
alpha_4                               0.65387     0.00046    0.65459     0.65315
alpha_5                               0.65858     0.00045    0.65929     0.65787
alpha_6                               0.64330     0.00047    0.64403     0.64257
alpha_7                               0.66502     0.00048    0.66578     0.66427
alpha_8                               0.65451     0.00052    0.65532     0.65369
alpha_9                               0.64799     0.00051    0.64878     0.64720
Alpha_loss                            -2.02048    0.01697    -1.99048    -2.05075
Training/policy_loss                  -34.05445   0.09252    -33.93190   -34.22868
Training/qf1_loss                     1289.18069  319.62185  2077.06494  785.78845
Training/qf2_loss                     1290.93116  322.33978  2086.94507  785.60413
Training/pf_norm                      0.41165     0.04884    0.49346     0.30926
Training/qf1_norm                     520.13163   119.96670  776.44305   345.85245
Training/qf2_norm                     522.34948   117.68370  773.92206   351.78540
log_std/mean                          -0.28984    0.00113    -0.28762    -0.29205
log_std/std                           0.12702     0.00043    0.12813     0.12651
log_std/max                           -0.12215    0.00196    -0.11872    -0.12520
log_std/min                           -0.62330    0.00493    -0.61798    -0.63618
log_probs/mean                        -0.76272    0.04423    -0.68797    -0.85373
log_probs/std                         1.98423     0.04348    2.04940     1.88021
log_probs/max                         6.29825     0.21763    6.61634     5.85290
log_probs/min                         -7.71002    0.59328    -6.55383    -8.48843
mean/mean                             -0.07209    0.00073    -0.07114    -0.07332
mean/std                              0.83870     0.00231    0.84281     0.83437
mean/max                              1.65716     0.00976    1.68168     1.64512
mean/min                              -2.00525    0.01270    -1.98909    -2.03786
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 1, 9, 5, 6, 8, 0, 7, 4, 3]
replay_buffer._size: [23100 23100 23100 23100 23100 23100 23100 23100 23100 23100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.564289808273315 0.002118825912475586
train_time 6.567717552185059
2023-09-06 13:41:28,759 MainThread INFO: EPOCH:152
2023-09-06 13:41:28,760 MainThread INFO: Time Consumed:6.588790655136108s
2023-09-06 13:41:28,760 MainThread INFO: Total Frames:229500s
 38%|‚ñà‚ñà‚ñà‚ñä      | 153/400 [10:27<26:42,  6.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               463.07359
Train_Epoch_Reward                    5931.00657
Running_Training_Average_Rewards      506.71742
Explore_Time                          0.01156
Train___Time                          6.56772
Eval____Time                          0.00323
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.42814
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.59409
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.12425
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -62.56185
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.42292
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -95.34621
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.88299
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5323.05586
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.60278
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -20.60036
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.41484     0.97224    9.00419     5.77710
alpha_0                               0.71298     0.00016    0.71322     0.71272
alpha_1                               0.64559     0.00053    0.64641     0.64476
alpha_2                               0.65336     0.00047    0.65410     0.65262
alpha_3                               0.65037     0.00050    0.65116     0.64959
alpha_4                               0.65227     0.00046    0.65299     0.65154
alpha_5                               0.65700     0.00045    0.65771     0.65629
alpha_6                               0.64169     0.00045    0.64241     0.64099
alpha_7                               0.66336     0.00048    0.66411     0.66260
alpha_8                               0.65269     0.00052    0.65351     0.65187
alpha_9                               0.64623     0.00050    0.64702     0.64544
Alpha_loss                            -2.02541    0.02671    -1.97992    -2.07165
Training/policy_loss                  -34.29510   0.06725    -34.14373   -34.37605
Training/qf1_loss                     1385.67745  511.27478  2274.59839  807.43610
Training/qf2_loss                     1384.64526  510.96295  2270.88354  807.39124
Training/pf_norm                      0.37406     0.04366    0.45414     0.31902
Training/qf1_norm                     540.19102   158.74044  804.21112   269.19809
Training/qf2_norm                     542.85242   155.54300  800.92578   278.89178
log_std/mean                          -0.29354    0.00129    -0.29198    -0.29593
log_std/std                           0.12757     0.00094    0.12873     0.12606
log_std/max                           -0.11404    0.00148    -0.11194    -0.11612
log_std/min                           -0.63117    0.00244    -0.62852    -0.63696
log_probs/mean                        -0.75039    0.05887    -0.65013    -0.84942
log_probs/std                         1.95695     0.03800    2.00628     1.88427
log_probs/max                         6.17910     0.21021    6.45186     5.70370
log_probs/min                         -7.83446    0.68607    -6.66534    -9.18623
mean/mean                             -0.07465    0.00147    -0.07214    -0.07687
mean/std                              0.83861     0.00293    0.84270     0.83460
mean/max                              1.63685     0.01615    1.67069     1.61334
mean/min                              -2.00922    0.00983    -1.99689    -2.03466
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 3, 7, 4, 2, 6, 8, 0, 9, 5]
replay_buffer._size: [23250 23250 23250 23250 23250 23250 23250 23250 23250 23250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.4592390060424805 0.0021104812622070312
train_time 6.4626429080963135
2023-09-06 13:41:35,426 MainThread INFO: EPOCH:153
2023-09-06 13:41:35,427 MainThread INFO: Time Consumed:6.482870101928711s
2023-09-06 13:41:35,427 MainThread INFO: Total Frames:231000s
 38%|‚ñà‚ñà‚ñà‚ñä      | 154/400 [10:33<26:49,  6.54s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               471.49873
Train_Epoch_Reward                    4816.52578
Running_Training_Average_Rewards      515.58790
Explore_Time                          0.01084
Train___Time                          6.46264
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -99.92628
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.02882
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.15078
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.94538
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.36689
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -88.40781
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.04582
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5510.02885
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.97059
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.46402
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.73390     0.79098    9.06811     6.14180
alpha_0                               0.71238     0.00017    0.71266     0.71211
alpha_1                               0.64376     0.00052    0.64458     0.64294
alpha_2                               0.65170     0.00048    0.65245     0.65095
alpha_3                               0.64863     0.00050    0.64941     0.64785
alpha_4                               0.65066     0.00046    0.65138     0.64993
alpha_5                               0.65542     0.00046    0.65613     0.65470
alpha_6                               0.64014     0.00044    0.64083     0.63945
alpha_7                               0.66167     0.00049    0.66243     0.66090
alpha_8                               0.65087     0.00052    0.65169     0.65004
alpha_9                               0.64449     0.00050    0.64527     0.64371
Alpha_loss                            -2.03277    0.01729    -2.00151    -2.06105
Training/policy_loss                  -34.54098   0.09891    -34.39199   -34.73632
Training/qf1_loss                     1478.29101  520.49063  2412.55151  875.43909
Training/qf2_loss                     1476.61440  520.93966  2405.96411  873.80145
Training/pf_norm                      0.36899     0.04035    0.43275     0.30788
Training/qf1_norm                     598.08569   125.23840  826.63226   345.16165
Training/qf2_norm                     599.92781   124.22640  822.39075   348.06454
log_std/mean                          -0.29981    0.00155    -0.29667    -0.30181
log_std/std                           0.12521     0.00055    0.12603     0.12466
log_std/max                           -0.12199    0.00153    -0.11864    -0.12342
log_std/min                           -0.63753    0.00514    -0.63042    -0.64910
log_probs/mean                        -0.73836    0.03953    -0.66957    -0.79774
log_probs/std                         1.94592     0.03672    1.99443     1.88902
log_probs/max                         6.18134     0.12588    6.39928     5.97388
log_probs/min                         -7.69710    1.08878    -6.56297    -10.54852
mean/mean                             -0.08122    0.00275    -0.07749    -0.08622
mean/std                              0.83551     0.00106    0.83732     0.83328
mean/max                              1.62929     0.00978    1.65007     1.61346
mean/min                              -2.02465    0.01552    -2.00583    -2.05877
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 0, 2, 8, 3, 9, 7, 6, 5, 4]
replay_buffer._size: [23400 23400 23400 23400 23400 23400 23400 23400 23400 23400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.022968053817749 0.0022895336151123047
train_time 7.026617050170898
2023-09-06 13:41:42,642 MainThread INFO: EPOCH:154
2023-09-06 13:41:42,642 MainThread INFO: Time Consumed:7.052134990692139s
2023-09-06 13:41:42,643 MainThread INFO: Total Frames:232500s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 155/400 [10:41<27:36,  6.76s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               489.77593
Train_Epoch_Reward                    4522.50390
Running_Training_Average_Rewards      509.00121
Explore_Time                          0.01649
Train___Time                          7.02662
Eval____Time                          0.00381
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.05020
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.41588
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.24925
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.95101
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.24731
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.65201
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.00116
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5747.90979
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.77024
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.50943
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.06968     0.71351    8.60647     5.86385
alpha_0                               0.71179     0.00017    0.71205     0.71152
alpha_1                               0.64193     0.00052    0.64275     0.64112
alpha_2                               0.65003     0.00048    0.65078     0.64928
alpha_3                               0.64690     0.00050    0.64767     0.64612
alpha_4                               0.64904     0.00046    0.64977     0.64831
alpha_5                               0.65382     0.00046    0.65454     0.65311
alpha_6                               0.63861     0.00043    0.63929     0.63794
alpha_7                               0.65996     0.00050    0.66073     0.65918
alpha_8                               0.64903     0.00053    0.64986     0.64820
alpha_9                               0.64276     0.00050    0.64353     0.64198
Alpha_loss                            -2.05541    0.02397    -2.00710    -2.09531
Training/policy_loss                  -34.94258   0.10722    -34.75839   -35.12266
Training/qf1_loss                     1223.04189  395.25664  2139.97314  746.63086
Training/qf2_loss                     1223.94005  394.46102  2136.37549  746.65125
Training/pf_norm                      0.39161     0.07023    0.52145     0.30398
Training/qf1_norm                     483.58035   112.69696  737.72516   300.26416
Training/qf2_norm                     488.21861   111.19692  738.15033   303.63132
log_std/mean                          -0.29566    0.00383    -0.28973    -0.30115
log_std/std                           0.12503     0.00025    0.12563     0.12479
log_std/max                           -0.10984    0.00633    -0.10081    -0.11985
log_std/min                           -0.63793    0.00315    -0.63346    -0.64299
log_probs/mean                        -0.76379    0.05208    -0.65409    -0.84955
log_probs/std                         1.92489     0.03734    1.96231     1.82631
log_probs/max                         6.18554     0.20076    6.42019     5.82529
log_probs/min                         -7.28996    0.94553    -6.26000    -9.18905
mean/mean                             -0.09224    0.00231    -0.08785    -0.09535
mean/std                              0.82709     0.00403    0.83321     0.82193
mean/max                              1.62075     0.00622    1.63205     1.61007
mean/min                              -2.03322    0.00581    -2.02451    -2.04293
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 1, 7, 2, 6, 8, 3, 9, 0, 5]
replay_buffer._size: [23550 23550 23550 23550 23550 23550 23550 23550 23550 23550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.6996657848358154 0.002147197723388672
train_time 3.7031311988830566
2023-09-06 13:41:49,185 MainThread INFO: EPOCH:155
2023-09-06 13:41:49,185 MainThread INFO: Time Consumed:4.001245498657227s
2023-09-06 13:41:49,186 MainThread INFO: Total Frames:234000s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 156/400 [10:47<27:09,  6.68s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               504.16650
Train_Epoch_Reward                    6271.35276
Running_Training_Average_Rewards      520.34608
Explore_Time                          0.29040
Train___Time                          3.70313
Eval____Time                          0.00307
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -107.88434
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.54734
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.29148
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.14333
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.30936
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.31148
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -76.21063
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5782.48796
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.91994
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.66075
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.86031     0.80867    9.87797     6.98518
alpha_0                               0.71119     0.00017    0.71146     0.71093
alpha_1                               0.64011     0.00053    0.64093     0.63929
alpha_2                               0.64835     0.00049    0.64911     0.64758
alpha_3                               0.64517     0.00050    0.64595     0.64439
alpha_4                               0.64742     0.00047    0.64815     0.64668
alpha_5                               0.65223     0.00046    0.65295     0.65151
alpha_6                               0.63712     0.00043    0.63779     0.63645
alpha_7                               0.65820     0.00051    0.65900     0.65741
alpha_8                               0.64718     0.00054    0.64802     0.64634
alpha_9                               0.64103     0.00050    0.64181     0.64024
Alpha_loss                            -2.08855    0.01612    -2.06193    -2.11282
Training/policy_loss                  -35.19566   0.11329    -34.94755   -35.34775
Training/qf1_loss                     1466.47583  400.83136  2617.58081  1173.66638
Training/qf2_loss                     1465.85627  401.94642  2620.48706  1170.50513
Training/pf_norm                      0.36873     0.06230    0.48654     0.29083
Training/qf1_norm                     614.70672   137.09522  953.92072   450.30676
Training/qf2_norm                     618.99356   134.11463  951.11566   460.80740
log_std/mean                          -0.28717    0.00080    -0.28618    -0.28845
log_std/std                           0.12646     0.00032    0.12687     0.12602
log_std/max                           -0.09181    0.00303    -0.08814    -0.09782
log_std/min                           -0.63517    0.00343    -0.63012    -0.64270
log_probs/mean                        -0.80911    0.03136    -0.75817    -0.85631
log_probs/std                         1.97685     0.03909    2.06716     1.93515
log_probs/max                         6.31518     0.20186    6.57391     5.92213
log_probs/min                         -7.24170    0.51219    -6.41030    -7.90165
mean/mean                             -0.09923    0.00218    -0.09600    -0.10213
mean/std                              0.82296     0.00133    0.82628     0.82106
mean/max                              1.63428     0.00984    1.65347     1.62087
mean/min                              -2.03934    0.00865    -2.02908    -2.05908
------------------------------------  ----------  ---------  ----------  ----------
sample: [0, 2, 7, 6, 1, 9, 5, 8, 4, 3]
replay_buffer._size: [23700 23700 23700 23700 23700 23700 23700 23700 23700 23700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7689154148101807 0.0024480819702148438
train_time 3.772702932357788
2023-09-06 13:41:55,746 MainThread INFO: EPOCH:156
2023-09-06 13:41:55,746 MainThread INFO: Time Consumed:4.177383661270142s
2023-09-06 13:41:55,747 MainThread INFO: Total Frames:235500s
 39%|‚ñà‚ñà‚ñà‚ñâ      | 157/400 [10:54<26:54,  6.64s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               508.89780
Train_Epoch_Reward                    6858.86944
Running_Training_Average_Rewards      588.42420
Explore_Time                          0.39690
Train___Time                          3.77270
Eval____Time                          0.00332
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -110.71393
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.46087
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.37047
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.92871
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.78297
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.09467
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.72685
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5682.94327
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.16718
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.03611
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.71762     1.06352    9.72660     6.19724
alpha_0                               0.71062     0.00016    0.71087     0.71037
alpha_1                               0.63828     0.00052    0.63910     0.63746
alpha_2                               0.64664     0.00049    0.64741     0.64587
alpha_3                               0.64344     0.00050    0.64422     0.64267
alpha_4                               0.64579     0.00047    0.64652     0.64505
alpha_5                               0.65064     0.00046    0.65135     0.64992
alpha_6                               0.63565     0.00042    0.63631     0.63499
alpha_7                               0.65643     0.00051    0.65723     0.65564
alpha_8                               0.64531     0.00054    0.64615     0.64447
alpha_9                               0.63928     0.00050    0.64007     0.63849
Alpha_loss                            -2.08394    0.02204    -2.04750    -2.13919
Training/policy_loss                  -35.53852   0.09776    -35.38566   -35.67770
Training/qf1_loss                     1532.04629  399.81388  2419.70947  884.48206
Training/qf2_loss                     1529.84370  399.75018  2421.05151  885.03485
Training/pf_norm                      0.38805     0.04770    0.48055     0.33722
Training/qf1_norm                     593.80725   174.64517  909.11237   330.00293
Training/qf2_norm                     598.72616   171.44985  910.78741   342.67123
log_std/mean                          -0.29525    0.00288    -0.29027    -0.29908
log_std/std                           0.12860     0.00123    0.13058     0.12663
log_std/max                           -0.09600    0.00306    -0.09061    -0.09988
log_std/min                           -0.64308    0.00458    -0.63488    -0.64943
log_probs/mean                        -0.76837    0.05021    -0.69827    -0.89691
log_probs/std                         2.00323     0.05941    2.15052     1.92943
log_probs/max                         6.52332     0.17317    6.78328     6.28497
log_probs/min                         -7.62479    0.89266    -6.37488    -8.85734
mean/mean                             -0.10438    0.00126    -0.10241    -0.10611
mean/std                              0.83413     0.00409    0.83966     0.82763
mean/max                              1.65520     0.00880    1.67453     1.64280
mean/min                              -2.07042    0.01310    -2.04758    -2.08578
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 6, 2, 7, 3, 0, 5, 4, 1, 8]
replay_buffer._size: [23850 23850 23850 23850 23850 23850 23850 23850 23850 23850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7071475982666016 0.002331972122192383
train_time 3.7108583450317383
2023-09-06 13:42:02,301 MainThread INFO: EPOCH:157
2023-09-06 13:42:02,302 MainThread INFO: Time Consumed:3.806333541870117s
2023-09-06 13:42:02,303 MainThread INFO: Total Frames:237000s
 40%|‚ñà‚ñà‚ñà‚ñâ      | 158/400 [11:00<26:43,  6.63s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               502.41563
Train_Epoch_Reward                    5794.64431
Running_Training_Average_Rewards      630.82888
Explore_Time                          0.08597
Train___Time                          3.71086
Eval____Time                          0.00483
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.19546
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.52167
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.39237
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.76331
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.37190
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.87056
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.92998
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5563.73497
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -84.51979
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.57178
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.34983     0.77431    9.01528     6.40643
alpha_0                               0.71008     0.00015    0.71032     0.70986
alpha_1                               0.63646     0.00052    0.63728     0.63564
alpha_2                               0.64493     0.00049    0.64570     0.64417
alpha_3                               0.64172     0.00049    0.64249     0.64096
alpha_4                               0.64416     0.00046    0.64489     0.64344
alpha_5                               0.64904     0.00046    0.64976     0.64832
alpha_6                               0.63420     0.00041    0.63484     0.63355
alpha_7                               0.65467     0.00050    0.65546     0.65388
alpha_8                               0.64344     0.00054    0.64428     0.64260
alpha_9                               0.63753     0.00050    0.63831     0.63674
Alpha_loss                            -2.07441    0.01896    -2.04898    -2.11460
Training/policy_loss                  -35.91653   0.10176    -35.76605   -36.06198
Training/qf1_loss                     1384.41107  336.13185  2050.32422  933.50861
Training/qf2_loss                     1381.86952  335.17973  2043.40271  927.83734
Training/pf_norm                      0.37436     0.06058    0.45697     0.28094
Training/qf1_norm                     530.03146   125.71080  816.84619   384.15558
Training/qf2_norm                     535.58055   123.91606  816.50031   386.51498
log_std/mean                          -0.29925    0.00167    -0.29584    -0.30073
log_std/std                           0.13223     0.00082    0.13328     0.13071
log_std/max                           -0.09328    0.00236    -0.08992    -0.09698
log_std/min                           -0.65019    0.00639    -0.63739    -0.66074
log_probs/mean                        -0.71759    0.04216    -0.65184    -0.79561
log_probs/std                         1.99125     0.04316    2.05708     1.92307
log_probs/max                         6.44009     0.12152    6.66357     6.24511
log_probs/min                         -7.41841    0.99134    -6.24556    -9.35111
mean/mean                             -0.10567    0.00051    -0.10506    -0.10641
mean/std                              0.83974     0.00227    0.84176     0.83482
mean/max                              1.66704     0.01132    1.68705     1.65518
mean/min                              -2.08049    0.01387    -2.05838    -2.10522
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 8, 0, 1, 9, 6, 5, 3, 7, 4]
replay_buffer._size: [24000 24000 24000 24000 24000 24000 24000 24000 24000 24000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.839330673217773 0.0021593570709228516
train_time 6.842831373214722
2023-09-06 13:42:09,319 MainThread INFO: EPOCH:158
2023-09-06 13:42:09,319 MainThread INFO: Time Consumed:6.859051942825317s
2023-09-06 13:42:09,320 MainThread INFO: Total Frames:238500s
 40%|‚ñà‚ñà‚ñà‚ñâ      | 159/400 [11:07<27:05,  6.74s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               498.60301
Train_Epoch_Reward                    6165.79948
Running_Training_Average_Rewards      627.31044
Explore_Time                          0.00572
Train___Time                          6.84283
Eval____Time                          0.00462
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.53618
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.89535
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.43656
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.26708
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.64223
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.48600
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.12444
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5666.01533
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -86.43850
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.35837
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.66650     0.91692    9.08924     6.52768
alpha_0                               0.70956     0.00016    0.70980     0.70932
alpha_1                               0.63465     0.00052    0.63546     0.63383
alpha_2                               0.64323     0.00049    0.64400     0.64247
alpha_3                               0.64003     0.00049    0.64079     0.63927
alpha_4                               0.64254     0.00047    0.64327     0.64181
alpha_5                               0.64744     0.00046    0.64816     0.64672
alpha_6                               0.63276     0.00041    0.63340     0.63213
alpha_7                               0.65292     0.00050    0.65371     0.65213
alpha_8                               0.64158     0.00053    0.64242     0.64075
alpha_9                               0.63578     0.00050    0.63657     0.63500
Alpha_loss                            -2.10261    0.01813    -2.07463    -2.13172
Training/policy_loss                  -36.25667   0.13000    -36.01994   -36.47312
Training/qf1_loss                     1459.13012  349.00506  1951.49841  999.12201
Training/qf2_loss                     1458.20421  349.31372  1951.54614  1000.09808
Training/pf_norm                      0.36530     0.06702    0.52600     0.29792
Training/qf1_norm                     580.15648   165.09072  849.02893   357.24908
Training/qf2_norm                     588.88448   161.81781  854.74048   373.61624
log_std/mean                          -0.29557    0.00042    -0.29509    -0.29641
log_std/std                           0.12764     0.00128    0.12988     0.12612
log_std/max                           -0.09386    0.00278    -0.08973    -0.09736
log_std/min                           -0.62927    0.00643    -0.62316    -0.64313
log_probs/mean                        -0.75677    0.04067    -0.69935    -0.82882
log_probs/std                         1.96395     0.04522    2.04336     1.89777
log_probs/max                         6.38091     0.15904    6.64031     6.14968
log_probs/min                         -7.18900    0.92494    -5.84667    -9.36981
mean/mean                             -0.10926    0.00191    -0.10654    -0.11217
mean/std                              0.82854     0.00257    0.83265     0.82558
mean/max                              1.67763     0.00997    1.69044     1.66006
mean/min                              -2.04974    0.01470    -2.03585    -2.08068
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 2, 9, 6, 1, 3, 8, 7, 0, 4]
replay_buffer._size: [24150 24150 24150 24150 24153 24156 24150 24150 24150 24155]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.846216917037964 0.002783536911010742
train_time 6.8504016399383545
2023-09-06 13:42:16,376 MainThread INFO: EPOCH:159
2023-09-06 13:42:16,377 MainThread INFO: Time Consumed:6.898020029067993s
2023-09-06 13:42:16,377 MainThread INFO: Total Frames:240000s
 40%|‚ñà‚ñà‚ñà‚ñà      | 160/400 [11:14<27:19,  6.83s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               501.48171
Train_Epoch_Reward                    7026.20041
Running_Training_Average_Rewards      632.88814
Explore_Time                          0.03883
Train___Time                          6.85040
Eval____Time                          0.00357
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -110.24187
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.88556
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.49010
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.31598
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.40238
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.35965
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.80397
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5770.03860
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -87.14521
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.37140
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.46871     1.04461    9.19841     5.59139
alpha_0                               0.70902     0.00015    0.70926     0.70879
alpha_1                               0.63282     0.00052    0.63364     0.63200
alpha_2                               0.64153     0.00049    0.64230     0.64076
alpha_3                               0.63833     0.00049    0.63910     0.63757
alpha_4                               0.64091     0.00047    0.64165     0.64018
alpha_5                               0.64583     0.00046    0.64656     0.64511
alpha_6                               0.63136     0.00040    0.63199     0.63073
alpha_7                               0.65115     0.00051    0.65195     0.65035
alpha_8                               0.63973     0.00053    0.64056     0.63889
alpha_9                               0.63404     0.00050    0.63482     0.63326
Alpha_loss                            -2.12223    0.01374    -2.10432    -2.14915
Training/policy_loss                  -36.53457   0.10678    -36.30619   -36.68942
Training/qf1_loss                     1496.53929  446.39857  2160.81104  820.66760
Training/qf2_loss                     1494.61339  448.16261  2160.15845  816.20404
Training/pf_norm                      0.38354     0.07542    0.52222     0.27457
Training/qf1_norm                     549.23574   177.86646  833.57672   241.26245
Training/qf2_norm                     557.81512   176.14909  840.79681   252.99536
log_std/mean                          -0.29909    0.00201    -0.29605    -0.30160
log_std/std                           0.12919     0.00239    0.13294     0.12601
log_std/max                           -0.09789    0.00037    -0.09734    -0.09843
log_std/min                           -0.64224    0.01342    -0.62213    -0.66317
log_probs/mean                        -0.77041    0.03009    -0.73206    -0.83115
log_probs/std                         2.00870     0.03168    2.07196     1.96446
log_probs/max                         6.34942     0.22319    6.66089     5.97969
log_probs/min                         -7.50054    0.55604    -6.83090    -8.47129
mean/mean                             -0.11907    0.00346    -0.11328    -0.12394
mean/std                              0.82653     0.00186    0.82968     0.82433
mean/max                              1.68242     0.00689    1.69327     1.67560
mean/min                              -2.05178    0.01307    -2.03204    -2.07333
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 3, 8, 2, 7, 5, 4, 0, 1, 9]
replay_buffer._size: [24300 24300 24300 24300 24300 24300 24300 24300 24300 24300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.638133525848389 0.0022017955780029297
train_time 6.641691207885742
2023-09-06 13:42:23,277 MainThread INFO: EPOCH:160
2023-09-06 13:42:23,278 MainThread INFO: Time Consumed:6.729283332824707s
2023-09-06 13:42:23,278 MainThread INFO: Total Frames:241500s
 40%|‚ñà‚ñà‚ñà‚ñà      | 161/400 [11:21<27:17,  6.85s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               505.86574
Train_Epoch_Reward                    6066.86662
Running_Training_Average_Rewards      641.96222
Explore_Time                          0.07756
Train___Time                          6.64169
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -109.35134
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.83127
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.50099
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.19064
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.50933
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.93181
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.14170
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5699.10660
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -87.97789
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.55249
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.43858     0.99713    8.74957     6.08435
alpha_0                               0.70850     0.00015    0.70874     0.70826
alpha_1                               0.63101     0.00052    0.63182     0.63019
alpha_2                               0.63982     0.00049    0.64059     0.63906
alpha_3                               0.63664     0.00048    0.63740     0.63589
alpha_4                               0.63928     0.00047    0.64001     0.63854
alpha_5                               0.64421     0.00047    0.64494     0.64348
alpha_6                               0.62996     0.00040    0.63059     0.62934
alpha_7                               0.64936     0.00052    0.65017     0.64855
alpha_8                               0.63787     0.00053    0.63871     0.63703
alpha_9                               0.63231     0.00049    0.63308     0.63153
Alpha_loss                            -2.12995    0.01959    -2.10567    -2.17838
Training/policy_loss                  -36.83710   0.12394    -36.60688   -37.04471
Training/qf1_loss                     1357.12021  368.70669  1885.35193  857.87347
Training/qf2_loss                     1355.13365  369.78603  1882.43054  851.58087
Training/pf_norm                      0.43900     0.09635    0.70402     0.35572
Training/qf1_norm                     545.36022   177.25480  765.86676   293.03705
Training/qf2_norm                     556.55955   174.10754  771.60712   305.79654
log_std/mean                          -0.29943    0.00121    -0.29797    -0.30146
log_std/std                           0.13415     0.00062    0.13506     0.13337
log_std/max                           -0.09089    0.00502    -0.08238    -0.09688
log_std/min                           -0.65839    0.00257    -0.65242    -0.66173
log_probs/mean                        -0.76400    0.04499    -0.71840    -0.87781
log_probs/std                         1.97479     0.03697    2.01738     1.88966
log_probs/max                         6.25880     0.14022    6.50595     6.01104
log_probs/min                         -7.19971    0.55393    -6.40251    -8.25035
mean/mean                             -0.12907    0.00326    -0.12460    -0.13479
mean/std                              0.82743     0.00126    0.82952     0.82550
mean/max                              1.66108     0.01018    1.68098     1.64690
mean/min                              -2.05781    0.00697    -2.04239    -2.06892
------------------------------------  ----------  ---------  ----------  ---------
sample: [8, 9, 1, 4, 5, 3, 6, 0, 2, 7]
replay_buffer._size: [24450 24450 24450 24450 24450 24450 24450 24450 24450 24450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.322798013687134 0.0024423599243164062
train_time 6.326589107513428
2023-09-06 13:42:29,855 MainThread INFO: EPOCH:161
2023-09-06 13:42:29,855 MainThread INFO: Time Consumed:6.371970176696777s
2023-09-06 13:42:29,856 MainThread INFO: Total Frames:243000s
 40%|‚ñà‚ñà‚ñà‚ñà      | 162/400 [11:28<26:54,  6.78s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               508.15355
Train_Epoch_Reward                    6199.60143
Running_Training_Average_Rewards      643.08895
Explore_Time                          0.03462
Train___Time                          6.32659
Eval____Time                          0.00507
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.04297
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.07552
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.56845
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.49287
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -71.13516
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.69971
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.23509
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5743.35660
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -89.64703
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.99495
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.57963     1.12907    9.75765     6.18306
alpha_0                               0.70794     0.00017    0.70821     0.70767
alpha_1                               0.62919     0.00052    0.63001     0.62838
alpha_2                               0.63812     0.00049    0.63889     0.63735
alpha_3                               0.63497     0.00048    0.63572     0.63423
alpha_4                               0.63763     0.00048    0.63838     0.63688
alpha_5                               0.64258     0.00047    0.64332     0.64184
alpha_6                               0.62860     0.00039    0.62920     0.62799
alpha_7                               0.64755     0.00052    0.64837     0.64673
alpha_8                               0.63601     0.00054    0.63685     0.63517
alpha_9                               0.63059     0.00049    0.63136     0.62982
Alpha_loss                            -2.15681    0.02420    -2.12721    -2.19448
Training/policy_loss                  -37.09746   0.10049    -36.93272   -37.23429
Training/qf1_loss                     1502.97102  423.80135  2262.52393  857.48877
Training/qf2_loss                     1502.64927  423.86508  2260.55640  858.79999
Training/pf_norm                      0.40769     0.06898    0.48935     0.29035
Training/qf1_norm                     574.83079   200.11701  961.20728   326.01794
Training/qf2_norm                     584.74810   195.64920  961.62616   341.47913
log_std/mean                          -0.29699    0.00055    -0.29629    -0.29830
log_std/std                           0.13207     0.00131    0.13447     0.13079
log_std/max                           -0.07914    0.00058    -0.07821    -0.08013
log_std/min                           -0.64683    0.00616    -0.64096    -0.66187
log_probs/mean                        -0.80129    0.05273    -0.73629    -0.89067
log_probs/std                         1.95357     0.04253    2.00607     1.89139
log_probs/max                         6.09058     0.16137    6.25671     5.85755
log_probs/min                         -8.46387    0.97525    -6.99776    -10.40045
mean/mean                             -0.14020    0.00216    -0.13604    -0.14282
mean/std                              0.81888     0.00234    0.82355     0.81674
mean/max                              1.63063     0.01074    1.65972     1.61932
mean/min                              -2.05139    0.01012    -2.04210    -2.08040
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 0, 8, 5, 6, 2, 3, 9, 4, 1]
replay_buffer._size: [24600 24600 24600 24600 24600 24600 24600 24600 24600 24600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.695353031158447 0.002351045608520508
train_time 6.6990578174591064
2023-09-06 13:42:36,743 MainThread INFO: EPOCH:162
2023-09-06 13:42:36,744 MainThread INFO: Time Consumed:6.718269109725952s
2023-09-06 13:42:36,744 MainThread INFO: Total Frames:244500s
 41%|‚ñà‚ñà‚ñà‚ñà      | 163/400 [11:35<26:51,  6.80s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               511.50987
Train_Epoch_Reward                    7751.94489
Running_Training_Average_Rewards      667.28043
Explore_Time                          0.00966
Train___Time                          6.69906
Eval____Time                          0.00426
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -108.65991
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.25784
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.76260
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.70232
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.54508
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.83588
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.21658
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5880.96564
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -91.25066
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.02271
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.54766     1.19831    9.43077     5.34829
alpha_0                               0.70733     0.00017    0.70760     0.70706
alpha_1                               0.62738     0.00052    0.62820     0.62657
alpha_2                               0.63640     0.00050    0.63717     0.63562
alpha_3                               0.63332     0.00047    0.63406     0.63258
alpha_4                               0.63597     0.00048    0.63672     0.63522
alpha_5                               0.64093     0.00048    0.64167     0.64018
alpha_6                               0.62726     0.00038    0.62786     0.62667
alpha_7                               0.64572     0.00053    0.64655     0.64490
alpha_8                               0.63413     0.00054    0.63498     0.63328
alpha_9                               0.62889     0.00049    0.62965     0.62813
Alpha_loss                            -2.16901    0.01597    -2.13518    -2.19066
Training/policy_loss                  -37.37453   0.07028    -37.28806   -37.49189
Training/qf1_loss                     1407.53638  491.80701  2353.25952  753.82874
Training/qf2_loss                     1404.55134  493.74583  2354.29077  749.59015
Training/pf_norm                      0.41660     0.08367    0.52891     0.27024
Training/qf1_norm                     580.36235   210.20896  925.10303   193.09341
Training/qf2_norm                     591.17706   205.60341  926.24701   213.23032
log_std/mean                          -0.30050    0.00064    -0.29961    -0.30149
log_std/std                           0.13162     0.00018    0.13189     0.13127
log_std/max                           -0.08306    0.00072    -0.08117    -0.08368
log_std/min                           -0.64881    0.00293    -0.64445    -0.65466
log_probs/mean                        -0.79614    0.03425    -0.72205    -0.83886
log_probs/std                         1.98274     0.02473    2.03206     1.94468
log_probs/max                         6.15451     0.15796    6.42562     5.88315
log_probs/min                         -7.35287    0.69375    -6.19876    -8.61525
mean/mean                             -0.14539    0.00071    -0.14390    -0.14628
mean/std                              0.81534     0.00201    0.81797     0.81180
mean/max                              1.63484     0.00909    1.65228     1.61838
mean/min                              -2.05926    0.00861    -2.04677    -2.07822
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 2, 3, 1, 0, 7, 5, 9, 8, 4]
replay_buffer._size: [24750 24750 24750 24750 24750 24750 24750 24750 24750 24750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.191801071166992 0.002109050750732422
train_time 7.1952314376831055
2023-09-06 13:42:44,153 MainThread INFO: EPOCH:163
2023-09-06 13:42:44,153 MainThread INFO: Time Consumed:7.21577525138855s
2023-09-06 13:42:44,153 MainThread INFO: Total Frames:246000s
 41%|‚ñà‚ñà‚ñà‚ñà      | 164/400 [11:42<27:27,  6.98s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               518.97108
Train_Epoch_Reward                    5980.63882
Running_Training_Average_Rewards      664.40617
Explore_Time                          0.00819
Train___Time                          7.19523
Eval____Time                          0.00752
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.46508
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.06940
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.80061
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.78017
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.23756
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.15314
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.44643
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5928.99988
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -91.74016
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.35184
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.17535     1.02678    8.71958     5.75695
alpha_0                               0.70672     0.00018    0.70700     0.70643
alpha_1                               0.62557     0.00052    0.62639     0.62476
alpha_2                               0.63466     0.00050    0.63544     0.63387
alpha_3                               0.63168     0.00047    0.63242     0.63094
alpha_4                               0.63430     0.00048    0.63506     0.63355
alpha_5                               0.63927     0.00048    0.64002     0.63851
alpha_6                               0.62595     0.00037    0.62654     0.62538
alpha_7                               0.64387     0.00054    0.64471     0.64303
alpha_8                               0.63225     0.00054    0.63309     0.63140
alpha_9                               0.62719     0.00049    0.62796     0.62643
Alpha_loss                            -2.19267    0.01701    -2.16539    -2.23204
Training/policy_loss                  -37.60384   0.07987    -37.46057   -37.71183
Training/qf1_loss                     1429.78372  417.94093  2259.19702  824.43378
Training/qf2_loss                     1425.93725  417.75452  2253.80737  820.03339
Training/pf_norm                      0.39774     0.05929    0.52085     0.31510
Training/qf1_norm                     517.79890   180.50102  777.82648   269.02390
Training/qf2_norm                     529.82414   176.97407  788.05359   288.42896
log_std/mean                          -0.29839    0.00053    -0.29769    -0.29948
log_std/std                           0.13108     0.00019    0.13135     0.13080
log_std/max                           -0.08584    0.00076    -0.08498    -0.08760
log_std/min                           -0.63942    0.00351    -0.63350    -0.64512
log_probs/mean                        -0.82552    0.03510    -0.77149    -0.90358
log_probs/std                         1.94781     0.03670    1.98050     1.85962
log_probs/max                         6.04857     0.18226    6.22253     5.65971
log_probs/min                         -7.98133    0.90147    -6.33331    -9.18384
mean/mean                             -0.14569    0.00086    -0.14490    -0.14781
mean/std                              0.80526     0.00286    0.81033     0.80142
mean/max                              1.60515     0.00927    1.62006     1.58519
mean/min                              -2.03286    0.00824    -2.01926    -2.04682
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 2, 7, 0, 9, 4, 1, 6, 5, 8]
replay_buffer._size: [24900 24900 24900 24900 24900 24900 24900 24900 24900 24900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.606586933135986 0.0022346973419189453
train_time 6.610164403915405
2023-09-06 13:42:51,003 MainThread INFO: EPOCH:164
2023-09-06 13:42:51,004 MainThread INFO: Time Consumed:6.63142728805542s
2023-09-06 13:42:51,004 MainThread INFO: Total Frames:247500s
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 165/400 [11:49<27:14,  6.96s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               533.39052
Train_Epoch_Reward                    6163.25370
Running_Training_Average_Rewards      663.19458
Explore_Time                          0.00937
Train___Time                          6.61016
Eval____Time                          0.00720
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.81278
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.19425
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.89706
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.00811
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.05199
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.50008
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.12342
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6178.67396
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.67273
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -61.36556
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.09874     1.08992    9.11767     5.70526
alpha_0                               0.70607     0.00019    0.70637     0.70577
alpha_1                               0.62377     0.00051    0.62458     0.62297
alpha_2                               0.63290     0.00051    0.63369     0.63210
alpha_3                               0.63004     0.00047    0.63078     0.62931
alpha_4                               0.63264     0.00048    0.63339     0.63189
alpha_5                               0.63759     0.00048    0.63834     0.63682
alpha_6                               0.62468     0.00036    0.62525     0.62411
alpha_7                               0.64199     0.00054    0.64284     0.64113
alpha_8                               0.63036     0.00054    0.63121     0.62952
alpha_9                               0.62550     0.00049    0.62626     0.62474
Alpha_loss                            -2.20764    0.01684    -2.17885    -2.23540
Training/policy_loss                  -37.90480   0.10819    -37.68550   -38.10176
Training/qf1_loss                     1368.92189  538.64788  2475.71948  734.68359
Training/qf2_loss                     1366.94691  541.00983  2477.48730  728.89136
Training/pf_norm                      0.39877     0.06650    0.51539     0.30742
Training/qf1_norm                     502.72726   196.08604  855.57544   251.03668
Training/qf2_norm                     514.41071   193.25839  863.80359   267.79062
log_std/mean                          -0.30059    0.00114    -0.29937    -0.30260
log_std/std                           0.13301     0.00136    0.13468     0.13109
log_std/max                           -0.08927    0.00135    -0.08745    -0.09218
log_std/min                           -0.64857    0.00736    -0.63713    -0.65883
log_probs/mean                        -0.83010    0.03439    -0.77446    -0.89741
log_probs/std                         1.96823     0.04156    2.05650     1.92060
log_probs/max                         6.02728     0.23126    6.40153     5.65350
log_probs/min                         -7.31051    0.77465    -6.11265    -8.24840
mean/mean                             -0.15349    0.00379    -0.14904    -0.16017
mean/std                              0.80420     0.00134    0.80594     0.80240
mean/max                              1.60956     0.00948    1.62770     1.59537
mean/min                              -2.05067    0.01441    -2.02822    -2.06987
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 9, 4, 3, 0, 6, 8, 7, 2, 5]
replay_buffer._size: [25050 25050 25050 25050 25050 25050 25050 25050 25050 25050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.336168527603149 0.0021059513092041016
train_time 6.339586496353149
2023-09-06 13:42:57,519 MainThread INFO: EPOCH:165
2023-09-06 13:42:57,519 MainThread INFO: Time Consumed:6.36243748664856s
2023-09-06 13:42:57,519 MainThread INFO: Total Frames:249000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 166/400 [11:55<26:33,  6.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               550.09810
Train_Epoch_Reward                    5389.69812
Running_Training_Average_Rewards      584.45302
Explore_Time                          0.01481
Train___Time                          6.33959
Eval____Time                          0.00325
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.73281
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.93872
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.94471
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.07967
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.54762
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.25888
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.90489
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6385.06468
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.16580
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -64.55204
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.60399     1.05785    8.30155     4.94539
alpha_0                               0.70542     0.00018    0.70570     0.70513
alpha_1                               0.62198     0.00051    0.62279     0.62118
alpha_2                               0.63113     0.00051    0.63193     0.63033
alpha_3                               0.62842     0.00046    0.62915     0.62769
alpha_4                               0.63097     0.00048    0.63172     0.63021
alpha_5                               0.63589     0.00049    0.63665     0.63512
alpha_6                               0.62341     0.00036    0.62398     0.62285
alpha_7                               0.64008     0.00055    0.64094     0.63921
alpha_8                               0.62849     0.00054    0.62933     0.62764
alpha_9                               0.62381     0.00048    0.62457     0.62306
Alpha_loss                            -2.22656    0.02533    -2.18271    -2.26198
Training/policy_loss                  -38.16047   0.08014    -38.08734   -38.31937
Training/qf1_loss                     1113.10576  398.62152  1868.38513  686.20911
Training/qf2_loss                     1107.90961  397.26806  1864.08167  678.25037
Training/pf_norm                      0.41462     0.05729    0.50396     0.30331
Training/qf1_norm                     425.99593   185.46472  728.40588   134.52278
Training/qf2_norm                     438.23042   185.52807  741.04596   141.60930
log_std/mean                          -0.29859    0.00325    -0.29371    -0.30291
log_std/std                           0.13429     0.00077    0.13506     0.13297
log_std/max                           -0.09101    0.00050    -0.09006    -0.09175
log_std/min                           -0.65476    0.00926    -0.64141    -0.66741
log_probs/mean                        -0.84343    0.05256    -0.75053    -0.91505
log_probs/std                         1.95323     0.03479    1.99997     1.90156
log_probs/max                         5.84204     0.19314    6.14341     5.58476
log_probs/min                         -7.89085    0.79371    -6.96112    -9.29148
mean/mean                             -0.17041    0.00490    -0.16246    -0.17793
mean/std                              0.79551     0.00619    0.80464     0.78566
mean/max                              1.60080     0.02353    1.63430     1.56659
mean/min                              -2.05573    0.01959    -2.03034    -2.08481
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 9, 7, 8, 3, 0, 2, 6, 1, 5]
replay_buffer._size: [25200 25200 25200 25200 25200 25200 25200 25200 25200 25200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.596631050109863 0.002508878707885742
train_time 6.600500822067261
2023-09-06 13:43:04,335 MainThread INFO: EPOCH:166
2023-09-06 13:43:04,336 MainThread INFO: Time Consumed:6.629851579666138s
2023-09-06 13:43:04,336 MainThread INFO: Total Frames:250500s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 167/400 [12:02<26:27,  6.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               568.56408
Train_Epoch_Reward                    5996.88835
Running_Training_Average_Rewards      584.99467
Explore_Time                          0.02031
Train___Time                          6.60050
Eval____Time                          0.00387
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -102.69922
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -91.40178
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.07070
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.12027
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.34640
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.90341
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.30067
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6496.08356
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.34723
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -65.95909
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.19136     1.11594    9.80249     5.66258
alpha_0                               0.70473     0.00021    0.70506     0.70440
alpha_1                               0.62019     0.00052    0.62100     0.61938
alpha_2                               0.62935     0.00052    0.63015     0.62854
alpha_3                               0.62679     0.00047    0.62753     0.62605
alpha_4                               0.62927     0.00049    0.63004     0.62850
alpha_5                               0.63417     0.00050    0.63495     0.63339
alpha_6                               0.62217     0.00036    0.62272     0.62161
alpha_7                               0.63814     0.00056    0.63902     0.63726
alpha_8                               0.62662     0.00054    0.62746     0.62577
alpha_9                               0.62215     0.00047    0.62289     0.62142
Alpha_loss                            -2.26955    0.01558    -2.24637    -2.30100
Training/policy_loss                  -38.28224   0.06585    -38.19048   -38.39836
Training/qf1_loss                     1408.58864  617.55893  3012.77734  765.55939
Training/qf2_loss                     1405.41557  619.61835  3015.06201  761.55157
Training/pf_norm                      0.41301     0.06795    0.52216     0.30094
Training/qf1_norm                     538.76420   201.13864  1009.21857  266.66818
Training/qf2_norm                     548.06319   197.71206  1007.56586  275.06073
log_std/mean                          -0.29388    0.00087    -0.29273    -0.29519
log_std/std                           0.13199     0.00121    0.13305     0.12952
log_std/max                           -0.09049    0.00088    -0.08909    -0.09217
log_std/min                           -0.64153    0.00284    -0.63597    -0.64559
log_probs/mean                        -0.91572    0.03977    -0.86055    -0.99868
log_probs/std                         1.91094     0.03361    1.95868     1.84704
log_probs/max                         5.81344     0.10016    5.99763     5.63366
log_probs/min                         -7.09819    0.71786    -6.11284    -8.28568
mean/mean                             -0.18454    0.00220    -0.17984    -0.18671
mean/std                              0.77922     0.00289    0.78329     0.77376
mean/max                              1.56406     0.00561    1.57187     1.55338
mean/min                              -2.03166    0.00644    -2.01855    -2.04023
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 7, 8, 4, 5, 9, 6, 1, 0, 2]
replay_buffer._size: [25350 25350 25350 25350 25350 25350 25350 25350 25350 25350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.7706210613250732 0.0023140907287597656
train_time 3.774292230606079
2023-09-06 13:43:11,139 MainThread INFO: EPOCH:167
2023-09-06 13:43:11,140 MainThread INFO: Time Consumed:3.7962071895599365s
2023-09-06 13:43:11,140 MainThread INFO: Total Frames:252000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 168/400 [12:09<26:21,  6.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               584.02414
Train_Epoch_Reward                    6474.45213
Running_Training_Average_Rewards      595.36795
Explore_Time                          0.01300
Train___Time                          3.77429
Eval____Time                          0.00400
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.85174
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -92.91358
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.24328
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.04716
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.59409
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.35734
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.76812
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6660.21270
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.56463
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.02283
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.03084     1.65223    11.66338    5.68701
alpha_0                               0.70398     0.00023    0.70433     0.70362
alpha_1                               0.61840     0.00051    0.61921     0.61760
alpha_2                               0.62755     0.00052    0.62836     0.62673
alpha_3                               0.62514     0.00048    0.62589     0.62439
alpha_4                               0.62754     0.00050    0.62832     0.62676
alpha_5                               0.63242     0.00051    0.63321     0.63163
alpha_6                               0.62093     0.00035    0.62149     0.62038
alpha_7                               0.63617     0.00057    0.63706     0.63528
alpha_8                               0.62475     0.00054    0.62559     0.62391
alpha_9                               0.62052     0.00047    0.62125     0.61979
Alpha_loss                            -2.29359    0.01777    -2.26304    -2.32697
Training/policy_loss                  -38.55773   0.14239    -38.27549   -38.76028
Training/qf1_loss                     1307.62859  750.80466  3513.43433  732.10358
Training/qf2_loss                     1303.90391  751.84530  3511.22461  725.30463
Training/pf_norm                      0.43022     0.06838    0.52953     0.33388
Training/qf1_norm                     510.81121   302.38729  1354.53320  261.73254
Training/qf2_norm                     522.17823   298.20860  1354.23999  275.11682
log_std/mean                          -0.29868    0.00305    -0.29494    -0.30337
log_std/std                           0.13014     0.00096    0.13154     0.12900
log_std/max                           -0.09340    0.00152    -0.09131    -0.09591
log_std/min                           -0.62898    0.00334    -0.62389    -0.63578
log_probs/mean                        -0.94052    0.04567    -0.86372    -1.02537
log_probs/std                         1.91576     0.03252    1.96722     1.85484
log_probs/max                         5.63701     0.14992    5.88289     5.30052
log_probs/min                         -7.76534    0.59807    -6.88027    -9.11809
mean/mean                             -0.18983    0.00396    -0.18523    -0.19724
mean/std                              0.77213     0.00047    0.77273     0.77103
mean/max                              1.55179     0.00780    1.57273     1.54485
mean/min                              -2.02309    0.00825    -2.00949    -2.03906
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 5, 8, 4, 6, 7, 3, 1, 9, 0]
replay_buffer._size: [25500 25500 25500 25500 25500 25500 25500 25500 25500 25500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.203679323196411 0.0021200180053710938
train_time 6.2071146965026855
2023-09-06 13:43:17,515 MainThread INFO: EPOCH:168
2023-09-06 13:43:17,516 MainThread INFO: Time Consumed:6.221846342086792s
2023-09-06 13:43:17,516 MainThread INFO: Total Frames:253500s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 169/400 [12:16<25:46,  6.70s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               603.73765
Train_Epoch_Reward                    5941.56905
Running_Training_Average_Rewards      613.76365
Explore_Time                          0.00551
Train___Time                          6.20711
Eval____Time                          0.00459
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -104.98871
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -94.68615
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.25074
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.18041
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.29154
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.08565
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.15678
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6998.16517
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.77841
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -69.40190
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.48175     1.14993    9.36825     5.81745
alpha_0                               0.70317     0.00024    0.70354     0.70279
alpha_1                               0.61663     0.00051    0.61743     0.61583
alpha_2                               0.62574     0.00052    0.62655     0.62492
alpha_3                               0.62348     0.00047    0.62423     0.62274
alpha_4                               0.62580     0.00050    0.62659     0.62502
alpha_5                               0.63065     0.00051    0.63145     0.62984
alpha_6                               0.61971     0.00035    0.62026     0.61917
alpha_7                               0.63417     0.00058    0.63508     0.63327
alpha_8                               0.62289     0.00053    0.62372     0.62206
alpha_9                               0.61890     0.00046    0.61963     0.61817
Alpha_loss                            -2.31353    0.01912    -2.28007    -2.33276
Training/policy_loss                  -38.79905   0.11850    -38.60374   -38.96954
Training/qf1_loss                     1562.42413  476.34965  2335.72559  898.82123
Training/qf2_loss                     1556.23135  476.87020  2336.38867  890.30353
Training/pf_norm                      0.40255     0.08570    0.49857     0.27734
Training/qf1_norm                     597.60087   217.95665  968.57916   294.07544
Training/qf2_norm                     607.24151   214.35896  971.20282   305.47952
log_std/mean                          -0.30214    0.00108    -0.30013    -0.30334
log_std/std                           0.13049     0.00053    0.13145     0.12997
log_std/max                           -0.09572    0.00097    -0.09354    -0.09733
log_std/min                           -0.62569    0.00431    -0.62060    -0.63635
log_probs/mean                        -0.95854    0.03749    -0.90074    -0.99951
log_probs/std                         1.89740     0.03559    1.96818     1.84149
log_probs/max                         5.54479     0.14879    5.77416     5.31974
log_probs/min                         -7.42619    0.72544    -6.48480    -8.75106
mean/mean                             -0.20274    0.00196    -0.19845    -0.20449
mean/std                              0.76476     0.00211    0.76900     0.76285
mean/max                              1.55038     0.00971    1.56542     1.53791
mean/min                              -2.02423    0.00808    -2.01516    -2.04237
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 0, 3, 4, 8, 5, 7, 6, 2, 1]
replay_buffer._size: [25650 25650 25650 25650 25650 25650 25650 25650 25650 25650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.6787121295928955 0.002207040786743164
train_time 4.682268142700195
2023-09-06 13:43:24,272 MainThread INFO: EPOCH:169
2023-09-06 13:43:24,273 MainThread INFO: Time Consumed:6.363706827163696s
2023-09-06 13:43:24,273 MainThread INFO: Total Frames:255000s
 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 170/400 [12:22<25:40,  6.70s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               632.71974
Train_Epoch_Reward                    8725.21795
Running_Training_Average_Rewards      704.70797
Explore_Time                          1.67298
Train___Time                          4.68227
Eval____Time                          0.00315
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.49278
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -97.19442
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.17454
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.33268
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.56657
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.60946
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.43720
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7375.43677
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.97994
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.25167
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.42142     1.07189    9.21397     5.88513
alpha_0                               0.70231     0.00025    0.70270     0.70192
alpha_1                               0.61485     0.00051    0.61565     0.61406
alpha_2                               0.62391     0.00053    0.62473     0.62308
alpha_3                               0.62184     0.00047    0.62258     0.62110
alpha_4                               0.62405     0.00050    0.62484     0.62326
alpha_5                               0.62885     0.00052    0.62966     0.62805
alpha_6                               0.61852     0.00034    0.61905     0.61799
alpha_7                               0.63216     0.00058    0.63307     0.63125
alpha_8                               0.62105     0.00053    0.62188     0.62022
alpha_9                               0.61729     0.00046    0.61801     0.61657
Alpha_loss                            -2.32877    0.01624    -2.29549    -2.35005
Training/policy_loss                  -39.18120   0.11107    -38.97300   -39.33804
Training/qf1_loss                     1291.15442  385.09624  1903.54517  815.37463
Training/qf2_loss                     1284.69444  385.13262  1897.78210  812.00183
Training/pf_norm                      0.37577     0.06662    0.49062     0.27138
Training/qf1_norm                     585.86850   193.71719  897.12659   325.08469
Training/qf2_norm                     596.19614   190.92357  904.07532   335.52151
log_std/mean                          -0.29914    0.00046    -0.29857    -0.29998
log_std/std                           0.13100     0.00039    0.13153     0.13024
log_std/max                           -0.09322    0.00125    -0.09216    -0.09677
log_std/min                           -0.61937    0.00350    -0.61456    -0.62678
log_probs/mean                        -0.96109    0.03355    -0.88730    -1.00144
log_probs/std                         1.89978     0.01888    1.93319     1.87057
log_probs/max                         5.49739     0.17447    5.75562     5.08529
log_probs/min                         -7.30700    0.68547    -6.61760    -8.99115
mean/mean                             -0.20656    0.00280    -0.20391    -0.21240
mean/std                              0.76316     0.00134    0.76494     0.76086
mean/max                              1.59593     0.01644    1.62659     1.56929
mean/min                              -2.03989    0.00963    -2.02629    -2.06070
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 7, 5, 1, 6, 0, 3, 9, 2, 8]
replay_buffer._size: [25800 25800 25800 25800 25800 25800 25800 25800 25800 25800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.547402858734131 0.0021724700927734375
train_time 6.550917863845825
2023-09-06 13:43:31,000 MainThread INFO: EPOCH:170
2023-09-06 13:43:31,001 MainThread INFO: Time Consumed:6.565484523773193s
2023-09-06 13:43:31,001 MainThread INFO: Total Frames:256500s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 171/400 [12:29<25:36,  6.71s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               676.17027
Train_Epoch_Reward                    6495.88609
Running_Training_Average_Rewards      705.42244
Explore_Time                          0.00680
Train___Time                          6.55092
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -91.14277
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -98.43654
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.17825
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.34388
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.72663
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.77867
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.47569
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7956.06037
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.95220
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.66001
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.05476     0.81442    8.12208     5.75371
alpha_0                               0.70145     0.00024    0.70184     0.70107
alpha_1                               0.61308     0.00051    0.61388     0.61229
alpha_2                               0.62207     0.00053    0.62290     0.62125
alpha_3                               0.62019     0.00047    0.62093     0.61945
alpha_4                               0.62230     0.00050    0.62309     0.62152
alpha_5                               0.62706     0.00051    0.62787     0.62625
alpha_6                               0.61732     0.00035    0.61787     0.61678
alpha_7                               0.63013     0.00058    0.63105     0.62922
alpha_8                               0.61921     0.00053    0.62004     0.61839
alpha_9                               0.61569     0.00046    0.61641     0.61497
Alpha_loss                            -2.34673    0.02586    -2.30533    -2.40319
Training/policy_loss                  -39.55785   0.10841    -39.37188   -39.69226
Training/qf1_loss                     1301.89215  260.27977  1765.48755  894.05627
Training/qf2_loss                     1296.19980  261.38734  1755.99219  884.60052
Training/pf_norm                      0.43330     0.08409    0.59408     0.31620
Training/qf1_norm                     519.28717   154.46507  729.29230   266.50021
Training/qf2_norm                     531.19293   153.20462  738.11383   283.24527
log_std/mean                          -0.30051    0.00086    -0.29887    -0.30147
log_std/std                           0.13200     0.00034    0.13250     0.13149
log_std/max                           -0.10300    0.00407    -0.09619    -0.10896
log_std/min                           -0.61397    0.00235    -0.61113    -0.61853
log_probs/mean                        -0.96802    0.05114    -0.88806    -1.07366
log_probs/std                         1.89580     0.03044    1.94532     1.85642
log_probs/max                         5.51122     0.16716    5.79104     5.25816
log_probs/min                         -7.67168    1.26249    -6.36213    -10.23226
mean/mean                             -0.22545    0.00653    -0.21457    -0.23469
mean/std                              0.75295     0.00471    0.75956     0.74473
mean/max                              1.59308     0.01343    1.61066     1.57444
mean/min                              -2.03798    0.00777    -2.02800    -2.05192
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 2, 6, 3, 7, 1, 8, 0, 4, 9]
replay_buffer._size: [25950 25950 25950 25950 25950 25950 25950 25950 25950 25950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.9432008266448975 0.002199411392211914
train_time 3.946746587753296
2023-09-06 13:43:37,884 MainThread INFO: EPOCH:171
2023-09-06 13:43:37,884 MainThread INFO: Time Consumed:4.450967788696289s
2023-09-06 13:43:37,884 MainThread INFO: Total Frames:258000s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 172/400 [12:36<25:42,  6.76s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               712.38439
Train_Epoch_Reward                    10249.86344
Running_Training_Average_Rewards      849.03225
Explore_Time                          0.49687
Train___Time                          3.94675
Eval____Time                          0.00307
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.52791
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -97.88891
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.16957
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.16719
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.38570
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.29942
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.17867
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8053.45239
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.71472
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.35196
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.94153      0.79774    8.10017     5.90225
alpha_0                               0.70058      0.00026    0.70098     0.70018
alpha_1                               0.61131      0.00051    0.61211     0.61052
alpha_2                               0.62023      0.00053    0.62106     0.61940
alpha_3                               0.61853      0.00048    0.61928     0.61778
alpha_4                               0.62055      0.00051    0.62134     0.61976
alpha_5                               0.62526      0.00052    0.62607     0.62445
alpha_6                               0.61612      0.00034    0.61666     0.61559
alpha_7                               0.62809      0.00059    0.62901     0.62717
alpha_8                               0.61738      0.00053    0.61821     0.61656
alpha_9                               0.61410      0.00045    0.61481     0.61339
Alpha_loss                            -2.37787     0.01017    -2.35956    -2.39717
Training/policy_loss                  -39.90753    0.09402    -39.72771   -40.04023
Training/qf1_loss                     1139.20454   192.63232  1374.18250  683.31134
Training/qf2_loss                     1133.91848   193.71500  1368.22656  674.23871
Training/pf_norm                      0.37387      0.05529    0.44679     0.26507
Training/qf1_norm                     490.45707    149.60323  715.27197   304.32291
Training/qf2_norm                     502.84811    148.13742  731.53326   321.41599
log_std/mean                          -0.29767     0.00148    -0.29589    -0.30005
log_std/std                           0.13183      0.00021    0.13206     0.13150
log_std/max                           -0.10481     0.00195    -0.10156    -0.10780
log_std/min                           -0.60873     0.00284    -0.60532    -0.61572
log_probs/mean                        -1.01048     0.01793    -0.97947    -1.03930
log_probs/std                         1.88085      0.04125    1.94275     1.79537
log_probs/max                         5.37334      0.13934    5.62941     5.10666
log_probs/min                         -7.15040     0.42827    -6.24094    -7.74344
mean/mean                             -0.24187     0.00320    -0.23649    -0.24700
mean/std                              0.73858      0.00340    0.74390     0.73325
mean/max                              1.55330      0.01185    1.58473     1.54383
mean/min                              -2.02005     0.00987    -2.01202    -2.04602
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 6, 4, 5, 9, 0, 3, 7, 1, 8]
replay_buffer._size: [26100 26100 26100 26100 26100 26100 26100 26100 26100 26100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.135233640670776 0.002112865447998047
train_time 7.138646602630615
2023-09-06 13:43:45,205 MainThread INFO: EPOCH:172
2023-09-06 13:43:45,206 MainThread INFO: Time Consumed:7.152447700500488s
2023-09-06 13:43:45,206 MainThread INFO: Total Frames:259500s
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 173/400 [12:43<26:12,  6.93s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               731.70591
Train_Epoch_Reward                    8910.57618
Running_Training_Average_Rewards      855.21086
Explore_Time                          0.00609
Train___Time                          7.13865
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.37604
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -99.68399
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.30723
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.94032
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.55799
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.53063
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.99341
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7925.20593
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.49968
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.27333
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.61024     1.14654    8.42739     4.83988
alpha_0                               0.69966     0.00027    0.70009     0.69923
alpha_1                               0.60954     0.00051    0.61034     0.60875
alpha_2                               0.61838     0.00054    0.61922     0.61754
alpha_3                               0.61687     0.00048    0.61762     0.61612
alpha_4                               0.61878     0.00051    0.61958     0.61799
alpha_5                               0.62344     0.00052    0.62426     0.62262
alpha_6                               0.61494     0.00034    0.61547     0.61441
alpha_7                               0.62603     0.00059    0.62696     0.62510
alpha_8                               0.61557     0.00052    0.61638     0.61476
alpha_9                               0.61253     0.00044    0.61323     0.61184
Alpha_loss                            -2.39659    0.02267    -2.36553    -2.43582
Training/policy_loss                  -40.13932   0.07276    -40.02153   -40.25787
Training/qf1_loss                     1103.65628  318.84791  1764.86133  697.28265
Training/qf2_loss                     1097.92949  319.14882  1759.25232  691.49744
Training/pf_norm                      0.38634     0.05792    0.49758     0.29431
Training/qf1_norm                     433.51090   223.51863  801.92517   97.52243
Training/qf2_norm                     443.99037   224.60629  812.17236   95.63416
log_std/mean                          -0.29836    0.00140    -0.29671    -0.30120
log_std/std                           0.13306     0.00048    0.13393     0.13241
log_std/max                           -0.10691    0.00252    -0.10381    -0.11165
log_std/min                           -0.61644    0.00544    -0.60986    -0.62547
log_probs/mean                        -1.02293    0.04379    -0.96606    -1.09638
log_probs/std                         1.86856     0.03588    1.90843     1.78011
log_probs/max                         5.31737     0.12013    5.56139     5.16111
log_probs/min                         -6.93015    0.68983    -5.72108    -8.08443
mean/mean                             -0.24892    0.00033    -0.24824    -0.24941
mean/std                              0.72952     0.00190    0.73296     0.72740
mean/max                              1.55563     0.00761    1.57361     1.54373
mean/min                              -2.02221    0.00918    -2.00481    -2.04011
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 2, 3, 5, 0, 9, 8, 1, 7, 6]
replay_buffer._size: [26250 26250 26250 26250 26250 26250 26250 26250 26250 26250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.387605667114258 0.0024416446685791016
train_time 4.391379356384277
2023-09-06 13:43:51,735 MainThread INFO: EPOCH:173
2023-09-06 13:43:51,736 MainThread INFO: Time Consumed:6.3767805099487305s
2023-09-06 13:43:51,736 MainThread INFO: Total Frames:261000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 174/400 [12:50<25:41,  6.82s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               728.56599
Train_Epoch_Reward                    8111.70819
Running_Training_Average_Rewards      909.07159
Explore_Time                          1.97539
Train___Time                          4.39138
Eval____Time                          0.00491
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.99289
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -100.47559
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.30913
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.76270
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.54407
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.19605
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.72845
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7845.30023
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.09852
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.02485
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.63557     0.60524    8.71170     6.82203
alpha_0                               0.69871     0.00027    0.69914     0.69827
alpha_1                               0.60778     0.00050    0.60857     0.60699
alpha_2                               0.61651     0.00054    0.61735     0.61567
alpha_3                               0.61519     0.00049    0.61595     0.61442
alpha_4                               0.61701     0.00051    0.61781     0.61621
alpha_5                               0.62162     0.00053    0.62244     0.62079
alpha_6                               0.61376     0.00034    0.61429     0.61323
alpha_7                               0.62396     0.00060    0.62489     0.62302
alpha_8                               0.61377     0.00051    0.61458     0.61297
alpha_9                               0.61099     0.00044    0.61168     0.61030
Alpha_loss                            -2.41502    0.02043    -2.39230    -2.46249
Training/policy_loss                  -40.35058   0.11442    -40.10431   -40.47184
Training/qf1_loss                     1375.43891  378.00716  2282.49780  993.85590
Training/qf2_loss                     1368.52778  377.28316  2270.54565  984.17346
Training/pf_norm                      0.41029     0.06838    0.55398     0.29765
Training/qf1_norm                     632.70469   111.98278  826.22675   467.21365
Training/qf2_norm                     641.59543   110.10204  833.71191   477.67499
log_std/mean                          -0.30165    0.00061    -0.30042    -0.30245
log_std/std                           0.13386     0.00039    0.13423     0.13315
log_std/max                           -0.11450    0.00182    -0.11099    -0.11671
log_std/min                           -0.62163    0.00286    -0.61761    -0.62658
log_probs/mean                        -1.03310    0.04005    -0.98528    -1.12867
log_probs/std                         1.86010     0.04458    1.94543     1.79650
log_probs/max                         5.28466     0.14024    5.44714     5.08005
log_probs/min                         -6.85727    0.44682    -6.21176    -7.49161
mean/mean                             -0.24436    0.00370    -0.23780    -0.24859
mean/std                              0.72446     0.00231    0.72739     0.72062
mean/max                              1.54866     0.00503    1.55735     1.54193
mean/min                              -2.01499    0.01187    -1.99725    -2.03030
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 3, 6, 5, 8, 2, 9, 1, 4, 7]
replay_buffer._size: [26400 26400 26400 26400 26400 26400 26400 26400 26400 26400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.85378098487854 0.002193450927734375
train_time 6.857271909713745
2023-09-06 13:43:58,785 MainThread INFO: EPOCH:174
2023-09-06 13:43:58,785 MainThread INFO: Time Consumed:6.890048027038574s
2023-09-06 13:43:58,785 MainThread INFO: Total Frames:262500s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 175/400 [12:57<25:46,  6.87s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               732.01780
Train_Epoch_Reward                    9577.13574
Running_Training_Average_Rewards      886.64734
Explore_Time                          0.02357
Train___Time                          6.85727
Eval____Time                          0.00329
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.42682
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -100.91004
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.24467
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.89637
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.21460
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.62148
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.83404
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8150.06923
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.85757
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -69.74107
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.24098     0.80612    8.56631     6.30380
alpha_0                               0.69770     0.00030    0.69817     0.69723
alpha_1                               0.60603     0.00050    0.60681     0.60525
alpha_2                               0.61464     0.00054    0.61548     0.61380
alpha_3                               0.61349     0.00049    0.61426     0.61272
alpha_4                               0.61523     0.00051    0.61603     0.61443
alpha_5                               0.61977     0.00053    0.62061     0.61893
alpha_6                               0.61259     0.00034    0.61312     0.61206
alpha_7                               0.62187     0.00060    0.62281     0.62093
alpha_8                               0.61199     0.00051    0.61279     0.61119
alpha_9                               0.60946     0.00044    0.61015     0.60877
Alpha_loss                            -2.44521    0.01267    -2.41872    -2.46275
Training/policy_loss                  -40.78564   0.12642    -40.59564   -40.99107
Training/qf1_loss                     1389.83951  401.00345  2289.35303  934.23553
Training/qf2_loss                     1383.78033  399.69007  2280.12671  930.97504
Training/pf_norm                      0.39609     0.07850    0.53573     0.28680
Training/qf1_norm                     550.66295   159.81993  822.47107   370.98447
Training/qf2_norm                     558.90566   156.92378  826.07568   382.74301
log_std/mean                          -0.30296    0.00175    -0.30041    -0.30532
log_std/std                           0.13463     0.00062    0.13536     0.13343
log_std/max                           -0.11695    0.00167    -0.11402    -0.11924
log_std/min                           -0.63464    0.01047    -0.62143    -0.64969
log_probs/mean                        -1.06869    0.03315    -1.02049    -1.11798
log_probs/std                         1.85702     0.03645    1.91347     1.80695
log_probs/max                         5.12131     0.12205    5.28396     4.92756
log_probs/min                         -7.32031    0.89127    -6.07786    -8.66087
mean/mean                             -0.23125    0.00324    -0.22564    -0.23644
mean/std                              0.72448     0.00251    0.72782     0.72076
mean/max                              1.56586     0.01608    1.59332     1.54375
mean/min                              -2.02160    0.01737    -1.99719    -2.05009
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 8, 9, 3, 7, 1, 4, 0, 5, 2]
replay_buffer._size: [26550 26550 26550 26550 26550 26550 26550 26550 26550 26550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.8170084953308105 0.0021810531616210938
train_time 6.820618152618408
2023-09-06 13:44:05,818 MainThread INFO: EPOCH:175
2023-09-06 13:44:05,819 MainThread INFO: Time Consumed:6.849504709243774s
2023-09-06 13:44:05,819 MainThread INFO: Total Frames:264000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 176/400 [13:04<25:50,  6.92s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               780.31477
Train_Epoch_Reward                    10512.44444
Running_Training_Average_Rewards      940.04295
Explore_Time                          0.01960
Train___Time                          6.82062
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -100.51551
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.07956
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.12949
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.25085
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.78430
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.10958
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.28524
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9411.18685
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.85411
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.22557
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.74017      0.82470    9.43451     6.51189
alpha_0                               0.69669      0.00028    0.69713     0.69627
alpha_1                               0.60429      0.00050    0.60507     0.60351
alpha_2                               0.61277      0.00054    0.61362     0.61193
alpha_3                               0.61178      0.00049    0.61255     0.61100
alpha_4                               0.61345      0.00051    0.61425     0.61266
alpha_5                               0.61790      0.00054    0.61875     0.61706
alpha_6                               0.61141      0.00034    0.61194     0.61087
alpha_7                               0.61978      0.00060    0.62072     0.61884
alpha_8                               0.61022      0.00051    0.61102     0.60942
alpha_9                               0.60793      0.00044    0.60862     0.60724
Alpha_loss                            -2.46127     0.02158    -2.41638    -2.49054
Training/policy_loss                  -41.16537    0.13504    -40.99137   -41.37912
Training/qf1_loss                     1603.06819   376.77888  2159.15796  935.10840
Training/qf2_loss                     1594.74031   375.68713  2149.22607  928.40039
Training/pf_norm                      0.41371      0.07764    0.57614     0.31626
Training/qf1_norm                     646.74894    163.77132  974.13635   396.89651
Training/qf2_norm                     654.83526    162.50091  982.33911   407.48749
log_std/mean                          -0.30310     0.00144    -0.30088    -0.30506
log_std/std                           0.13652      0.00055    0.13702     0.13532
log_std/max                           -0.11179     0.00207    -0.10971    -0.11543
log_std/min                           -0.65541     0.00445    -0.64909    -0.66467
log_probs/mean                        -1.06507     0.04793    -0.97282    -1.14051
log_probs/std                         1.89271      0.02979    1.93953     1.85317
log_probs/max                         5.17345      0.11995    5.34481     4.96291
log_probs/min                         -7.90290     1.26724    -6.38576    -10.46352
mean/mean                             -0.22402     0.00045    -0.22302    -0.22455
mean/std                              0.72635      0.00179    0.72823     0.72258
mean/max                              1.59066      0.00853    1.60909     1.58125
mean/min                              -2.05407     0.01021    -2.04446    -2.07690
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 1, 4, 6, 9, 7, 0, 8, 5, 2]
replay_buffer._size: [26700 26700 26700 26700 26700 26700 26700 26700 26700 26700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.179715633392334 0.002126455307006836
train_time 4.183155536651611
2023-09-06 13:44:12,984 MainThread INFO: EPOCH:176
2023-09-06 13:44:12,984 MainThread INFO: Time Consumed:4.468661308288574s
2023-09-06 13:44:12,984 MainThread INFO: Total Frames:265500s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 177/400 [13:11<26:00,  7.00s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               869.99414
Train_Epoch_Reward                    10521.00802
Running_Training_Average_Rewards      1020.35294
Explore_Time                          0.27785
Train___Time                          4.18316
Eval____Time                          0.00323
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.25700
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.51755
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.30952
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.50235
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.57022
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.09477
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.57810
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10573.69524
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -93.00804
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -70.30865
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.25865      1.00102    8.71632     5.47702
alpha_0                               0.69575      0.00027    0.69617     0.69532
alpha_1                               0.60255      0.00050    0.60333     0.60178
alpha_2                               0.61089      0.00054    0.61174     0.61004
alpha_3                               0.61006      0.00049    0.61083     0.60928
alpha_4                               0.61168      0.00051    0.61248     0.61088
alpha_5                               0.61603      0.00054    0.61687     0.61519
alpha_6                               0.61020      0.00035    0.61075     0.60965
alpha_7                               0.61770      0.00060    0.61863     0.61676
alpha_8                               0.60845      0.00051    0.60925     0.60765
alpha_9                               0.60639      0.00044    0.60708     0.60570
Alpha_loss                            -2.49591     0.01883    -2.47037    -2.52777
Training/policy_loss                  -41.60217    0.11575    -41.43473   -41.79219
Training/qf1_loss                     1274.34453   435.45357  2042.29724  641.50433
Training/qf2_loss                     1266.74078   436.02250  2036.76526  631.70746
Training/pf_norm                      0.37934      0.03900    0.44972     0.32534
Training/qf1_norm                     555.36077    197.43505  833.05444   215.09633
Training/qf2_norm                     563.05471    195.55931  837.68878   223.00928
log_std/mean                          -0.29928     0.00074    -0.29827    -0.30068
log_std/std                           0.13625      0.00027    0.13671     0.13580
log_std/max                           -0.10905     0.00112    -0.10671    -0.11043
log_std/min                           -0.63850     0.00741    -0.62821    -0.64983
log_probs/mean                        -1.10978     0.03514    -1.06620    -1.17043
log_probs/std                         1.86904      0.04197    1.96241     1.81398
log_probs/max                         5.10593      0.12594    5.37794     4.91918
log_probs/min                         -7.51341     0.92695    -5.77950    -8.73660
mean/mean                             -0.22192     0.00163    -0.22032    -0.22553
mean/std                              0.71574      0.00364    0.72185     0.71055
mean/max                              1.58444      0.00960    1.60343     1.57110
mean/min                              -2.02104     0.01741    -1.99511    -2.05086
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 4, 6, 9, 0, 8, 5, 3, 2, 1]
replay_buffer._size: [26850 26850 26850 26850 26850 26850 26850 26850 26850 26850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.119809627532959 0.0020935535430908203
train_time 7.123203754425049
2023-09-06 13:44:20,265 MainThread INFO: EPOCH:177
2023-09-06 13:44:20,265 MainThread INFO: Time Consumed:7.136507272720337s
2023-09-06 13:44:20,265 MainThread INFO: Total Frames:267000s
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 178/400 [13:18<26:12,  7.08s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               972.49155
Train_Epoch_Reward                    9812.08808
Running_Training_Average_Rewards      1028.18468
Explore_Time                          0.00428
Train___Time                          7.12320
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -103.65789
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.16657
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.26920
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.49941
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.96945
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.94326
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.49130
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11278.08903
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.86541
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -69.98170
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.39189      0.94084    9.09250     6.32511
alpha_0                               0.69477      0.00029    0.69522     0.69433
alpha_1                               0.60083      0.00049    0.60161     0.60005
alpha_2                               0.60900      0.00054    0.60986     0.60815
alpha_3                               0.60833      0.00050    0.60911     0.60755
alpha_4                               0.60991      0.00051    0.61070     0.60911
alpha_5                               0.61416      0.00054    0.61500     0.61332
alpha_6                               0.60899      0.00035    0.60953     0.60844
alpha_7                               0.61560      0.00060    0.61655     0.61466
alpha_8                               0.60667      0.00051    0.60747     0.60587
alpha_9                               0.60485      0.00044    0.60554     0.60417
Alpha_loss                            -2.51845     0.02318    -2.48730    -2.55801
Training/policy_loss                  -42.00312    0.11713    -41.84331   -42.13755
Training/qf1_loss                     1455.21534   309.86262  2002.67114  1012.85870
Training/qf2_loss                     1448.29766   310.58713  1994.68945  1001.17609
Training/pf_norm                      0.36294      0.06266    0.47039     0.24303
Training/qf1_norm                     562.87752    185.79918  893.86035   334.82376
Training/qf2_norm                     569.67835    184.71733  900.27429   340.86914
log_std/mean                          -0.30344     0.00211    -0.30055    -0.30615
log_std/std                           0.13751      0.00033    0.13794     0.13707
log_std/max                           -0.11395     0.00260    -0.10995    -0.11723
log_std/min                           -0.63366     0.00369    -0.62937    -0.64178
log_probs/mean                        -1.12852     0.04469    -1.06784    -1.21476
log_probs/std                         1.86302      0.03067    1.91186     1.81694
log_probs/max                         5.04372      0.21128    5.24363     4.44528
log_probs/min                         -7.84297     1.69108    -6.25448    -11.38131
mean/mean                             -0.22737     0.00058    -0.22648    -0.22815
mean/std                              0.70962      0.00041    0.71063     0.70904
mean/max                              1.59738      0.01466    1.62514     1.58320
mean/min                              -2.00719     0.01040    -1.99437    -2.02857
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 5, 0, 9, 6, 2, 8, 1, 7, 4]
replay_buffer._size: [27000 27000 27000 27000 27000 27000 27000 27000 27000 27000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.566720724105835 0.0021119117736816406
train_time 4.570161819458008
2023-09-06 13:44:27,001 MainThread INFO: EPOCH:178
2023-09-06 13:44:27,002 MainThread INFO: Time Consumed:6.568121671676636s
2023-09-06 13:44:27,003 MainThread INFO: Total Frames:268500s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 179/400 [13:25<25:41,  6.98s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1044.84674
Train_Epoch_Reward                    11397.92297
Running_Training_Average_Rewards      1057.70064
Explore_Time                          1.98969
Train___Time                          4.57016
Eval____Time                          0.00367
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -90.59196
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.23412
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.23462
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.28637
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.34892
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.29711
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.05226
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11574.28811
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.40768
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -69.22663
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.61281      0.80555    8.82681     6.22558
alpha_0                               0.69379      0.00028    0.69423     0.69335
alpha_1                               0.59910      0.00050    0.59988     0.59833
alpha_2                               0.60711      0.00054    0.60796     0.60626
alpha_3                               0.60659      0.00050    0.60737     0.60581
alpha_4                               0.60813      0.00051    0.60893     0.60732
alpha_5                               0.61230      0.00053    0.61313     0.61146
alpha_6                               0.60777      0.00034    0.60832     0.60724
alpha_7                               0.61350      0.00061    0.61445     0.61255
alpha_8                               0.60489      0.00051    0.60569     0.60409
alpha_9                               0.60333      0.00044    0.60401     0.60264
Alpha_loss                            -2.52883     0.01035    -2.51246    -2.54437
Training/policy_loss                  -42.35749    0.11430    -42.15566   -42.48422
Training/qf1_loss                     1558.72273   289.16650  1863.15710  921.52307
Training/qf2_loss                     1553.62567   288.69997  1863.89685  919.99481
Training/pf_norm                      0.33836      0.05276    0.39376     0.25430
Training/qf1_norm                     599.43699    167.31458  848.19354   316.33008
Training/qf2_norm                     607.57537    164.76810  852.93170   328.09955
log_std/mean                          -0.30634     0.00021    -0.30590    -0.30662
log_std/std                           0.13827      0.00014    0.13858     0.13804
log_std/max                           -0.12140     0.00137    -0.11811    -0.12289
log_std/min                           -0.63745     0.00382    -0.63086    -0.64461
log_probs/mean                        -1.11508     0.02106    -1.08953    -1.15310
log_probs/std                         1.88404      0.03393    1.95620     1.83877
log_probs/max                         5.25142      0.11019    5.42082     5.05852
log_probs/min                         -7.13171     0.79110    -5.96115    -8.74751
mean/mean                             -0.22705     0.00051    -0.22629    -0.22814
mean/std                              0.70880      0.00145    0.71033     0.70565
mean/max                              1.63739      0.00725    1.65321     1.62866
mean/min                              -2.03733     0.00709    -2.02821    -2.05248
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 3, 6, 4, 0, 5, 8, 9, 2, 1]
replay_buffer._size: [27150 27150 27150 27150 27150 27150 27150 27150 27150 27150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.354842662811279 0.0021545886993408203
train_time 7.3583385944366455
2023-09-06 13:44:34,558 MainThread INFO: EPOCH:179
2023-09-06 13:44:34,559 MainThread INFO: Time Consumed:7.375103950500488s
2023-09-06 13:44:34,559 MainThread INFO: Total Frames:270000s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 180/400 [13:33<26:13,  7.15s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1082.62827
Train_Epoch_Reward                    12676.88199
Running_Training_Average_Rewards      1129.56310
Explore_Time                          0.00769
Train___Time                          7.35834
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.90557
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.42781
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.22873
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.15423
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.24724
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.81835
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.65924
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11708.02901
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -92.05313
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -68.53999
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.07026      0.91653    8.35999     5.36616
alpha_0                               0.69283      0.00027    0.69326     0.69240
alpha_1                               0.59737      0.00050    0.59815     0.59659
alpha_2                               0.60522      0.00054    0.60607     0.60437
alpha_3                               0.60485      0.00050    0.60564     0.60406
alpha_4                               0.60635      0.00051    0.60715     0.60554
alpha_5                               0.61043      0.00054    0.61127     0.60959
alpha_6                               0.60658      0.00035    0.60712     0.60603
alpha_7                               0.61139      0.00060    0.61234     0.61044
alpha_8                               0.60311      0.00051    0.60391     0.60230
alpha_9                               0.60179      0.00044    0.60248     0.60109
Alpha_loss                            -2.57225     0.02734    -2.52978    -2.60176
Training/policy_loss                  -42.69644    0.08084    -42.54665   -42.81076
Training/qf1_loss                     1378.66008   418.38466  1989.83105  647.22382
Training/qf2_loss                     1371.68954   418.17910  1977.28406  639.98444
Training/pf_norm                      0.41188      0.05525    0.51779     0.34488
Training/qf1_norm                     502.45439    177.59728  782.55255   178.96786
Training/qf2_norm                     510.58064    176.39961  788.04877   190.19989
log_std/mean                          -0.30231     0.00158    -0.30068    -0.30529
log_std/std                           0.14039      0.00154    0.14347     0.13835
log_std/max                           -0.11475     0.00365    -0.11012    -0.12090
log_std/min                           -0.63801     0.00425    -0.63205    -0.64623
log_probs/mean                        -1.17422     0.04878    -1.10398    -1.22370
log_probs/std                         1.87761      0.03693    1.92665     1.80840
log_probs/max                         5.18492      0.14432    5.34980     4.85026
log_probs/min                         -7.22698     0.68025    -6.16403    -8.37191
mean/mean                             -0.22924     0.00157    -0.22771    -0.23255
mean/std                              0.69843      0.00326    0.70423     0.69479
mean/max                              1.60923      0.01560    1.63016     1.58720
mean/min                              -2.03268     0.00597    -2.01927    -2.04040
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 7, 5, 0, 3, 4, 6, 8, 9, 2]
replay_buffer._size: [27300 27300 27300 27300 27300 27300 27300 27300 27300 27300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.74074912071228 0.0021469593048095703
train_time 6.744292736053467
2023-09-06 13:44:41,494 MainThread INFO: EPOCH:180
2023-09-06 13:44:41,494 MainThread INFO: Time Consumed:6.761414289474487s
2023-09-06 13:44:41,495 MainThread INFO: Total Frames:271500s
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 181/400 [13:39<25:52,  7.09s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1098.31223
Train_Epoch_Reward                    10789.38325
Running_Training_Average_Rewards      1162.13961
Explore_Time                          0.00734
Train___Time                          6.74429
Eval____Time                          0.00382
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.38786
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.68899
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.98011
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.99653
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.58847
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.93655
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.23336
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11724.87788
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -91.66065
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.64160
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.55378      1.19579    9.89168     5.82936
alpha_0                               0.69187      0.00028    0.69230     0.69143
alpha_1                               0.59564      0.00050    0.59642     0.59485
alpha_2                               0.60333      0.00054    0.60418     0.60248
alpha_3                               0.60310      0.00050    0.60389     0.60231
alpha_4                               0.60455      0.00051    0.60536     0.60375
alpha_5                               0.60857      0.00054    0.60941     0.60773
alpha_6                               0.60537      0.00035    0.60591     0.60483
alpha_7                               0.60929      0.00060    0.61023     0.60834
alpha_8                               0.60132      0.00051    0.60212     0.60052
alpha_9                               0.60025      0.00044    0.60094     0.59956
Alpha_loss                            -2.57227     0.01311    -2.54545    -2.58805
Training/policy_loss                  -43.04139    0.12949    -42.83588   -43.22414
Training/qf1_loss                     1458.56070   440.28923  2329.83984  784.14758
Training/qf2_loss                     1450.54441   438.57776  2316.36768  779.08270
Training/pf_norm                      0.40622      0.08474    0.54592     0.25771
Training/qf1_norm                     595.15135    249.11859  1089.32666  236.41068
Training/qf2_norm                     599.01046    247.62293  1085.30969  237.78458
log_std/mean                          -0.30332     0.00159    -0.30114    -0.30577
log_std/std                           0.14633      0.00082    0.14711     0.14445
log_std/max                           -0.11070     0.00090    -0.10909    -0.11223
log_std/min                           -0.65371     0.00372    -0.64680    -0.65892
log_probs/mean                        -1.14592     0.02588    -1.09590    -1.18838
log_probs/std                         1.88567      0.03623    1.95843     1.83389
log_probs/max                         5.10781      0.15215    5.23569     4.68190
log_probs/min                         -7.52033     1.73144    -5.97622    -12.33657
mean/mean                             -0.23530     0.00093    -0.23319    -0.23640
mean/std                              0.69605      0.00026    0.69645     0.69564
mean/max                              1.56374      0.01060    1.57966     1.54872
mean/min                              -2.03546     0.00587    -2.02438    -2.04649
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 6, 3, 2, 5, 0, 9, 1, 7, 8]
replay_buffer._size: [27450 27450 27450 27450 27450 27450 27450 27450 27450 27450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.626099109649658 0.002203226089477539
train_time 6.629634857177734
2023-09-06 13:44:48,311 MainThread INFO: EPOCH:181
2023-09-06 13:44:48,312 MainThread INFO: Time Consumed:6.656523704528809s
2023-09-06 13:44:48,312 MainThread INFO: Total Frames:273000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 182/400 [13:46<25:27,  7.01s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1113.96594
Train_Epoch_Reward                    10231.93906
Running_Training_Average_Rewards      1123.27348
Explore_Time                          0.01180
Train___Time                          6.62963
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.25074
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.13238
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.72715
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.98208
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.43077
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.95101
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.05312
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12037.33528
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -91.39592
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.19237
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.10479      0.81026    7.98840     5.23578
alpha_0                               0.69089      0.00029    0.69134     0.69043
alpha_1                               0.59390      0.00050    0.59468     0.59312
alpha_2                               0.60144      0.00054    0.60229     0.60059
alpha_3                               0.60134      0.00051    0.60213     0.60054
alpha_4                               0.60276      0.00051    0.60357     0.60196
alpha_5                               0.60669      0.00054    0.60754     0.60584
alpha_6                               0.60417      0.00034    0.60471     0.60363
alpha_7                               0.60719      0.00060    0.60813     0.60624
alpha_8                               0.59954      0.00051    0.60034     0.59874
alpha_9                               0.59873      0.00043    0.59941     0.59806
Alpha_loss                            -2.60161     0.01561    -2.56682    -2.62251
Training/policy_loss                  -43.37452    0.10643    -43.20390   -43.54017
Training/qf1_loss                     1364.49130   351.04932  1835.49890  744.73248
Training/qf2_loss                     1354.74684   349.23898  1823.33435  740.46216
Training/pf_norm                      0.37468      0.11080    0.69296     0.29059
Training/qf1_norm                     503.96748    161.02011  703.30920   157.70236
Training/qf2_norm                     508.95332    160.99797  708.28430   160.77071
log_std/mean                          -0.30512     0.00090    -0.30346    -0.30633
log_std/std                           0.14616      0.00034    0.14705     0.14587
log_std/max                           -0.11211     0.00076    -0.11097    -0.11339
log_std/min                           -0.64947     0.00293    -0.64536    -0.65573
log_probs/mean                        -1.17836     0.03034    -1.11383    -1.21975
log_probs/std                         1.87066      0.02800    1.92514     1.82891
log_probs/max                         5.06504      0.10780    5.24993     4.88474
log_probs/min                         -7.14333     0.81843    -6.01870    -8.93661
mean/mean                             -0.22899     0.00229    -0.22673    -0.23375
mean/std                              0.69401      0.00097    0.69642     0.69306
mean/max                              1.56099      0.00850    1.57691     1.55118
mean/min                              -2.02806     0.00672    -2.01702    -2.03927
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 9, 0, 1, 4, 3, 2, 6, 8, 5]
replay_buffer._size: [27600 27600 27600 27600 27600 27600 27600 27600 27600 27600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.192053318023682 0.0021812915802001953
train_time 7.195572853088379
2023-09-06 13:44:55,725 MainThread INFO: EPOCH:182
2023-09-06 13:44:55,725 MainThread INFO: Time Consumed:7.218883514404297s
2023-09-06 13:44:55,726 MainThread INFO: Total Frames:274500s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 183/400 [13:54<25:47,  7.13s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1150.22412
Train_Epoch_Reward                    12989.85460
Running_Training_Average_Rewards      1133.70590
Explore_Time                          0.00967
Train___Time                          7.19557
Eval____Time                          0.00455
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.64126
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.69667
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.81128
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.22970
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.04576
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.18935
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.41672
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12790.86895
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -91.30321
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.79482
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.05008      1.15605    9.39632     5.41577
alpha_0                               0.68987      0.00029    0.69032     0.68941
alpha_1                               0.59217      0.00050    0.59295     0.59139
alpha_2                               0.59955      0.00054    0.60040     0.59871
alpha_3                               0.59956      0.00051    0.60036     0.59876
alpha_4                               0.60097      0.00052    0.60178     0.60016
alpha_5                               0.60480      0.00054    0.60566     0.60395
alpha_6                               0.60298      0.00034    0.60351     0.60244
alpha_7                               0.60509      0.00060    0.60603     0.60415
alpha_8                               0.59777      0.00051    0.59857     0.59698
alpha_9                               0.59723      0.00043    0.59791     0.59655
Alpha_loss                            -2.63112     0.01784    -2.59543    -2.64731
Training/policy_loss                  -43.64190    0.05469    -43.52661   -43.69443
Training/qf1_loss                     1414.83372   555.77948  2545.75708  676.63928
Training/qf2_loss                     1406.67053   554.86798  2534.96045  672.43915
Training/pf_norm                      0.40953      0.05740    0.48800     0.30822
Training/qf1_norm                     490.74014    242.90672  999.57983   166.40280
Training/qf2_norm                     495.06158    242.67378  998.34930   170.20146
log_std/mean                          -0.30056     0.00142    -0.29888    -0.30323
log_std/std                           0.14611      0.00017    0.14644     0.14583
log_std/max                           -0.11220     0.00126    -0.10964    -0.11356
log_std/min                           -0.64861     0.00122    -0.64669    -0.65140
log_probs/mean                        -1.20186     0.03444    -1.13981    -1.23656
log_probs/std                         1.88190      0.04568    1.98106     1.82851
log_probs/max                         5.18605      0.14563    5.40685     4.95959
log_probs/min                         -7.01937     0.84690    -5.93651    -8.54728
mean/mean                             -0.22729     0.00135    -0.22620    -0.23031
mean/std                              0.68927      0.00249    0.69338     0.68471
mean/max                              1.59048      0.00841    1.60533     1.57855
mean/min                              -2.04021     0.00737    -2.03290    -2.05335
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 7, 4, 5, 6, 9, 0, 8, 3, 1]
replay_buffer._size: [27750 27750 27750 27750 27750 27750 27750 27750 27750 27750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.162786960601807 0.0024526119232177734
train_time 7.166548490524292
2023-09-06 13:45:03,100 MainThread INFO: EPOCH:183
2023-09-06 13:45:03,100 MainThread INFO: Time Consumed:7.190670728683472s
2023-09-06 13:45:03,101 MainThread INFO: Total Frames:276000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 184/400 [14:01<25:55,  7.20s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1202.36370
Train_Epoch_Reward                    12257.17507
Running_Training_Average_Rewards      1182.63229
Explore_Time                          0.01550
Train___Time                          7.16655
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.95260
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -102.34898
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.67630
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.14864
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.10643
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -89.28234
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.36845
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13302.29377
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -90.82548
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -67.63349
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.43223      0.88603    9.13787     6.10604
alpha_0                               0.68886      0.00029    0.68931     0.68840
alpha_1                               0.59044      0.00050    0.59122     0.58966
alpha_2                               0.59767      0.00054    0.59852     0.59682
alpha_3                               0.59779      0.00051    0.59859     0.59699
alpha_4                               0.59917      0.00052    0.59998     0.59836
alpha_5                               0.60291      0.00054    0.60376     0.60205
alpha_6                               0.60177      0.00035    0.60232     0.60122
alpha_7                               0.60300      0.00060    0.60394     0.60205
alpha_8                               0.59600      0.00051    0.59680     0.59521
alpha_9                               0.59572      0.00043    0.59640     0.59504
Alpha_loss                            -2.66121     0.01562    -2.61938    -2.67656
Training/policy_loss                  -43.90035    0.07585    -43.76937   -44.03696
Training/qf1_loss                     1581.71567   511.33971  2615.66284  965.67816
Training/qf2_loss                     1575.34488   510.63330  2616.40894  960.78070
Training/pf_norm                      0.42865      0.07145    0.51834     0.26448
Training/qf1_norm                     575.09427    191.89920  944.78290   282.86749
Training/qf2_norm                     577.47970    190.50380  948.53925   286.94360
log_std/mean                          -0.29705     0.00099    -0.29582    -0.29869
log_std/std                           0.14468      0.00107    0.14615     0.14331
log_std/max                           -0.11027     0.00103    -0.10859    -0.11193
log_std/min                           -0.63783     0.00658    -0.62734    -0.64670
log_probs/mean                        -1.23505     0.02842    -1.15885    -1.26196
log_probs/std                         1.84387      0.03255    1.89524     1.77959
log_probs/max                         5.12330      0.19543    5.38478     4.77355
log_probs/min                         -7.36227     1.36555    -5.85701    -10.58402
mean/mean                             -0.23447     0.00151    -0.23168    -0.23669
mean/std                              0.67415      0.00585    0.68333     0.66553
mean/max                              1.58699      0.01208    1.60802     1.56984
mean/min                              -2.02171     0.01888    -1.99347    -2.05070
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 2, 1, 9, 0, 8, 4, 5, 3, 7]
replay_buffer._size: [27900 27900 27900 27900 27900 27900 27900 27900 27900 27900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.358577251434326 0.002088308334350586
train_time 7.362200736999512
2023-09-06 13:45:10,654 MainThread INFO: EPOCH:184
2023-09-06 13:45:10,654 MainThread INFO: Time Consumed:7.3911004066467285s
2023-09-06 13:45:10,655 MainThread INFO: Total Frames:277500s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 185/400 [14:09<26:10,  7.31s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1248.93712
Train_Epoch_Reward                    12508.49333
Running_Training_Average_Rewards      1258.51743
Explore_Time                          0.01688
Train___Time                          7.36220
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -96.43537
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -101.90576
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.51048
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.03950
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.76743
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.12994
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.88519
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13438.38735
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -90.09221
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -66.19926
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.76996      0.51896    7.62063     5.71545
alpha_0                               0.68782      0.00031    0.68830     0.68734
alpha_1                               0.58871      0.00050    0.58949     0.58793
alpha_2                               0.59577      0.00055    0.59663     0.59491
alpha_3                               0.59600      0.00051    0.59681     0.59520
alpha_4                               0.59736      0.00052    0.59818     0.59654
alpha_5                               0.60101      0.00055    0.60187     0.60015
alpha_6                               0.60054      0.00036    0.60110     0.59998
alpha_7                               0.60090      0.00060    0.60184     0.59996
alpha_8                               0.59423      0.00051    0.59503     0.59343
alpha_9                               0.59422      0.00043    0.59489     0.59354
Alpha_loss                            -2.71523     0.01702    -2.68283    -2.73724
Training/policy_loss                  -44.27239    0.11172    -44.07305   -44.47561
Training/qf1_loss                     1277.86018   277.43107  1844.51074  787.52454
Training/qf2_loss                     1269.82010   277.87240  1837.23828  779.29242
Training/pf_norm                      0.39972      0.06705    0.56462     0.32424
Training/qf1_norm                     423.02570    110.09398  633.72748   208.57886
Training/qf2_norm                     426.51668    109.73822  634.54999   210.63583
log_std/mean                          -0.29757     0.00112    -0.29660    -0.29964
log_std/std                           0.14401      0.00078    0.14548     0.14317
log_std/max                           -0.10874     0.00115    -0.10711    -0.11122
log_std/min                           -0.63083     0.00501    -0.62362    -0.63974
log_probs/mean                        -1.31433     0.02745    -1.26221    -1.34473
log_probs/std                         1.83526      0.02582    1.86676     1.78624
log_probs/max                         5.05607      0.14361    5.29648     4.78447
log_probs/min                         -7.66470     0.50834    -6.40072    -8.22290
mean/mean                             -0.23858     0.00102    -0.23707    -0.24005
mean/std                              0.65868      0.00254    0.66387     0.65625
mean/max                              1.56937      0.00776    1.58441     1.55665
mean/min                              -1.98776     0.00826    -1.97511    -1.99975
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 6, 5, 1, 0, 4, 2, 7, 9, 3]
replay_buffer._size: [28050 28050 28050 28050 28050 28050 28050 28050 28050 28050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.038355827331543 0.0023488998413085938
train_time 7.04207706451416
2023-09-06 13:45:17,906 MainThread INFO: EPOCH:185
2023-09-06 13:45:17,906 MainThread INFO: Time Consumed:7.066111326217651s
2023-09-06 13:45:17,907 MainThread INFO: Total Frames:279000s
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 186/400 [14:16<25:59,  7.29s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1272.82404
Train_Epoch_Reward                    14589.67153
Running_Training_Average_Rewards      1311.84466
Explore_Time                          0.01565
Train___Time                          7.04208
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.04106
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -100.94245
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.95350
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.68494
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.96468
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.05239
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.96549
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13482.98876
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -88.15837
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.87789
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.23280      1.03890    8.97505     5.54895
alpha_0                               0.68673      0.00031    0.68723     0.68625
alpha_1                               0.58698      0.00050    0.58776     0.58620
alpha_2                               0.59386      0.00055    0.59472     0.59299
alpha_3                               0.59421      0.00052    0.59502     0.59339
alpha_4                               0.59554      0.00052    0.59636     0.59472
alpha_5                               0.59910      0.00055    0.59996     0.59824
alpha_6                               0.59929      0.00036    0.59985     0.59872
alpha_7                               0.59881      0.00060    0.59975     0.59786
alpha_8                               0.59246      0.00051    0.59326     0.59167
alpha_9                               0.59272      0.00043    0.59339     0.59204
Alpha_loss                            -2.72383     0.01701    -2.69211    -2.75043
Training/policy_loss                  -44.55451    0.07834    -44.43109   -44.70787
Training/qf1_loss                     1457.60939   511.49101  2245.53320  785.24506
Training/qf2_loss                     1450.15529   511.90250  2236.52002  780.09253
Training/pf_norm                      0.41409      0.03675    0.48672     0.37379
Training/qf1_norm                     532.59303    225.87291  923.94019   174.24258
Training/qf2_norm                     534.56578    223.15495  914.59924   172.68826
log_std/mean                          -0.30312     0.00121    -0.30041    -0.30449
log_std/std                           0.14810      0.00105    0.14952     0.14590
log_std/max                           -0.11006     0.00096    -0.10865    -0.11195
log_std/min                           -0.65956     0.00899    -0.64736    -0.67654
log_probs/mean                        -1.29792     0.03979    -1.23900    -1.36958
log_probs/std                         1.83514      0.02302    1.87612     1.79047
log_probs/max                         5.09646      0.17212    5.43473     4.89784
log_probs/min                         -6.81806     0.66953    -6.09962    -8.18911
mean/mean                             -0.24373     0.00219    -0.24043    -0.24710
mean/std                              0.65833      0.00108    0.65960     0.65612
mean/max                              1.58120      0.00581    1.59018     1.56947
mean/min                              -2.01869     0.00921    -1.99929    -2.03123
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 0, 4, 1, 2, 5, 7, 9, 8, 6]
replay_buffer._size: [28200 28200 28200 28200 28200 28200 28200 28200 28200 28200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.190981149673462 0.0022149085998535156
train_time 7.194546937942505
2023-09-06 13:45:25,306 MainThread INFO: EPOCH:186
2023-09-06 13:45:25,307 MainThread INFO: Time Consumed:7.214114189147949s
2023-09-06 13:45:25,307 MainThread INFO: Total Frames:280500s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 187/400 [14:23<25:59,  7.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1282.95107
Train_Epoch_Reward                    12300.53447
Running_Training_Average_Rewards      1313.28998
Explore_Time                          0.00875
Train___Time                          7.19455
Eval____Time                          0.00585
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -97.66082
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -100.05533
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.20206
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.46654
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.11268
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.76681
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.51901
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13569.20019
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -86.45052
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -62.20442
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.25034      1.00998    9.00206     5.64314
alpha_0                               0.68567      0.00030    0.68614     0.68520
alpha_1                               0.58525      0.00050    0.58603     0.58447
alpha_2                               0.59194      0.00055    0.59280     0.59107
alpha_3                               0.59240      0.00052    0.59322     0.59159
alpha_4                               0.59371      0.00053    0.59453     0.59288
alpha_5                               0.59718      0.00055    0.59804     0.59632
alpha_6                               0.59803      0.00036    0.59860     0.59746
alpha_7                               0.59672      0.00060    0.59766     0.59578
alpha_8                               0.59071      0.00050    0.59149     0.58992
alpha_9                               0.59122      0.00043    0.59189     0.59054
Alpha_loss                            -2.75105     0.03033    -2.71009    -2.80645
Training/policy_loss                  -44.91785    0.09053    -44.73147   -45.04796
Training/qf1_loss                     1485.60424   565.07392  2804.92163  799.56366
Training/qf2_loss                     1476.80881   566.87458  2799.57666  790.32715
Training/pf_norm                      0.43198      0.04265    0.51231     0.37937
Training/qf1_norm                     538.01391    222.68405  952.09619   206.45322
Training/qf2_norm                     540.01413    219.71732  953.40900   212.29247
log_std/mean                          -0.29720     0.00327    -0.29258    -0.30232
log_std/std                           0.14965      0.00020    0.14997     0.14935
log_std/max                           -0.10694     0.00172    -0.10419    -0.10984
log_std/min                           -0.67113     0.00445    -0.66228    -0.67939
log_probs/mean                        -1.31737     0.05278    -1.24513    -1.41445
log_probs/std                         1.84545      0.03319    1.92038     1.81037
log_probs/max                         5.04155      0.23186    5.26477     4.50052
log_probs/min                         -7.00365     0.52683    -6.26090    -8.00238
mean/mean                             -0.24693     0.00069    -0.24593    -0.24795
mean/std                              0.64971      0.00435    0.65596     0.64308
mean/max                              1.57468      0.01617    1.59770     1.54635
mean/min                              -2.02027     0.01585    -1.99344    -2.04351
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 4, 6, 3, 0, 2, 5, 7, 1, 8]
replay_buffer._size: [28350 28350 28350 28350 28350 28350 28350 28350 28350 28350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.031584739685059 0.002207040786743164
train_time 7.035130023956299
2023-09-06 13:45:32,582 MainThread INFO: EPOCH:187
2023-09-06 13:45:32,583 MainThread INFO: Time Consumed:7.084993124008179s
2023-09-06 13:45:32,583 MainThread INFO: Total Frames:282000s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 188/400 [14:31<25:52,  7.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1290.38127
Train_Epoch_Reward                    11909.81887
Running_Training_Average_Rewards      1293.33416
Explore_Time                          0.03491
Train___Time                          7.03513
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.41610
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -99.63551
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.29165
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.38374
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.81606
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.25262
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -80.42534
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13618.28630
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -85.44418
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -61.29311
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.22969      0.99112    10.10024    6.52959
alpha_0                               0.68461      0.00032    0.68510     0.68411
alpha_1                               0.58352      0.00050    0.58430     0.58274
alpha_2                               0.59001      0.00055    0.59088     0.58915
alpha_3                               0.59059      0.00052    0.59141     0.58977
alpha_4                               0.59186      0.00053    0.59270     0.59102
alpha_5                               0.59526      0.00055    0.59613     0.59439
alpha_6                               0.59676      0.00037    0.59733     0.59618
alpha_7                               0.59463      0.00060    0.59557     0.59370
alpha_8                               0.58897      0.00050    0.58975     0.58819
alpha_9                               0.58972      0.00043    0.59039     0.58905
Alpha_loss                            -2.78584     0.01346    -2.76077    -2.81338
Training/policy_loss                  -45.23406    0.13167    -44.96027   -45.43409
Training/qf1_loss                     1413.07710   291.60956  1944.81799  974.92590
Training/qf2_loss                     1404.97561   290.80784  1928.99512  969.52441
Training/pf_norm                      0.41216      0.05007    0.50431     0.33105
Training/qf1_norm                     531.56708    224.89572  1187.61230  378.59860
Training/qf2_norm                     531.28227    222.73346  1179.82092  378.30133
log_std/mean                          -0.29160     0.00037    -0.29111    -0.29218
log_std/std                           0.15017      0.00078    0.15137     0.14907
log_std/max                           -0.10168     0.00237    -0.09827    -0.10424
log_std/min                           -0.68421     0.01321    -0.66621    -0.70500
log_probs/mean                        -1.36025     0.02963    -1.32124    -1.42913
log_probs/std                         1.81411      0.02534    1.85279     1.77741
log_probs/max                         5.06722      0.08581    5.20631     4.85832
log_probs/min                         -7.32472     1.01376    -5.82342    -9.76494
mean/mean                             -0.24758     0.00066    -0.24633    -0.24841
mean/std                              0.63886      0.00167    0.64191     0.63580
mean/max                              1.53198      0.00681    1.54424     1.52033
mean/min                              -1.99508     0.00778    -1.98557    -2.01117
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 5, 9, 3, 2, 6, 8, 1, 4, 0]
replay_buffer._size: [28500 28500 28500 28500 28500 28500 28500 28500 28500 28500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.340453863143921 0.002086162567138672
train_time 7.34384560585022
2023-09-06 13:45:40,120 MainThread INFO: EPOCH:188
2023-09-06 13:45:40,121 MainThread INFO: Time Consumed:7.3595123291015625s
2023-09-06 13:45:40,121 MainThread INFO: Total Frames:283500s
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 189/400 [14:38<25:59,  7.39s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1293.61898
Train_Epoch_Reward                    12522.80518
Running_Training_Average_Rewards      1224.43862
Explore_Time                          0.00565
Train___Time                          7.34385
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.92207
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -98.03417
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.26607
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.97177
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.84231
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.09843
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.87949
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13562.25494
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.02251
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.73873
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.39806      0.75651    8.38680     6.11087
alpha_0                               0.68351      0.00031    0.68400     0.68302
alpha_1                               0.58180      0.00049    0.58257     0.58103
alpha_2                               0.58809      0.00055    0.58896     0.58722
alpha_3                               0.58877      0.00052    0.58959     0.58795
alpha_4                               0.59000      0.00053    0.59084     0.58916
alpha_5                               0.59332      0.00056    0.59419     0.59245
alpha_6                               0.59547      0.00038    0.59605     0.59488
alpha_7                               0.59256      0.00059    0.59349     0.59164
alpha_8                               0.58724      0.00050    0.58802     0.58646
alpha_9                               0.58822      0.00043    0.58890     0.58755
Alpha_loss                            -2.80813     0.02087    -2.76829    -2.83809
Training/policy_loss                  -45.60449    0.15044    -45.37307   -45.83881
Training/qf1_loss                     1514.82676   316.58364  1954.73535  938.64160
Training/qf2_loss                     1505.20188   315.46094  1944.11292  929.18213
Training/pf_norm                      0.44620      0.09872    0.67280     0.29906
Training/qf1_norm                     567.74825    173.78496  783.83813   268.26614
Training/qf2_norm                     565.82439    173.14562  782.59625   265.74112
log_std/mean                          -0.29618     0.00223    -0.29258    -0.29895
log_std/std                           0.15189      0.00046    0.15239     0.15092
log_std/max                           -0.10492     0.00326    -0.09975    -0.10956
log_std/min                           -0.71165     0.00762    -0.69995    -0.72279
log_probs/mean                        -1.36797     0.04116    -1.28923    -1.43399
log_probs/std                         1.82442      0.02100    1.85394     1.78758
log_probs/max                         5.09426      0.14959    5.34837     4.88552
log_probs/min                         -6.65742     0.69149    -5.92068    -8.49799
mean/mean                             -0.24132     0.00412    -0.23354    -0.24572
mean/std                              0.63274      0.00140    0.63537     0.63046
mean/max                              1.56996      0.01654    1.60054     1.54844
mean/min                              -2.01180     0.00669    -1.99912    -2.02121
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 3, 8, 5, 0, 4, 7, 1, 6, 9]
replay_buffer._size: [28650 28650 28650 28650 28650 28650 28650 28650 28650 28650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.750407457351685 0.0021228790283203125
train_time 6.753846645355225
2023-09-06 13:45:47,280 MainThread INFO: EPOCH:189
2023-09-06 13:45:47,280 MainThread INFO: Time Consumed:6.782205581665039s
2023-09-06 13:45:47,281 MainThread INFO: Total Frames:285000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 190/400 [14:45<25:36,  7.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1287.52676
Train_Epoch_Reward                    12703.24716
Running_Training_Average_Rewards      1237.86237
Explore_Time                          0.00627
Train___Time                          6.75385
Eval____Time                          0.00728
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.60834
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -96.93035
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -58.26782
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.11751
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.00345
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.48242
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.52080
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13400.24150
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -81.64039
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -58.67501
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.08543      1.22586    9.15379     4.87669
alpha_0                               0.68243      0.00031    0.68292     0.68194
alpha_1                               0.58008      0.00050    0.58086     0.57930
alpha_2                               0.58617      0.00055    0.58703     0.58531
alpha_3                               0.58695      0.00053    0.58777     0.58612
alpha_4                               0.58814      0.00053    0.58898     0.58731
alpha_5                               0.59138      0.00055    0.59225     0.59052
alpha_6                               0.59415      0.00038    0.59475     0.59355
alpha_7                               0.59051      0.00059    0.59143     0.58959
alpha_8                               0.58551      0.00050    0.58629     0.58473
alpha_9                               0.58671      0.00044    0.58740     0.58603
Alpha_loss                            -2.84628     0.01626    -2.82307    -2.87607
Training/policy_loss                  -46.05956    0.12237    -45.85610   -46.23425
Training/qf1_loss                     1198.64720   391.79069  2021.46375  651.52148
Training/qf2_loss                     1190.47472   391.42774  2012.11060  642.07080
Training/pf_norm                      0.41242      0.03785    0.48267     0.36929
Training/qf1_norm                     493.38426    248.96135  939.77924   110.37435
Training/qf2_norm                     491.71865    252.19955  937.80151   92.92916
log_std/mean                          -0.30250     0.00184    -0.29962    -0.30493
log_std/std                           0.15014      0.00039    0.15099     0.14965
log_std/max                           -0.11499     0.00195    -0.11095    -0.11783
log_std/min                           -0.72244     0.00753    -0.70938    -0.73457
log_probs/mean                        -1.41100     0.03767    -1.35115    -1.48139
log_probs/std                         1.79959      0.03245    1.84790     1.74505
log_probs/max                         5.25956      0.19012    5.55837     4.86578
log_probs/min                         -7.14760     0.85400    -6.34296    -8.93829
mean/mean                             -0.22710     0.00260    -0.22351    -0.23186
mean/std                              0.63131      0.00126    0.63418     0.63011
mean/max                              1.60573      0.00679    1.61832     1.59482
mean/min                              -2.00444     0.00601    -1.98939    -2.01151
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 8, 7, 0, 1, 2, 6, 9, 4, 3]
replay_buffer._size: [28800 28800 28800 28800 28800 28800 28800 28800 28800 28800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.033446788787842 0.002122640609741211
train_time 4.0368945598602295
2023-09-06 13:45:54,438 MainThread INFO: EPOCH:190
2023-09-06 13:45:54,439 MainThread INFO: Time Consumed:4.0545361042022705s
2023-09-06 13:45:54,439 MainThread INFO: Total Frames:286500s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 191/400 [14:52<25:19,  7.27s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1270.36591
Train_Epoch_Reward                    12458.62464
Running_Training_Average_Rewards      1256.15590
Explore_Time                          0.01001
Train___Time                          4.03689
Eval____Time                          0.00315
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.98680
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -95.28154
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.90599
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.76141
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.38115
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.13818
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -79.01288
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13127.00683
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.71512
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -57.32139
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.05158      0.87729    8.44737     5.61950
alpha_0                               0.68136      0.00030    0.68183     0.68089
alpha_1                               0.57835      0.00050    0.57913     0.57757
alpha_2                               0.58425      0.00055    0.58511     0.58339
alpha_3                               0.58511      0.00053    0.58594     0.58429
alpha_4                               0.58629      0.00053    0.58712     0.58545
alpha_5                               0.58945      0.00055    0.59032     0.58858
alpha_6                               0.59283      0.00038    0.59342     0.59223
alpha_7                               0.58846      0.00058    0.58938     0.58755
alpha_8                               0.58378      0.00050    0.58456     0.58301
alpha_9                               0.58519      0.00044    0.58587     0.58451
Alpha_loss                            -2.85136     0.01826    -2.82556    -2.88026
Training/policy_loss                  -46.29736    0.11965    -46.07459   -46.51970
Training/qf1_loss                     1418.78232   352.88744  1985.28711  809.81293
Training/qf2_loss                     1409.31725   350.77245  1974.29297  803.18579
Training/pf_norm                      0.40368      0.04582    0.46545     0.33473
Training/qf1_norm                     487.54563    199.33183  793.95984   146.43990
Training/qf2_norm                     486.49144    199.88539  791.90021   144.40451
log_std/mean                          -0.30028     0.00402    -0.29358    -0.30486
log_std/std                           0.15192      0.00032    0.15219     0.15116
log_std/max                           -0.10839     0.00426    -0.10344    -0.11498
log_std/min                           -0.73022     0.00679    -0.71705    -0.74116
log_probs/mean                        -1.38564     0.03214    -1.33653    -1.43497
log_probs/std                         1.82028      0.04183    1.89166     1.76089
log_probs/max                         5.43801      0.24848    5.74336     5.00030
log_probs/min                         -6.29792     0.42648    -5.68514    -7.01194
mean/mean                             -0.22010     0.00171    -0.21773    -0.22260
mean/std                              0.63223      0.00211    0.63494     0.62847
mean/max                              1.62860      0.00616    1.63875     1.62056
mean/min                              -2.01862     0.00505    -2.01304    -2.02901
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 6, 4, 3, 1, 7, 2, 8, 5, 9]
replay_buffer._size: [28950 28950 28950 28950 28950 28950 28950 28950 28950 28950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.7445409297943115 0.0022177696228027344
train_time 6.748103618621826
2023-09-06 13:46:01,378 MainThread INFO: EPOCH:191
2023-09-06 13:46:01,378 MainThread INFO: Time Consumed:6.760988473892212s
2023-09-06 13:46:01,378 MainThread INFO: Total Frames:288000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 192/400 [14:59<24:50,  7.17s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1238.30726
Train_Epoch_Reward                    12536.63637
Running_Training_Average_Rewards      1256.61694
Explore_Time                          0.00435
Train___Time                          6.74810
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.97831
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -94.14049
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.38614
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.04547
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.28185
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.34004
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.88295
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12610.98601
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -77.84121
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.36957
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.90915      0.75013    8.10479     6.01478
alpha_0                               0.68032      0.00030    0.68079     0.67986
alpha_1                               0.57661      0.00050    0.57739     0.57583
alpha_2                               0.58233      0.00055    0.58320     0.58147
alpha_3                               0.58328      0.00053    0.58411     0.58246
alpha_4                               0.58443      0.00053    0.58526     0.58359
alpha_5                               0.58752      0.00056    0.58839     0.58665
alpha_6                               0.59150      0.00039    0.59210     0.59089
alpha_7                               0.58644      0.00058    0.58735     0.58553
alpha_8                               0.58206      0.00049    0.58283     0.58129
alpha_9                               0.58367      0.00044    0.58436     0.58297
Alpha_loss                            -2.89464     0.01896    -2.86338    -2.92524
Training/policy_loss                  -46.52906    0.10399    -46.35644   -46.74524
Training/qf1_loss                     1375.32383   282.99260  2009.43677  1000.60596
Training/qf2_loss                     1366.15205   283.97280  2002.23535  990.99872
Training/pf_norm                      0.41701      0.07028    0.57380     0.32808
Training/qf1_norm                     455.68957    175.58936  741.50928   242.41241
Training/qf2_norm                     455.30179    175.48837  737.48578   240.68950
log_std/mean                          -0.29081     0.00081    -0.28981    -0.29214
log_std/std                           0.15384      0.00093    0.15514     0.15242
log_std/max                           -0.10167     0.00190    -0.09939    -0.10483
log_std/min                           -0.74536     0.01227    -0.72265    -0.76294
log_probs/mean                        -1.43511     0.03689    -1.36368    -1.48316
log_probs/std                         1.83314      0.03247    1.88090     1.77505
log_probs/max                         5.41369      0.16994    5.75375     5.07571
log_probs/min                         -6.94421     0.86559    -5.59686    -9.05103
mean/mean                             -0.22142     0.00294    -0.21780    -0.22621
mean/std                              0.62638      0.00085    0.62785     0.62466
mean/max                              1.62965      0.00774    1.64070     1.61393
mean/min                              -2.02784     0.00666    -2.01175    -2.03301
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 1, 3, 4, 8, 7, 9, 0, 2, 6]
replay_buffer._size: [29100 29100 29100 29100 29100 29100 29100 29100 29100 29100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.471635103225708 0.0025119781494140625
train_time 7.475497484207153
2023-09-06 13:46:09,034 MainThread INFO: EPOCH:192
2023-09-06 13:46:09,035 MainThread INFO: Time Consumed:7.492556810379028s
2023-09-06 13:46:09,035 MainThread INFO: Total Frames:289500s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 193/400 [15:07<25:13,  7.31s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1198.86095
Train_Epoch_Reward                    13205.89612
Running_Training_Average_Rewards      1273.37190
Explore_Time                          0.00807
Train___Time                          7.47550
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.71915
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -92.58791
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -57.11963
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.12074
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.84874
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.08236
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.56589
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12204.88491
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.93574
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.29864
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.83958      1.16591    9.94323     6.33886
alpha_0                               0.67929      0.00030    0.67976     0.67881
alpha_1                               0.57487      0.00050    0.57565     0.57409
alpha_2                               0.58041      0.00055    0.58128     0.57955
alpha_3                               0.58145      0.00053    0.58227     0.58062
alpha_4                               0.58256      0.00054    0.58340     0.58171
alpha_5                               0.58559      0.00055    0.58646     0.58473
alpha_6                               0.59015      0.00039    0.59076     0.58954
alpha_7                               0.58443      0.00058    0.58533     0.58353
alpha_8                               0.58034      0.00049    0.58111     0.57957
alpha_9                               0.58212      0.00044    0.58282     0.58143
Alpha_loss                            -2.91900     0.01174    -2.89485    -2.93309
Training/policy_loss                  -46.88188    0.15352    -46.64045   -47.12413
Training/qf1_loss                     1773.61294   614.62817  3187.57983  1153.26855
Training/qf2_loss                     1765.18885   615.31204  3181.16406  1145.78833
Training/pf_norm                      0.42085      0.05951    0.51960     0.34402
Training/qf1_norm                     662.35367    265.10043  1143.82654  323.07907
Training/qf2_norm                     660.74871    260.24452  1135.88135  329.40378
log_std/mean                          -0.29530     0.00165    -0.29283    -0.29810
log_std/std                           0.15475      0.00030    0.15519     0.15438
log_std/max                           -0.10482     0.00109    -0.10356    -0.10771
log_std/min                           -0.77197     0.01159    -0.75432    -0.78787
log_probs/mean                        -1.45519     0.01869    -1.42293    -1.47891
log_probs/std                         1.79327      0.02237    1.82264     1.74347
log_probs/max                         5.19947      0.30521    5.76990     4.76882
log_probs/min                         -6.69467     0.52765    -5.94465    -7.59509
mean/mean                             -0.22954     0.00105    -0.22744    -0.23053
mean/std                              0.62153      0.00161    0.62401     0.61916
mean/max                              1.59035      0.00898    1.60868     1.57736
mean/min                              -2.01466     0.00591    -2.00249    -2.02628
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 0, 9, 8, 6, 2, 4, 1, 3, 5]
replay_buffer._size: [29250 29250 29250 29250 29250 29250 29250 29250 29250 29250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.04057240486145 0.002267122268676758
train_time 4.044158935546875
2023-09-06 13:46:16,391 MainThread INFO: EPOCH:193
2023-09-06 13:46:16,392 MainThread INFO: Time Consumed:4.2513110637664795s
2023-09-06 13:46:16,392 MainThread INFO: Total Frames:291000s
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 194/400 [15:14<25:08,  7.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1153.72326
Train_Epoch_Reward                    11145.75849
Running_Training_Average_Rewards      1229.60970
Explore_Time                          0.19879
Train___Time                          4.04416
Eval____Time                          0.00323
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.82859
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.66053
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.96268
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.54380
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.89582
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.45170
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -78.13677
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11753.49665
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.02997
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.61516
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.01425      0.99614    8.84687     5.58696
alpha_0                               0.67823      0.00030    0.67870     0.67775
alpha_1                               0.57314      0.00050    0.57392     0.57236
alpha_2                               0.57850      0.00055    0.57936     0.57764
alpha_3                               0.57961      0.00053    0.58044     0.57878
alpha_4                               0.58068      0.00054    0.58153     0.57984
alpha_5                               0.58366      0.00055    0.58453     0.58280
alpha_6                               0.58879      0.00040    0.58940     0.58816
alpha_7                               0.58243      0.00057    0.58333     0.58154
alpha_8                               0.57863      0.00049    0.57940     0.57787
alpha_9                               0.58057      0.00045    0.58127     0.57987
Alpha_loss                            -2.94918     0.01483    -2.92594    -2.96858
Training/policy_loss                  -47.31013    0.14325    -47.11682   -47.51446
Training/qf1_loss                     1266.66115   292.07860  1786.45239  701.32147
Training/qf2_loss                     1258.22628   291.98020  1776.06348  696.49200
Training/pf_norm                      0.43720      0.06460    0.55041     0.32037
Training/qf1_norm                     467.68635    232.13753  921.80237   178.43269
Training/qf2_norm                     465.10116    230.49648  914.22504   175.03973
log_std/mean                          -0.30061     0.00139    -0.29839    -0.30264
log_std/std                           0.15457      0.00036    0.15520     0.15404
log_std/max                           -0.11339     0.00360    -0.10666    -0.11831
log_std/min                           -0.78845     0.01059    -0.77215    -0.80647
log_probs/mean                        -1.47791     0.02537    -1.44475    -1.51919
log_probs/std                         1.82001      0.01218    1.84392     1.80522
log_probs/max                         5.32524      0.13701    5.59397     5.11813
log_probs/min                         -6.83222     0.79669    -5.36415    -7.96418
mean/mean                             -0.22691     0.00233    -0.22240    -0.22973
mean/std                              0.61474      0.00217    0.61864     0.61168
mean/max                              1.59418      0.00638    1.60590     1.58659
mean/min                              -2.00740     0.00235    -2.00297    -2.01166
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 0, 2, 6, 5, 1, 4, 8, 3, 9]
replay_buffer._size: [29400 29400 29400 29400 29400 29400 29400 29400 29400 29400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 6.931509494781494 0.002106189727783203
train_time 6.934911012649536
2023-09-06 13:46:23,514 MainThread INFO: EPOCH:194
2023-09-06 13:46:23,514 MainThread INFO: Time Consumed:6.946937084197998s
2023-09-06 13:46:23,515 MainThread INFO: Total Frames:292500s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 195/400 [15:21<24:48,  7.26s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1110.78061
Train_Epoch_Reward                    11744.57817
Running_Training_Average_Rewards      1203.20776
Explore_Time                          0.00455
Train___Time                          6.93491
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.94978
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.35695
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.43004
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.42161
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.48384
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.62290
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -77.22797
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11313.94082
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.72166
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.28550
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.02321      1.38184    9.85738     5.42023
alpha_0                               0.67717      0.00030    0.67764     0.67671
alpha_1                               0.57140      0.00050    0.57218     0.57061
alpha_2                               0.57659      0.00055    0.57745     0.57573
alpha_3                               0.57776      0.00053    0.57860     0.57693
alpha_4                               0.57881      0.00054    0.57965     0.57796
alpha_5                               0.58174      0.00055    0.58260     0.58087
alpha_6                               0.58740      0.00040    0.58803     0.58676
alpha_7                               0.58045      0.00056    0.58134     0.57957
alpha_8                               0.57693      0.00049    0.57770     0.57616
alpha_9                               0.57902      0.00045    0.57971     0.57832
Alpha_loss                            -2.97138     0.01801    -2.94373    -2.99960
Training/policy_loss                  -47.62690    0.08097    -47.48152   -47.71516
Training/qf1_loss                     1317.08605   501.11077  2181.46729  717.42633
Training/qf2_loss                     1307.34789   499.31043  2168.65747  710.06409
Training/pf_norm                      0.44603      0.05003    0.58634     0.40116
Training/qf1_norm                     477.65002    316.23626  1148.00500  125.16577
Training/qf2_norm                     474.44000    312.83968  1132.19128  121.97803
log_std/mean                          -0.30309     0.00035    -0.30265    -0.30357
log_std/std                           0.15657      0.00105    0.15820     0.15522
log_std/max                           -0.11774     0.00087    -0.11653    -0.11899
log_std/min                           -0.80920     0.00846    -0.79796    -0.82456
log_probs/mean                        -1.48510     0.02843    -1.45087    -1.52824
log_probs/std                         1.80808      0.03147    1.86592     1.76259
log_probs/max                         5.48391      0.18689    5.68712     5.21738
log_probs/min                         -7.16668     1.26900    -5.56216    -9.19474
mean/mean                             -0.21579     0.00292    -0.21229    -0.22140
mean/std                              0.60748      0.00207    0.61148     0.60431
mean/max                              1.61602      0.00623    1.62174     1.60061
mean/min                              -2.00261     0.00606    -1.99213    -2.00899
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 9, 2, 7, 5, 1, 6, 0, 3, 4]
replay_buffer._size: [29550 29550 29550 29550 29550 29550 29550 29550 29550 29550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.3851282596588135 0.0025043487548828125
train_time 7.388937711715698
2023-09-06 13:46:31,076 MainThread INFO: EPOCH:195
2023-09-06 13:46:31,076 MainThread INFO: Time Consumed:7.404045581817627s
2023-09-06 13:46:31,076 MainThread INFO: Total Frames:294000s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 196/400 [15:29<25:01,  7.36s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1075.91297
Train_Epoch_Reward                    10464.56132
Running_Training_Average_Rewards      1111.82993
Explore_Time                          0.00521
Train___Time                          7.38894
Eval____Time                          0.00553
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.39633
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.53155
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -55.77014
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.66598
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.97569
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.68093
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.99651
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11121.76579
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.00156
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.17024
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.15653      0.85476    8.73282     6.03274
alpha_0                               0.67615      0.00030    0.67661     0.67568
alpha_1                               0.56965      0.00050    0.57044     0.56887
alpha_2                               0.57468      0.00055    0.57554     0.57382
alpha_3                               0.57591      0.00053    0.57675     0.57508
alpha_4                               0.57693      0.00054    0.57778     0.57608
alpha_5                               0.57981      0.00055    0.58068     0.57894
alpha_6                               0.58598      0.00041    0.58662     0.58534
alpha_7                               0.57850      0.00056    0.57937     0.57763
alpha_8                               0.57523      0.00049    0.57599     0.57446
alpha_9                               0.57746      0.00045    0.57816     0.57675
Alpha_loss                            -3.00585     0.01966    -2.97226    -3.02696
Training/policy_loss                  -47.87753    0.15115    -47.64793   -48.19569
Training/qf1_loss                     1435.29921   442.97080  2188.53491  810.92932
Training/qf2_loss                     1425.29865   442.16016  2178.08594  799.93842
Training/pf_norm                      0.49309      0.09971    0.68565     0.38384
Training/qf1_norm                     509.34805    204.73155  905.51276   252.85994
Training/qf2_norm                     504.06876    203.95696  896.48468   244.96951
log_std/mean                          -0.30343     0.00067    -0.30251    -0.30434
log_std/std                           0.15969      0.00076    0.16081     0.15841
log_std/max                           -0.11580     0.00071    -0.11459    -0.11701
log_std/min                           -0.83303     0.01234    -0.81319    -0.85840
log_probs/mean                        -1.52127     0.03981    -1.45318    -1.56114
log_probs/std                         1.78753      0.04322    1.84385     1.72040
log_probs/max                         5.16980      0.21072    5.45444     4.71445
log_probs/min                         -7.40215     0.77394    -6.27281    -8.59101
mean/mean                             -0.21043     0.00123    -0.20786    -0.21192
mean/std                              0.60343      0.00066    0.60454     0.60255
mean/max                              1.59037      0.01026    1.60550     1.57036
mean/min                              -1.96440     0.01303    -1.94216    -1.98404
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 6, 8, 0, 4, 7, 9, 1, 3, 5]
replay_buffer._size: [29700 29700 29700 29700 29700 29700 29700 29700 29700 29700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.688985109329224 0.0021715164184570312
train_time 7.692481279373169
2023-09-06 13:46:38,984 MainThread INFO: EPOCH:196
2023-09-06 13:46:38,987 MainThread INFO: Time Consumed:7.728684902191162s
2023-09-06 13:46:38,987 MainThread INFO: Total Frames:295500s
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 197/400 [15:37<25:26,  7.52s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1044.86561
Train_Epoch_Reward                    12969.10286
Running_Training_Average_Rewards      1172.60808
Explore_Time                          0.02605
Train___Time                          7.69248
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.67846
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.49506
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -54.86585
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.82555
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.66708
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.52214
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.74712
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10792.39439
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -64.23110
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.41110
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.41801      1.11354    10.29818    6.18512
alpha_0                               0.67509      0.00031    0.67557     0.67462
alpha_1                               0.56790      0.00050    0.56869     0.56711
alpha_2                               0.57277      0.00055    0.57363     0.57191
alpha_3                               0.57406      0.00053    0.57489     0.57323
alpha_4                               0.57504      0.00054    0.57589     0.57419
alpha_5                               0.57789      0.00055    0.57875     0.57702
alpha_6                               0.58457      0.00040    0.58520     0.58394
alpha_7                               0.57657      0.00055    0.57744     0.57572
alpha_8                               0.57354      0.00048    0.57430     0.57278
alpha_9                               0.57588      0.00045    0.57659     0.57517
Alpha_loss                            -3.01381     0.02394    -2.97491    -3.04939
Training/policy_loss                  -48.28106    0.10516    -48.13197   -48.42673
Training/qf1_loss                     1754.66115   437.12548  2512.99536  967.48340
Training/qf2_loss                     1744.35287   434.90542  2501.69995  963.87970
Training/pf_norm                      0.53413      0.10186    0.79262     0.43599
Training/qf1_norm                     552.48495    270.25371  1267.71985  302.07358
Training/qf2_norm                     546.56416    267.42660  1252.32275  290.88669
log_std/mean                          -0.30226     0.00228    -0.29795    -0.30455
log_std/std                           0.16345      0.00132    0.16509     0.16127
log_std/max                           -0.11027     0.00374    -0.10482    -0.11546
log_std/min                           -0.86345     0.01209    -0.84302    -0.88631
log_probs/mean                        -1.50179     0.04055    -1.42926    -1.55948
log_probs/std                         1.81210      0.04691    1.90667     1.73575
log_probs/max                         5.30428      0.24180    5.73189     4.92768
log_probs/min                         -7.22441     1.39857    -5.50754    -9.96000
mean/mean                             -0.20310     0.00224    -0.20004    -0.20694
mean/std                              0.60642      0.00102    0.60799     0.60453
mean/max                              1.57314      0.00520    1.58015     1.56168
mean/min                              -1.95471     0.01114    -1.93826    -1.97084
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 9, 5, 6, 4, 2, 1, 3, 7, 0]
replay_buffer._size: [29858 29858 29857 29859 29855 29858 29855 29858 29858 29855]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.509372711181641 0.0021343231201171875
train_time 7.5128254890441895
2023-09-06 13:46:46,818 MainThread INFO: EPOCH:197
2023-09-06 13:46:46,818 MainThread INFO: Time Consumed:7.661675691604614s
2023-09-06 13:46:46,819 MainThread INFO: Total Frames:297000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 198/400 [15:45<25:36,  7.61s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1009.19251
Train_Epoch_Reward                    10897.14978
Running_Training_Average_Rewards      1144.36047
Explore_Time                          0.14051
Train___Time                          7.51283
Eval____Time                          0.00320
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -79.42125
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -75.09162
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -53.46541
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.60590
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.08591
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.28240
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.11293
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10199.65428
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.21879
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.12259
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.44905      0.98791    8.99660     5.86683
alpha_0                               0.67406      0.00029    0.67452     0.67361
alpha_1                               0.56615      0.00050    0.56694     0.56537
alpha_2                               0.57087      0.00055    0.57172     0.57001
alpha_3                               0.57221      0.00053    0.57305     0.57138
alpha_4                               0.57315      0.00054    0.57400     0.57230
alpha_5                               0.57597      0.00055    0.57683     0.57511
alpha_6                               0.58317      0.00041    0.58380     0.58253
alpha_7                               0.57468      0.00054    0.57553     0.57384
alpha_8                               0.57186      0.00048    0.57261     0.57110
alpha_9                               0.57429      0.00046    0.57501     0.57357
Alpha_loss                            -3.04001     0.02168    -3.00519    -3.08365
Training/policy_loss                  -48.68727    0.15169    -48.48531   -48.97401
Training/qf1_loss                     1475.21060   456.43877  2418.35840  1000.36444
Training/qf2_loss                     1466.63832   457.36847  2413.38257  992.19043
Training/pf_norm                      0.45414      0.05056    0.55699     0.39654
Training/qf1_norm                     558.74530    227.62450  907.10626   183.79964
Training/qf2_norm                     554.87929    225.97570  900.91150   174.00273
log_std/mean                          -0.29428     0.00145    -0.29288    -0.29716
log_std/std                           0.16450      0.00077    0.16548     0.16317
log_std/max                           -0.10118     0.00122    -0.09947    -0.10278
log_std/min                           -0.88067     0.00888    -0.86808    -0.89287
log_probs/mean                        -1.51776     0.03562    -1.47256    -1.58799
log_probs/std                         1.81488      0.02695    1.85954     1.78490
log_probs/max                         5.57413      0.18320    5.86826     5.27207
log_probs/min                         -7.08708     1.20661    -5.45470    -9.13504
mean/mean                             -0.19507     0.00353    -0.18871    -0.19965
mean/std                              0.60041      0.00234    0.60429     0.59721
mean/max                              1.57844      0.00260    1.58300     1.57482
mean/min                              -1.97028     0.00490    -1.96294    -1.97796
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 3, 9, 2, 6, 0, 5, 8, 4, 1]
replay_buffer._size: [30000 30000 30000 30000 30000 30000 30000 30000 30000 30000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.5402305126190186 0.0021321773529052734
train_time 7.5436718463897705
2023-09-06 13:46:54,516 MainThread INFO: EPOCH:198
2023-09-06 13:46:54,517 MainThread INFO: Time Consumed:7.561350584030151s
2023-09-06 13:46:54,517 MainThread INFO: Total Frames:298500s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 199/400 [15:52<25:34,  7.64s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               965.12333
Train_Epoch_Reward                    12811.29527
Running_Training_Average_Rewards      1222.58493
Explore_Time                          0.00925
Train___Time                          7.54367
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -85.48670
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.92068
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.70389
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.35383
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.19856
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.79848
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.21501
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9779.33731
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.45517
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.70339
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.45195      0.91257    8.74847     6.13772
alpha_0                               0.67305      0.00030    0.67351     0.67259
alpha_1                               0.56440      0.00050    0.56519     0.56362
alpha_2                               0.56897      0.00054    0.56982     0.56812
alpha_3                               0.57036      0.00053    0.57119     0.56952
alpha_4                               0.57126      0.00054    0.57211     0.57040
alpha_5                               0.57406      0.00055    0.57492     0.57320
alpha_6                               0.58174      0.00041    0.58238     0.58109
alpha_7                               0.57282      0.00053    0.57365     0.57199
alpha_8                               0.57018      0.00048    0.57094     0.56943
alpha_9                               0.57267      0.00047    0.57341     0.57194
Alpha_loss                            -3.07964     0.01619    -3.04382    -3.10323
Training/policy_loss                  -49.15315    0.13295    -48.94847   -49.42578
Training/qf1_loss                     1485.83524   464.94328  2635.82007  1002.01202
Training/qf2_loss                     1475.70836   465.26291  2627.61987  993.26056
Training/pf_norm                      0.46032      0.07026    0.58266     0.35339
Training/qf1_norm                     547.78633    228.22425  878.71881   217.85828
Training/qf2_norm                     545.34547    225.55847  872.89081   219.92059
log_std/mean                          -0.29530     0.00157    -0.29351    -0.29820
log_std/std                           0.16437      0.00109    0.16646     0.16320
log_std/max                           -0.10431     0.00092    -0.10316    -0.10635
log_std/min                           -0.90549     0.01174    -0.88605    -0.93167
log_probs/mean                        -1.55961     0.02973    -1.50794    -1.61047
log_probs/std                         1.80411      0.04270    1.86526     1.72873
log_probs/max                         5.51542      0.22043    5.86649     5.03713
log_probs/min                         -7.10498     1.18716    -5.77859    -9.56526
mean/mean                             -0.17797     0.00637    -0.16727    -0.18723
mean/std                              0.59876      0.00164    0.60208     0.59692
mean/max                              1.58495      0.01081    1.60713     1.57517
mean/min                              -1.96659     0.00884    -1.95782    -1.98432
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 2, 0, 1, 8, 7, 4, 9, 3, 6]
replay_buffer._size: [30150 30150 30154 30152 30150 30152 30150 30152 30155 30150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.424741744995117 0.0025293827056884766
train_time 7.428587913513184
2023-09-06 13:47:02,215 MainThread INFO: EPOCH:199
2023-09-06 13:47:02,215 MainThread INFO: Time Consumed:7.500295639038086s
2023-09-06 13:47:02,215 MainThread INFO: Total Frames:300000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 200/400 [16:00<25:34,  7.67s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               922.33146
Train_Epoch_Reward                    9716.02639
Running_Training_Average_Rewards      1114.14905
Explore_Time                          0.06281
Train___Time                          7.42859
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.73616
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -70.22122
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -51.14498
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.47266
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.51863
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.32550
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.48347
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9480.21542
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.22137
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.89678
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.42047     1.02856    9.44630     6.26182
alpha_0                               0.67206     0.00027    0.67249     0.67165
alpha_1                               0.56265     0.00050    0.56344     0.56187
alpha_2                               0.56708     0.00054    0.56793     0.56623
alpha_3                               0.56849     0.00054    0.56933     0.56765
alpha_4                               0.56936     0.00055    0.57021     0.56850
alpha_5                               0.57214     0.00055    0.57300     0.57128
alpha_6                               0.58030     0.00041    0.58094     0.57965
alpha_7                               0.57097     0.00053    0.57180     0.57015
alpha_8                               0.56851     0.00048    0.56926     0.56775
alpha_9                               0.57104     0.00047    0.57178     0.57029
Alpha_loss                            -3.09346    0.00931    -3.08175    -3.11475
Training/policy_loss                  -49.55726   0.11345    -49.40434   -49.71847
Training/qf1_loss                     1354.52484  414.25090  2031.26208  778.69641
Training/qf2_loss                     1342.87637  412.79314  2021.93518  768.16620
Training/pf_norm                      0.44460     0.05786    0.53543     0.36129
Training/qf1_norm                     537.07634   255.61471  1073.17590  257.08252
Training/qf2_norm                     534.13096   253.28361  1061.60608  259.64890
log_std/mean                          -0.30219    0.00222    -0.29876    -0.30537
log_std/std                           0.16859     0.00092    0.16978     0.16700
log_std/max                           -0.10486    0.00111    -0.10324    -0.10711
log_std/min                           -0.94027    0.01107    -0.91269    -0.95426
log_probs/mean                        -1.54375    0.02460    -1.51337    -1.59189
log_probs/std                         1.87038     0.03182    1.90801     1.82379
log_probs/max                         5.82231     0.18921    6.14503     5.60693
log_probs/min                         -6.74577    0.96274    -5.88556    -9.23618
mean/mean                             -0.15727    0.00402    -0.15246    -0.16463
mean/std                              0.60542     0.00142    0.60727     0.60291
mean/max                              1.61690     0.00364    1.62338     1.60976
mean/min                              -1.98611    0.00244    -1.98365    -1.99096
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 0, 6, 8, 1, 9, 2, 4, 5, 7]
replay_buffer._size: [30300 30300 30300 30300 30300 30300 30300 30300 30300 30300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.753781795501709 0.0022492408752441406
train_time 7.757379531860352
2023-09-06 13:47:10,235 MainThread INFO: EPOCH:200
2023-09-06 13:47:10,236 MainThread INFO: Time Consumed:7.814558506011963s
2023-09-06 13:47:10,236 MainThread INFO: Total Frames:301500s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 201/400 [16:09<26:48,  8.08s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               884.79993
Train_Epoch_Reward                    8343.89091
Running_Training_Average_Rewards      1029.04042
Explore_Time                          0.04969
Train___Time                          7.75738
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.39811
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -67.88396
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.07893
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -62.55736
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.97866
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.16571
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -69.18891
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9051.57614
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.38197
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.64073
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.19710     1.17724    8.86692     4.94160
alpha_0                               0.67116     0.00025    0.67156     0.67077
alpha_1                               0.56091     0.00050    0.56169     0.56012
alpha_2                               0.56519     0.00054    0.56604     0.56434
alpha_3                               0.56663     0.00053    0.56747     0.56580
alpha_4                               0.56746     0.00054    0.56831     0.56662
alpha_5                               0.57023     0.00055    0.57109     0.56937
alpha_6                               0.57886     0.00041    0.57951     0.57821
alpha_7                               0.56915     0.00052    0.56997     0.56834
alpha_8                               0.56683     0.00048    0.56758     0.56607
alpha_9                               0.56939     0.00047    0.57013     0.56865
Alpha_loss                            -3.10258    0.01323    -3.07413    -3.12460
Training/policy_loss                  -49.88822   0.12439    -49.58543   -50.07728
Training/qf1_loss                     1344.85535  342.96799  1764.07849  722.40790
Training/qf2_loss                     1335.84611  342.23109  1749.23792  715.52832
Training/pf_norm                      0.46444     0.04956    0.56137     0.38663
Training/qf1_norm                     502.47287   252.51881  871.93634   130.85992
Training/qf2_norm                     499.25867   252.43165  869.54944   119.53024
log_std/mean                          -0.30818    0.00128    -0.30618    -0.30992
log_std/std                           0.16985     0.00051    0.17087     0.16923
log_std/max                           -0.10886    0.00187    -0.10573    -0.11118
log_std/min                           -0.96450    0.01105    -0.95168    -0.98727
log_probs/mean                        -1.53117    0.02388    -1.49368    -1.57479
log_probs/std                         1.86160     0.03332    1.93614     1.81451
log_probs/max                         5.73074     0.23854    6.31802     5.43862
log_probs/min                         -7.57392    1.11147    -5.99525    -9.74281
mean/mean                             -0.15378    0.00094    -0.15264    -0.15574
mean/std                              0.60579     0.00073    0.60726     0.60451
mean/max                              1.59760     0.00972    1.61301     1.58405
mean/min                              -1.97435    0.00326    -1.97127    -1.98077
------------------------------------  ----------  ---------  ----------  ---------
snapshot at 200
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [6, 9, 8, 5, 3, 7, 4, 0, 2, 1]
replay_buffer._size: [30450 30450 30450 30450 30450 30450 30450 30450 30450 30450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.618679523468018 0.002210855484008789
train_time 4.622244834899902
2023-09-06 13:47:18,392 MainThread INFO: EPOCH:201
2023-09-06 13:47:18,393 MainThread INFO: Time Consumed:4.737737655639648s
2023-09-06 13:47:18,393 MainThread INFO: Total Frames:303000s
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 202/400 [16:16<25:40,  7.78s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               852.94760
Train_Epoch_Reward                    8345.21348
Running_Training_Average_Rewards      880.17103
Explore_Time                          0.10718
Train___Time                          4.62224
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -82.43075
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.30787
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.77747
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.30394
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.01500
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.27023
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -67.60542
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8797.59104
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.53367
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.41500
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.20319     0.93112    9.19593     5.81883
alpha_0                               0.67029     0.00025    0.67068     0.66990
alpha_1                               0.55916     0.00050    0.55994     0.55837
alpha_2                               0.56330     0.00054    0.56415     0.56246
alpha_3                               0.56478     0.00053    0.56561     0.56394
alpha_4                               0.56558     0.00054    0.56643     0.56473
alpha_5                               0.56832     0.00055    0.56918     0.56747
alpha_6                               0.57742     0.00041    0.57807     0.57678
alpha_7                               0.56737     0.00051    0.56817     0.56657
alpha_8                               0.56515     0.00048    0.56590     0.56439
alpha_9                               0.56774     0.00047    0.56848     0.56700
Alpha_loss                            -3.12005    0.00477    -3.11359    -3.12891
Training/policy_loss                  -50.24642   0.09997    -50.10493   -50.43938
Training/qf1_loss                     1546.05244  440.52637  2567.38721  1017.93262
Training/qf2_loss                     1535.84512  440.81392  2555.42358  1003.44720
Training/pf_norm                      0.45960     0.04926    0.52078     0.36630
Training/qf1_norm                     476.97182   212.87467  940.95715   190.44637
Training/qf2_norm                     474.53415   212.53724  935.82025   185.62218
log_std/mean                          -0.30847    0.00136    -0.30577    -0.30987
log_std/std                           0.17271     0.00103    0.17425     0.17118
log_std/max                           -0.10694    0.00234    -0.10217    -0.10961
log_std/min                           -0.99645    0.00778    -0.97787    -1.00541
log_probs/mean                        -1.53276    0.01419    -1.51518    -1.56740
log_probs/std                         1.85267     0.03590    1.91410     1.80282
log_probs/max                         5.54447     0.18835    5.92741     5.21020
log_probs/min                         -7.40136    1.17962    -5.77795    -9.65124
mean/mean                             -0.15801    0.00095    -0.15638    -0.15916
mean/std                              0.60404     0.00042    0.60458     0.60345
mean/max                              1.56212     0.01029    1.57917     1.55212
mean/min                              -1.95291    0.01202    -1.93591    -1.96874
------------------------------------  ----------  ---------  ----------  ----------
sample: [7, 2, 5, 3, 4, 6, 9, 8, 1, 0]
replay_buffer._size: [30600 30600 30600 30600 30600 30600 30600 30600 30600 30600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.43428373336792 0.002096891403198242
train_time 7.437692880630493
2023-09-06 13:47:26,084 MainThread INFO: EPOCH:202
2023-09-06 13:47:26,084 MainThread INFO: Time Consumed:7.467629432678223s
2023-09-06 13:47:26,085 MainThread INFO: Total Frames:304500s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 203/400 [16:24<25:27,  7.75s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               826.58403
Train_Epoch_Reward                    8257.98978
Running_Training_Average_Rewards      831.56981
Explore_Time                          0.02097
Train___Time                          7.43769
Eval____Time                          0.00290
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.65640
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.40806
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -44.31439
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.65771
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.78150
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.69925
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.80456
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8658.46954
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.11337
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.74697
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.49881     1.27372    8.79783     4.68971
alpha_0                               0.66939     0.00027    0.66981     0.66897
alpha_1                               0.55741     0.00050    0.55820     0.55663
alpha_2                               0.56143     0.00054    0.56227     0.56059
alpha_3                               0.56292     0.00053    0.56376     0.56209
alpha_4                               0.56369     0.00054    0.56454     0.56284
alpha_5                               0.56642     0.00055    0.56728     0.56556
alpha_6                               0.57599     0.00041    0.57663     0.57535
alpha_7                               0.56562     0.00050    0.56640     0.56483
alpha_8                               0.56347     0.00048    0.56422     0.56272
alpha_9                               0.56609     0.00047    0.56684     0.56535
Alpha_loss                            -3.14249    0.01745    -3.11003    -3.17476
Training/policy_loss                  -50.53969   0.07924    -50.45118   -50.72055
Training/qf1_loss                     1548.38873  507.39201  2436.13940  691.35120
Training/qf2_loss                     1537.60156  506.22538  2422.57690  685.10413
Training/pf_norm                      0.48265     0.05552    0.61005     0.38418
Training/qf1_norm                     594.16763   240.88240  852.59528   150.76932
Training/qf2_norm                     587.89798   239.92560  847.70392   146.81276
log_std/mean                          -0.30380    0.00053    -0.30319    -0.30511
log_std/std                           0.17658     0.00133    0.17869     0.17486
log_std/max                           -0.09859    0.00250    -0.09406    -0.10249
log_std/min                           -1.02506    0.01333    -1.00204    -1.04829
log_probs/mean                        -1.54619    0.03764    -1.49960    -1.61751
log_probs/std                         1.83450     0.04055    1.91375     1.77647
log_probs/max                         5.60131     0.13500    5.79012     5.31104
log_probs/min                         -6.86215    0.90618    -5.56663    -8.46297
mean/mean                             -0.15059    0.00292    -0.14608    -0.15546
mean/std                              0.60632     0.00225    0.61044     0.60360
mean/max                              1.56164     0.00392    1.56873     1.55573
mean/min                              -1.94089    0.00476    -1.93391    -1.94829
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 6, 0, 2, 7, 8, 1, 9, 4, 3]
replay_buffer._size: [30750 30750 30750 30750 30750 30750 30750 30750 30750 30750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.705984354019165 0.002924203872680664
train_time 7.710423946380615
2023-09-06 13:47:33,990 MainThread INFO: EPOCH:203
2023-09-06 13:47:33,990 MainThread INFO: Time Consumed:7.724913835525513s
2023-09-06 13:47:33,991 MainThread INFO: Total Frames:306000s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 204/400 [16:32<25:30,  7.81s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               811.80695
Train_Epoch_Reward                    8608.48212
Running_Training_Average_Rewards      840.38951
Explore_Time                          0.00520
Train___Time                          7.71042
Eval____Time                          0.00438
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.29776
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.08961
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -39.45063
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.11915
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.75170
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -59.98589
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -63.82406
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8572.64338
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.52559
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.60948
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.99245     1.13582    9.39090     5.83672
alpha_0                               0.66846     0.00026    0.66888     0.66805
alpha_1                               0.55567     0.00050    0.55645     0.55488
alpha_2                               0.55956     0.00053    0.56040     0.55873
alpha_3                               0.56108     0.00053    0.56191     0.56025
alpha_4                               0.56180     0.00054    0.56265     0.56095
alpha_5                               0.56452     0.00054    0.56538     0.56367
alpha_6                               0.57457     0.00041    0.57521     0.57393
alpha_7                               0.56389     0.00049    0.56466     0.56312
alpha_8                               0.56181     0.00047    0.56256     0.56107
alpha_9                               0.56444     0.00047    0.56519     0.56370
Alpha_loss                            -3.14267    0.02074    -3.11105    -3.18181
Training/policy_loss                  -50.89585   0.12077    -50.71189   -51.05793
Training/qf1_loss                     1420.72816  448.16748  2499.67041  804.27795
Training/qf2_loss                     1411.24332  449.74529  2492.57690  792.44281
Training/pf_norm                      0.48080     0.07437    0.59661     0.38912
Training/qf1_norm                     452.89056   276.16341  1040.74268  177.36862
Training/qf2_norm                     446.20778   272.60523  1021.74493  175.72800
log_std/mean                          -0.30534    0.00165    -0.30314    -0.30748
log_std/std                           0.18036     0.00054    0.18121     0.17935
log_std/max                           -0.09252    0.00151    -0.09038    -0.09508
log_std/min                           -1.05915    0.01577    -1.03851    -1.07967
log_probs/mean                        -1.51383    0.04338    -1.45083    -1.59799
log_probs/std                         1.85940     0.02985    1.90016     1.81075
log_probs/max                         5.58109     0.12519    5.76652     5.26893
log_probs/min                         -6.87914    0.59409    -5.93917    -7.74768
mean/mean                             -0.13902    0.00345    -0.13343    -0.14487
mean/std                              0.61825     0.00416    0.62395     0.61191
mean/max                              1.55642     0.00552    1.56667     1.54935
mean/min                              -1.95132    0.00313    -1.94797    -1.95933
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 3, 7, 5, 2, 8, 0, 1, 6, 4]
replay_buffer._size: [30900 30900 30900 30900 30900 30900 30900 30900 30900 30900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.851134538650513 0.0021872520446777344
train_time 7.854640007019043
2023-09-06 13:47:42,123 MainThread INFO: EPOCH:204
2023-09-06 13:47:42,154 MainThread INFO: Time Consumed:7.923887491226196s
2023-09-06 13:47:42,155 MainThread INFO: Total Frames:307500s
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 205/400 [16:40<25:43,  7.92s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               799.05882
Train_Epoch_Reward                    8387.75817
Running_Training_Average_Rewards      841.80767
Explore_Time                          0.05650
Train___Time                          7.85464
Eval____Time                          0.00571
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.44360
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -59.50870
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.32224
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.58005
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.05073
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.91492
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.93104
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8388.44736
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -48.61748
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.59072
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.13687     1.43521    10.30978    5.56842
alpha_0                               0.66754     0.00026    0.66796     0.66713
alpha_1                               0.55392     0.00050    0.55471     0.55314
alpha_2                               0.55771     0.00053    0.55854     0.55689
alpha_3                               0.55924     0.00053    0.56007     0.55842
alpha_4                               0.55992     0.00054    0.56077     0.55907
alpha_5                               0.56264     0.00054    0.56348     0.56179
alpha_6                               0.57315     0.00041    0.57379     0.57252
alpha_7                               0.56220     0.00048    0.56295     0.56146
alpha_8                               0.56017     0.00047    0.56091     0.55943
alpha_9                               0.56279     0.00047    0.56354     0.56205
Alpha_loss                            -3.15196    0.01701    -3.10895    -3.17298
Training/policy_loss                  -51.14274   0.06578    -51.02239   -51.24506
Training/qf1_loss                     1558.43441  735.32868  2735.35327  675.84656
Training/qf2_loss                     1548.59033  734.04199  2722.95532  666.60803
Training/pf_norm                      0.48214     0.06706    0.61693     0.40730
Training/qf1_norm                     481.86286   355.09762  1273.22534  88.84722
Training/qf2_norm                     474.35003   353.66137  1261.14233  78.09415
log_std/mean                          -0.30886    0.00066    -0.30779    -0.31006
log_std/std                           0.18158     0.00111    0.18386     0.18021
log_std/max                           -0.09933    0.00159    -0.09577    -0.10110
log_std/min                           -1.06748    0.01538    -1.04417    -1.09349
log_probs/mean                        -1.50063    0.03452    -1.42810    -1.55994
log_probs/std                         1.87870     0.04389    1.92764     1.77874
log_probs/max                         5.59125     0.18914    5.81131     5.22576
log_probs/min                         -7.11545    0.64759    -5.94039    -8.33201
mean/mean                             -0.12970    0.00156    -0.12808    -0.13251
mean/std                              0.62782     0.00169    0.63061     0.62496
mean/max                              1.54306     0.00476    1.54862     1.53334
mean/min                              -1.95751    0.00370    -1.95235    -1.96398
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 5, 6, 4, 3, 2, 1, 0, 8, 9]
replay_buffer._size: [31050 31050 31050 31050 31050 31050 31050 31050 31050 31050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.604888916015625 0.0021920204162597656
train_time 7.60839581489563
2023-09-06 13:47:49,947 MainThread INFO: EPOCH:205
2023-09-06 13:47:49,950 MainThread INFO: Time Consumed:7.637071371078491s
2023-09-06 13:47:49,951 MainThread INFO: Total Frames:309000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 206/400 [16:48<25:29,  7.88s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               782.80975
Train_Epoch_Reward                    8885.39637
Running_Training_Average_Rewards      862.72122
Explore_Time                          0.01752
Train___Time                          7.60840
Eval____Time                          0.00506
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -92.22563
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.11162
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -31.68757
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.85462
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.60515
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.26871
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -61.78618
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8162.48477
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.72721
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.40289
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.75404     1.15662    8.53728     4.47366
alpha_0                               0.66663     0.00026    0.66704     0.66622
alpha_1                               0.55218     0.00050    0.55297     0.55140
alpha_2                               0.55588     0.00052    0.55670     0.55506
alpha_3                               0.55741     0.00052    0.55824     0.55659
alpha_4                               0.55804     0.00054    0.55889     0.55720
alpha_5                               0.56076     0.00054    0.56160     0.55992
alpha_6                               0.57176     0.00039    0.57238     0.57115
alpha_7                               0.56056     0.00046    0.56129     0.55984
alpha_8                               0.55853     0.00047    0.55927     0.55779
alpha_9                               0.56114     0.00047    0.56188     0.56040
Alpha_loss                            -3.14396    0.01129    -3.12813    -3.16324
Training/policy_loss                  -51.46797   0.17543    -51.23698   -51.82030
Training/qf1_loss                     1322.05784  432.29678  1985.99792  651.00488
Training/qf2_loss                     1309.83835  431.95846  1972.83984  643.14557
Training/pf_norm                      0.52070     0.06422    0.62647     0.44391
Training/qf1_norm                     436.12682   192.88865  805.21796   119.75804
Training/qf2_norm                     429.74357   194.23446  800.15417   103.24529
log_std/mean                          -0.31079    0.00044    -0.31010    -0.31163
log_std/std                           0.18615     0.00116    0.18767     0.18416
log_std/max                           -0.09340    0.00346    -0.08831    -0.09835
log_std/min                           -1.08951    0.01112    -1.07081    -1.11075
log_probs/mean                        -1.45600    0.02301    -1.43003    -1.50093
log_probs/std                         1.89303     0.04861    1.96267     1.83506
log_probs/max                         5.44392     0.17304    5.67741     5.20548
log_probs/min                         -7.06974    0.58719    -6.24866    -8.25825
mean/mean                             -0.13058    0.00136    -0.12828    -0.13254
mean/std                              0.63292     0.00082    0.63396     0.63150
mean/max                              1.51119     0.01353    1.54097     1.49363
mean/min                              -1.95960    0.00447    -1.95625    -1.97060
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 9, 7, 2, 1, 3, 8, 4, 5, 6]
replay_buffer._size: [31200 31200 31200 31200 31200 31200 31200 31200 31200 31200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 4.1009297370910645 0.0021157264709472656
train_time 4.104346513748169
2023-09-06 13:47:57,491 MainThread INFO: EPOCH:206
2023-09-06 13:47:57,491 MainThread INFO: Time Consumed:4.116554260253906s
2023-09-06 13:47:57,492 MainThread INFO: Total Frames:310500s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 207/400 [16:55<25:00,  7.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               764.89580
Train_Epoch_Reward                    7699.13014
Running_Training_Average_Rewards      832.40949
Explore_Time                          0.00456
Train___Time                          4.10435
Eval____Time                          0.00319
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.45289
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.54521
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -27.12115
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.57272
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.80561
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.58901
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.90275
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8031.05130
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.94577
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.54521
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.41612     1.07552    9.44511     5.56184
alpha_0                               0.66570     0.00027    0.66613     0.66528
alpha_1                               0.55045     0.00050    0.55123     0.54967
alpha_2                               0.55406     0.00052    0.55488     0.55324
alpha_3                               0.55559     0.00052    0.55641     0.55477
alpha_4                               0.55617     0.00054    0.55701     0.55533
alpha_5                               0.55889     0.00054    0.55973     0.55805
alpha_6                               0.57041     0.00038    0.57101     0.56981
alpha_7                               0.55896     0.00046    0.55968     0.55824
alpha_8                               0.55690     0.00047    0.55763     0.55617
alpha_9                               0.55950     0.00047    0.56023     0.55876
Alpha_loss                            -3.16779    0.02045    -3.13798    -3.21221
Training/policy_loss                  -51.70540   0.15740    -51.54475   -52.07002
Training/qf1_loss                     1761.92338  569.62352  2709.43018  799.66687
Training/qf2_loss                     1749.51953  567.35909  2690.01367  786.59436
Training/pf_norm                      0.53020     0.03473    0.61649     0.48960
Training/qf1_norm                     566.07996   256.54635  1067.83972  124.96510
Training/qf2_norm                     556.82802   254.42611  1052.20496  120.30834
log_std/mean                          -0.30943    0.00047    -0.30886    -0.31034
log_std/std                           0.18872     0.00057    0.18983     0.18790
log_std/max                           -0.08765    0.00107    -0.08624    -0.08959
log_std/min                           -1.10336    0.01424    -1.08006    -1.12012
log_probs/mean                        -1.47182    0.03193    -1.41969    -1.53738
log_probs/std                         1.87278     0.03331    1.92588     1.81909
log_probs/max                         5.23855     0.14983    5.58595     5.04418
log_probs/min                         -6.60224    0.87700    -5.29539    -7.99576
mean/mean                             -0.13298    0.00141    -0.13153    -0.13578
mean/std                              0.62812     0.00177    0.63123     0.62607
mean/max                              1.47878     0.00930    1.49793     1.46519
mean/min                              -1.95531    0.00524    -1.94945    -1.96597
------------------------------------  ----------  ---------  ----------  ---------
sample: [6, 7, 9, 8, 1, 0, 4, 2, 5, 3]
replay_buffer._size: [31350 31350 31350 31350 31350 31350 31350 31350 31350 31350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.743025302886963 0.002226591110229492
train_time 7.746615648269653
2023-09-06 13:48:05,413 MainThread INFO: EPOCH:207
2023-09-06 13:48:05,414 MainThread INFO: Time Consumed:7.762394666671753s
2023-09-06 13:48:05,414 MainThread INFO: Total Frames:312000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 208/400 [17:03<25:00,  7.82s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               751.04070
Train_Epoch_Reward                    9092.72123
Running_Training_Average_Rewards      855.90826
Explore_Time                          0.00663
Train___Time                          7.74662
Eval____Time                          0.00406
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -89.14587
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.78480
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.86529
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.08830
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.61682
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.32297
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -60.17844
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7957.03674
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.37488
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.82452
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.51886     1.02179    9.40432     5.59093
alpha_0                               0.66474     0.00029    0.66518     0.66429
alpha_1                               0.54872     0.00050    0.54950     0.54795
alpha_2                               0.55225     0.00052    0.55306     0.55143
alpha_3                               0.55378     0.00052    0.55459     0.55296
alpha_4                               0.55430     0.00054    0.55514     0.55346
alpha_5                               0.55703     0.00053    0.55786     0.55619
alpha_6                               0.56910     0.00037    0.56968     0.56852
alpha_7                               0.55737     0.00045    0.55809     0.55667
alpha_8                               0.55527     0.00046    0.55600     0.55455
alpha_9                               0.55785     0.00047    0.55859     0.55711
Alpha_loss                            -3.16960    0.01552    -3.13763    -3.19529
Training/policy_loss                  -52.06089   0.15496    -51.84038   -52.28590
Training/qf1_loss                     1774.79674  544.02187  2771.35938  772.07227
Training/qf2_loss                     1763.65567  543.59754  2756.27954  761.08319
Training/pf_norm                      0.51088     0.03928    0.61372     0.45270
Training/qf1_norm                     589.70859   256.63577  1078.64929  117.73702
Training/qf2_norm                     578.29218   253.75618  1058.58484  110.28806
log_std/mean                          -0.31077    0.00057    -0.30979    -0.31192
log_std/std                           0.19134     0.00107    0.19317     0.18974
log_std/max                           -0.09099    0.00053    -0.08998    -0.09165
log_std/min                           -1.12478    0.01671    -1.09459    -1.14640
log_probs/mean                        -1.45128    0.02661    -1.39634    -1.49835
log_probs/std                         1.84584     0.04795    1.91843     1.79067
log_probs/max                         5.06048     0.16801    5.28999     4.80735
log_probs/min                         -6.73536    0.60368    -5.94703    -7.55985
mean/mean                             -0.14228    0.00306    -0.13657    -0.14637
mean/std                              0.62708     0.00137    0.63006     0.62533
mean/max                              1.43085     0.01700    1.45535     1.40798
mean/min                              -1.93050    0.00894    -1.91799    -1.94324
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 3, 7, 4, 8, 0, 9, 6, 2, 5]
replay_buffer._size: [31500 31500 31500 31500 31500 31500 31500 31500 31500 31500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 8.077243328094482 0.0021915435791015625
train_time 8.080766677856445
2023-09-06 13:48:13,659 MainThread INFO: EPOCH:208
2023-09-06 13:48:13,661 MainThread INFO: Time Consumed:8.108864068984985s
2023-09-06 13:48:13,662 MainThread INFO: Total Frames:313500s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 209/400 [17:12<25:17,  7.94s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.46903
Train_Epoch_Reward                    8287.59392
Running_Training_Average_Rewards      835.98151
Explore_Time                          0.00743
Train___Time                          8.08077
Eval____Time                          0.00472
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -88.94961
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -58.95867
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.22759
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.50461
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.63818
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.31210
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.23093
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7996.40804
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.77794
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.14334
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.21256     0.94933    9.40264     6.22237
alpha_0                               0.66369     0.00031    0.66418     0.66320
alpha_1                               0.54700     0.00049    0.54778     0.54623
alpha_2                               0.55045     0.00051    0.55125     0.54964
alpha_3                               0.55197     0.00052    0.55278     0.55116
alpha_4                               0.55242     0.00054    0.55327     0.55158
alpha_5                               0.55518     0.00053    0.55601     0.55435
alpha_6                               0.56782     0.00036    0.56839     0.56726
alpha_7                               0.55582     0.00044    0.55651     0.55513
alpha_8                               0.55367     0.00046    0.55439     0.55295
alpha_9                               0.55621     0.00047    0.55695     0.55547
Alpha_loss                            -3.17161    0.01799    -3.14007    -3.20171
Training/policy_loss                  -52.49666   0.18389    -52.22291   -52.88176
Training/qf1_loss                     1518.56435  499.44339  2785.68262  916.47577
Training/qf2_loss                     1507.53603  499.27078  2772.08325  907.40668
Training/pf_norm                      0.46748     0.05581    0.59760     0.40054
Training/qf1_norm                     507.53260   255.69392  1094.75818  261.83679
Training/qf2_norm                     496.86433   250.07277  1070.95569  258.41122
log_std/mean                          -0.31532    0.00182    -0.31229    -0.31744
log_std/std                           0.19473     0.00075    0.19573     0.19310
log_std/max                           -0.09639    0.00275    -0.09160    -0.10082
log_std/min                           -1.15139    0.01312    -1.12795    -1.16877
log_probs/mean                        -1.42865    0.03222    -1.36359    -1.46793
log_probs/std                         1.84604     0.03203    1.88264     1.77754
log_probs/max                         4.87710     0.11249    5.06707     4.74000
log_probs/min                         -6.61291    0.70307    -5.75649    -8.48681
mean/mean                             -0.14774    0.00112    -0.14513    -0.14885
mean/std                              0.63345     0.00198    0.63687     0.63057
mean/max                              1.40448     0.00452    1.41330     1.39841
mean/min                              -1.93808    0.01133    -1.92231    -1.96013
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 7, 2, 9, 0, 4, 6, 1, 8, 5]
replay_buffer._size: [31650 31659 31656 31659 31656 31656 31655 31658 31650 31655]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.870329856872559 0.0021140575408935547
train_time 7.8737664222717285
2023-09-06 13:48:21,806 MainThread INFO: EPOCH:209
2023-09-06 13:48:21,807 MainThread INFO: Time Consumed:7.985769033432007s
2023-09-06 13:48:21,807 MainThread INFO: Total Frames:315000s
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 210/400 [17:20<25:20,  8.00s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.34076
Train_Epoch_Reward                    8624.85791
Running_Training_Average_Rewards      866.83910
Explore_Time                          0.10339
Train___Time                          7.87377
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -95.40427
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.28036
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.17214
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.88394
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.91831
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -52.06780
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.50377
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8004.31704
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.15585
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.20769
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.35686     1.34997    9.94364     5.40908
alpha_0                               0.66260     0.00031    0.66309     0.66212
alpha_1                               0.54528     0.00049    0.54606     0.54451
alpha_2                               0.54866     0.00051    0.54947     0.54786
alpha_3                               0.55018     0.00051    0.55098     0.54937
alpha_4                               0.55056     0.00053    0.55140     0.54972
alpha_5                               0.55334     0.00053    0.55416     0.55251
alpha_6                               0.56658     0.00035    0.56714     0.56603
alpha_7                               0.55430     0.00043    0.55498     0.55362
alpha_8                               0.55208     0.00045    0.55280     0.55137
alpha_9                               0.55456     0.00047    0.55530     0.55382
Alpha_loss                            -3.18795    0.01600    -3.16256    -3.21229
Training/policy_loss                  -52.96094   0.13954    -52.71251   -53.17177
Training/qf1_loss                     1574.49390  524.89204  2549.33521  904.06073
Training/qf2_loss                     1563.09232  523.28605  2535.87305  898.24945
Training/pf_norm                      0.47948     0.05154    0.58695     0.41745
Training/qf1_norm                     540.30603   327.93047  1197.12671  117.77338
Training/qf2_norm                     530.85198   325.58233  1181.05005  109.07336
log_std/mean                          -0.31437    0.00180    -0.31161    -0.31707
log_std/std                           0.19654     0.00052    0.19761     0.19600
log_std/max                           -0.09944    0.00135    -0.09662    -0.10095
log_std/min                           -1.15824    0.01367    -1.13253    -1.17642
log_probs/mean                        -1.42314    0.02209    -1.38087    -1.46242
log_probs/std                         1.87758     0.03201    1.93538     1.83120
log_probs/max                         5.18970     0.09752    5.29364     4.92740
log_probs/min                         -6.70005    0.53236    -5.97248    -7.70459
mean/mean                             -0.13419    0.00688    -0.12238    -0.14372
mean/std                              0.63913     0.00149    0.64219     0.63716
mean/max                              1.43120     0.01047    1.44310     1.41098
mean/min                              -1.97382    0.00676    -1.95894    -1.98196
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 8, 2, 4, 6, 5, 1, 7, 9, 0]
replay_buffer._size: [31800 31800 31800 31800 31800 31800 31800 31800 31800 31800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.968214750289917 0.002518177032470703
train_time 7.972068786621094
2023-09-06 13:48:29,993 MainThread INFO: EPOCH:210
2023-09-06 13:48:29,994 MainThread INFO: Time Consumed:8.015234231948853s
2023-09-06 13:48:29,994 MainThread INFO: Total Frames:316500s
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 211/400 [17:28<25:25,  8.07s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.00788
Train_Epoch_Reward                    8287.10260
Running_Training_Average_Rewards      839.98515
Explore_Time                          0.03244
Train___Time                          7.97207
Eval____Time                          0.00412
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -93.75132
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.46705
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          55.62362
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.47935
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.19540
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -52.10518
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -58.70698
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7856.09322
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.75223
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.41096
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.02881     1.15465    8.62685     4.90444
alpha_0                               0.66157     0.00029    0.66202     0.66112
alpha_1                               0.54357     0.00049    0.54434     0.54281
alpha_2                               0.54688     0.00051    0.54768     0.54608
alpha_3                               0.54838     0.00051    0.54919     0.54758
alpha_4                               0.54870     0.00053    0.54953     0.54786
alpha_5                               0.55151     0.00052    0.55233     0.55069
alpha_6                               0.56535     0.00035    0.56590     0.56480
alpha_7                               0.55278     0.00043    0.55347     0.55210
alpha_8                               0.55050     0.00046    0.55121     0.54979
alpha_9                               0.55291     0.00048    0.55366     0.55217
Alpha_loss                            -3.20115    0.01067    -3.18884    -3.22155
Training/policy_loss                  -53.23705   0.12259    -53.04441   -53.44420
Training/qf1_loss                     1474.95368  483.61614  2140.68286  719.07135
Training/qf2_loss                     1463.77755  482.46265  2130.50269  707.07440
Training/pf_norm                      0.45160     0.05708    0.54393     0.38492
Training/qf1_norm                     467.84083   258.24996  852.93542   100.30843
Training/qf2_norm                     460.96561   255.93557  841.26648   93.56657
log_std/mean                          -0.30918    0.00071    -0.30845    -0.31102
log_std/std                           0.19977     0.00076    0.20076     0.19869
log_std/max                           -0.09298    0.00148    -0.09081    -0.09558
log_std/min                           -1.16817    0.01799    -1.13469    -1.18799
log_probs/mean                        -1.41401    0.01877    -1.38353    -1.44618
log_probs/std                         1.92214     0.04187    1.99050     1.82300
log_probs/max                         5.17050     0.15350    5.37344     4.90327
log_probs/min                         -6.85068    0.40351    -6.38629    -7.68435
mean/mean                             -0.11142    0.00504    -0.10352    -0.12013
mean/std                              0.64764     0.00322    0.65261     0.64285
mean/max                              1.42163     0.01280    1.44036     1.40546
mean/min                              -1.96502    0.00676    -1.95641    -1.97654
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 2, 1, 7, 9, 3, 5, 8, 6, 4]
replay_buffer._size: [31950 31950 31950 31950 31950 31950 31950 31950 31950 31950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 7.925142288208008 0.002175569534301758
train_time 7.928682327270508
2023-09-06 13:48:38,171 MainThread INFO: EPOCH:211
2023-09-06 13:48:38,172 MainThread INFO: Time Consumed:7.990793228149414s
2023-09-06 13:48:38,172 MainThread INFO: Total Frames:318000s
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 212/400 [17:36<25:20,  8.09s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 212/400 [17:39<15:39,  5.00s/it]
------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               735.98816
Train_Epoch_Reward                    7958.86035
Running_Training_Average_Rewards      829.02736
Explore_Time                          0.05215
Train___Time                          7.92868
Eval____Time                          0.00360
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -98.01375
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.63270
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.30195
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.59379
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.51478
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.52676
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -59.80343
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7709.32167
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.50974
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.35129
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.13590     0.82792    8.49868     6.00044
alpha_0                               0.66057     0.00029    0.66102     0.66013
alpha_1                               0.54187     0.00049    0.54264     0.54110
alpha_2                               0.54511     0.00051    0.54590     0.54432
alpha_3                               0.54659     0.00051    0.54740     0.54579
alpha_4                               0.54685     0.00053    0.54768     0.54602
alpha_5                               0.54970     0.00052    0.55051     0.54889
alpha_6                               0.56415     0.00034    0.56468     0.56362
alpha_7                               0.55127     0.00043    0.55195     0.55059
alpha_8                               0.54891     0.00046    0.54963     0.54820
alpha_9                               0.55126     0.00047    0.55200     0.55052
Alpha_loss                            -3.20473    0.01374    -3.18082    -3.22637
Training/policy_loss                  -53.48587   0.16482    -53.22879   -53.68562
Training/qf1_loss                     1529.07186  404.43964  2337.49097  1048.50488
Training/qf2_loss                     1517.70802  403.91552  2325.15674  1039.54358
Training/pf_norm                      0.43517     0.02310    0.46828     0.39825
Training/qf1_norm                     481.08237   215.72263  865.66498   219.56659
Training/qf2_norm                     473.32012   213.18275  853.66077   212.81747
log_std/mean                          -0.30978    0.00058    -0.30862    -0.31041
log_std/std                           0.19874     0.00097    0.20002     0.19728
log_std/max                           -0.10248    0.00294    -0.09759    -0.10605
log_std/min                           -1.18438    0.00838    -1.17144    -1.19482
log_probs/mean                        -1.39305    0.02331    -1.34423    -1.42554
log_probs/std                         1.93113     0.01413    1.95755     1.90807
log_probs/max                         5.33653     0.12897    5.55502     5.13295
log_probs/min                         -6.59051    0.72828    -5.49570    -7.78182
mean/mean                             -0.09239    0.00614    -0.08277    -0.10161
mean/std                              0.65331     0.00079    0.65469     0.65234
mean/max                              1.40682     0.00238    1.41130     1.40381
mean/min                              -1.96146    0.00319    -1.95605    -1.96639
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 1, 6, 0, 7, 8, 5, 4, 9, 2]
replay_buffer._size: [32100 32100 32100 32100 32100 32100 32100 32100 32100 32100]
obs.device cuda:0
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 302, in train_worker_process
    if traj_collect_mod[env_info.env_rank] and success==0:
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 292, in train_worker_process
    if traj_collect_mod[env_info.env_rank] == 0:
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 291, in train_worker_process
    new_value = max(traj_collect_mod[env_info.env_rank],success)
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 230, in train_worker_process
    mask_this_task = mask_buffer[env_info.env_rank]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 230, in train_worker_process
    mask_this_task = mask_buffer[env_info.env_rank]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 230, in train_worker_process
    mask_this_task = mask_buffer[env_info.env_rank]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 189, in recv_handle
    return recvfds(s, 1)[0]
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 157, in recvfds
    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 310, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 305, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 410, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer, epoch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 304, in update_per_epoch
    info = self.update(batch, task_sample_index, task_scheduler, mask_buffer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 115, in update
    policy_device_masks = self.concat_mask_tensors(task_scheduler.task_sample_num,
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 47, in concat_mask_tensors
    single_mask = [each.expand(task_batch_size, -1).to(device) for each in specific_mask_buffer[i]]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
wandb: - 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 149, in _serve
    send(conn, destination_pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 50, in send
    reduction.send_handle(conn, new_fd, pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 184, in send_handle
    sendfds(s, [handle])
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 149, in sendfds
    sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)])
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 142, in _serve
    with self._listener.accept() as conn:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 465, in accept
    deliver_challenge(c, self._authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 738, in deliver_challenge
    connection.send_bytes(CHALLENGE + message)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 142, in _serve
    with self._listener.accept() as conn:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 465, in accept
    deliver_challenge(c, self._authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 738, in deliver_challenge
    connection.send_bytes(CHALLENGE + message)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
wandb: \ 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: | 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: / 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: - 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: \ 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: | 0.081 MB of 0.081 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                    0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    8 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                    9 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                           Alpha_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                         Eval____Time ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñÇ
wandb:                         Explore_Time ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                          Reward_Mean ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:              Running_Average_Rewards ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb:     Running_Training_Average_Rewards ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:                   Train_Epoch_Reward ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                         Train___Time ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñà‚ñà
wandb:                     Training/pf_norm ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñá
wandb:                 Training/policy_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                    Training/qf1_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ
wandb:                    Training/qf1_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÉ
wandb:                    Training/qf2_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ
wandb:                    Training/qf2_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÉ
wandb:                              alpha_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_1 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_2 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_3 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_4 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_5 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_6 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_7 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_8 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              alpha_9 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: button-press-topdown-v1_eval_rewards ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
wandb: button-press-topdown-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 door-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ
wandb:                 door-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         drawer-close-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá
wandb:         drawer-close-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          drawer-open-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb:          drawer-open-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        log_probs/max ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                       log_probs/mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                        log_probs/min ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ
wandb:                        log_probs/std ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                          log_std/max ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ
wandb:                         log_std/mean ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          log_std/min ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:                          log_std/std ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:                             mean/max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:                            mean/mean ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÜ
wandb:                             mean/min ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                             mean/std ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:                    mean_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      ped-insert-side-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb:      ped-insert-side-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           pick-place-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb:           pick-place-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 push-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:                 push-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                reach-v1_eval_rewards ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb:                reach-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                    save_traj_mod_sum ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_8 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   task_policy_mask_9 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         window-close-v1_eval_rewards ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ
wandb:         window-close-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          window-open-v1_eval_rewards ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          window-open-v1_success_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                    0 0.0
wandb:                                    1 0.0
wandb:                                    2 0.0
wandb:                                    3 0.0
wandb:                                    4 0.0
wandb:                                    5 0.0
wandb:                                    6 0.0
wandb:                                    7 0.0
wandb:                                    8 0.0
wandb:                                    9 0.0
wandb:                           Alpha_loss -3.21611
wandb:                         Eval____Time 0.0036
wandb:                         Explore_Time 0.05215
wandb:                          Reward_Mean 6.16136
wandb:              Running_Average_Rewards 735.98816
wandb:     Running_Training_Average_Rewards 829.02736
wandb:                   Train_Epoch_Reward 7958.86035
wandb:                         Train___Time 7.92868
wandb:                     Training/pf_norm 0.45461
wandb:                 Training/policy_loss -53.67375
wandb:                    Training/qf1_loss 1482.86975
wandb:                    Training/qf1_norm 227.23016
wandb:                    Training/qf2_loss 1469.39868
wandb:                    Training/qf2_norm 227.23625
wandb:                              alpha_0 0.66013
wandb:                              alpha_1 0.5411
wandb:                              alpha_2 0.54432
wandb:                              alpha_3 0.54579
wandb:                              alpha_4 0.54602
wandb:                              alpha_5 0.54889
wandb:                              alpha_6 0.56362
wandb:                              alpha_7 0.55059
wandb:                              alpha_8 0.5482
wandb:                              alpha_9 0.55052
wandb: button-press-topdown-v1_eval_rewards -98.01375
wandb: button-press-topdown-v1_success_rate 0.0
wandb:                 door-v1_eval_rewards -60.6327
wandb:                 door-v1_success_rate 0.0
wandb:         drawer-close-v1_eval_rewards -21.30195
wandb:         drawer-close-v1_success_rate 0.0
wandb:          drawer-open-v1_eval_rewards -54.59379
wandb:          drawer-open-v1_success_rate 0.0
wandb:                        log_probs/max 5.43941
wandb:                       log_probs/mean -1.40168
wandb:                        log_probs/min -7.70859
wandb:                        log_probs/std 1.9219
wandb:                          log_std/max -0.10521
wandb:                         log_std/mean -0.31028
wandb:                          log_std/min -1.17144
wandb:                          log_std/std 0.19751
wandb:                             mean/max 1.40533
wandb:                            mean/mean -0.08277
wandb:                             mean/min -1.96377
wandb:                             mean/std 0.65259
wandb:                    mean_success_rate 0.0
wandb:      ped-insert-side-v1_eval_rewards -75.51478
wandb:      ped-insert-side-v1_success_rate 0.0
wandb:           pick-place-v1_eval_rewards -57.52676
wandb:           pick-place-v1_success_rate 0.0
wandb:                 push-v1_eval_rewards -59.80343
wandb:                 push-v1_success_rate 0.0
wandb:                reach-v1_eval_rewards 7709.32167
wandb:                reach-v1_success_rate 0.0
wandb:                    save_traj_mod_sum 1
wandb:                   task_policy_mask_0 74
wandb:                   task_policy_mask_1 81
wandb:                   task_policy_mask_2 53
wandb:                   task_policy_mask_3 60
wandb:                   task_policy_mask_4 87
wandb:                   task_policy_mask_5 68
wandb:                   task_policy_mask_6 79
wandb:                   task_policy_mask_7 64
wandb:                   task_policy_mask_8 72
wandb:                   task_policy_mask_9 75
wandb:         window-close-v1_eval_rewards -53.50974
wandb:         window-close-v1_success_rate 0.0
wandb:          window-open-v1_eval_rewards -51.35129
wandb:          window-open-v1_success_rate 0.0
wandb: 
wandb: üöÄ View run warm-pyramid-365 at: https://wandb.ai/liqianxi/dst_mtrl/runs/u0e84re1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20230906_133053-u0e84re1/logs
