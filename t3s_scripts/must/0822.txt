W&B disabled.
2023-08-22 20:43:23,653 MainThread INFO: Experiment Name:testing_must_mtsac
2023-08-22 20:43:23,653 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      50,
      50
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      50,
      50
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      50,
      50
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.9
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 200,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 2,
    "mask_update_interval": 22,
    "update_end_epoch": 50,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2023-08-22 20:44:36,375 MainThread INFO: Finished Pretrain
  0%|          | 0/200 [00:00<?, ?it/s]epoch, update_end_epoch 0 50
freq 22
sample: [0, 3, 1, 7, 6, 8, 5, 4, 9, 2]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
train_time 0.14247560501098633
eval time 5.240331649780273
snapshot at best
2023-08-22 20:44:42,250 MainThread INFO: EPOCH:0
2023-08-22 20:44:42,250 MainThread INFO: Time Consumed:5.860037326812744s
2023-08-22 20:44:42,250 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:340: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/200 [00:08<28:47,  8.68s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1145.65207
Train_Epoch_Reward                    7835.18641
Running_Training_Average_Rewards      783.51864
Explore_Time                          0.00323
Train___Time                          0.14248
Eval____Time                          5.24033
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.22928
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48062
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.70141
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70482
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16609
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89336
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93160
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11701.82844
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47554
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.72501
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.25221     0.41711    10.66933    9.83510
alpha_0                               0.99955      0.00015    0.99970     0.99940
alpha_1                               0.99955      0.00015    0.99970     0.99940
alpha_2                               0.99955      0.00015    0.99970     0.99940
alpha_3                               0.99955      0.00015    0.99970     0.99940
alpha_4                               0.99955      0.00015    0.99970     0.99940
alpha_5                               0.99955      0.00015    0.99970     0.99940
alpha_6                               0.99955      0.00015    0.99970     0.99940
alpha_7                               0.99955      0.00015    0.99970     0.99940
alpha_8                               0.99955      0.00015    0.99970     0.99940
alpha_9                               0.99955      0.00015    0.99970     0.99940
Alpha_loss                            -0.00100     0.00100    -0.00000    -0.00201
Training/policy_loss                  -2.67883     0.00670    -2.67212    -2.68553
Training/qf1_loss                     1695.21790   120.63403  1815.85193  1574.58386
Training/qf2_loss                     1695.23651   120.63458  1815.87109  1574.60193
Training/pf_norm                      0.44913      0.02559    0.47472     0.42354
Training/qf1_norm                     26.31780     0.85658    27.17438    25.46122
Training/qf2_norm                     26.36909     0.85742    27.22651    25.51167
log_std/mean                          -0.00137     0.00022    -0.00115    -0.00160
log_std/std                           0.00136      0.00000    0.00136     0.00136
log_std/max                           0.00049      0.00022    0.00072     0.00027
log_std/min                           -0.00361     0.00022    -0.00339    -0.00383
log_probs/mean                        -2.67877     0.00688    -2.67189    -2.68565
log_probs/std                         0.44644      0.00149    0.44793     0.44496
log_probs/max                         -1.32293     0.03430    -1.28863    -1.35723
log_probs/min                         -4.41491     0.20939    -4.20552    -4.62431
mean/mean                             0.00031      0.00016    0.00047     0.00015
mean/std                              0.00144      0.00001    0.00145     0.00143
mean/max                              0.00314      0.00019    0.00333     0.00295
mean/min                              -0.00137     0.00020    -0.00118    -0.00157
------------------------------------  -----------  ---------  ----------  ----------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/16/model
epoch, update_end_epoch 1 50
freq 22
sample: [0, 6, 1, 4, 5, 2, 8, 3, 7, 9]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
train_time 0.13780450820922852
eval time 0.0023756027221679688
2023-08-22 20:44:45,219 MainThread INFO: EPOCH:1
2023-08-22 20:44:45,219 MainThread INFO: Time Consumed:0.14505839347839355s
2023-08-22 20:44:45,220 MainThread INFO: Total Frames:3000s
  1%|          | 2/200 [00:08<12:15,  3.72s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1145.64811
Train_Epoch_Reward                    24830.52246
Running_Training_Average_Rewards      1633.28544
Explore_Time                          0.00343
Train___Time                          0.13780
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.30853
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48062
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.70141
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70482
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16609
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89336
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93160
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11701.82844
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47554
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.72501
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           9.93642      0.11106   10.04748    9.82536
alpha_0                               0.99895      0.00015   0.99910     0.99880
alpha_1                               0.99895      0.00015   0.99910     0.99880
alpha_2                               0.99895      0.00015   0.99910     0.99880
alpha_3                               0.99895      0.00015   0.99910     0.99880
alpha_4                               0.99895      0.00015   0.99910     0.99880
alpha_5                               0.99895      0.00015   0.99910     0.99880
alpha_6                               0.99895      0.00015   0.99910     0.99880
alpha_7                               0.99895      0.00015   0.99910     0.99880
alpha_8                               0.99895      0.00015   0.99910     0.99880
alpha_9                               0.99895      0.00015   0.99910     0.99880
Alpha_loss                            -0.00501     0.00100   -0.00401    -0.00600
Training/policy_loss                  -2.67341     0.00407   -2.66933    -2.67748
Training/qf1_loss                     1477.99829   82.75586  1560.75415  1395.24243
Training/qf2_loss                     1478.01630   82.75616  1560.77246  1395.26013
Training/pf_norm                      0.43807      0.00145   0.43953     0.43662
Training/qf1_norm                     25.63233     0.22901   25.86134    25.40332
Training/qf2_norm                     25.68678     0.24950   25.93629    25.43728
log_std/mean                          -0.00225     0.00022   -0.00203    -0.00247
log_std/std                           0.00136      0.00000   0.00136     0.00136
log_std/max                           -0.00040     0.00022   -0.00018    -0.00062
log_std/min                           -0.00449     0.00022   -0.00427    -0.00471
log_probs/mean                        -2.67404     0.00390   -2.67014    -2.67794
log_probs/std                         0.43820      0.00073   0.43893     0.43747
log_probs/max                         -1.28693     0.05815   -1.22878    -1.34508
log_probs/min                         -4.18136     0.18405   -3.99731    -4.36541
mean/mean                             0.00030      0.00003   0.00032     0.00027
mean/std                              0.00146      0.00002   0.00148     0.00144
mean/max                              0.00328      0.00011   0.00339     0.00317
mean/min                              -0.00142     0.00006   -0.00136    -0.00148
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 2 50
freq 22
sample: [9, 1, 4, 6, 0, 7, 2, 8, 3, 5]
replay_buffer._size: [600 600 600 600 600 600 600 600 593 590]
train_time 0.13535761833190918
eval time 0.002591848373413086
2023-08-22 20:44:45,455 MainThread INFO: EPOCH:2
2023-08-22 20:44:45,456 MainThread INFO: Time Consumed:0.14070463180541992s
2023-08-22 20:44:45,456 MainThread INFO: Total Frames:4500s
  2%|▏         | 3/200 [00:09<06:58,  2.13s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1145.48614
Train_Epoch_Reward                    13612.95297
Running_Training_Average_Rewards      1542.62206
Explore_Time                          0.00220
Train___Time                          0.13536
Eval____Time                          0.00259
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.12808
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.48062
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.70141
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70482
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16609
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89336
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.93160
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11701.82844
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47554
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.72501
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.00127      0.73144    9.73271     8.26982
alpha_0                               0.99835      0.00015    0.99850     0.99820
alpha_1                               0.99835      0.00015    0.99850     0.99820
alpha_2                               0.99835      0.00015    0.99850     0.99820
alpha_3                               0.99835      0.00015    0.99850     0.99820
alpha_4                               0.99835      0.00015    0.99850     0.99820
alpha_5                               0.99835      0.00015    0.99850     0.99820
alpha_6                               0.99835      0.00015    0.99850     0.99820
alpha_7                               0.99835      0.00015    0.99850     0.99820
alpha_8                               0.99835      0.00015    0.99850     0.99820
alpha_9                               0.99835      0.00015    0.99850     0.99820
Alpha_loss                            -0.00901     0.00100    -0.00801    -0.01000
Training/policy_loss                  -2.66966     0.00311    -2.66655    -2.67277
Training/qf1_loss                     1340.72394   219.05060  1559.77454  1121.67334
Training/qf2_loss                     1340.74017   219.05157  1559.79175  1121.68860
Training/pf_norm                      0.43588      0.01276    0.44864     0.42311
Training/qf1_norm                     23.69596     1.47297    25.16892    22.22299
Training/qf2_norm                     23.74318     1.47591    25.21909    22.26727
log_std/mean                          -0.00312     0.00022    -0.00290    -0.00334
log_std/std                           0.00135      0.00000    0.00135     0.00135
log_std/max                           -0.00129     0.00022    -0.00107    -0.00152
log_std/min                           -0.00533     0.00021    -0.00512    -0.00554
log_probs/mean                        -2.67099     0.00294    -2.66805    -2.67393
log_probs/std                         0.43409      0.00124    0.43534     0.43285
log_probs/max                         -1.25018     0.03609    -1.21409    -1.28626
log_probs/min                         -3.82478     0.04339    -3.78139    -3.86818
mean/mean                             0.00047      0.00003    0.00050     0.00044
mean/std                              0.00156      0.00002    0.00159     0.00154
mean/max                              0.00374      0.00009    0.00383     0.00365
mean/min                              -0.00119     0.00009    -0.00110    -0.00127
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 3 50
freq 22
sample: [5, 8, 0, 1, 7, 3, 6, 2, 9, 4]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
train_time 0.11351609230041504
eval time 0.0020906925201416016
2023-08-22 20:44:45,703 MainThread INFO: EPOCH:3
2023-08-22 20:44:45,703 MainThread INFO: Time Consumed:0.11845898628234863s
2023-08-22 20:44:45,703 MainThread INFO: Total Frames:6000s
  2%|▏         | 4/200 [00:09<04:31,  1.38s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1144.82377
Train_Epoch_Reward                    8622.71261
Running_Training_Average_Rewards      1568.87293
Explore_Time                          0.00233
Train___Time                          0.11352
Eval____Time                          0.00209
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.84826
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.44160
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.72448
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.72351
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19978
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94904
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.00110
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11678.73074
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.44557
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74767
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.88801      0.47775    7.36576     6.41026
alpha_0                               0.99775      0.00015    0.99790     0.99760
alpha_1                               0.99775      0.00015    0.99790     0.99760
alpha_2                               0.99775      0.00015    0.99790     0.99760
alpha_3                               0.99775      0.00015    0.99790     0.99760
alpha_4                               0.99775      0.00015    0.99790     0.99760
alpha_5                               0.99775      0.00015    0.99790     0.99760
alpha_6                               0.99775      0.00015    0.99790     0.99760
alpha_7                               0.99775      0.00015    0.99790     0.99760
alpha_8                               0.99775      0.00015    0.99790     0.99760
alpha_9                               0.99775      0.00015    0.99790     0.99760
Alpha_loss                            -0.01302     0.00100    -0.01202    -0.01403
Training/policy_loss                  -2.67553     0.00143    -2.67410    -2.67696
Training/qf1_loss                     932.29587    105.20816  1037.50403  827.08771
Training/qf2_loss                     932.30896    105.20874  1037.51770  827.10022
Training/pf_norm                      0.41967      0.00488    0.42455     0.41479
Training/qf1_norm                     19.39731     0.96571    20.36302    18.43159
Training/qf2_norm                     19.42859     0.96561    20.39421    18.46298
log_std/mean                          -0.00399     0.00022    -0.00377    -0.00421
log_std/std                           0.00135      0.00000    0.00135     0.00135
log_std/max                           -0.00218     0.00022    -0.00196    -0.00239
log_std/min                           -0.00620     0.00023    -0.00597    -0.00642
log_probs/mean                        -2.67756     0.00161    -2.67596    -2.67917
log_probs/std                         0.41498      0.00447    0.41945     0.41050
log_probs/max                         -1.28186     0.16192    -1.11995    -1.44378
log_probs/min                         -3.95721     0.32327    -3.63394    -4.28047
mean/mean                             0.00060      0.00003    0.00064     0.00057
mean/std                              0.00168      0.00004    0.00172     0.00164
mean/max                              0.00417      0.00012    0.00429     0.00406
mean/min                              -0.00127     0.00000    -0.00127    -0.00128
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 4 50
freq 22
sample: [1, 8, 6, 7, 9, 5, 0, 4, 3, 2]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
train_time 0.12555432319641113
eval time 0.002669095993041992
2023-08-22 20:44:45,967 MainThread INFO: EPOCH:4
2023-08-22 20:44:45,967 MainThread INFO: Time Consumed:0.13160109519958496s
2023-08-22 20:44:45,967 MainThread INFO: Total Frames:7500s
  2%|▎         | 5/200 [00:09<03:11,  1.02it/s]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1143.03097
Train_Epoch_Reward                    1226.48245
Running_Training_Average_Rewards      782.07160
Explore_Time                          0.00259
Train___Time                          0.12555
Eval____Time                          0.00267
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.47516
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.41102
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.74266
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.74486
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21306
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.98511
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.04779
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11648.47101
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42714
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.76667
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.12289      0.22296    8.34584     7.89993
alpha_0                               0.99715      0.00015    0.99730     0.99700
alpha_1                               0.99715      0.00015    0.99730     0.99700
alpha_2                               0.99715      0.00015    0.99730     0.99701
alpha_3                               0.99715      0.00015    0.99730     0.99700
alpha_4                               0.99715      0.00015    0.99730     0.99701
alpha_5                               0.99715      0.00015    0.99730     0.99701
alpha_6                               0.99715      0.00015    0.99730     0.99701
alpha_7                               0.99715      0.00015    0.99730     0.99700
alpha_8                               0.99715      0.00015    0.99730     0.99700
alpha_9                               0.99715      0.00015    0.99730     0.99700
Alpha_loss                            -0.01702     0.00096    -0.01606    -0.01798
Training/policy_loss                  -2.67283     0.01503    -2.65780    -2.68786
Training/qf1_loss                     1216.18079   167.27405  1383.45483  1048.90674
Training/qf2_loss                     1216.19562   167.27448  1383.47009  1048.92114
Training/pf_norm                      0.42629      0.04395    0.47024     0.38235
Training/qf1_norm                     21.90682     0.44566    22.35248    21.46115
Training/qf2_norm                     21.94494     0.44481    22.38975    21.50014
log_std/mean                          -0.00487     0.00022    -0.00465    -0.00508
log_std/std                           0.00135      0.00000    0.00135     0.00135
log_std/max                           -0.00305     0.00022    -0.00283    -0.00327
log_std/min                           -0.00710     0.00023    -0.00688    -0.00733
log_probs/mean                        -2.67555     0.01490    -2.66065    -2.69045
log_probs/std                         0.42205      0.00086    0.42291     0.42118
log_probs/max                         -1.38373     0.03699    -1.34675    -1.42072
log_probs/min                         -4.19479     0.62095    -3.57384    -4.81573
mean/mean                             0.00074      0.00003    0.00077     0.00072
mean/std                              0.00173      0.00001    0.00174     0.00172
mean/max                              0.00438      0.00001    0.00439     0.00437
mean/min                              -0.00124     0.00001    -0.00123    -0.00124
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 5 50
freq 22
sample: [7, 6, 3, 5, 4, 0, 1, 2, 9, 8]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1034]
train_time 0.1314539909362793
eval time 0.002901792526245117
2023-08-22 20:44:46,220 MainThread INFO: EPOCH:5
2023-08-22 20:44:46,221 MainThread INFO: Time Consumed:0.1372232437133789s
2023-08-22 20:44:46,221 MainThread INFO: Total Frames:9000s
  3%|▎         | 6/200 [00:09<02:23,  1.35it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1140.28451
Train_Epoch_Reward                    15624.60574
Running_Training_Average_Rewards      849.12669
Explore_Time                          0.00235
Train___Time                          0.13145
Eval____Time                          0.00290
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.15444
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.38020
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.75409
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.75979
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20591
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99593
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07506
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11619.75571
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.41118
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.79118
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.88645      0.51052    7.39696     6.37593
alpha_0                               0.99656      0.00015    0.99670     0.99641
alpha_1                               0.99656      0.00015    0.99671     0.99641
alpha_2                               0.99656      0.00015    0.99671     0.99641
alpha_3                               0.99656      0.00015    0.99671     0.99641
alpha_4                               0.99656      0.00015    0.99671     0.99641
alpha_5                               0.99656      0.00015    0.99671     0.99641
alpha_6                               0.99656      0.00015    0.99671     0.99641
alpha_7                               0.99656      0.00015    0.99670     0.99641
alpha_8                               0.99656      0.00015    0.99670     0.99641
alpha_9                               0.99655      0.00015    0.99670     0.99640
Alpha_loss                            -0.02105     0.00099    -0.02006    -0.02204
Training/policy_loss                  -2.67904     0.00282    -2.67622    -2.68186
Training/qf1_loss                     949.78430    156.99829  1106.78259  792.78601
Training/qf2_loss                     949.79724    156.99878  1106.79602  792.79846
Training/pf_norm                      0.42776      0.00066    0.42842     0.42710
Training/qf1_norm                     19.37233     1.02613    20.39846    18.34620
Training/qf2_norm                     19.39869     1.03774    20.43643    18.36095
log_std/mean                          -0.00575     0.00022    -0.00553    -0.00597
log_std/std                           0.00135      0.00000    0.00135     0.00135
log_std/max                           -0.00393     0.00022    -0.00371    -0.00415
log_std/min                           -0.00801     0.00023    -0.00778    -0.00824
log_probs/mean                        -2.68247     0.00265    -2.67982    -2.68512
log_probs/std                         0.42687      0.00310    0.42997     0.42377
log_probs/max                         -1.24297     0.10072    -1.14225    -1.34369
log_probs/min                         -4.41743     0.28500    -4.13243    -4.70242
mean/mean                             0.00084      0.00002    0.00086     0.00082
mean/std                              0.00168      0.00001    0.00168     0.00167
mean/max                              0.00433      0.00000    0.00433     0.00433
mean/min                              -0.00116     0.00003    -0.00113    -0.00119
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 6 50
freq 22
sample: [6, 4, 8, 5, 2, 0, 3, 7, 9, 1]
replay_buffer._size: [1194 1149 1188 1200 1186 1154 1161 1179 1172 1154]
train_time 0.23905491828918457
eval time 0.0029032230377197266
2023-08-22 20:44:46,576 MainThread INFO: EPOCH:6
2023-08-22 20:44:46,576 MainThread INFO: Time Consumed:0.24396204948425293s
2023-08-22 20:44:46,576 MainThread INFO: Total Frames:10500s
  4%|▎         | 7/200 [00:10<01:58,  1.63it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1138.81868
Train_Epoch_Reward                    2080.35658
Running_Training_Average_Rewards      631.04816
Explore_Time                          0.00153
Train___Time                          0.23905
Eval____Time                          0.00290
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.14492
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33965
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.78338
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.73213
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18434
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99640
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.08540
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11647.10893
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.39828
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.76959
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.96616      0.09182   6.05798    5.87434
alpha_0                               0.99596      0.00015   0.99611    0.99581
alpha_1                               0.99596      0.00015   0.99611    0.99581
alpha_2                               0.99596      0.00015   0.99611    0.99581
alpha_3                               0.99596      0.00015   0.99611    0.99581
alpha_4                               0.99596      0.00015   0.99611    0.99581
alpha_5                               0.99596      0.00015   0.99611    0.99581
alpha_6                               0.99596      0.00015   0.99611    0.99581
alpha_7                               0.99596      0.00015   0.99611    0.99581
alpha_8                               0.99596      0.00015   0.99611    0.99581
alpha_9                               0.99596      0.00015   0.99611    0.99581
Alpha_loss                            -0.02508     0.00098   -0.02409   -0.02606
Training/policy_loss                  -2.68324     0.00584   -2.67740   -2.68907
Training/qf1_loss                     769.62189    20.26025  789.88214  749.36163
Training/qf2_loss                     769.63345    20.26022  789.89368  749.37323
Training/pf_norm                      0.39791      0.00820   0.40611    0.38971
Training/qf1_norm                     17.49305     0.17626   17.66930   17.31679
Training/qf2_norm                     17.51688     0.17890   17.69579   17.33798
log_std/mean                          -0.00663     0.00022   -0.00641   -0.00685
log_std/std                           0.00134      0.00000   0.00134    0.00134
log_std/max                           -0.00482     0.00022   -0.00460   -0.00504
log_std/min                           -0.00892     0.00023   -0.00869   -0.00915
log_probs/mean                        -2.68737     0.00569   -2.68168   -2.69306
log_probs/std                         0.42193      0.00147   0.42340    0.42046
log_probs/max                         -1.30924     0.03640   -1.27285   -1.34564
log_probs/min                         -3.96246     0.22341   -3.73904   -4.18587
mean/mean                             0.00097      0.00002   0.00099    0.00094
mean/std                              0.00164      0.00002   0.00166    0.00162
mean/max                              0.00433      0.00003   0.00436    0.00430
mean/min                              -0.00101     0.00001   -0.00100   -0.00103
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 7 50
freq 22
sample: [0, 5, 8, 3, 9, 2, 7, 1, 4, 6]
replay_buffer._size: [1349 1350 1348 1350 1350 1350 1350 1350 1334 1343]
train_time 0.18380022048950195
eval time 0.0022411346435546875
2023-08-22 20:44:46,919 MainThread INFO: EPOCH:7
2023-08-22 20:44:46,920 MainThread INFO: Time Consumed:0.19100260734558105s
2023-08-22 20:44:46,920 MainThread INFO: Total Frames:12000s
  4%|▍         | 8/200 [00:10<01:41,  1.89it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1139.22701
Train_Epoch_Reward                    2111.69158
Running_Training_Average_Rewards      660.55513
Explore_Time                          0.00429
Train___Time                          0.18380
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.90717
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29923
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.79676
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.70602
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16675
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99972
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.08539
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11659.01008
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.38448
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.75696
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.48880      0.30788   5.79667    5.18092
alpha_0                               0.99536      0.00015   0.99551    0.99521
alpha_1                               0.99536      0.00015   0.99551    0.99521
alpha_2                               0.99536      0.00015   0.99551    0.99521
alpha_3                               0.99536      0.00015   0.99551    0.99521
alpha_4                               0.99536      0.00015   0.99551    0.99521
alpha_5                               0.99536      0.00015   0.99551    0.99521
alpha_6                               0.99536      0.00015   0.99551    0.99521
alpha_7                               0.99536      0.00015   0.99551    0.99521
alpha_8                               0.99536      0.00015   0.99551    0.99521
alpha_9                               0.99536      0.00015   0.99551    0.99521
Alpha_loss                            -0.02909     0.00100   -0.02809   -0.03009
Training/policy_loss                  -2.68186     0.00035   -2.68151   -2.68222
Training/qf1_loss                     678.04892    41.02542  719.07434  637.02350
Training/qf2_loss                     678.05975    41.02606  719.08582  637.03369
Training/pf_norm                      0.39082      0.01229   0.40311    0.37853
Training/qf1_norm                     16.49423     0.62417   17.11840   15.87005
Training/qf2_norm                     16.51837     0.62060   17.13898   15.89777
log_std/mean                          -0.00752     0.00022   -0.00729   -0.00774
log_std/std                           0.00133      0.00000   0.00133    0.00133
log_std/max                           -0.00571     0.00022   -0.00549   -0.00593
log_std/min                           -0.00985     0.00023   -0.00962   -0.01007
log_probs/mean                        -2.68668     0.00018   -2.68650   -2.68686
log_probs/std                         0.41730      0.00500   0.42231    0.41230
log_probs/max                         -1.35239     0.01557   -1.33682   -1.36797
log_probs/min                         -4.52720     0.09744   -4.42976   -4.62463
mean/mean                             0.00107      0.00003   0.00110    0.00105
mean/std                              0.00162      0.00000   0.00163    0.00162
mean/max                              0.00439      0.00003   0.00442    0.00436
mean/min                              -0.00093     0.00002   -0.00091   -0.00094
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 8 50
freq 22
sample: [8, 6, 4, 3, 5, 0, 9, 7, 1, 2]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
train_time 0.11594009399414062
eval time 0.0024640560150146484
2023-08-22 20:44:47,211 MainThread INFO: EPOCH:8
2023-08-22 20:44:47,211 MainThread INFO: Time Consumed:0.12121748924255371s
2023-08-22 20:44:47,211 MainThread INFO: Total Frames:13500s
  4%|▍         | 9/200 [00:10<01:27,  2.19it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1141.12134
Train_Epoch_Reward                    3679.23981
Running_Training_Average_Rewards      262.37627
Explore_Time                          0.00223
Train___Time                          0.11594
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.53545
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.27260
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.81142
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.68419
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16289
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01052
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.09057
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11676.74370
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.37414
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74406
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.87410      0.01898   5.89308    5.85512
alpha_0                               0.99476      0.00015   0.99491    0.99461
alpha_1                               0.99476      0.00015   0.99491    0.99461
alpha_2                               0.99477      0.00015   0.99491    0.99462
alpha_3                               0.99476      0.00015   0.99491    0.99461
alpha_4                               0.99476      0.00015   0.99491    0.99461
alpha_5                               0.99476      0.00015   0.99491    0.99461
alpha_6                               0.99477      0.00015   0.99491    0.99462
alpha_7                               0.99476      0.00015   0.99491    0.99461
alpha_8                               0.99476      0.00015   0.99491    0.99461
alpha_9                               0.99476      0.00015   0.99491    0.99461
Alpha_loss                            -0.03309     0.00096   -0.03213   -0.03405
Training/policy_loss                  -2.67972     0.00880   -2.67092   -2.68852
Training/qf1_loss                     777.24832    12.02121  789.26953  765.22711
Training/qf2_loss                     777.25940    12.02100  789.28040  765.23840
Training/pf_norm                      0.42880      0.04083   0.46963    0.38796
Training/qf1_norm                     17.29684     0.04543   17.34226   17.25141
Training/qf2_norm                     17.32662     0.03985   17.36647   17.28677
log_std/mean                          -0.00841     0.00022   -0.00818   -0.00863
log_std/std                           0.00132      0.00000   0.00132    0.00132
log_std/max                           -0.00659     0.00022   -0.00637   -0.00681
log_std/min                           -0.01075     0.00022   -0.01053   -0.01097
log_probs/mean                        -2.68520     0.00868   -2.67652   -2.69388
log_probs/std                         0.40989      0.00383   0.41372    0.40607
log_probs/max                         -1.43235     0.06381   -1.36854   -1.49616
log_probs/min                         -4.52190     0.17631   -4.34560   -4.69821
mean/mean                             0.00110      0.00000   0.00110    0.00110
mean/std                              0.00164      0.00001   0.00165    0.00162
mean/max                              0.00439      0.00001   0.00440    0.00438
mean/min                              -0.00103     0.00006   -0.00097   -0.00108
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 9 50
freq 22
sample: [0, 8, 9, 5, 2, 7, 4, 3, 1, 6]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
train_time 0.11492490768432617
eval time 0.0021224021911621094
2023-08-22 20:44:47,510 MainThread INFO: EPOCH:9
2023-08-22 20:44:47,511 MainThread INFO: Time Consumed:0.12011098861694336s
2023-08-22 20:44:47,511 MainThread INFO: Total Frames:15000s
  5%|▌         | 10/200 [00:11<01:16,  2.48it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1142.90875
Train_Epoch_Reward                    5061.61010
Running_Training_Average_Rewards      361.75138
Explore_Time                          0.00240
Train___Time                          0.11492
Eval____Time                          0.00212
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.81640
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.24586
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.81971
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.65705
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14948
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01026
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07858
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11697.16833
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36177
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.73216
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.35107      0.19914   6.55021    6.15193
alpha_0                               0.99416      0.00015   0.99431    0.99402
alpha_1                               0.99416      0.00015   0.99431    0.99402
alpha_2                               0.99417      0.00015   0.99432    0.99402
alpha_3                               0.99417      0.00015   0.99432    0.99402
alpha_4                               0.99417      0.00015   0.99432    0.99402
alpha_5                               0.99417      0.00015   0.99432    0.99402
alpha_6                               0.99417      0.00015   0.99432    0.99402
alpha_7                               0.99417      0.00015   0.99432    0.99402
alpha_8                               0.99417      0.00015   0.99432    0.99402
alpha_9                               0.99417      0.00015   0.99431    0.99402
Alpha_loss                            -0.03712     0.00097   -0.03615   -0.03810
Training/policy_loss                  -2.68184     0.00535   -2.67649   -2.68719
Training/qf1_loss                     820.84830    91.15512  912.00342  729.69318
Training/qf2_loss                     820.85986    91.15546  912.01532  729.70441
Training/pf_norm                      0.39178      0.00827   0.40005    0.38351
Training/qf1_norm                     18.28980     0.42818   18.71799   17.86162
Training/qf2_norm                     18.32372     0.42711   18.75084   17.89661
log_std/mean                          -0.00931     0.00023   -0.00908   -0.00953
log_std/std                           0.00132      0.00000   0.00132    0.00132
log_std/max                           -0.00745     0.00021   -0.00724   -0.00766
log_std/min                           -0.01166     0.00023   -0.01143   -0.01189
log_probs/mean                        -2.68799     0.00521   -2.68277   -2.69320
log_probs/std                         0.40580      0.00407   0.40987    0.40173
log_probs/max                         -1.35916     0.06209   -1.29708   -1.42125
log_probs/min                         -4.17732     0.00767   -4.16965   -4.18500
mean/mean                             0.00100      0.00003   0.00103    0.00097
mean/std                              0.00160      0.00003   0.00163    0.00157
mean/max                              0.00411      0.00011   0.00422    0.00399
mean/min                              -0.00126     0.00004   -0.00122   -0.00130
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 10 50
freq 22
sample: [3, 2, 8, 9, 4, 5, 1, 0, 6, 7]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
train_time 0.12290525436401367
eval time 0.002758026123046875
snapshot at best
2023-08-22 20:44:48,352 MainThread INFO: EPOCH:10
2023-08-22 20:44:48,352 MainThread INFO: Time Consumed:0.6304080486297607s
2023-08-22 20:44:48,352 MainThread INFO: Total Frames:16500s
  6%|▌         | 11/200 [00:12<01:41,  1.86it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1144.59168
Train_Epoch_Reward                    16742.13285
Running_Training_Average_Rewards      849.43276
Explore_Time                          0.00506
Train___Time                          0.12291
Eval____Time                          0.00276
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.96388
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.23819
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.80726
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.64095
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.12076
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99788
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.05497
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11714.30626
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36735
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.71949
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.26986      0.53472    6.80458    5.73514
alpha_0                               0.99357      0.00015    0.99372    0.99342
alpha_1                               0.99357      0.00015    0.99372    0.99342
alpha_2                               0.99357      0.00015    0.99372    0.99342
alpha_3                               0.99357      0.00015    0.99372    0.99342
alpha_4                               0.99357      0.00015    0.99372    0.99342
alpha_5                               0.99357      0.00015    0.99372    0.99342
alpha_6                               0.99357      0.00015    0.99372    0.99342
alpha_7                               0.99357      0.00015    0.99372    0.99342
alpha_8                               0.99357      0.00015    0.99372    0.99342
alpha_9                               0.99357      0.00015    0.99372    0.99342
Alpha_loss                            -0.04117     0.00099    -0.04018   -0.04216
Training/policy_loss                  -2.68740     0.00255    -2.68484   -2.68995
Training/qf1_loss                     818.13339    127.17160  945.30499  690.96179
Training/qf2_loss                     818.14456    127.17252  945.31708  690.97205
Training/pf_norm                      0.38736      0.03480    0.42217    0.35256
Training/qf1_norm                     18.12189     1.10823    19.23012   17.01366
Training/qf2_norm                     18.15676     1.11032    19.26708   17.04645
log_std/mean                          -0.01021     0.00023    -0.00999   -0.01044
log_std/std                           0.00131      0.00000    0.00132    0.00131
log_std/max                           -0.00829     0.00021    -0.00808   -0.00850
log_std/min                           -0.01259     0.00024    -0.01235   -0.01283
log_probs/mean                        -2.69423     0.00241    -2.69182   -2.69664
log_probs/std                         0.41178      0.00251    0.41429    0.40928
log_probs/max                         -1.42603     0.01502    -1.41101   -1.44104
log_probs/min                         -4.41665     0.64789    -3.76875   -5.06454
mean/mean                             0.00088      0.00003    0.00091    0.00085
mean/std                              0.00152      0.00002    0.00154    0.00150
mean/max                              0.00370      0.00010    0.00380    0.00360
mean/min                              -0.00150     0.00005    -0.00144   -0.00155
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 11 50
freq 22
sample: [7, 2, 3, 9, 6, 5, 0, 4, 1, 8]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
train_time 0.1575300693511963
eval time 0.0028045177459716797
snapshot at best
2023-08-22 20:44:49,089 MainThread INFO: EPOCH:11
2023-08-22 20:44:49,089 MainThread INFO: Time Consumed:0.6304824352264404s
2023-08-22 20:44:49,089 MainThread INFO: Total Frames:18000s
  6%|▌         | 12/200 [00:12<01:52,  1.67it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1147.12717
Train_Epoch_Reward                    24557.08563
Running_Training_Average_Rewards      1545.36095
Explore_Time                          0.00277
Train___Time                          0.15753
Eval____Time                          0.00280
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.60095
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.25267
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.79980
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62637
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.09528
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.97622
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.03016
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11748.59164
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.39305
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.69462
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.69257      0.27203   6.96461    6.42054
alpha_0                               0.99297      0.00015   0.99312    0.99282
alpha_1                               0.99297      0.00015   0.99312    0.99282
alpha_2                               0.99298      0.00015   0.99312    0.99283
alpha_3                               0.99297      0.00015   0.99312    0.99282
alpha_4                               0.99298      0.00015   0.99312    0.99283
alpha_5                               0.99297      0.00015   0.99312    0.99282
alpha_6                               0.99298      0.00015   0.99313    0.99283
alpha_7                               0.99297      0.00015   0.99312    0.99282
alpha_8                               0.99297      0.00015   0.99312    0.99282
alpha_9                               0.99297      0.00015   0.99312    0.99282
Alpha_loss                            -0.04514     0.00100   -0.04414   -0.04615
Training/policy_loss                  -2.67904     0.00001   -2.67903   -2.67905
Training/qf1_loss                     910.86169    39.04541  949.90710  871.81628
Training/qf2_loss                     910.87341    39.04565  949.91907  871.82776
Training/pf_norm                      0.42365      0.01549   0.43914    0.40817
Training/qf1_norm                     19.00637     0.54412   19.55050   18.46225
Training/qf2_norm                     19.04139     0.54674   19.58813   18.49464
log_std/mean                          -0.01112     0.00023   -0.01089   -0.01135
log_std/std                           0.00132      0.00000   0.00132    0.00131
log_std/max                           -0.00913     0.00021   -0.00892   -0.00933
log_std/min                           -0.01355     0.00024   -0.01331   -0.01380
log_probs/mean                        -2.68646     0.00017   -2.68629   -2.68664
log_probs/std                         0.41199      0.00779   0.41978    0.40419
log_probs/max                         -1.36604     0.04440   -1.32164   -1.41044
log_probs/min                         -4.10409     0.15839   -3.94570   -4.26248
mean/mean                             0.00084      0.00000   0.00085    0.00084
mean/std                              0.00144      0.00001   0.00145    0.00142
mean/max                              0.00339      0.00006   0.00345    0.00333
mean/min                              -0.00158     0.00001   -0.00157   -0.00158
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 12 50
freq 22
sample: [5, 2, 6, 4, 1, 3, 8, 0, 7, 9]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
train_time 0.12104082107543945
eval time 0.0024695396423339844
snapshot at best
2023-08-22 20:44:49,778 MainThread INFO: EPOCH:12
2023-08-22 20:44:49,779 MainThread INFO: Time Consumed:0.5902857780456543s
2023-08-22 20:44:49,779 MainThread INFO: Total Frames:19500s
  6%|▋         | 13/200 [00:13<01:56,  1.61it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1150.59044
Train_Epoch_Reward                    5077.36858
Running_Training_Average_Rewards      1545.88624
Explore_Time                          0.00255
Train___Time                          0.12104
Eval____Time                          0.00247
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.63812
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26429
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.79900
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.60885
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.08031
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95481
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01298
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11792.63051
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.40746
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.66966
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.72900      0.40136    7.13037     6.32764
alpha_0                               0.99237      0.00015    0.99252     0.99223
alpha_1                               0.99238      0.00015    0.99252     0.99223
alpha_2                               0.99238      0.00015    0.99253     0.99223
alpha_3                               0.99238      0.00015    0.99253     0.99223
alpha_4                               0.99238      0.00015    0.99253     0.99223
alpha_5                               0.99238      0.00015    0.99253     0.99223
alpha_6                               0.99238      0.00015    0.99253     0.99223
alpha_7                               0.99238      0.00015    0.99253     0.99223
alpha_8                               0.99238      0.00015    0.99253     0.99223
alpha_9                               0.99238      0.00015    0.99253     0.99223
Alpha_loss                            -0.04917     0.00100    -0.04817    -0.05018
Training/policy_loss                  -2.68115     0.00051    -2.68064    -2.68166
Training/qf1_loss                     967.94489    137.23358  1105.17847  830.71130
Training/qf2_loss                     967.95700    137.23502  1105.19202  830.72198
Training/pf_norm                      0.42303      0.02461    0.44763     0.39842
Training/qf1_norm                     19.06765     0.80322    19.87087    18.26443
Training/qf2_norm                     19.09563     0.79373    19.88936    18.30190
log_std/mean                          -0.01204     0.00023    -0.01181    -0.01228
log_std/std                           0.00133      0.00000    0.00133     0.00132
log_std/max                           -0.00996     0.00021    -0.00975    -0.01018
log_std/min                           -0.01453     0.00025    -0.01428    -0.01477
log_probs/mean                        -2.68922     0.00035    -2.68887    -2.68958
log_probs/std                         0.41422      0.01700    0.43123     0.39722
log_probs/max                         -1.32541     0.03226    -1.29315    -1.35766
log_probs/min                         -5.06170     0.64399    -4.41771    -5.70569
mean/mean                             0.00082      0.00001    0.00083     0.00081
mean/std                              0.00139      0.00001    0.00140     0.00138
mean/max                              0.00312      0.00007    0.00318     0.00305
mean/min                              -0.00171     0.00005    -0.00166    -0.00176
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 13 50
freq 22
sample: [4, 0, 5, 1, 6, 3, 9, 7, 2, 8]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
train_time 0.11590147018432617
eval time 0.0023653507232666016
snapshot at best
2023-08-22 20:44:50,490 MainThread INFO: EPOCH:13
2023-08-22 20:44:50,490 MainThread INFO: Time Consumed:0.6251609325408936s
2023-08-22 20:44:50,490 MainThread INFO: Total Frames:21000s
  7%|▋         | 14/200 [00:14<02:00,  1.54it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1154.37134
Train_Epoch_Reward                    4673.82241
Running_Training_Average_Rewards      1143.60922
Explore_Time                          0.00245
Train___Time                          0.11590
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.90050
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26261
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.80437
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.58519
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.07149
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94200
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.99836
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11828.45128
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.41706
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.64698
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.11123      0.33572   6.44695    5.77551
alpha_0                               0.99178      0.00015   0.99193    0.99163
alpha_1                               0.99178      0.00015   0.99193    0.99163
alpha_2                               0.99178      0.00015   0.99193    0.99163
alpha_3                               0.99178      0.00015   0.99193    0.99163
alpha_4                               0.99178      0.00015   0.99193    0.99163
alpha_5                               0.99178      0.00015   0.99193    0.99163
alpha_6                               0.99179      0.00015   0.99194    0.99164
alpha_7                               0.99178      0.00015   0.99193    0.99163
alpha_8                               0.99178      0.00015   0.99193    0.99163
alpha_9                               0.99178      0.00015   0.99193    0.99163
Alpha_loss                            -0.05327     0.00096   -0.05230   -0.05423
Training/policy_loss                  -2.69004     0.00535   -2.68470   -2.69539
Training/qf1_loss                     718.44690    52.15613  770.60303  666.29077
Training/qf2_loss                     718.45731    52.15640  770.61371  666.30090
Training/pf_norm                      0.37163      0.00041   0.37204    0.37121
Training/qf1_norm                     17.81850     0.65160   18.47010   17.16691
Training/qf2_norm                     17.85476     0.65360   18.50836   17.20116
log_std/mean                          -0.01298     0.00023   -0.01274   -0.01321
log_std/std                           0.00134      0.00000   0.00134    0.00134
log_std/max                           -0.01081     0.00021   -0.01061   -0.01102
log_std/min                           -0.01553     0.00025   -0.01528   -0.01578
log_probs/mean                        -2.69882     0.00524   -2.69358   -2.70406
log_probs/std                         0.39268      0.00805   0.40074    0.38463
log_probs/max                         -1.54836     0.01884   -1.52953   -1.56720
log_probs/min                         -3.74896     0.02525   -3.72370   -3.77421
mean/mean                             0.00082      0.00000   0.00083    0.00082
mean/std                              0.00138      0.00000   0.00138    0.00138
mean/max                              0.00293      0.00005   0.00297    0.00288
mean/min                              -0.00191     0.00004   -0.00186   -0.00195
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 14 50
freq 22
sample: [9, 3, 0, 1, 2, 7, 5, 6, 4, 8]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
train_time 0.11692333221435547
eval time 0.0022416114807128906
snapshot at best
2023-08-22 20:44:51,199 MainThread INFO: EPOCH:14
2023-08-22 20:44:51,199 MainThread INFO: Time Consumed:0.6253676414489746s
2023-08-22 20:44:51,199 MainThread INFO: Total Frames:22500s
  8%|▊         | 15/200 [00:14<02:03,  1.50it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1157.40877
Train_Epoch_Reward                    11108.94231
Running_Training_Average_Rewards      695.33778
Explore_Time                          0.00232
Train___Time                          0.11692
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.84573
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26759
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.79551
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57757
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.05508
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92076
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98243
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11844.75723
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.43172
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.63561
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.31236      0.29795   6.61030    6.01441
alpha_0                               0.99118      0.00015   0.99133    0.99103
alpha_1                               0.99118      0.00015   0.99133    0.99103
alpha_2                               0.99119      0.00015   0.99134    0.99104
alpha_3                               0.99118      0.00015   0.99133    0.99104
alpha_4                               0.99119      0.00015   0.99134    0.99104
alpha_5                               0.99119      0.00015   0.99134    0.99104
alpha_6                               0.99119      0.00015   0.99134    0.99104
alpha_7                               0.99119      0.00015   0.99134    0.99104
alpha_8                               0.99119      0.00015   0.99133    0.99104
alpha_9                               0.99119      0.00015   0.99133    0.99104
Alpha_loss                            -0.05717     0.00098   -0.05619   -0.05815
Training/policy_loss                  -2.67559     0.00304   -2.67254   -2.67863
Training/qf1_loss                     816.02319    64.74036  880.76355  751.28284
Training/qf2_loss                     816.03427    64.74026  880.77454  751.29401
Training/pf_norm                      0.41555      0.03842   0.45397    0.37713
Training/qf1_norm                     18.21797     0.63287   18.85083   17.58510
Training/qf2_norm                     18.25048     0.64197   18.89245   17.60851
log_std/mean                          -0.01391     0.00023   -0.01368   -0.01414
log_std/std                           0.00136      0.00000   0.00136    0.00135
log_std/max                           -0.01165     0.00021   -0.01144   -0.01186
log_std/min                           -0.01655     0.00026   -0.01629   -0.01680
log_probs/mean                        -2.68485     0.00292   -2.68193   -2.68778
log_probs/std                         0.41020      0.00195   0.41214    0.40825
log_probs/max                         -1.33633     0.03967   -1.29666   -1.37600
log_probs/min                         -4.18434     0.21578   -3.96856   -4.40012
mean/mean                             0.00084      0.00000   0.00084    0.00083
mean/std                              0.00135      0.00001   0.00135    0.00134
mean/max                              0.00274      0.00003   0.00276    0.00271
mean/min                              -0.00195     0.00000   -0.00195   -0.00196
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 15 50
freq 22
sample: [6, 8, 5, 3, 9, 1, 0, 7, 4, 2]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
train_time 0.1237802505493164
eval time 0.0027599334716796875
snapshot at best
2023-08-22 20:44:51,942 MainThread INFO: EPOCH:15
2023-08-22 20:44:51,942 MainThread INFO: Time Consumed:0.6625182628631592s
2023-08-22 20:44:51,942 MainThread INFO: Total Frames:24000s
  8%|▊         | 16/200 [00:15<02:06,  1.45it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1159.79492
Train_Epoch_Reward                    9599.03101
Running_Training_Average_Rewards      846.05986
Explore_Time                          0.00269
Train___Time                          0.12378
Eval____Time                          0.00276
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.39397
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26986
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.80406
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57433
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.05234
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91289
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97673
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11869.82712
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.44395
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.61949
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.10439      0.35440  6.45879    5.75000
alpha_0                               0.99059      0.00015  0.99074    0.99044
alpha_1                               0.99059      0.00015  0.99074    0.99044
alpha_2                               0.99059      0.00015  0.99074    0.99044
alpha_3                               0.99059      0.00015  0.99074    0.99044
alpha_4                               0.99059      0.00015  0.99074    0.99044
alpha_5                               0.99060      0.00015  0.99074    0.99045
alpha_6                               0.99060      0.00015  0.99075    0.99045
alpha_7                               0.99059      0.00015  0.99074    0.99044
alpha_8                               0.99059      0.00015  0.99074    0.99044
alpha_9                               0.99059      0.00015  0.99074    0.99044
Alpha_loss                            -0.06128     0.00096  -0.06032   -0.06225
Training/policy_loss                  -2.68594     0.00483  -2.68111   -2.69077
Training/qf1_loss                     732.57605    2.17139  734.74744  730.40466
Training/qf2_loss                     732.58609    2.17038  734.75647  730.41571
Training/pf_norm                      0.36547      0.00030  0.36577    0.36517
Training/qf1_norm                     17.80462     0.71825  18.52287   17.08638
Training/qf2_norm                     17.84138     0.71071  18.55209   17.13068
log_std/mean                          -0.01485     0.00024  -0.01462   -0.01509
log_std/std                           0.00138      0.00000  0.00138    0.00137
log_std/max                           -0.01251     0.00022  -0.01229   -0.01273
log_std/min                           -0.01758     0.00026  -0.01732   -0.01784
log_probs/mean                        -2.69591     0.00472  -2.69119   -2.70063
log_probs/std                         0.40055      0.00470  0.40525    0.39585
log_probs/max                         -1.47265     0.11594  -1.35671   -1.58859
log_probs/min                         -4.40186     0.25391  -4.14795   -4.65577
mean/mean                             0.00088      0.00002  0.00090    0.00086
mean/std                              0.00131      0.00002  0.00133    0.00129
mean/max                              0.00272      0.00001  0.00273    0.00271
mean/min                              -0.00189     0.00005  -0.00184   -0.00195
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 16 50
freq 22
sample: [9, 6, 0, 8, 1, 3, 4, 7, 2, 5]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
train_time 0.13009071350097656
eval time 0.0023534297943115234
snapshot at best
2023-08-22 20:44:52,663 MainThread INFO: EPOCH:16
2023-08-22 20:44:52,663 MainThread INFO: Time Consumed:0.6356568336486816s
2023-08-22 20:44:52,663 MainThread INFO: Total Frames:25500s
  8%|▊         | 17/200 [00:16<02:08,  1.43it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1161.73414
Train_Epoch_Reward                    7934.37747
Running_Training_Average_Rewards      954.74503
Explore_Time                          0.00236
Train___Time                          0.13009
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.34240
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26046
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.82506
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57150
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.06721
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.91879
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98090
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11892.02233
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.44597
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.61071
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.18480      0.28600   6.47080    5.89879
alpha_0                               0.98999      0.00015   0.99014    0.98984
alpha_1                               0.98999      0.00015   0.99014    0.98984
alpha_2                               0.99000      0.00015   0.99015    0.98985
alpha_3                               0.98999      0.00015   0.99014    0.98985
alpha_4                               0.99000      0.00015   0.99015    0.98985
alpha_5                               0.99000      0.00015   0.99015    0.98985
alpha_6                               0.99000      0.00015   0.99015    0.98986
alpha_7                               0.99000      0.00015   0.99015    0.98985
alpha_8                               0.99000      0.00015   0.99014    0.98985
alpha_9                               0.99000      0.00015   0.99015    0.98985
Alpha_loss                            -0.06522     0.00126   -0.06396   -0.06649
Training/policy_loss                  -2.67672     0.02613   -2.65060   -2.70285
Training/qf1_loss                     783.79544    58.26199  842.05743  725.53345
Training/qf2_loss                     783.80487    58.26288  842.06775  725.54199
Training/pf_norm                      0.40254      0.07630   0.47884    0.32624
Training/qf1_norm                     17.94922     0.60969   18.55891   17.33953
Training/qf2_norm                     17.99214     0.60632   18.59846   17.38581
log_std/mean                          -0.01580     0.00024   -0.01556   -0.01605
log_std/std                           0.00140      0.00001   0.00141    0.00139
log_std/max                           -0.01339     0.00022   -0.01317   -0.01362
log_std/min                           -0.01861     0.00026   -0.01835   -0.01887
log_probs/mean                        -2.68718     0.02653   -2.66065   -2.71371
log_probs/std                         0.41043      0.01088   0.42132    0.39955
log_probs/max                         -1.34085     0.03623   -1.30462   -1.37707
log_probs/min                         -4.58197     0.89948   -3.68249   -5.48145
mean/mean                             0.00092      0.00002   0.00095    0.00090
mean/std                              0.00124      0.00002   0.00126    0.00122
mean/max                              0.00287      0.00009   0.00296    0.00278
mean/min                              -0.00171     0.00007   -0.00164   -0.00178
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 17 50
freq 22
sample: [8, 3, 2, 0, 6, 9, 5, 4, 1, 7]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
train_time 0.12439417839050293
eval time 0.002321481704711914
snapshot at best
2023-08-22 20:44:53,371 MainThread INFO: EPOCH:17
2023-08-22 20:44:53,371 MainThread INFO: Time Consumed:0.6157479286193848s
2023-08-22 20:44:53,371 MainThread INFO: Total Frames:27000s
  9%|▉         | 18/200 [00:17<02:07,  1.43it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1164.58199
Train_Epoch_Reward                    10336.05837
Running_Training_Average_Rewards      928.98223
Explore_Time                          0.00276
Train___Time                          0.12439
Eval____Time                          0.00232
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.50800
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.25883
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84269
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57847
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.09070
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.92675
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.99656
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11919.94738
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.46191
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.60266
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.90981      0.01315  6.92295    6.89666
alpha_0                               0.98940      0.00015  0.98955    0.98925
alpha_1                               0.98940      0.00015  0.98955    0.98925
alpha_2                               0.98940      0.00015  0.98955    0.98926
alpha_3                               0.98940      0.00015  0.98955    0.98925
alpha_4                               0.98941      0.00015  0.98955    0.98926
alpha_5                               0.98941      0.00015  0.98956    0.98926
alpha_6                               0.98941      0.00015  0.98956    0.98926
alpha_7                               0.98940      0.00015  0.98955    0.98925
alpha_8                               0.98940      0.00015  0.98955    0.98925
alpha_9                               0.98940      0.00015  0.98955    0.98926
Alpha_loss                            -0.06920     0.00102  -0.06818   -0.07022
Training/policy_loss                  -2.67262     0.00149  -2.67113   -2.67411
Training/qf1_loss                     907.88086    1.70715  909.58801  906.17371
Training/qf2_loss                     907.89169    1.70615  909.59784  906.18555
Training/pf_norm                      0.39801      0.00200  0.40001    0.39602
Training/qf1_norm                     19.46744     0.02511  19.49255   19.44233
Training/qf2_norm                     19.50740     0.03691  19.54431   19.47049
log_std/mean                          -0.01676     0.00024  -0.01652   -0.01700
log_std/std                           0.00142      0.00001  0.00143    0.00142
log_std/max                           -0.01429     0.00023  -0.01406   -0.01452
log_std/min                           -0.01965     0.00026  -0.01939   -0.01991
log_probs/mean                        -2.68362     0.00165  -2.68196   -2.68527
log_probs/std                         0.39977      0.00690  0.40667    0.39287
log_probs/max                         -1.41981     0.05661  -1.36320   -1.47643
log_probs/min                         -4.86632     0.89072  -3.97560   -5.75704
mean/mean                             0.00099      0.00001  0.00099    0.00098
mean/std                              0.00122      0.00000  0.00122    0.00121
mean/max                              0.00314      0.00004  0.00318    0.00310
mean/min                              -0.00157     0.00000  -0.00157   -0.00157
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 18 50
freq 22
sample: [3, 9, 5, 8, 0, 2, 1, 4, 6, 7]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
train_time 0.11824274063110352
eval time 0.0022552013397216797
2023-08-22 20:44:53,578 MainThread INFO: EPOCH:18
2023-08-22 20:44:53,578 MainThread INFO: Time Consumed:0.12356448173522949s
2023-08-22 20:44:53,578 MainThread INFO: Total Frames:28500s
 10%|▉         | 19/200 [00:17<01:42,  1.77it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1166.25452
Train_Epoch_Reward                    16678.56976
Running_Training_Average_Rewards      1164.96685
Explore_Time                          0.00256
Train___Time                          0.11824
Eval____Time                          0.00226
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.81630
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.25011
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85519
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.59020
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.11650
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94094
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01813
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11924.63387
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47452
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.61667
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.44857      0.31793   6.76650    6.13064
alpha_0                               0.98880      0.00015   0.98895    0.98866
alpha_1                               0.98880      0.00015   0.98895    0.98866
alpha_2                               0.98881      0.00015   0.98896    0.98866
alpha_3                               0.98880      0.00015   0.98895    0.98866
alpha_4                               0.98881      0.00015   0.98896    0.98866
alpha_5                               0.98882      0.00015   0.98896    0.98867
alpha_6                               0.98882      0.00015   0.98896    0.98867
alpha_7                               0.98881      0.00015   0.98896    0.98866
alpha_8                               0.98881      0.00015   0.98896    0.98866
alpha_9                               0.98881      0.00015   0.98896    0.98866
Alpha_loss                            -0.07341     0.00096   -0.07245   -0.07437
Training/policy_loss                  -2.69034     0.00441   -2.68593   -2.69475
Training/qf1_loss                     805.66135    28.76004  834.42139  776.90131
Training/qf2_loss                     805.66989    28.76010  834.42999  776.90979
Training/pf_norm                      0.35824      0.00402   0.36226    0.35422
Training/qf1_norm                     18.51486     0.65526   19.17011   17.85960
Training/qf2_norm                     18.56668     0.66088   19.22756   17.90579
log_std/mean                          -0.01773     0.00024   -0.01749   -0.01797
log_std/std                           0.00144      0.00001   0.00145    0.00144
log_std/max                           -0.01521     0.00023   -0.01498   -0.01544
log_std/min                           -0.02071     0.00027   -0.02044   -0.02097
log_probs/mean                        -2.70210     0.00431   -2.69779   -2.70640
log_probs/std                         0.39699      0.00604   0.40303    0.39095
log_probs/max                         -1.42610     0.01811   -1.40799   -1.44421
log_probs/min                         -4.79408     0.50562   -4.28846   -5.29971
mean/mean                             0.00099      0.00001   0.00100    0.00097
mean/std                              0.00118      0.00002   0.00120    0.00115
mean/max                              0.00317      0.00002   0.00319    0.00315
mean/min                              -0.00144     0.00004   -0.00140   -0.00148
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 19 50
freq 22
sample: [9, 4, 0, 1, 7, 2, 8, 3, 6, 5]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
train_time 0.11873745918273926
eval time 0.0024831295013427734
snapshot at best
2023-08-22 20:44:54,497 MainThread INFO: EPOCH:19
2023-08-22 20:44:54,497 MainThread INFO: Time Consumed:0.6464695930480957s
2023-08-22 20:44:54,497 MainThread INFO: Total Frames:30000s
 10%|█         | 20/200 [00:18<01:58,  1.52it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1167.93349
Train_Epoch_Reward                    2634.74597
Running_Training_Average_Rewards      988.31247
Explore_Time                          0.00214
Train___Time                          0.11874
Eval____Time                          0.00248
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.83090
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.24000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.86212
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.59100
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.13552
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94391
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.03002
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11939.10632
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47964
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.62460
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.61855      0.74665    7.36520     5.87191
alpha_0                               0.98821      0.00015    0.98836     0.98806
alpha_1                               0.98821      0.00015    0.98836     0.98806
alpha_2                               0.98822      0.00015    0.98836     0.98807
alpha_3                               0.98821      0.00015    0.98836     0.98806
alpha_4                               0.98822      0.00015    0.98837     0.98807
alpha_5                               0.98822      0.00015    0.98837     0.98808
alpha_6                               0.98822      0.00015    0.98837     0.98807
alpha_7                               0.98821      0.00015    0.98836     0.98807
alpha_8                               0.98821      0.00015    0.98836     0.98806
alpha_9                               0.98822      0.00015    0.98837     0.98807
Alpha_loss                            -0.07733     0.00097    -0.07636    -0.07829
Training/policy_loss                  -2.68045     0.00328    -2.67717    -2.68373
Training/qf1_loss                     837.19037    205.40314  1042.59351  631.78723
Training/qf2_loss                     837.19986    205.40427  1042.60413  631.79559
Training/pf_norm                      0.38228      0.00454    0.38681     0.37774
Training/qf1_norm                     18.90441     1.56107    20.46548    17.34334
Training/qf2_norm                     18.95032     1.56145    20.51176    17.38887
log_std/mean                          -0.01870     0.00024    -0.01846    -0.01895
log_std/std                           0.00146      0.00000    0.00146     0.00145
log_std/max                           -0.01611     0.00023    -0.01588    -0.01634
log_std/min                           -0.02174     0.00025    -0.02149    -0.02199
log_probs/mean                        -2.69265     0.00318    -2.68947    -2.69583
log_probs/std                         0.39460      0.00244    0.39705     0.39216
log_probs/max                         -1.31329     0.00818    -1.30511    -1.32147
log_probs/min                         -4.09552     0.43420    -3.66132    -4.52972
mean/mean                             0.00095      0.00001    0.00096     0.00094
mean/std                              0.00108      0.00003    0.00111     0.00106
mean/max                              0.00312      0.00002    0.00314     0.00310
mean/min                              -0.00123     0.00007    -0.00116    -0.00130
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 20 50
freq 22
sample: [4, 7, 3, 0, 2, 1, 5, 9, 6, 8]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
train_time 0.1320960521697998
eval time 0.0026140213012695312
2023-08-22 20:44:54,720 MainThread INFO: EPOCH:20
2023-08-22 20:44:54,720 MainThread INFO: Time Consumed:0.13767004013061523s
2023-08-22 20:44:54,720 MainThread INFO: Total Frames:31500s
 10%|█         | 21/200 [00:18<01:36,  1.86it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1168.09204
Train_Epoch_Reward                    10921.36767
Running_Training_Average_Rewards      1007.82278
Explore_Time                          0.00242
Train___Time                          0.13210
Eval____Time                          0.00261
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.63676
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.24981
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.87185
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.60450
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16932
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95696
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.05759
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11939.12828
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.51275
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.63130
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.58316      0.51193   7.09509    6.07123
alpha_0                               0.98762      0.00015   0.98777    0.98747
alpha_1                               0.98762      0.00015   0.98777    0.98747
alpha_2                               0.98762      0.00015   0.98777    0.98747
alpha_3                               0.98762      0.00015   0.98777    0.98747
alpha_4                               0.98762      0.00015   0.98777    0.98748
alpha_5                               0.98763      0.00015   0.98778    0.98748
alpha_6                               0.98763      0.00015   0.98778    0.98748
alpha_7                               0.98762      0.00015   0.98777    0.98747
alpha_8                               0.98762      0.00015   0.98777    0.98747
alpha_9                               0.98762      0.00015   0.98777    0.98748
Alpha_loss                            -0.08141     0.00103   -0.08038   -0.08243
Training/policy_loss                  -2.68501     0.00154   -2.68347   -2.68654
Training/qf1_loss                     838.14191    91.19891  929.34082  746.94299
Training/qf2_loss                     838.15430    91.19958  929.35388  746.95471
Training/pf_norm                      0.35072      0.02518   0.37589    0.32554
Training/qf1_norm                     18.81988     1.05389   19.87378   17.76599
Training/qf2_norm                     18.83547     1.05505   19.89052   17.78042
log_std/mean                          -0.01968     0.00024   -0.01943   -0.01992
log_std/std                           0.00147      0.00001   0.00148    0.00147
log_std/max                           -0.01705     0.00024   -0.01681   -0.01729
log_std/min                           -0.02277     0.00026   -0.02251   -0.02303
log_probs/mean                        -2.69780     0.00170   -2.69610   -2.69950
log_probs/std                         0.41494      0.01524   0.43018    0.39969
log_probs/max                         -1.46524     0.00995   -1.45529   -1.47519
log_probs/min                         -5.98988     1.98037   -4.00951   -7.97025
mean/mean                             0.00090      0.00001   0.00091    0.00089
mean/std                              0.00102      0.00001   0.00103    0.00101
mean/max                              0.00293      0.00004   0.00296    0.00289
mean/min                              -0.00115     0.00009   -0.00106   -0.00124
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 21 50
freq 22
sample: [9, 8, 2, 4, 0, 3, 5, 1, 7, 6]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
train_time 0.136214017868042
eval time 0.0031468868255615234
2023-08-22 20:44:55,153 MainThread INFO: EPOCH:21
2023-08-22 20:44:55,153 MainThread INFO: Time Consumed:0.1420755386352539s
2023-08-22 20:44:55,153 MainThread INFO: Total Frames:33000s
 11%|█         | 22/200 [00:18<01:30,  1.98it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1168.35860
Train_Epoch_Reward                    6723.65546
Running_Training_Average_Rewards      675.99230
Explore_Time                          0.00221
Train___Time                          0.13621
Eval____Time                          0.00315
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.40856
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.25903
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.87235
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62912
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21356
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.98193
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.09785
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11925.61422
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.55130
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.64848
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.29678      0.63171    7.92849     6.66507
alpha_0                               0.98703      0.00015    0.98717     0.98688
alpha_1                               0.98702      0.00015    0.98717     0.98688
alpha_2                               0.98703      0.00015    0.98718     0.98688
alpha_3                               0.98702      0.00015    0.98717     0.98688
alpha_4                               0.98703      0.00015    0.98718     0.98688
alpha_5                               0.98704      0.00015    0.98719     0.98689
alpha_6                               0.98704      0.00015    0.98719     0.98689
alpha_7                               0.98703      0.00015    0.98717     0.98688
alpha_8                               0.98703      0.00015    0.98717     0.98688
alpha_9                               0.98703      0.00015    0.98718     0.98688
Alpha_loss                            -0.08535     0.00097    -0.08438    -0.08631
Training/policy_loss                  -2.67797     0.00309    -2.67489    -2.68106
Training/qf1_loss                     992.26190    164.19684  1156.45874  828.06506
Training/qf2_loss                     992.27121    164.19815  1156.46936  828.07306
Training/pf_norm                      0.35213      0.02350    0.37564     0.32863
Training/qf1_norm                     20.31700     1.33261    21.64961    18.98439
Training/qf2_norm                     20.36834     1.33087    21.69921    19.03747
log_std/mean                          -0.02066     0.00024    -0.02041    -0.02090
log_std/std                           0.00149      0.00001    0.00150     0.00149
log_std/max                           -0.01797     0.00022    -0.01775    -0.01819
log_std/min                           -0.02380     0.00026    -0.02354    -0.02407
log_probs/mean                        -2.69121     0.00300    -2.68821    -2.69421
log_probs/std                         0.39256      0.00781    0.40037     0.38475
log_probs/max                         -1.40719     0.05751    -1.34968    -1.46470
log_probs/min                         -3.75170     0.09968    -3.65201    -3.85138
mean/mean                             0.00091      0.00001    0.00092     0.00091
mean/std                              0.00097      0.00001    0.00098     0.00097
mean/max                              0.00295      0.00003    0.00298     0.00292
mean/min                              -0.00137     0.00003    -0.00134    -0.00139
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 22 50
freq 22
start to update mask
sample: [5, 6, 3, 7, 4, 1, 0, 9, 8, 2]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
train_time 0.16522574424743652
eval time 0.003904581069946289
2023-08-22 20:44:58,881 MainThread INFO: EPOCH:22
2023-08-22 20:44:58,881 MainThread INFO: Time Consumed:0.1742100715637207s
2023-08-22 20:44:58,882 MainThread INFO: Total Frames:34500s
 12%|█▏        | 23/200 [00:22<04:21,  1.48s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1167.92013
Train_Epoch_Reward                    6074.49413
Running_Training_Average_Rewards      790.65057
Explore_Time                          0.00368
Train___Time                          0.16523
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.77496
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26600
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.88369
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.64789
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25777
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01477
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14274
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11925.44107
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.58122
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.65772
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.97038      0.15192   6.12230    5.81846
alpha_0                               0.98643      0.00015   0.98658    0.98629
alpha_1                               0.98643      0.00015   0.98658    0.98628
alpha_2                               0.98644      0.00015   0.98659    0.98629
alpha_3                               0.98643      0.00015   0.98658    0.98628
alpha_4                               0.98644      0.00015   0.98659    0.98629
alpha_5                               0.98645      0.00015   0.98659    0.98630
alpha_6                               0.98645      0.00015   0.98659    0.98630
alpha_7                               0.98643      0.00015   0.98658    0.98629
alpha_8                               0.98643      0.00015   0.98658    0.98628
alpha_9                               0.98644      0.00015   0.98659    0.98629
Alpha_loss                            -0.08917     0.00100   -0.08817   -0.09016
Training/policy_loss                  -2.66133     0.00067   -2.66066   -2.66201
Training/qf1_loss                     614.83319    49.91974  664.75293  564.91345
Training/qf2_loss                     614.84717    49.92029  664.76746  564.92688
Training/pf_norm                      0.41335      0.01777   0.43112    0.39557
Training/qf1_norm                     17.68128     0.32084   18.00212   17.36045
Training/qf2_norm                     17.64020     0.31906   17.95926   17.32114
log_std/mean                          -0.01822     0.00022   -0.01800   -0.01843
log_std/std                           0.00165      0.00000   0.00166    0.00165
log_std/max                           -0.01548     0.00021   -0.01527   -0.01569
log_std/min                           -0.02159     0.00023   -0.02136   -0.02181
log_probs/mean                        -2.67647     0.00052   -2.67596   -2.67699
log_probs/std                         0.39944      0.00133   0.40077    0.39811
log_probs/max                         -1.37713     0.00154   -1.37559   -1.37866
log_probs/min                         -3.60243     0.04572   -3.55671   -3.64815
mean/mean                             0.00100      0.00000   0.00100    0.00100
mean/std                              0.00076      0.00003   0.00079    0.00074
mean/max                              0.00261      0.00003   0.00263    0.00258
mean/min                              -0.00024     0.00008   -0.00016   -0.00032
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 23 50
freq 22
sample: [6, 4, 8, 5, 7, 0, 9, 3, 2, 1]
replay_buffer._size: [3747 3750 3750 3750 3750 3750 3750 3750 3732 3731]
train_time 0.11914587020874023
eval time 0.002451658248901367
2023-08-22 20:44:59,132 MainThread INFO: EPOCH:23
2023-08-22 20:44:59,132 MainThread INFO: Time Consumed:0.124176025390625s
2023-08-22 20:44:59,132 MainThread INFO: Total Frames:36000s
 12%|█▏        | 24/200 [00:22<03:13,  1.10s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1167.98012
Train_Epoch_Reward                    10427.11610
Running_Training_Average_Rewards      774.17552
Explore_Time                          0.00210
Train___Time                          0.11915
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.12461
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.27503
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.90227
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.66028
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.29675
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.04328
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.17903
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11935.98520
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.59968
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.66697
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.56077      0.13778   5.69855    5.42299
alpha_0                               0.98584      0.00015   0.98599    0.98569
alpha_1                               0.98584      0.00015   0.98599    0.98569
alpha_2                               0.98585      0.00015   0.98599    0.98570
alpha_3                               0.98584      0.00015   0.98599    0.98569
alpha_4                               0.98585      0.00015   0.98600    0.98570
alpha_5                               0.98586      0.00015   0.98600    0.98571
alpha_6                               0.98585      0.00015   0.98600    0.98571
alpha_7                               0.98584      0.00015   0.98599    0.98569
alpha_8                               0.98584      0.00015   0.98599    0.98569
alpha_9                               0.98585      0.00015   0.98600    0.98570
Alpha_loss                            -0.09328     0.00102   -0.09226   -0.09431
Training/policy_loss                  -2.66853     0.00136   -2.66717   -2.66989
Training/qf1_loss                     560.68439    43.00085  603.68524  517.68353
Training/qf2_loss                     560.69720    43.00208  603.69928  517.69513
Training/pf_norm                      0.42383      0.01338   0.43721    0.41045
Training/qf1_norm                     16.80868     0.31487   17.12355   16.49381
Training/qf2_norm                     16.77227     0.30909   17.08137   16.46318
log_std/mean                          -0.01913     0.00024   -0.01889   -0.01937
log_std/std                           0.00166      0.00000   0.00166    0.00166
log_std/max                           -0.01639     0.00023   -0.01616   -0.01662
log_std/min                           -0.02251     0.00024   -0.02226   -0.02275
log_probs/mean                        -2.68436     0.00151   -2.68285   -2.68587
log_probs/std                         0.39458      0.00938   0.40396    0.38520
log_probs/max                         -1.46364     0.00502   -1.45862   -1.46867
log_probs/min                         -4.44878     0.22579   -4.22300   -4.67457
mean/mean                             0.00098      0.00001   0.00099    0.00098
mean/std                              0.00085      0.00001   0.00086    0.00084
mean/max                              0.00266      0.00000   0.00266    0.00266
mean/min                              -0.00053     0.00005   -0.00048   -0.00057
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 24 50
freq 22
sample: [9, 5, 1, 8, 4, 7, 0, 6, 3, 2]
replay_buffer._size: [3861 3842 3878 3872 3882 3855 3837 3837 3828 3825]
train_time 0.13763213157653809
eval time 0.002485990524291992
snapshot at best
2023-08-22 20:44:59,913 MainThread INFO: EPOCH:24
2023-08-22 20:44:59,913 MainThread INFO: Time Consumed:0.6797323226928711s
2023-08-22 20:44:59,913 MainThread INFO: Total Frames:37500s
 12%|█▎        | 25/200 [00:23<02:55,  1.01s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1170.32699
Train_Epoch_Reward                    10220.87140
Running_Training_Average_Rewards      890.74939
Explore_Time                          0.00175
Train___Time                          0.13763
Eval____Time                          0.00249
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.30610
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.40540
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.86107
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.76955
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30694
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.04978
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14456
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12003.52091
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57507
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74424
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.81752      0.13684   6.95435    6.68068
alpha_0                               0.98525      0.00015   0.98540    0.98510
alpha_1                               0.98525      0.00015   0.98540    0.98510
alpha_2                               0.98525      0.00015   0.98540    0.98511
alpha_3                               0.98525      0.00015   0.98540    0.98510
alpha_4                               0.98526      0.00015   0.98541    0.98511
alpha_5                               0.98526      0.00015   0.98541    0.98512
alpha_6                               0.98526      0.00015   0.98541    0.98511
alpha_7                               0.98525      0.00015   0.98540    0.98510
alpha_8                               0.98525      0.00015   0.98540    0.98510
alpha_9                               0.98526      0.00015   0.98540    0.98511
Alpha_loss                            -0.09769     0.00104   -0.09666   -0.09873
Training/policy_loss                  -2.69475     0.00182   -2.69293   -2.69658
Training/qf1_loss                     809.41763    27.67484  837.09247  781.74280
Training/qf2_loss                     809.43295    27.67575  837.10870  781.75720
Training/pf_norm                      0.32741      0.00281   0.33021    0.32460
Training/qf1_norm                     19.43875     0.28494   19.72369   19.15381
Training/qf2_norm                     19.39374     0.28159   19.67533   19.11215
log_std/mean                          -0.02012     0.00025   -0.01987   -0.02037
log_std/std                           0.00166      0.00000   0.00166    0.00166
log_std/max                           -0.01736     0.00025   -0.01712   -0.01761
log_std/min                           -0.02351     0.00025   -0.02327   -0.02376
log_probs/mean                        -2.71146     0.00196   -2.70950   -2.71343
log_probs/std                         0.40557      0.00216   0.40773    0.40341
log_probs/max                         -1.41228     0.03290   -1.37938   -1.44518
log_probs/min                         -5.12871     0.65599   -4.47272   -5.78470
mean/mean                             0.00094      0.00001   0.00096    0.00093
mean/std                              0.00085      0.00000   0.00086    0.00085
mean/max                              0.00256      0.00003   0.00260    0.00253
mean/min                              -0.00069     0.00003   -0.00066   -0.00072
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 25 50
freq 22
sample: [2, 8, 6, 0, 1, 3, 7, 9, 5, 4]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
train_time 0.12926363945007324
eval time 0.002332925796508789
snapshot at best
2023-08-22 20:45:00,661 MainThread INFO: EPOCH:25
2023-08-22 20:45:00,661 MainThread INFO: Time Consumed:0.6433508396148682s
2023-08-22 20:45:00,661 MainThread INFO: Total Frames:39000s
 13%|█▎        | 26/200 [00:24<02:41,  1.08it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1172.86788
Train_Epoch_Reward                    19727.25098
Running_Training_Average_Rewards      1345.84128
Explore_Time                          0.00320
Train___Time                          0.12926
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.96997
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.42497
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85041
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.78247
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30981
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.05421
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.15287
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12008.32741
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.59761
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74415
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.75764      0.49860    7.25624    6.25904
alpha_0                               0.98466      0.00015    0.98481    0.98451
alpha_1                               0.98465      0.00015    0.98480    0.98451
alpha_2                               0.98466      0.00015    0.98481    0.98452
alpha_3                               0.98466      0.00015    0.98480    0.98451
alpha_4                               0.98467      0.00015    0.98481    0.98452
alpha_5                               0.98467      0.00015    0.98482    0.98452
alpha_6                               0.98467      0.00015    0.98482    0.98452
alpha_7                               0.98466      0.00015    0.98481    0.98451
alpha_8                               0.98466      0.00015    0.98480    0.98451
alpha_9                               0.98467      0.00015    0.98481    0.98452
Alpha_loss                            -0.10160     0.00119    -0.10041   -0.10279
Training/policy_loss                  -2.68619     0.01190    -2.67429   -2.69810
Training/qf1_loss                     855.55368    115.02090  970.57458  740.53278
Training/qf2_loss                     855.56921    115.02246  970.59167  740.54675
Training/pf_norm                      0.32946      0.03594    0.36540    0.29352
Training/qf1_norm                     19.30107     1.04603    20.34711   18.25504
Training/qf2_norm                     19.25848     1.04050    20.29898   18.21798
log_std/mean                          -0.02112     0.00026    -0.02087   -0.02138
log_std/std                           0.00166      0.00000    0.00167    0.00166
log_std/max                           -0.01837     0.00025    -0.01812   -0.01861
log_std/min                           -0.02448     0.00023    -0.02425   -0.02472
log_probs/mean                        -2.70322     0.01219    -2.69104   -2.71541
log_probs/std                         0.39039      0.00262    0.39301    0.38777
log_probs/max                         -1.48144     0.00805    -1.47339   -1.48949
log_probs/min                         -5.02193     0.50483    -4.51710   -5.52676
mean/mean                             0.00098      0.00002    0.00100    0.00095
mean/std                              0.00087      0.00001    0.00087    0.00086
mean/max                              0.00252      0.00001    0.00254    0.00251
mean/min                              -0.00078     0.00000    -0.00078   -0.00078
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 26 50
freq 22
sample: [5, 0, 8, 6, 7, 3, 9, 4, 2, 1]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
train_time 0.14345860481262207
eval time 0.002524137496948242
snapshot at best
2023-08-22 20:45:01,471 MainThread INFO: EPOCH:26
2023-08-22 20:45:01,471 MainThread INFO: Time Consumed:0.7160756587982178s
2023-08-22 20:45:01,471 MainThread INFO: Total Frames:40500s
 14%|█▎        | 27/200 [00:25<02:34,  1.12it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1175.82122
Train_Epoch_Reward                    10134.35123
Running_Training_Average_Rewards      1336.08245
Explore_Time                          0.00294
Train___Time                          0.14346
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.36589
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.44209
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.84589
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.79162
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31949
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.06282
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.16432
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12019.18740
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61589
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74181
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.55701      0.08706  6.64407    6.46996
alpha_0                               0.98407      0.00015  0.98422    0.98392
alpha_1                               0.98406      0.00015  0.98421    0.98391
alpha_2                               0.98407      0.00015  0.98422    0.98392
alpha_3                               0.98407      0.00015  0.98421    0.98392
alpha_4                               0.98408      0.00015  0.98422    0.98393
alpha_5                               0.98408      0.00015  0.98423    0.98393
alpha_6                               0.98408      0.00015  0.98423    0.98393
alpha_7                               0.98407      0.00015  0.98422    0.98392
alpha_8                               0.98406      0.00015  0.98421    0.98392
alpha_9                               0.98407      0.00015  0.98422    0.98393
Alpha_loss                            -0.10539     0.00094  -0.10445   -0.10632
Training/policy_loss                  -2.67131     0.00440  -2.66691   -2.67571
Training/qf1_loss                     693.56125    3.77383  697.33508  689.78741
Training/qf2_loss                     693.57721    3.77423  697.35144  689.80298
Training/pf_norm                      0.35977      0.02073  0.38050    0.33904
Training/qf1_norm                     18.92951     0.20197  19.13149   18.72754
Training/qf2_norm                     18.88400     0.19983  19.08383   18.68418
log_std/mean                          -0.02215     0.00026  -0.02189   -0.02240
log_std/std                           0.00167      0.00000  0.00167    0.00167
log_std/max                           -0.01936     0.00024  -0.01911   -0.01960
log_std/min                           -0.02547     0.00025  -0.02522   -0.02573
log_probs/mean                        -2.68849     0.00437  -2.68412   -2.69287
log_probs/std                         0.39430      0.00708  0.40138    0.38721
log_probs/max                         -1.42726     0.06511  -1.36215   -1.49237
log_probs/min                         -4.62006     0.23402  -4.38604   -4.85408
mean/mean                             0.00107      0.00001  0.00108    0.00106
mean/std                              0.00090      0.00001  0.00091    0.00089
mean/max                              0.00261      0.00002  0.00263    0.00259
mean/min                              -0.00077     0.00000  -0.00077   -0.00078
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 27 50
freq 22
sample: [5, 7, 3, 9, 0, 4, 8, 6, 2, 1]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
train_time 0.12032580375671387
eval time 0.0023882389068603516
snapshot at best
2023-08-22 20:45:02,202 MainThread INFO: EPOCH:27
2023-08-22 20:45:02,202 MainThread INFO: Time Consumed:0.6327550411224365s
2023-08-22 20:45:02,202 MainThread INFO: Total Frames:42000s
 14%|█▍        | 28/200 [00:25<02:24,  1.19it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1176.74937
Train_Epoch_Reward                    16412.74938
Running_Training_Average_Rewards      1542.47839
Explore_Time                          0.00242
Train___Time                          0.12033
Eval____Time                          0.00239
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.34853
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.43202
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85204
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.78767
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.32248
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.06939
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.17369
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12028.53939
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.60807
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.74297
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.40388      0.20563   6.60952    6.19825
alpha_0                               0.98348      0.00015   0.98363    0.98333
alpha_1                               0.98347      0.00015   0.98362    0.98332
alpha_2                               0.98348      0.00015   0.98363    0.98333
alpha_3                               0.98347      0.00015   0.98362    0.98333
alpha_4                               0.98348      0.00015   0.98363    0.98334
alpha_5                               0.98349      0.00015   0.98364    0.98334
alpha_6                               0.98349      0.00015   0.98364    0.98334
alpha_7                               0.98348      0.00015   0.98363    0.98333
alpha_8                               0.98347      0.00015   0.98362    0.98333
alpha_9                               0.98348      0.00015   0.98363    0.98334
Alpha_loss                            -0.10929     0.00112   -0.10817   -0.11041
Training/policy_loss                  -2.66398     0.00671   -2.65727   -2.67069
Training/qf1_loss                     746.76178    67.68622  814.44800  679.07556
Training/qf2_loss                     746.77847    67.68698  814.46545  679.09149
Training/pf_norm                      0.38085      0.00952   0.39037    0.37134
Training/qf1_norm                     18.60228     0.39362   18.99590   18.20866
Training/qf2_norm                     18.55516     0.38921   18.94437   18.16596
log_std/mean                          -0.02319     0.00027   -0.02292   -0.02346
log_std/std                           0.00167      0.00000   0.00167    0.00167
log_std/max                           -0.02037     0.00026   -0.02011   -0.02063
log_std/min                           -0.02649     0.00027   -0.02622   -0.02675
log_probs/mean                        -2.68140     0.00691   -2.67449   -2.68831
log_probs/std                         0.39371      0.00453   0.39823    0.38918
log_probs/max                         -1.45910     0.00002   -1.45908   -1.45912
log_probs/min                         -3.62570     0.04439   -3.58131   -3.67010
mean/mean                             0.00111      0.00001   0.00112    0.00110
mean/std                              0.00086      0.00001   0.00088    0.00085
mean/max                              0.00253      0.00004   0.00257    0.00250
mean/min                              -0.00064     0.00004   -0.00060   -0.00068
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 28 50
freq 22
sample: [5, 0, 2, 3, 6, 7, 4, 1, 8, 9]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
train_time 0.11676406860351562
eval time 0.002262592315673828
snapshot at best
2023-08-22 20:45:02,894 MainThread INFO: EPOCH:28
2023-08-22 20:45:02,894 MainThread INFO: Time Consumed:0.6108787059783936s
2023-08-22 20:45:02,894 MainThread INFO: Total Frames:43500s
 14%|█▍        | 29/200 [00:26<02:15,  1.26it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1178.15718
Train_Epoch_Reward                    4112.56784
Running_Training_Average_Rewards      1021.98895
Explore_Time                          0.00241
Train___Time                          0.11676
Eval____Time                          0.00226
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.83548
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.42255
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.85837
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.77111
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30702
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.05951
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.16843
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12043.43114
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.60102
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.73241
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.57302      0.47267    7.04569    6.10035
alpha_0                               0.98289      0.00015    0.98304    0.98274
alpha_1                               0.98288      0.00015    0.98303    0.98273
alpha_2                               0.98289      0.00015    0.98304    0.98274
alpha_3                               0.98288      0.00015    0.98303    0.98274
alpha_4                               0.98289      0.00015    0.98304    0.98275
alpha_5                               0.98290      0.00015    0.98305    0.98275
alpha_6                               0.98290      0.00015    0.98305    0.98275
alpha_7                               0.98289      0.00015    0.98304    0.98274
alpha_8                               0.98288      0.00015    0.98303    0.98274
alpha_9                               0.98289      0.00015    0.98304    0.98275
Alpha_loss                            -0.11381     0.00080    -0.11300   -0.11461
Training/policy_loss                  -2.69309     0.01194    -2.68115   -2.70503
Training/qf1_loss                     800.68936    164.07101  964.76038  636.61835
Training/qf2_loss                     800.70706    164.07242  964.77948  636.63464
Training/pf_norm                      0.33569      0.01716    0.35285    0.31853
Training/qf1_norm                     18.96282     0.94856    19.91138   18.01426
Training/qf2_norm                     18.91211     0.94284    19.85495   17.96928
log_std/mean                          -0.02426     0.00027    -0.02399   -0.02453
log_std/std                           0.00167      0.00000    0.00167    0.00167
log_std/max                           -0.02140     0.00026    -0.02115   -0.02166
log_std/min                           -0.02754     0.00026    -0.02727   -0.02780
log_probs/mean                        -2.71131     0.01207    -2.69923   -2.72338
log_probs/std                         0.39373      0.00097    0.39470    0.39276
log_probs/max                         -1.51508     0.03358    -1.48150   -1.54865
log_probs/min                         -5.08217     0.34450    -4.73766   -5.42667
mean/mean                             0.00114      0.00002    0.00115    0.00112
mean/std                              0.00085      0.00001    0.00086    0.00084
mean/max                              0.00244      0.00002    0.00246    0.00242
mean/min                              -0.00048     0.00006    -0.00042   -0.00054
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 29 50
freq 22
sample: [7, 5, 2, 1, 9, 3, 6, 8, 4, 0]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
train_time 0.15287542343139648
eval time 0.0023086071014404297
snapshot at best
2023-08-22 20:45:03,607 MainThread INFO: EPOCH:29
2023-08-22 20:45:03,607 MainThread INFO: Time Consumed:0.6307759284973145s
2023-08-22 20:45:03,607 MainThread INFO: Total Frames:45000s
 15%|█▌        | 30/200 [00:27<02:11,  1.29it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1179.97573
Train_Epoch_Reward                    5480.88856
Running_Training_Average_Rewards      866.87353
Explore_Time                          0.00250
Train___Time                          0.15288
Eval____Time                          0.00231
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.11502
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.41863
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.86345
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.74512
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28096
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.03904
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.15202
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12072.31374
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.59913
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.70617
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.49929      0.39874   6.89803    6.10054
alpha_0                               0.98230      0.00015   0.98245    0.98215
alpha_1                               0.98229      0.00015   0.98244    0.98214
alpha_2                               0.98230      0.00015   0.98245    0.98215
alpha_3                               0.98229      0.00015   0.98244    0.98214
alpha_4                               0.98231      0.00015   0.98245    0.98216
alpha_5                               0.98231      0.00015   0.98246    0.98217
alpha_6                               0.98231      0.00015   0.98246    0.98216
alpha_7                               0.98230      0.00015   0.98245    0.98215
alpha_8                               0.98229      0.00015   0.98244    0.98215
alpha_9                               0.98230      0.00015   0.98245    0.98216
Alpha_loss                            -0.11738     0.00101   -0.11637   -0.11839
Training/policy_loss                  -2.66709     0.00036   -2.66673   -2.66744
Training/qf1_loss                     763.85559    46.00024  809.85583  717.85535
Training/qf2_loss                     763.87363    46.00064  809.87427  717.87299
Training/pf_norm                      0.38573      0.00636   0.39209    0.37937
Training/qf1_norm                     18.82936     0.81939   19.64875   18.00996
Training/qf2_norm                     18.77815     0.82010   19.59824   17.95805
log_std/mean                          -0.02534     0.00027   -0.02507   -0.02562
log_std/std                           0.00168      0.00000   0.00168    0.00167
log_std/max                           -0.02243     0.00026   -0.02217   -0.02269
log_std/min                           -0.02860     0.00027   -0.02833   -0.02887
log_probs/mean                        -2.68513     0.00043   -2.68471   -2.68556
log_probs/std                         0.38795      0.00134   0.38929    0.38660
log_probs/max                         -1.47787     0.04734   -1.43053   -1.52522
log_probs/min                         -4.16591     0.05510   -4.11080   -4.22101
mean/mean                             0.00127      0.00004   0.00131    0.00123
mean/std                              0.00083      0.00000   0.00083    0.00082
mean/max                              0.00263      0.00006   0.00269    0.00256
mean/min                              -0.00014     0.00009   -0.00005   -0.00023
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 30 50
freq 22
sample: [0, 6, 4, 7, 9, 2, 3, 5, 1, 8]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
train_time 0.12437653541564941
eval time 0.002571582794189453
snapshot at best
2023-08-22 20:45:04,297 MainThread INFO: EPOCH:30
2023-08-22 20:45:04,297 MainThread INFO: Time Consumed:0.602346658706665s
2023-08-22 20:45:04,297 MainThread INFO: Total Frames:46500s
 16%|█▌        | 31/200 [00:27<02:06,  1.34it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1182.82495
Train_Epoch_Reward                    6177.59691
Running_Training_Average_Rewards      525.70178
Explore_Time                          0.00259
Train___Time                          0.12438
Eval____Time                          0.00257
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.90650
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.38686
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.88618
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.69786
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25505
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01859
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.13628
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12112.21247
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.56813
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.67805
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.39366      0.18016   6.57381    6.21350
alpha_0                               0.98171      0.00015   0.98186    0.98156
alpha_1                               0.98170      0.00015   0.98185    0.98155
alpha_2                               0.98171      0.00015   0.98186    0.98156
alpha_3                               0.98170      0.00015   0.98185    0.98155
alpha_4                               0.98172      0.00015   0.98186    0.98157
alpha_5                               0.98172      0.00015   0.98187    0.98158
alpha_6                               0.98172      0.00015   0.98187    0.98157
alpha_7                               0.98171      0.00015   0.98186    0.98156
alpha_8                               0.98170      0.00015   0.98185    0.98156
alpha_9                               0.98171      0.00015   0.98186    0.98157
Alpha_loss                            -0.12140     0.00101   -0.12039   -0.12241
Training/policy_loss                  -2.66722     0.00028   -2.66693   -2.66750
Training/qf1_loss                     729.84390    33.39828  763.24219  696.44562
Training/qf2_loss                     729.86124    33.39920  763.26044  696.46204
Training/pf_norm                      0.39153      0.03619   0.42772    0.35535
Training/qf1_norm                     18.62449     0.39442   19.01891   18.23007
Training/qf2_norm                     18.57683     0.39080   18.96763   18.18604
log_std/mean                          -0.02646     0.00028   -0.02617   -0.02674
log_std/std                           0.00168      0.00000   0.00168    0.00167
log_std/max                           -0.02350     0.00027   -0.02324   -0.02377
log_std/min                           -0.02973     0.00029   -0.02944   -0.03002
log_probs/mean                        -2.68554     0.00034   -2.68520   -2.68588
log_probs/std                         0.37492      0.00403   0.37894    0.37089
log_probs/max                         -1.57574     0.04211   -1.53363   -1.61785
log_probs/min                         -4.15608     0.00419   -4.15189   -4.16027
mean/mean                             0.00140      0.00001   0.00141    0.00139
mean/std                              0.00075      0.00002   0.00077    0.00072
mean/max                              0.00271      0.00002   0.00274    0.00269
mean/min                              0.00020      0.00004   0.00024    0.00016
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 31 50
freq 22
sample: [8, 4, 7, 5, 1, 0, 2, 6, 9, 3]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
train_time 0.15590691566467285
eval time 0.002783060073852539
snapshot at best
2023-08-22 20:45:05,081 MainThread INFO: EPOCH:31
2023-08-22 20:45:05,082 MainThread INFO: Time Consumed:0.6936912536621094s
2023-08-22 20:45:05,082 MainThread INFO: Total Frames:48000s
 16%|█▌        | 32/200 [00:28<02:08,  1.31it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1187.43419
Train_Epoch_Reward                    1467.03797
Running_Training_Average_Rewards      437.51745
Explore_Time                          0.00294
Train___Time                          0.15591
Eval____Time                          0.00278
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.40927
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.35590
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.92899
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.65096
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25669
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.02702
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14841
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12176.90401
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.53804
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.63632
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.44612      0.36488   6.81100    6.08124
alpha_0                               0.98112      0.00015   0.98127    0.98097
alpha_1                               0.98111      0.00015   0.98126    0.98096
alpha_2                               0.98112      0.00015   0.98127    0.98097
alpha_3                               0.98111      0.00015   0.98126    0.98096
alpha_4                               0.98113      0.00015   0.98127    0.98098
alpha_5                               0.98113      0.00015   0.98128    0.98099
alpha_6                               0.98113      0.00015   0.98128    0.98098
alpha_7                               0.98112      0.00015   0.98127    0.98097
alpha_8                               0.98112      0.00015   0.98126    0.98097
alpha_9                               0.98112      0.00015   0.98127    0.98098
Alpha_loss                            -0.12583     0.00099   -0.12484   -0.12682
Training/policy_loss                  -2.68856     0.00095   -2.68761   -2.68951
Training/qf1_loss                     793.02487    80.16782  873.19269  712.85706
Training/qf2_loss                     793.04346    80.16833  873.21179  712.87512
Training/pf_norm                      0.31893      0.00755   0.32647    0.31138
Training/qf1_norm                     18.80038     0.75443   19.55480   18.04595
Training/qf2_norm                     18.74873     0.75380   19.50253   17.99493
log_std/mean                          -0.02759     0.00028   -0.02731   -0.02788
log_std/std                           0.00168      0.00000   0.00168    0.00168
log_std/max                           -0.02460     0.00028   -0.02432   -0.02488
log_std/min                           -0.03082     0.00028   -0.03054   -0.03110
log_probs/mean                        -2.70752     0.00090   -2.70662   -2.70842
log_probs/std                         0.38120      0.00518   0.38638    0.37602
log_probs/max                         -1.53170     0.03843   -1.49327   -1.57013
log_probs/min                         -4.30894     0.07252   -4.23642   -4.38146
mean/mean                             0.00143      0.00001   0.00144    0.00143
mean/std                              0.00063      0.00003   0.00067    0.00060
mean/max                              0.00269      0.00007   0.00276    0.00262
mean/min                              0.00035      0.00004   0.00038    0.00031
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 32 50
freq 22
sample: [7, 8, 4, 9, 0, 5, 1, 3, 2, 6]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
train_time 0.12636327743530273
eval time 0.0021448135375976562
snapshot at best
2023-08-22 20:45:05,827 MainThread INFO: EPOCH:32
2023-08-22 20:45:05,827 MainThread INFO: Time Consumed:0.6410677433013916s
2023-08-22 20:45:05,827 MainThread INFO: Total Frames:49500s
 16%|█▋        | 33/200 [00:29<02:05,  1.33it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1192.29307
Train_Epoch_Reward                    23972.51230
Running_Training_Average_Rewards      1053.90491
Explore_Time                          0.00239
Train___Time                          0.12636
Eval____Time                          0.00214
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.47663
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.34060
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.96248
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.61747
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26311
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.03952
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.16520
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12223.15255
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.52282
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.60414
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.30162      0.37977   6.68139    5.92184
alpha_0                               0.98053      0.00015   0.98068    0.98039
alpha_1                               0.98052      0.00015   0.98067    0.98037
alpha_2                               0.98053      0.00015   0.98068    0.98038
alpha_3                               0.98052      0.00015   0.98067    0.98037
alpha_4                               0.98054      0.00015   0.98068    0.98039
alpha_5                               0.98055      0.00015   0.98069    0.98040
alpha_6                               0.98054      0.00015   0.98069    0.98040
alpha_7                               0.98053      0.00015   0.98068    0.98038
alpha_8                               0.98053      0.00015   0.98067    0.98038
alpha_9                               0.98053      0.00015   0.98068    0.98039
Alpha_loss                            -0.12987     0.00104   -0.12883   -0.13091
Training/policy_loss                  -2.68917     0.00140   -2.68777   -2.69057
Training/qf1_loss                     784.86218    60.44836  845.31055  724.41382
Training/qf2_loss                     784.88040    60.45035  845.33075  724.43005
Training/pf_norm                      0.32786      0.00715   0.33501    0.32072
Training/qf1_norm                     18.47357     0.82043   19.29400   17.65314
Training/qf2_norm                     18.42345     0.81365   19.23710   17.60980
log_std/mean                          -0.02873     0.00028   -0.02844   -0.02901
log_std/std                           0.00169      0.00000   0.00169    0.00168
log_std/max                           -0.02569     0.00027   -0.02542   -0.02596
log_std/min                           -0.03194     0.00028   -0.03166   -0.03222
log_probs/mean                        -2.70836     0.00148   -2.70688   -2.70984
log_probs/std                         0.38421      0.00432   0.38853    0.37989
log_probs/max                         -1.45964     0.04634   -1.41330   -1.50597
log_probs/min                         -4.47118     0.17303   -4.29815   -4.64421
mean/mean                             0.00143      0.00001   0.00144    0.00143
mean/std                              0.00056      0.00001   0.00058    0.00055
mean/max                              0.00304      0.00010   0.00314    0.00293
mean/min                              0.00043      0.00004   0.00047    0.00040
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 33 50
freq 22
sample: [4, 0, 1, 6, 8, 5, 2, 3, 9, 7]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
train_time 0.12620329856872559
eval time 0.0026116371154785156
snapshot at best
2023-08-22 20:45:06,548 MainThread INFO: EPOCH:33
2023-08-22 20:45:06,548 MainThread INFO: Time Consumed:0.635443925857544s
2023-08-22 20:45:06,548 MainThread INFO: Total Frames:51000s
 17%|█▋        | 34/200 [00:30<02:03,  1.34it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1197.57134
Train_Epoch_Reward                    7703.81141
Running_Training_Average_Rewards      1104.77872
Explore_Time                          0.00235
Train___Time                          0.12620
Eval____Time                          0.00261
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.99509
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33271
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.99726
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.58066
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26772
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.05078
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18240
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12266.51682
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.51549
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.56740
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.58160      0.43182   7.01342    6.14978
alpha_0                               0.97995      0.00015   0.98009    0.97980
alpha_1                               0.97993      0.00015   0.98008    0.97978
alpha_2                               0.97994      0.00015   0.98009    0.97979
alpha_3                               0.97993      0.00015   0.98008    0.97979
alpha_4                               0.97995      0.00015   0.98010    0.97980
alpha_5                               0.97996      0.00015   0.98010    0.97981
alpha_6                               0.97995      0.00015   0.98010    0.97981
alpha_7                               0.97994      0.00015   0.98009    0.97979
alpha_8                               0.97994      0.00015   0.98009    0.97979
alpha_9                               0.97995      0.00015   0.98009    0.97980
Alpha_loss                            -0.13345     0.00100   -0.13245   -0.13445
Training/policy_loss                  -2.66699     0.00022   -2.66677   -2.66721
Training/qf1_loss                     794.94394    52.31339  847.25732  742.63055
Training/qf2_loss                     794.96408    52.31387  847.27795  742.65021
Training/pf_norm                      0.39271      0.00351   0.39622    0.38919
Training/qf1_norm                     19.11900     0.90605   20.02505   18.21296
Training/qf2_norm                     19.06199     0.90660   19.96859   18.15538
log_std/mean                          -0.02986     0.00029   -0.02957   -0.03015
log_std/std                           0.00170      0.00001   0.00171    0.00170
log_std/max                           -0.02676     0.00028   -0.02649   -0.02704
log_std/min                           -0.03306     0.00030   -0.03275   -0.03336
log_probs/mean                        -2.68595     0.00019   -2.68575   -2.68614
log_probs/std                         0.37774      0.01054   0.38828    0.36719
log_probs/max                         -1.44207     0.00374   -1.43833   -1.44581
log_probs/min                         -4.04604     0.16727   -3.87877   -4.21330
mean/mean                             0.00148      0.00001   0.00149    0.00148
mean/std                              0.00060      0.00003   0.00064    0.00057
mean/max                              0.00355      0.00014   0.00369    0.00342
mean/min                              0.00053      0.00001   0.00054    0.00051
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 34 50
freq 22
sample: [1, 4, 2, 8, 3, 7, 6, 5, 0, 9]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
train_time 0.19026613235473633
eval time 0.010816097259521484
snapshot at best
2023-08-22 20:45:07,311 MainThread INFO: EPOCH:34
2023-08-22 20:45:07,311 MainThread INFO: Time Consumed:0.6705100536346436s
2023-08-22 20:45:07,311 MainThread INFO: Total Frames:52500s
 18%|█▊        | 35/200 [00:31<02:03,  1.34it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1202.24101
Train_Epoch_Reward                    7148.44857
Running_Training_Average_Rewards      1294.15908
Explore_Time                          0.00230
Train___Time                          0.19027
Eval____Time                          0.01082
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.31880
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.30456
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.05016
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.53041
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28097
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.07144
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20838
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12323.81779
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.48708
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.52369
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.54466      0.08459   6.62926    6.46007
alpha_0                               0.97936      0.00015   0.97951    0.97921
alpha_1                               0.97934      0.00015   0.97949    0.97919
alpha_2                               0.97935      0.00015   0.97950    0.97920
alpha_3                               0.97934      0.00015   0.97949    0.97920
alpha_4                               0.97936      0.00015   0.97951    0.97921
alpha_5                               0.97937      0.00015   0.97952    0.97922
alpha_6                               0.97937      0.00015   0.97951    0.97922
alpha_7                               0.97935      0.00015   0.97950    0.97921
alpha_8                               0.97935      0.00015   0.97950    0.97920
alpha_9                               0.97936      0.00015   0.97950    0.97921
Alpha_loss                            -0.13824     0.00112   -0.13712   -0.13936
Training/policy_loss                  -2.70365     0.00524   -2.69841   -2.70889
Training/qf1_loss                     777.80881    11.55655  789.36536  766.25226
Training/qf2_loss                     777.82535    11.55887  789.38422  766.26648
Training/pf_norm                      0.26830      0.01930   0.28760    0.24899
Training/qf1_norm                     19.04762     0.17155   19.21918   18.87607
Training/qf2_norm                     19.00922     0.16101   19.17023   18.84821
log_std/mean                          -0.03102     0.00029   -0.03073   -0.03131
log_std/std                           0.00172      0.00000   0.00173    0.00172
log_std/max                           -0.02787     0.00029   -0.02758   -0.02816
log_std/min                           -0.03427     0.00026   -0.03401   -0.03453
log_probs/mean                        -2.72355     0.00539   -2.71815   -2.72894
log_probs/std                         0.36705      0.00418   0.37123    0.36287
log_probs/max                         -1.54946     0.07734   -1.47212   -1.62679
log_probs/min                         -4.05169     0.08981   -3.96189   -4.14150
mean/mean                             0.00142      0.00001   0.00143    0.00141
mean/std                              0.00080      0.00006   0.00085    0.00074
mean/max                              0.00406      0.00012   0.00418    0.00393
mean/min                              0.00047      0.00001   0.00048    0.00046
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 35 50
freq 22
sample: [9, 2, 6, 3, 8, 4, 7, 0, 5, 1]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
train_time 0.12830185890197754
eval time 0.002669811248779297
snapshot at best
2023-08-22 20:45:08,094 MainThread INFO: EPOCH:35
2023-08-22 20:45:08,094 MainThread INFO: Time Consumed:0.7021045684814453s
2023-08-22 20:45:08,094 MainThread INFO: Total Frames:54000s
 18%|█▊        | 36/200 [00:31<02:05,  1.30it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1207.63837
Train_Epoch_Reward                    821.81828
Running_Training_Average_Rewards      522.46928
Explore_Time                          0.00308
Train___Time                          0.12830
Eval____Time                          0.00267
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.52481
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.28888
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.09329
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.46927
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.27563
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.07120
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.21479
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12392.95533
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47097
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.46510
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           5.97768      0.65661    6.63429    5.32107
alpha_0                               0.97877      0.00015    0.97892    0.97863
alpha_1                               0.97875      0.00015    0.97890    0.97861
alpha_2                               0.97876      0.00015    0.97891    0.97862
alpha_3                               0.97876      0.00015    0.97890    0.97861
alpha_4                               0.97877      0.00015    0.97892    0.97862
alpha_5                               0.97878      0.00015    0.97893    0.97863
alpha_6                               0.97878      0.00015    0.97893    0.97863
alpha_7                               0.97876      0.00015    0.97891    0.97862
alpha_8                               0.97876      0.00015    0.97891    0.97861
alpha_9                               0.97877      0.00015    0.97892    0.97862
Alpha_loss                            -0.14181     0.00085    -0.14096   -0.14265
Training/policy_loss                  -2.68161     0.00741    -2.67420   -2.68903
Training/qf1_loss                     680.00516    145.94131  825.94647  534.06384
Training/qf2_loss                     680.02368    145.94342  825.96710  534.08026
Training/pf_norm                      0.34058      0.00440    0.34498    0.33618
Training/qf1_norm                     17.85281     1.38280    19.23561   16.47001
Training/qf2_norm                     17.80237     1.37568    19.17805   16.42669
log_std/mean                          -0.03216     0.00028    -0.03187   -0.03244
log_std/std                           0.00174      0.00000    0.00174    0.00173
log_std/max                           -0.02898     0.00029    -0.02870   -0.02927
log_std/min                           -0.03550     0.00031    -0.03519   -0.03580
log_probs/mean                        -2.70119     0.00752    -2.69368   -2.70871
log_probs/std                         0.37289      0.00826    0.38116    0.36463
log_probs/max                         -1.55559     0.01860    -1.53699   -1.57419
log_probs/min                         -3.90189     0.10050    -3.80139   -4.00238
mean/mean                             0.00131      0.00003    0.00134    0.00127
mean/std                              0.00109      0.00009    0.00117    0.00100
mean/max                              0.00454      0.00012    0.00467    0.00442
mean/min                              0.00013      0.00015    0.00028    -0.00002
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 36 50
freq 22
sample: [5, 2, 4, 6, 3, 9, 1, 0, 8, 7]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
train_time 0.14556050300598145
eval time 0.002352476119995117
snapshot at best
2023-08-22 20:45:08,865 MainThread INFO: EPOCH:36
2023-08-22 20:45:08,866 MainThread INFO: Time Consumed:0.6522254943847656s
2023-08-22 20:45:08,866 MainThread INFO: Total Frames:55500s
 18%|█▊        | 37/200 [00:32<02:03,  1.32it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1213.78702
Train_Epoch_Reward                    5714.48821
Running_Training_Average_Rewards      456.15850
Explore_Time                          0.00341
Train___Time                          0.14556
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.09885
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.27753
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.13030
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.40695
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25996
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.05960
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20975
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12456.79617
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.45978
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.40663
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           5.85496      0.12214   5.97710    5.73283
alpha_0                               0.97818      0.00015   0.97833    0.97804
alpha_1                               0.97816      0.00015   0.97831    0.97802
alpha_2                               0.97817      0.00015   0.97832    0.97803
alpha_3                               0.97817      0.00015   0.97831    0.97802
alpha_4                               0.97818      0.00015   0.97833    0.97804
alpha_5                               0.97819      0.00015   0.97834    0.97805
alpha_6                               0.97819      0.00015   0.97834    0.97804
alpha_7                               0.97818      0.00015   0.97832    0.97803
alpha_8                               0.97817      0.00015   0.97832    0.97803
alpha_9                               0.97818      0.00015   0.97833    0.97803
Alpha_loss                            -0.14582     0.00108   -0.14474   -0.14690
Training/policy_loss                  -2.68073     0.00321   -2.67753   -2.68394
Training/qf1_loss                     627.93912    29.10519  657.04431  598.83392
Training/qf2_loss                     627.95782    29.10675  657.06458  598.85107
Training/pf_norm                      0.34435      0.01421   0.35857    0.33014
Training/qf1_norm                     17.61583     0.28157   17.89740   17.33426
Training/qf2_norm                     17.56411     0.27471   17.83882   17.28941
log_std/mean                          -0.03330     0.00029   -0.03301   -0.03359
log_std/std                           0.00175      0.00000   0.00175    0.00174
log_std/max                           -0.03013     0.00028   -0.02984   -0.03041
log_std/min                           -0.03667     0.00034   -0.03633   -0.03701
log_probs/mean                        -2.70044     0.00332   -2.69712   -2.70376
log_probs/std                         0.36844      0.00471   0.37315    0.36373
log_probs/max                         -1.51231     0.04619   -1.46612   -1.55850
log_probs/min                         -4.09004     0.02342   -4.06662   -4.11347
mean/mean                             0.00119      0.00000   0.00119    0.00119
mean/std                              0.00134      0.00006   0.00140    0.00128
mean/max                              0.00491      0.00010   0.00502    0.00481
mean/min                              -0.00024     0.00003   -0.00021   -0.00028
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 37 50
freq 22
sample: [3, 7, 0, 6, 5, 8, 2, 9, 4, 1]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
train_time 0.11865854263305664
eval time 0.0027284622192382812
snapshot at best
2023-08-22 20:45:09,541 MainThread INFO: EPOCH:37
2023-08-22 20:45:09,542 MainThread INFO: Time Consumed:0.590674638748169s
2023-08-22 20:45:09,542 MainThread INFO: Total Frames:57000s
 19%|█▉        | 38/200 [00:33<01:59,  1.36it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1219.75756
Train_Epoch_Reward                    6542.80321
Running_Training_Average_Rewards      435.97032
Explore_Time                          0.00307
Train___Time                          0.11866
Eval____Time                          0.00273
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.00025
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26445
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.15069
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.34799
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.22648
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.02947
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18608
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12504.17121
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.44631
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.36089
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.66999      0.13777  6.80776    6.53222
alpha_0                               0.97760      0.00015  0.97774    0.97745
alpha_1                               0.97758      0.00015  0.97772    0.97743
alpha_2                               0.97759      0.00015  0.97773    0.97744
alpha_3                               0.97758      0.00015  0.97773    0.97743
alpha_4                               0.97760      0.00015  0.97774    0.97745
alpha_5                               0.97761      0.00015  0.97775    0.97746
alpha_6                               0.97760      0.00015  0.97775    0.97746
alpha_7                               0.97759      0.00015  0.97773    0.97744
alpha_8                               0.97759      0.00015  0.97773    0.97744
alpha_9                               0.97759      0.00015  0.97774    0.97745
Alpha_loss                            -0.14980     0.00112  -0.14868   -0.15093
Training/policy_loss                  -2.67882     0.00510  -2.67372   -2.68392
Training/qf1_loss                     833.44043    1.20862  834.64905  832.23181
Training/qf2_loss                     833.46176    1.20901  834.67078  832.25275
Training/pf_norm                      0.35387      0.00373  0.35761    0.35014
Training/qf1_norm                     19.37753     0.27511  19.65263   19.10242
Training/qf2_norm                     19.31931     0.27860  19.59790   19.04071
log_std/mean                          -0.03446     0.00029  -0.03417   -0.03475
log_std/std                           0.00176      0.00000  0.00176    0.00176
log_std/max                           -0.03129     0.00030  -0.03100   -0.03159
log_std/min                           -0.03795     0.00031  -0.03764   -0.03826
log_probs/mean                        -2.69859     0.00525  -2.69334   -2.70384
log_probs/std                         0.36256      0.00656  0.36913    0.35600
log_probs/max                         -1.51979     0.06719  -1.45260   -1.58699
log_probs/min                         -4.06407     0.07790  -3.98617   -4.14196
mean/mean                             0.00116      0.00000  0.00116    0.00116
mean/std                              0.00151      0.00002  0.00153    0.00150
mean/max                              0.00520      0.00003  0.00522    0.00517
mean/min                              -0.00038     0.00001  -0.00037   -0.00038
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 38 50
freq 22
sample: [2, 8, 3, 1, 6, 9, 0, 5, 7, 4]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
train_time 0.12087321281433105
eval time 0.0023605823516845703
snapshot at best
2023-08-22 20:45:10,264 MainThread INFO: EPOCH:38
2023-08-22 20:45:10,264 MainThread INFO: Time Consumed:0.6285214424133301s
2023-08-22 20:45:10,264 MainThread INFO: Total Frames:58500s
 20%|█▉        | 39/200 [00:33<01:57,  1.37it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1224.89578
Train_Epoch_Reward                    9920.92692
Running_Training_Average_Rewards      739.27394
Explore_Time                          0.00235
Train___Time                          0.12087
Eval____Time                          0.00236
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.95602
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.24772
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.17447
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.29625
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19989
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.00908
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.16990
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12546.03371
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42932
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.32305
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.78430      0.45309    7.23739     6.33120
alpha_0                               0.97701      0.00015    0.97716     0.97686
alpha_1                               0.97699      0.00015    0.97713     0.97684
alpha_2                               0.97700      0.00015    0.97715     0.97685
alpha_3                               0.97699      0.00015    0.97714     0.97684
alpha_4                               0.97701      0.00015    0.97716     0.97686
alpha_5                               0.97702      0.00015    0.97717     0.97687
alpha_6                               0.97702      0.00015    0.97716     0.97687
alpha_7                               0.97700      0.00015    0.97715     0.97685
alpha_8                               0.97700      0.00015    0.97715     0.97685
alpha_9                               0.97701      0.00015    0.97715     0.97686
Alpha_loss                            -0.15414     0.00111    -0.15303    -0.15525
Training/policy_loss                  -2.69217     0.00428    -2.68788    -2.69645
Training/qf1_loss                     939.56064    101.49881  1041.05945  838.06183
Training/qf2_loss                     939.58075    101.50116  1041.08191  838.07959
Training/pf_norm                      0.30054      0.03265    0.33319     0.26789
Training/qf1_norm                     19.62395     0.98034    20.60429    18.64362
Training/qf2_norm                     19.57360     0.97325    20.54685    18.60035
log_std/mean                          -0.03563     0.00030    -0.03533    -0.03593
log_std/std                           0.00177      0.00000    0.00177     0.00177
log_std/max                           -0.03248     0.00029    -0.03219    -0.03277
log_std/min                           -0.03920     0.00030    -0.03890    -0.03949
log_probs/mean                        -2.71236     0.00439    -2.70797    -2.71675
log_probs/std                         0.36384      0.00229    0.36613     0.36155
log_probs/max                         -1.55134     0.00821    -1.54313    -1.55954
log_probs/min                         -4.23635     0.19551    -4.04084    -4.43185
mean/mean                             0.00115      0.00000    0.00115     0.00115
mean/std                              0.00153      0.00000    0.00153     0.00153
mean/max                              0.00522      0.00001    0.00523     0.00521
mean/min                              -0.00037     0.00001    -0.00036    -0.00037
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 39 50
freq 22
sample: [3, 4, 1, 7, 8, 0, 6, 9, 2, 5]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
train_time 0.12331962585449219
eval time 0.002244234085083008
2023-08-22 20:45:10,480 MainThread INFO: EPOCH:39
2023-08-22 20:45:10,481 MainThread INFO: Time Consumed:0.12881684303283691s
2023-08-22 20:45:10,481 MainThread INFO: Total Frames:60000s
 20%|██        | 40/200 [00:34<01:32,  1.72it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1227.61778
Train_Epoch_Reward                    11050.64536
Running_Training_Average_Rewards      917.14585
Explore_Time                          0.00261
Train___Time                          0.12332
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.39219
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.23602
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.17223
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.28103
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18109
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99531
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.15945
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12541.31769
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42213
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33134
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.53973      0.82893    7.36866     5.71080
alpha_0                               0.97642      0.00015    0.97657     0.97628
alpha_1                               0.97640      0.00015    0.97655     0.97625
alpha_2                               0.97641      0.00015    0.97656     0.97627
alpha_3                               0.97640      0.00015    0.97655     0.97626
alpha_4                               0.97642      0.00015    0.97657     0.97628
alpha_5                               0.97643      0.00015    0.97658     0.97629
alpha_6                               0.97643      0.00015    0.97658     0.97629
alpha_7                               0.97641      0.00015    0.97656     0.97626
alpha_8                               0.97641      0.00015    0.97656     0.97627
alpha_9                               0.97642      0.00015    0.97657     0.97627
Alpha_loss                            -0.15809     0.00090    -0.15719    -0.15898
Training/policy_loss                  -2.68839     0.00468    -2.68371    -2.69307
Training/qf1_loss                     840.88116    176.55957  1017.44073  664.32159
Training/qf2_loss                     840.89963    176.56100  1017.46063  664.33862
Training/pf_norm                      0.31748      0.00291    0.32039     0.31458
Training/qf1_norm                     19.13200     1.71280    20.84480    17.41920
Training/qf2_norm                     19.08830     1.71222    20.80052    17.37608
log_std/mean                          -0.03680     0.00029    -0.03651    -0.03710
log_std/std                           0.00178      0.00001    0.00179     0.00178
log_std/max                           -0.03364     0.00029    -0.03335    -0.03393
log_std/min                           -0.04040     0.00030    -0.04009    -0.04070
log_probs/mean                        -2.70859     0.00477    -2.70382    -2.71336
log_probs/std                         0.36338      0.00087    0.36425     0.36252
log_probs/max                         -1.56044     0.01057    -1.54986    -1.57101
log_probs/min                         -4.15184     0.09089    -4.06095    -4.24272
mean/mean                             0.00117      0.00001    0.00118     0.00116
mean/std                              0.00150      0.00001    0.00151     0.00149
mean/max                              0.00522      0.00000    0.00523     0.00522
mean/min                              -0.00031     0.00002    -0.00029    -0.00034
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 40 50
freq 22
sample: [9, 1, 6, 2, 7, 3, 4, 8, 0, 5]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
train_time 0.11802554130554199
eval time 0.0022363662719726562
2023-08-22 20:45:10,843 MainThread INFO: EPOCH:40
2023-08-22 20:45:10,843 MainThread INFO: Time Consumed:0.12660455703735352s
2023-08-22 20:45:10,843 MainThread INFO: Total Frames:61500s
 20%|██        | 41/200 [00:34<01:22,  1.94it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1228.66627
Train_Epoch_Reward                    8748.57978
Running_Training_Average_Rewards      990.67174
Explore_Time                          0.00323
Train___Time                          0.11803
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.82127
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.23581
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.17012
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.27808
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.17147
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.99397
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.16114
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12537.21019
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42489
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34030
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.19247      0.28271   6.47518    5.90976
alpha_0                               0.97584      0.00015   0.97598    0.97569
alpha_1                               0.97581      0.00015   0.97596    0.97567
alpha_2                               0.97583      0.00015   0.97597    0.97568
alpha_3                               0.97582      0.00015   0.97596    0.97567
alpha_4                               0.97584      0.00015   0.97598    0.97569
alpha_5                               0.97585      0.00015   0.97599    0.97570
alpha_6                               0.97585      0.00015   0.97599    0.97570
alpha_7                               0.97582      0.00015   0.97597    0.97568
alpha_8                               0.97583      0.00015   0.97597    0.97568
alpha_9                               0.97583      0.00015   0.97598    0.97569
Alpha_loss                            -0.16196     0.00088   -0.16108   -0.16284
Training/policy_loss                  -2.68182     0.00509   -2.67673   -2.68691
Training/qf1_loss                     781.36017    79.94434  861.30450  701.41583
Training/qf2_loss                     781.37454    79.94400  861.31854  701.43054
Training/pf_norm                      0.36204      0.01445   0.37649    0.34759
Training/qf1_norm                     18.41440     0.60373   19.01814   17.81067
Training/qf2_norm                     18.38822     0.60724   18.99546   17.78098
log_std/mean                          -0.03798     0.00030   -0.03769   -0.03828
log_std/std                           0.00180      0.00000   0.00180    0.00180
log_std/max                           -0.03480     0.00028   -0.03452   -0.03509
log_std/min                           -0.04175     0.00032   -0.04143   -0.04207
log_probs/mean                        -2.70193     0.00516   -2.69677   -2.70709
log_probs/std                         0.36908      0.00078   0.36986    0.36829
log_probs/max                         -1.61087     0.08210   -1.52877   -1.69297
log_probs/min                         -5.84886     0.48512   -5.36374   -6.33397
mean/mean                             0.00121      0.00002   0.00123    0.00119
mean/std                              0.00147      0.00000   0.00147    0.00147
mean/max                              0.00526      0.00003   0.00529    0.00524
mean/min                              -0.00030     0.00002   -0.00028   -0.00032
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 41 50
freq 22
sample: [7, 3, 6, 0, 4, 5, 2, 8, 9, 1]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
train_time 0.15517950057983398
eval time 0.0032002925872802734
snapshot at best
2023-08-22 20:45:11,839 MainThread INFO: EPOCH:41
2023-08-22 20:45:11,839 MainThread INFO: Time Consumed:0.7246501445770264s
2023-08-22 20:45:11,840 MainThread INFO: Total Frames:63000s
 21%|██        | 42/200 [00:35<01:43,  1.53it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1228.74972
Train_Epoch_Reward                    16099.34145
Running_Training_Average_Rewards      1196.61889
Explore_Time                          0.00273
Train___Time                          0.15518
Eval____Time                          0.00320
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.30871
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.23755
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.17682
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.28116
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18407
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01477
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18250
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12542.89092
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42759
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34614
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.41009      0.04098   6.45106    6.36911
alpha_0                               0.97525      0.00015   0.97540    0.97511
alpha_1                               0.97523      0.00015   0.97537    0.97508
alpha_2                               0.97524      0.00015   0.97539    0.97509
alpha_3                               0.97523      0.00015   0.97538    0.97508
alpha_4                               0.97525      0.00015   0.97540    0.97510
alpha_5                               0.97526      0.00015   0.97541    0.97511
alpha_6                               0.97526      0.00015   0.97541    0.97511
alpha_7                               0.97524      0.00015   0.97538    0.97509
alpha_8                               0.97524      0.00015   0.97539    0.97509
alpha_9                               0.97525      0.00015   0.97539    0.97510
Alpha_loss                            -0.16592     0.00099   -0.16492   -0.16691
Training/policy_loss                  -2.67914     0.00047   -2.67867   -2.67960
Training/qf1_loss                     751.76779    36.90927  788.67706  714.85852
Training/qf2_loss                     751.77942    36.91064  788.69006  714.86877
Training/pf_norm                      0.34290      0.02337   0.36627    0.31953
Training/qf1_norm                     18.88602     0.08714   18.97316   18.79889
Training/qf2_norm                     18.87254     0.08087   18.95341   18.79167
log_std/mean                          -0.03919     0.00031   -0.03888   -0.03950
log_std/std                           0.00182      0.00001   0.00183    0.00181
log_std/max                           -0.03594     0.00030   -0.03564   -0.03623
log_std/min                           -0.04291     0.00030   -0.04261   -0.04320
log_probs/mean                        -2.69921     0.00051   -2.69870   -2.69972
log_probs/std                         0.35447      0.00122   0.35570    0.35325
log_probs/max                         -1.61801     0.04191   -1.57609   -1.65992
log_probs/min                         -4.10966     0.04483   -4.06483   -4.15449
mean/mean                             0.00130      0.00003   0.00133    0.00128
mean/std                              0.00149      0.00000   0.00149    0.00149
mean/max                              0.00541      0.00004   0.00545    0.00537
mean/min                              -0.00018     0.00001   -0.00017   -0.00020
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 42 50
freq 22
sample: [3, 4, 0, 8, 9, 1, 7, 2, 6, 5]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
train_time 0.1758131980895996
eval time 0.002744436264038086
snapshot at best
2023-08-22 20:45:12,576 MainThread INFO: EPOCH:42
2023-08-22 20:45:12,576 MainThread INFO: Time Consumed:0.6456449031829834s
2023-08-22 20:45:12,576 MainThread INFO: Total Frames:64500s
 22%|██▏       | 43/200 [00:36<01:46,  1.47it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1229.44976
Train_Epoch_Reward                    9597.72635
Running_Training_Average_Rewards      1148.18825
Explore_Time                          0.00318
Train___Time                          0.17581
Eval____Time                          0.00274
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.38106
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.22126
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.18802
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.26660
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18081
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.02109
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18982
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12552.35269
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.41132
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34474
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.47829      0.14349   6.62178    6.33480
alpha_0                               0.97467      0.00015   0.97481    0.97452
alpha_1                               0.97464      0.00015   0.97479    0.97449
alpha_2                               0.97465      0.00015   0.97480    0.97451
alpha_3                               0.97464      0.00015   0.97479    0.97450
alpha_4                               0.97466      0.00015   0.97481    0.97452
alpha_5                               0.97467      0.00015   0.97482    0.97453
alpha_6                               0.97467      0.00015   0.97482    0.97453
alpha_7                               0.97465      0.00015   0.97480    0.97450
alpha_8                               0.97465      0.00015   0.97480    0.97451
alpha_9                               0.97466      0.00015   0.97481    0.97452
Alpha_loss                            -0.17025     0.00097   -0.16928   -0.17122
Training/policy_loss                  -2.69080     0.00140   -2.68940   -2.69220
Training/qf1_loss                     797.72302    52.87836  850.60138  744.84467
Training/qf2_loss                     797.74179    52.88077  850.62256  744.86102
Training/pf_norm                      0.31843      0.02495   0.34338    0.29348
Training/qf1_norm                     19.05688     0.30136   19.35823   18.75552
Training/qf2_norm                     19.01095     0.29019   19.30115   18.72076
log_std/mean                          -0.04041     0.00030   -0.04011   -0.04072
log_std/std                           0.00185      0.00001   0.00186    0.00184
log_std/max                           -0.03703     0.00027   -0.03676   -0.03730
log_std/min                           -0.04434     0.00039   -0.04395   -0.04473
log_probs/mean                        -2.71119     0.00145   -2.70974   -2.71264
log_probs/std                         0.36155      0.00465   0.36620    0.35689
log_probs/max                         -1.63935     0.03771   -1.60164   -1.67707
log_probs/min                         -4.73591     0.57751   -4.15840   -5.31342
mean/mean                             0.00146      0.00004   0.00150    0.00142
mean/std                              0.00142      0.00004   0.00146    0.00139
mean/max                              0.00548      0.00003   0.00551    0.00546
mean/min                              0.00006      0.00008   0.00014    -0.00002
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 43 50
freq 22
sample: [8, 2, 6, 7, 9, 5, 1, 3, 4, 0]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
train_time 0.13749384880065918
eval time 0.002630472183227539
snapshot at best
2023-08-22 20:45:13,324 MainThread INFO: EPOCH:43
2023-08-22 20:45:13,324 MainThread INFO: Time Consumed:0.6501729488372803s
2023-08-22 20:45:13,324 MainThread INFO: Total Frames:66000s
 22%|██▏       | 44/200 [00:37<01:49,  1.43it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1230.72257
Train_Epoch_Reward                    5499.36924
Running_Training_Average_Rewards      1039.88123
Explore_Time                          0.00302
Train___Time                          0.13749
Eval____Time                          0.00263
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.30511
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.21561
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.20997
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.25637
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19528
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.04860
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.21769
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12573.98995
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.40941
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33434
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.34767      0.11567   6.46335    6.23200
alpha_0                               0.97408      0.00015   0.97423    0.97394
alpha_1                               0.97405      0.00015   0.97420    0.97391
alpha_2                               0.97407      0.00015   0.97422    0.97392
alpha_3                               0.97406      0.00015   0.97420    0.97391
alpha_4                               0.97408      0.00015   0.97422    0.97393
alpha_5                               0.97409      0.00015   0.97424    0.97394
alpha_6                               0.97409      0.00015   0.97423    0.97394
alpha_7                               0.97406      0.00015   0.97421    0.97392
alpha_8                               0.97407      0.00015   0.97422    0.97392
alpha_9                               0.97408      0.00015   0.97422    0.97393
Alpha_loss                            -0.17440     0.00104   -0.17336   -0.17544
Training/policy_loss                  -2.69518     0.00115   -2.69403   -2.69633
Training/qf1_loss                     726.44595    19.39352  745.83948  707.05243
Training/qf2_loss                     726.46118    19.39563  745.85681  707.06555
Training/pf_norm                      0.27760      0.02637   0.30396    0.25123
Training/qf1_norm                     18.81914     0.24015   19.05928   18.57899
Training/qf2_norm                     18.78875     0.23092   19.01967   18.55783
log_std/mean                          -0.04163     0.00031   -0.04133   -0.04194
log_std/std                           0.00188      0.00001   0.00188    0.00187
log_std/max                           -0.03814     0.00028   -0.03785   -0.03842
log_std/min                           -0.04563     0.00041   -0.04522   -0.04604
log_probs/mean                        -2.71571     0.00120   -2.71451   -2.71691
log_probs/std                         0.35403      0.00488   0.35891    0.34915
log_probs/max                         -1.60439     0.06630   -1.53809   -1.67068
log_probs/min                         -4.04116     0.15210   -3.88907   -4.19326
mean/mean                             0.00165      0.00005   0.00170    0.00161
mean/std                              0.00134      0.00002   0.00136    0.00132
mean/max                              0.00553      0.00001   0.00553    0.00552
mean/min                              0.00036      0.00004   0.00041    0.00032
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 44 50
freq 22
start to update mask
sample: [0, 6, 3, 7, 1, 8, 4, 2, 5, 9]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
train_time 0.12192797660827637
eval time 0.002959012985229492
snapshot at best
2023-08-22 20:45:17,256 MainThread INFO: EPOCH:44
2023-08-22 20:45:17,257 MainThread INFO: Time Consumed:0.6717770099639893s
2023-08-22 20:45:17,257 MainThread INFO: Total Frames:67500s
 22%|██▎       | 45/200 [00:40<04:19,  1.68s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1231.95266
Train_Epoch_Reward                    11353.88473
Running_Training_Average_Rewards      881.69934
Explore_Time                          0.00471
Train___Time                          0.12193
Eval____Time                          0.00296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.16774
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.20757
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.23259
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.26325
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.23113
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.09670
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.26473
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12576.84480
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.40192
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34483
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.28735      0.05994   6.34729    6.22741
alpha_0                               0.97350      0.00015   0.97364    0.97335
alpha_1                               0.97347      0.00015   0.97362    0.97332
alpha_2                               0.97348      0.00015   0.97363    0.97334
alpha_3                               0.97347      0.00015   0.97362    0.97333
alpha_4                               0.97349      0.00015   0.97364    0.97335
alpha_5                               0.97350      0.00015   0.97365    0.97336
alpha_6                               0.97350      0.00015   0.97365    0.97336
alpha_7                               0.97348      0.00015   0.97363    0.97333
alpha_8                               0.97348      0.00015   0.97363    0.97334
alpha_9                               0.97349      0.00015   0.97364    0.97335
Alpha_loss                            -0.17832     0.00097   -0.17735   -0.17929
Training/policy_loss                  -2.69078     0.00146   -2.68932   -2.69224
Training/qf1_loss                     699.38113    26.54141  725.92255  672.83972
Training/qf2_loss                     699.39578    26.54062  725.93640  672.85516
Training/pf_norm                      0.28676      0.01988   0.30664    0.26687
Training/qf1_norm                     18.71992     0.13141   18.85134   18.58851
Training/qf2_norm                     18.68250     0.13485   18.81734   18.54765
log_std/mean                          -0.04281     0.00030   -0.04251   -0.04311
log_std/std                           0.00190      0.00001   0.00191    0.00189
log_std/max                           -0.03924     0.00027   -0.03897   -0.03950
log_std/min                           -0.04708     0.00034   -0.04674   -0.04741
log_probs/mean                        -2.71148     0.00151   -2.70998   -2.71299
log_probs/std                         0.34328      0.00514   0.34842    0.33814
log_probs/max                         -1.59633     0.04165   -1.55469   -1.63798
log_probs/min                         -4.21023     0.08342   -4.12681   -4.29365
mean/mean                             0.00194      0.00006   0.00200    0.00188
mean/std                              0.00128      0.00002   0.00130    0.00127
mean/max                              0.00561      0.00001   0.00562    0.00560
mean/min                              0.00053      0.00002   0.00054    0.00051
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 45 50
freq 22
sample: [4, 7, 8, 2, 1, 6, 5, 0, 3, 9]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
train_time 0.1338024139404297
eval time 0.002328634262084961
2023-08-22 20:45:17,508 MainThread INFO: EPOCH:45
2023-08-22 20:45:17,508 MainThread INFO: Time Consumed:0.1393420696258545s
2023-08-22 20:45:17,508 MainThread INFO: Total Frames:69000s
 23%|██▎       | 46/200 [00:41<03:11,  1.25s/it]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1232.58622
Train_Epoch_Reward                    6305.58035
Running_Training_Average_Rewards      771.96114
Explore_Time                          0.00272
Train___Time                          0.13380
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.44412
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.17887
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.25954
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.26266
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26522
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14009
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30608
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12574.75173
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.37476
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.36552
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.47656      0.54726    7.02381    5.92930
alpha_0                               0.97291      0.00015    0.97306    0.97277
alpha_1                               0.97288      0.00015    0.97303    0.97274
alpha_2                               0.97290      0.00015    0.97305    0.97275
alpha_3                               0.97289      0.00015    0.97303    0.97274
alpha_4                               0.97291      0.00015    0.97305    0.97276
alpha_5                               0.97292      0.00015    0.97307    0.97277
alpha_6                               0.97292      0.00015    0.97306    0.97277
alpha_7                               0.97289      0.00015    0.97304    0.97275
alpha_8                               0.97290      0.00015    0.97305    0.97275
alpha_9                               0.97291      0.00015    0.97305    0.97276
Alpha_loss                            -0.18227     0.00124    -0.18103   -0.18352
Training/policy_loss                  -2.68767     0.00843    -2.67924   -2.69610
Training/qf1_loss                     753.15836    160.91458  914.07294  592.24377
Training/qf2_loss                     753.17023    160.91815  914.08838  592.25208
Training/pf_norm                      0.32579      0.03699    0.36279    0.28880
Training/qf1_norm                     19.13177     1.17317    20.30494   17.95860
Training/qf2_norm                     19.10805     1.16020    20.26826   17.94785
log_std/mean                          -0.04402     0.00031    -0.04371   -0.04433
log_std/std                           0.00193      0.00001    0.00194    0.00192
log_std/max                           -0.04034     0.00028    -0.04006   -0.04062
log_std/min                           -0.04853     0.00031    -0.04822   -0.04884
log_probs/mean                        -2.70829     0.00867    -2.69962   -2.71695
log_probs/std                         0.34525      0.00634    0.35159    0.33891
log_probs/max                         -1.65222     0.06732    -1.58490   -1.71953
log_probs/min                         -4.54565     0.10063    -4.44502   -4.64628
mean/mean                             0.00214      0.00003    0.00218    0.00211
mean/std                              0.00125      0.00002    0.00127    0.00123
mean/max                              0.00573      0.00001    0.00573    0.00572
mean/min                              0.00062      0.00001    0.00063    0.00061
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 46 50
freq 22
sample: [7, 2, 1, 9, 0, 5, 4, 3, 6, 8]
replay_buffer._size: [7196 7199 7200 7200 7200 7166 7200 7200 7169 7196]
train_time 0.14316320419311523
eval time 0.002031564712524414
snapshot at best
2023-08-22 20:45:18,237 MainThread INFO: EPOCH:46
2023-08-22 20:45:18,237 MainThread INFO: Time Consumed:0.6269664764404297s
2023-08-22 20:45:18,237 MainThread INFO: Total Frames:70500s
 24%|██▎       | 47/200 [00:41<02:46,  1.09s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1233.22270
Train_Epoch_Reward                    5614.81603
Running_Training_Average_Rewards      775.80937
Explore_Time                          0.00363
Train___Time                          0.14316
Eval____Time                          0.00203
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.16244
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.15354
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.28916
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.25625
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39568
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17975
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.34206
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12581.39523
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.34690
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.37751
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.08284      0.22166   7.30450    6.86118
alpha_0                               0.97233      0.00015   0.97247    0.97218
alpha_1                               0.97230      0.00015   0.97244    0.97215
alpha_2                               0.97232      0.00015   0.97246    0.97217
alpha_3                               0.97230      0.00015   0.97245    0.97216
alpha_4                               0.97232      0.00015   0.97247    0.97218
alpha_5                               0.97234      0.00015   0.97248    0.97219
alpha_6                               0.97233      0.00015   0.97248    0.97219
alpha_7                               0.97231      0.00015   0.97245    0.97216
alpha_8                               0.97231      0.00015   0.97246    0.97217
alpha_9                               0.97232      0.00015   0.97247    0.97218
Alpha_loss                            -0.18643     0.00075   -0.18568   -0.18719
Training/policy_loss                  -2.69233     0.00889   -2.68344   -2.70121
Training/qf1_loss                     874.91861    69.46048  944.37909  805.45813
Training/qf2_loss                     874.92874    69.45981  944.38855  805.46893
Training/pf_norm                      0.27670      0.04032   0.31702    0.23638
Training/qf1_norm                     20.44726     0.46525   20.91251   19.98201
Training/qf2_norm                     20.43285     0.46803   20.90087   19.96482
log_std/mean                          -0.04524     0.00030   -0.04494   -0.04554
log_std/std                           0.00197      0.00001   0.00198    0.00196
log_std/max                           -0.04143     0.00026   -0.04117   -0.04169
log_std/min                           -0.04994     0.00034   -0.04960   -0.05028
log_probs/mean                        -2.71303     0.00915   -2.70388   -2.72218
log_probs/std                         0.34473      0.00396   0.34870    0.34077
log_probs/max                         -1.63290     0.03054   -1.60237   -1.66344
log_probs/min                         -4.59838     0.44448   -4.15390   -5.04287
mean/mean                             0.00216      0.00001   0.00216    0.00215
mean/std                              0.00120      0.00001   0.00120    0.00119
mean/max                              0.00563      0.00003   0.00566    0.00561
mean/min                              0.00051      0.00006   0.00057    0.00046
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 47 50
freq 22
sample: [6, 7, 0, 3, 1, 2, 9, 4, 5, 8]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
train_time 0.14293789863586426
eval time 0.0024633407592773438
2023-08-22 20:45:18,489 MainThread INFO: EPOCH:47
2023-08-22 20:45:18,489 MainThread INFO: Time Consumed:0.14911293983459473s
2023-08-22 20:45:18,489 MainThread INFO: Total Frames:72000s
 24%|██▍       | 48/200 [00:42<02:08,  1.19it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1232.93223
Train_Epoch_Reward                    7500.27675
Running_Training_Average_Rewards      647.35577
Explore_Time                          0.00306
Train___Time                          0.14294
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.38090
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.15882
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29152
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.27117
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.41616
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20565
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.36707
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12569.75847
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.35133
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.39585
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.18489      0.05109   6.23598    6.13380
alpha_0                               0.97174      0.00015   0.97189    0.97160
alpha_1                               0.97171      0.00015   0.97186    0.97157
alpha_2                               0.97173      0.00015   0.97188    0.97158
alpha_3                               0.97172      0.00015   0.97186    0.97157
alpha_4                               0.97174      0.00015   0.97188    0.97159
alpha_5                               0.97175      0.00015   0.97190    0.97161
alpha_6                               0.97175      0.00015   0.97189    0.97160
alpha_7                               0.97172      0.00015   0.97187    0.97158
alpha_8                               0.97173      0.00015   0.97188    0.97158
alpha_9                               0.97174      0.00015   0.97188    0.97159
Alpha_loss                            -0.19057     0.00114   -0.18943   -0.19171
Training/policy_loss                  -2.69584     0.00450   -2.69134   -2.70034
Training/qf1_loss                     725.67337    76.83218  802.50555  648.84119
Training/qf2_loss                     725.67444    76.83276  802.50720  648.84167
Training/pf_norm                      0.28554      0.00012   0.28566    0.28541
Training/qf1_norm                     18.54158     0.09011   18.63168   18.45147
Training/qf2_norm                     18.56193     0.08793   18.64986   18.47400
log_std/mean                          -0.04646     0.00031   -0.04615   -0.04676
log_std/std                           0.00201      0.00001   0.00202    0.00200
log_std/max                           -0.04249     0.00027   -0.04222   -0.04276
log_std/min                           -0.05123     0.00028   -0.05095   -0.05151
log_probs/mean                        -2.71661     0.00460   -2.71201   -2.72122
log_probs/std                         0.35526      0.00006   0.35532    0.35521
log_probs/max                         -1.63948     0.03253   -1.60695   -1.67201
log_probs/min                         -4.80503     0.43639   -4.36864   -5.24142
mean/mean                             0.00213      0.00000   0.00213    0.00213
mean/std                              0.00121      0.00001   0.00122    0.00120
mean/max                              0.00566      0.00003   0.00569    0.00563
mean/min                              0.00041      0.00000   0.00041    0.00041
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 48 50
freq 22
sample: [0, 6, 8, 2, 5, 9, 3, 4, 7, 1]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
train_time 0.13666653633117676
eval time 0.002940654754638672
2023-08-22 20:45:18,768 MainThread INFO: EPOCH:48
2023-08-22 20:45:18,769 MainThread INFO: Time Consumed:0.1443953514099121s
2023-08-22 20:45:18,769 MainThread INFO: Total Frames:73500s
 24%|██▍       | 49/200 [00:42<01:41,  1.49it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1232.83483
Train_Epoch_Reward                    13853.71603
Running_Training_Average_Rewards      898.96029
Explore_Time                          0.00414
Train___Time                          0.13667
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.64522
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.17537
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29423
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.27796
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42950
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22721
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.39062
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12574.43773
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36751
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.39722
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           5.70623      0.15815  5.86438    5.54808
alpha_0                               0.97116      0.00015  0.97130    0.97101
alpha_1                               0.97113      0.00015  0.97127    0.97098
alpha_2                               0.97115      0.00015  0.97129    0.97100
alpha_3                               0.97113      0.00015  0.97128    0.97099
alpha_4                               0.97115      0.00015  0.97130    0.97101
alpha_5                               0.97117      0.00015  0.97132    0.97102
alpha_6                               0.97116      0.00015  0.97131    0.97102
alpha_7                               0.97114      0.00015  0.97128    0.97099
alpha_8                               0.97115      0.00015  0.97129    0.97100
alpha_9                               0.97115      0.00015  0.97130    0.97101
Alpha_loss                            -0.19417     0.00091  -0.19325   -0.19508
Training/policy_loss                  -2.68106     0.00307  -2.67799   -2.68414
Training/qf1_loss                     551.95209    2.16827  554.12036  549.78381
Training/qf2_loss                     551.95493    2.16464  554.11957  549.79028
Training/pf_norm                      0.29776      0.01311  0.31088    0.28465
Training/qf1_norm                     17.54461     0.28410  17.82872   17.26051
Training/qf2_norm                     17.55241     0.30149  17.85390   17.25092
log_std/mean                          -0.04768     0.00030  -0.04738   -0.04798
log_std/std                           0.00205      0.00001  0.00206    0.00204
log_std/max                           -0.04362     0.00028  -0.04334   -0.04391
log_std/min                           -0.05265     0.00035  -0.05230   -0.05300
log_probs/mean                        -2.70127     0.00321  -2.69807   -2.70448
log_probs/std                         0.35087      0.00008  0.35096    0.35079
log_probs/max                         -1.61311     0.02656  -1.58655   -1.63968
log_probs/min                         -4.70300     0.81933  -3.88367   -5.52233
mean/mean                             0.00209      0.00002  0.00211    0.00207
mean/std                              0.00122      0.00001  0.00122    0.00121
mean/max                              0.00568      0.00002  0.00570    0.00567
mean/min                              0.00045      0.00002  0.00046    0.00043
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 49 50
freq 22
sample: [4, 3, 1, 2, 5, 0, 9, 8, 7, 6]
replay_buffer._size: [7650 7649 7649 7650 7650 7650 7650 7650 7650 7637]
train_time 0.16968226432800293
eval time 0.002870798110961914
2023-08-22 20:45:19,042 MainThread INFO: EPOCH:49
2023-08-22 20:45:19,043 MainThread INFO: Time Consumed:0.17500805854797363s
2023-08-22 20:45:19,043 MainThread INFO: Total Frames:75000s
 25%|██▌       | 50/200 [00:42<01:23,  1.80it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1232.34832
Train_Epoch_Reward                    10619.65080
Running_Training_Average_Rewards      1065.78812
Explore_Time                          0.00197
Train___Time                          0.16968
Eval____Time                          0.00287
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.77615
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.18155
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.28790
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.26929
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.41224
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21628
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.38500
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12575.59511
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.37515
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.39478
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.92666      0.57463    7.50129     6.35203
alpha_0                               0.97057      0.00015    0.97072     0.97043
alpha_1                               0.97054      0.00015    0.97069     0.97040
alpha_2                               0.97056      0.00015    0.97071     0.97042
alpha_3                               0.97055      0.00015    0.97070     0.97040
alpha_4                               0.97057      0.00015    0.97072     0.97042
alpha_5                               0.97059      0.00015    0.97073     0.97044
alpha_6                               0.97058      0.00015    0.97073     0.97044
alpha_7                               0.97055      0.00015    0.97070     0.97041
alpha_8                               0.97056      0.00015    0.97071     0.97042
alpha_9                               0.97057      0.00015    0.97071     0.97042
Alpha_loss                            -0.19817     0.00104    -0.19713    -0.19921
Training/policy_loss                  -2.68028     0.00103    -2.67925    -2.68130
Training/qf1_loss                     953.57275    103.61438  1057.18713  849.95837
Training/qf2_loss                     953.57751    103.60974  1057.18726  849.96777
Training/pf_norm                      0.31149      0.00453    0.31602     0.30697
Training/qf1_norm                     20.15703     1.18723    21.34426    18.96980
Training/qf2_norm                     20.16079     1.21100    21.37179    18.94979
log_std/mean                          -0.04891     0.00031    -0.04860    -0.04923
log_std/std                           0.00211      0.00002    0.00213     0.00209
log_std/max                           -0.04469     0.00025    -0.04444    -0.04495
log_std/min                           -0.05398     0.00041    -0.05357    -0.05438
log_probs/mean                        -2.70036     0.00098    -2.69938    -2.70134
log_probs/std                         0.34228      0.00759    0.34986     0.33469
log_probs/max                         -1.67942     0.06139    -1.61803    -1.74080
log_probs/min                         -4.61118     0.46947    -4.14171    -5.08065
mean/mean                             0.00201      0.00001    0.00202     0.00200
mean/std                              0.00130      0.00003    0.00133     0.00126
mean/max                              0.00580      0.00006    0.00586     0.00575
mean/min                              0.00038      0.00003    0.00042     0.00035
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 50 50
freq 22
sample: [9, 6, 4, 2, 8, 0, 3, 5, 1, 7]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
train_time 0.13870525360107422
eval time 0.0023741722106933594
2023-08-22 20:45:19,330 MainThread INFO: EPOCH:50
2023-08-22 20:45:19,330 MainThread INFO: Time Consumed:0.14371728897094727s
2023-08-22 20:45:19,330 MainThread INFO: Total Frames:76500s
 26%|██▌       | 51/200 [00:43<01:09,  2.14it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1232.56729
Train_Epoch_Reward                    46827.27662
Running_Training_Average_Rewards      2376.68811
Explore_Time                          0.00215
Train___Time                          0.13871
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.80840
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.18786
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27515
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.25055
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.38125
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18641
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.35789
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12582.70437
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.38438
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.38345
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.24205      0.11963   6.36168    6.12241
alpha_0                               0.96999      0.00015   0.97014    0.96985
alpha_1                               0.96996      0.00015   0.97010    0.96981
alpha_2                               0.96998      0.00015   0.97013    0.96983
alpha_3                               0.96997      0.00015   0.97011    0.96982
alpha_4                               0.96999      0.00015   0.97013    0.96984
alpha_5                               0.97000      0.00015   0.97015    0.96986
alpha_6                               0.97000      0.00015   0.97014    0.96985
alpha_7                               0.96997      0.00015   0.97012    0.96982
alpha_8                               0.96998      0.00015   0.97013    0.96984
alpha_9                               0.96999      0.00015   0.97013    0.96984
Alpha_loss                            -0.20266     0.00096   -0.20171   -0.20362
Training/policy_loss                  -2.69546     0.00163   -2.69383   -2.69709
Training/qf1_loss                     773.16724    25.66302  798.83026  747.50421
Training/qf2_loss                     773.16876    25.66400  798.83276  747.50476
Training/pf_norm                      0.27431      0.01632   0.29063    0.25799
Training/qf1_norm                     18.73535     0.23272   18.96807   18.50263
Training/qf2_norm                     18.74719     0.23808   18.98527   18.50911
log_std/mean                          -0.05017     0.00031   -0.04985   -0.05048
log_std/std                           0.00218      0.00002   0.00220    0.00216
log_std/max                           -0.04576     0.00028   -0.04548   -0.04603
log_std/min                           -0.05548     0.00040   -0.05508   -0.05588
log_probs/mean                        -2.71587     0.00177   -2.71411   -2.71764
log_probs/std                         0.34741      0.00465   0.35206    0.34276
log_probs/max                         -1.69948     0.02454   -1.67494   -1.72402
log_probs/min                         -5.49695     0.43134   -5.06561   -5.92829
mean/mean                             0.00198      0.00000   0.00198    0.00198
mean/std                              0.00145      0.00004   0.00149    0.00140
mean/max                              0.00607      0.00008   0.00615    0.00599
mean/min                              0.00008      0.00008   0.00017    -0.00000
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 51 50
freq 22
sample: [4, 1, 9, 5, 0, 2, 3, 7, 8, 6]
replay_buffer._size: [7950 7914 7950 7923 7950 7950 7917 7914 7950 7948]
train_time 0.14159536361694336
eval time 0.0025289058685302734
snapshot at best
2023-08-22 20:45:20,083 MainThread INFO: EPOCH:51
2023-08-22 20:45:20,083 MainThread INFO: Time Consumed:0.6564340591430664s
2023-08-22 20:45:20,083 MainThread INFO: Total Frames:78000s
 26%|██▌       | 52/200 [00:43<01:21,  1.81it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1233.11955
Train_Epoch_Reward                    18643.02850
Running_Training_Average_Rewards      2536.33186
Explore_Time                          0.00189
Train___Time                          0.14160
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.21656
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.16504
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27569
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.20843
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33640
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14205
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.31763
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12598.19881
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36746
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.36891
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.63908      0.34097    6.98005    6.29811
alpha_0                               0.96941      0.00015    0.96955    0.96926
alpha_1                               0.96937      0.00015    0.96952    0.96923
alpha_2                               0.96940      0.00015    0.96954    0.96925
alpha_3                               0.96938      0.00015    0.96953    0.96924
alpha_4                               0.96940      0.00015    0.96955    0.96926
alpha_5                               0.96942      0.00015    0.96957    0.96928
alpha_6                               0.96941      0.00015    0.96956    0.96927
alpha_7                               0.96939      0.00015    0.96953    0.96924
alpha_8                               0.96940      0.00015    0.96954    0.96925
alpha_9                               0.96940      0.00015    0.96955    0.96926
Alpha_loss                            -0.20646     0.00086    -0.20560   -0.20732
Training/policy_loss                  -2.68794     0.00453    -2.68341   -2.69247
Training/qf1_loss                     765.13931    124.63083  889.77014  640.50848
Training/qf2_loss                     765.13223    124.63254  889.76477  640.49969
Training/pf_norm                      0.27860      0.04588    0.32449    0.23272
Training/qf1_norm                     19.62258     0.74281    20.36539   18.87978
Training/qf2_norm                     19.67151     0.73707    20.40858   18.93444
log_std/mean                          -0.05143     0.00031    -0.05111   -0.05174
log_std/std                           0.00226      0.00002    0.00228    0.00223
log_std/max                           -0.04685     0.00027    -0.04657   -0.04712
log_std/min                           -0.05683     0.00030    -0.05653   -0.05714
log_probs/mean                        -2.70801     0.00473    -2.70328   -2.71274
log_probs/std                         0.33145      0.00685    0.33829    0.32460
log_probs/max                         -1.70246     0.00673    -1.69573   -1.70919
log_probs/min                         -4.50212     0.12744    -4.37467   -4.62956
mean/mean                             0.00193      0.00001    0.00194    0.00192
mean/std                              0.00161      0.00003    0.00164    0.00157
mean/max                              0.00633      0.00005    0.00638    0.00628
mean/min                              -0.00023     0.00008    -0.00015   -0.00030
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 52 50
freq 22
sample: [2, 5, 9, 7, 4, 3, 6, 8, 0, 1]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
train_time 0.1360607147216797
eval time 0.0028357505798339844
snapshot at best
2023-08-22 20:45:20,829 MainThread INFO: EPOCH:52
2023-08-22 20:45:20,830 MainThread INFO: Time Consumed:0.6627655029296875s
2023-08-22 20:45:20,830 MainThread INFO: Total Frames:79500s
 26%|██▋       | 53/200 [00:44<01:29,  1.63it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1234.96165
Train_Epoch_Reward                    6709.98680
Running_Training_Average_Rewards      2406.00973
Explore_Time                          0.00206
Train___Time                          0.13606
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.90984
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.15339
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.28668
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16461
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30125
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.10606
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.28476
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12631.46257
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36170
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33440
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.70957      0.32843   7.03800    6.38115
alpha_0                               0.96883      0.00015   0.96897    0.96868
alpha_1                               0.96879      0.00015   0.96894    0.96865
alpha_2                               0.96882      0.00015   0.96896    0.96867
alpha_3                               0.96880      0.00015   0.96895    0.96866
alpha_4                               0.96882      0.00015   0.96897    0.96868
alpha_5                               0.96884      0.00015   0.96898    0.96869
alpha_6                               0.96883      0.00015   0.96898    0.96869
alpha_7                               0.96880      0.00015   0.96895    0.96866
alpha_8                               0.96882      0.00015   0.96896    0.96867
alpha_9                               0.96882      0.00015   0.96897    0.96868
Alpha_loss                            -0.21096     0.00126   -0.20970   -0.21223
Training/policy_loss                  -2.70276     0.00790   -2.69486   -2.71065
Training/qf1_loss                     780.45975    95.47501  875.93475  684.98474
Training/qf2_loss                     780.44922    95.48035  875.92957  684.96887
Training/pf_norm                      0.24222      0.01529   0.25751    0.22693
Training/qf1_norm                     19.78624     0.69736   20.48360   19.08888
Training/qf2_norm                     19.84928     0.67675   20.52603   19.17253
log_std/mean                          -0.05269     0.00032   -0.05238   -0.05301
log_std/std                           0.00234      0.00002   0.00236    0.00232
log_std/max                           -0.04794     0.00028   -0.04766   -0.04822
log_std/min                           -0.05842     0.00034   -0.05808   -0.05876
log_probs/mean                        -2.72303     0.00801   -2.71502   -2.73104
log_probs/std                         0.33854      0.00705   0.34558    0.33149
log_probs/max                         -1.66743     0.00361   -1.66382   -1.67104
log_probs/min                         -4.41378     0.27478   -4.13900   -4.68856
mean/mean                             0.00194      0.00001   0.00195    0.00194
mean/std                              0.00173      0.00002   0.00175    0.00170
mean/max                              0.00650      0.00001   0.00652    0.00649
mean/min                              -0.00054     0.00009   -0.00045   -0.00064
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 53 50
freq 22
sample: [4, 0, 9, 3, 6, 2, 8, 1, 7, 5]
replay_buffer._size: [8250 8250 8250 8250 8250 8250 8250 8250 8250 8250]
train_time 0.1258711814880371
eval time 0.002619504928588867
snapshot at best
2023-08-22 20:45:21,577 MainThread INFO: EPOCH:53
2023-08-22 20:45:21,577 MainThread INFO: Time Consumed:0.6515653133392334s
2023-08-22 20:45:21,578 MainThread INFO: Total Frames:81000s
 27%|██▋       | 54/200 [00:45<01:35,  1.54it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1237.73905
Train_Epoch_Reward                    9450.94648
Running_Training_Average_Rewards      1160.13206
Explore_Time                          0.00366
Train___Time                          0.12587
Eval____Time                          0.00262
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.12840
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.13742
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29178
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.12983
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26705
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.07028
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.24999
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12652.74832
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.35055
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.31212
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           6.46669      0.23617   6.70286     6.23052
alpha_0                               0.96825      0.00015   0.96839     0.96810
alpha_1                               0.96821      0.00015   0.96835     0.96806
alpha_2                               0.96823      0.00015   0.96838     0.96809
alpha_3                               0.96822      0.00015   0.96837     0.96807
alpha_4                               0.96824      0.00015   0.96839     0.96809
alpha_5                               0.96826      0.00015   0.96840     0.96811
alpha_6                               0.96825      0.00015   0.96839     0.96810
alpha_7                               0.96822      0.00015   0.96837     0.96807
alpha_8                               0.96824      0.00015   0.96838     0.96809
alpha_9                               0.96824      0.00015   0.96838     0.96809
Alpha_loss                            -0.21418     0.00106   -0.21311    -0.21524
Training/policy_loss                  -2.67778     0.00176   -2.67602    -2.67955
Training/qf1_loss                     964.88995    98.99188  1063.88184  865.89807
Training/qf2_loss                     964.87872    98.99103  1063.86975  865.88770
Training/pf_norm                      0.28638      0.01823   0.30461     0.26814
Training/qf1_norm                     19.28681     0.46654   19.75336    18.82027
Training/qf2_norm                     19.34622     0.47104   19.81726    18.87519
log_std/mean                          -0.05395     0.00032   -0.05363    -0.05427
log_std/std                           0.00243      0.00002   0.00245     0.00241
log_std/max                           -0.04901     0.00026   -0.04875    -0.04927
log_std/min                           -0.05982     0.00044   -0.05939    -0.06026
log_probs/mean                        -2.69708     0.00176   -2.69532    -2.69884
log_probs/std                         0.33212      0.00473   0.33685     0.32739
log_probs/max                         -1.68285     0.03120   -1.65165    -1.71405
log_probs/min                         -4.24856     0.11990   -4.12866    -4.36845
mean/mean                             0.00187      0.00002   0.00189     0.00185
mean/std                              0.00180      0.00002   0.00182     0.00179
mean/max                              0.00649      0.00001   0.00650     0.00648
mean/min                              -0.00083     0.00004   -0.00080    -0.00087
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 54 50
freq 22
sample: [6, 3, 5, 8, 9, 7, 0, 2, 4, 1]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
train_time 0.14029860496520996
eval time 0.002620220184326172
2023-08-22 20:45:21,808 MainThread INFO: EPOCH:54
2023-08-22 20:45:21,808 MainThread INFO: Time Consumed:0.1459667682647705s
2023-08-22 20:45:21,808 MainThread INFO: Total Frames:82500s
 28%|██▊       | 55/200 [00:45<01:16,  1.90it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1239.42442
Train_Epoch_Reward                    3426.82675
Running_Training_Average_Rewards      652.92533
Explore_Time                          0.00248
Train___Time                          0.14030
Eval____Time                          0.00262
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.80863
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.13908
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27763
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.11588
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.22836
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.03192
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.21540
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12647.84072
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.35712
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.30487
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.02117      0.03921  6.06037    5.98196
alpha_0                               0.96766      0.00015  0.96781    0.96752
alpha_1                               0.96763      0.00015  0.96777    0.96748
alpha_2                               0.96765      0.00015  0.96780    0.96751
alpha_3                               0.96764      0.00015  0.96778    0.96749
alpha_4                               0.96766      0.00015  0.96780    0.96751
alpha_5                               0.96767      0.00015  0.96782    0.96753
alpha_6                               0.96767      0.00015  0.96781    0.96752
alpha_7                               0.96764      0.00015  0.96778    0.96749
alpha_8                               0.96765      0.00015  0.96780    0.96751
alpha_9                               0.96766      0.00015  0.96780    0.96751
Alpha_loss                            -0.21881     0.00103  -0.21778   -0.21985
Training/policy_loss                  -2.69627     0.00077  -2.69549   -2.69704
Training/qf1_loss                     676.12466    1.52267  677.64734  674.60199
Training/qf2_loss                     676.11234    1.51669  677.62903  674.59564
Training/pf_norm                      0.28241      0.01465  0.29706    0.26776
Training/qf1_norm                     18.37460     0.09869  18.47329   18.27590
Training/qf2_norm                     18.43571     0.07372  18.50943   18.36199
log_std/mean                          -0.05522     0.00032  -0.05490   -0.05554
log_std/std                           0.00253      0.00002  0.00255    0.00250
log_std/max                           -0.05015     0.00028  -0.04987   -0.05043
log_std/min                           -0.06133     0.00030  -0.06103   -0.06162
log_probs/mean                        -2.71589     0.00075  -2.71513   -2.71664
log_probs/std                         0.32541      0.00001  0.32542    0.32541
log_probs/max                         -1.81952     0.02611  -1.79341   -1.84564
log_probs/min                         -4.06120     0.07120  -3.99001   -4.13240
mean/mean                             0.00176      0.00005  0.00181    0.00171
mean/std                              0.00179      0.00002  0.00181    0.00177
mean/max                              0.00633      0.00009  0.00642    0.00624
mean/min                              -0.00098     0.00004  -0.00094   -0.00102
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 55 50
freq 22
sample: [3, 9, 7, 0, 2, 6, 1, 4, 5, 8]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
train_time 0.15028834342956543
eval time 0.0024766921997070312
2023-08-22 20:45:22,112 MainThread INFO: EPOCH:55
2023-08-22 20:45:22,112 MainThread INFO: Time Consumed:0.155562162399292s
2023-08-22 20:45:22,112 MainThread INFO: Total Frames:84000s
 28%|██▊       | 56/200 [00:45<01:06,  2.18it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1240.30592
Train_Epoch_Reward                    8462.10626
Running_Training_Average_Rewards      711.32932
Explore_Time                          0.00229
Train___Time                          0.15029
Eval____Time                          0.00248
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.79756
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.15716
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26904
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.11594
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21362
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01853
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20456
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12649.45398
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.37994
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.29282
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.02697      0.16304  6.19002    5.86393
alpha_0                               0.96708      0.00015  0.96723    0.96694
alpha_1                               0.96704      0.00015  0.96719    0.96690
alpha_2                               0.96707      0.00015  0.96722    0.96692
alpha_3                               0.96706      0.00015  0.96720    0.96691
alpha_4                               0.96708      0.00015  0.96722    0.96693
alpha_5                               0.96709      0.00015  0.96724    0.96695
alpha_6                               0.96709      0.00015  0.96723    0.96694
alpha_7                               0.96705      0.00015  0.96720    0.96691
alpha_8                               0.96707      0.00015  0.96722    0.96693
alpha_9                               0.96708      0.00015  0.96722    0.96693
Alpha_loss                            -0.22268     0.00095  -0.22173   -0.22363
Training/policy_loss                  -2.69148     0.00164  -2.68985   -2.69312
Training/qf1_loss                     707.38263    7.99066  715.37329  699.39197
Training/qf2_loss                     707.36621    7.98706  715.35327  699.37915
Training/pf_norm                      0.28553      0.01313  0.29866    0.27240
Training/qf1_norm                     18.42710     0.32297  18.75007   18.10413
Training/qf2_norm                     18.50202     0.30924  18.81126   18.19278
log_std/mean                          -0.05651     0.00032  -0.05619   -0.05683
log_std/std                           0.00263      0.00002  0.00265    0.00260
log_std/max                           -0.05123     0.00026  -0.05098   -0.05149
log_std/min                           -0.06282     0.00031  -0.06251   -0.06313
log_probs/mean                        -2.71065     0.00173  -2.70892   -2.71238
log_probs/std                         0.33211      0.00372  0.33584    0.32839
log_probs/max                         -1.77461     0.00380  -1.77081   -1.77841
log_probs/min                         -4.88055     0.66105  -4.21950   -5.54160
mean/mean                             0.00153      0.00007  0.00160    0.00146
mean/std                              0.00173      0.00000  0.00173    0.00173
mean/max                              0.00601      0.00005  0.00606    0.00596
mean/min                              -0.00113     0.00004  -0.00109   -0.00117
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 56 50
freq 22
sample: [6, 8, 9, 0, 3, 4, 1, 7, 5, 2]
replay_buffer._size: [8700 8700 8700 8700 8700 8700 8700 8700 8700 8700]
train_time 0.13097167015075684
eval time 0.002451658248901367
2023-08-22 20:45:22,386 MainThread INFO: EPOCH:56
2023-08-22 20:45:22,386 MainThread INFO: Time Consumed:0.13597893714904785s
2023-08-22 20:45:22,386 MainThread INFO: Total Frames:85500s
 28%|██▊       | 57/200 [00:46<00:57,  2.47it/s]------------------------------------  -----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1238.61383
Train_Epoch_Reward                    8244.23140
Running_Training_Average_Rewards      671.10548
Explore_Time                          0.00208
Train___Time                          0.13097
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.20335
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.20448
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.22844
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.14928
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19635
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.00472
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.19594
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12613.96820
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.43105
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.30642
mean_success_rate                     0.00000

Name                                  Mean         Std        Max        Min
Reward_Mean                           6.43448      0.42466    6.85914    6.00982
alpha_0                               0.96650      0.00015    0.96665    0.96636
alpha_1                               0.96646      0.00015    0.96661    0.96632
alpha_2                               0.96649      0.00015    0.96663    0.96634
alpha_3                               0.96648      0.00015    0.96662    0.96633
alpha_4                               0.96649      0.00015    0.96664    0.96635
alpha_5                               0.96651      0.00015    0.96666    0.96637
alpha_6                               0.96650      0.00015    0.96665    0.96636
alpha_7                               0.96647      0.00015    0.96662    0.96633
alpha_8                               0.96649      0.00015    0.96664    0.96635
alpha_9                               0.96650      0.00015    0.96664    0.96635
Alpha_loss                            -0.22679     0.00127    -0.22552   -0.22805
Training/policy_loss                  -2.69395     0.00742    -2.68652   -2.70137
Training/qf1_loss                     826.10950    141.26221  967.37170  684.84729
Training/qf2_loss                     826.09210    141.26776  967.35986  684.82434
Training/pf_norm                      0.24525      0.02847    0.27372    0.21679
Training/qf1_norm                     19.34162     0.92363    20.26525   18.41799
Training/qf2_norm                     19.41518     0.90303    20.31821   18.51215
log_std/mean                          -0.05781     0.00033    -0.05749   -0.05814
log_std/std                           0.00272      0.00003    0.00275    0.00270
log_std/max                           -0.05238     0.00029    -0.05208   -0.05267
log_std/min                           -0.06436     0.00031    -0.06404   -0.06467
log_probs/mean                        -2.71290     0.00761    -2.70529   -2.72050
log_probs/std                         0.32686      0.00172    0.32858    0.32514
log_probs/max                         -1.68614     0.02901    -1.65713   -1.71515
log_probs/min                         -4.13706     0.30549    -3.83157   -4.44256
mean/mean                             0.00130      0.00005    0.00135    0.00125
mean/std                              0.00176      0.00002    0.00178    0.00174
mean/max                              0.00589      0.00000    0.00589    0.00588
mean/min                              -0.00133     0.00006    -0.00128   -0.00139
------------------------------------  -----------  ---------  ---------  ---------
epoch, update_end_epoch 57 50
freq 22
sample: [7, 3, 6, 8, 4, 9, 1, 2, 0, 5]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
train_time 0.11743974685668945
eval time 0.0025064945220947266
2023-08-22 20:45:22,713 MainThread INFO: EPOCH:57
2023-08-22 20:45:22,713 MainThread INFO: Time Consumed:0.1227872371673584s
2023-08-22 20:45:22,713 MainThread INFO: Total Frames:87000s
 29%|██▉       | 58/200 [00:46<00:54,  2.62it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1237.26868
Train_Epoch_Reward                    21033.42622
Running_Training_Average_Rewards      1257.99213
Explore_Time                          0.00231
Train___Time                          0.11744
Eval____Time                          0.00251
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.33238
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.24684
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.20233
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16240
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.17523
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.98829
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18416
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12605.07079
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.47558
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.29607
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.15118      0.35157    7.50275     6.79960
alpha_0                               0.96592      0.00015    0.96607     0.96578
alpha_1                               0.96588      0.00015    0.96603     0.96574
alpha_2                               0.96591      0.00015    0.96605     0.96576
alpha_3                               0.96590      0.00015    0.96604     0.96575
alpha_4                               0.96591      0.00015    0.96606     0.96577
alpha_5                               0.96593      0.00015    0.96608     0.96579
alpha_6                               0.96592      0.00015    0.96607     0.96578
alpha_7                               0.96589      0.00015    0.96604     0.96575
alpha_8                               0.96591      0.00015    0.96606     0.96577
alpha_9                               0.96592      0.00015    0.96606     0.96577
Alpha_loss                            -0.23101     0.00120    -0.22981    -0.23221
Training/policy_loss                  -2.69960     0.00538    -2.69422    -2.70498
Training/qf1_loss                     955.09967    101.60150  1056.70117  853.49817
Training/qf2_loss                     955.08206    101.59653  1056.67859  853.48553
Training/pf_norm                      0.27523      0.00812    0.28335     0.26711
Training/qf1_norm                     20.89856     0.76197    21.66054    20.13659
Training/qf2_norm                     20.97547     0.78694    21.76242    20.18853
log_std/mean                          -0.05912     0.00033    -0.05879    -0.05945
log_std/std                           0.00283      0.00002    0.00285     0.00280
log_std/max                           -0.05349     0.00031    -0.05318    -0.05381
log_std/min                           -0.06591     0.00038    -0.06553    -0.06630
log_probs/mean                        -2.71838     0.00546    -2.71292    -2.72385
log_probs/std                         0.32579      0.00138    0.32716     0.32441
log_probs/max                         -1.76358     0.05124    -1.71234    -1.81482
log_probs/min                         -4.56008     0.16108    -4.39900    -4.72117
mean/mean                             0.00111      0.00005    0.00116     0.00107
mean/std                              0.00183      0.00001    0.00184     0.00182
mean/max                              0.00584      0.00002    0.00586     0.00582
mean/min                              -0.00154     0.00003    -0.00151    -0.00157
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 58 50
freq 22
sample: [7, 1, 8, 0, 2, 6, 9, 4, 3, 5]
replay_buffer._size: [9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]
train_time 0.13768339157104492
eval time 0.0032765865325927734
2023-08-22 20:45:23,053 MainThread INFO: EPOCH:58
2023-08-22 20:45:23,053 MainThread INFO: Time Consumed:0.14375901222229004s
2023-08-22 20:45:23,053 MainThread INFO: Total Frames:88500s
 30%|██▉       | 59/200 [00:46<00:52,  2.66it/s]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1235.96041
Train_Epoch_Reward                    12482.15967
Running_Training_Average_Rewards      1391.99391
Explore_Time                          0.00222
Train___Time                          0.13768
Eval____Time                          0.00328
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.03739
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26820
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.18797
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.15743
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14346
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95544
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.15560
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12610.44602
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.50341
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.28042
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           6.96807      0.27926   7.24733     6.68882
alpha_0                               0.96534      0.00015   0.96549     0.96520
alpha_1                               0.96530      0.00015   0.96545     0.96516
alpha_2                               0.96533      0.00015   0.96547     0.96518
alpha_3                               0.96531      0.00015   0.96546     0.96517
alpha_4                               0.96533      0.00015   0.96548     0.96519
alpha_5                               0.96535      0.00015   0.96550     0.96521
alpha_6                               0.96534      0.00015   0.96549     0.96520
alpha_7                               0.96531      0.00014   0.96546     0.96517
alpha_8                               0.96533      0.00015   0.96548     0.96519
alpha_9                               0.96534      0.00015   0.96548     0.96519
Alpha_loss                            -0.23494     0.00166   -0.23328    -0.23660
Training/policy_loss                  -2.69678     0.01807   -2.67872    -2.71485
Training/qf1_loss                     1098.76300   66.89337  1165.65637  1031.86963
Training/qf2_loss                     1098.73706   66.89844  1165.63550  1031.83862
Training/pf_norm                      0.24764      0.05998   0.30762     0.18765
Training/qf1_norm                     20.55283     0.61002   21.16285    19.94280
Training/qf2_norm                     20.65943     0.58778   21.24721    20.07166
log_std/mean                          -0.06044     0.00034   -0.06011    -0.06078
log_std/std                           0.00292      0.00003   0.00295     0.00290
log_std/max                           -0.05466     0.00028   -0.05438    -0.05494
log_std/min                           -0.06741     0.00039   -0.06702    -0.06780
log_probs/mean                        -2.71509     0.01858   -2.69651    -2.73368
log_probs/std                         0.32207      0.00195   0.32402     0.32012
log_probs/max                         -1.76792     0.03896   -1.72896    -1.80688
log_probs/min                         -4.60430     0.21868   -4.38562    -4.82298
mean/mean                             0.00092      0.00004   0.00097     0.00088
mean/std                              0.00185      0.00000   0.00185     0.00185
mean/max                              0.00573      0.00004   0.00576     0.00569
mean/min                              -0.00152     0.00003   -0.00149    -0.00156
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 59 50
freq 22
sample: [4, 6, 9, 7, 2, 5, 8, 1, 0, 3]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
train_time 0.12065267562866211
eval time 0.0027723312377929688
2023-08-22 20:45:23,415 MainThread INFO: EPOCH:59
2023-08-22 20:45:23,415 MainThread INFO: Time Consumed:0.1268296241760254s
2023-08-22 20:45:23,415 MainThread INFO: Total Frames:90000s
 30%|███       | 60/200 [00:47<00:51,  2.71it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1236.07262
Train_Epoch_Reward                    6195.10426
Running_Training_Average_Rewards      1323.68967
Explore_Time                          0.00297
Train___Time                          0.12065
Eval____Time                          0.00277
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.82235
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29801
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.17907
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16546
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.12944
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93767
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.13829
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12615.88362
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.53717
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.26172
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.96731      0.32813   7.29544    6.63918
alpha_0                               0.96476      0.00014   0.96491    0.96462
alpha_1                               0.96472      0.00015   0.96487    0.96458
alpha_2                               0.96475      0.00015   0.96489    0.96460
alpha_3                               0.96473      0.00015   0.96488    0.96459
alpha_4                               0.96475      0.00015   0.96490    0.96461
alpha_5                               0.96477      0.00014   0.96492    0.96463
alpha_6                               0.96476      0.00015   0.96491    0.96462
alpha_7                               0.96473      0.00014   0.96488    0.96459
alpha_8                               0.96475      0.00015   0.96489    0.96460
alpha_9                               0.96476      0.00015   0.96490    0.96461
Alpha_loss                            -0.23901     0.00082   -0.23819   -0.23983
Training/policy_loss                  -2.69805     0.00498   -2.69307   -2.70303
Training/qf1_loss                     899.59375    68.91571  968.50946  830.67804
Training/qf2_loss                     899.56323    68.92078  968.48401  830.64246
Training/pf_norm                      0.24451      0.03647   0.28099    0.20804
Training/qf1_norm                     20.62117     0.74171   21.36287   19.87946
Training/qf2_norm                     20.74320     0.72057   21.46378   20.02263
log_std/mean                          -0.06176     0.00032   -0.06143   -0.06208
log_std/std                           0.00302      0.00003   0.00305    0.00299
log_std/max                           -0.05580     0.00030   -0.05549   -0.05610
log_std/min                           -0.06864     0.00038   -0.06826   -0.06902
log_probs/mean                        -2.71611     0.00530   -2.71081   -2.72142
log_probs/std                         0.32100      0.00285   0.32385    0.31815
log_probs/max                         -1.70134     0.01543   -1.68590   -1.71677
log_probs/min                         -5.35049     0.66386   -4.68663   -6.01434
mean/mean                             0.00087      0.00001   0.00087    0.00086
mean/std                              0.00185      0.00001   0.00186    0.00185
mean/max                              0.00571      0.00001   0.00571    0.00570
mean/min                              -0.00127     0.00005   -0.00122   -0.00132
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 60 50
freq 22
sample: [1, 8, 9, 4, 5, 3, 6, 2, 7, 0]
replay_buffer._size: [9300 9300 9300 9300 9300 9300 9300 9300 9300 9300]
train_time 0.1275796890258789
eval time 0.002679586410522461
2023-08-22 20:45:23,811 MainThread INFO: EPOCH:60
2023-08-22 20:45:23,811 MainThread INFO: Time Consumed:0.13320159912109375s
2023-08-22 20:45:23,811 MainThread INFO: Total Frames:91500s
 30%|███       | 61/200 [00:47<00:52,  2.63it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1237.10618
Train_Epoch_Reward                    26650.67415
Running_Training_Average_Rewards      1510.93127
Explore_Time                          0.00242
Train___Time                          0.12758
Eval____Time                          0.00268
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.92760
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.32580
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.18989
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.17919
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.15358
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.96076
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.15918
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12636.72067
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57277
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.23761
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.73155      0.08203    6.81358     6.64952
alpha_0                               0.96418      0.00014    0.96433     0.96404
alpha_1                               0.96414      0.00015    0.96428     0.96399
alpha_2                               0.96417      0.00014    0.96431     0.96402
alpha_3                               0.96415      0.00015    0.96430     0.96401
alpha_4                               0.96417      0.00015    0.96432     0.96403
alpha_5                               0.96419      0.00014    0.96434     0.96405
alpha_6                               0.96418      0.00015    0.96433     0.96404
alpha_7                               0.96415      0.00014    0.96430     0.96401
alpha_8                               0.96417      0.00015    0.96431     0.96402
alpha_9                               0.96418      0.00014    0.96432     0.96403
Alpha_loss                            -0.24314     0.00141    -0.24173    -0.24456
Training/policy_loss                  -2.70103     0.01093    -2.69010    -2.71196
Training/qf1_loss                     945.34384    115.54483  1060.88867  829.79901
Training/qf2_loss                     945.30951    115.54767  1060.85718  829.76184
Training/pf_norm                      0.19900      0.02592    0.22492     0.17308
Training/qf1_norm                     20.10879     0.15445    20.26324    19.95434
Training/qf2_norm                     20.24069     0.14385    20.38453    20.09684
log_std/mean                          -0.06306     0.00032    -0.06273    -0.06338
log_std/std                           0.00311      0.00002    0.00313     0.00309
log_std/max                           -0.05695     0.00027    -0.05668    -0.05721
log_std/min                           -0.07025     0.00027    -0.06999    -0.07052
log_probs/mean                        -2.71869     0.01117    -2.70752    -2.72986
log_probs/std                         0.30543      0.00264    0.30807     0.30279
log_probs/max                         -1.80118     0.03937    -1.76181    -1.84055
log_probs/min                         -4.01468     0.22938    -3.78530    -4.24406
mean/mean                             0.00098      0.00005    0.00104     0.00093
mean/std                              0.00188      0.00001    0.00188     0.00187
mean/max                              0.00588      0.00006    0.00595     0.00582
mean/min                              -0.00127     0.00001    -0.00126    -0.00128
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 61 50
freq 22
sample: [4, 2, 5, 7, 6, 8, 1, 0, 9, 3]
replay_buffer._size: [9450 9450 9450 9450 9450 9450 9450 9450 9450 9450]
train_time 0.1248159408569336
eval time 0.002824544906616211
snapshot at best
2023-08-22 20:45:24,710 MainThread INFO: EPOCH:61
2023-08-22 20:45:24,710 MainThread INFO: Time Consumed:0.6300342082977295s
2023-08-22 20:45:24,710 MainThread INFO: Total Frames:93000s
 31%|███       | 62/200 [00:48<01:12,  1.90it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1238.96696
Train_Epoch_Reward                    1875.67303
Running_Training_Average_Rewards      1157.38171
Explore_Time                          0.00228
Train___Time                          0.12482
Eval____Time                          0.00282
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.53292
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.31914
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.22409
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18507
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20641
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.01038
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20257
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12671.05576
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57419
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22080
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.87250      1.00630    7.87880     5.86619
alpha_0                               0.96360      0.00014    0.96375     0.96346
alpha_1                               0.96356      0.00015    0.96370     0.96341
alpha_2                               0.96359      0.00014    0.96373     0.96344
alpha_3                               0.96357      0.00015    0.96372     0.96343
alpha_4                               0.96359      0.00014    0.96374     0.96345
alpha_5                               0.96361      0.00014    0.96376     0.96347
alpha_6                               0.96360      0.00015    0.96375     0.96346
alpha_7                               0.96358      0.00014    0.96372     0.96343
alpha_8                               0.96359      0.00015    0.96373     0.96344
alpha_9                               0.96360      0.00014    0.96374     0.96345
Alpha_loss                            -0.24730     0.00154    -0.24576    -0.24884
Training/policy_loss                  -2.70464     0.01403    -2.69061    -2.71867
Training/qf1_loss                     933.68982    291.58240  1225.27222  642.10742
Training/qf2_loss                     933.64856    291.57935  1225.22791  642.06921
Training/pf_norm                      0.24948      0.07070    0.32018     0.17878
Training/qf1_norm                     20.46123     2.21981    22.68104    18.24142
Training/qf2_norm                     20.61682     2.23285    22.84967    18.38397
log_std/mean                          -0.06434     0.00033    -0.06402    -0.06467
log_std/std                           0.00321      0.00002    0.00324     0.00319
log_std/max                           -0.05810     0.00027    -0.05784    -0.05837
log_std/min                           -0.07169     0.00045    -0.07124    -0.07214
log_probs/mean                        -2.72184     0.01446    -2.70738    -2.73630
log_probs/std                         0.31357      0.00911    0.32268     0.30447
log_probs/max                         -1.75915     0.05414    -1.70501    -1.81329
log_probs/min                         -4.44953     0.24413    -4.20540    -4.69367
mean/mean                             0.00114      0.00003    0.00117     0.00111
mean/std                              0.00189      0.00001    0.00190     0.00188
mean/max                              0.00607      0.00005    0.00612     0.00602
mean/min                              -0.00129     0.00002    -0.00128    -0.00131
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 62 50
freq 22
sample: [5, 8, 7, 2, 4, 3, 6, 1, 9, 0]
replay_buffer._size: [9600 9600 9600 9600 9600 9600 9600 9600 9600 9600]
train_time 0.1483747959136963
eval time 0.003187894821166992
snapshot at best
2023-08-22 20:45:25,442 MainThread INFO: EPOCH:62
2023-08-22 20:45:25,442 MainThread INFO: Time Consumed:0.6438601016998291s
2023-08-22 20:45:25,442 MainThread INFO: Total Frames:94500s
 32%|███▏      | 63/200 [00:49<01:20,  1.70it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1242.29862
Train_Epoch_Reward                    2127.87074
Running_Training_Average_Rewards      1021.80726
Explore_Time                          0.00314
Train___Time                          0.14837
Eval____Time                          0.00319
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.71357
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29575
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26750
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18475
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26876
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.06737
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.24873
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12708.17910
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.55623
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.21239
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           6.93650      0.17845   7.11495     6.75806
alpha_0                               0.96303      0.00014   0.96317     0.96288
alpha_1                               0.96298      0.00015   0.96312     0.96283
alpha_2                               0.96301      0.00014   0.96315     0.96286
alpha_3                               0.96299      0.00014   0.96314     0.96285
alpha_4                               0.96301      0.00014   0.96316     0.96287
alpha_5                               0.96303      0.00014   0.96318     0.96289
alpha_6                               0.96302      0.00014   0.96317     0.96288
alpha_7                               0.96300      0.00014   0.96314     0.96285
alpha_8                               0.96301      0.00014   0.96315     0.96286
alpha_9                               0.96302      0.00014   0.96316     0.96287
Alpha_loss                            -0.25120     0.00083   -0.25037    -0.25203
Training/policy_loss                  -2.70134     0.00451   -2.69684    -2.70585
Training/qf1_loss                     1005.93066   52.20129  1058.13196  953.72937
Training/qf2_loss                     1005.87970   52.20184  1058.08154  953.67786
Training/pf_norm                      0.26773      0.00030   0.26803     0.26743
Training/qf1_norm                     20.62945     0.42941   21.05886    20.20004
Training/qf2_norm                     20.82068     0.42766   21.24835    20.39302
log_std/mean                          -0.06563     0.00032   -0.06531    -0.06595
log_std/std                           0.00331      0.00002   0.00333     0.00328
log_std/max                           -0.05926     0.00028   -0.05898    -0.05954
log_std/min                           -0.07322     0.00032   -0.07291    -0.07354
log_probs/mean                        -2.71811     0.00486   -2.71325    -2.72298
log_probs/std                         0.31888      0.00970   0.32858     0.30919
log_probs/max                         -1.74416     0.03040   -1.71376    -1.77457
log_probs/min                         -4.97336     0.39707   -4.57630    -5.37043
mean/mean                             0.00115      0.00001   0.00116     0.00115
mean/std                              0.00193      0.00001   0.00194     0.00193
mean/max                              0.00620      0.00001   0.00621     0.00619
mean/min                              -0.00142     0.00005   -0.00136    -0.00147
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 63 50
freq 22
sample: [2, 3, 6, 8, 1, 5, 7, 4, 0, 9]
replay_buffer._size: [9750 9750 9750 9750 9750 9750 9750 9750 9750 9750]
train_time 0.12163686752319336
eval time 0.0030221939086914062
snapshot at best
2023-08-22 20:45:26,131 MainThread INFO: EPOCH:63
2023-08-22 20:45:26,131 MainThread INFO: Time Consumed:0.605273962020874s
2023-08-22 20:45:26,131 MainThread INFO: Total Frames:96000s
 32%|███▏      | 64/200 [00:49<01:24,  1.61it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1245.82800
Train_Epoch_Reward                    8738.70389
Running_Training_Average_Rewards      424.74159
Explore_Time                          0.00297
Train___Time                          0.12164
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.57494
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.28828
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29656
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18399
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31037
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.10248
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.27425
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12739.68210
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.55165
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20386
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.01571      0.56465    7.58036     6.45106
alpha_0                               0.96245      0.00014    0.96259     0.96230
alpha_1                               0.96240      0.00014    0.96254     0.96225
alpha_2                               0.96243      0.00014    0.96257     0.96228
alpha_3                               0.96241      0.00014    0.96256     0.96227
alpha_4                               0.96243      0.00014    0.96258     0.96229
alpha_5                               0.96245      0.00014    0.96260     0.96231
alpha_6                               0.96244      0.00014    0.96259     0.96230
alpha_7                               0.96242      0.00014    0.96256     0.96227
alpha_8                               0.96243      0.00014    0.96257     0.96228
alpha_9                               0.96244      0.00014    0.96258     0.96229
Alpha_loss                            -0.25503     0.00084    -0.25420    -0.25587
Training/policy_loss                  -2.69673     0.00428    -2.69245    -2.70101
Training/qf1_loss                     1047.06689   267.41565  1314.48254  779.65125
Training/qf2_loss                     1047.00104   267.41278  1314.41382  779.58826
Training/pf_norm                      0.20099      0.00663    0.20762     0.19435
Training/qf1_norm                     20.82854     1.20873    22.03728    19.61981
Training/qf2_norm                     21.07621     1.22487    22.30108    19.85134
log_std/mean                          -0.06693     0.00032    -0.06661    -0.06725
log_std/std                           0.00342      0.00003    0.00345     0.00339
log_std/max                           -0.06041     0.00027    -0.06015    -0.06068
log_std/min                           -0.07450     0.00026    -0.07424    -0.07477
log_probs/mean                        -2.71271     0.00456    -2.70815    -2.71726
log_probs/std                         0.29825      0.00174    0.29999     0.29651
log_probs/max                         -1.75391     0.01045    -1.74346    -1.76436
log_probs/min                         -3.87657     0.09047    -3.78610    -3.96704
mean/mean                             0.00112      0.00001    0.00113     0.00111
mean/std                              0.00197      0.00002    0.00199     0.00195
mean/max                              0.00619      0.00001    0.00620     0.00617
mean/min                              -0.00169     0.00007    -0.00163    -0.00176
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 64 50
freq 22
sample: [9, 8, 6, 3, 0, 1, 7, 2, 4, 5]
replay_buffer._size: [9900 9900 9900 9900 9900 9900 9900 9900 9900 9900]
train_time 0.1372973918914795
eval time 0.0028352737426757812
snapshot at best
2023-08-22 20:45:26,860 MainThread INFO: EPOCH:64
2023-08-22 20:45:26,860 MainThread INFO: Time Consumed:0.6357557773590088s
2023-08-22 20:45:26,860 MainThread INFO: Total Frames:97500s
 32%|███▎      | 65/200 [00:50<01:28,  1.52it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1248.54303
Train_Epoch_Reward                    10433.35247
Running_Training_Average_Rewards      709.99757
Explore_Time                          0.00235
Train___Time                          0.13730
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.94632
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.30651
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29547
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.19600
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.32332
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.11158
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.27408
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12753.25621
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57479
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.19714
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.46354      0.15165  6.61520    6.31189
alpha_0                               0.96187      0.00014  0.96201    0.96173
alpha_1                               0.96182      0.00014  0.96196    0.96168
alpha_2                               0.96185      0.00014  0.96199    0.96170
alpha_3                               0.96184      0.00014  0.96198    0.96169
alpha_4                               0.96185      0.00014  0.96200    0.96171
alpha_5                               0.96187      0.00014  0.96202    0.96173
alpha_6                               0.96186      0.00014  0.96201    0.96172
alpha_7                               0.96184      0.00014  0.96199    0.96170
alpha_8                               0.96185      0.00014  0.96200    0.96171
alpha_9                               0.96186      0.00014  0.96200    0.96171
Alpha_loss                            -0.25954     0.00066  -0.25888   -0.26020
Training/policy_loss                  -2.70904     0.00861  -2.70044   -2.71765
Training/qf1_loss                     781.53992    8.50903  790.04895  773.03088
Training/qf2_loss                     781.48569    8.51047  789.99615  772.97522
Training/pf_norm                      0.20903      0.01197  0.22100    0.19706
Training/qf1_norm                     19.69894     0.33159  20.03053   19.36736
Training/qf2_norm                     19.89303     0.32698  20.22000   19.56605
log_std/mean                          -0.06821     0.00032  -0.06789   -0.06853
log_std/std                           0.00355      0.00003  0.00358    0.00351
log_std/max                           -0.06144     0.00027  -0.06117   -0.06171
log_std/min                           -0.07610     0.00030  -0.07581   -0.07640
log_probs/mean                        -2.72491     0.00907  -2.71584   -2.73397
log_probs/std                         0.30553      0.00090  0.30643    0.30463
log_probs/max                         -1.77977     0.01619  -1.76358   -1.79596
log_probs/min                         -4.43602     0.10201  -4.33401   -4.53803
mean/mean                             0.00122      0.00004  0.00126    0.00118
mean/std                              0.00201      0.00000  0.00201    0.00200
mean/max                              0.00628      0.00000  0.00628    0.00627
mean/min                              -0.00181     0.00000  -0.00181   -0.00181
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 65 50
freq 22
sample: [4, 9, 7, 6, 0, 8, 3, 5, 2, 1]
replay_buffer._size: [10050 10050 10050 10050 10050 10050 10050 10050 10050 10050]
train_time 0.12447285652160645
eval time 0.0021865367889404297
snapshot at best
2023-08-22 20:45:27,605 MainThread INFO: EPOCH:65
2023-08-22 20:45:27,605 MainThread INFO: Time Consumed:0.6404716968536377s
2023-08-22 20:45:27,605 MainThread INFO: Total Frames:99000s
 33%|███▎      | 66/200 [00:51<01:31,  1.46it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1250.97709
Train_Epoch_Reward                    1924.30304
Running_Training_Average_Rewards      703.21198
Explore_Time                          0.00286
Train___Time                          0.12447
Eval____Time                          0.00219
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.32731
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.31087
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.31776
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.19706
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.35329
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14229
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.29673
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12784.09030
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57933
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.17978
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.62498      0.11307    6.73804     6.51191
alpha_0                               0.96129      0.00014    0.96144     0.96115
alpha_1                               0.96124      0.00014    0.96139     0.96110
alpha_2                               0.96127      0.00014    0.96142     0.96113
alpha_3                               0.96126      0.00014    0.96140     0.96111
alpha_4                               0.96127      0.00014    0.96142     0.96113
alpha_5                               0.96130      0.00014    0.96144     0.96115
alpha_6                               0.96128      0.00014    0.96143     0.96114
alpha_7                               0.96126      0.00014    0.96141     0.96112
alpha_8                               0.96127      0.00014    0.96142     0.96113
alpha_9                               0.96128      0.00014    0.96142     0.96114
Alpha_loss                            -0.26305     0.00092    -0.26213    -0.26397
Training/policy_loss                  -2.69659     0.00206    -2.69454    -2.69865
Training/qf1_loss                     874.32043    136.65594  1010.97638  737.66449
Training/qf2_loss                     874.26077    136.66049  1010.92126  737.60028
Training/pf_norm                      0.23801      0.00441    0.24242     0.23360
Training/qf1_norm                     20.07645     0.22968    20.30614    19.84677
Training/qf2_norm                     20.28486     0.24538    20.53024    20.03947
log_std/mean                          -0.06948     0.00032    -0.06916    -0.06980
log_std/std                           0.00367      0.00003    0.00370     0.00364
log_std/max                           -0.06252     0.00026    -0.06225    -0.06278
log_std/min                           -0.07764     0.00019    -0.07745    -0.07783
log_probs/mean                        -2.71121     0.00221    -2.70900    -2.71342
log_probs/std                         0.30337      0.00061    0.30398     0.30276
log_probs/max                         -1.79287     0.01303    -1.77983    -1.80590
log_probs/min                         -4.67063     0.59074    -4.07989    -5.26137
mean/mean                             0.00132      0.00000    0.00132     0.00132
mean/std                              0.00200      0.00000    0.00200     0.00200
mean/max                              0.00623      0.00003    0.00626     0.00620
mean/min                              -0.00190     0.00003    -0.00187    -0.00193
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 66 50
freq 22
sample: [2, 3, 0, 1, 6, 9, 7, 5, 4, 8]
replay_buffer._size: [10200 10200 10200 10200 10200 10200 10200 10200 10200 10200]
train_time 0.17363309860229492
eval time 0.0036232471466064453
snapshot at best
2023-08-22 20:45:28,447 MainThread INFO: EPOCH:66
2023-08-22 20:45:28,448 MainThread INFO: Time Consumed:0.7256708145141602s
2023-08-22 20:45:28,448 MainThread INFO: Total Frames:100500s
 34%|███▎      | 67/200 [00:52<01:36,  1.37it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1252.88923
Train_Epoch_Reward                    13033.61686
Running_Training_Average_Rewards      846.37575
Explore_Time                          0.00314
Train___Time                          0.17363
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.15369
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.31403
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.34158
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.21241
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39640
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18644
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.33106
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12796.95485
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57914
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.17995
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.90858      0.55516    7.46374     6.35342
alpha_0                               0.96072      0.00014    0.96086     0.96057
alpha_1                               0.96066      0.00014    0.96081     0.96052
alpha_2                               0.96069      0.00014    0.96084     0.96055
alpha_3                               0.96068      0.00014    0.96082     0.96053
alpha_4                               0.96070      0.00014    0.96084     0.96055
alpha_5                               0.96072      0.00014    0.96086     0.96058
alpha_6                               0.96070      0.00014    0.96085     0.96056
alpha_7                               0.96069      0.00014    0.96083     0.96054
alpha_8                               0.96069      0.00014    0.96084     0.96055
alpha_9                               0.96070      0.00014    0.96085     0.96056
Alpha_loss                            -0.26772     0.00081    -0.26691    -0.26853
Training/policy_loss                  -2.71248     0.00476    -2.70773    -2.71724
Training/qf1_loss                     941.09894    155.06683  1096.16577  786.03210
Training/qf2_loss                     941.01849    155.05792  1096.07642  785.96057
Training/pf_norm                      0.20374      0.04132    0.24506     0.16241
Training/qf1_norm                     20.73853     1.23535    21.97388    19.50318
Training/qf2_norm                     21.02562     1.27097    22.29659    19.75465
log_std/mean                          -0.07077     0.00032    -0.07044    -0.07109
log_std/std                           0.00381      0.00004    0.00384     0.00377
log_std/max                           -0.06355     0.00026    -0.06329    -0.06381
log_std/min                           -0.07917     0.00054    -0.07864    -0.07971
log_probs/mean                        -2.72714     0.00505    -2.72209    -2.73219
log_probs/std                         0.30066      0.00011    0.30077     0.30055
log_probs/max                         -1.91671     0.03978    -1.87693    -1.95650
log_probs/min                         -4.59734     0.03127    -4.56607    -4.62860
mean/mean                             0.00139      0.00003    0.00141     0.00136
mean/std                              0.00197      0.00001    0.00198     0.00197
mean/max                              0.00611      0.00001    0.00611     0.00610
mean/min                              -0.00194     0.00002    -0.00192    -0.00196
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 67 50
freq 22
sample: [3, 1, 2, 0, 7, 6, 5, 9, 4, 8]
replay_buffer._size: [10350 10350 10350 10350 10350 10350 10350 10350 10350 10350]
train_time 0.1452958583831787
eval time 0.0027289390563964844
2023-08-22 20:45:28,700 MainThread INFO: EPOCH:67
2023-08-22 20:45:28,700 MainThread INFO: Time Consumed:0.15166568756103516s
2023-08-22 20:45:28,700 MainThread INFO: Total Frames:102000s
 34%|███▍      | 68/200 [00:52<01:17,  1.71it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1254.27633
Train_Epoch_Reward                    15825.32260
Running_Training_Average_Rewards      1026.10808
Explore_Time                          0.00310
Train___Time                          0.14530
Eval____Time                          0.00273
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.44588
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33282
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.34501
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.23661
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42336
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21310
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.35045
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12795.76967
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.59284
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.18572
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.98155      0.08795   7.06950    6.89360
alpha_0                               0.96014      0.00014   0.96028    0.96000
alpha_1                               0.96009      0.00014   0.96023    0.95994
alpha_2                               0.96011      0.00014   0.96026    0.95997
alpha_3                               0.96010      0.00014   0.96024    0.95996
alpha_4                               0.96012      0.00014   0.96026    0.95997
alpha_5                               0.96014      0.00014   0.96029    0.96000
alpha_6                               0.96013      0.00014   0.96027    0.95998
alpha_7                               0.96011      0.00014   0.96025    0.95996
alpha_8                               0.96012      0.00014   0.96026    0.95997
alpha_9                               0.96012      0.00014   0.96027    0.95998
Alpha_loss                            -0.27142     0.00123   -0.27019   -0.27265
Training/policy_loss                  -2.70493     0.00548   -2.69945   -2.71041
Training/qf1_loss                     909.93588    77.56186  987.49774  832.37402
Training/qf2_loss                     909.86093    77.57059  987.43152  832.29034
Training/pf_norm                      0.21001      0.04067   0.25069    0.16934
Training/qf1_norm                     20.96386     0.19979   21.16365   20.76407
Training/qf2_norm                     21.22613     0.16536   21.39149   21.06077
log_std/mean                          -0.07207     0.00033   -0.07174   -0.07240
log_std/std                           0.00395      0.00003   0.00398    0.00392
log_std/max                           -0.06462     0.00027   -0.06435   -0.06490
log_std/min                           -0.08089     0.00036   -0.08053   -0.08124
log_probs/mean                        -2.71851     0.00539   -2.71312   -2.72389
log_probs/std                         0.29640      0.01151   0.30791    0.28489
log_probs/max                         -1.81616     0.04342   -1.77273   -1.85958
log_probs/min                         -4.48989     0.41045   -4.07945   -4.90034
mean/mean                             0.00148      0.00001   0.00149    0.00147
mean/std                              0.00202      0.00003   0.00205    0.00199
mean/max                              0.00625      0.00007   0.00632    0.00618
mean/min                              -0.00190     0.00001   -0.00189   -0.00191
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 68 50
freq 22
sample: [3, 7, 8, 9, 1, 2, 4, 6, 0, 5]
replay_buffer._size: [10500 10500 10500 10500 10500 10500 10500 10500 10500 10500]
train_time 0.1606121063232422
eval time 0.003235340118408203
snapshot at best
2023-08-22 20:45:29,744 MainThread INFO: EPOCH:68
2023-08-22 20:45:29,744 MainThread INFO: Time Consumed:0.6649599075317383s
2023-08-22 20:45:29,744 MainThread INFO: Total Frames:103500s
 34%|███▍      | 69/200 [00:53<01:34,  1.38it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1255.24914
Train_Epoch_Reward                    21908.82377
Running_Training_Average_Rewards      1692.25877
Explore_Time                          0.00236
Train___Time                          0.16061
Eval____Time                          0.00324
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.16195
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.32248
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.36723
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.24195
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45532
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24430
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.37260
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12808.50517
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.57920
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.18989
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.26611      0.24494    7.51105     7.02117
alpha_0                               0.95956      0.00014    0.95971     0.95942
alpha_1                               0.95951      0.00014    0.95965     0.95936
alpha_2                               0.95954      0.00014    0.95968     0.95939
alpha_3                               0.95952      0.00014    0.95967     0.95938
alpha_4                               0.95954      0.00014    0.95969     0.95940
alpha_5                               0.95957      0.00014    0.95971     0.95942
alpha_6                               0.95955      0.00014    0.95969     0.95940
alpha_7                               0.95953      0.00014    0.95968     0.95939
alpha_8                               0.95954      0.00014    0.95968     0.95939
alpha_9                               0.95955      0.00014    0.95969     0.95940
Alpha_loss                            -0.27551     0.00096    -0.27456    -0.27647
Training/policy_loss                  -2.70686     0.00096    -2.70590    -2.70782
Training/qf1_loss                     1015.36047   167.81592  1183.17639  847.54456
Training/qf2_loss                     1015.26764   167.80780  1183.07544  847.45984
Training/pf_norm                      0.20990      0.02255    0.23244     0.18735
Training/qf1_norm                     21.61305     0.56154    22.17459    21.05152
Training/qf2_norm                     21.94223     0.59332    22.53555    21.34891
log_std/mean                          -0.07336     0.00032    -0.07304    -0.07367
log_std/std                           0.00408      0.00003    0.00411     0.00405
log_std/max                           -0.06569     0.00026    -0.06544    -0.06595
log_std/min                           -0.08237     0.00028    -0.08209    -0.08265
log_probs/mean                        -2.71980     0.00129    -2.71851    -2.72110
log_probs/std                         0.30092      0.00026    0.30118     0.30065
log_probs/max                         -1.76962     0.00718    -1.76244    -1.77679
log_probs/min                         -4.41890     0.34761    -4.07129    -4.76652
mean/mean                             0.00145      0.00001    0.00147     0.00144
mean/std                              0.00211      0.00001    0.00212     0.00210
mean/max                              0.00642      0.00002    0.00644     0.00639
mean/min                              -0.00194     0.00000    -0.00194    -0.00194
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 69 50
freq 22
sample: [6, 8, 9, 5, 3, 2, 4, 7, 1, 0]
replay_buffer._size: [10650 10650 10650 10650 10650 10650 10650 10650 10650 10650]
train_time 0.1347508430480957
eval time 0.002298593521118164
snapshot at best
2023-08-22 20:45:30,523 MainThread INFO: EPOCH:69
2023-08-22 20:45:30,523 MainThread INFO: Time Consumed:0.6797220706939697s
2023-08-22 20:45:30,523 MainThread INFO: Total Frames:105000s
 35%|███▌      | 70/200 [00:54<01:36,  1.35it/s]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1256.59300
Train_Epoch_Reward                    29727.35711
Running_Training_Average_Rewards      2248.71678
Explore_Time                          0.00268
Train___Time                          0.13475
Eval____Time                          0.00230
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.82211
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.30457
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.38919
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.22320
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45226
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24463
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.36981
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12837.10998
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.56086
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16741
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.69519      0.04955   7.74474     7.64564
alpha_0                               0.95899      0.00014   0.95913     0.95884
alpha_1                               0.95893      0.00014   0.95907     0.95878
alpha_2                               0.95896      0.00014   0.95910     0.95882
alpha_3                               0.95895      0.00014   0.95909     0.95880
alpha_4                               0.95896      0.00014   0.95911     0.95882
alpha_5                               0.95899      0.00014   0.95913     0.95884
alpha_6                               0.95897      0.00014   0.95912     0.95883
alpha_7                               0.95895      0.00014   0.95910     0.95881
alpha_8                               0.95896      0.00014   0.95910     0.95882
alpha_9                               0.95897      0.00014   0.95911     0.95883
Alpha_loss                            -0.27990     0.00060   -0.27930    -0.28049
Training/policy_loss                  -2.71561     0.00949   -2.70612    -2.72510
Training/qf1_loss                     1288.72900   70.21851  1358.94751  1218.51050
Training/qf2_loss                     1288.61877   70.21375  1358.83252  1218.40503
Training/pf_norm                      0.19040      0.02737   0.21776     0.16303
Training/qf1_norm                     22.64254     0.12740   22.76994    22.51514
Training/qf2_norm                     23.03315     0.14097   23.17411    22.89218
log_std/mean                          -0.07463     0.00032   -0.07431    -0.07495
log_std/std                           0.00422      0.00003   0.00425     0.00418
log_std/max                           -0.06672     0.00026   -0.06646    -0.06698
log_std/min                           -0.08359     0.00028   -0.08331    -0.08387
log_probs/mean                        -2.72806     0.01001   -2.71805    -2.73808
log_probs/std                         0.29229      0.00507   0.29736     0.28722
log_probs/max                         -1.80674     0.00398   -1.80276    -1.81073
log_probs/min                         -4.44199     0.23272   -4.20927    -4.67471
mean/mean                             0.00146      0.00000   0.00146     0.00145
mean/std                              0.00218      0.00001   0.00219     0.00217
mean/max                              0.00663      0.00003   0.00666     0.00660
mean/min                              -0.00193     0.00000   -0.00193    -0.00193
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 70 50
freq 22
sample: [4, 3, 5, 0, 2, 9, 1, 8, 7, 6]
replay_buffer._size: [10800 10800 10800 10800 10800 10800 10800 10800 10800 10800]
train_time 0.12476468086242676
eval time 0.003680706024169922
snapshot at best
2023-08-22 20:45:31,289 MainThread INFO: EPOCH:70
2023-08-22 20:45:31,290 MainThread INFO: Time Consumed:0.6606924533843994s
2023-08-22 20:45:31,290 MainThread INFO: Total Frames:106500s
 36%|███▌      | 71/200 [00:54<01:36,  1.34it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1258.89249
Train_Epoch_Reward                    19631.14993
Running_Training_Average_Rewards      2375.57769
Explore_Time                          0.00273
Train___Time                          0.12476
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.61772
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.28340
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40057
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.19980
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43465
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23393
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.35934
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12858.85723
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.54516
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15401
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           7.09146      0.13978  7.23124    6.95168
alpha_0                               0.95841      0.00014  0.95855    0.95827
alpha_1                               0.95835      0.00014  0.95850    0.95821
alpha_2                               0.95838      0.00014  0.95853    0.95824
alpha_3                               0.95837      0.00014  0.95851    0.95822
alpha_4                               0.95839      0.00014  0.95853    0.95824
alpha_5                               0.95841      0.00014  0.95856    0.95827
alpha_6                               0.95839      0.00014  0.95854    0.95825
alpha_7                               0.95838      0.00014  0.95852    0.95823
alpha_8                               0.95838      0.00014  0.95853    0.95824
alpha_9                               0.95839      0.00014  0.95854    0.95825
Alpha_loss                            -0.28350     0.00110  -0.28241   -0.28460
Training/policy_loss                  -2.70629     0.00223  -2.70405   -2.70852
Training/qf1_loss                     992.11758    7.73123  999.84882  984.38635
Training/qf2_loss                     992.02402    7.71786  999.74188  984.30615
Training/pf_norm                      0.21859      0.00920  0.22779    0.20940
Training/qf1_norm                     21.36001     0.29394  21.65395   21.06607
Training/qf2_norm                     21.67484     0.24380  21.91864   21.43103
log_std/mean                          -0.07590     0.00033  -0.07558   -0.07623
log_std/std                           0.00435      0.00004  0.00438    0.00431
log_std/max                           -0.06779     0.00026  -0.06752   -0.06805
log_std/min                           -0.08519     0.00033  -0.08487   -0.08552
log_probs/mean                        -2.71750     0.00204  -2.71546   -2.71954
log_probs/std                         0.29713      0.00940  0.30653    0.28774
log_probs/max                         -1.88484     0.00499  -1.87984   -1.88983
log_probs/min                         -5.61852     1.22575  -4.39277   -6.84427
mean/mean                             0.00145      0.00002  0.00147    0.00143
mean/std                              0.00227      0.00003  0.00230    0.00224
mean/max                              0.00685      0.00004  0.00689    0.00680
mean/min                              -0.00201     0.00006  -0.00195   -0.00207
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 71 50
freq 22
sample: [9, 8, 3, 0, 4, 1, 5, 6, 7, 2]
replay_buffer._size: [10950 10950 10950 10950 10950 10950 10950 10950 10950 10950]
train_time 0.1532917022705078
eval time 0.002187013626098633
snapshot at best
2023-08-22 20:45:32,075 MainThread INFO: EPOCH:71
2023-08-22 20:45:32,076 MainThread INFO: Time Consumed:0.6867995262145996s
2023-08-22 20:45:32,076 MainThread INFO: Total Frames:108000s
 36%|███▌      | 72/200 [00:55<01:37,  1.31it/s]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1261.07222
Train_Epoch_Reward                    9396.46303
Running_Training_Average_Rewards      1958.49900
Explore_Time                          0.00289
Train___Time                          0.15329
Eval____Time                          0.00219
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.63412
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26185
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.41353
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.17975
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42669
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23140
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.35731
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12879.13618
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.52759
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.14188
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.81088      0.67329    8.48417     7.13759
alpha_0                               0.95783      0.00014    0.95798     0.95769
alpha_1                               0.95777      0.00014    0.95792     0.95763
alpha_2                               0.95781      0.00014    0.95795     0.95766
alpha_3                               0.95779      0.00014    0.95794     0.95765
alpha_4                               0.95781      0.00014    0.95796     0.95767
alpha_5                               0.95783      0.00014    0.95798     0.95769
alpha_6                               0.95782      0.00014    0.95796     0.95767
alpha_7                               0.95780      0.00014    0.95795     0.95766
alpha_8                               0.95781      0.00014    0.95795     0.95766
alpha_9                               0.95782      0.00014    0.95796     0.95767
Alpha_loss                            -0.28792     0.00068    -0.28724    -0.28860
Training/policy_loss                  -2.71556     0.00716    -2.70840    -2.72273
Training/qf1_loss                     1246.29645   150.40558  1396.70203  1095.89087
Training/qf2_loss                     1246.19519   150.37073  1396.56592  1095.82446
Training/pf_norm                      0.19170      0.00748    0.19918     0.18422
Training/qf1_norm                     23.04623     1.49054    24.53677    21.55569
Training/qf2_norm                     23.38238     1.62522    25.00760    21.75716
log_std/mean                          -0.07720     0.00033    -0.07687    -0.07752
log_std/std                           0.00448      0.00004    0.00452     0.00445
log_std/max                           -0.06887     0.00027    -0.06860    -0.06915
log_std/min                           -0.08668     0.00056    -0.08612    -0.08724
log_probs/mean                        -2.72630     0.00772    -2.71858    -2.73402
log_probs/std                         0.29569      0.00536    0.30105     0.29033
log_probs/max                         -1.82388     0.04152    -1.78236    -1.86540
log_probs/min                         -4.69368     0.44711    -4.24657    -5.14079
mean/mean                             0.00130      0.00004    0.00134     0.00126
mean/std                              0.00237      0.00001    0.00238     0.00236
mean/max                              0.00693      0.00000    0.00693     0.00692
mean/min                              -0.00227     0.00004    -0.00223    -0.00231
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 72 50
freq 22
sample: [9, 0, 5, 3, 6, 7, 4, 8, 1, 2]
replay_buffer._size: [11100 11100 11100 11100 11100 11100 11100 11100 11100 11100]
train_time 0.12880945205688477
eval time 0.0023627281188964844
snapshot at best
2023-08-22 20:45:32,821 MainThread INFO: EPOCH:72
2023-08-22 20:45:32,821 MainThread INFO: Time Consumed:0.6377773284912109s
2023-08-22 20:45:32,821 MainThread INFO: Total Frames:109500s
 36%|███▋      | 73/200 [00:56<01:35,  1.33it/s]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1263.21228
Train_Epoch_Reward                    16383.03163
Running_Training_Average_Rewards      1513.68815
Explore_Time                          0.00266
Train___Time                          0.12881
Eval____Time                          0.00236
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.97026
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.26731
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40847
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16388
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39746
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20784
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.33749
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12903.17754
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.53120
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.11588
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.04083      0.42376   8.46459     7.61707
alpha_0                               0.95726      0.00014   0.95740     0.95711
alpha_1                               0.95720      0.00014   0.95734     0.95705
alpha_2                               0.95723      0.00014   0.95738     0.95709
alpha_3                               0.95722      0.00014   0.95736     0.95707
alpha_4                               0.95724      0.00014   0.95738     0.95709
alpha_5                               0.95726      0.00014   0.95740     0.95711
alpha_6                               0.95724      0.00014   0.95738     0.95710
alpha_7                               0.95723      0.00014   0.95737     0.95708
alpha_8                               0.95723      0.00014   0.95737     0.95709
alpha_9                               0.95724      0.00014   0.95739     0.95710
Alpha_loss                            -0.29195     0.00121   -0.29074    -0.29316
Training/policy_loss                  -2.71611     0.00458   -2.71154    -2.72069
Training/qf1_loss                     1391.98657   20.47913  1412.46570  1371.50745
Training/qf2_loss                     1391.85736   20.47113  1412.32849  1371.38623
Training/pf_norm                      0.18908      0.01742   0.20650     0.17165
Training/qf1_norm                     23.62325     0.92313   24.54638    22.70012
Training/qf2_norm                     24.06813     0.95777   25.02590    23.11036
log_std/mean                          -0.07851     0.00033   -0.07818    -0.07884
log_std/std                           0.00463      0.00004   0.00466     0.00459
log_std/max                           -0.06996     0.00028   -0.06969    -0.07024
log_std/min                           -0.08807     0.00049   -0.08759    -0.08856
log_probs/mean                        -2.72593     0.00460   -2.72133    -2.73053
log_probs/std                         0.28976      0.00550   0.29526     0.28427
log_probs/max                         -1.85566     0.05064   -1.80501    -1.90630
log_probs/min                         -4.36065     0.28887   -4.07178    -4.64952
mean/mean                             0.00116      0.00004   0.00120     0.00112
mean/std                              0.00244      0.00002   0.00246     0.00243
mean/max                              0.00697      0.00001   0.00697     0.00696
mean/min                              -0.00250     0.00008   -0.00242    -0.00257
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 73 50
freq 22
sample: [1, 5, 2, 8, 7, 6, 9, 0, 4, 3]
replay_buffer._size: [11250 11250 11250 11250 11250 11250 11250 11250 11250 11250]
train_time 0.1281425952911377
eval time 0.0029587745666503906
snapshot at best
2023-08-22 20:45:33,524 MainThread INFO: EPOCH:73
2023-08-22 20:45:33,524 MainThread INFO: Time Consumed:0.6174876689910889s
2023-08-22 20:45:33,524 MainThread INFO: Total Frames:111000s
 37%|███▋      | 74/200 [00:57<01:33,  1.35it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1264.98286
Train_Epoch_Reward                    4239.69581
Running_Training_Average_Rewards      1000.63968
Explore_Time                          0.00281
Train___Time                          0.12814
Eval____Time                          0.00296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.40849
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.27115
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.39467
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.15261
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36184
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18092
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.31920
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12910.47081
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.53225
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.10375
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.68663      0.00679   6.69342    6.67983
alpha_0                               0.95668      0.00014   0.95683    0.95654
alpha_1                               0.95662      0.00014   0.95676    0.95648
alpha_2                               0.95666      0.00014   0.95680    0.95651
alpha_3                               0.95664      0.00014   0.95678    0.95650
alpha_4                               0.95666      0.00014   0.95681    0.95652
alpha_5                               0.95668      0.00014   0.95683    0.95654
alpha_6                               0.95666      0.00014   0.95681    0.95652
alpha_7                               0.95665      0.00014   0.95680    0.95651
alpha_8                               0.95665      0.00014   0.95680    0.95651
alpha_9                               0.95667      0.00014   0.95681    0.95652
Alpha_loss                            -0.29592     0.00077   -0.29515   -0.29669
Training/policy_loss                  -2.71529     0.00490   -2.71039   -2.72019
Training/qf1_loss                     824.70630    47.81226  872.51855  776.89404
Training/qf2_loss                     824.58685    47.80896  872.39581  776.77789
Training/pf_norm                      0.20704      0.03464   0.24168    0.17240
Training/qf1_norm                     20.61938     0.03584   20.65521   20.58354
Training/qf2_norm                     21.01851     0.04912   21.06763   20.96939
log_std/mean                          -0.07982     0.00033   -0.07949   -0.08014
log_std/std                           0.00477      0.00003   0.00480    0.00474
log_std/max                           -0.07105     0.00026   -0.07079   -0.07132
log_std/min                           -0.08970     0.00030   -0.08939   -0.09000
log_probs/mean                        -2.72422     0.00546   -2.71876   -2.72967
log_probs/std                         0.29170      0.01301   0.30471    0.27869
log_probs/max                         -1.80809     0.02753   -1.78055   -1.83562
log_probs/min                         -4.20797     0.32418   -3.88379   -4.53215
mean/mean                             0.00107      0.00000   0.00107    0.00107
mean/std                              0.00252      0.00002   0.00253    0.00250
mean/max                              0.00699      0.00001   0.00700    0.00698
mean/min                              -0.00280     0.00007   -0.00273   -0.00287
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 74 50
freq 22
sample: [1, 6, 3, 0, 9, 2, 4, 8, 5, 7]
replay_buffer._size: [11400 11400 11400 11400 11400 11400 11400 11400 11400 11400]
train_time 0.15952205657958984
eval time 0.0029518604278564453
snapshot at best
2023-08-22 20:45:34,298 MainThread INFO: EPOCH:74
2023-08-22 20:45:34,299 MainThread INFO: Time Consumed:0.6817030906677246s
2023-08-22 20:45:34,299 MainThread INFO: Total Frames:112500s
 38%|███▊      | 75/200 [00:57<01:33,  1.34it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1266.57927
Train_Epoch_Reward                    15802.43630
Running_Training_Average_Rewards      1214.17212
Explore_Time                          0.00242
Train___Time                          0.15952
Eval____Time                          0.00295
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.97529
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29092
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.38239
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.14848
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33673
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16552
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30806
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12922.09576
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.54942
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.08439
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.70653      0.12897   6.83550    6.57756
alpha_0                               0.95611      0.00014   0.95625    0.95596
alpha_1                               0.95604      0.00014   0.95619    0.95590
alpha_2                               0.95608      0.00014   0.95623    0.95594
alpha_3                               0.95606      0.00014   0.95621    0.95592
alpha_4                               0.95609      0.00014   0.95623    0.95594
alpha_5                               0.95611      0.00014   0.95625    0.95596
alpha_6                               0.95609      0.00014   0.95623    0.95594
alpha_7                               0.95608      0.00014   0.95622    0.95593
alpha_8                               0.95608      0.00014   0.95622    0.95593
alpha_9                               0.95609      0.00014   0.95623    0.95595
Alpha_loss                            -0.29995     0.00082   -0.29914   -0.30077
Training/policy_loss                  -2.71600     0.00403   -2.71197   -2.72002
Training/qf1_loss                     861.69885    84.30798  946.00684  777.39087
Training/qf2_loss                     861.57486    84.31589  945.89075  777.25897
Training/pf_norm                      0.19942      0.01620   0.21562    0.18322
Training/qf1_norm                     20.71810     0.26926   20.98736   20.44885
Training/qf2_norm                     21.13310     0.24017   21.37327   20.89292
log_std/mean                          -0.08113     0.00033   -0.08080   -0.08146
log_std/std                           0.00491      0.00003   0.00495    0.00488
log_std/max                           -0.07215     0.00029   -0.07187   -0.07244
log_std/min                           -0.09117     0.00019   -0.09097   -0.09136
log_probs/mean                        -2.72390     0.00440   -2.71950   -2.72830
log_probs/std                         0.27518      0.00459   0.27977    0.27060
log_probs/max                         -1.96914     0.02573   -1.94341   -1.99488
log_probs/min                         -3.84002     0.11379   -3.72623   -3.95381
mean/mean                             0.00104      0.00001   0.00105    0.00103
mean/std                              0.00253      0.00000   0.00253    0.00253
mean/max                              0.00698      0.00001   0.00699    0.00697
mean/min                              -0.00294     0.00003   -0.00291   -0.00297
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 75 50
freq 22
sample: [1, 0, 5, 8, 4, 9, 2, 3, 7, 6]
replay_buffer._size: [11550 11550 11550 11550 11550 11550 11550 11550 11550 11550]
train_time 0.1606745719909668
eval time 0.002878904342651367
snapshot at best
2023-08-22 20:45:35,068 MainThread INFO: EPOCH:75
2023-08-22 20:45:35,068 MainThread INFO: Time Consumed:0.681227445602417s
2023-08-22 20:45:35,068 MainThread INFO: Total Frames:114000s
 38%|███▊      | 76/200 [00:58<01:33,  1.32it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1267.69316
Train_Epoch_Reward                    19474.76583
Running_Training_Average_Rewards      1317.22993
Explore_Time                          0.00332
Train___Time                          0.16067
Eval____Time                          0.00288
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.19986
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29983
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.37564
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.14720
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.32602
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16327
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30800
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12932.63874
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.55207
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.07254
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.15109      0.18209   7.33318    6.96900
alpha_0                               0.95553      0.00014   0.95568    0.95539
alpha_1                               0.95547      0.00014   0.95561    0.95532
alpha_2                               0.95551      0.00014   0.95565    0.95536
alpha_3                               0.95549      0.00014   0.95563    0.95535
alpha_4                               0.95551      0.00014   0.95565    0.95537
alpha_5                               0.95553      0.00014   0.95568    0.95539
alpha_6                               0.95551      0.00014   0.95566    0.95537
alpha_7                               0.95550      0.00014   0.95565    0.95536
alpha_8                               0.95550      0.00014   0.95565    0.95536
alpha_9                               0.95552      0.00014   0.95566    0.95537
Alpha_loss                            -0.30400     0.00060   -0.30340   -0.30460
Training/policy_loss                  -2.71721     0.00840   -2.70881   -2.72561
Training/qf1_loss                     936.56381    50.62210  987.18591  885.94171
Training/qf2_loss                     936.40796    50.63568  987.04364  885.77228
Training/pf_norm                      0.18941      0.02831   0.21772    0.16110
Training/qf1_norm                     21.76523     0.46182   22.22705   21.30341
Training/qf2_norm                     22.29326     0.40525   22.69851   21.88801
log_std/mean                          -0.08244     0.00032   -0.08211   -0.08276
log_std/std                           0.00506      0.00004   0.00509    0.00502
log_std/max                           -0.07329     0.00028   -0.07300   -0.07357
log_std/min                           -0.09246     0.00047   -0.09199   -0.09293
log_probs/mean                        -2.72394     0.00916   -2.71478   -2.73310
log_probs/std                         0.28733      0.00362   0.29094    0.28371
log_probs/max                         -1.82867     0.00135   -1.82732   -1.83002
log_probs/min                         -5.38128     1.01477   -4.36651   -6.39605
mean/mean                             0.00096      0.00002   0.00098    0.00094
mean/std                              0.00253      0.00000   0.00253    0.00252
mean/max                              0.00687      0.00002   0.00689    0.00684
mean/min                              -0.00311     0.00005   -0.00306   -0.00316
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 76 50
freq 22
sample: [5, 1, 6, 4, 2, 9, 3, 7, 0, 8]
replay_buffer._size: [11700 11700 11700 11700 11700 11700 11700 11700 11700 11700]
train_time 0.13428425788879395
eval time 0.002462625503540039
2023-08-22 20:45:35,309 MainThread INFO: EPOCH:76
2023-08-22 20:45:35,309 MainThread INFO: Time Consumed:0.1407015323638916s
2023-08-22 20:45:35,309 MainThread INFO: Total Frames:115500s
 38%|███▊      | 77/200 [00:59<01:14,  1.66it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1267.91647
Train_Epoch_Reward                    14656.04175
Running_Training_Average_Rewards      1664.44146
Explore_Time                          0.00350
Train___Time                          0.13428
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.80872
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.32066
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.35352
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.15382
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30596
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.15220
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30226
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12921.48067
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.56829
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.07000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.25216      0.22563   7.47780     7.02653
alpha_0                               0.95496      0.00014   0.95510     0.95482
alpha_1                               0.95489      0.00014   0.95504     0.95475
alpha_2                               0.95493      0.00014   0.95508     0.95479
alpha_3                               0.95491      0.00014   0.95506     0.95477
alpha_4                               0.95494      0.00014   0.95508     0.95479
alpha_5                               0.95496      0.00014   0.95510     0.95481
alpha_6                               0.95494      0.00014   0.95508     0.95479
alpha_7                               0.95493      0.00014   0.95507     0.95479
alpha_8                               0.95493      0.00014   0.95507     0.95478
alpha_9                               0.95494      0.00014   0.95508     0.95480
Alpha_loss                            -0.30799     0.00099   -0.30700    -0.30897
Training/policy_loss                  -2.71715     0.00028   -2.71688    -2.71743
Training/qf1_loss                     1023.67706   44.23236  1067.90942  979.44470
Training/qf2_loss                     1023.50922   44.22113  1067.73035  979.28809
Training/pf_norm                      0.21675      0.01783   0.23458     0.19892
Training/qf1_norm                     22.06272     0.48750   22.55023    21.57522
Training/qf2_norm                     22.63039     0.53725   23.16764    22.09314
log_std/mean                          -0.08378     0.00035   -0.08344    -0.08413
log_std/std                           0.00520      0.00004   0.00524     0.00516
log_std/max                           -0.07442     0.00026   -0.07416    -0.07469
log_std/min                           -0.09399     0.00039   -0.09360    -0.09437
log_probs/mean                        -2.72256     0.00055   -2.72201    -2.72312
log_probs/std                         0.28736      0.00638   0.29374     0.28098
log_probs/max                         -1.88040     0.00461   -1.87579    -1.88502
log_probs/min                         -4.77479     0.15274   -4.62204    -4.92753
mean/mean                             0.00093      0.00001   0.00094     0.00092
mean/std                              0.00245      0.00002   0.00247     0.00242
mean/max                              0.00671      0.00004   0.00675     0.00667
mean/min                              -0.00310     0.00003   -0.00307    -0.00313
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 77 50
freq 22
sample: [5, 0, 4, 1, 6, 7, 9, 3, 2, 8]
replay_buffer._size: [11850 11850 11850 11850 11850 11850 11850 11850 11850 11850]
train_time 0.15913963317871094
eval time 0.0023987293243408203
2023-08-22 20:45:35,863 MainThread INFO: EPOCH:77
2023-08-22 20:45:35,863 MainThread INFO: Time Consumed:0.16492390632629395s
2023-08-22 20:45:35,864 MainThread INFO: Total Frames:117000s
 39%|███▉      | 78/200 [00:59<01:12,  1.69it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1266.99605
Train_Epoch_Reward                    4968.26832
Running_Training_Average_Rewards      1303.30253
Explore_Time                          0.00283
Train___Time                          0.15914
Eval____Time                          0.00240
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.34876
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33899
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.32823
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16385
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28550
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14316
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30423
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12896.81747
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.58433
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.07832
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.98723      0.64598    7.63321     6.34124
alpha_0                               0.95439      0.00014    0.95453     0.95424
alpha_1                               0.95432      0.00014    0.95446     0.95418
alpha_2                               0.95436      0.00014    0.95450     0.95421
alpha_3                               0.95434      0.00014    0.95448     0.95420
alpha_4                               0.95436      0.00014    0.95450     0.95422
alpha_5                               0.95438      0.00014    0.95453     0.95424
alpha_6                               0.95436      0.00014    0.95451     0.95422
alpha_7                               0.95436      0.00014    0.95450     0.95421
alpha_8                               0.95435      0.00014    0.95450     0.95421
alpha_9                               0.95437      0.00014    0.95451     0.95422
Alpha_loss                            -0.31207     0.00100    -0.31108    -0.31307
Training/policy_loss                  -2.71885     0.00005    -2.71880    -2.71891
Training/qf1_loss                     956.42685    264.10660  1220.53345  692.32025
Training/qf2_loss                     956.27911    264.09540  1220.37451  692.18372
Training/pf_norm                      0.17299      0.04329    0.21627     0.12970
Training/qf1_norm                     21.56722     1.47103    23.03825    20.09619
Training/qf2_norm                     22.04230     1.50777    23.55007    20.53452
log_std/mean                          -0.08515     0.00033    -0.08482    -0.08548
log_std/std                           0.00536      0.00004    0.00540     0.00533
log_std/max                           -0.07551     0.00026    -0.07525    -0.07577
log_std/min                           -0.09575     0.00011    -0.09564    -0.09585
log_probs/mean                        -2.72350     0.00032    -2.72319    -2.72382
log_probs/std                         0.27483      0.00539    0.28022     0.26943
log_probs/max                         -1.84937     0.05081    -1.79856    -1.90017
log_probs/min                         -4.80953     0.14803    -4.66150    -4.95756
mean/mean                             0.00084      0.00002    0.00087     0.00082
mean/std                              0.00240      0.00001    0.00241     0.00239
mean/max                              0.00655      0.00002    0.00657     0.00653
mean/min                              -0.00317     0.00000    -0.00316    -0.00317
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 78 50
freq 22
sample: [5, 2, 1, 7, 4, 0, 9, 3, 6, 8]
replay_buffer._size: [12000 12000 12000 12000 12000 12000 12000 12000 12000 12000]
train_time 0.11861348152160645
eval time 0.002430438995361328
2023-08-22 20:45:36,377 MainThread INFO: EPOCH:78
2023-08-22 20:45:36,377 MainThread INFO: Time Consumed:0.12430620193481445s
2023-08-22 20:45:36,377 MainThread INFO: Total Frames:118500s
 40%|███▉      | 79/200 [01:00<01:09,  1.75it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1264.96214
Train_Epoch_Reward                    10402.72575
Running_Training_Average_Rewards      1000.90119
Explore_Time                          0.00244
Train___Time                          0.11861
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.21799
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.35943
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.30269
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18272
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.27606
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14502
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.31441
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12872.67623
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.60572
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.09536
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.65650      0.63334    8.28984     7.02317
alpha_0                               0.95381      0.00014    0.95395     0.95367
alpha_1                               0.95374      0.00014    0.95389     0.95360
alpha_2                               0.95378      0.00014    0.95393     0.95364
alpha_3                               0.95377      0.00014    0.95391     0.95362
alpha_4                               0.95379      0.00014    0.95393     0.95364
alpha_5                               0.95381      0.00014    0.95395     0.95366
alpha_6                               0.95379      0.00014    0.95393     0.95365
alpha_7                               0.95378      0.00014    0.95393     0.95364
alpha_8                               0.95378      0.00014    0.95392     0.95363
alpha_9                               0.95379      0.00014    0.95394     0.95365
Alpha_loss                            -0.31571     0.00103    -0.31467    -0.31674
Training/policy_loss                  -2.71173     0.00067    -2.71107    -2.71240
Training/qf1_loss                     1101.62964   253.38318  1355.01282  848.24646
Training/qf2_loss                     1101.44073   253.35577  1354.79651  848.08496
Training/pf_norm                      0.17835      0.00389    0.18224     0.17447
Training/qf1_norm                     23.12107     1.44050    24.56156    21.68057
Training/qf2_norm                     23.75077     1.54534    25.29612    22.20543
log_std/mean                          -0.08652     0.00035    -0.08618    -0.08687
log_std/std                           0.00553      0.00004    0.00557     0.00549
log_std/max                           -0.07663     0.00031    -0.07632    -0.07694
log_std/min                           -0.09738     0.00022    -0.09716    -0.09760
log_probs/mean                        -2.71470     0.00045    -2.71426    -2.71515
log_probs/std                         0.26309      0.00069    0.26378     0.26239
log_probs/max                         -1.89888     0.03167    -1.86721    -1.93056
log_probs/min                         -4.11787     0.21612    -3.90176    -4.33399
mean/mean                             0.00084      0.00001    0.00085     0.00084
mean/std                              0.00243      0.00003    0.00247     0.00240
mean/max                              0.00662      0.00004    0.00666     0.00658
mean/min                              -0.00327     0.00007    -0.00320    -0.00334
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 79 50
freq 22
sample: [5, 3, 2, 1, 7, 0, 8, 6, 9, 4]
replay_buffer._size: [12150 12150 12150 12150 12150 12150 12150 12150 12150 12150]
train_time 0.14631104469299316
eval time 0.0023322105407714844
2023-08-22 20:45:37,055 MainThread INFO: EPOCH:79
2023-08-22 20:45:37,056 MainThread INFO: Time Consumed:0.1522231101989746s
2023-08-22 20:45:37,056 MainThread INFO: Total Frames:120000s
 40%|████      | 80/200 [01:00<01:12,  1.66it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1262.84964
Train_Epoch_Reward                    14585.67940
Running_Training_Average_Rewards      998.55578
Explore_Time                          0.00307
Train___Time                          0.14631
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.74651
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.36380
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.28558
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.17213
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24786
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.12326
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30117
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12865.01611
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61002
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.09553
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.43648      0.99894    7.43543     5.43754
alpha_0                               0.95324      0.00014    0.95338     0.95309
alpha_1                               0.95317      0.00014    0.95331     0.95303
alpha_2                               0.95321      0.00014    0.95335     0.95307
alpha_3                               0.95319      0.00014    0.95334     0.95305
alpha_4                               0.95321      0.00014    0.95336     0.95307
alpha_5                               0.95323      0.00014    0.95338     0.95309
alpha_6                               0.95322      0.00014    0.95336     0.95307
alpha_7                               0.95321      0.00014    0.95335     0.95307
alpha_8                               0.95320      0.00014    0.95335     0.95306
alpha_9                               0.95322      0.00014    0.95336     0.95307
Alpha_loss                            -0.31991     0.00102    -0.31889    -0.32093
Training/policy_loss                  -2.71648     0.00067    -2.71581    -2.71715
Training/qf1_loss                     770.19188    306.23134  1076.42322  463.96054
Training/qf2_loss                     770.00790    306.19937  1076.20728  463.80853
Training/pf_norm                      0.18558      0.00201    0.18759     0.18358
Training/qf1_norm                     20.39448     2.23789    22.63237    18.15660
Training/qf2_norm                     20.99730     2.36115    23.35845    18.63614
log_std/mean                          -0.08790     0.00035    -0.08755    -0.08825
log_std/std                           0.00569      0.00004    0.00573     0.00565
log_std/max                           -0.07777     0.00030    -0.07746    -0.07807
log_std/min                           -0.09884     0.00030    -0.09854    -0.09914
log_probs/mean                        -2.71821     0.00015    -2.71806    -2.71836
log_probs/std                         0.26544      0.00999    0.27543     0.25545
log_probs/max                         -1.93268     0.02941    -1.90327    -1.96209
log_probs/min                         -4.42324     0.28929    -4.13395    -4.71253
mean/mean                             0.00092      0.00002    0.00095     0.00090
mean/std                              0.00260      0.00006    0.00267     0.00254
mean/max                              0.00684      0.00007    0.00691     0.00677
mean/min                              -0.00363     0.00013    -0.00350    -0.00376
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 80 50
freq 22
sample: [0, 3, 8, 1, 4, 5, 9, 6, 7, 2]
replay_buffer._size: [12300 12300 12300 12300 12300 12300 12300 12300 12300 12300]
train_time 0.1426563262939453
eval time 0.0027687549591064453
2023-08-22 20:45:37,710 MainThread INFO: EPOCH:80
2023-08-22 20:45:37,710 MainThread INFO: Time Consumed:0.14879775047302246s
2023-08-22 20:45:37,710 MainThread INFO: Total Frames:121500s
 40%|████      | 81/200 [01:01<01:13,  1.62it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1263.06764
Train_Epoch_Reward                    10335.68970
Running_Training_Average_Rewards      1177.46983
Explore_Time                          0.00279
Train___Time                          0.14266
Eval____Time                          0.00277
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.79793
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.37976
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.30101
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.15430
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25586
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13691
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.31580
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12905.80862
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.62386
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.06119
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.99373      0.03832   7.03205    6.95541
alpha_0                               0.95267      0.00014   0.95281    0.95252
alpha_1                               0.95260      0.00014   0.95274    0.95245
alpha_2                               0.95264      0.00014   0.95278    0.95249
alpha_3                               0.95262      0.00014   0.95276    0.95248
alpha_4                               0.95264      0.00014   0.95278    0.95250
alpha_5                               0.95266      0.00014   0.95280    0.95252
alpha_6                               0.95264      0.00014   0.95279    0.95250
alpha_7                               0.95264      0.00014   0.95278    0.95249
alpha_8                               0.95263      0.00014   0.95277    0.95249
alpha_9                               0.95265      0.00014   0.95279    0.95250
Alpha_loss                            -0.32380     0.00072   -0.32308   -0.32453
Training/policy_loss                  -2.71510     0.00521   -2.70989   -2.72031
Training/qf1_loss                     858.73364    52.89612  911.62976  805.83752
Training/qf2_loss                     858.54718    52.90234  911.44952  805.64484
Training/pf_norm                      0.16911      0.03453   0.20363    0.13458
Training/qf1_norm                     21.75330     0.07164   21.82495   21.68166
Training/qf2_norm                     22.35662     0.04523   22.40185   22.31139
log_std/mean                          -0.08930     0.00035   -0.08894   -0.08965
log_std/std                           0.00587      0.00004   0.00591    0.00582
log_std/max                           -0.07894     0.00029   -0.07865   -0.07922
log_std/min                           -0.10064     0.00030   -0.10034   -0.10093
log_probs/mean                        -2.71516     0.00596   -2.70920   -2.72112
log_probs/std                         0.27624      0.00567   0.28191    0.27057
log_probs/max                         -1.91877     0.05035   -1.86842   -1.96912
log_probs/min                         -4.94948     0.75996   -4.18952   -5.70945
mean/mean                             0.00099      0.00002   0.00101    0.00098
mean/std                              0.00281      0.00004   0.00285    0.00277
mean/max                              0.00704      0.00004   0.00707    0.00700
mean/min                              -0.00404     0.00008   -0.00396   -0.00411
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 81 50
freq 22
sample: [8, 7, 6, 3, 9, 4, 1, 5, 2, 0]
replay_buffer._size: [12450 12450 12450 12450 12450 12450 12450 12450 12450 12450]
train_time 0.1387004852294922
eval time 0.002515077590942383
snapshot at best
2023-08-22 20:45:38,857 MainThread INFO: EPOCH:81
2023-08-22 20:45:38,857 MainThread INFO: Time Consumed:0.674048900604248s
2023-08-22 20:45:38,857 MainThread INFO: Total Frames:123000s
 41%|████      | 82/200 [01:02<01:30,  1.30it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1266.41005
Train_Epoch_Reward                    16736.70521
Running_Training_Average_Rewards      1388.60248
Explore_Time                          0.00265
Train___Time                          0.13870
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.57941
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.40792
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.33157
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.13902
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28292
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.16888
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.34594
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12970.35995
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.64559
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.00948
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.64223      0.31202   7.95426     7.33021
alpha_0                               0.95209      0.00014   0.95224     0.95195
alpha_1                               0.95203      0.00014   0.95217     0.95188
alpha_2                               0.95206      0.00014   0.95221     0.95192
alpha_3                               0.95205      0.00014   0.95219     0.95191
alpha_4                               0.95207      0.00014   0.95221     0.95192
alpha_5                               0.95209      0.00014   0.95223     0.95195
alpha_6                               0.95207      0.00014   0.95221     0.95193
alpha_7                               0.95206      0.00014   0.95221     0.95192
alpha_8                               0.95206      0.00014   0.95220     0.95191
alpha_9                               0.95207      0.00014   0.95222     0.95193
Alpha_loss                            -0.32863     0.00111   -0.32752    -0.32975
Training/policy_loss                  -2.73168     0.00238   -2.72930    -2.73406
Training/qf1_loss                     1008.94339   27.29611  1036.23950  981.64728
Training/qf2_loss                     1008.71759   27.26459  1035.98218  981.45300
Training/pf_norm                      0.16011      0.00592   0.16603     0.15419
Training/qf1_norm                     23.29727     0.72839   24.02566    22.56887
Training/qf2_norm                     24.04474     0.84999   24.89473    23.19475
log_std/mean                          -0.09069     0.00035   -0.09033    -0.09104
log_std/std                           0.00604      0.00005   0.00609     0.00599
log_std/max                           -0.08010     0.00030   -0.07980    -0.08040
log_std/min                           -0.10205     0.00060   -0.10146    -0.10265
log_probs/mean                        -2.73129     0.00209   -2.72920    -2.73339
log_probs/std                         0.27344      0.01465   0.28809     0.25879
log_probs/max                         -1.92337     0.00275   -1.92062    -1.92612
log_probs/min                         -4.07697     0.41393   -3.66304    -4.49091
mean/mean                             0.00106      0.00001   0.00107     0.00105
mean/std                              0.00288      0.00000   0.00288     0.00288
mean/max                              0.00719      0.00003   0.00722     0.00716
mean/min                              -0.00415     0.00001   -0.00414    -0.00416
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 82 50
freq 22
sample: [3, 4, 2, 8, 9, 1, 0, 6, 7, 5]
replay_buffer._size: [12600 12600 12600 12600 12600 12600 12600 12600 12600 12600]
train_time 0.18796467781066895
eval time 0.4331667423248291
snapshot at best
2023-08-22 20:45:40,144 MainThread INFO: EPOCH:82
2023-08-22 20:45:40,145 MainThread INFO: Time Consumed:1.1972301006317139s
2023-08-22 20:45:40,145 MainThread INFO: Total Frames:124500s
 42%|████▏     | 83/200 [01:03<01:48,  1.08it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1271.56254
Train_Epoch_Reward                    2947.23470
Running_Training_Average_Rewards      1000.65432
Explore_Time                          0.00299
Train___Time                          0.18796
Eval____Time                          0.43317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.80614
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.42116
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.35426
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.13301
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31590
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21038
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.38734
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13009.91834
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.65692
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.98825
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.86283      0.13273   6.99556    6.73010
alpha_0                               0.95152      0.00014   0.95166    0.95138
alpha_1                               0.95145      0.00014   0.95160    0.95131
alpha_2                               0.95149      0.00014   0.95163    0.95135
alpha_3                               0.95148      0.00014   0.95162    0.95133
alpha_4                               0.95149      0.00014   0.95164    0.95135
alpha_5                               0.95152      0.00014   0.95166    0.95137
alpha_6                               0.95150      0.00014   0.95164    0.95136
alpha_7                               0.95149      0.00014   0.95163    0.95135
alpha_8                               0.95148      0.00014   0.95163    0.95134
alpha_9                               0.95150      0.00014   0.95164    0.95136
Alpha_loss                            -0.33316     0.00094   -0.33223   -0.33410
Training/policy_loss                  -2.74242     0.00114   -2.74128   -2.74356
Training/qf1_loss                     896.08081    42.01282  938.09363  854.06799
Training/qf2_loss                     895.87305    42.01025  937.88330  853.86279
Training/pf_norm                      0.12573      0.02160   0.14733    0.10412
Training/qf1_norm                     21.57859     0.31252   21.89111   21.26607
Training/qf2_norm                     22.24634     0.32062   22.56697   21.92572
log_std/mean                          -0.09208     0.00034   -0.09174   -0.09242
log_std/std                           0.00622      0.00005   0.00627    0.00617
log_std/max                           -0.08126     0.00030   -0.08096   -0.08157
log_std/min                           -0.10398     0.00072   -0.10327   -0.10470
log_probs/mean                        -2.74107     0.00160   -2.73947   -2.74266
log_probs/std                         0.27130      0.00655   0.27785    0.26475
log_probs/max                         -1.95673     0.03628   -1.92045   -1.99300
log_probs/min                         -4.26745     0.16874   -4.09871   -4.43619
mean/mean                             0.00102      0.00003   0.00105    0.00100
mean/std                              0.00299      0.00005   0.00304    0.00293
mean/max                              0.00744      0.00009   0.00753    0.00735
mean/min                              -0.00427     0.00007   -0.00420   -0.00433
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 83 50
freq 22
sample: [0, 5, 9, 4, 6, 7, 3, 1, 2, 8]
replay_buffer._size: [12750 12750 12750 12750 12750 12750 12750 12750 12750 12750]
train_time 0.1264493465423584
eval time 0.002308368682861328
snapshot at best
2023-08-22 20:45:40,882 MainThread INFO: EPOCH:83
2023-08-22 20:45:40,882 MainThread INFO: Time Consumed:0.6343111991882324s
2023-08-22 20:45:40,882 MainThread INFO: Total Frames:126000s
 42%|████▏     | 84/200 [01:04<01:41,  1.15it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1275.95599
Train_Epoch_Reward                    18882.66662
Running_Training_Average_Rewards      1285.55355
Explore_Time                          0.00271
Train___Time                          0.12645
Eval____Time                          0.00231
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.30289
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.41970
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.37483
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.12089
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33338
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23854
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.41526
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13042.41790
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.65114
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.97571
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.16230      0.14089   7.30319    7.02141
alpha_0                               0.95095      0.00014   0.95109    0.95081
alpha_1                               0.95088      0.00014   0.95102    0.95074
alpha_2                               0.95092      0.00014   0.95106    0.95077
alpha_3                               0.95090      0.00014   0.95105    0.95076
alpha_4                               0.95092      0.00014   0.95106    0.95078
alpha_5                               0.95094      0.00014   0.95109    0.95080
alpha_6                               0.95093      0.00014   0.95107    0.95078
alpha_7                               0.95092      0.00014   0.95106    0.95078
alpha_8                               0.95091      0.00014   0.95105    0.95077
alpha_9                               0.95093      0.00014   0.95107    0.95079
Alpha_loss                            -0.33647     0.00115   -0.33532   -0.33762
Training/policy_loss                  -2.72957     0.00306   -2.72650   -2.73263
Training/qf1_loss                     893.08017    52.67685  945.75702  840.40332
Training/qf2_loss                     892.82462    52.65109  945.47571  840.17352
Training/pf_norm                      0.14218      0.01005   0.15223    0.13214
Training/qf1_norm                     22.31318     0.27211   22.58528   22.04107
Training/qf2_norm                     23.16098     0.37129   23.53227   22.78969
log_std/mean                          -0.09340     0.00033   -0.09307   -0.09373
log_std/std                           0.00640      0.00005   0.00644    0.00635
log_std/max                           -0.08233     0.00026   -0.08207   -0.08260
log_std/min                           -0.10538     0.00040   -0.10498   -0.10578
log_probs/mean                        -2.72616     0.00277   -2.72339   -2.72892
log_probs/std                         0.26777      0.01161   0.27938    0.25617
log_probs/max                         -1.95410     0.05115   -1.90296   -2.00525
log_probs/min                         -4.52847     0.22949   -4.29898   -4.75796
mean/mean                             0.00100      0.00001   0.00101    0.00099
mean/std                              0.00320      0.00005   0.00325    0.00316
mean/max                              0.00792      0.00010   0.00802    0.00782
mean/min                              -0.00444     0.00004   -0.00440   -0.00449
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 84 50
freq 22
sample: [9, 6, 1, 8, 5, 7, 3, 4, 2, 0]
replay_buffer._size: [12900 12900 12900 12900 12900 12900 12900 12900 12900 12900]
train_time 0.1410682201385498
eval time 0.0037806034088134766
snapshot at best
2023-08-22 20:45:41,642 MainThread INFO: EPOCH:84
2023-08-22 20:45:41,642 MainThread INFO: Time Consumed:0.6509623527526855s
2023-08-22 20:45:41,642 MainThread INFO: Total Frames:127500s
 42%|████▎     | 85/200 [01:05<01:36,  1.20it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1280.88135
Train_Epoch_Reward                    17862.37853
Running_Training_Average_Rewards      1323.07599
Explore_Time                          0.00262
Train___Time                          0.14107
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.84149
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.40022
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.41880
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.07279
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.32949
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24331
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.41910
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13113.48705
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.62951
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.92225
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.15196      0.42653   7.57849     6.72542
alpha_0                               0.95038      0.00014   0.95052     0.95023
alpha_1                               0.95031      0.00014   0.95045     0.95017
alpha_2                               0.95034      0.00014   0.95049     0.95020
alpha_3                               0.95033      0.00014   0.95047     0.95019
alpha_4                               0.95035      0.00014   0.95049     0.95020
alpha_5                               0.95037      0.00014   0.95051     0.95023
alpha_6                               0.95035      0.00014   0.95050     0.95021
alpha_7                               0.95035      0.00014   0.95049     0.95021
alpha_8                               0.95034      0.00014   0.95048     0.95020
alpha_9                               0.95036      0.00014   0.95050     0.95021
Alpha_loss                            -0.34046     0.00133   -0.33913    -0.34178
Training/policy_loss                  -2.73007     0.00608   -2.72399    -2.73614
Training/qf1_loss                     1050.98901   67.91858  1118.90759  983.07043
Training/qf2_loss                     1050.73969   67.91437  1118.65405  982.82532
Training/pf_norm                      0.21869      0.02091   0.23960     0.19778
Training/qf1_norm                     22.39727     0.99259   23.38986    21.40468
Training/qf2_norm                     23.20529     1.01152   24.21680    22.19377
log_std/mean                          -0.09472     0.00035   -0.09437    -0.09507
log_std/std                           0.00657      0.00005   0.00662     0.00652
log_std/max                           -0.08342     0.00028   -0.08314    -0.08369
log_std/min                           -0.10735     0.00039   -0.10696    -0.10775
log_probs/mean                        -2.72492     0.00620   -2.71872    -2.73112
log_probs/std                         0.27102      0.00022   0.27124     0.27080
log_probs/max                         -1.96467     0.03783   -1.92684    -2.00250
log_probs/min                         -4.36141     0.06216   -4.29926    -4.42357
mean/mean                             0.00093      0.00002   0.00096     0.00091
mean/std                              0.00331      0.00000   0.00331     0.00331
mean/max                              0.00817      0.00004   0.00820     0.00813
mean/min                              -0.00447     0.00004   -0.00444    -0.00451
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 85 50
freq 22
sample: [2, 0, 6, 1, 3, 5, 7, 9, 8, 4]
replay_buffer._size: [13050 13050 13050 13050 13050 13050 13050 13050 13050 13050]
train_time 0.1688365936279297
eval time 0.0024938583374023438
snapshot at best
2023-08-22 20:45:42,455 MainThread INFO: EPOCH:85
2023-08-22 20:45:43,227 MainThread INFO: Time Consumed:0.7176008224487305s
2023-08-22 20:45:43,227 MainThread INFO: Total Frames:129000s
 43%|████▎     | 86/200 [01:06<02:00,  1.06s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1285.89847
Train_Epoch_Reward                    13339.18680
Running_Training_Average_Rewards      1669.47440
Explore_Time                          0.00247
Train___Time                          0.16884
Eval____Time                          0.00249
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.98889
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.39554
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.44907
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.04101
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.32602
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24735
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.42307
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13164.53494
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61629
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.88920
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.75877      0.00328    7.76204     7.75549
alpha_0                               0.94980      0.00014    0.94995     0.94966
alpha_1                               0.94974      0.00014    0.94988     0.94959
alpha_2                               0.94977      0.00014    0.94991     0.94963
alpha_3                               0.94976      0.00014    0.94990     0.94962
alpha_4                               0.94978      0.00014    0.94992     0.94963
alpha_5                               0.94980      0.00014    0.94994     0.94966
alpha_6                               0.94978      0.00014    0.94993     0.94964
alpha_7                               0.94978      0.00014    0.94992     0.94963
alpha_8                               0.94977      0.00014    0.94991     0.94962
alpha_9                               0.94979      0.00014    0.94993     0.94964
Alpha_loss                            -0.34468     0.00120    -0.34348    -0.34588
Training/policy_loss                  -2.73476     0.00387    -2.73090    -2.73863
Training/qf1_loss                     1091.59067   129.10501  1220.69568  962.48566
Training/qf2_loss                     1091.30856   129.10757  1220.41614  962.20099
Training/pf_norm                      0.16894      0.00551    0.17444     0.16343
Training/qf1_norm                     23.89648     0.03238    23.92886    23.86410
Training/qf2_norm                     24.82116     0.03878    24.85994    24.78237
log_std/mean                          -0.09609     0.00036    -0.09574    -0.09645
log_std/std                           0.00676      0.00005    0.00681     0.00671
log_std/max                           -0.08462     0.00025    -0.08437    -0.08487
log_std/min                           -0.10860     0.00028    -0.10831    -0.10888
log_probs/mean                        -2.72834     0.00359    -2.72475    -2.73192
log_probs/std                         0.27184      0.00347    0.27530     0.26837
log_probs/max                         -1.98393     0.01404    -1.96989    -1.99797
log_probs/min                         -4.34022     0.18948    -4.15074    -4.52971
mean/mean                             0.00090      0.00000    0.00090     0.00090
mean/std                              0.00332      0.00000    0.00333     0.00332
mean/max                              0.00821      0.00002    0.00823     0.00820
mean/min                              -0.00449     0.00000    -0.00449    -0.00450
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 86 50
freq 22
sample: [6, 3, 4, 1, 8, 7, 2, 9, 0, 5]
replay_buffer._size: [13200 13200 13200 13200 13200 13200 13200 13200 13200 13200]
train_time 0.14183354377746582
eval time 0.0025360584259033203
snapshot at best
2023-08-22 20:45:43,983 MainThread INFO: EPOCH:86
2023-08-22 20:45:43,984 MainThread INFO: Time Consumed:0.6585979461669922s
2023-08-22 20:45:43,984 MainThread INFO: Total Frames:130500s
 44%|████▎     | 87/200 [01:07<01:49,  1.03it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1290.56652
Train_Epoch_Reward                    21150.61656
Running_Training_Average_Rewards      1745.07273
Explore_Time                          0.00259
Train___Time                          0.14183
Eval____Time                          0.00254
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.61314
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.40184
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46007
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.03330
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33294
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.25935
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.43458
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13176.66923
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61428
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89285
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.29062      0.36723   7.65785     6.92339
alpha_0                               0.94923      0.00014   0.94938     0.94909
alpha_1                               0.94917      0.00014   0.94931     0.94902
alpha_2                               0.94920      0.00014   0.94934     0.94906
alpha_3                               0.94919      0.00014   0.94933     0.94905
alpha_4                               0.94920      0.00014   0.94935     0.94906
alpha_5                               0.94923      0.00014   0.94937     0.94908
alpha_6                               0.94921      0.00014   0.94935     0.94907
alpha_7                               0.94921      0.00014   0.94935     0.94906
alpha_8                               0.94920      0.00014   0.94934     0.94905
alpha_9                               0.94922      0.00014   0.94936     0.94907
Alpha_loss                            -0.34892     0.00074   -0.34818    -0.34966
Training/policy_loss                  -2.73982     0.00473   -2.73509    -2.74455
Training/qf1_loss                     1005.86078   77.07904  1082.93982  928.78174
Training/qf2_loss                     1005.58813   77.07153  1082.65967  928.51660
Training/pf_norm                      0.14968      0.00052   0.15020     0.14917
Training/qf1_norm                     22.91000     0.85837   23.76837    22.05163
Training/qf2_norm                     23.79395     0.89143   24.68538    22.90252
log_std/mean                          -0.09751     0.00034   -0.09717    -0.09786
log_std/std                           0.00694      0.00004   0.00698     0.00691
log_std/max                           -0.08575     0.00028   -0.08547    -0.08602
log_std/min                           -0.11004     0.00041   -0.10963    -0.11045
log_probs/mean                        -2.73202     0.00528   -2.72674    -2.73730
log_probs/std                         0.25796      0.00241   0.26037     0.25556
log_probs/max                         -2.03437     0.03148   -2.00289    -2.06585
log_probs/min                         -5.22488     0.49498   -4.72990    -5.71986
mean/mean                             0.00091      0.00000   0.00092     0.00091
mean/std                              0.00330      0.00001   0.00331     0.00330
mean/max                              0.00816      0.00001   0.00817     0.00815
mean/min                              -0.00445     0.00001   -0.00444    -0.00445
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 87 50
freq 22
sample: [4, 6, 7, 8, 5, 0, 2, 3, 1, 9]
replay_buffer._size: [13350 13350 13350 13350 13350 13350 13350 13350 13350 13350]
train_time 0.13761544227600098
eval time 0.002592325210571289
2023-08-22 20:45:44,351 MainThread INFO: EPOCH:87
2023-08-22 20:45:44,351 MainThread INFO: Time Consumed:0.1435239315032959s
2023-08-22 20:45:44,351 MainThread INFO: Total Frames:132000s
 44%|████▍     | 88/200 [01:08<01:28,  1.26it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1292.25067
Train_Epoch_Reward                    12571.27240
Running_Training_Average_Rewards      1568.70253
Explore_Time                          0.00278
Train___Time                          0.13762
Eval____Time                          0.00259
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.46867
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.41778
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46543
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.04343
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36116
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.30035
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.47402
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13172.80279
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.62782
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.90946
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.79779      0.70483    8.50262     7.09296
alpha_0                               0.94866      0.00014    0.94881     0.94852
alpha_1                               0.94859      0.00014    0.94874     0.94845
alpha_2                               0.94863      0.00014    0.94877     0.94848
alpha_3                               0.94862      0.00014    0.94876     0.94847
alpha_4                               0.94863      0.00014    0.94878     0.94849
alpha_5                               0.94866      0.00014    0.94880     0.94851
alpha_6                               0.94864      0.00014    0.94878     0.94850
alpha_7                               0.94864      0.00014    0.94878     0.94849
alpha_8                               0.94863      0.00014    0.94877     0.94848
alpha_9                               0.94864      0.00014    0.94879     0.94850
Alpha_loss                            -0.35293     0.00163    -0.35130    -0.35455
Training/policy_loss                  -2.74076     0.01160    -2.72916    -2.75236
Training/qf1_loss                     1090.75897   258.60077  1349.35974  832.15820
Training/qf2_loss                     1090.43430   258.53958  1348.97388  831.89471
Training/pf_norm                      0.15125      0.02756    0.17881     0.12369
Training/qf1_norm                     24.15422     1.61697    25.77118    22.53725
Training/qf2_norm                     25.21993     1.85047    27.07040    23.36946
log_std/mean                          -0.09890     0.00035    -0.09855    -0.09925
log_std/std                           0.00711      0.00005    0.00716     0.00707
log_std/max                           -0.08681     0.00026    -0.08656    -0.08707
log_std/min                           -0.11196     0.00012    -0.11184    -0.11208
log_probs/mean                        -2.73115     0.01170    -2.71944    -2.74285
log_probs/std                         0.27547      0.00932    0.28480     0.26615
log_probs/max                         -1.96522     0.00652    -1.95870    -1.97173
log_probs/min                         -5.09884     0.50107    -4.59776    -5.59991
mean/mean                             0.00087      0.00002    0.00089     0.00085
mean/std                              0.00330      0.00002    0.00332     0.00328
mean/max                              0.00798      0.00009    0.00807     0.00790
mean/min                              -0.00456     0.00003    -0.00453    -0.00460
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 88 50
freq 22
sample: [5, 6, 4, 1, 8, 2, 7, 3, 0, 9]
replay_buffer._size: [13500 13500 13500 13500 13500 13500 13500 13500 13500 13500]
train_time 0.1541292667388916
eval time 0.0023796558380126953
2023-08-22 20:45:45,016 MainThread INFO: EPOCH:88
2023-08-22 20:45:45,016 MainThread INFO: Time Consumed:0.1600203514099121s
2023-08-22 20:45:45,017 MainThread INFO: Total Frames:133500s
 44%|████▍     | 89/200 [01:08<01:23,  1.33it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1292.53823
Train_Epoch_Reward                    10758.92135
Running_Training_Average_Rewards      1482.69368
Explore_Time                          0.00299
Train___Time                          0.15413
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.52631
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.44358
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47452
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.05675
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39619
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.34953
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.52119
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13175.12503
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.65257
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.91913
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.90476      0.59337    8.49813     7.31139
alpha_0                               0.94809      0.00014    0.94823     0.94795
alpha_1                               0.94802      0.00014    0.94817     0.94788
alpha_2                               0.94806      0.00014    0.94820     0.94791
alpha_3                               0.94805      0.00014    0.94819     0.94790
alpha_4                               0.94806      0.00014    0.94820     0.94792
alpha_5                               0.94809      0.00014    0.94823     0.94794
alpha_6                               0.94807      0.00014    0.94821     0.94793
alpha_7                               0.94806      0.00014    0.94821     0.94792
alpha_8                               0.94805      0.00014    0.94820     0.94791
alpha_9                               0.94807      0.00014    0.94822     0.94793
Alpha_loss                            -0.35688     0.00137    -0.35551    -0.35825
Training/policy_loss                  -2.74067     0.00700    -2.73367    -2.74766
Training/qf1_loss                     1117.66586   220.46048  1338.12634  897.20538
Training/qf2_loss                     1117.32233   220.40790  1337.73022  896.91443
Training/pf_norm                      0.14622      0.03390    0.18012     0.11232
Training/qf1_norm                     24.50715     1.37617    25.88332    23.13097
Training/qf2_norm                     25.63669     1.57263    27.20933    24.06406
log_std/mean                          -0.10029     0.00034    -0.09995    -0.10063
log_std/std                           0.00730      0.00004    0.00734     0.00727
log_std/max                           -0.08787     0.00024    -0.08764    -0.08811
log_std/min                           -0.11352     0.00017    -0.11334    -0.11369
log_probs/mean                        -2.72931     0.00669    -2.72262    -2.73600
log_probs/std                         0.25506      0.00415    0.25921     0.25090
log_probs/max                         -1.90842     0.00291    -1.90551    -1.91133
log_probs/min                         -4.54055     0.36378    -4.17677    -4.90434
mean/mean                             0.00083      0.00002    0.00085     0.00081
mean/std                              0.00331      0.00001    0.00332     0.00330
mean/max                              0.00775      0.00002    0.00777     0.00772
mean/min                              -0.00482     0.00003    -0.00479    -0.00485
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 89 50
freq 22
sample: [4, 7, 0, 6, 5, 8, 3, 1, 2, 9]
replay_buffer._size: [13650 13650 13650 13650 13650 13650 13650 13650 13650 13650]
train_time 0.12928175926208496
eval time 0.002440929412841797
2023-08-22 20:45:45,737 MainThread INFO: EPOCH:89
2023-08-22 20:45:45,737 MainThread INFO: Time Consumed:0.13525748252868652s
2023-08-22 20:45:45,737 MainThread INFO: Total Frames:135000s
 45%|████▌     | 90/200 [01:09<01:22,  1.34it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1291.42119
Train_Epoch_Reward                    17462.51192
Running_Training_Average_Rewards      1359.75686
Explore_Time                          0.00282
Train___Time                          0.12928
Eval____Time                          0.00244
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.81153
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.50434
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46045
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.09400
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42153
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.38267
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.55301
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13151.99040
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.70990
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.93709
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.96001      0.35343   8.31345     7.60658
alpha_0                               0.94752      0.00014   0.94766     0.94738
alpha_1                               0.94745      0.00014   0.94760     0.94731
alpha_2                               0.94749      0.00014   0.94763     0.94734
alpha_3                               0.94748      0.00014   0.94762     0.94733
alpha_4                               0.94749      0.00014   0.94763     0.94735
alpha_5                               0.94752      0.00014   0.94766     0.94737
alpha_6                               0.94750      0.00014   0.94764     0.94736
alpha_7                               0.94749      0.00014   0.94764     0.94735
alpha_8                               0.94748      0.00014   0.94763     0.94734
alpha_9                               0.94750      0.00014   0.94765     0.94736
Alpha_loss                            -0.36120     0.00105   -0.36015    -0.36225
Training/policy_loss                  -2.74737     0.00105   -2.74632    -2.74842
Training/qf1_loss                     1053.06946   75.27942  1128.34888  977.79004
Training/qf2_loss                     1052.73218   75.27405  1128.00623  977.45813
Training/pf_norm                      0.12241      0.00782   0.13023     0.11460
Training/qf1_norm                     24.80762     0.85597   25.66360    23.95165
Training/qf2_norm                     25.90148     0.86787   26.76935    25.03360
log_std/mean                          -0.10163     0.00033   -0.10130    -0.10196
log_std/std                           0.00750      0.00005   0.00754     0.00745
log_std/max                           -0.08888     0.00024   -0.08864    -0.08913
log_std/min                           -0.11541     0.00037   -0.11504    -0.11579
log_probs/mean                        -2.73439     0.00067   -2.73373    -2.73506
log_probs/std                         0.27073      0.00452   0.27525     0.26620
log_probs/max                         -1.98172     0.04307   -1.93866    -2.02479
log_probs/min                         -5.07206     0.28814   -4.78392    -5.36020
mean/mean                             0.00087      0.00001   0.00088     0.00086
mean/std                              0.00343      0.00003   0.00346     0.00339
mean/max                              0.00787      0.00004   0.00791     0.00783
mean/min                              -0.00504     0.00005   -0.00499    -0.00509
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 90 50
freq 22
sample: [5, 1, 9, 0, 2, 7, 3, 6, 8, 4]
replay_buffer._size: [13800 13800 13800 13800 13800 13800 13800 13800 13800 13800]
train_time 0.13095641136169434
eval time 0.0025124549865722656
snapshot at best
2023-08-22 20:45:46,955 MainThread INFO: EPOCH:90
2023-08-22 20:45:46,956 MainThread INFO: Time Consumed:0.6600103378295898s
2023-08-22 20:45:46,956 MainThread INFO: Total Frames:136500s
 46%|████▌     | 91/200 [01:10<01:35,  1.14it/s]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1291.74716
Train_Epoch_Reward                    27138.81039
Running_Training_Average_Rewards      1845.34146
Explore_Time                          0.00281
Train___Time                          0.13096
Eval____Time                          0.00251
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.41191
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.52157
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47857
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.08266
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43898
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.40773
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.58241
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13175.08641
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.73001
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.91903
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.79125      0.44291    8.23416     7.34834
alpha_0                               0.94695      0.00014    0.94709     0.94681
alpha_1                               0.94688      0.00014    0.94703     0.94674
alpha_2                               0.94692      0.00014    0.94706     0.94677
alpha_3                               0.94691      0.00014    0.94705     0.94676
alpha_4                               0.94692      0.00014    0.94706     0.94678
alpha_5                               0.94695      0.00014    0.94709     0.94680
alpha_6                               0.94693      0.00014    0.94707     0.94679
alpha_7                               0.94692      0.00014    0.94707     0.94678
alpha_8                               0.94691      0.00014    0.94706     0.94677
alpha_9                               0.94693      0.00014    0.94707     0.94679
Alpha_loss                            -0.36507     0.00096    -0.36411    -0.36603
Training/policy_loss                  -2.74608     0.00047    -2.74561    -2.74655
Training/qf1_loss                     1190.49939   188.68347  1379.18286  1001.81592
Training/qf2_loss                     1190.15497   188.66827  1378.82324  1001.48669
Training/pf_norm                      0.12709      0.02792    0.15501     0.09918
Training/qf1_norm                     24.48083     1.04224    25.52307    23.43860
Training/qf2_norm                     25.59618     1.10688    26.70307    24.48930
log_std/mean                          -0.10291     0.00032    -0.10259    -0.10323
log_std/std                           0.00767      0.00005    0.00772     0.00762
log_std/max                           -0.08982     0.00029    -0.08953    -0.09010
log_std/min                           -0.11615     0.00029    -0.11587    -0.11644
log_probs/mean                        -2.73100     0.00097    -2.73003    -2.73197
log_probs/std                         0.26422      0.00211    0.26633     0.26211
log_probs/max                         -1.97742     0.04312    -1.93430    -2.02055
log_probs/min                         -5.01472     0.14647    -4.86825    -5.16119
mean/mean                             0.00090      0.00001    0.00091     0.00090
mean/std                              0.00354      0.00000    0.00354     0.00354
mean/max                              0.00796      0.00004    0.00800     0.00791
mean/min                              -0.00520     0.00000    -0.00520    -0.00521
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 91 50
freq 22
sample: [3, 5, 6, 4, 1, 8, 2, 9, 7, 0]
replay_buffer._size: [13950 13950 13950 13950 13950 13950 13950 13950 13950 13950]
train_time 0.13561248779296875
eval time 0.002760648727416992
snapshot at best
2023-08-22 20:45:47,684 MainThread INFO: EPOCH:91
2023-08-22 20:45:47,684 MainThread INFO: Time Consumed:0.6443333625793457s
2023-08-22 20:45:47,684 MainThread INFO: Total Frames:138000s
 46%|████▌     | 92/200 [01:11<01:30,  1.19it/s]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1292.88262
Train_Epoch_Reward                    2611.62308
Running_Training_Average_Rewards      1573.76485
Explore_Time                          0.00253
Train___Time                          0.13561
Eval____Time                          0.00276
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.13225
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.53008
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.51044
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.06658
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46421
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.44052
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.61719
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13211.24174
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.73977
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89148
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.70515      0.34308    8.04823     7.36207
alpha_0                               0.94638      0.00014    0.94652     0.94624
alpha_1                               0.94631      0.00014    0.94646     0.94617
alpha_2                               0.94635      0.00014    0.94649     0.94620
alpha_3                               0.94634      0.00014    0.94648     0.94620
alpha_4                               0.94635      0.00014    0.94649     0.94621
alpha_5                               0.94638      0.00014    0.94652     0.94623
alpha_6                               0.94636      0.00014    0.94650     0.94622
alpha_7                               0.94635      0.00014    0.94650     0.94621
alpha_8                               0.94634      0.00014    0.94649     0.94620
alpha_9                               0.94636      0.00014    0.94651     0.94622
Alpha_loss                            -0.36888     0.00111    -0.36777    -0.36999
Training/policy_loss                  -2.74394     0.00201    -2.74193    -2.74594
Training/qf1_loss                     1085.28534   131.97223  1217.25757  953.31311
Training/qf2_loss                     1084.89206   131.94901  1216.84106  952.94305
Training/pf_norm                      0.13923      0.01786    0.15709     0.12136
Training/qf1_norm                     24.26477     0.78557    25.05034    23.47920
Training/qf2_norm                     25.55176     0.88143    26.43319    24.67033
log_std/mean                          -0.10418     0.00032    -0.10385    -0.10450
log_std/std                           0.00784      0.00005    0.00789     0.00779
log_std/max                           -0.09070     0.00020    -0.09050    -0.09091
log_std/min                           -0.11764     0.00048    -0.11716    -0.11813
log_probs/mean                        -2.72660     0.00176    -2.72484    -2.72836
log_probs/std                         0.25334      0.00533    0.25867     0.24801
log_probs/max                         -1.99313     0.00262    -1.99051    -1.99575
log_probs/min                         -4.28849     0.01549    -4.27300    -4.30397
mean/mean                             0.00091      0.00000    0.00091     0.00091
mean/std                              0.00351      0.00002    0.00353     0.00349
mean/max                              0.00779      0.00003    0.00782     0.00776
mean/min                              -0.00521     0.00002    -0.00519    -0.00523
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 92 50
freq 22
sample: [2, 1, 5, 0, 7, 6, 3, 4, 9, 8]
replay_buffer._size: [14100 14100 14100 14100 14100 14100 14100 14100 14100 14100]
train_time 0.1384296417236328
eval time 0.0031845569610595703
2023-08-22 20:45:47,954 MainThread INFO: EPOCH:92
2023-08-22 20:45:47,955 MainThread INFO: Time Consumed:0.14551353454589844s
2023-08-22 20:45:47,955 MainThread INFO: Total Frames:139500s
 46%|████▋     | 93/200 [01:11<01:11,  1.49it/s]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1294.32812
Train_Epoch_Reward                    11633.81453
Running_Training_Average_Rewards      1379.47493
Explore_Time                          0.00320
Train___Time                          0.13843
Eval____Time                          0.00318
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.84562
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.55405
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.50980
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.08591
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.48836
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.47759
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.65888
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13192.76825
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.75991
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.90739
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.11567      0.14569   8.26136     7.96998
alpha_0                               0.94581      0.00014   0.94596     0.94567
alpha_1                               0.94575      0.00014   0.94589     0.94560
alpha_2                               0.94578      0.00014   0.94592     0.94563
alpha_3                               0.94577      0.00014   0.94591     0.94563
alpha_4                               0.94578      0.00014   0.94592     0.94564
alpha_5                               0.94581      0.00014   0.94595     0.94566
alpha_6                               0.94579      0.00014   0.94593     0.94565
alpha_7                               0.94578      0.00014   0.94593     0.94564
alpha_8                               0.94577      0.00014   0.94592     0.94563
alpha_9                               0.94579      0.00014   0.94594     0.94565
Alpha_loss                            -0.37300     0.00087   -0.37213    -0.37388
Training/policy_loss                  -2.74718     0.00150   -2.74569    -2.74868
Training/qf1_loss                     1208.94434   33.13794  1242.08228  1175.80640
Training/qf2_loss                     1208.55371   33.08752  1241.64124  1175.46619
Training/pf_norm                      0.16137      0.01850   0.17987     0.14287
Training/qf1_norm                     25.48668     0.33333   25.82001    25.15335
Training/qf2_norm                     26.75777     0.52256   27.28033    26.23521
log_std/mean                          -0.10545     0.00032   -0.10513    -0.10578
log_std/std                           0.00803      0.00004   0.00807     0.00799
log_std/max                           -0.09162     0.00024   -0.09138    -0.09187
log_std/min                           -0.11945     0.00003   -0.11941    -0.11948
log_probs/mean                        -2.72789     0.00250   -2.72539    -2.73038
log_probs/std                         0.25035      0.00341   0.25376     0.24694
log_probs/max                         -2.08294     0.02257   -2.06036    -2.10551
log_probs/min                         -4.35018     0.14749   -4.20269    -4.49768
mean/mean                             0.00091      0.00000   0.00091     0.00091
mean/std                              0.00350      0.00001   0.00351     0.00349
mean/max                              0.00762      0.00004   0.00766     0.00758
mean/min                              -0.00527     0.00001   -0.00526    -0.00527
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 93 50
freq 22
sample: [6, 4, 3, 8, 2, 7, 1, 9, 0, 5]
replay_buffer._size: [14250 14250 14250 14250 14250 14250 14250 14250 14250 14250]
train_time 0.15622496604919434
eval time 0.0029234886169433594
2023-08-22 20:45:48,779 MainThread INFO: EPOCH:93
2023-08-22 20:45:48,779 MainThread INFO: Time Consumed:0.16244053840637207s
2023-08-22 20:45:48,779 MainThread INFO: Total Frames:141000s
 47%|████▋     | 94/200 [01:12<01:15,  1.40it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1294.30816
Train_Epoch_Reward                    10429.97110
Running_Training_Average_Rewards      822.51362
Explore_Time                          0.00241
Train___Time                          0.15622
Eval____Time                          0.00292
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.73437
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.58500
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.50126
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.10989
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50595
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.51552
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.70561
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13176.28253
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.78138
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.92861
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.75995      0.44664   8.20659     7.31331
alpha_0                               0.94524      0.00014   0.94539     0.94510
alpha_1                               0.94518      0.00014   0.94532     0.94503
alpha_2                               0.94521      0.00014   0.94535     0.94507
alpha_3                               0.94520      0.00014   0.94534     0.94506
alpha_4                               0.94521      0.00014   0.94535     0.94507
alpha_5                               0.94524      0.00014   0.94538     0.94510
alpha_6                               0.94522      0.00014   0.94536     0.94508
alpha_7                               0.94522      0.00014   0.94536     0.94507
alpha_8                               0.94521      0.00014   0.94535     0.94506
alpha_9                               0.94522      0.00014   0.94537     0.94508
Alpha_loss                            -0.37743     0.00080   -0.37663    -0.37822
Training/policy_loss                  -2.75562     0.00292   -2.75271    -2.75854
Training/qf1_loss                     1033.72107   69.47107  1103.19214  964.25000
Training/qf2_loss                     1033.28113   69.43823  1102.71936  963.84290
Training/pf_norm                      0.13028      0.00581   0.13609     0.12447
Training/qf1_norm                     24.58330     1.10975   25.69305    23.47355
Training/qf2_norm                     26.00782     1.22588   27.23370    24.78194
log_std/mean                          -0.10673     0.00032   -0.10641    -0.10704
log_std/std                           0.00818      0.00005   0.00823     0.00814
log_std/max                           -0.09262     0.00030   -0.09232    -0.09292
log_std/min                           -0.12047     0.00023   -0.12025    -0.12070
log_probs/mean                        -2.73461     0.00386   -2.73075    -2.73847
log_probs/std                         0.25926      0.00018   0.25944     0.25909
log_probs/max                         -2.05472     0.00777   -2.04695    -2.06249
log_probs/min                         -4.99127     0.00309   -4.98819    -4.99436
mean/mean                             0.00098      0.00003   0.00100     0.00095
mean/std                              0.00337      0.00004   0.00341     0.00333
mean/max                              0.00732      0.00007   0.00739     0.00725
mean/min                              -0.00505     0.00008   -0.00497    -0.00513
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 94 50
freq 22
sample: [8, 7, 4, 3, 1, 5, 0, 6, 2, 9]
replay_buffer._size: [14400 14400 14400 14400 14400 14400 14400 14400 14400 14400]
train_time 0.12909698486328125
eval time 0.002335786819458008
2023-08-22 20:45:49,500 MainThread INFO: EPOCH:94
2023-08-22 20:45:49,500 MainThread INFO: Time Consumed:0.13452863693237305s
2023-08-22 20:45:49,500 MainThread INFO: Total Frames:142500s
 48%|████▊     | 95/200 [01:13<01:16,  1.38it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1291.92373
Train_Epoch_Reward                    17973.29413
Running_Training_Average_Rewards      1334.56933
Explore_Time                          0.00257
Train___Time                          0.12910
Eval____Time                          0.00234
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.16949
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.60167
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.48829
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.13862
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.52493
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.55299
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.75135
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13138.30680
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.79677
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.96655
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           7.16188      0.05774  7.21963    7.10414
alpha_0                               0.94468      0.00014  0.94482    0.94453
alpha_1                               0.94461      0.00014  0.94475    0.94446
alpha_2                               0.94464      0.00014  0.94478    0.94450
alpha_3                               0.94463      0.00014  0.94477    0.94449
alpha_4                               0.94464      0.00014  0.94478    0.94450
alpha_5                               0.94467      0.00014  0.94481    0.94453
alpha_6                               0.94465      0.00014  0.94479    0.94451
alpha_7                               0.94465      0.00014  0.94479    0.94450
alpha_8                               0.94464      0.00014  0.94478    0.94449
alpha_9                               0.94466      0.00014  0.94480    0.94451
Alpha_loss                            -0.38132     0.00064  -0.38068   -0.38196
Training/policy_loss                  -2.75508     0.00612  -2.74896   -2.76121
Training/qf1_loss                     908.39703    1.07184  909.46887  907.32520
Training/qf2_loss                     907.97687    1.00586  908.98273  906.97101
Training/pf_norm                      0.12067      0.01809  0.13876    0.10258
Training/qf1_norm                     23.28729     0.05498  23.34227   23.23230
Training/qf2_norm                     24.64351     0.29561  24.93912   24.34789
log_std/mean                          -0.10795     0.00030  -0.10765   -0.10824
log_std/std                           0.00833      0.00003  0.00836    0.00830
log_std/max                           -0.09366     0.00028  -0.09338   -0.09395
log_std/min                           -0.12180     0.00028  -0.12152   -0.12208
log_probs/mean                        -2.73179     0.00665  -2.72514   -2.73844
log_probs/std                         0.25785      0.00911  0.26695    0.24874
log_probs/max                         -2.04620     0.00469  -2.04151   -2.05089
log_probs/min                         -4.86235     0.73888  -4.12348   -5.60123
mean/mean                             0.00101      0.00000  0.00101    0.00100
mean/std                              0.00322      0.00003  0.00326    0.00319
mean/max                              0.00707      0.00008  0.00715    0.00698
mean/min                              -0.00478     0.00007  -0.00472   -0.00485
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 95 50
freq 22
sample: [3, 5, 7, 1, 8, 9, 6, 0, 4, 2]
replay_buffer._size: [14550 14550 14550 14550 14550 14550 14550 14550 14550 14550]
train_time 0.12902474403381348
eval time 0.0024132728576660156
2023-08-22 20:45:50,276 MainThread INFO: EPOCH:95
2023-08-22 20:45:50,276 MainThread INFO: Time Consumed:0.13466215133666992s
2023-08-22 20:45:50,276 MainThread INFO: Total Frames:144000s
 48%|████▊     | 96/200 [01:13<01:16,  1.36it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1287.90509
Train_Epoch_Reward                    16487.80657
Running_Training_Average_Rewards      1496.36906
Explore_Time                          0.00260
Train___Time                          0.12902
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.39798
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.61970
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46032
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18429
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.54938
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.58818
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.79142
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13076.35442
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.81681
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.02480
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.39891      0.21799   7.61690     7.18092
alpha_0                               0.94411      0.00014   0.94425     0.94397
alpha_1                               0.94404      0.00014   0.94418     0.94390
alpha_2                               0.94407      0.00014   0.94421     0.94393
alpha_3                               0.94406      0.00014   0.94421     0.94392
alpha_4                               0.94407      0.00014   0.94421     0.94393
alpha_5                               0.94410      0.00014   0.94424     0.94396
alpha_6                               0.94408      0.00014   0.94422     0.94394
alpha_7                               0.94408      0.00014   0.94422     0.94394
alpha_8                               0.94407      0.00014   0.94421     0.94393
alpha_9                               0.94409      0.00014   0.94423     0.94395
Alpha_loss                            -0.38510     0.00197   -0.38313    -0.38707
Training/policy_loss                  -2.75273     0.01658   -2.73616    -2.76931
Training/qf1_loss                     1012.68494   51.99060  1064.67554  960.69434
Training/qf2_loss                     1012.25708   52.01440  1064.27148  960.24268
Training/pf_norm                      0.13249      0.04291   0.17540     0.08958
Training/qf1_norm                     24.00151     0.62132   24.62283    23.38018
Training/qf2_norm                     25.38238     0.52977   25.91215    24.85261
log_std/mean                          -0.10916     0.00031   -0.10884    -0.10947
log_std/std                           0.00847      0.00003   0.00850     0.00844
log_std/max                           -0.09469     0.00026   -0.09443    -0.09496
log_std/min                           -0.12344     0.00047   -0.12297    -0.12392
log_probs/mean                        -2.72696     0.01672   -2.71024    -2.74367
log_probs/std                         0.24930      0.00249   0.25179     0.24681
log_probs/max                         -1.99436     0.05750   -1.93686    -2.05186
log_probs/min                         -4.27014     0.12548   -4.14466    -4.39563
mean/mean                             0.00102      0.00001   0.00104     0.00101
mean/std                              0.00306      0.00004   0.00310     0.00303
mean/max                              0.00733      0.00004   0.00736     0.00729
mean/min                              -0.00445     0.00009   -0.00436    -0.00454
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 96 50
freq 22
sample: [3, 2, 4, 1, 8, 0, 6, 5, 7, 9]
replay_buffer._size: [14700 14700 14700 14700 14700 14700 14700 14700 14700 14700]
train_time 0.1257014274597168
eval time 0.0021369457244873047
2023-08-22 20:45:51,127 MainThread INFO: EPOCH:96
2023-08-22 20:45:51,127 MainThread INFO: Time Consumed:0.13082075119018555s
2023-08-22 20:45:51,127 MainThread INFO: Total Frames:145500s
 48%|████▊     | 97/200 [01:14<01:19,  1.29it/s]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1281.77920
Train_Epoch_Reward                    4570.36207
Running_Training_Average_Rewards      1301.04876
Explore_Time                          0.00247
Train___Time                          0.12570
Eval____Time                          0.00214
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.77727
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.64045
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.42492
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.24588
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.57711
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.62572
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83354
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12991.20880
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.84452
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.10116
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.66173      0.04528  6.70701    6.61645
alpha_0                               0.94354      0.00014  0.94368    0.94340
alpha_1                               0.94347      0.00014  0.94361    0.94333
alpha_2                               0.94350      0.00014  0.94364    0.94336
alpha_3                               0.94350      0.00014  0.94364    0.94335
alpha_4                               0.94350      0.00014  0.94365    0.94336
alpha_5                               0.94353      0.00014  0.94367    0.94339
alpha_6                               0.94351      0.00014  0.94365    0.94337
alpha_7                               0.94351      0.00014  0.94365    0.94337
alpha_8                               0.94350      0.00014  0.94364    0.94336
alpha_9                               0.94352      0.00014  0.94366    0.94338
Alpha_loss                            -0.38967     0.00099  -0.38868   -0.39066
Training/policy_loss                  -2.76386     0.00010  -2.76376   -2.76396
Training/qf1_loss                     800.77060    5.93582  806.70642  794.83478
Training/qf2_loss                     800.39102    5.89743  806.28845  794.49359
Training/pf_norm                      0.12180      0.03090  0.15270    0.09090
Training/qf1_norm                     22.35705     0.21309  22.57015   22.14396
Training/qf2_norm                     23.54289     0.06694  23.60983   23.47595
log_std/mean                          -0.11041     0.00031  -0.11010   -0.11072
log_std/std                           0.00862      0.00004  0.00865    0.00858
log_std/max                           -0.09575     0.00028  -0.09547   -0.09603
log_std/min                           -0.12439     0.00033  -0.12407   -0.12472
log_probs/mean                        -2.73602     0.00046  -2.73556   -2.73647
log_probs/std                         0.25960      0.00734  0.26694    0.25226
log_probs/max                         -2.00010     0.01472  -1.98538   -2.01482
log_probs/min                         -4.57659     0.49530  -4.08129   -5.07189
mean/mean                             0.00105      0.00000  0.00105    0.00105
mean/std                              0.00290      0.00005  0.00295    0.00285
mean/max                              0.00743      0.00001  0.00744    0.00743
mean/min                              -0.00404     0.00011  -0.00393   -0.00415
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 97 50
freq 22
sample: [0, 5, 6, 4, 1, 2, 7, 8, 3, 9]
replay_buffer._size: [14850 14850 14850 14850 14850 14850 14850 14850 14850 14850]
train_time 0.12399744987487793
eval time 0.0025320053100585938
2023-08-22 20:45:51,894 MainThread INFO: EPOCH:97
2023-08-22 20:45:51,895 MainThread INFO: Time Consumed:0.12950873374938965s
2023-08-22 20:45:51,895 MainThread INFO: Total Frames:147000s
 49%|████▉     | 98/200 [01:15<01:18,  1.30it/s]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1275.04775
Train_Epoch_Reward                    5016.00407
Running_Training_Average_Rewards      869.13909
Explore_Time                          0.00220
Train___Time                          0.12400
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.65534
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.62332
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40459
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.27050
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.57909
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.63627
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.85030
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12938.38231
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.83374
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15654
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.26538      0.25741   7.52278    7.00797
alpha_0                               0.94297      0.00014   0.94312    0.94283
alpha_1                               0.94290      0.00014   0.94304    0.94276
alpha_2                               0.94294      0.00014   0.94308    0.94279
alpha_3                               0.94293      0.00014   0.94307    0.94279
alpha_4                               0.94293      0.00014   0.94308    0.94279
alpha_5                               0.94296      0.00014   0.94311    0.94282
alpha_6                               0.94294      0.00014   0.94309    0.94280
alpha_7                               0.94294      0.00014   0.94309    0.94280
alpha_8                               0.94293      0.00014   0.94308    0.94279
alpha_9                               0.94295      0.00014   0.94309    0.94281
Alpha_loss                            -0.39357     0.00113   -0.39244   -0.39471
Training/policy_loss                  -2.76356     0.00248   -2.76108   -2.76604
Training/qf1_loss                     872.50696    33.29785  905.80481  839.20911
Training/qf2_loss                     872.06918    33.30875  905.37793  838.76044
Training/pf_norm                      0.12496      0.00563   0.13060    0.11933
Training/qf1_norm                     23.90246     0.65356   24.55602   23.24890
Training/qf2_norm                     25.29122     0.61151   25.90273   24.67971
log_std/mean                          -0.11167     0.00030   -0.11137   -0.11197
log_std/std                           0.00877      0.00004   0.00881    0.00874
log_std/max                           -0.09678     0.00024   -0.09654   -0.09703
log_std/min                           -0.12615     0.00037   -0.12578   -0.12652
log_probs/mean                        -2.73345     0.00208   -2.73137   -2.73553
log_probs/std                         0.24105      0.00938   0.25042    0.23167
log_probs/max                         -2.07156     0.01723   -2.05433   -2.08878
log_probs/min                         -4.41334     0.40505   -4.00830   -4.81839
mean/mean                             0.00110      0.00002   0.00112    0.00109
mean/std                              0.00276      0.00000   0.00276    0.00275
mean/max                              0.00751      0.00007   0.00758    0.00744
mean/min                              -0.00363     0.00006   -0.00357   -0.00368
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 98 50
freq 22
sample: [0, 1, 5, 8, 9, 3, 4, 6, 7, 2]
replay_buffer._size: [15000 15000 15000 15000 15000 15000 15000 15000 15000 15000]
train_time 0.1477503776550293
eval time 0.0023763179779052734
2023-08-22 20:45:52,718 MainThread INFO: EPOCH:98
2023-08-22 20:45:52,718 MainThread INFO: Time Consumed:0.15752863883972168s
2023-08-22 20:45:52,718 MainThread INFO: Total Frames:148500s
 50%|████▉     | 99/200 [01:16<01:18,  1.29it/s]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1268.41080
Train_Epoch_Reward                    3461.96361
Running_Training_Average_Rewards      434.94433
Explore_Time                          0.00670
Train___Time                          0.14775
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.71821
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.59723
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.37519
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.29982
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.57893
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.63699
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.84976
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12873.91333
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.82051
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22352
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.55130      0.31831   7.86962     7.23299
alpha_0                               0.94241      0.00014   0.94255     0.94227
alpha_1                               0.94234      0.00014   0.94248     0.94219
alpha_2                               0.94237      0.00014   0.94251     0.94223
alpha_3                               0.94236      0.00014   0.94250     0.94222
alpha_4                               0.94237      0.00014   0.94251     0.94222
alpha_5                               0.94240      0.00014   0.94254     0.94225
alpha_6                               0.94237      0.00014   0.94252     0.94223
alpha_7                               0.94238      0.00014   0.94252     0.94223
alpha_8                               0.94237      0.00014   0.94251     0.94222
alpha_9                               0.94238      0.00014   0.94253     0.94224
Alpha_loss                            -0.39769     0.00047   -0.39723    -0.39816
Training/policy_loss                  -2.76685     0.00824   -2.75861    -2.77509
Training/qf1_loss                     1030.22958   79.55508  1109.78467  950.67450
Training/qf2_loss                     1029.78143   79.57379  1109.35522  950.20764
Training/pf_norm                      0.13275      0.00498   0.13773     0.12777
Training/qf1_norm                     24.76998     0.79872   25.56870    23.97126
Training/qf2_norm                     26.18712     0.73868   26.92581    25.44844
log_std/mean                          -0.11285     0.00030   -0.11255    -0.11315
log_std/std                           0.00893      0.00005   0.00898     0.00889
log_std/max                           -0.09767     0.00024   -0.09742    -0.09791
log_std/min                           -0.12745     0.00051   -0.12694    -0.12796
log_probs/mean                        -2.73459     0.00926   -2.72533    -2.74385
log_probs/std                         0.25776      0.00857   0.26632     0.24919
log_probs/max                         -2.01312     0.05411   -1.95901    -2.06724
log_probs/min                         -5.81278     0.25829   -5.55449    -6.07106
mean/mean                             0.00127      0.00004   0.00131     0.00123
mean/std                              0.00278      0.00001   0.00279     0.00277
mean/max                              0.00787      0.00001   0.00788     0.00787
mean/min                              -0.00324     0.00010   -0.00314    -0.00334
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 99 50
freq 22
sample: [8, 0, 1, 2, 4, 6, 5, 9, 7, 3]
replay_buffer._size: [15150 15150 15150 15150 15150 15150 15150 15150 15150 15150]
train_time 0.1605973243713379
eval time 0.003309965133666992
2023-08-22 20:45:53,607 MainThread INFO: EPOCH:99
2023-08-22 20:45:53,607 MainThread INFO: Time Consumed:0.16740059852600098s
2023-08-22 20:45:53,607 MainThread INFO: Total Frames:150000s
 50%|█████     | 100/200 [01:17<01:21,  1.23it/s]------------------------------------  -----------  -------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1264.16324
Train_Epoch_Reward                    2913.33822
Running_Training_Average_Rewards      379.71020
Explore_Time                          0.00278
Train___Time                          0.16060
Eval____Time                          0.00331
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.03384
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.56625
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.39877
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.31581
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.63171
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.69329
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.89530
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12865.29858
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.79670
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.25553
mean_success_rate                     0.00000

Name                                  Mean         Std      Max         Min
Reward_Mean                           7.67097      0.06108  7.73205     7.60990
alpha_0                               0.94184      0.00014  0.94198     0.94170
alpha_1                               0.94177      0.00014  0.94191     0.94163
alpha_2                               0.94180      0.00014  0.94194     0.94166
alpha_3                               0.94179      0.00014  0.94194     0.94165
alpha_4                               0.94180      0.00014  0.94194     0.94166
alpha_5                               0.94183      0.00014  0.94197     0.94169
alpha_6                               0.94181      0.00014  0.94195     0.94167
alpha_7                               0.94181      0.00014  0.94195     0.94167
alpha_8                               0.94180      0.00014  0.94194     0.94166
alpha_9                               0.94182      0.00014  0.94196     0.94167
Alpha_loss                            -0.40108     0.00120  -0.39988    -0.40228
Training/policy_loss                  -2.75913     0.00346  -2.75567    -2.76259
Training/qf1_loss                     1037.04681   4.00555  1041.05237  1033.04126
Training/qf2_loss                     1036.58545   3.99536  1040.58081  1032.59009
Training/pf_norm                      0.12728      0.00354  0.13081     0.12374
Training/qf1_norm                     25.18887     0.11185  25.30072    25.07702
Training/qf2_norm                     26.64682     0.14855  26.79537    26.49827
log_std/mean                          -0.11401     0.00030  -0.11371    -0.11431
log_std/std                           0.00910      0.00005  0.00915     0.00906
log_std/max                           -0.09843     0.00023  -0.09820    -0.09866
log_std/min                           -0.12852     0.00051  -0.12801    -0.12904
log_probs/mean                        -2.72339     0.00313  -2.72027    -2.72652
log_probs/std                         0.25539      0.00190  0.25729     0.25349
log_probs/max                         -2.01090     0.02335  -1.98755    -2.03424
log_probs/min                         -5.12220     0.03591  -5.08629    -5.15812
mean/mean                             0.00146      0.00004  0.00150     0.00142
mean/std                              0.00272      0.00003  0.00275     0.00269
mean/max                              0.00784      0.00006  0.00790     0.00778
mean/min                              -0.00282     0.00014  -0.00268    -0.00296
------------------------------------  -----------  -------  ----------  ----------
epoch, update_end_epoch 100 50
freq 22
sample: [6, 7, 0, 4, 3, 8, 5, 2, 9, 1]
replay_buffer._size: [15300 15300 15300 15300 15300 15300 15300 15300 15300 15300]
train_time 0.14881420135498047
eval time 0.002864360809326172
2023-08-22 20:45:54,448 MainThread INFO: EPOCH:100
2023-08-22 20:45:54,448 MainThread INFO: Time Consumed:0.15596413612365723s
2023-08-22 20:45:54,448 MainThread INFO: Total Frames:151500s
 50%|█████     | 101/200 [01:51<17:37, 10.68s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1262.28899
Train_Epoch_Reward                    15416.44512
Running_Training_Average_Rewards      726.39157
Explore_Time                          0.00350
Train___Time                          0.14881
Eval____Time                          0.00286
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.85801
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.50484
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.43375
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.29138
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.64930
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.70895
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.90044
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12887.48446
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.73158
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.26096
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.22546      0.34501    7.57046     6.88045
alpha_0                               0.94127      0.00014    0.94142     0.94113
alpha_1                               0.94120      0.00014    0.94134     0.94106
alpha_2                               0.94124      0.00014    0.94138     0.94109
alpha_3                               0.94123      0.00014    0.94137     0.94109
alpha_4                               0.94123      0.00014    0.94137     0.94109
alpha_5                               0.94126      0.00014    0.94140     0.94112
alpha_6                               0.94124      0.00014    0.94138     0.94110
alpha_7                               0.94124      0.00014    0.94139     0.94110
alpha_8                               0.94123      0.00014    0.94138     0.94109
alpha_9                               0.94125      0.00014    0.94139     0.94111
Alpha_loss                            -0.40602     0.00130    -0.40472    -0.40732
Training/policy_loss                  -2.77535     0.00529    -2.77006    -2.78064
Training/qf1_loss                     928.18033    142.58481  1070.76514  785.59552
Training/qf2_loss                     927.71640    142.57120  1070.28760  785.14520
Training/pf_norm                      0.09363      0.00080    0.09443     0.09284
Training/qf1_norm                     24.23390     0.92066    25.15457    23.31324
Training/qf2_norm                     25.68758     0.95703    26.64461    24.73055
log_std/mean                          -0.11520     0.00028    -0.11491    -0.11548
log_std/std                           0.00928      0.00004    0.00932     0.00924
log_std/max                           -0.09932     0.00019    -0.09913    -0.09952
log_std/min                           -0.13013     0.00039    -0.12974    -0.13052
log_probs/mean                        -2.73820     0.00481    -2.73338    -2.74301
log_probs/std                         0.25960      0.00088    0.26048     0.25872
log_probs/max                         -2.05864     0.01914    -2.03950    -2.07777
log_probs/min                         -4.82997     0.23066    -4.59931    -5.06063
mean/mean                             0.00167      0.00006    0.00173     0.00161
mean/std                              0.00265      0.00002    0.00267     0.00263
mean/max                              0.00766      0.00009    0.00775     0.00757
mean/min                              -0.00232     0.00011    -0.00222    -0.00243
------------------------------------  -----------  ---------  ----------  ---------
snapshot at 100
history save at ./log/testing_must_mtsac/mt10/16/model
epoch, update_end_epoch 101 50
freq 22
sample: [2, 7, 6, 8, 5, 4, 1, 0, 9, 3]
replay_buffer._size: [15450 15450 15450 15450 15450 15450 15450 15450 15450 15450]
train_time 0.13931512832641602
eval time 0.0024802684783935547
2023-08-22 20:46:27,560 MainThread INFO: EPOCH:101
2023-08-22 20:46:27,560 MainThread INFO: Time Consumed:0.14593172073364258s
2023-08-22 20:46:27,560 MainThread INFO: Total Frames:153000s
 51%|█████     | 102/200 [01:51<12:19,  7.55s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1264.11930
Train_Epoch_Reward                    2373.23521
Running_Training_Average_Rewards      690.10062
Explore_Time                          0.00330
Train___Time                          0.13932
Eval____Time                          0.00248
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.51643
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.41490
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47350
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.23961
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.63583
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.69788
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.88425
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12919.48042
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.63602
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.25975
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.34420      0.35156   7.69577     6.99264
alpha_0                               0.94071      0.00014   0.94085     0.94057
alpha_1                               0.94064      0.00014   0.94078     0.94050
alpha_2                               0.94067      0.00014   0.94081     0.94053
alpha_3                               0.94066      0.00014   0.94080     0.94052
alpha_4                               0.94067      0.00014   0.94081     0.94052
alpha_5                               0.94070      0.00014   0.94084     0.94055
alpha_6                               0.94067      0.00014   0.94081     0.94053
alpha_7                               0.94068      0.00014   0.94082     0.94054
alpha_8                               0.94067      0.00014   0.94081     0.94053
alpha_9                               0.94068      0.00014   0.94082     0.94054
Alpha_loss                            -0.40936     0.00094   -0.40842    -0.41030
Training/policy_loss                  -2.76713     0.00073   -2.76639    -2.76786
Training/qf1_loss                     981.41754    93.70526  1075.12280  887.71228
Training/qf2_loss                     980.93890    93.66937  1074.60828  887.26953
Training/pf_norm                      0.15419      0.01112   0.16531     0.14307
Training/qf1_norm                     24.66677     0.80987   25.47664    23.85690
Training/qf2_norm                     26.16143     0.93424   27.09566    25.22719
log_std/mean                          -0.11633     0.00029   -0.11604    -0.11662
log_std/std                           0.00942      0.00003   0.00945     0.00939
log_std/max                           -0.10005     0.00021   -0.09984    -0.10026
log_std/min                           -0.13138     0.00044   -0.13093    -0.13182
log_probs/mean                        -2.72650     0.00116   -2.72534    -2.72766
log_probs/std                         0.24618      0.00244   0.24861     0.24374
log_probs/max                         -2.00132     0.00777   -1.99355    -2.00908
log_probs/min                         -4.60797     0.01899   -4.58898    -4.62696
mean/mean                             0.00190      0.00005   0.00195     0.00185
mean/std                              0.00259      0.00004   0.00263     0.00256
mean/max                              0.00744      0.00006   0.00749     0.00738
mean/min                              -0.00196     0.00012   -0.00184    -0.00208
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 102 50
freq 22
sample: [5, 8, 7, 0, 2, 3, 4, 9, 1, 6]
replay_buffer._size: [15600 15600 15600 15600 15600 15600 15600 15600 15600 15600]
train_time 0.1254873275756836
eval time 0.0025606155395507812
2023-08-22 20:46:28,373 MainThread INFO: EPOCH:102
2023-08-22 20:46:28,374 MainThread INFO: Time Consumed:0.131453275680542s
2023-08-22 20:46:28,374 MainThread INFO: Total Frames:154500s
 52%|█████▏    | 103/200 [01:52<08:57,  5.54s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1267.70051
Train_Epoch_Reward                    7386.64974
Running_Training_Average_Rewards      839.21100
Explore_Time                          0.00289
Train___Time                          0.12549
Eval____Time                          0.00256
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.37046
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.32300
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.52238
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.16454
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.60513
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.67087
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.85480
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12979.41862
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.53373
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22587
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.69509      0.74703    8.44212     6.94807
alpha_0                               0.94014      0.00014    0.94028     0.94000
alpha_1                               0.94007      0.00014    0.94021     0.93993
alpha_2                               0.94010      0.00014    0.94024     0.93996
alpha_3                               0.94009      0.00014    0.94024     0.93995
alpha_4                               0.94010      0.00014    0.94024     0.93996
alpha_5                               0.94013      0.00014    0.94027     0.93999
alpha_6                               0.94011      0.00014    0.94025     0.93996
alpha_7                               0.94011      0.00014    0.94025     0.93997
alpha_8                               0.94010      0.00014    0.94024     0.93996
alpha_9                               0.94012      0.00014    0.94026     0.93997
Alpha_loss                            -0.41397     0.00129    -0.41268    -0.41526
Training/policy_loss                  -2.77838     0.00509    -2.77330    -2.78347
Training/qf1_loss                     1106.68439   270.10736  1376.79175  836.57703
Training/qf2_loss                     1106.13422   270.04962  1376.18384  836.08459
Training/pf_norm                      0.10803      0.02160    0.12963     0.08642
Training/qf1_norm                     25.62708     1.88872    27.51580    23.73837
Training/qf2_norm                     27.37634     2.08763    29.46396    25.28871
log_std/mean                          -0.11747     0.00027    -0.11719    -0.11774
log_std/std                           0.00955      0.00003    0.00958     0.00951
log_std/max                           -0.10098     0.00018    -0.10080    -0.10115
log_std/min                           -0.13278     0.00024    -0.13254    -0.13301
log_probs/mean                        -2.73557     0.00450    -2.73107    -2.74008
log_probs/std                         0.24661      0.00127    0.24789     0.24534
log_probs/max                         -2.03685     0.09238    -1.94447    -2.12923
log_probs/min                         -5.34556     0.16674    -5.17882    -5.51230
mean/mean                             0.00217      0.00007    0.00224     0.00211
mean/std                              0.00243      0.00005    0.00248     0.00237
mean/max                              0.00773      0.00008    0.00781     0.00765
mean/min                              -0.00144     0.00015    -0.00129    -0.00159
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 103 50
freq 22
sample: [3, 2, 7, 1, 5, 8, 0, 4, 6, 9]
replay_buffer._size: [15750 15750 15750 15750 15750 15750 15750 15750 15750 15750]
train_time 0.11927056312561035
eval time 0.002429485321044922
2023-08-22 20:46:29,177 MainThread INFO: EPOCH:103
2023-08-22 20:46:29,177 MainThread INFO: Time Consumed:0.1249535083770752s
2023-08-22 20:46:29,177 MainThread INFO: Total Frames:156000s
 52%|█████▏    | 104/200 [01:52<06:35,  4.12s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1272.04679
Train_Epoch_Reward                    21050.39909
Running_Training_Average_Rewards      1027.00947
Explore_Time                          0.00272
Train___Time                          0.11927
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.25765
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.21875
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.54848
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.08971
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.54158
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.61228
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.80160
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13002.24483
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42011
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22097
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.76185      0.66633    8.42818     7.09552
alpha_0                               0.93958      0.00014    0.93972     0.93944
alpha_1                               0.93951      0.00014    0.93965     0.93936
alpha_2                               0.93954      0.00014    0.93968     0.93940
alpha_3                               0.93953      0.00014    0.93967     0.93939
alpha_4                               0.93953      0.00014    0.93967     0.93939
alpha_5                               0.93956      0.00014    0.93970     0.93942
alpha_6                               0.93954      0.00014    0.93968     0.93940
alpha_7                               0.93955      0.00014    0.93969     0.93941
alpha_8                               0.93954      0.00014    0.93968     0.93940
alpha_9                               0.93955      0.00014    0.93969     0.93941
Alpha_loss                            -0.41845     0.00085    -0.41760    -0.41930
Training/policy_loss                  -2.78807     0.00221    -2.78586    -2.79027
Training/qf1_loss                     1154.35272   254.76910  1409.12183  899.58362
Training/qf2_loss                     1153.75592   254.71991  1408.47583  899.03601
Training/pf_norm                      0.09818      0.00086    0.09903     0.09732
Training/qf1_norm                     25.83935     1.72792    27.56727    24.11143
Training/qf2_norm                     27.74749     1.90195    29.64944    25.84554
log_std/mean                          -0.11845     0.00023    -0.11822    -0.11868
log_std/std                           0.00966      0.00002    0.00968     0.00964
log_std/max                           -0.10179     0.00017    -0.10161    -0.10196
log_std/min                           -0.13430     0.00013    -0.13417    -0.13443
log_probs/mean                        -2.74252     0.00269    -2.73982    -2.74521
log_probs/std                         0.24681      0.01107    0.25788     0.23574
log_probs/max                         -2.11565     0.01176    -2.10390    -2.12741
log_probs/min                         -5.25095     0.82957    -4.42137    -6.08052
mean/mean                             0.00241      0.00005    0.00246     0.00236
mean/std                              0.00226      0.00001    0.00227     0.00225
mean/max                              0.00802      0.00010    0.00812     0.00791
mean/min                              -0.00089     0.00009    -0.00080    -0.00098
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 104 50
freq 22
sample: [5, 3, 0, 6, 1, 7, 2, 9, 4, 8]
replay_buffer._size: [15900 15900 15900 15900 15900 15900 15900 15900 15900 15900]
train_time 0.11851382255554199
eval time 0.0024306774139404297
2023-08-22 20:46:30,056 MainThread INFO: EPOCH:104
2023-08-22 20:46:30,057 MainThread INFO: Time Consumed:0.12391185760498047s
2023-08-22 20:46:30,057 MainThread INFO: Total Frames:157500s
 52%|█████▎    | 105/200 [01:53<04:58,  3.14s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1273.93450
Train_Epoch_Reward                    24358.13693
Running_Training_Average_Rewards      1759.83953
Explore_Time                          0.00237
Train___Time                          0.11851
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.40748
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.13128
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.54710
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.03281
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45577
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.53559
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.73023
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12984.75996
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.32485
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.24145
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.85745      0.05184   7.90929     7.80562
alpha_0                               0.93901      0.00014   0.93915     0.93887
alpha_1                               0.93894      0.00014   0.93908     0.93880
alpha_2                               0.93897      0.00014   0.93911     0.93883
alpha_3                               0.93896      0.00014   0.93910     0.93882
alpha_4                               0.93897      0.00014   0.93911     0.93883
alpha_5                               0.93900      0.00014   0.93914     0.93886
alpha_6                               0.93897      0.00014   0.93912     0.93883
alpha_7                               0.93898      0.00014   0.93912     0.93884
alpha_8                               0.93897      0.00014   0.93911     0.93883
alpha_9                               0.93899      0.00014   0.93913     0.93884
Alpha_loss                            -0.42195     0.00080   -0.42115    -0.42276
Training/policy_loss                  -2.78240     0.00230   -2.78010    -2.78469
Training/qf1_loss                     1150.10968   22.38898  1172.49866  1127.72070
Training/qf2_loss                     1149.48248   22.32831  1171.81079  1127.15417
Training/pf_norm                      0.09526      0.00833   0.10359     0.08693
Training/qf1_norm                     26.22690     0.03392   26.26081    26.19298
Training/qf2_norm                     28.22850     0.24823   28.47674    27.98027
log_std/mean                          -0.11934     0.00021   -0.11913    -0.11955
log_std/std                           0.00971      0.00001   0.00972     0.00970
log_std/max                           -0.10260     0.00023   -0.10237    -0.10283
log_std/min                           -0.13505     0.00011   -0.13494    -0.13516
log_probs/mean                        -2.73364     0.00339   -2.73025    -2.73703
log_probs/std                         0.23763      0.00194   0.23957     0.23569
log_probs/max                         -2.10583     0.04105   -2.06478    -2.14688
log_probs/min                         -4.48696     0.03419   -4.45277    -4.52115
mean/mean                             0.00259      0.00004   0.00263     0.00255
mean/std                              0.00224      0.00001   0.00225     0.00224
mean/max                              0.00834      0.00009   0.00843     0.00825
mean/min                              -0.00053     0.00008   -0.00046    -0.00061
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 105 50
freq 22
sample: [5, 1, 8, 6, 2, 7, 4, 3, 9, 0]
replay_buffer._size: [16050 16050 16050 16050 16050 16050 16050 16050 16050 16050]
train_time 0.18203973770141602
eval time 0.003138303756713867
2023-08-22 20:46:31,043 MainThread INFO: EPOCH:105
2023-08-22 20:46:31,043 MainThread INFO: Time Consumed:0.18916893005371094s
2023-08-22 20:46:31,043 MainThread INFO: Total Frames:159000s
 53%|█████▎    | 106/200 [01:54<03:54,  2.49s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1274.42052
Train_Epoch_Reward                    10377.81154
Running_Training_Average_Rewards      1859.54492
Explore_Time                          0.00329
Train___Time                          0.18204
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.09202
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05017
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.55764
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.97967
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39394
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.47590
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.67282
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12984.44088
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.24430
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.24584
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.09234      0.32486   8.41719     7.76748
alpha_0                               0.93845      0.00014   0.93859     0.93831
alpha_1                               0.93837      0.00014   0.93852     0.93823
alpha_2                               0.93841      0.00014   0.93855     0.93827
alpha_3                               0.93840      0.00014   0.93854     0.93826
alpha_4                               0.93840      0.00014   0.93854     0.93826
alpha_5                               0.93843      0.00014   0.93857     0.93829
alpha_6                               0.93841      0.00014   0.93855     0.93827
alpha_7                               0.93842      0.00014   0.93856     0.93828
alpha_8                               0.93841      0.00014   0.93855     0.93827
alpha_9                               0.93842      0.00014   0.93856     0.93828
Alpha_loss                            -0.42547     0.00087   -0.42460    -0.42635
Training/policy_loss                  -2.77799     0.00104   -2.77695    -2.77903
Training/qf1_loss                     1226.14050   56.60400  1282.74451  1169.53650
Training/qf2_loss                     1225.53760   56.59937  1282.13696  1168.93823
Training/pf_norm                      0.10891      0.02493   0.13384     0.08398
Training/qf1_norm                     27.01228     0.85403   27.86631    26.15824
Training/qf2_norm                     28.91389     0.87047   29.78436    28.04342
log_std/mean                          -0.12017     0.00019   -0.11998    -0.12036
log_std/std                           0.00977      0.00001   0.00978     0.00976
log_std/max                           -0.10338     0.00016   -0.10322    -0.10354
log_std/min                           -0.13578     0.00004   -0.13574    -0.13582
log_probs/mean                        -2.72518     0.00221   -2.72298    -2.72739
log_probs/std                         0.23440      0.00229   0.23668     0.23211
log_probs/max                         -2.12075     0.03858   -2.08217    -2.15933
log_probs/min                         -4.95610     0.04381   -4.91229    -4.99992
mean/mean                             0.00274      0.00004   0.00278     0.00270
mean/std                              0.00232      0.00002   0.00234     0.00231
mean/max                              0.00866      0.00005   0.00871     0.00861
mean/min                              -0.00050     0.00007   -0.00043    -0.00057
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 106 50
freq 22
sample: [4, 2, 8, 0, 5, 7, 3, 1, 6, 9]
replay_buffer._size: [16200 16200 16200 16200 16200 16200 16200 16200 16200 16200]
train_time 0.14052224159240723
eval time 0.0020589828491210938
2023-08-22 20:46:31,885 MainThread INFO: EPOCH:106
2023-08-22 20:46:31,885 MainThread INFO: Time Consumed:0.14618802070617676s
2023-08-22 20:46:31,886 MainThread INFO: Total Frames:160500s
 54%|█████▎    | 107/200 [01:55<03:05,  2.00s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1274.22273
Train_Epoch_Reward                    35086.27773
Running_Training_Average_Rewards      2327.40754
Explore_Time                          0.00290
Train___Time                          0.14052
Eval____Time                          0.00206
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.14688
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.98577
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56808
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.91943
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31532
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.40076
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.60129
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12996.94021
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.17703
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22569
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.05008      0.56186    8.61195     7.48822
alpha_0                               0.93788      0.00014    0.93803     0.93774
alpha_1                               0.93781      0.00014    0.93795     0.93767
alpha_2                               0.93784      0.00014    0.93798     0.93770
alpha_3                               0.93783      0.00014    0.93797     0.93769
alpha_4                               0.93784      0.00014    0.93798     0.93770
alpha_5                               0.93787      0.00014    0.93801     0.93773
alpha_6                               0.93784      0.00014    0.93798     0.93770
alpha_7                               0.93785      0.00014    0.93799     0.93771
alpha_8                               0.93784      0.00014    0.93798     0.93770
alpha_9                               0.93785      0.00014    0.93800     0.93771
Alpha_loss                            -0.43039     0.00090    -0.42949    -0.43128
Training/policy_loss                  -2.79365     0.00094    -2.79271    -2.79459
Training/qf1_loss                     1192.25662   215.61227  1407.86890  976.64435
Training/qf2_loss                     1191.60248   215.55109  1407.15356  976.05139
Training/pf_norm                      0.08077      0.01053    0.09130     0.07023
Training/qf1_norm                     27.06954     1.37457    28.44412    25.69497
Training/qf2_norm                     29.15065     1.59619    30.74684    27.55445
log_std/mean                          -0.12098     0.00019    -0.12079    -0.12117
log_std/std                           0.00984      0.00001    0.00985     0.00983
log_std/max                           -0.10413     0.00022    -0.10391    -0.10434
log_std/min                           -0.13679     0.00002    -0.13677    -0.13682
log_probs/mean                        -2.73873     0.00186    -2.73687    -2.74059
log_probs/std                         0.24335      0.00745    0.25080     0.23591
log_probs/max                         -2.07798     0.02384    -2.05414    -2.10182
log_probs/min                         -5.00012     0.33610    -4.66402    -5.33621
mean/mean                             0.00274      0.00001    0.00275     0.00274
mean/std                              0.00241      0.00001    0.00242     0.00239
mean/max                              0.00870      0.00002    0.00872     0.00868
mean/min                              -0.00088     0.00007    -0.00081    -0.00095
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 107 50
freq 22
sample: [7, 3, 2, 5, 1, 6, 9, 4, 8, 0]
replay_buffer._size: [16350 16350 16350 16350 16350 16350 16350 16350 16350 16350]
train_time 0.15167927742004395
eval time 0.0020034313201904297
2023-08-22 20:46:32,838 MainThread INFO: EPOCH:107
2023-08-22 20:46:32,838 MainThread INFO: Time Consumed:0.15701770782470703s
2023-08-22 20:46:32,838 MainThread INFO: Total Frames:162000s
 54%|█████▍    | 108/200 [01:56<02:34,  1.68s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1274.54663
Train_Epoch_Reward                    7341.90305
Running_Training_Average_Rewards      1760.19974
Explore_Time                          0.00275
Train___Time                          0.15168
Eval____Time                          0.00200
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.16324
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.93722
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56631
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.88148
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24845
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.33554
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.54034
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12988.09450
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.12834
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.22327
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.85709      0.07688   7.93397     7.78021
alpha_0                               0.93732      0.00014   0.93746     0.93718
alpha_1                               0.93725      0.00014   0.93739     0.93711
alpha_2                               0.93728      0.00014   0.93742     0.93714
alpha_3                               0.93727      0.00014   0.93741     0.93713
alpha_4                               0.93727      0.00014   0.93741     0.93713
alpha_5                               0.93730      0.00014   0.93745     0.93716
alpha_6                               0.93728      0.00014   0.93742     0.93714
alpha_7                               0.93729      0.00014   0.93743     0.93715
alpha_8                               0.93728      0.00014   0.93742     0.93714
alpha_9                               0.93729      0.00014   0.93743     0.93715
Alpha_loss                            -0.43404     0.00102   -0.43302    -0.43507
Training/policy_loss                  -2.79070     0.00097   -2.78973    -2.79168
Training/qf1_loss                     1110.97754   33.40796  1144.38550  1077.56958
Training/qf2_loss                     1110.33820   33.41901  1143.75720  1076.91919
Training/pf_norm                      0.11035      0.01608   0.12642     0.09427
Training/qf1_norm                     26.71370     0.11250   26.82619    26.60120
Training/qf2_norm                     28.72179     0.14697   28.86876    28.57481
log_std/mean                          -0.12177     0.00021   -0.12156    -0.12198
log_std/std                           0.00993      0.00002   0.00994     0.00991
log_std/max                           -0.10479     0.00018   -0.10461    -0.10497
log_std/min                           -0.13790     0.00004   -0.13786    -0.13794
log_probs/mean                        -2.73251     0.00015   -2.73236    -2.73267
log_probs/std                         0.25624      0.00701   0.26325     0.24923
log_probs/max                         -2.06820     0.00329   -2.06491    -2.07149
log_probs/min                         -5.28606     0.15720   -5.12886    -5.44326
mean/mean                             0.00270      0.00001   0.00271     0.00268
mean/std                              0.00252      0.00003   0.00254     0.00249
mean/max                              0.00878      0.00002   0.00880     0.00876
mean/min                              -0.00118     0.00006   -0.00113    -0.00124
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 108 50
freq 22
sample: [0, 7, 4, 3, 5, 8, 9, 2, 6, 1]
replay_buffer._size: [16500 16500 16500 16500 16500 16500 16500 16500 16500 16500]
train_time 0.14826273918151855
eval time 0.002503633499145508
2023-08-22 20:46:33,759 MainThread INFO: EPOCH:108
2023-08-22 20:46:33,760 MainThread INFO: Time Consumed:0.1550760269165039s
2023-08-22 20:46:33,760 MainThread INFO: Total Frames:163500s
 55%|█████▍    | 109/200 [01:57<02:12,  1.45s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1274.32132
Train_Epoch_Reward                    27699.97077
Running_Training_Average_Rewards      2337.60505
Explore_Time                          0.00374
Train___Time                          0.14826
Eval____Time                          0.00250
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.14118
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92790
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.55939
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.85328
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19874
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.28366
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.49062
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12989.73901
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.11039
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20446
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.57928      0.25015    7.82944     7.32913
alpha_0                               0.93676      0.00014    0.93690     0.93662
alpha_1                               0.93668      0.00014    0.93682     0.93654
alpha_2                               0.93671      0.00014    0.93686     0.93657
alpha_3                               0.93670      0.00014    0.93684     0.93656
alpha_4                               0.93671      0.00014    0.93685     0.93657
alpha_5                               0.93674      0.00014    0.93688     0.93660
alpha_6                               0.93672      0.00014    0.93686     0.93657
alpha_7                               0.93673      0.00014    0.93687     0.93659
alpha_8                               0.93671      0.00014    0.93685     0.93657
alpha_9                               0.93673      0.00014    0.93687     0.93658
Alpha_loss                            -0.43793     0.00045    -0.43748    -0.43838
Training/policy_loss                  -2.79175     0.00766    -2.78409    -2.79942
Training/qf1_loss                     1023.66040   125.96375  1149.62415  897.69666
Training/qf2_loss                     1023.00287   125.92316  1148.92603  897.07971
Training/pf_norm                      0.11649      0.00463    0.12112     0.11186
Training/qf1_norm                     26.06979     0.58109    26.65088    25.48870
Training/qf2_norm                     28.13800     0.72215    28.86016    27.41585
log_std/mean                          -0.12264     0.00021    -0.12243    -0.12285
log_std/std                           0.01000      0.00002    0.01002     0.00998
log_std/max                           -0.10544     0.00022    -0.10523    -0.10566
log_std/min                           -0.13916     0.00017    -0.13899    -0.13933
log_probs/mean                        -2.72999     0.00869    -2.72130    -2.73867
log_probs/std                         0.25327      0.01081    0.26408     0.24246
log_probs/max                         -2.15082     0.00300    -2.14782    -2.15383
log_probs/min                         -5.22314     0.61042    -4.61272    -5.83355
mean/mean                             0.00266      0.00003    0.00269     0.00263
mean/std                              0.00260      0.00001    0.00261     0.00258
mean/max                              0.00892      0.00002    0.00895     0.00890
mean/min                              -0.00129     0.00001    -0.00128    -0.00130
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 109 50
freq 22
sample: [8, 0, 7, 9, 3, 2, 4, 5, 6, 1]
replay_buffer._size: [16650 16650 16650 16650 16650 16650 16650 16650 16650 16650]
train_time 0.14498591423034668
eval time 0.002349376678466797
2023-08-22 20:46:34,766 MainThread INFO: EPOCH:109
2023-08-22 20:46:34,766 MainThread INFO: Time Consumed:0.15138578414916992s
2023-08-22 20:46:34,766 MainThread INFO: Total Frames:165000s
 55%|█████▌    | 110/200 [01:58<01:58,  1.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1274.56975
Train_Epoch_Reward                    4008.00338
Running_Training_Average_Rewards      1301.66257
Explore_Time                          0.00335
Train___Time                          0.14499
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.77680
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92250
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56316
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.82754
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.17783
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.26513
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.47633
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13010.34002
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.09199
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.18595
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.48558      0.41166    7.89724     7.07392
alpha_0                               0.93619      0.00014    0.93633     0.93605
alpha_1                               0.93612      0.00014    0.93626     0.93598
alpha_2                               0.93615      0.00014    0.93629     0.93601
alpha_3                               0.93614      0.00014    0.93628     0.93600
alpha_4                               0.93615      0.00014    0.93629     0.93601
alpha_5                               0.93618      0.00014    0.93632     0.93604
alpha_6                               0.93615      0.00014    0.93629     0.93601
alpha_7                               0.93616      0.00014    0.93630     0.93602
alpha_8                               0.93615      0.00014    0.93629     0.93601
alpha_9                               0.93616      0.00014    0.93630     0.93602
Alpha_loss                            -0.44165     0.00089    -0.44077    -0.44254
Training/policy_loss                  -2.79009     0.00067    -2.78942    -2.79076
Training/qf1_loss                     999.38922    145.07037  1144.45959  854.31885
Training/qf2_loss                     998.74295    145.05759  1143.80054  853.68536
Training/pf_norm                      0.13077      0.02537    0.15614     0.10540
Training/qf1_norm                     26.08275     1.14683    27.22958    24.93592
Training/qf2_norm                     28.09976     1.18003    29.27979    26.91973
log_std/mean                          -0.12355     0.00023    -0.12332    -0.12378
log_std/std                           0.01010      0.00002    0.01012     0.01007
log_std/max                           -0.10615     0.00015    -0.10600    -0.10630
log_std/min                           -0.14032     0.00006    -0.14026    -0.14037
log_probs/mean                        -2.72499     0.00193    -2.72307    -2.72692
log_probs/std                         0.23661      0.00809    0.24470     0.22852
log_probs/max                         -2.15783     0.00018    -2.15765    -2.15800
log_probs/min                         -4.52513     0.52526    -3.99987    -5.05039
mean/mean                             0.00253      0.00001    0.00254     0.00252
mean/std                              0.00272      0.00005    0.00277     0.00267
mean/max                              0.00910      0.00008    0.00918     0.00902
mean/min                              -0.00152     0.00007    -0.00145    -0.00159
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 110 50
freq 22
sample: [2, 4, 9, 3, 5, 0, 1, 6, 7, 8]
replay_buffer._size: [16800 16800 16800 16800 16800 16800 16800 16800 16800 16800]
train_time 0.1508638858795166
eval time 0.0028421878814697266
2023-08-22 20:46:35,669 MainThread INFO: EPOCH:110
2023-08-22 20:46:35,669 MainThread INFO: Time Consumed:0.156754732131958s
2023-08-22 20:46:35,670 MainThread INFO: Total Frames:166500s
 56%|█████▌    | 111/200 [01:59<01:46,  1.20s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1275.97443
Train_Epoch_Reward                    4385.10706
Running_Training_Average_Rewards      1203.10271
Explore_Time                          0.00244
Train___Time                          0.15086
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.93513
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.94545
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.55773
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.81135
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.15709
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24698
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.45796
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13035.58524
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.10755
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15527
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.98704      0.51623   8.50327     7.47081
alpha_0                               0.93563      0.00014   0.93577     0.93549
alpha_1                               0.93555      0.00014   0.93570     0.93541
alpha_2                               0.93559      0.00014   0.93573     0.93545
alpha_3                               0.93558      0.00014   0.93572     0.93543
alpha_4                               0.93558      0.00014   0.93572     0.93544
alpha_5                               0.93561      0.00014   0.93576     0.93547
alpha_6                               0.93559      0.00014   0.93573     0.93545
alpha_7                               0.93560      0.00014   0.93574     0.93546
alpha_8                               0.93559      0.00014   0.93573     0.93545
alpha_9                               0.93560      0.00014   0.93574     0.93546
Alpha_loss                            -0.44604     0.00103   -0.44501    -0.44707
Training/policy_loss                  -2.79877     0.00112   -2.79765    -2.79988
Training/qf1_loss                     1239.29462   61.83124  1301.12585  1177.46338
Training/qf2_loss                     1238.51318   61.72046  1300.23364  1176.79272
Training/pf_norm                      0.07362      0.00923   0.08285     0.06439
Training/qf1_norm                     27.39817     1.25841   28.65658    26.13975
Training/qf2_norm                     29.87490     1.66286   31.53776    28.21204
log_std/mean                          -0.12442     0.00021   -0.12421    -0.12462
log_std/std                           0.01017      0.00002   0.01020     0.01015
log_std/max                           -0.10687     0.00016   -0.10671    -0.10703
log_std/min                           -0.14108     0.00032   -0.14076    -0.14140
log_probs/mean                        -2.73015     0.00020   -2.72996    -2.73035
log_probs/std                         0.23009      0.00012   0.23021     0.22996
log_probs/max                         -2.10109     0.00616   -2.09493    -2.10725
log_probs/min                         -4.93171     0.03803   -4.89368    -4.96974
mean/mean                             0.00243      0.00002   0.00246     0.00241
mean/std                              0.00288      0.00004   0.00292     0.00284
mean/max                              0.00931      0.00007   0.00938     0.00924
mean/min                              -0.00178     0.00003   -0.00176    -0.00181
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 111 50
freq 22
sample: [6, 5, 8, 0, 3, 2, 1, 7, 9, 4]
replay_buffer._size: [16950 16950 16950 16950 16950 16950 16950 16950 16950 16950]
train_time 0.11373209953308105
eval time 0.0022907257080078125
2023-08-22 20:46:36,875 MainThread INFO: EPOCH:111
2023-08-22 20:46:36,876 MainThread INFO: Time Consumed:0.1190643310546875s
2023-08-22 20:46:36,876 MainThread INFO: Total Frames:168000s
 56%|█████▌    | 112/200 [02:00<01:45,  1.20s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1277.87035
Train_Epoch_Reward                    11346.64009
Running_Training_Average_Rewards      657.99168
Explore_Time                          0.00247
Train___Time                          0.11373
Eval____Time                          0.00229
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.13669
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92134
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56551
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.77732
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.11537
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20857
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.42294
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13048.20925
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07905
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.13550
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.16847      1.06586    9.23432     7.10261
alpha_0                               0.93507      0.00014    0.93521     0.93493
alpha_1                               0.93499      0.00014    0.93513     0.93485
alpha_2                               0.93503      0.00014    0.93517     0.93489
alpha_3                               0.93501      0.00014    0.93515     0.93487
alpha_4                               0.93502      0.00014    0.93516     0.93488
alpha_5                               0.93505      0.00014    0.93519     0.93491
alpha_6                               0.93502      0.00014    0.93517     0.93488
alpha_7                               0.93504      0.00014    0.93518     0.93490
alpha_8                               0.93502      0.00014    0.93516     0.93488
alpha_9                               0.93503      0.00014    0.93518     0.93489
Alpha_loss                            -0.45006     0.00043    -0.44963    -0.45049
Training/policy_loss                  -2.80105     0.00686    -2.79420    -2.80791
Training/qf1_loss                     1379.10370   336.28168  1715.38538  1042.82202
Training/qf2_loss                     1378.30554   336.08386  1714.38940  1042.22168
Training/pf_norm                      0.13725      0.01187    0.14912     0.12538
Training/qf1_norm                     28.13751     2.74547    30.88298    25.39204
Training/qf2_norm                     30.67050     3.42780    34.09830    27.24270
log_std/mean                          -0.12519     0.00020    -0.12499    -0.12539
log_std/std                           0.01025      0.00002    0.01027     0.01023
log_std/max                           -0.10753     0.00012    -0.10740    -0.10765
log_std/min                           -0.14214     0.00007    -0.14207    -0.14221
log_probs/mean                        -2.72978     0.00873    -2.72106    -2.73851
log_probs/std                         0.24719      0.02613    0.27332     0.22106
log_probs/max                         -2.09448     0.01859    -2.07589    -2.11306
log_probs/min                         -5.32739     1.37721    -3.95018    -6.70460
mean/mean                             0.00237      0.00001    0.00238     0.00235
mean/std                              0.00298      0.00001    0.00300     0.00297
mean/max                              0.00945      0.00003    0.00948     0.00942
mean/min                              -0.00187     0.00002    -0.00184    -0.00189
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 112 50
freq 22
sample: [2, 7, 1, 3, 5, 6, 8, 4, 0, 9]
replay_buffer._size: [17100 17100 17100 17100 17100 17100 17100 17100 17100 17100]
train_time 0.14021635055541992
eval time 0.002920389175415039
2023-08-22 20:46:37,930 MainThread INFO: EPOCH:112
2023-08-22 20:46:37,930 MainThread INFO: Time Consumed:0.14671015739440918s
2023-08-22 20:46:37,930 MainThread INFO: Total Frames:169500s
 56%|█████▋    | 113/200 [02:01<01:40,  1.16s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1279.68513
Train_Epoch_Reward                    37821.96421
Running_Training_Average_Rewards      1785.12371
Explore_Time                          0.00280
Train___Time                          0.14022
Eval____Time                          0.00292
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.06405
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92027
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.58434
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.75513
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.10107
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20023
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.41644
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13069.71277
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07210
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.10298
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.48474      0.68052    8.16526     6.80422
alpha_0                               0.93451      0.00014    0.93465     0.93437
alpha_1                               0.93443      0.00014    0.93457     0.93429
alpha_2                               0.93446      0.00014    0.93460     0.93432
alpha_3                               0.93445      0.00014    0.93459     0.93431
alpha_4                               0.93446      0.00014    0.93460     0.93432
alpha_5                               0.93449      0.00014    0.93463     0.93435
alpha_6                               0.93446      0.00014    0.93460     0.93432
alpha_7                               0.93448      0.00014    0.93462     0.93434
alpha_8                               0.93446      0.00014    0.93460     0.93432
alpha_9                               0.93447      0.00014    0.93461     0.93433
Alpha_loss                            -0.45466     0.00101    -0.45365    -0.45568
Training/policy_loss                  -2.81242     0.00126    -2.81115    -2.81368
Training/qf1_loss                     1184.81174   211.72110  1396.53284  973.09064
Training/qf2_loss                     1184.09631   211.68188  1395.77820  972.41443
Training/pf_norm                      0.09680      0.00205    0.09884     0.09475
Training/qf1_norm                     26.46048     1.81548    28.27596    24.64501
Training/qf2_norm                     28.68939     1.94441    30.63380    26.74498
log_std/mean                          -0.12605     0.00019    -0.12585    -0.12624
log_std/std                           0.01035      0.00002    0.01037     0.01033
log_std/max                           -0.10828     0.00020    -0.10809    -0.10848
log_std/min                           -0.14296     0.00036    -0.14259    -0.14332
log_probs/mean                        -2.73792     0.00001    -2.73791    -2.73792
log_probs/std                         0.24758      0.00442    0.25200     0.24315
log_probs/max                         -2.09531     0.05830    -2.03702    -2.15361
log_probs/min                         -4.61742     0.09226    -4.52516    -4.70969
mean/mean                             0.00247      0.00005    0.00252     0.00242
mean/std                              0.00291      0.00004    0.00294     0.00287
mean/max                              0.00935      0.00003    0.00939     0.00932
mean/min                              -0.00174     0.00007    -0.00167    -0.00180
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 113 50
freq 22
sample: [9, 0, 6, 2, 7, 4, 8, 1, 3, 5]
replay_buffer._size: [17250 17250 17250 17250 17250 17250 17250 17250 17250 17250]
train_time 0.126478910446167
eval time 0.0024182796478271484
2023-08-22 20:46:38,846 MainThread INFO: EPOCH:113
2023-08-22 20:46:38,846 MainThread INFO: Time Consumed:0.13222146034240723s
2023-08-22 20:46:38,846 MainThread INFO: Total Frames:171000s
 57%|█████▋    | 114/200 [02:02<01:33,  1.09s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1279.92435
Train_Epoch_Reward                    14188.12597
Running_Training_Average_Rewards      2111.89101
Explore_Time                          0.00275
Train___Time                          0.12648
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.45237
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.90627
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.58497
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.75994
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.09938
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20559
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.42155
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13041.99328
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.04707
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.12867
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.78120      0.68330    8.46450     7.09791
alpha_0                               0.93394      0.00014    0.93409     0.93380
alpha_1                               0.93387      0.00014    0.93401     0.93373
alpha_2                               0.93390      0.00014    0.93404     0.93376
alpha_3                               0.93389      0.00014    0.93403     0.93375
alpha_4                               0.93389      0.00014    0.93404     0.93375
alpha_5                               0.93393      0.00014    0.93407     0.93379
alpha_6                               0.93390      0.00014    0.93404     0.93376
alpha_7                               0.93391      0.00014    0.93405     0.93377
alpha_8                               0.93390      0.00014    0.93404     0.93376
alpha_9                               0.93391      0.00014    0.93405     0.93377
Alpha_loss                            -0.45798     0.00132    -0.45666    -0.45929
Training/policy_loss                  -2.80633     0.00503    -2.80130    -2.81136
Training/qf1_loss                     1246.61475   195.71509  1442.32983  1050.89966
Training/qf2_loss                     1245.77527   195.67334  1441.44861  1050.10193
Training/pf_norm                      0.10028      0.02471    0.12499     0.07557
Training/qf1_norm                     27.31286     1.84142    29.15428    25.47145
Training/qf2_norm                     29.96946     1.99067    31.96013    27.97878
log_std/mean                          -0.12684     0.00020    -0.12663    -0.12704
log_std/std                           0.01045      0.00002    0.01047     0.01043
log_std/max                           -0.10894     0.00015    -0.10880    -0.10909
log_std/min                           -0.14384     0.00032    -0.14352    -0.14416
log_probs/mean                        -2.72706     0.00446    -2.72260    -2.73151
log_probs/std                         0.22933      0.00109    0.23042     0.22824
log_probs/max                         -2.11242     0.04127    -2.07116    -2.15369
log_probs/min                         -5.02141     0.15210    -4.86931    -5.17351
mean/mean                             0.00258      0.00001    0.00259     0.00257
mean/std                              0.00283      0.00001    0.00284     0.00283
mean/max                              0.00930      0.00001    0.00932     0.00929
mean/min                              -0.00160     0.00001    -0.00159    -0.00161
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 114 50
freq 22
sample: [4, 0, 2, 1, 5, 8, 9, 6, 7, 3]
replay_buffer._size: [17400 17400 17400 17400 17400 17400 17400 17400 17400 17400]
train_time 0.13295602798461914
eval time 0.002418041229248047
2023-08-22 20:46:39,808 MainThread INFO: EPOCH:114
2023-08-22 20:46:39,808 MainThread INFO: Time Consumed:0.13857483863830566s
2023-08-22 20:46:39,808 MainThread INFO: Total Frames:172500s
 57%|█████▊    | 115/200 [02:03<01:29,  1.05s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1279.22570
Train_Epoch_Reward                    22138.19644
Running_Training_Average_Rewards      2471.60955
Explore_Time                          0.00262
Train___Time                          0.13296
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.47177
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.89894
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.59530
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.77243
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.12392
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23360
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.44933
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13017.62126
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.03038
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15816
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.03504      0.27832    8.31336     7.75672
alpha_0                               0.93338      0.00014    0.93352     0.93324
alpha_1                               0.93331      0.00014    0.93345     0.93316
alpha_2                               0.93334      0.00014    0.93348     0.93320
alpha_3                               0.93333      0.00014    0.93347     0.93319
alpha_4                               0.93333      0.00014    0.93347     0.93319
alpha_5                               0.93336      0.00014    0.93350     0.93322
alpha_6                               0.93334      0.00014    0.93348     0.93320
alpha_7                               0.93335      0.00014    0.93349     0.93321
alpha_8                               0.93334      0.00014    0.93348     0.93320
alpha_9                               0.93335      0.00014    0.93349     0.93321
Alpha_loss                            -0.46294     0.00152    -0.46142    -0.46446
Training/policy_loss                  -2.82179     0.00778    -2.81401    -2.82958
Training/qf1_loss                     1135.27054   117.82443  1253.09497  1017.44611
Training/qf2_loss                     1134.45392   117.73724  1252.19116  1016.71667
Training/pf_norm                      0.11775      0.00180    0.11955     0.11595
Training/qf1_norm                     28.27081     0.59978    28.87058    27.67103
Training/qf2_norm                     30.82183     0.90218    31.72400    29.91965
log_std/mean                          -0.12759     0.00018    -0.12741    -0.12777
log_std/std                           0.01051      0.00001    0.01052     0.01050
log_std/max                           -0.10957     0.00012    -0.10945    -0.10969
log_std/min                           -0.14524     0.00017    -0.14507    -0.14541
log_probs/mean                        -2.74037     0.00733    -2.73304    -2.74770
log_probs/std                         0.23396      0.00416    0.23812     0.22980
log_probs/max                         -2.12450     0.00075    -2.12375    -2.12525
log_probs/min                         -5.03185     0.10331    -4.92854    -5.13516
mean/mean                             0.00263      0.00003    0.00265     0.00260
mean/std                              0.00278      0.00003    0.00281     0.00275
mean/max                              0.00921      0.00004    0.00925     0.00916
mean/min                              -0.00157     0.00003    -0.00154    -0.00160
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 115 50
freq 22
sample: [0, 2, 7, 1, 9, 3, 8, 4, 6, 5]
replay_buffer._size: [17550 17550 17550 17550 17550 17550 17550 17550 17550 17550]
train_time 0.15612125396728516
eval time 0.003099203109741211
2023-08-22 20:46:40,848 MainThread INFO: EPOCH:115
2023-08-22 20:46:40,849 MainThread INFO: Time Consumed:0.16246795654296875s
2023-08-22 20:46:40,849 MainThread INFO: Total Frames:174000s
 58%|█████▊    | 116/200 [02:04<01:27,  1.04s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1276.46823
Train_Epoch_Reward                    10598.99918
Running_Training_Average_Rewards      1564.17739
Explore_Time                          0.00262
Train___Time                          0.15612
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.50015
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.89041
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.58270
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.77739
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.11283
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21862
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.43943
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12985.49491
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.01066
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.19067
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.14214      0.36443    7.50657     6.77771
alpha_0                               0.93282      0.00014    0.93296     0.93268
alpha_1                               0.93274      0.00014    0.93288     0.93260
alpha_2                               0.93278      0.00014    0.93292     0.93264
alpha_3                               0.93277      0.00014    0.93291     0.93262
alpha_4                               0.93277      0.00014    0.93291     0.93263
alpha_5                               0.93280      0.00014    0.93294     0.93266
alpha_6                               0.93278      0.00014    0.93292     0.93264
alpha_7                               0.93279      0.00014    0.93293     0.93265
alpha_8                               0.93278      0.00014    0.93292     0.93264
alpha_9                               0.93279      0.00014    0.93293     0.93265
Alpha_loss                            -0.46614     0.00134    -0.46480    -0.46748
Training/policy_loss                  -2.81453     0.00523    -2.80929    -2.81976
Training/qf1_loss                     928.67963    122.71991  1051.39954  805.95972
Training/qf2_loss                     927.94699    122.75089  1050.69788  805.19611
Training/pf_norm                      0.09802      0.01605    0.11407     0.08197
Training/qf1_norm                     26.07221     1.05587    27.12808    25.01634
Training/qf2_norm                     28.32649     0.94513    29.27162    27.38136
log_std/mean                          -0.12823     0.00016    -0.12808    -0.12839
log_std/std                           0.01056      0.00001    0.01057     0.01055
log_std/max                           -0.11001     0.00006    -0.10995    -0.11007
log_std/min                           -0.14541     0.00021    -0.14520    -0.14562
log_probs/mean                        -2.72801     0.00473    -2.72329    -2.73274
log_probs/std                         0.22954      0.01300    0.24254     0.21654
log_probs/max                         -2.05721     0.04568    -2.01153    -2.10288
log_probs/min                         -4.69978     0.52599    -4.17379    -5.22577
mean/mean                             0.00285      0.00007    0.00293     0.00278
mean/std                              0.00264      0.00003    0.00267     0.00262
mean/max                              0.00916      0.00001    0.00917     0.00915
mean/min                              -0.00128     0.00009    -0.00119    -0.00136
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 116 50
freq 22
sample: [6, 0, 1, 8, 9, 7, 3, 2, 5, 4]
replay_buffer._size: [17700 17700 17700 17700 17700 17700 17700 17700 17700 17700]
train_time 0.12790942192077637
eval time 0.00211334228515625
2023-08-22 20:46:41,786 MainThread INFO: EPOCH:116
2023-08-22 20:46:41,786 MainThread INFO: Time Consumed:0.13393402099609375s
2023-08-22 20:46:41,786 MainThread INFO: Total Frames:175500s
 58%|█████▊    | 117/200 [02:05<01:23,  1.01s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1273.97297
Train_Epoch_Reward                    1986.37258
Running_Training_Average_Rewards      1157.45227
Explore_Time                          0.00321
Train___Time                          0.12791
Eval____Time                          0.00211
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.96926
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.89083
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.57228
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.79699
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.13304
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23428
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.45555
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12957.81527
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.99977
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.23358
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.68121      0.06013   8.74134     8.62108
alpha_0                               0.93226      0.00014   0.93240     0.93212
alpha_1                               0.93218      0.00014   0.93232     0.93204
alpha_2                               0.93222      0.00014   0.93236     0.93208
alpha_3                               0.93220      0.00014   0.93234     0.93206
alpha_4                               0.93221      0.00014   0.93235     0.93207
alpha_5                               0.93224      0.00014   0.93238     0.93210
alpha_6                               0.93222      0.00014   0.93236     0.93208
alpha_7                               0.93223      0.00014   0.93237     0.93209
alpha_8                               0.93222      0.00014   0.93236     0.93208
alpha_9                               0.93223      0.00014   0.93237     0.93209
Alpha_loss                            -0.47107     0.00082   -0.47025    -0.47188
Training/policy_loss                  -2.83059     0.00163   -2.82896    -2.83222
Training/qf1_loss                     1383.15802   20.67755  1403.83557  1362.48047
Training/qf2_loss                     1382.15881   20.67444  1402.83325  1361.48438
Training/pf_norm                      0.07647      0.01470   0.09117     0.06177
Training/qf1_norm                     30.29701     0.28679   30.58380    30.01021
Training/qf2_norm                     33.44815     0.31713   33.76528    33.13102
log_std/mean                          -0.12876     0.00014   -0.12863    -0.12890
log_std/std                           0.01058      0.00001   0.01059     0.01057
log_std/max                           -0.11048     0.00007   -0.11041    -0.11055
log_std/min                           -0.14621     0.00030   -0.14591    -0.14650
log_probs/mean                        -2.74064     0.00283   -2.73782    -2.74347
log_probs/std                         0.24119      0.02363   0.26481     0.21756
log_probs/max                         -2.10214     0.06875   -2.03339    -2.17090
log_probs/min                         -5.32082     0.74749   -4.57332    -6.06831
mean/mean                             0.00317      0.00006   0.00324     0.00311
mean/std                              0.00249      0.00005   0.00254     0.00244
mean/max                              0.00915      0.00004   0.00919     0.00910
mean/min                              -0.00081     0.00014   -0.00066    -0.00095
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 117 50
freq 22
sample: [8, 1, 7, 2, 5, 4, 6, 0, 9, 3]
replay_buffer._size: [17850 17850 17850 17850 17850 17850 17850 17850 17850 17850]
train_time 0.13440203666687012
eval time 0.002458333969116211
2023-08-22 20:46:43,110 MainThread INFO: EPOCH:117
2023-08-22 20:46:43,110 MainThread INFO: Time Consumed:0.14111948013305664s
2023-08-22 20:46:43,111 MainThread INFO: Total Frames:177000s
 59%|█████▉    | 118/200 [02:06<01:30,  1.10s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1271.67968
Train_Epoch_Reward                    3782.29107
Running_Training_Average_Rewards      545.58876
Explore_Time                          0.00358
Train___Time                          0.13440
Eval____Time                          0.00246
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.63088
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.88510
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.59938
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.80472
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19003
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.29340
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.50944
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12958.22706
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.97302
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.25249
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.63394      0.45596    8.08990     7.17798
alpha_0                               0.93170      0.00014    0.93184     0.93156
alpha_1                               0.93162      0.00014    0.93176     0.93148
alpha_2                               0.93166      0.00014    0.93180     0.93152
alpha_3                               0.93164      0.00014    0.93178     0.93150
alpha_4                               0.93165      0.00014    0.93179     0.93151
alpha_5                               0.93168      0.00014    0.93182     0.93154
alpha_6                               0.93165      0.00014    0.93179     0.93151
alpha_7                               0.93167      0.00014    0.93181     0.93153
alpha_8                               0.93165      0.00014    0.93179     0.93151
alpha_9                               0.93167      0.00014    0.93181     0.93153
Alpha_loss                            -0.47473     0.00085    -0.47388    -0.47559
Training/policy_loss                  -2.82889     0.00131    -2.82758    -2.83020
Training/qf1_loss                     1144.57727   169.85449  1314.43176  974.72278
Training/qf2_loss                     1143.78391   169.82620  1313.61011  973.95770
Training/pf_norm                      0.12313      0.00499    0.12812     0.11814
Training/qf1_norm                     27.80275     1.23283    29.03558    26.56993
Training/qf2_norm                     30.24140     1.33235    31.57374    28.90905
log_std/mean                          -0.12917     0.00009    -0.12908    -0.12925
log_std/std                           0.01058      0.00000    0.01058     0.01057
log_std/max                           -0.11081     0.00004    -0.11077    -0.11085
log_std/min                           -0.14657     0.00035    -0.14622    -0.14692
log_probs/mean                        -2.73511     0.00227    -2.73284    -2.73738
log_probs/std                         0.24363      0.00655    0.25018     0.23708
log_probs/max                         -2.15470     0.01572    -2.13898    -2.17043
log_probs/min                         -5.04245     0.07855    -4.96389    -5.12100
mean/mean                             0.00344      0.00008    0.00352     0.00337
mean/std                              0.00230      0.00003    0.00234     0.00227
mean/max                              0.00904      0.00002    0.00906     0.00902
mean/min                              -0.00050     0.00003    -0.00046    -0.00053
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 118 50
freq 22
sample: [9, 5, 4, 7, 3, 8, 1, 6, 2, 0]
replay_buffer._size: [18000 18000 18000 18000 18000 18000 18000 18000 18000 18000]
train_time 0.13533425331115723
eval time 0.0027408599853515625
2023-08-22 20:46:44,200 MainThread INFO: EPOCH:118
2023-08-22 20:46:44,200 MainThread INFO: Time Consumed:0.14150428771972656s
2023-08-22 20:46:44,200 MainThread INFO: Total Frames:178500s
 60%|█████▉    | 119/200 [02:07<01:29,  1.11s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1270.47611
Train_Epoch_Reward                    3377.84618
Running_Training_Average_Rewards      304.88366
Explore_Time                          0.00284
Train___Time                          0.13533
Eval____Time                          0.00274
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.95815
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.91491
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.61921
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.84509
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.27606
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.38552
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.59431
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12938.52337
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.97780
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.28734
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.81116      0.15829   7.96945     7.65287
alpha_0                               0.93114      0.00014   0.93128     0.93100
alpha_1                               0.93106      0.00014   0.93120     0.93092
alpha_2                               0.93110      0.00014   0.93124     0.93096
alpha_3                               0.93108      0.00014   0.93122     0.93094
alpha_4                               0.93109      0.00014   0.93123     0.93095
alpha_5                               0.93112      0.00014   0.93126     0.93098
alpha_6                               0.93109      0.00014   0.93123     0.93095
alpha_7                               0.93111      0.00014   0.93125     0.93097
alpha_8                               0.93109      0.00014   0.93123     0.93095
alpha_9                               0.93111      0.00014   0.93125     0.93097
Alpha_loss                            -0.47873     0.00075   -0.47798    -0.47948
Training/policy_loss                  -2.83249     0.00235   -2.83014    -2.83485
Training/qf1_loss                     1106.43390   77.46881  1183.90271  1028.96509
Training/qf2_loss                     1105.54437   77.46808  1183.01245  1028.07629
Training/pf_norm                      0.10049      0.00030   0.10079     0.10019
Training/qf1_norm                     28.37599     0.37781   28.75379    27.99818
Training/qf2_norm                     31.13405     0.37898   31.51302    30.75507
log_std/mean                          -0.12954     0.00009   -0.12944    -0.12963
log_std/std                           0.01059      0.00001   0.01060     0.01058
log_std/max                           -0.11120     0.00011   -0.11109    -0.11130
log_std/min                           -0.14708     0.00042   -0.14666    -0.14750
log_probs/mean                        -2.73429     0.00371   -2.73058    -2.73800
log_probs/std                         0.24891      0.00627   0.25518     0.24264
log_probs/max                         -2.10987     0.01636   -2.09352    -2.12623
log_probs/min                         -5.13459     0.54066   -4.59392    -5.67525
mean/mean                             0.00372      0.00005   0.00377     0.00367
mean/std                              0.00224      0.00001   0.00225     0.00223
mean/max                              0.00913      0.00002   0.00915     0.00912
mean/min                              -0.00069     0.00007   -0.00062    -0.00077
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 119 50
freq 22
sample: [5, 8, 3, 9, 1, 0, 2, 4, 7, 6]
replay_buffer._size: [18150 18150 18150 18150 18150 18150 18150 18150 18150 18150]
train_time 0.1624469757080078
eval time 0.0033152103424072266
2023-08-22 20:46:45,305 MainThread INFO: EPOCH:119
2023-08-22 20:46:45,305 MainThread INFO: Time Consumed:0.16973114013671875s
2023-08-22 20:46:45,305 MainThread INFO: Total Frames:180000s
 60%|██████    | 120/200 [02:09<01:28,  1.11s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1270.47365
Train_Epoch_Reward                    5830.63619
Running_Training_Average_Rewards      433.02578
Explore_Time                          0.00300
Train___Time                          0.16245
Eval____Time                          0.00332
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.77562
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.92595
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.66682
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.85865
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.37195
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.48491
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.68295
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12967.47047
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.96804
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.27956
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.74471      0.47376    8.21847     7.27095
alpha_0                               0.93058      0.00014    0.93072     0.93044
alpha_1                               0.93050      0.00014    0.93064     0.93036
alpha_2                               0.93054      0.00014    0.93068     0.93040
alpha_3                               0.93052      0.00014    0.93066     0.93038
alpha_4                               0.93053      0.00014    0.93067     0.93039
alpha_5                               0.93056      0.00014    0.93070     0.93042
alpha_6                               0.93053      0.00014    0.93067     0.93039
alpha_7                               0.93055      0.00014    0.93069     0.93041
alpha_8                               0.93053      0.00014    0.93067     0.93039
alpha_9                               0.93055      0.00014    0.93069     0.93041
Alpha_loss                            -0.48273     0.00092    -0.48181    -0.48365
Training/policy_loss                  -2.83587     0.00033    -2.83554    -2.83620
Training/qf1_loss                     1134.51694   206.59525  1341.11218  927.92169
Training/qf2_loss                     1133.66565   206.49512  1340.16077  927.17053
Training/pf_norm                      0.08527      0.01485    0.10011     0.07042
Training/qf1_norm                     28.43314     1.20057    29.63371    27.23257
Training/qf2_norm                     31.04389     1.53568    32.57956    29.50821
log_std/mean                          -0.12993     0.00009    -0.12984    -0.13002
log_std/std                           0.01060      0.00001    0.01060     0.01059
log_std/max                           -0.11142     0.00013    -0.11129    -0.11155
log_std/min                           -0.14786     0.00011    -0.14774    -0.14797
log_probs/mean                        -2.73361     0.00128    -2.73233    -2.73489
log_probs/std                         0.22553      0.00520    0.23073     0.22033
log_probs/max                         -2.14214     0.01336    -2.12878    -2.15550
log_probs/min                         -4.25398     0.17662    -4.07736    -4.43061
mean/mean                             0.00384      0.00001    0.00384     0.00383
mean/std                              0.00227      0.00002    0.00229     0.00225
mean/max                              0.00930      0.00006    0.00935     0.00924
mean/min                              -0.00111     0.00012    -0.00099    -0.00123
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 120 50
freq 22
sample: [3, 5, 6, 2, 1, 9, 4, 7, 8, 0]
replay_buffer._size: [18300 18300 18300 18300 18300 18300 18300 18300 18300 18300]
train_time 0.14203166961669922
eval time 0.0031194686889648438
2023-08-22 20:46:46,268 MainThread INFO: EPOCH:120
2023-08-22 20:46:46,268 MainThread INFO: Time Consumed:0.14854145050048828s
2023-08-22 20:46:46,268 MainThread INFO: Total Frames:181500s
 60%|██████    | 121/200 [02:09<01:23,  1.06s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1272.51311
Train_Epoch_Reward                    1982.97269
Running_Training_Average_Rewards      373.04850
Explore_Time                          0.00282
Train___Time                          0.14203
Eval____Time                          0.00312
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.24093
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.94881
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70617
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.86178
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43741
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.55394
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.74648
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13007.98381
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.96919
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.24672
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.37721      0.15444   7.53165     7.22277
alpha_0                               0.93002      0.00014   0.93016     0.92988
alpha_1                               0.92994      0.00014   0.93008     0.92980
alpha_2                               0.92998      0.00014   0.93012     0.92984
alpha_3                               0.92996      0.00014   0.93010     0.92982
alpha_4                               0.92997      0.00014   0.93011     0.92983
alpha_5                               0.93000      0.00014   0.93014     0.92986
alpha_6                               0.92997      0.00014   0.93011     0.92983
alpha_7                               0.92999      0.00014   0.93013     0.92985
alpha_8                               0.92998      0.00014   0.93011     0.92984
alpha_9                               0.92999      0.00014   0.93013     0.92985
Alpha_loss                            -0.48668     0.00123   -0.48545    -0.48791
Training/policy_loss                  -2.83836     0.00375   -2.83461    -2.84211
Training/qf1_loss                     1073.33533   28.37878  1101.71411  1044.95654
Training/qf2_loss                     1072.52051   28.41821  1100.93872  1044.10229
Training/pf_norm                      0.09036      0.00041   0.09077     0.08995
Training/qf1_norm                     27.57527     0.48344   28.05870    27.09183
Training/qf2_norm                     30.04880     0.34557   30.39436    29.70323
log_std/mean                          -0.13024     0.00008   -0.13016    -0.13032
log_std/std                           0.01059      0.00000   0.01059     0.01059
log_std/max                           -0.11168     0.00012   -0.11156    -0.11181
log_std/min                           -0.14849     0.00028   -0.14821    -0.14877
log_probs/mean                        -2.73217     0.00304   -2.72913    -2.73521
log_probs/std                         0.24671      0.00342   0.25012     0.24329
log_probs/max                         -2.10367     0.01029   -2.09338    -2.11396
log_probs/min                         -5.39155     0.55495   -4.83660    -5.94650
mean/mean                             0.00381      0.00003   0.00384     0.00379
mean/std                              0.00235      0.00002   0.00236     0.00233
mean/max                              0.00938      0.00003   0.00941     0.00935
mean/min                              -0.00156     0.00011   -0.00145    -0.00167
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 121 50
freq 22
sample: [7, 0, 5, 9, 6, 8, 3, 4, 2, 1]
replay_buffer._size: [18450 18450 18450 18450 18450 18450 18450 18450 18450 18450]
train_time 0.12434673309326172
eval time 0.0025835037231445312
2023-08-22 20:46:47,480 MainThread INFO: EPOCH:121
2023-08-22 20:46:47,481 MainThread INFO: Time Consumed:0.13106918334960938s
2023-08-22 20:46:47,481 MainThread INFO: Total Frames:183000s
 61%|██████    | 122/200 [02:11<01:26,  1.11s/it]------------------------------------  -----------  -------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1275.87978
Train_Epoch_Reward                    9989.52270
Running_Training_Average_Rewards      593.43772
Explore_Time                          0.00343
Train___Time                          0.12435
Eval____Time                          0.00258
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.67436
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.97319
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.73241
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.85425
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45500
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.57753
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76668
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13042.88039
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.98055
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20130
mean_success_rate                     0.00000

Name                                  Mean         Std      Max         Min
Reward_Mean                           7.39140      0.01334  7.40474     7.37806
alpha_0                               0.92946      0.00014  0.92960     0.92932
alpha_1                               0.92938      0.00014  0.92952     0.92924
alpha_2                               0.92942      0.00014  0.92956     0.92928
alpha_3                               0.92940      0.00014  0.92954     0.92926
alpha_4                               0.92941      0.00014  0.92955     0.92927
alpha_5                               0.92944      0.00014  0.92958     0.92930
alpha_6                               0.92941      0.00014  0.92955     0.92927
alpha_7                               0.92943      0.00014  0.92957     0.92929
alpha_8                               0.92942      0.00014  0.92956     0.92928
alpha_9                               0.92943      0.00014  0.92957     0.92929
Alpha_loss                            -0.49086     0.00101  -0.48984    -0.49187
Training/policy_loss                  -2.84445     0.00123  -2.84323    -2.84568
Training/qf1_loss                     1019.22049   0.06113  1019.28162  1019.15936
Training/qf2_loss                     1018.33331   0.12726  1018.46057  1018.20605
Training/pf_norm                      0.08465      0.00836  0.09301     0.07629
Training/qf1_norm                     27.71721     0.06880  27.78601    27.64840
Training/qf2_norm                     30.42369     0.16274  30.58643    30.26095
log_std/mean                          -0.13051     0.00005  -0.13045    -0.13056
log_std/std                           0.01057      0.00000  0.01057     0.01057
log_std/max                           -0.11200     0.00001  -0.11199    -0.11201
log_std/min                           -0.14878     0.00004  -0.14874    -0.14882
log_probs/mean                        -2.73389     0.00002  -2.73387    -2.73391
log_probs/std                         0.25505      0.01308  0.26813     0.24197
log_probs/max                         -2.10951     0.03863  -2.07088    -2.14814
log_probs/min                         -5.48203     0.44486  -5.03717    -5.92688
mean/mean                             0.00370      0.00002  0.00373     0.00368
mean/std                              0.00245      0.00003  0.00248     0.00242
mean/max                              0.00930      0.00003  0.00934     0.00927
mean/min                              -0.00212     0.00015  -0.00198    -0.00227
------------------------------------  -----------  -------  ----------  ----------
epoch, update_end_epoch 122 50
freq 22
sample: [9, 3, 2, 8, 5, 0, 4, 1, 6, 7]
replay_buffer._size: [18600 18600 18600 18600 18600 18600 18600 18600 18600 18600]
train_time 0.1471419334411621
eval time 0.00237274169921875
2023-08-22 20:46:48,625 MainThread INFO: EPOCH:122
2023-08-22 20:46:48,625 MainThread INFO: Time Consumed:0.15282130241394043s
2023-08-22 20:46:48,625 MainThread INFO: Total Frames:184500s
 62%|██████▏   | 123/200 [02:12<01:25,  1.11s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1278.74474
Train_Epoch_Reward                    5083.31110
Running_Training_Average_Rewards      568.52688
Explore_Time                          0.00268
Train___Time                          0.14714
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.81914
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.01605
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.72878
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.85726
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44049
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.56753
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.75288
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13054.75961
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.01364
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15900
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.80922      0.30567   7.11489    6.50355
alpha_0                               0.92890      0.00014   0.92904    0.92876
alpha_1                               0.92882      0.00014   0.92896    0.92868
alpha_2                               0.92886      0.00014   0.92900    0.92872
alpha_3                               0.92885      0.00014   0.92899    0.92871
alpha_4                               0.92885      0.00014   0.92899    0.92871
alpha_5                               0.92888      0.00014   0.92902    0.92874
alpha_6                               0.92885      0.00014   0.92899    0.92871
alpha_7                               0.92887      0.00014   0.92901    0.92873
alpha_8                               0.92886      0.00014   0.92900    0.92872
alpha_9                               0.92887      0.00014   0.92901    0.92873
Alpha_loss                            -0.49518     0.00182   -0.49335   -0.49700
Training/policy_loss                  -2.85183     0.01152   -2.84032   -2.86335
Training/qf1_loss                     869.59381    40.00024  909.59406  829.59357
Training/qf2_loss                     868.80240    40.07309  908.87549  828.72931
Training/pf_norm                      0.10488      0.01589   0.12078    0.08899
Training/qf1_norm                     26.30135     1.07135   27.37269   25.23000
Training/qf2_norm                     28.67959     0.81780   29.49739   27.86179
log_std/mean                          -0.13070     0.00005   -0.13065   -0.13074
log_std/std                           0.01052      0.00002   0.01054    0.01050
log_std/max                           -0.11218     0.00004   -0.11214   -0.11222
log_std/min                           -0.14894     0.00022   -0.14872   -0.14916
log_probs/mean                        -2.73749     0.01102   -2.72647   -2.74852
log_probs/std                         0.22889      0.00717   0.23606    0.22173
log_probs/max                         -2.14926     0.00114   -2.14811   -2.15040
log_probs/min                         -4.40707     0.29942   -4.10765   -4.70650
mean/mean                             0.00366      0.00001   0.00366    0.00365
mean/std                              0.00251      0.00000   0.00251    0.00251
mean/max                              0.00919      0.00006   0.00925    0.00914
mean/min                              -0.00249     0.00004   -0.00245   -0.00253
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 123 50
freq 22
sample: [4, 3, 2, 8, 6, 7, 1, 0, 9, 5]
replay_buffer._size: [18750 18750 18750 18750 18750 18750 18750 18750 18750 18750]
train_time 0.1356356143951416
eval time 0.002882719039916992
2023-08-22 20:46:49,778 MainThread INFO: EPOCH:123
2023-08-22 20:46:49,779 MainThread INFO: Time Consumed:0.14166736602783203s
2023-08-22 20:46:49,779 MainThread INFO: Total Frames:186000s
 62%|██████▏   | 124/200 [02:13<01:25,  1.13s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1280.19807
Train_Epoch_Reward                    13955.83450
Running_Training_Average_Rewards      967.62228
Explore_Time                          0.00250
Train___Time                          0.13564
Eval____Time                          0.00288
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.55705
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05571
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.72660
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.86810
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44046
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.56857
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.75166
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13062.01552
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.05106
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.12408
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.46701      0.05143    8.51843     8.41558
alpha_0                               0.92834      0.00014    0.92848     0.92820
alpha_1                               0.92826      0.00014    0.92840     0.92812
alpha_2                               0.92830      0.00014    0.92844     0.92816
alpha_3                               0.92829      0.00014    0.92843     0.92815
alpha_4                               0.92829      0.00014    0.92843     0.92815
alpha_5                               0.92832      0.00014    0.92846     0.92818
alpha_6                               0.92829      0.00014    0.92843     0.92816
alpha_7                               0.92832      0.00014    0.92845     0.92818
alpha_8                               0.92830      0.00014    0.92844     0.92816
alpha_9                               0.92831      0.00014    0.92845     0.92817
Alpha_loss                            -0.49910     0.00151    -0.49759    -0.50061
Training/policy_loss                  -2.85462     0.00731    -2.84731    -2.86193
Training/qf1_loss                     1306.59888   130.42920  1437.02808  1176.16968
Training/qf2_loss                     1305.59375   130.31958  1435.91333  1175.27417
Training/pf_norm                      0.08726      0.00708    0.09434     0.08017
Training/qf1_norm                     31.26985     0.04760    31.31745    31.22226
Training/qf2_norm                     34.34507     0.42274    34.76781    33.92234
log_std/mean                          -0.13090     0.00005    -0.13086    -0.13095
log_std/std                           0.01047      0.00001    0.01048     0.01047
log_std/max                           -0.11247     0.00010    -0.11237    -0.11257
log_std/min                           -0.14963     0.00038    -0.14925    -0.15000
log_probs/mean                        -2.73577     0.00668    -2.72910    -2.74245
log_probs/std                         0.22908      0.01308    0.24216     0.21599
log_probs/max                         -2.12176     0.00879    -2.11297    -2.13054
log_probs/min                         -4.32380     0.23183    -4.09197    -4.55562
mean/mean                             0.00371      0.00001    0.00372     0.00370
mean/std                              0.00251      0.00001    0.00252     0.00250
mean/max                              0.00904      0.00005    0.00909     0.00899
mean/min                              -0.00261     0.00002    -0.00259    -0.00263
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 124 50
freq 22
sample: [6, 2, 9, 1, 4, 3, 7, 5, 0, 8]
replay_buffer._size: [18900 18900 18900 18900 18900 18900 18900 18900 18900 18900]
train_time 0.1281435489654541
eval time 0.002595663070678711
2023-08-22 20:46:50,903 MainThread INFO: EPOCH:124
2023-08-22 20:46:50,903 MainThread INFO: Time Consumed:0.13473153114318848s
2023-08-22 20:46:50,903 MainThread INFO: Total Frames:187500s
 62%|██████▎   | 125/200 [02:14<01:24,  1.12s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1279.99473
Train_Epoch_Reward                    819.21492
Running_Training_Average_Rewards      661.94535
Explore_Time                          0.00346
Train___Time                          0.12814
Eval____Time                          0.00260
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.22925
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.07075
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.72159
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.88525
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44538
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.58025
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76252
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13041.46059
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07249
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.12834
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.56844      0.43645    8.00489     7.13199
alpha_0                               0.92778      0.00014    0.92792     0.92764
alpha_1                               0.92771      0.00014    0.92784     0.92757
alpha_2                               0.92774      0.00014    0.92788     0.92760
alpha_3                               0.92773      0.00014    0.92787     0.92759
alpha_4                               0.92773      0.00014    0.92787     0.92759
alpha_5                               0.92776      0.00014    0.92790     0.92762
alpha_6                               0.92774      0.00014    0.92788     0.92760
alpha_7                               0.92776      0.00014    0.92790     0.92762
alpha_8                               0.92774      0.00014    0.92788     0.92760
alpha_9                               0.92775      0.00014    0.92789     0.92761
Alpha_loss                            -0.50297     0.00128    -0.50169    -0.50425
Training/policy_loss                  -2.85725     0.00518    -2.85207    -2.86244
Training/qf1_loss                     1169.56854   237.50458  1407.07312  932.06396
Training/qf2_loss                     1168.58908   237.41605  1406.00513  931.17303
Training/pf_norm                      0.10985      0.03018    0.14003     0.07966
Training/qf1_norm                     28.77501     1.31410    30.08911    27.46091
Training/qf2_norm                     31.75657     1.60787    33.36444    30.14869
log_std/mean                          -0.13103     0.00002    -0.13100    -0.13105
log_std/std                           0.01043      0.00003    0.01045     0.01040
log_std/max                           -0.11265     0.00005    -0.11259    -0.11270
log_std/min                           -0.14942     0.00001    -0.14942    -0.14943
log_probs/mean                        -2.73331     0.00355    -2.72976    -2.73686
log_probs/std                         0.23157      0.00018    0.23175     0.23140
log_probs/max                         -2.11666     0.00735    -2.10931    -2.12401
log_probs/min                         -4.56251     0.05349    -4.50902    -4.61600
mean/mean                             0.00382      0.00004    0.00386     0.00378
mean/std                              0.00252      0.00003    0.00255     0.00249
mean/max                              0.00875      0.00004    0.00879     0.00870
mean/min                              -0.00266     0.00004    -0.00262    -0.00270
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 125 50
freq 22
sample: [2, 3, 8, 0, 9, 6, 4, 1, 7, 5]
replay_buffer._size: [19050 19050 19050 19050 19050 19050 19050 19050 19050 19050]
train_time 0.14917325973510742
eval time 0.0033583641052246094
2023-08-22 20:46:52,098 MainThread INFO: EPOCH:125
2023-08-22 20:46:52,098 MainThread INFO: Time Consumed:0.4713785648345947s
2023-08-22 20:46:52,098 MainThread INFO: Total Frames:189000s
 63%|██████▎   | 126/200 [02:15<01:24,  1.14s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1278.62814
Train_Epoch_Reward                    18189.40079
Running_Training_Average_Rewards      1098.81501
Explore_Time                          0.31816
Train___Time                          0.14917
Eval____Time                          0.00336
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.07211
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.08024
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70934
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.92375
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47479
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.61083
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.79376
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13010.32149
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.08959
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15990
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.68348      0.51269    8.19617     7.17079
alpha_0                               0.92722      0.00014    0.92736     0.92708
alpha_1                               0.92715      0.00014    0.92729     0.92701
alpha_2                               0.92718      0.00014    0.92732     0.92705
alpha_3                               0.92717      0.00014    0.92731     0.92703
alpha_4                               0.92717      0.00014    0.92731     0.92704
alpha_5                               0.92720      0.00014    0.92734     0.92707
alpha_6                               0.92718      0.00014    0.92732     0.92704
alpha_7                               0.92720      0.00014    0.92734     0.92706
alpha_8                               0.92718      0.00014    0.92732     0.92704
alpha_9                               0.92719      0.00014    0.92733     0.92705
Alpha_loss                            -0.50689     0.00126    -0.50563    -0.50815
Training/policy_loss                  -2.86027     0.00436    -2.85591    -2.86463
Training/qf1_loss                     1142.33221   135.51923  1277.85144  1006.81299
Training/qf2_loss                     1141.34924   135.40454  1276.75378  1005.94470
Training/pf_norm                      0.08718      0.01457    0.10175     0.07261
Training/qf1_norm                     29.34745     1.43823    30.78568    27.90923
Training/qf2_norm                     32.32392     1.82173    34.14565    30.50218
log_std/mean                          -0.13114     0.00005    -0.13109    -0.13120
log_std/std                           0.01036      0.00001    0.01037     0.01035
log_std/max                           -0.11280     0.00001    -0.11279    -0.11281
log_std/min                           -0.14948     0.00012    -0.14935    -0.14960
log_probs/mean                        -2.73153     0.00327    -2.72826    -2.73480
log_probs/std                         0.24151      0.00696    0.24847     0.23455
log_probs/max                         -2.10149     0.01823    -2.08326    -2.11973
log_probs/min                         -4.93476     0.32366    -4.61109    -5.25842
mean/mean                             0.00398      0.00004    0.00402     0.00395
mean/std                              0.00259      0.00000    0.00260     0.00259
mean/max                              0.00871      0.00001    0.00872     0.00870
mean/min                              -0.00267     0.00005    -0.00262    -0.00272
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 126 50
freq 22
sample: [4, 9, 6, 8, 3, 1, 2, 0, 7, 5]
replay_buffer._size: [19200 19200 19200 19200 19200 19200 19200 19200 19200 19200]
train_time 0.13809776306152344
eval time 0.0025687217712402344
2023-08-22 20:46:53,258 MainThread INFO: EPOCH:126
2023-08-22 20:46:53,258 MainThread INFO: Time Consumed:0.14460134506225586s
2023-08-22 20:46:53,258 MainThread INFO: Total Frames:190500s
 64%|██████▎   | 127/200 [02:16<01:24,  1.15s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1277.39511
Train_Epoch_Reward                    7223.25051
Running_Training_Average_Rewards      874.39554
Explore_Time                          0.00318
Train___Time                          0.13810
Eval____Time                          0.00257
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.17652
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.08331
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70548
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.93268
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47876
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.61416
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.79789
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13012.92942
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.09471
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16447
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.87895      0.30146    8.18041     7.57749
alpha_0                               0.92667      0.00014    0.92681     0.92653
alpha_1                               0.92659      0.00014    0.92673     0.92645
alpha_2                               0.92663      0.00014    0.92677     0.92649
alpha_3                               0.92661      0.00014    0.92675     0.92647
alpha_4                               0.92662      0.00014    0.92676     0.92648
alpha_5                               0.92665      0.00014    0.92679     0.92651
alpha_6                               0.92662      0.00014    0.92676     0.92648
alpha_7                               0.92664      0.00014    0.92678     0.92650
alpha_8                               0.92662      0.00014    0.92676     0.92648
alpha_9                               0.92664      0.00014    0.92678     0.92650
Alpha_loss                            -0.51091     0.00011    -0.51080    -0.51101
Training/policy_loss                  -2.86432     0.00974    -2.85459    -2.87406
Training/qf1_loss                     1157.16061   150.92935  1308.08997  1006.23126
Training/qf2_loss                     1156.24600   150.89279  1307.13879  1005.35321
Training/pf_norm                      0.08249      0.00143    0.08392     0.08106
Training/qf1_norm                     30.35600     0.95270    31.30869    29.40330
Training/qf2_norm                     33.08633     1.08050    34.16684    32.00583
log_std/mean                          -0.13141     0.00008    -0.13132    -0.13149
log_std/std                           0.01034      0.00000    0.01034     0.01033
log_std/max                           -0.11305     0.00002    -0.11302    -0.11307
log_std/min                           -0.14969     0.00026    -0.14943    -0.14995
log_probs/mean                        -2.73116     0.01195    -2.71921    -2.74311
log_probs/std                         0.26117      0.04838    0.30955     0.21279
log_probs/max                         -2.12276     0.00475    -2.11801    -2.12751
log_probs/min                         -6.19788     1.80991    -4.38797    -8.00779
mean/mean                             0.00410      0.00002    0.00412     0.00408
mean/std                              0.00261      0.00001    0.00262     0.00260
mean/max                              0.00876      0.00002    0.00878     0.00873
mean/min                              -0.00254     0.00002    -0.00253    -0.00256
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 127 50
freq 22
sample: [0, 9, 2, 6, 8, 7, 5, 3, 4, 1]
replay_buffer._size: [19350 19350 19350 19350 19350 19350 19350 19350 19350 19350]
train_time 0.14124727249145508
eval time 0.0029611587524414062
2023-08-22 20:46:54,535 MainThread INFO: EPOCH:127
2023-08-22 20:46:54,535 MainThread INFO: Time Consumed:0.14826416969299316s
2023-08-22 20:46:54,535 MainThread INFO: Total Frames:192000s
 64%|██████▍   | 128/200 [02:18<01:25,  1.19s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1276.34205
Train_Epoch_Reward                    6093.98039
Running_Training_Average_Rewards      1050.22106
Explore_Time                          0.00324
Train___Time                          0.14125
Eval____Time                          0.00296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.41295
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05373
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70104
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.92617
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47362
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.60119
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.78484
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13007.18136
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07630
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.17878
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.26989      0.42763   7.69752     6.84226
alpha_0                               0.92611      0.00014   0.92625     0.92597
alpha_1                               0.92603      0.00014   0.92617     0.92589
alpha_2                               0.92607      0.00014   0.92621     0.92593
alpha_3                               0.92606      0.00014   0.92620     0.92592
alpha_4                               0.92606      0.00014   0.92620     0.92592
alpha_5                               0.92609      0.00014   0.92623     0.92595
alpha_6                               0.92606      0.00014   0.92620     0.92592
alpha_7                               0.92609      0.00014   0.92622     0.92595
alpha_8                               0.92607      0.00014   0.92621     0.92593
alpha_9                               0.92608      0.00014   0.92622     0.92594
Alpha_loss                            -0.51571     0.00092   -0.51478    -0.51663
Training/policy_loss                  -2.87791     0.00063   -2.87729    -2.87854
Training/qf1_loss                     1044.88586   89.22668  1134.11255  955.65918
Training/qf2_loss                     1043.94690   89.26562  1133.21252  954.68127
Training/pf_norm                      0.11653      0.01524   0.13177     0.10129
Training/qf1_norm                     28.64497     1.42005   30.06503    27.22492
Training/qf2_norm                     31.45264     1.28333   32.73597    30.16932
log_std/mean                          -0.13162     0.00004   -0.13159    -0.13166
log_std/std                           0.01028      0.00002   0.01030     0.01027
log_std/max                           -0.11320     0.00002   -0.11318    -0.11323
log_std/min                           -0.14978     0.00004   -0.14975    -0.14982
log_probs/mean                        -2.74094     0.00117   -2.73977    -2.74211
log_probs/std                         0.23343      0.00057   0.23399     0.23286
log_probs/max                         -2.10955     0.03055   -2.07900    -2.14010
log_probs/min                         -4.91123     0.19399   -4.71724    -5.10522
mean/mean                             0.00418      0.00003   0.00421     0.00415
mean/std                              0.00267      0.00001   0.00268     0.00265
mean/max                              0.00891      0.00005   0.00896     0.00886
mean/min                              -0.00252     0.00005   -0.00247    -0.00257
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 128 50
freq 22
sample: [9, 3, 8, 7, 6, 5, 0, 1, 4, 2]
replay_buffer._size: [19500 19500 19500 19500 19500 19500 19500 19500 19500 19500]
train_time 0.13115954399108887
eval time 0.0022203922271728516
2023-08-22 20:46:55,724 MainThread INFO: EPOCH:128
2023-08-22 20:46:55,724 MainThread INFO: Time Consumed:0.1367800235748291s
2023-08-22 20:46:55,725 MainThread INFO: Total Frames:193500s
 64%|██████▍   | 129/200 [02:19<01:24,  1.20s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1276.84023
Train_Epoch_Reward                    10914.89224
Running_Training_Average_Rewards      807.73744
Explore_Time                          0.00262
Train___Time                          0.13116
Eval____Time                          0.00222
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.56455
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.03221
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.71233
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.91294
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47617
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.59794
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.78366
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13026.66793
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07073
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16466
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.56642      0.45605    8.02247     7.11036
alpha_0                               0.92555      0.00014    0.92569     0.92541
alpha_1                               0.92547      0.00014    0.92561     0.92534
alpha_2                               0.92551      0.00014    0.92565     0.92537
alpha_3                               0.92550      0.00014    0.92564     0.92536
alpha_4                               0.92550      0.00014    0.92564     0.92536
alpha_5                               0.92553      0.00014    0.92567     0.92539
alpha_6                               0.92551      0.00014    0.92564     0.92537
alpha_7                               0.92553      0.00014    0.92567     0.92539
alpha_8                               0.92551      0.00014    0.92565     0.92537
alpha_9                               0.92552      0.00014    0.92566     0.92538
Alpha_loss                            -0.51959     0.00106    -0.51852    -0.52065
Training/policy_loss                  -2.88122     0.00249    -2.87873    -2.88370
Training/qf1_loss                     1087.75165   184.80206  1272.55371  902.94958
Training/qf2_loss                     1086.68292   184.80304  1271.48596  901.87988
Training/pf_norm                      0.11059      0.01774    0.12833     0.09285
Training/qf1_norm                     29.55984     1.51244    31.07228    28.04741
Training/qf2_norm                     32.78487     1.49860    34.28346    31.28627
log_std/mean                          -0.13170     0.00001    -0.13170    -0.13171
log_std/std                           0.01021      0.00002    0.01023     0.01019
log_std/max                           -0.11342     0.00002    -0.11340    -0.11344
log_std/min                           -0.15001     0.00001    -0.15000    -0.15003
log_probs/mean                        -2.73865     0.00064    -2.73801    -2.73929
log_probs/std                         0.23405      0.00596    0.24001     0.22809
log_probs/max                         -2.18328     0.00119    -2.18209    -2.18447
log_probs/min                         -4.56637     0.21047    -4.35590    -4.77684
mean/mean                             0.00425      0.00003    0.00428     0.00422
mean/std                              0.00270      0.00001    0.00271     0.00269
mean/max                              0.00886      0.00009    0.00895     0.00877
mean/min                              -0.00242     0.00005    -0.00237    -0.00247
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 129 50
freq 22
sample: [9, 6, 3, 4, 8, 7, 1, 0, 2, 5]
replay_buffer._size: [19650 19650 19650 19650 19650 19650 19650 19650 19650 19650]
train_time 0.15392446517944336
eval time 0.003052949905395508
2023-08-22 20:46:57,083 MainThread INFO: EPOCH:129
2023-08-22 20:46:57,083 MainThread INFO: Time Consumed:0.16091442108154297s
2023-08-22 20:46:57,083 MainThread INFO: Total Frames:195000s
 65%|██████▌   | 130/200 [02:20<01:26,  1.24s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1277.40750
Train_Epoch_Reward                    14594.16046
Running_Training_Average_Rewards      1053.43444
Explore_Time                          0.00321
Train___Time                          0.15392
Eval____Time                          0.00305
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.95362
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.01003
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70649
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.89839
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.45610
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.57331
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76367
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13030.48389
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.06341
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.15934
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.30685      0.31212   7.61897     6.99474
alpha_0                               0.92499      0.00014   0.92513     0.92485
alpha_1                               0.92492      0.00014   0.92506     0.92478
alpha_2                               0.92496      0.00014   0.92510     0.92482
alpha_3                               0.92494      0.00014   0.92508     0.92480
alpha_4                               0.92494      0.00014   0.92508     0.92481
alpha_5                               0.92498      0.00014   0.92511     0.92484
alpha_6                               0.92495      0.00014   0.92509     0.92481
alpha_7                               0.92497      0.00014   0.92511     0.92483
alpha_8                               0.92495      0.00014   0.92509     0.92482
alpha_9                               0.92497      0.00014   0.92511     0.92483
Alpha_loss                            -0.52303     0.00127   -0.52176    -0.52430
Training/policy_loss                  -2.87825     0.00492   -2.87333    -2.88318
Training/qf1_loss                     1016.30780   81.25055  1097.55835  935.05725
Training/qf2_loss                     1015.29852   81.21747  1096.51599  934.08105
Training/pf_norm                      0.09046      0.00658   0.09704     0.08387
Training/qf1_norm                     29.03769     1.02408   30.06177    28.01361
Training/qf2_norm                     32.05813     1.12196   33.18009    30.93616
log_std/mean                          -0.13164     0.00004   -0.13160    -0.13168
log_std/std                           0.01014      0.00003   0.01016     0.01011
log_std/max                           -0.11346     0.00002   -0.11344    -0.11348
log_std/min                           -0.14988     0.00008   -0.14980    -0.14996
log_probs/mean                        -2.73077     0.00332   -2.72745    -2.73409
log_probs/std                         0.22500      0.00229   0.22729     0.22270
log_probs/max                         -2.14279     0.01030   -2.13249    -2.15309
log_probs/min                         -4.77086     0.39595   -4.37491    -5.16680
mean/mean                             0.00438      0.00003   0.00442     0.00435
mean/std                              0.00265      0.00001   0.00266     0.00264
mean/max                              0.00858      0.00003   0.00861     0.00855
mean/min                              -0.00220     0.00006   -0.00213    -0.00226
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 130 50
freq 22
sample: [1, 9, 4, 5, 6, 8, 7, 3, 2, 0]
replay_buffer._size: [19800 19800 19800 19800 19800 19800 19800 19800 19800 19800]
train_time 0.13343501091003418
eval time 0.0022301673889160156
2023-08-22 20:46:58,176 MainThread INFO: EPOCH:130
2023-08-22 20:46:58,176 MainThread INFO: Time Consumed:0.13965129852294922s
2023-08-22 20:46:58,176 MainThread INFO: Total Frames:196500s
 66%|██████▌   | 131/200 [02:21<01:22,  1.19s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1276.76595
Train_Epoch_Reward                    18355.89470
Running_Training_Average_Rewards      1462.16491
Explore_Time                          0.00338
Train___Time                          0.13344
Eval____Time                          0.00223
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.56074
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.01264
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.68351
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.94846
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.49007
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.60704
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.79948
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12983.11567
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.08055
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20696
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.95086      0.30027    8.25112     7.65059
alpha_0                               0.92444      0.00014    0.92458     0.92430
alpha_1                               0.92436      0.00014    0.92450     0.92422
alpha_2                               0.92440      0.00014    0.92454     0.92426
alpha_3                               0.92438      0.00014    0.92452     0.92425
alpha_4                               0.92439      0.00014    0.92453     0.92425
alpha_5                               0.92442      0.00014    0.92456     0.92428
alpha_6                               0.92439      0.00014    0.92453     0.92425
alpha_7                               0.92442      0.00014    0.92456     0.92428
alpha_8                               0.92440      0.00014    0.92454     0.92426
alpha_9                               0.92441      0.00014    0.92455     0.92427
Alpha_loss                            -0.52699     0.00133    -0.52566    -0.52832
Training/policy_loss                  -2.88233     0.00477    -2.87755    -2.88710
Training/qf1_loss                     1210.83331   110.13251  1320.96582  1100.70081
Training/qf2_loss                     1209.74091   109.90717  1319.64807  1099.83374
Training/pf_norm                      0.10683      0.03579    0.14263     0.07104
Training/qf1_norm                     31.24625     0.70882    31.95506    30.53743
Training/qf2_norm                     34.52685     1.45231    35.97916    33.07454
log_std/mean                          -0.13149     0.00003    -0.13145    -0.13152
log_std/std                           0.01005      0.00002    0.01007     0.01002
log_std/max                           -0.11354     0.00005    -0.11349    -0.11359
log_std/min                           -0.15001     0.00000    -0.15001    -0.15001
log_probs/mean                        -2.72962     0.00404    -2.72557    -2.73366
log_probs/std                         0.22654      0.00443    0.23098     0.22211
log_probs/max                         -2.12755     0.03154    -2.09600    -2.15909
log_probs/min                         -4.33469     0.13656    -4.19813    -4.47126
mean/mean                             0.00449      0.00002    0.00452     0.00447
mean/std                              0.00263      0.00001    0.00264     0.00262
mean/max                              0.00885      0.00008    0.00893     0.00877
mean/min                              -0.00204     0.00005    -0.00199    -0.00209
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 131 50
freq 22
sample: [8, 5, 4, 3, 1, 0, 2, 6, 9, 7]
replay_buffer._size: [19950 19950 19950 19950 19950 19950 19950 19950 19950 19950]
train_time 0.13020658493041992
eval time 0.0026946067810058594
2023-08-22 20:46:59,417 MainThread INFO: EPOCH:131
2023-08-22 20:46:59,417 MainThread INFO: Time Consumed:0.13597702980041504s
2023-08-22 20:46:59,417 MainThread INFO: Total Frames:198000s
 66%|██████▌   | 132/200 [02:23<01:21,  1.20s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1274.10985
Train_Epoch_Reward                    27929.73538
Running_Training_Average_Rewards      2029.32635
Explore_Time                          0.00256
Train___Time                          0.13021
Eval____Time                          0.00269
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.28119
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.01046
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.67449
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.98571
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.53226
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.64478
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83314
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12948.95564
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.08909
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.23485
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.94782      0.27710   8.22492     7.67072
alpha_0                               0.92388      0.00014   0.92402     0.92374
alpha_1                               0.92381      0.00014   0.92394     0.92367
alpha_2                               0.92385      0.00014   0.92398     0.92371
alpha_3                               0.92383      0.00014   0.92397     0.92369
alpha_4                               0.92383      0.00014   0.92397     0.92369
alpha_5                               0.92386      0.00014   0.92400     0.92372
alpha_6                               0.92384      0.00014   0.92398     0.92370
alpha_7                               0.92386      0.00014   0.92400     0.92372
alpha_8                               0.92384      0.00014   0.92398     0.92370
alpha_9                               0.92385      0.00014   0.92399     0.92371
Alpha_loss                            -0.53174     0.00107   -0.53067    -0.53281
Training/policy_loss                  -2.89508     0.00203   -2.89304    -2.89711
Training/qf1_loss                     1332.30383   98.79773  1431.10156  1233.50610
Training/qf2_loss                     1331.24329   98.87292  1430.11621  1232.37036
Training/pf_norm                      0.09611      0.00770   0.10381     0.08841
Training/qf1_norm                     31.55596     1.11434   32.67030    30.44162
Training/qf2_norm                     34.70897     0.85258   35.56156    33.85639
log_std/mean                          -0.13135     0.00001   -0.13135    -0.13136
log_std/std                           0.00994      0.00001   0.00996     0.00993
log_std/max                           -0.11380     0.00001   -0.11379    -0.11380
log_std/min                           -0.14920     0.00013   -0.14907    -0.14932
log_probs/mean                        -2.73854     0.00068   -2.73786    -2.73922
log_probs/std                         0.24164      0.00182   0.24346     0.23983
log_probs/max                         -2.17558     0.01598   -2.15960    -2.19156
log_probs/min                         -4.85326     0.05578   -4.79748    -4.90904
mean/mean                             0.00455      0.00001   0.00456     0.00453
mean/std                              0.00268      0.00001   0.00269     0.00267
mean/max                              0.00910      0.00007   0.00917     0.00904
mean/min                              -0.00208     0.00001   -0.00207    -0.00209
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 132 50
freq 22
sample: [2, 1, 3, 5, 4, 7, 6, 8, 9, 0]
replay_buffer._size: [20100 20100 20100 20100 20100 20100 20100 20100 20100 20100]
train_time 0.1384587287902832
eval time 0.002360105514526367
2023-08-22 20:47:00,639 MainThread INFO: EPOCH:132
2023-08-22 20:47:00,640 MainThread INFO: Time Consumed:0.14391827583312988s
2023-08-22 20:47:00,640 MainThread INFO: Total Frames:199500s
 66%|██████▋   | 133/200 [02:24<01:20,  1.21s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1270.24821
Train_Epoch_Reward                    18039.24538
Running_Training_Average_Rewards      2144.16252
Explore_Time                          0.00249
Train___Time                          0.13846
Eval____Time                          0.00236
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.11909
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.02614
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.66209
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.02355
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.57131
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.67717
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.86000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12923.34784
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.11058
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.24734
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.84668      0.37764    8.22432     7.46904
alpha_0                               0.92333      0.00014    0.92346     0.92319
alpha_1                               0.92325      0.00014    0.92339     0.92311
alpha_2                               0.92329      0.00014    0.92343     0.92315
alpha_3                               0.92327      0.00014    0.92341     0.92313
alpha_4                               0.92328      0.00014    0.92342     0.92314
alpha_5                               0.92331      0.00014    0.92345     0.92317
alpha_6                               0.92328      0.00014    0.92342     0.92314
alpha_7                               0.92331      0.00014    0.92345     0.92317
alpha_8                               0.92329      0.00014    0.92343     0.92315
alpha_9                               0.92330      0.00014    0.92344     0.92316
Alpha_loss                            -0.53541     0.00170    -0.53372    -0.53711
Training/policy_loss                  -2.89617     0.01022    -2.88595    -2.90639
Training/qf1_loss                     1140.68439   113.83441  1254.51880  1026.84998
Training/qf2_loss                     1139.43469   113.76025  1253.19495  1025.67444
Training/pf_norm                      0.09576      0.02214    0.11790     0.07363
Training/qf1_norm                     31.15297     0.95506    32.10804    30.19791
Training/qf2_norm                     34.90215     1.20264    36.10478    33.69951
log_std/mean                          -0.13145     0.00006    -0.13140    -0.13151
log_std/std                           0.00988      0.00001    0.00989     0.00987
log_std/max                           -0.11389     0.00005    -0.11383    -0.11394
log_std/min                           -0.14963     0.00026    -0.14937    -0.14990
log_probs/mean                        -2.73373     0.00861    -2.72512    -2.74233
log_probs/std                         0.23426      0.02353    0.25779     0.21074
log_probs/max                         -2.10756     0.02173    -2.08584    -2.12929
log_probs/min                         -5.05090     0.89548    -4.15542    -5.94638
mean/mean                             0.00468      0.00007    0.00475     0.00462
mean/std                              0.00275      0.00003    0.00279     0.00272
mean/max                              0.00959      0.00018    0.00977     0.00942
mean/min                              -0.00202     0.00004    -0.00198    -0.00206
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 133 50
freq 22
sample: [4, 7, 9, 6, 5, 0, 1, 2, 8, 3]
replay_buffer._size: [20250 20250 20250 20250 20250 20250 20250 20250 20250 20250]
train_time 0.1466367244720459
eval time 0.0023450851440429688
2023-08-22 20:47:01,947 MainThread INFO: EPOCH:133
2023-08-22 20:47:01,947 MainThread INFO: Time Consumed:0.15211772918701172s
2023-08-22 20:47:01,947 MainThread INFO: Total Frames:201000s
 67%|██████▋   | 134/200 [02:25<01:21,  1.24s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1266.92441
Train_Epoch_Reward                    17012.87380
Running_Training_Average_Rewards      2099.39515
Explore_Time                          0.00261
Train___Time                          0.14664
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.74645
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.04457
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.65054
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.06639
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.61952
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.72373
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.90779
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12896.17096
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.13577
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.26411
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.24560      0.24733    7.49293     6.99827
alpha_0                               0.92277      0.00014    0.92291     0.92263
alpha_1                               0.92269      0.00014    0.92283     0.92256
alpha_2                               0.92273      0.00014    0.92287     0.92260
alpha_3                               0.92272      0.00014    0.92286     0.92258
alpha_4                               0.92272      0.00014    0.92286     0.92258
alpha_5                               0.92275      0.00014    0.92289     0.92261
alpha_6                               0.92273      0.00014    0.92286     0.92259
alpha_7                               0.92275      0.00014    0.92289     0.92261
alpha_8                               0.92273      0.00014    0.92287     0.92259
alpha_9                               0.92274      0.00014    0.92288     0.92260
Alpha_loss                            -0.53898     0.00057    -0.53841    -0.53955
Training/policy_loss                  -2.89704     0.00369    -2.89335    -2.90074
Training/qf1_loss                     952.88306    154.80713  1107.69019  798.07593
Training/qf2_loss                     951.84570    154.79578  1106.64148  797.04993
Training/pf_norm                      0.09006      0.00992    0.09998     0.08013
Training/qf1_norm                     29.66219     0.72729    30.38948    28.93491
Training/qf2_norm                     32.71334     0.76153    33.47486    31.95181
log_std/mean                          -0.13165     0.00006    -0.13159    -0.13171
log_std/std                           0.00983      0.00001    0.00984     0.00982
log_std/max                           -0.11411     0.00001    -0.11410    -0.11413
log_std/min                           -0.14942     0.00008    -0.14935    -0.14950
log_probs/mean                        -2.72769     0.00551    -2.72217    -2.73320
log_probs/std                         0.22767      0.00969    0.23736     0.21798
log_probs/max                         -2.14344     0.00813    -2.13531    -2.15157
log_probs/min                         -4.41250     0.06843    -4.34408    -4.48093
mean/mean                             0.00487      0.00002    0.00489     0.00485
mean/std                              0.00284      0.00001    0.00285     0.00283
mean/max                              0.01015      0.00008    0.01023     0.01007
mean/min                              -0.00184     0.00004    -0.00180    -0.00188
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 134 50
freq 22
sample: [4, 5, 6, 2, 9, 8, 3, 7, 1, 0]
replay_buffer._size: [20400 20400 20400 20400 20400 20400 20400 20400 20400 20400]
train_time 0.13623523712158203
eval time 0.0023775100708007812
2023-08-22 20:47:03,319 MainThread INFO: EPOCH:134
2023-08-22 20:47:05,205 MainThread INFO: Time Consumed:0.14170265197753906s
2023-08-22 20:47:05,205 MainThread INFO: Total Frames:202500s
 68%|██████▊   | 135/200 [02:28<02:00,  1.85s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1264.59082
Train_Epoch_Reward                    17641.87578
Running_Training_Average_Rewards      1756.46650
Explore_Time                          0.00254
Train___Time                          0.13624
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.30752
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.04427
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.64653
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.10294
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.67511
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.77536
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.95685
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12877.60280
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.14192
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.29035
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.18946      0.12862   8.31808     8.06085
alpha_0                               0.92222      0.00014   0.92235     0.92208
alpha_1                               0.92214      0.00014   0.92228     0.92200
alpha_2                               0.92218      0.00014   0.92232     0.92204
alpha_3                               0.92216      0.00014   0.92230     0.92202
alpha_4                               0.92217      0.00014   0.92230     0.92203
alpha_5                               0.92220      0.00014   0.92234     0.92206
alpha_6                               0.92217      0.00014   0.92231     0.92203
alpha_7                               0.92220      0.00014   0.92234     0.92206
alpha_8                               0.92218      0.00014   0.92232     0.92204
alpha_9                               0.92219      0.00014   0.92233     0.92205
Alpha_loss                            -0.54320     0.00099   -0.54221    -0.54419
Training/policy_loss                  -2.90365     0.00053   -2.90312    -2.90418
Training/qf1_loss                     1275.52545   13.93329  1289.45874  1261.59216
Training/qf2_loss                     1274.43304   13.88654  1288.31958  1260.54651
Training/pf_norm                      0.08533      0.00926   0.09459     0.07606
Training/qf1_norm                     33.23529     0.55790   33.79319    32.67739
Training/qf2_norm                     36.44647     0.41405   36.86052    36.03241
log_std/mean                          -0.13186     0.00005   -0.13181    -0.13191
log_std/std                           0.00978      0.00002   0.00979     0.00976
log_std/max                           -0.11437     0.00008   -0.11429    -0.11444
log_std/min                           -0.14959     0.00011   -0.14948    -0.14970
log_probs/mean                        -2.72988     0.00027   -2.72961    -2.73015
log_probs/std                         0.23558      0.01488   0.25047     0.22070
log_probs/max                         -2.11810     0.05219   -2.06591    -2.17030
log_probs/min                         -5.02026     0.75482   -4.26544    -5.77508
mean/mean                             0.00488      0.00000   0.00488     0.00488
mean/std                              0.00292      0.00002   0.00294     0.00290
mean/max                              0.01049      0.00009   0.01058     0.01041
mean/min                              -0.00177     0.00002   -0.00175    -0.00178
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 135 50
freq 22
sample: [6, 2, 8, 4, 3, 9, 7, 1, 0, 5]
replay_buffer._size: [20550 20550 20550 20550 20550 20550 20550 20550 20550 20550]
train_time 0.13267970085144043
eval time 0.0020678043365478516
2023-08-22 20:47:05,450 MainThread INFO: EPOCH:135
2023-08-22 20:47:05,450 MainThread INFO: Time Consumed:0.1380627155303955s
2023-08-22 20:47:05,450 MainThread INFO: Total Frames:204000s
 68%|██████▊   | 136/200 [02:29<01:27,  1.37s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1262.61722
Train_Epoch_Reward                    11203.87263
Running_Training_Average_Rewards      1528.62074
Explore_Time                          0.00261
Train___Time                          0.13268
Eval____Time                          0.00207
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.28113
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.04954
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.61820
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.12855
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.68289
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.77842
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.95691
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12857.81790
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.16450
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.31518
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.31652      0.67521    7.99173     6.64131
alpha_0                               0.92166      0.00014    0.92180     0.92152
alpha_1                               0.92158      0.00014    0.92172     0.92145
alpha_2                               0.92163      0.00014    0.92176     0.92149
alpha_3                               0.92161      0.00014    0.92175     0.92147
alpha_4                               0.92161      0.00014    0.92175     0.92147
alpha_5                               0.92164      0.00014    0.92178     0.92150
alpha_6                               0.92162      0.00014    0.92176     0.92148
alpha_7                               0.92164      0.00014    0.92178     0.92150
alpha_8                               0.92162      0.00014    0.92176     0.92148
alpha_9                               0.92163      0.00014    0.92177     0.92149
Alpha_loss                            -0.54779     0.00156    -0.54623    -0.54934
Training/policy_loss                  -2.91557     0.00694    -2.90863    -2.92251
Training/qf1_loss                     1003.74011   217.71667  1221.45679  786.02344
Training/qf2_loss                     1002.60583   217.70532  1220.31116  784.90051
Training/pf_norm                      0.08799      0.01710    0.10509     0.07090
Training/qf1_norm                     30.30635     2.29700    32.60335    28.00936
Training/qf2_norm                     33.63646     2.35202    35.98848    31.28444
log_std/mean                          -0.13202     0.00006    -0.13197    -0.13208
log_std/std                           0.00971      0.00002    0.00973     0.00969
log_std/max                           -0.11471     0.00007    -0.11464    -0.11478
log_std/min                           -0.14940     0.00003    -0.14937    -0.14944
log_probs/mean                        -2.73648     0.00668    -2.72980    -2.74316
log_probs/std                         0.24292      0.00297    0.24589     0.23996
log_probs/max                         -2.13728     0.05819    -2.07909    -2.19547
log_probs/min                         -4.96697     0.27303    -4.69394    -5.24001
mean/mean                             0.00488      0.00002    0.00489     0.00486
mean/std                              0.00302      0.00003    0.00305     0.00300
mean/max                              0.01091      0.00007    0.01098     0.01083
mean/min                              -0.00164     0.00002    -0.00162    -0.00166
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 136 50
freq 22
sample: [6, 8, 3, 4, 1, 9, 0, 5, 7, 2]
replay_buffer._size: [20700 20700 20700 20700 20700 20700 20700 20700 20700 20700]
train_time 0.1282820701599121
eval time 0.0024116039276123047
2023-08-22 20:47:06,724 MainThread INFO: EPOCH:136
2023-08-22 20:47:06,725 MainThread INFO: Time Consumed:0.13423728942871094s
2023-08-22 20:47:06,725 MainThread INFO: Total Frames:205500s
 68%|██████▊   | 137/200 [02:30<01:24,  1.34s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1260.24560
Train_Epoch_Reward                    22163.65984
Running_Training_Average_Rewards      1700.31361
Explore_Time                          0.00276
Train___Time                          0.12828
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.01114
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05126
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.57857
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.15203
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.67153
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.76184
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.93932
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12827.55737
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.18433
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34378
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.80046      0.67386    8.47432     7.12661
alpha_0                               0.92111      0.00014    0.92124     0.92097
alpha_1                               0.92103      0.00014    0.92117     0.92089
alpha_2                               0.92107      0.00014    0.92121     0.92093
alpha_3                               0.92105      0.00014    0.92119     0.92092
alpha_4                               0.92106      0.00014    0.92119     0.92092
alpha_5                               0.92109      0.00014    0.92123     0.92095
alpha_6                               0.92106      0.00014    0.92120     0.92092
alpha_7                               0.92109      0.00014    0.92123     0.92095
alpha_8                               0.92107      0.00014    0.92121     0.92093
alpha_9                               0.92108      0.00014    0.92122     0.92094
Alpha_loss                            -0.55167     0.00051    -0.55116    -0.55218
Training/policy_loss                  -2.91915     0.00447    -2.91468    -2.92361
Training/qf1_loss                     1175.83847   239.70450  1415.54297  936.13397
Training/qf2_loss                     1174.60620   239.54565  1414.15186  935.06055
Training/pf_norm                      0.12589      0.01110    0.13700     0.11479
Training/qf1_norm                     32.08257     2.01702    34.09959    30.06555
Training/qf2_norm                     35.72858     2.52745    38.25603    33.20114
log_std/mean                          -0.13220     0.00002    -0.13218    -0.13222
log_std/std                           0.00963      0.00003    0.00966     0.00961
log_std/max                           -0.11487     0.00008    -0.11479    -0.11495
log_std/min                           -0.14976     0.00013    -0.14963    -0.14988
log_probs/mean                        -2.73445     0.00619    -2.72825    -2.74064
log_probs/std                         0.24894      0.00447    0.25342     0.24447
log_probs/max                         -2.13713     0.04483    -2.09230    -2.18197
log_probs/min                         -5.72159     0.04057    -5.68103    -5.76216
mean/mean                             0.00482      0.00002    0.00484     0.00480
mean/std                              0.00318      0.00004    0.00322     0.00314
mean/max                              0.01139      0.00013    0.01152     0.01126
mean/min                              -0.00156     0.00002    -0.00154    -0.00158
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 137 50
freq 22
sample: [9, 8, 3, 7, 1, 4, 6, 2, 0, 5]
replay_buffer._size: [20850 20850 20850 20850 20850 20850 20850 20850 20850 20850]
train_time 0.12027907371520996
eval time 0.0022661685943603516
2023-08-22 20:47:07,904 MainThread INFO: EPOCH:137
2023-08-22 20:47:07,904 MainThread INFO: Time Consumed:0.12562179565429688s
2023-08-22 20:47:07,904 MainThread INFO: Total Frames:207000s
 69%|██████▉   | 138/200 [02:31<01:19,  1.29s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1256.95339
Train_Epoch_Reward                    14168.95880
Running_Training_Average_Rewards      1584.54971
Explore_Time                          0.00244
Train___Time                          0.12028
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.59330
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.07184
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.52115
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.18611
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.65421
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.73614
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.91502
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12785.17119
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.22131
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.37659
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.96187      0.06910   8.03097     7.89277
alpha_0                               0.92055      0.00014   0.92069     0.92041
alpha_1                               0.92048      0.00014   0.92062     0.92034
alpha_2                               0.92052      0.00014   0.92066     0.92038
alpha_3                               0.92050      0.00014   0.92064     0.92036
alpha_4                               0.92050      0.00014   0.92064     0.92036
alpha_5                               0.92054      0.00014   0.92067     0.92040
alpha_6                               0.92051      0.00014   0.92065     0.92037
alpha_7                               0.92054      0.00014   0.92067     0.92040
alpha_8                               0.92052      0.00014   0.92065     0.92038
alpha_9                               0.92052      0.00014   0.92066     0.92039
Alpha_loss                            -0.55520     0.00027   -0.55493    -0.55547
Training/policy_loss                  -2.91784     0.00689   -2.91096    -2.92473
Training/qf1_loss                     1188.74976   52.49414  1241.24390  1136.25562
Training/qf2_loss                     1187.57202   52.60364  1240.17566  1134.96838
Training/pf_norm                      0.10805      0.00541   0.11346     0.10263
Training/qf1_norm                     33.11160     0.03871   33.15031    33.07289
Training/qf2_norm                     36.55724     0.29994   36.85717    36.25730
log_std/mean                          -0.13243     0.00006   -0.13237    -0.13249
log_std/std                           0.00958      0.00000   0.00959     0.00958
log_std/max                           -0.11513     0.00007   -0.11506    -0.11520
log_std/min                           -0.15004     0.00018   -0.14987    -0.15022
log_probs/mean                        -2.72812     0.00896   -2.71915    -2.73708
log_probs/std                         0.23384      0.00538   0.23922     0.22846
log_probs/max                         -2.13417     0.02026   -2.11391    -2.15443
log_probs/min                         -5.53879     0.43857   -5.10022    -5.97735
mean/mean                             0.00470      0.00002   0.00472     0.00469
mean/std                              0.00334      0.00005   0.00340     0.00329
mean/max                              0.01176      0.00009   0.01186     0.01167
mean/min                              -0.00170     0.00007   -0.00163    -0.00177
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 138 50
freq 22
sample: [0, 4, 1, 8, 6, 9, 5, 2, 7, 3]
replay_buffer._size: [21000 21000 21000 21000 21000 21000 21000 21000 21000 21000]
train_time 0.13140153884887695
eval time 0.002429962158203125
2023-08-22 20:47:09,191 MainThread INFO: EPOCH:138
2023-08-22 20:47:09,191 MainThread INFO: Time Consumed:0.13773798942565918s
2023-08-22 20:47:09,192 MainThread INFO: Total Frames:208500s
 70%|██████▉   | 139/200 [02:32<01:18,  1.29s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1253.78806
Train_Epoch_Reward                    8557.48683
Running_Training_Average_Rewards      1496.33685
Explore_Time                          0.00316
Train___Time                          0.13140
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.33274
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.06980
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46777
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.17412
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.58427
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.65567
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83762
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12768.61376
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.23841
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.37071
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.79111      0.20177    7.99289     7.58934
alpha_0                               0.92000      0.00014    0.92014     0.91986
alpha_1                               0.91992      0.00014    0.92006     0.91979
alpha_2                               0.91997      0.00014    0.92010     0.91983
alpha_3                               0.91995      0.00014    0.92008     0.91981
alpha_4                               0.91995      0.00014    0.92009     0.91981
alpha_5                               0.91998      0.00014    0.92012     0.91984
alpha_6                               0.91996      0.00014    0.92009     0.91982
alpha_7                               0.91998      0.00014    0.92012     0.91984
alpha_8                               0.91996      0.00014    0.92010     0.91982
alpha_9                               0.91997      0.00014    0.92011     0.91983
Alpha_loss                            -0.56014     0.00153    -0.55862    -0.56167
Training/policy_loss                  -2.93418     0.00728    -2.92690    -2.94145
Training/qf1_loss                     1248.70721   187.64825  1436.35547  1061.05896
Training/qf2_loss                     1247.47620   187.52502  1435.00122  1059.95117
Training/pf_norm                      0.11037      0.00596    0.11633     0.10442
Training/qf1_norm                     32.68256     0.55149    33.23405    32.13107
Training/qf2_norm                     36.27066     0.94037    37.21104    35.33029
log_std/mean                          -0.13272     0.00008    -0.13264    -0.13281
log_std/std                           0.00955      0.00000    0.00955     0.00955
log_std/max                           -0.11543     0.00002    -0.11541    -0.11545
log_std/min                           -0.15040     0.00012    -0.15027    -0.15052
log_probs/mean                        -2.73892     0.00621    -2.73272    -2.74513
log_probs/std                         0.26164      0.01410    0.27573     0.24754
log_probs/max                         -2.13134     0.01421    -2.11713    -2.14555
log_probs/min                         -5.92869     0.50605    -5.42264    -6.43473
mean/mean                             0.00465      0.00002    0.00467     0.00462
mean/std                              0.00363      0.00009    0.00372     0.00355
mean/max                              0.01232      0.00013    0.01246     0.01219
mean/min                              -0.00208     0.00013    -0.00195    -0.00221
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 139 50
freq 22
sample: [5, 2, 9, 4, 3, 8, 1, 7, 6, 0]
replay_buffer._size: [21150 21150 21150 21150 21150 21150 21150 21150 21150 21150]
train_time 0.18132734298706055
eval time 0.0032002925872802734
2023-08-22 20:47:10,390 MainThread INFO: EPOCH:139
2023-08-22 20:47:10,390 MainThread INFO: Time Consumed:0.1886141300201416s
2023-08-22 20:47:10,391 MainThread INFO: Total Frames:210000s
 70%|███████   | 140/200 [02:34<01:15,  1.26s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1253.64772
Train_Epoch_Reward                    31024.90165
Running_Training_Average_Rewards      1791.71158
Explore_Time                          0.00328
Train___Time                          0.18133
Eval____Time                          0.00320
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.34365
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05101
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.45278
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.12343
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.50870
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.56672
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.75189
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12813.00103
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.23882
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.31051
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.80146      0.28009   8.08155     7.52137
alpha_0                               0.91944      0.00014   0.91958     0.91931
alpha_1                               0.91937      0.00014   0.91951     0.91923
alpha_2                               0.91941      0.00014   0.91955     0.91927
alpha_3                               0.91939      0.00014   0.91953     0.91926
alpha_4                               0.91939      0.00014   0.91953     0.91926
alpha_5                               0.91943      0.00014   0.91957     0.91929
alpha_6                               0.91940      0.00014   0.91954     0.91926
alpha_7                               0.91943      0.00014   0.91957     0.91929
alpha_8                               0.91941      0.00014   0.91955     0.91927
alpha_9                               0.91942      0.00014   0.91956     0.91928
Alpha_loss                            -0.56362     0.00058   -0.56304    -0.56419
Training/policy_loss                  -2.93348     0.00398   -2.92950    -2.93746
Training/qf1_loss                     1029.00787   62.25848  1091.26636  966.74939
Training/qf2_loss                     1027.74487   62.27661  1090.02148  965.46826
Training/pf_norm                      0.07522      0.00610   0.08132     0.06912
Training/qf1_norm                     32.83725     0.93288   33.77012    31.90437
Training/qf2_norm                     36.53547     0.88585   37.42132    35.64962
log_std/mean                          -0.13318     0.00011   -0.13307    -0.13330
log_std/std                           0.00955      0.00000   0.00956     0.00955
log_std/max                           -0.11576     0.00011   -0.11565    -0.11586
log_std/min                           -0.15084     0.00019   -0.15065    -0.15103
log_probs/mean                        -2.73200     0.00519   -2.72681    -2.73719
log_probs/std                         0.22692      0.00787   0.23479     0.21905
log_probs/max                         -2.16642     0.05853   -2.10789    -2.22495
log_probs/min                         -4.87701     0.30669   -4.57032    -5.18370
mean/mean                             0.00457      0.00002   0.00459     0.00455
mean/std                              0.00395      0.00006   0.00401     0.00389
mean/max                              0.01278      0.00008   0.01286     0.01270
mean/min                              -0.00255     0.00009   -0.00246    -0.00264
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 140 50
freq 22
sample: [6, 2, 7, 9, 5, 4, 1, 3, 8, 0]
replay_buffer._size: [21300 21300 21300 21300 21300 21300 21300 21300 21300 21300]
train_time 0.12581467628479004
eval time 0.002334117889404297
2023-08-22 20:47:11,730 MainThread INFO: EPOCH:140
2023-08-22 20:47:11,730 MainThread INFO: Time Consumed:0.13120317459106445s
2023-08-22 20:47:11,730 MainThread INFO: Total Frames:211500s
 70%|███████   | 141/200 [02:35<01:15,  1.28s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1256.95045
Train_Epoch_Reward                    9264.13841
Running_Training_Average_Rewards      1628.21756
Explore_Time                          0.00251
Train___Time                          0.12581
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.62339
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.05322
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.44285
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.07959
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44893
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.49663
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.68836
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12872.30951
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.25994
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.23921
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.08964      0.37838    8.46802     7.71126
alpha_0                               0.91889      0.00014    0.91903     0.91875
alpha_1                               0.91882      0.00014    0.91896     0.91868
alpha_2                               0.91886      0.00014    0.91900     0.91872
alpha_3                               0.91884      0.00014    0.91898     0.91870
alpha_4                               0.91884      0.00014    0.91898     0.91870
alpha_5                               0.91888      0.00014    0.91902     0.91874
alpha_6                               0.91885      0.00014    0.91899     0.91871
alpha_7                               0.91888      0.00014    0.91901     0.91874
alpha_8                               0.91886      0.00014    0.91899     0.91872
alpha_9                               0.91886      0.00014    0.91900     0.91873
Alpha_loss                            -0.56784     0.00090    -0.56694    -0.56873
Training/policy_loss                  -2.94058     0.00087    -2.93971    -2.94145
Training/qf1_loss                     1241.68634   133.82233  1375.50867  1107.86401
Training/qf2_loss                     1240.53766   133.78009  1374.31775  1106.75757
Training/pf_norm                      0.10944      0.00411    0.11355     0.10533
Training/qf1_norm                     34.43771     1.22636    35.66407    33.21135
Training/qf2_norm                     37.76683     1.36619    39.13302    36.40064
log_std/mean                          -0.13359     0.00009    -0.13350    -0.13368
log_std/std                           0.00953      0.00001    0.00954     0.00952
log_std/max                           -0.11613     0.00018    -0.11595    -0.11631
log_std/min                           -0.15107     0.00015    -0.15092    -0.15122
log_probs/mean                        -2.73404     0.00139    -2.73265    -2.73542
log_probs/std                         0.24835      0.00102    0.24937     0.24733
log_probs/max                         -2.16524     0.01063    -2.15461    -2.17587
log_probs/min                         -5.43417     0.25656    -5.17761    -5.69073
mean/mean                             0.00455      0.00002    0.00458     0.00453
mean/std                              0.00422      0.00007    0.00429     0.00415
mean/max                              0.01315      0.00013    0.01329     0.01302
mean/min                              -0.00291     0.00010    -0.00281    -0.00301
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 141 50
freq 22
sample: [2, 7, 5, 4, 9, 3, 0, 8, 6, 1]
replay_buffer._size: [21450 21450 21450 21450 21450 21450 21450 21450 21450 21450]
train_time 0.16535353660583496
eval time 0.0030317306518554688
2023-08-22 20:47:12,999 MainThread INFO: EPOCH:141
2023-08-22 20:47:12,999 MainThread INFO: Time Consumed:0.17172670364379883s
2023-08-22 20:47:12,999 MainThread INFO: Total Frames:213000s
 71%|███████   | 142/200 [02:36<01:14,  1.29s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1261.99839
Train_Epoch_Reward                    19420.16526
Running_Training_Average_Rewards      1990.30684
Explore_Time                          0.00273
Train___Time                          0.16535
Eval____Time                          0.00303
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.99327
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.03835
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.43768
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.03840
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.39477
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.43050
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.62713
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12917.72184
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.26123
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.17980
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.44164      0.56054    8.00218     6.88110
alpha_0                               0.91834      0.00014    0.91848     0.91820
alpha_1                               0.91826      0.00014    0.91840     0.91813
alpha_2                               0.91831      0.00014    0.91845     0.91817
alpha_3                               0.91829      0.00014    0.91843     0.91815
alpha_4                               0.91829      0.00014    0.91843     0.91815
alpha_5                               0.91833      0.00014    0.91846     0.91819
alpha_6                               0.91830      0.00014    0.91844     0.91816
alpha_7                               0.91832      0.00014    0.91846     0.91819
alpha_8                               0.91830      0.00014    0.91844     0.91817
alpha_9                               0.91831      0.00014    0.91845     0.91817
Alpha_loss                            -0.57152     0.00139    -0.57013    -0.57291
Training/policy_loss                  -2.94345     0.00550    -2.93795    -2.94895
Training/qf1_loss                     1102.12402   138.24121  1240.36523  963.88281
Training/qf2_loss                     1100.88733   138.13879  1239.02612  962.74854
Training/pf_norm                      0.08372      0.01147    0.09518     0.07225
Training/qf1_norm                     32.13854     1.93772    34.07626    30.20082
Training/qf2_norm                     35.72532     2.25002    37.97535    33.47530
log_std/mean                          -0.13398     0.00008    -0.13390    -0.13406
log_std/std                           0.00948      0.00002    0.00950     0.00946
log_std/max                           -0.11677     0.00013    -0.11664    -0.11690
log_std/min                           -0.15133     0.00009    -0.15124    -0.15142
log_probs/mean                        -2.72971     0.00443    -2.72528    -2.73414
log_probs/std                         0.24235      0.00039    0.24274     0.24196
log_probs/max                         -2.15788     0.01436    -2.14352    -2.17224
log_probs/min                         -5.01994     0.14720    -4.87274    -5.16714
mean/mean                             0.00458      0.00001    0.00459     0.00458
mean/std                              0.00446      0.00004    0.00451     0.00442
mean/max                              0.01357      0.00009    0.01366     0.01348
mean/min                              -0.00318     0.00003    -0.00315    -0.00321
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 142 50
freq 22
sample: [3, 2, 9, 6, 5, 4, 7, 8, 1, 0]
replay_buffer._size: [21600 21600 21600 21600 21600 21600 21600 21600 21600 21600]
train_time 0.1237187385559082
eval time 0.0031812191009521484
2023-08-22 20:47:14,292 MainThread INFO: EPOCH:142
2023-08-22 20:47:14,292 MainThread INFO: Time Consumed:0.12999391555786133s
2023-08-22 20:47:14,292 MainThread INFO: Total Frames:214500s
 72%|███████▏  | 143/200 [02:37<01:12,  1.28s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1267.26661
Train_Epoch_Reward                    4269.31778
Running_Training_Average_Rewards      1098.45405
Explore_Time                          0.00258
Train___Time                          0.12372
Eval____Time                          0.00318
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.39445
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.01053
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.44836
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.99640
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.35425
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.38184
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.58344
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12967.23455
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.24124
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.12391
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.99826      0.23305   8.23131     7.76521
alpha_0                               0.91779      0.00014   0.91792     0.91765
alpha_1                               0.91771      0.00014   0.91785     0.91757
alpha_2                               0.91776      0.00014   0.91789     0.91762
alpha_3                               0.91774      0.00014   0.91787     0.91760
alpha_4                               0.91774      0.00014   0.91788     0.91760
alpha_5                               0.91778      0.00014   0.91791     0.91764
alpha_6                               0.91775      0.00014   0.91788     0.91761
alpha_7                               0.91777      0.00014   0.91791     0.91763
alpha_8                               0.91775      0.00014   0.91789     0.91761
alpha_9                               0.91776      0.00014   0.91790     0.91762
Alpha_loss                            -0.57553     0.00094   -0.57459    -0.57647
Training/policy_loss                  -2.94940     0.00048   -2.94893    -2.94988
Training/qf1_loss                     1125.34009   34.99622  1160.33630  1090.34387
Training/qf2_loss                     1124.10040   34.86151  1158.96191  1089.23889
Training/pf_norm                      0.10242      0.00929   0.11172     0.09313
Training/qf1_norm                     34.40264     0.52308   34.92572    33.87955
Training/qf2_norm                     37.97177     0.93575   38.90753    37.03602
log_std/mean                          -0.13430     0.00009   -0.13421    -0.13440
log_std/std                           0.00943      0.00000   0.00944     0.00943
log_std/max                           -0.11722     0.00014   -0.11709    -0.11736
log_std/min                           -0.15152     0.00007   -0.15145    -0.15158
log_probs/mean                        -2.72927     0.00079   -2.72848    -2.73007
log_probs/std                         0.24508      0.00879   0.25387     0.23629
log_probs/max                         -2.15578     0.00232   -2.15347    -2.15810
log_probs/min                         -5.11794     0.06112   -5.05682    -5.17905
mean/mean                             0.00461      0.00000   0.00461     0.00460
mean/std                              0.00464      0.00002   0.00466     0.00461
mean/max                              0.01380      0.00003   0.01383     0.01377
mean/min                              -0.00329     0.00003   -0.00326    -0.00332
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 143 50
freq 22
sample: [0, 4, 2, 1, 6, 7, 9, 5, 8, 3]
replay_buffer._size: [21750 21750 21750 21750 21750 21750 21750 21750 21750 21750]
train_time 0.47234606742858887
eval time 0.0025777816772460938
2023-08-22 20:47:15,776 MainThread INFO: EPOCH:143
2023-08-22 20:47:15,776 MainThread INFO: Time Consumed:0.4774916172027588s
2023-08-22 20:47:15,776 MainThread INFO: Total Frames:216000s
 72%|███████▏  | 144/200 [02:39<01:15,  1.35s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1271.10391
Train_Epoch_Reward                    2573.80800
Running_Training_Average_Rewards      875.44303
Explore_Time                          0.00187
Train___Time                          0.47235
Eval____Time                          0.00258
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.26776
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.97926
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.45261
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.96335
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31130
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.33215
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.53952
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12994.24705
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.21520
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.08957
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.22337      0.05590   7.27927    7.16747
alpha_0                               0.91723      0.00014   0.91737    0.91710
alpha_1                               0.91716      0.00014   0.91730    0.91702
alpha_2                               0.91721      0.00014   0.91734    0.91707
alpha_3                               0.91718      0.00014   0.91732    0.91705
alpha_4                               0.91719      0.00014   0.91732    0.91705
alpha_5                               0.91722      0.00014   0.91736    0.91709
alpha_6                               0.91719      0.00014   0.91733    0.91706
alpha_7                               0.91722      0.00014   0.91736    0.91708
alpha_8                               0.91720      0.00014   0.91734    0.91706
alpha_9                               0.91721      0.00014   0.91735    0.91707
Alpha_loss                            -0.57903     0.00114   -0.57789   -0.58017
Training/policy_loss                  -2.94889     0.00346   -2.94543   -2.95235
Training/qf1_loss                     946.81827    30.84933  977.66760  915.96893
Training/qf2_loss                     945.70807    30.87311  976.58118  914.83496
Training/pf_norm                      0.10824      0.01710   0.12534    0.09114
Training/qf1_norm                     32.08358     0.17888   32.26246   31.90470
Training/qf2_norm                     35.23393     0.26738   35.50132   34.96655
log_std/mean                          -0.13468     0.00009   -0.13459   -0.13477
log_std/std                           0.00941      0.00002   0.00942    0.00939
log_std/max                           -0.11737     0.00007   -0.11729   -0.11744
log_std/min                           -0.15186     0.00014   -0.15172   -0.15199
log_probs/mean                        -2.72295     0.00154   -2.72142   -2.72449
log_probs/std                         0.22493      0.00442   0.22935    0.22052
log_probs/max                         -2.12568     0.00006   -2.12562   -2.12574
log_probs/min                         -4.48269     0.06932   -4.41337   -4.55200
mean/mean                             0.00454      0.00001   0.00456    0.00453
mean/std                              0.00472      0.00001   0.00473    0.00471
mean/max                              0.01354      0.00011   0.01365    0.01342
mean/min                              -0.00339     0.00002   -0.00337   -0.00341
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 144 50
freq 22
sample: [8, 9, 1, 6, 0, 2, 4, 5, 3, 7]
replay_buffer._size: [21874 21861 21838 21873 21868 21841 21847 21885 21860 21858]
train_time 1.4382266998291016
eval time 0.002290010452270508
2023-08-22 20:47:17,338 MainThread INFO: EPOCH:144
2023-08-22 20:47:17,338 MainThread INFO: Time Consumed:1.4428765773773193s
2023-08-22 20:47:17,338 MainThread INFO: Total Frames:217500s
 72%|███████▎  | 145/200 [02:41<01:17,  1.41s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1274.53288
Train_Epoch_Reward                    7091.46443
Running_Training_Average_Rewards      464.48634
Explore_Time                          0.00181
Train___Time                          1.43823
Eval____Time                          0.00229
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.21047
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.93403
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.46393
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.90974
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25435
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.27167
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.48491
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13024.93349
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.16941
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.04489
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.32352      0.53562   7.85913     6.78790
alpha_0                               0.91668      0.00014   0.91682     0.91655
alpha_1                               0.91661      0.00014   0.91675     0.91647
alpha_2                               0.91665      0.00014   0.91679     0.91652
alpha_3                               0.91663      0.00014   0.91677     0.91650
alpha_4                               0.91663      0.00014   0.91677     0.91650
alpha_5                               0.91667      0.00014   0.91681     0.91654
alpha_6                               0.91664      0.00014   0.91678     0.91651
alpha_7                               0.91667      0.00014   0.91681     0.91653
alpha_8                               0.91665      0.00014   0.91679     0.91651
alpha_9                               0.91666      0.00014   0.91679     0.91652
Alpha_loss                            -0.58342     0.00093   -0.58248    -0.58435
Training/policy_loss                  -2.95844     0.00106   -2.95738    -2.95950
Training/qf1_loss                     954.02209    95.71594  1049.73804  858.30615
Training/qf2_loss                     952.73013    95.68930  1048.41943  857.04083
Training/pf_norm                      0.08293      0.00512   0.08805     0.07781
Training/qf1_norm                     32.45773     1.85845   34.31618    30.59928
Training/qf2_norm                     36.16651     1.94664   38.11315    34.21988
log_std/mean                          -0.13505     0.00009   -0.13496    -0.13514
log_std/std                           0.00935      0.00001   0.00936     0.00933
log_std/max                           -0.11751     0.00002   -0.11749    -0.11753
log_std/min                           -0.15192     0.00020   -0.15172    -0.15213
log_probs/mean                        -2.72695     0.00088   -2.72607    -2.72783
log_probs/std                         0.21359      0.00422   0.21781     0.20937
log_probs/max                         -2.19008     0.01071   -2.17937    -2.20078
log_probs/min                         -4.24125     0.08767   -4.15358    -4.32892
mean/mean                             0.00444      0.00001   0.00445     0.00443
mean/std                              0.00477      0.00002   0.00479     0.00476
mean/max                              0.01298      0.00014   0.01312     0.01284
mean/min                              -0.00357     0.00005   -0.00352    -0.00362
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 145 50
freq 22
sample: [6, 9, 0, 7, 2, 5, 3, 4, 8, 1]
replay_buffer._size: [22050 22050 22050 22050 22050 22050 22050 22050 22050 22050]
train_time 0.13914179801940918
eval time 0.002644062042236328
2023-08-22 20:47:18,889 MainThread INFO: EPOCH:145
2023-08-22 20:47:18,889 MainThread INFO: Time Consumed:0.14622879028320312s
2023-08-22 20:47:18,889 MainThread INFO: Total Frames:219000s
 73%|███████▎  | 146/200 [02:42<01:18,  1.46s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1277.50522
Train_Epoch_Reward                    9607.78006
Running_Training_Average_Rewards      642.43508
Explore_Time                          0.00367
Train___Time                          0.13914
Eval____Time                          0.00264
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.89889
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.88663
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.48566
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.84980
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20164
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22251
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.44470
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13066.96549
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.12023
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.98525
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.69461      0.38424    8.07885     7.31036
alpha_0                               0.91613      0.00014    0.91627     0.91600
alpha_1                               0.91606      0.00014    0.91619     0.91592
alpha_2                               0.91610      0.00014    0.91624     0.91597
alpha_3                               0.91608      0.00014    0.91622     0.91594
alpha_4                               0.91608      0.00014    0.91622     0.91595
alpha_5                               0.91612      0.00014    0.91626     0.91598
alpha_6                               0.91609      0.00014    0.91623     0.91596
alpha_7                               0.91612      0.00014    0.91626     0.91598
alpha_8                               0.91610      0.00014    0.91623     0.91596
alpha_9                               0.91611      0.00014    0.91624     0.91597
Alpha_loss                            -0.58877     0.00115    -0.58762    -0.58991
Training/policy_loss                  -2.97908     0.00295    -2.97613    -2.98202
Training/qf1_loss                     1058.17703   137.08505  1195.26208  921.09198
Training/qf2_loss                     1056.86652   136.83783  1193.70435  920.02869
Training/pf_norm                      0.10071      0.03002    0.13074     0.07069
Training/qf1_norm                     34.04090     1.12741    35.16832    32.91349
Training/qf2_norm                     37.79048     1.89785    39.68833    35.89263
log_std/mean                          -0.13538     0.00010    -0.13528    -0.13548
log_std/std                           0.00932      0.00001    0.00933     0.00931
log_std/max                           -0.11769     0.00007    -0.11761    -0.11776
log_std/min                           -0.15219     0.00028    -0.15191    -0.15248
log_probs/mean                        -2.74188     0.00154    -2.74035    -2.74342
log_probs/std                         0.24023      0.00758    0.24781     0.23265
log_probs/max                         -2.17991     0.03119    -2.14871    -2.21110
log_probs/min                         -4.77138     0.06686    -4.70452    -4.83825
mean/mean                             0.00447      0.00001    0.00448     0.00446
mean/std                              0.00487      0.00003    0.00490     0.00484
mean/max                              0.01267      0.00004    0.01272     0.01263
mean/min                              -0.00365     0.00002    -0.00363    -0.00367
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 146 50
freq 22
sample: [7, 1, 8, 4, 5, 3, 6, 0, 9, 2]
replay_buffer._size: [22200 22200 22200 22200 22200 22200 22200 22200 22200 22200]
train_time 0.15111184120178223
eval time 0.0026481151580810547
2023-08-22 20:47:20,400 MainThread INFO: EPOCH:146
2023-08-22 20:47:20,400 MainThread INFO: Time Consumed:0.15732526779174805s
2023-08-22 20:47:20,400 MainThread INFO: Total Frames:220500s
 74%|███████▎  | 147/200 [02:44<01:17,  1.46s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1281.77841
Train_Epoch_Reward                    10081.39810
Running_Training_Average_Rewards      892.68809
Explore_Time                          0.00296
Train___Time                          0.15111
Eval____Time                          0.00265
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.39037
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.83737
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.52520
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.79104
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.17887
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20787
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.43723
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13118.65709
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.07129
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.92587
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.79727      0.40308    8.20035     7.39418
alpha_0                               0.91558      0.00014    0.91572     0.91545
alpha_1                               0.91551      0.00014    0.91564     0.91537
alpha_2                               0.91555      0.00014    0.91569     0.91542
alpha_3                               0.91553      0.00014    0.91567     0.91539
alpha_4                               0.91553      0.00014    0.91567     0.91540
alpha_5                               0.91557      0.00014    0.91571     0.91543
alpha_6                               0.91554      0.00014    0.91568     0.91541
alpha_7                               0.91557      0.00014    0.91570     0.91543
alpha_8                               0.91555      0.00014    0.91568     0.91541
alpha_9                               0.91556      0.00014    0.91569     0.91542
Alpha_loss                            -0.59148     0.00089    -0.59059    -0.59237
Training/policy_loss                  -2.97086     0.00058    -2.97028    -2.97143
Training/qf1_loss                     1143.73468   158.51703  1302.25171  985.21765
Training/qf2_loss                     1142.31586   158.41937  1300.73523  983.89648
Training/pf_norm                      0.08908      0.00096    0.09004     0.08812
Training/qf1_norm                     34.51052     1.45846    35.96898    33.05206
Training/qf2_norm                     38.58215     1.75462    40.33676    36.82753
log_std/mean                          -0.13563     0.00005    -0.13558    -0.13568
log_std/std                           0.00924      0.00002    0.00926     0.00923
log_std/max                           -0.11802     0.00003    -0.11798    -0.11805
log_std/min                           -0.15211     0.00022    -0.15189    -0.15234
log_probs/mean                        -2.72666     0.00141    -2.72524    -2.72807
log_probs/std                         0.22177      0.00535    0.22712     0.21642
log_probs/max                         -2.17016     0.00548    -2.16468    -2.17564
log_probs/min                         -4.45269     0.09728    -4.35541    -4.54996
mean/mean                             0.00455      0.00004    0.00459     0.00451
mean/std                              0.00495      0.00002    0.00498     0.00493
mean/max                              0.01246      0.00001    0.01247     0.01244
mean/min                              -0.00362     0.00004    -0.00358    -0.00366
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 147 50
freq 22
sample: [8, 6, 7, 0, 1, 3, 4, 2, 9, 5]
replay_buffer._size: [22350 22350 22350 22350 22350 22350 22350 22350 22350 22350]
train_time 0.12277007102966309
eval time 0.0022864341735839844
2023-08-22 20:47:21,822 MainThread INFO: EPOCH:147
2023-08-22 20:47:21,823 MainThread INFO: Time Consumed:0.12857556343078613s
2023-08-22 20:47:21,823 MainThread INFO: Total Frames:222000s
 74%|███████▍  | 148/200 [02:45<01:15,  1.45s/it]------------------------------------  -----------  -------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1286.64223
Train_Epoch_Reward                    21430.76241
Running_Training_Average_Rewards      1370.66469
Explore_Time                          0.00296
Train___Time                          0.12277
Eval____Time                          0.00229
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.86831
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.79018
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.55841
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.74271
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16297
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20253
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.43913
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13160.77289
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.02349
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.88039
mean_success_rate                     0.00000

Name                                  Mean         Std      Max        Min
Reward_Mean                           6.92038      0.14927  7.06965    6.77110
alpha_0                               0.91503      0.00014  0.91517    0.91489
alpha_1                               0.91496      0.00014  0.91509    0.91482
alpha_2                               0.91500      0.00014  0.91514    0.91487
alpha_3                               0.91498      0.00014  0.91512    0.91484
alpha_4                               0.91498      0.00014  0.91512    0.91485
alpha_5                               0.91502      0.00014  0.91516    0.91488
alpha_6                               0.91499      0.00014  0.91513    0.91486
alpha_7                               0.91502      0.00014  0.91515    0.91488
alpha_8                               0.91500      0.00014  0.91513    0.91486
alpha_9                               0.91501      0.00014  0.91514    0.91487
Alpha_loss                            -0.59672     0.00115  -0.59557   -0.59787
Training/policy_loss                  -2.99068     0.00250  -2.98819   -2.99318
Training/qf1_loss                     845.08966    0.91406  846.00372  844.17560
Training/qf2_loss                     843.90283    1.05359  844.95642  842.84924
Training/pf_norm                      0.09872      0.03305  0.13177    0.06567
Training/qf1_norm                     31.93866     0.20362  32.14228   31.73503
Training/qf2_norm                     35.26957     0.61781  35.88737   34.65176
log_std/mean                          -0.13579     0.00003  -0.13576   -0.13582
log_std/std                           0.00916      0.00002  0.00918    0.00914
log_std/max                           -0.11837     0.00010  -0.11827   -0.11847
log_std/min                           -0.15243     0.00011  -0.15232   -0.15255
log_probs/mean                        -2.74018     0.00157  -2.73861   -2.74175
log_probs/std                         0.24052      0.00057  0.24108    0.23995
log_probs/max                         -2.19614     0.03656  -2.15958   -2.23270
log_probs/min                         -5.43062     0.33687  -5.09375   -5.76749
mean/mean                             0.00479      0.00008  0.00487    0.00471
mean/std                              0.00504      0.00001  0.00505    0.00504
mean/max                              0.01251      0.00001  0.01252    0.01251
mean/min                              -0.00338     0.00010  -0.00328   -0.00348
------------------------------------  -----------  -------  ---------  ---------
epoch, update_end_epoch 148 50
freq 22
sample: [3, 2, 0, 7, 6, 9, 5, 1, 8, 4]
replay_buffer._size: [22500 22500 22500 22500 22500 22500 22500 22500 22500 22500]
train_time 0.1406724452972412
eval time 0.002825498580932617
snapshot at best
2023-08-22 20:47:24,186 MainThread INFO: EPOCH:148
2023-08-22 20:47:24,186 MainThread INFO: Time Consumed:0.7306914329528809s
2023-08-22 20:47:24,186 MainThread INFO: Total Frames:223500s
 74%|███████▍  | 149/200 [02:47<01:28,  1.73s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1291.57757
Train_Epoch_Reward                    7555.93029
Running_Training_Average_Rewards      1302.26969
Explore_Time                          0.00365
Train___Time                          0.14067
Eval____Time                          0.00283
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.01631
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.72471
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.60338
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.68642
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16087
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.21114
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.45159
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13202.58777
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.95592
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.84710
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.17685      0.18631   8.36315     7.99054
alpha_0                               0.91448      0.00014   0.91462     0.91434
alpha_1                               0.91441      0.00014   0.91454     0.91427
alpha_2                               0.91445      0.00014   0.91459     0.91431
alpha_3                               0.91443      0.00014   0.91457     0.91429
alpha_4                               0.91443      0.00014   0.91457     0.91430
alpha_5                               0.91447      0.00014   0.91461     0.91433
alpha_6                               0.91444      0.00014   0.91458     0.91431
alpha_7                               0.91447      0.00014   0.91460     0.91433
alpha_8                               0.91445      0.00014   0.91458     0.91431
alpha_9                               0.91446      0.00014   0.91459     0.91432
Alpha_loss                            -0.60015     0.00025   -0.59990    -0.60040
Training/policy_loss                  -2.98989     0.00678   -2.98310    -2.99667
Training/qf1_loss                     1287.87378   47.39844  1335.27222  1240.47534
Training/qf2_loss                     1286.57422   47.30054  1333.87476  1239.27368
Training/pf_norm                      0.10255      0.01368   0.11623     0.08888
Training/qf1_norm                     36.79783     0.47417   37.27200    36.32365
Training/qf2_norm                     40.49109     0.79060   41.28168    39.70049
log_std/mean                          -0.13593     0.00004   -0.13589    -0.13596
log_std/std                           0.00907      0.00001   0.00908     0.00906
log_std/max                           -0.11871     0.00004   -0.11868    -0.11875
log_std/min                           -0.15195     0.00018   -0.15177    -0.15213
log_probs/mean                        -2.73321     0.00856   -2.72465    -2.74177
log_probs/std                         0.23379      0.01643   0.25022     0.21736
log_probs/max                         -2.13202     0.02473   -2.10729    -2.15676
log_probs/min                         -4.99071     0.66831   -4.32240    -5.65902
mean/mean                             0.00507      0.00004   0.00511     0.00502
mean/std                              0.00511      0.00001   0.00513     0.00510
mean/max                              0.01251      0.00002   0.01254     0.01249
mean/min                              -0.00306     0.00008   -0.00298    -0.00314
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 149 50
freq 22
sample: [2, 5, 7, 0, 8, 4, 9, 3, 6, 1]
replay_buffer._size: [22650 22650 22650 22650 22650 22650 22650 22650 22650 22650]
train_time 0.14365458488464355
eval time 0.002988100051879883
snapshot at best
2023-08-22 20:47:25,790 MainThread INFO: EPOCH:149
2023-08-22 20:47:25,790 MainThread INFO: Time Consumed:0.740781307220459s
2023-08-22 20:47:25,790 MainThread INFO: Total Frames:225000s
 75%|███████▌  | 150/200 [02:49<01:24,  1.68s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1296.43211
Train_Epoch_Reward                    32411.38353
Running_Training_Average_Rewards      2046.60254
Explore_Time                          0.00288
Train___Time                          0.14365
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.50640
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.63294
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.66947
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.61921
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18201
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24097
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.48255
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13264.94372
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.86588
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.81615
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.14034      0.02598   8.16632     8.11437
alpha_0                               0.91393      0.00014   0.91407     0.91380
alpha_1                               0.91386      0.00014   0.91399     0.91372
alpha_2                               0.91390      0.00014   0.91404     0.91377
alpha_3                               0.91388      0.00014   0.91402     0.91374
alpha_4                               0.91388      0.00014   0.91402     0.91375
alpha_5                               0.91392      0.00014   0.91406     0.91378
alpha_6                               0.91389      0.00014   0.91403     0.91376
alpha_7                               0.91392      0.00014   0.91406     0.91378
alpha_8                               0.91389      0.00014   0.91403     0.91376
alpha_9                               0.91391      0.00014   0.91404     0.91377
Alpha_loss                            -0.60487     0.00033   -0.60453    -0.60520
Training/policy_loss                  -3.00370     0.00507   -2.99863    -3.00878
Training/qf1_loss                     1246.53583   13.07318  1259.60901  1233.46265
Training/qf2_loss                     1245.18018   13.02759  1258.20776  1232.15259
Training/pf_norm                      0.07149      0.00780   0.07928     0.06369
Training/qf1_norm                     36.85676     0.13390   36.99066    36.72286
Training/qf2_norm                     40.68041     0.00165   40.68206    40.67876
log_std/mean                          -0.13610     0.00005   -0.13605    -0.13615
log_std/std                           0.00899      0.00002   0.00902     0.00897
log_std/max                           -0.11884     0.00005   -0.11878    -0.11889
log_std/min                           -0.15167     0.00004   -0.15163    -0.15171
log_probs/mean                        -2.74062     0.00759   -2.73303    -2.74821
log_probs/std                         0.24460      0.01101   0.25561     0.23360
log_probs/max                         -2.16008     0.00912   -2.15096    -2.16920
log_probs/min                         -5.82004     0.13710   -5.68295    -5.95714
mean/mean                             0.00529      0.00005   0.00535     0.00524
mean/std                              0.00521      0.00003   0.00524     0.00518
mean/max                              0.01267      0.00004   0.01271     0.01263
mean/min                              -0.00288     0.00001   -0.00287    -0.00289
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 150 50
freq 22
sample: [1, 6, 7, 5, 9, 2, 3, 4, 0, 8]
replay_buffer._size: [22800 22800 22800 22800 22800 22800 22800 22800 22800 22800]
train_time 0.12568187713623047
eval time 0.0025634765625
snapshot at best
2023-08-22 20:47:27,204 MainThread INFO: EPOCH:150
2023-08-22 20:47:27,204 MainThread INFO: Time Consumed:0.6755735874176025s
2023-08-22 20:47:27,204 MainThread INFO: Total Frames:226500s
 76%|███████▌  | 151/200 [02:50<01:18,  1.61s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1301.42920
Train_Epoch_Reward                    26063.50679
Running_Training_Average_Rewards      2201.02735
Explore_Time                          0.00290
Train___Time                          0.12568
Eval____Time                          0.00256
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.21948
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.57476
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70636
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.57830
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19755
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.26273
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.50716
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13313.67592
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.81233
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.79962
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.55342      0.20660   7.76002     7.34682
alpha_0                               0.91338      0.00014   0.91352     0.91325
alpha_1                               0.91331      0.00014   0.91345     0.91317
alpha_2                               0.91335      0.00014   0.91349     0.91322
alpha_3                               0.91333      0.00014   0.91347     0.91319
alpha_4                               0.91333      0.00014   0.91347     0.91320
alpha_5                               0.91337      0.00014   0.91351     0.91323
alpha_6                               0.91334      0.00014   0.91348     0.91321
alpha_7                               0.91337      0.00014   0.91351     0.91323
alpha_8                               0.91334      0.00014   0.91348     0.91321
alpha_9                               0.91336      0.00014   0.91349     0.91322
Alpha_loss                            -0.60867     0.00087   -0.60780    -0.60954
Training/policy_loss                  -3.00867     0.00006   -3.00861    -3.00873
Training/qf1_loss                     1071.41330   97.78812  1169.20142  973.62518
Training/qf2_loss                     1069.87183   97.74377  1167.61560  972.12805
Training/pf_norm                      0.13126      0.02172   0.15298     0.10954
Training/qf1_norm                     34.52120     0.78178   35.30298    33.73942
Training/qf2_norm                     38.89940     0.92736   39.82677    37.97204
log_std/mean                          -0.13625     0.00003   -0.13622    -0.13628
log_std/std                           0.00892      0.00003   0.00895     0.00890
log_std/max                           -0.11908     0.00020   -0.11888    -0.11928
log_std/min                           -0.15157     0.00000   -0.15157    -0.15158
log_probs/mean                        -2.73782     0.00156   -2.73626    -2.73938
log_probs/std                         0.22776      0.00599   0.23375     0.22177
log_probs/max                         -2.15598     0.02127   -2.13471    -2.17725
log_probs/min                         -4.59507     0.01060   -4.58447    -4.60566
mean/mean                             0.00549      0.00003   0.00552     0.00546
mean/std                              0.00537      0.00004   0.00540     0.00533
mean/max                              0.01297      0.00012   0.01309     0.01286
mean/min                              -0.00278     0.00001   -0.00277    -0.00279
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 151 50
freq 22
sample: [6, 9, 5, 7, 0, 2, 4, 3, 1, 8]
replay_buffer._size: [22950 22950 22950 22950 22950 22950 22950 22950 22950 22950]
train_time 0.13875341415405273
eval time 0.0021560192108154297
snapshot at best
2023-08-22 20:47:28,959 MainThread INFO: EPOCH:151
2023-08-22 20:47:28,959 MainThread INFO: Time Consumed:0.655580997467041s
2023-08-22 20:47:28,959 MainThread INFO: Total Frames:228000s
 76%|███████▌  | 152/200 [02:52<01:19,  1.65s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1306.35776
Train_Epoch_Reward                    15169.93294
Running_Training_Average_Rewards      2454.82744
Explore_Time                          0.00392
Train___Time                          0.13875
Eval____Time                          0.00216
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.61374
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.52325
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.74720
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.53109
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20935
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.27822
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.52616
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13363.74798
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.76192
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.77004
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.64641      0.41393   9.06034     8.23248
alpha_0                               0.91283      0.00014   0.91297     0.91270
alpha_1                               0.91276      0.00014   0.91290     0.91262
alpha_2                               0.91280      0.00014   0.91294     0.91267
alpha_3                               0.91278      0.00014   0.91292     0.91264
alpha_4                               0.91278      0.00014   0.91292     0.91265
alpha_5                               0.91282      0.00014   0.91296     0.91269
alpha_6                               0.91279      0.00014   0.91293     0.91266
alpha_7                               0.91282      0.00014   0.91296     0.91268
alpha_8                               0.91280      0.00014   0.91293     0.91266
alpha_9                               0.91281      0.00014   0.91294     0.91267
Alpha_loss                            -0.61242     0.00117   -0.61124    -0.61359
Training/policy_loss                  -3.01184     0.00255   -3.00929    -3.01439
Training/qf1_loss                     1213.83954   82.92377  1296.76331  1130.91577
Training/qf2_loss                     1212.37970   82.86749  1295.24719  1129.51221
Training/pf_norm                      0.08273      0.00586   0.08859     0.07686
Training/qf1_norm                     39.28390     1.46257   40.74647    37.82133
Training/qf2_norm                     43.37141     1.64392   45.01533    41.72749
log_std/mean                          -0.13625     0.00003   -0.13622    -0.13628
log_std/std                           0.00883      0.00004   0.00887     0.00879
log_std/max                           -0.11925     0.00003   -0.11921    -0.11928
log_std/min                           -0.15145     0.00012   -0.15133    -0.15157
log_probs/mean                        -2.73448     0.00175   -2.73273    -2.73624
log_probs/std                         0.23852      0.00040   0.23892     0.23813
log_probs/max                         -2.14169     0.02058   -2.12111    -2.16226
log_probs/min                         -5.14888     0.03778   -5.11110    -5.18666
mean/mean                             0.00557      0.00001   0.00558     0.00556
mean/std                              0.00558      0.00006   0.00564     0.00553
mean/max                              0.01358      0.00016   0.01375     0.01342
mean/min                              -0.00279     0.00007   -0.00272    -0.00286
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 152 50
freq 22
sample: [7, 4, 0, 8, 1, 2, 9, 5, 3, 6]
replay_buffer._size: [23100 23100 23100 23100 23100 23100 23100 23100 23100 23100]
train_time 0.5672571659088135
eval time 0.0025784969329833984
snapshot at best
2023-08-22 20:47:30,490 MainThread INFO: EPOCH:152
2023-08-22 20:47:30,491 MainThread INFO: Time Consumed:1.162541151046753s
2023-08-22 20:47:30,491 MainThread INFO: Total Frames:229500s
 76%|███████▋  | 153/200 [02:54<01:16,  1.62s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1309.97401
Train_Epoch_Reward                    18819.43180
Running_Training_Average_Rewards      2001.76238
Explore_Time                          0.00338
Train___Time                          0.56726
Eval____Time                          0.00258
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.44614
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.51430
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.73751
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.51646
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18914
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.25932
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.51833
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13366.11706
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.75256
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.76773
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.77523      0.31237    8.08760     7.46286
alpha_0                               0.91229      0.00014    0.91242     0.91215
alpha_1                               0.91221      0.00014    0.91235     0.91207
alpha_2                               0.91225      0.00014    0.91239     0.91212
alpha_3                               0.91223      0.00014    0.91237     0.91210
alpha_4                               0.91224      0.00014    0.91237     0.91210
alpha_5                               0.91227      0.00014    0.91241     0.91214
alpha_6                               0.91225      0.00014    0.91238     0.91211
alpha_7                               0.91227      0.00014    0.91241     0.91213
alpha_8                               0.91225      0.00014    0.91238     0.91211
alpha_9                               0.91226      0.00014    0.91239     0.91212
Alpha_loss                            -0.61717     0.00157    -0.61561    -0.61874
Training/policy_loss                  -3.02551     0.00726    -3.01825    -3.03276
Training/qf1_loss                     1212.88516   200.25449  1413.13965  1012.63068
Training/qf2_loss                     1211.44025   200.02435  1411.46460  1011.41589
Training/pf_norm                      0.10756      0.00285    0.11041     0.10470
Training/qf1_norm                     36.23385     0.88219    37.11604    35.35166
Training/qf2_norm                     40.28773     1.58468    41.87241    38.70304
log_std/mean                          -0.13616     0.00002    -0.13615    -0.13618
log_std/std                           0.00871      0.00003    0.00874     0.00869
log_std/max                           -0.11936     0.00003    -0.11933    -0.11940
log_std/min                           -0.15127     0.00006    -0.15121    -0.15133
log_probs/mean                        -2.74218     0.00603    -2.73615    -2.74820
log_probs/std                         0.23243      0.00755    0.23998     0.22488
log_probs/max                         -2.19308     0.00621    -2.18687    -2.19929
log_probs/min                         -5.17081     0.62039    -4.55042    -5.79121
mean/mean                             0.00561      0.00002    0.00563     0.00558
mean/std                              0.00581      0.00005    0.00586     0.00575
mean/max                              0.01425      0.00014    0.01439     0.01411
mean/min                              -0.00301     0.00001    -0.00300    -0.00303
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 153 50
freq 22
sample: [7, 3, 4, 6, 8, 0, 1, 5, 2, 9]
replay_buffer._size: [23250 23250 23250 23250 23250 23250 23250 23250 23250 23250]
train_time 0.15313339233398438
eval time 0.002388477325439453
2023-08-22 20:47:31,370 MainThread INFO: EPOCH:153
2023-08-22 20:47:31,370 MainThread INFO: Time Consumed:0.15938973426818848s
2023-08-22 20:47:31,370 MainThread INFO: Total Frames:231000s
 77%|███████▋  | 154/200 [02:55<01:04,  1.39s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1311.06558
Train_Epoch_Reward                    7951.88998
Running_Training_Average_Rewards      1398.04182
Explore_Time                          0.00307
Train___Time                          0.15313
Eval____Time                          0.00239
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.06564
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.54294
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70289
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.52511
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.16798
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.24318
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.51580
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13352.08269
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.78227
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.77210
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.46216      0.19272   8.65488     8.26944
alpha_0                               0.91174      0.00014   0.91187     0.91160
alpha_1                               0.91166      0.00014   0.91180     0.91153
alpha_2                               0.91171      0.00014   0.91184     0.91157
alpha_3                               0.91168      0.00014   0.91182     0.91155
alpha_4                               0.91169      0.00014   0.91183     0.91155
alpha_5                               0.91173      0.00014   0.91186     0.91159
alpha_6                               0.91170      0.00014   0.91183     0.91156
alpha_7                               0.91172      0.00014   0.91186     0.91159
alpha_8                               0.91170      0.00014   0.91183     0.91156
alpha_9                               0.91171      0.00014   0.91185     0.91157
Alpha_loss                            -0.62126     0.00010   -0.62116    -0.62135
Training/policy_loss                  -3.03253     0.00845   -3.02408    -3.04098
Training/qf1_loss                     1269.66351   24.22784  1293.89136  1245.43567
Training/qf2_loss                     1268.16119   24.22675  1292.38794  1243.93445
Training/pf_norm                      0.09521      0.00084   0.09606     0.09437
Training/qf1_norm                     39.12994     0.92217   40.05211    38.20778
Training/qf2_norm                     43.34686     0.91298   44.25983    42.43388
log_std/mean                          -0.13600     0.00004   -0.13596    -0.13604
log_std/std                           0.00861      0.00002   0.00863     0.00859
log_std/max                           -0.11960     0.00005   -0.11954    -0.11965
log_std/min                           -0.15100     0.00002   -0.15098    -0.15103
log_probs/mean                        -2.74251     0.01208   -2.73042    -2.75459
log_probs/std                         0.23521      0.01140   0.24660     0.22381
log_probs/max                         -2.15582     0.01326   -2.14256    -2.16908
log_probs/min                         -4.95698     0.63257   -4.32441    -5.58955
mean/mean                             0.00576      0.00005   0.00581     0.00571
mean/std                              0.00600      0.00004   0.00605     0.00596
mean/max                              0.01478      0.00017   0.01495     0.01461
mean/min                              -0.00303     0.00000   -0.00303    -0.00303
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 154 50
freq 22
sample: [7, 3, 0, 9, 4, 1, 8, 6, 2, 5]
replay_buffer._size: [23400 23400 23400 23400 23400 23400 23400 23400 23400 23400]
train_time 0.14945745468139648
eval time 0.002421855926513672
snapshot at best
2023-08-22 20:47:33,589 MainThread INFO: EPOCH:154
2023-08-22 20:47:33,589 MainThread INFO: Time Consumed:0.6644461154937744s
2023-08-22 20:47:33,589 MainThread INFO: Total Frames:232500s
 78%|███████▊  | 155/200 [02:57<01:13,  1.64s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1312.57884
Train_Epoch_Reward                    2793.93510
Running_Training_Average_Rewards      985.50856
Explore_Time                          0.00316
Train___Time                          0.14946
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.60532
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.54836
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.71160
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.51055
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.18531
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.26072
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.53987
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13394.08198
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.78845
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.74706
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.51967      0.77738    9.29705     7.74230
alpha_0                               0.91119      0.00014    0.91133     0.91105
alpha_1                               0.91111      0.00014    0.91125     0.91098
alpha_2                               0.91116      0.00014    0.91130     0.91102
alpha_3                               0.91114      0.00014    0.91127     0.91100
alpha_4                               0.91114      0.00014    0.91128     0.91100
alpha_5                               0.91118      0.00014    0.91131     0.91104
alpha_6                               0.91115      0.00014    0.91129     0.91101
alpha_7                               0.91117      0.00014    0.91131     0.91104
alpha_8                               0.91115      0.00014    0.91129     0.91101
alpha_9                               0.91116      0.00014    0.91130     0.91102
Alpha_loss                            -0.62395     0.00070    -0.62325    -0.62465
Training/policy_loss                  -3.02597     0.00180    -3.02416    -3.02777
Training/qf1_loss                     1498.33154   436.87878  1935.21033  1061.45276
Training/qf2_loss                     1496.73499   436.65637  1933.39136  1060.07861
Training/pf_norm                      0.08814      0.01824    0.10639     0.06990
Training/qf1_norm                     39.45774     2.68117    42.13891    36.77657
Training/qf2_norm                     43.93085     3.36427    47.29512    40.56658
log_std/mean                          -0.13577     0.00006    -0.13571    -0.13583
log_std/std                           0.00851      0.00003    0.00853     0.00848
log_std/max                           -0.11948     0.00001    -0.11947    -0.11949
log_std/min                           -0.15071     0.00016    -0.15055    -0.15087
log_probs/mean                        -2.72784     0.00336    -2.72449    -2.73120
log_probs/std                         0.21837      0.00225    0.22062     0.21612
log_probs/max                         -2.14846     0.02164    -2.12683    -2.17010
log_probs/min                         -4.33173     0.04340    -4.28833    -4.37513
mean/mean                             0.00590      0.00005    0.00594     0.00585
mean/std                              0.00612      0.00002    0.00614     0.00610
mean/max                              0.01530      0.00008    0.01537     0.01522
mean/min                              -0.00307     0.00002    -0.00305    -0.00308
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 155 50
freq 22
sample: [8, 9, 0, 4, 7, 6, 1, 5, 2, 3]
replay_buffer._size: [23550 23550 23550 23550 23550 23550 23550 23550 23550 23550]
train_time 0.146040678024292
eval time 0.0021638870239257812
2023-08-22 20:47:34,672 MainThread INFO: EPOCH:155
2023-08-22 20:47:34,672 MainThread INFO: Time Consumed:0.15160870552062988s
2023-08-22 20:47:34,672 MainThread INFO: Total Frames:234000s
 78%|███████▊  | 156/200 [02:58<01:04,  1.48s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1313.38608
Train_Epoch_Reward                    23257.25826
Running_Training_Average_Rewards      1133.43611
Explore_Time                          0.00273
Train___Time                          0.14604
Eval____Time                          0.00216
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.28874
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.55328
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.70480
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.51916
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20650
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.28317
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.56600
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13395.29884
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.79742
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.74701
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.25495      0.39368   8.64863     7.86127
alpha_0                               0.91064      0.00014   0.91078     0.91050
alpha_1                               0.91057      0.00014   0.91070     0.91043
alpha_2                               0.91061      0.00014   0.91075     0.91047
alpha_3                               0.91059      0.00014   0.91072     0.91045
alpha_4                               0.91059      0.00014   0.91073     0.91046
alpha_5                               0.91063      0.00014   0.91077     0.91049
alpha_6                               0.91060      0.00014   0.91074     0.91046
alpha_7                               0.91063      0.00014   0.91076     0.91049
alpha_8                               0.91060      0.00014   0.91074     0.91046
alpha_9                               0.91061      0.00014   0.91075     0.91047
Alpha_loss                            -0.62893     0.00072   -0.62821    -0.62965
Training/policy_loss                  -3.04348     0.00131   -3.04217    -3.04479
Training/qf1_loss                     1209.42371   54.19995  1263.62366  1155.22375
Training/qf2_loss                     1207.90326   54.22101  1262.12427  1153.68225
Training/pf_norm                      0.08654      0.00629   0.09283     0.08025
Training/qf1_norm                     38.85544     1.67378   40.52922    37.18166
Training/qf2_norm                     43.10353     1.61148   44.71501    41.49204
log_std/mean                          -0.13552     0.00006   -0.13545    -0.13558
log_std/std                           0.00838      0.00003   0.00842     0.00835
log_std/max                           -0.11949     0.00015   -0.11933    -0.11964
log_std/min                           -0.15025     0.00001   -0.15024    -0.15026
log_probs/mean                        -2.73780     0.00316   -2.73463    -2.74096
log_probs/std                         0.23969      0.00159   0.24128     0.23810
log_probs/max                         -2.15180     0.01182   -2.13998    -2.16362
log_probs/min                         -4.92581     0.15657   -4.76924    -5.08238
mean/mean                             0.00605      0.00003   0.00608     0.00602
mean/std                              0.00615      0.00000   0.00616     0.00615
mean/max                              0.01543      0.00001   0.01544     0.01542
mean/min                              -0.00299     0.00001   -0.00298    -0.00300
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 156 50
freq 22
sample: [2, 7, 6, 3, 4, 8, 0, 9, 1, 5]
replay_buffer._size: [23700 23700 23700 23700 23700 23700 23700 23700 23700 23700]
train_time 0.13840436935424805
eval time 0.0030145645141601562
snapshot at best
2023-08-22 20:47:37,016 MainThread INFO: EPOCH:156
2023-08-22 20:47:37,016 MainThread INFO: Time Consumed:0.7459697723388672s
2023-08-22 20:47:37,016 MainThread INFO: Total Frames:235500s
 78%|███████▊  | 157/200 [03:00<01:14,  1.73s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1315.47030
Train_Epoch_Reward                    4376.05722
Running_Training_Average_Rewards      1014.24169
Explore_Time                          0.00309
Train___Time                          0.13840
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.29038
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.52518
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.72329
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.50601
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.23150
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.31284
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.59835
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13411.98704
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.76808
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.73994
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.36000      1.33330    9.69330     7.02669
alpha_0                               0.91009      0.00014    0.91023     0.90996
alpha_1                               0.91002      0.00014    0.91016     0.90988
alpha_2                               0.91006      0.00014    0.91020     0.90993
alpha_3                               0.91004      0.00014    0.91018     0.90990
alpha_4                               0.91005      0.00014    0.91018     0.90991
alpha_5                               0.91008      0.00014    0.91022     0.90995
alpha_6                               0.91005      0.00014    0.91019     0.90992
alpha_7                               0.91008      0.00014    0.91022     0.90994
alpha_8                               0.91005      0.00014    0.91019     0.90992
alpha_9                               0.91006      0.00014    0.91020     0.90993
Alpha_loss                            -0.63268     0.00108    -0.63160    -0.63376
Training/policy_loss                  -3.04565     0.00269    -3.04296    -3.04834
Training/qf1_loss                     1293.52209   332.30530  1625.82739  961.21680
Training/qf2_loss                     1291.91199   331.98230  1623.89429  959.92969
Training/pf_norm                      0.07849      0.01901    0.09750     0.05948
Training/qf1_norm                     39.54875     4.84092    44.38968    34.70783
Training/qf2_norm                     44.02276     5.79348    49.81625    38.22928
log_std/mean                          -0.13531     0.00004    -0.13528    -0.13535
log_std/std                           0.00827      0.00002    0.00829     0.00825
log_std/max                           -0.11962     0.00006    -0.11955    -0.11968
log_std/min                           -0.15020     0.00017    -0.15003    -0.15037
log_probs/mean                        -2.73459     0.00070    -2.73389    -2.73530
log_probs/std                         0.22283      0.00314    0.22598     0.21969
log_probs/max                         -2.15420     0.02159    -2.13261    -2.17580
log_probs/min                         -4.46707     0.27681    -4.19026    -4.74388
mean/mean                             0.00612      0.00004    0.00616     0.00608
mean/std                              0.00609      0.00002    0.00612     0.00607
mean/max                              0.01539      0.00001    0.01540     0.01537
mean/min                              -0.00300     0.00004    -0.00296    -0.00304
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 157 50
freq 22
sample: [2, 6, 8, 3, 9, 0, 7, 4, 1, 5]
replay_buffer._size: [23850 23850 23850 23850 23850 23850 23850 23850 23850 23850]
train_time 0.12793540954589844
eval time 0.002428770065307617
snapshot at best
2023-08-22 20:47:38,456 MainThread INFO: EPOCH:157
2023-08-22 20:47:38,615 MainThread INFO: Time Consumed:0.6246488094329834s
2023-08-22 20:47:38,615 MainThread INFO: Total Frames:237000s
 79%|███████▉  | 158/200 [03:02<01:11,  1.70s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1316.15490
Train_Epoch_Reward                    19610.49736
Running_Training_Average_Rewards      1574.79376
Explore_Time                          0.00342
Train___Time                          0.12794
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.81068
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.51524
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.72698
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.51106
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25832
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.34487
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.63209
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13424.02035
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.75801
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.74020
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.47874      0.04828   7.52702     7.43046
alpha_0                               0.90955      0.00014   0.90968     0.90941
alpha_1                               0.90947      0.00014   0.90961     0.90933
alpha_2                               0.90952      0.00014   0.90965     0.90938
alpha_3                               0.90949      0.00014   0.90963     0.90935
alpha_4                               0.90950      0.00014   0.90964     0.90936
alpha_5                               0.90954      0.00014   0.90967     0.90940
alpha_6                               0.90950      0.00014   0.90964     0.90937
alpha_7                               0.90953      0.00014   0.90967     0.90940
alpha_8                               0.90951      0.00014   0.90964     0.90937
alpha_9                               0.90952      0.00014   0.90965     0.90938
Alpha_loss                            -0.63651     0.00071   -0.63580    -0.63721
Training/policy_loss                  -3.05131     0.00123   -3.05009    -3.05254
Training/qf1_loss                     1056.12906   58.71677  1114.84583  997.41229
Training/qf2_loss                     1054.63644   58.69095  1113.32739  995.94550
Training/pf_norm                      0.11065      0.00885   0.11951     0.10180
Training/qf1_norm                     36.56210     0.31046   36.87257    36.25164
Training/qf2_norm                     40.69768     0.38910   41.08678    40.30858
log_std/mean                          -0.13514     0.00001   -0.13513    -0.13516
log_std/std                           0.00816      0.00002   0.00818     0.00814
log_std/max                           -0.11967     0.00003   -0.11965    -0.11970
log_std/min                           -0.14956     0.00018   -0.14939    -0.14974
log_probs/mean                        -2.73221     0.00323   -2.72898    -2.73545
log_probs/std                         0.23835      0.01011   0.24847     0.22824
log_probs/max                         -2.13859     0.02336   -2.11523    -2.16194
log_probs/min                         -4.40144     0.31502   -4.08642    -4.71646
mean/mean                             0.00629      0.00003   0.00632     0.00626
mean/std                              0.00601      0.00002   0.00603     0.00600
mean/max                              0.01542      0.00001   0.01542     0.01541
mean/min                              -0.00279     0.00006   -0.00273    -0.00285
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 158 50
freq 22
sample: [7, 4, 3, 9, 2, 5, 6, 8, 0, 1]
replay_buffer._size: [24000 24000 24000 24000 24000 24000 24000 24000 24000 24000]
train_time 0.14260196685791016
eval time 0.0021576881408691406
snapshot at best
2023-08-22 20:47:40,050 MainThread INFO: EPOCH:158
2023-08-22 20:47:40,051 MainThread INFO: Time Consumed:0.641467809677124s
2023-08-22 20:47:40,051 MainThread INFO: Total Frames:238500s
 80%|███████▉  | 159/200 [03:03<01:06,  1.61s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1317.31598
Train_Epoch_Reward                    4673.00426
Running_Training_Average_Rewards      955.31863
Explore_Time                          0.00301
Train___Time                          0.14260
Eval____Time                          0.00216
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.34195
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.47924
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.74676
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.50878
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.29612
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.38897
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.67386
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13436.37618
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.72290
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.75259
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.54643      0.23316    8.77958     8.31327
alpha_0                               0.90900      0.00014    0.90914     0.90886
alpha_1                               0.90892      0.00014    0.90906     0.90879
alpha_2                               0.90897      0.00014    0.90911     0.90883
alpha_3                               0.90894      0.00014    0.90908     0.90881
alpha_4                               0.90895      0.00014    0.90909     0.90882
alpha_5                               0.90899      0.00014    0.90913     0.90885
alpha_6                               0.90896      0.00014    0.90909     0.90882
alpha_7                               0.90899      0.00014    0.90912     0.90885
alpha_8                               0.90896      0.00014    0.90909     0.90882
alpha_9                               0.90897      0.00014    0.90911     0.90883
Alpha_loss                            -0.64041     0.00128    -0.63913    -0.64169
Training/policy_loss                  -3.05785     0.00451    -3.05334    -3.06237
Training/qf1_loss                     1321.30927   146.57135  1467.88062  1174.73792
Training/qf2_loss                     1319.61841   146.55066  1466.16907  1173.06775
Training/pf_norm                      0.09941      0.02083    0.12024     0.07858
Training/qf1_norm                     40.85641     0.84787    41.70428    40.00855
Training/qf2_norm                     45.52259     0.93176    46.45435    44.59083
log_std/mean                          -0.13517     0.00001    -0.13516    -0.13518
log_std/std                           0.00808      0.00003    0.00811     0.00806
log_std/max                           -0.11997     0.00019    -0.11978    -0.12016
log_std/min                           -0.14968     0.00022    -0.14946    -0.14990
log_probs/mean                        -2.73065     0.00282    -2.72783    -2.73347
log_probs/std                         0.24448      0.01569    0.26017     0.22878
log_probs/max                         -2.10947     0.05330    -2.05618    -2.16277
log_probs/min                         -4.98543     0.39202    -4.59341    -5.37745
mean/mean                             0.00644      0.00003    0.00647     0.00641
mean/std                              0.00588      0.00004    0.00593     0.00584
mean/max                              0.01539      0.00001    0.01539     0.01538
mean/min                              -0.00267     0.00001    -0.00267    -0.00268
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 159 50
freq 22
sample: [4, 8, 2, 1, 6, 3, 0, 5, 9, 7]
replay_buffer._size: [24150 24150 24150 24150 24150 24150 24150 24150 24150 24150]
train_time 0.12296795845031738
eval time 0.002773761749267578
2023-08-22 20:47:41,404 MainThread INFO: EPOCH:159
2023-08-22 20:47:41,405 MainThread INFO: Time Consumed:0.12952518463134766s
2023-08-22 20:47:41,405 MainThread INFO: Total Frames:240000s
 80%|████████  | 160/200 [03:05<01:01,  1.54s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1317.48191
Train_Epoch_Reward                    20206.85673
Running_Training_Average_Rewards      1483.01194
Explore_Time                          0.00285
Train___Time                          0.12297
Eval____Time                          0.00277
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.75163
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.42924
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.74598
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.50990
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.30352
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.40023
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.68655
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13420.56523
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.68038
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.78841
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.80044      0.23614   8.03658     7.56431
alpha_0                               0.90845      0.00014   0.90859     0.90832
alpha_1                               0.90838      0.00014   0.90851     0.90824
alpha_2                               0.90842      0.00014   0.90856     0.90829
alpha_3                               0.90840      0.00014   0.90853     0.90826
alpha_4                               0.90841      0.00014   0.90854     0.90827
alpha_5                               0.90844      0.00014   0.90858     0.90831
alpha_6                               0.90841      0.00014   0.90855     0.90827
alpha_7                               0.90844      0.00014   0.90858     0.90830
alpha_8                               0.90841      0.00014   0.90855     0.90828
alpha_9                               0.90842      0.00014   0.90856     0.90829
Alpha_loss                            -0.64417     0.00055   -0.64362    -0.64473
Training/policy_loss                  -3.06267     0.00293   -3.05974    -3.06560
Training/qf1_loss                     1139.22546   33.21338  1172.43884  1106.01208
Training/qf2_loss                     1137.58362   33.14734  1170.73096  1104.43628
Training/pf_norm                      0.08651      0.00399   0.09051     0.08252
Training/qf1_norm                     38.06293     1.10370   39.16664    36.95923
Training/qf2_norm                     42.59994     0.91475   43.51468    41.68519
log_std/mean                          -0.13529     0.00004   -0.13525    -0.13533
log_std/std                           0.00799      0.00001   0.00801     0.00798
log_std/max                           -0.12046     0.00023   -0.12023    -0.12069
log_std/min                           -0.14965     0.00007   -0.14958    -0.14971
log_probs/mean                        -2.72775     0.00481   -2.72294    -2.73256
log_probs/std                         0.21871      0.00626   0.22497     0.21246
log_probs/max                         -2.15483     0.04062   -2.11420    -2.19545
log_probs/min                         -4.67949     0.11792   -4.56157    -4.79741
mean/mean                             0.00663      0.00004   0.00666     0.00659
mean/std                              0.00567      0.00005   0.00572     0.00563
mean/max                              0.01530      0.00004   0.01534     0.01525
mean/min                              -0.00254     0.00006   -0.00248    -0.00260
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 160 50
freq 22
sample: [7, 0, 9, 2, 8, 4, 3, 1, 6, 5]
replay_buffer._size: [24300 24300 24300 24300 24300 24300 24300 24300 24300 24300]
train_time 0.13535523414611816
eval time 0.0029020309448242188
2023-08-22 20:47:42,986 MainThread INFO: EPOCH:160
2023-08-22 20:47:42,987 MainThread INFO: Time Consumed:0.14145684242248535s
2023-08-22 20:47:42,987 MainThread INFO: Total Frames:241500s
 80%|████████  | 161/200 [03:06<01:00,  1.56s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1316.55167
Train_Epoch_Reward                    5011.82648
Running_Training_Average_Rewards      996.38958
Explore_Time                          0.00260
Train___Time                          0.13536
Eval____Time                          0.00290
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.02850
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.37100
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.74130
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.52019
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31664
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.41909
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.70634
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13391.40023
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.62935
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.85214
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.60696      0.42304    9.03000     8.18393
alpha_0                               0.90791      0.00014    0.90804     0.90777
alpha_1                               0.90783      0.00014    0.90797     0.90770
alpha_2                               0.90788      0.00014    0.90801     0.90774
alpha_3                               0.90785      0.00014    0.90799     0.90771
alpha_4                               0.90786      0.00014    0.90800     0.90773
alpha_5                               0.90790      0.00014    0.90803     0.90776
alpha_6                               0.90786      0.00014    0.90800     0.90773
alpha_7                               0.90789      0.00014    0.90803     0.90776
alpha_8                               0.90787      0.00014    0.90800     0.90773
alpha_9                               0.90788      0.00014    0.90802     0.90774
Alpha_loss                            -0.64856     0.00071    -0.64785    -0.64927
Training/policy_loss                  -3.07317     0.00150    -3.07167    -3.07467
Training/qf1_loss                     1344.00745   138.63269  1482.64014  1205.37476
Training/qf2_loss                     1342.18823   138.40625  1480.59448  1203.78198
Training/pf_norm                      0.08585      0.02017    0.10601     0.06568
Training/qf1_norm                     41.74691     1.35526    43.10217    40.39165
Training/qf2_norm                     46.78242     2.04074    48.82317    44.74168
log_std/mean                          -0.13549     0.00007    -0.13542    -0.13556
log_std/std                           0.00792      0.00001    0.00793     0.00792
log_std/max                           -0.12081     0.00012    -0.12070    -0.12093
log_std/min                           -0.14978     0.00006    -0.14971    -0.14984
log_probs/mean                        -2.73132     0.00313    -2.72819    -2.73446
log_probs/std                         0.23133      0.00308    0.23442     0.22825
log_probs/max                         -2.18385     0.00372    -2.18013    -2.18757
log_probs/min                         -5.09079     0.03623    -5.05456    -5.12702
mean/mean                             0.00680      0.00005    0.00685     0.00675
mean/std                              0.00547      0.00005    0.00553     0.00542
mean/max                              0.01516      0.00005    0.01520     0.01511
mean/min                              -0.00233     0.00006    -0.00227    -0.00240
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 161 50
freq 22
sample: [0, 6, 8, 5, 1, 2, 7, 4, 3, 9]
replay_buffer._size: [24450 24450 24450 24450 24450 24450 24450 24450 24450 24450]
train_time 0.1252295970916748
eval time 0.00238800048828125
2023-08-22 20:47:44,705 MainThread INFO: EPOCH:161
2023-08-22 20:47:44,705 MainThread INFO: Time Consumed:0.13066983222961426s
2023-08-22 20:47:44,705 MainThread INFO: Total Frames:243000s
 81%|████████  | 162/200 [03:08<01:01,  1.61s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1315.18545
Train_Epoch_Reward                    7723.64817
Running_Training_Average_Rewards      1098.07771
Explore_Time                          0.00244
Train___Time                          0.12523
Eval____Time                          0.00239
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.10425
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.32258
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.74694
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.52617
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.34080
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.44582
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.73602
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13384.18553
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.58689
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89755
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.07976      0.99373    9.07349     7.08604
alpha_0                               0.90736      0.00014    0.90750     0.90723
alpha_1                               0.90729      0.00014    0.90742     0.90715
alpha_2                               0.90733      0.00014    0.90747     0.90720
alpha_3                               0.90730      0.00014    0.90744     0.90717
alpha_4                               0.90732      0.00014    0.90745     0.90718
alpha_5                               0.90735      0.00014    0.90749     0.90722
alpha_6                               0.90732      0.00014    0.90746     0.90718
alpha_7                               0.90735      0.00014    0.90748     0.90721
alpha_8                               0.90732      0.00014    0.90746     0.90718
alpha_9                               0.90733      0.00014    0.90747     0.90720
Alpha_loss                            -0.65322     0.00095    -0.65227    -0.65416
Training/policy_loss                  -3.08616     0.00023    -3.08593    -3.08639
Training/qf1_loss                     1218.99408   361.91437  1580.90845  857.07971
Training/qf2_loss                     1217.38788   361.89899  1579.28687  855.48889
Training/pf_norm                      0.10352      0.00217    0.10569     0.10135
Training/qf1_norm                     39.89831     4.16432    44.06263    35.73399
Training/qf2_norm                     44.26963     4.22784    48.49746    40.04179
log_std/mean                          -0.13571     0.00003    -0.13568    -0.13574
log_std/std                           0.00786      0.00001    0.00787     0.00785
log_std/max                           -0.12117     0.00007    -0.12110    -0.12124
log_std/min                           -0.14998     0.00001    -0.14997    -0.14999
log_probs/mean                        -2.73760     0.00070    -2.73691    -2.73830
log_probs/std                         0.22567      0.00979    0.23546     0.21588
log_probs/max                         -2.16007     0.02383    -2.13624    -2.18389
log_probs/min                         -4.72568     0.55139    -4.17429    -5.27708
mean/mean                             0.00700      0.00004    0.00703     0.00696
mean/std                              0.00527      0.00006    0.00533     0.00522
mean/max                              0.01507      0.00003    0.01510     0.01504
mean/min                              -0.00215     0.00003    -0.00212    -0.00217
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 162 50
freq 22
sample: [8, 5, 2, 4, 6, 0, 9, 7, 1, 3]
replay_buffer._size: [24600 24600 24600 24600 24600 24600 24600 24600 24600 24600]
train_time 0.12401056289672852
eval time 0.0023348331451416016
2023-08-22 20:47:46,370 MainThread INFO: EPOCH:162
2023-08-22 20:47:46,371 MainThread INFO: Time Consumed:0.12941837310791016s
2023-08-22 20:47:46,371 MainThread INFO: Total Frames:244500s
 82%|████████▏ | 163/200 [03:10<01:00,  1.62s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1314.09561
Train_Epoch_Reward                    9314.79309
Running_Training_Average_Rewards      735.00892
Explore_Time                          0.00254
Train___Time                          0.12401
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.58805
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.25961
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.76497
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.52132
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.37213
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.47587
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76923
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13383.80006
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.53349
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.94137
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.50701      1.08054    9.58755     7.42648
alpha_0                               0.90682      0.00014    0.90695     0.90668
alpha_1                               0.90674      0.00014    0.90688     0.90660
alpha_2                               0.90679      0.00014    0.90692     0.90665
alpha_3                               0.90676      0.00014    0.90690     0.90662
alpha_4                               0.90677      0.00014    0.90691     0.90664
alpha_5                               0.90681      0.00014    0.90694     0.90667
alpha_6                               0.90677      0.00014    0.90691     0.90664
alpha_7                               0.90680      0.00014    0.90694     0.90667
alpha_8                               0.90677      0.00014    0.90691     0.90664
alpha_9                               0.90679      0.00014    0.90692     0.90665
Alpha_loss                            -0.65664     0.00128    -0.65536    -0.65791
Training/policy_loss                  -3.08801     0.00489    -3.08312    -3.09290
Training/qf1_loss                     1263.16760   386.08704  1649.25464  877.08057
Training/qf2_loss                     1261.44516   385.84683  1647.29199  875.59833
Training/pf_norm                      0.09512      0.01299    0.10811     0.08213
Training/qf1_norm                     42.01827     4.18067    46.19894    37.83760
Training/qf2_norm                     46.73530     4.89219    51.62749    41.84312
log_std/mean                          -0.13578     0.00001    -0.13576    -0.13579
log_std/std                           0.00778      0.00002    0.00780     0.00775
log_std/max                           -0.12139     0.00010    -0.12130    -0.12149
log_std/min                           -0.15019     0.00015    -0.15005    -0.15034
log_probs/mean                        -2.73111     0.00273    -2.72838    -2.73384
log_probs/std                         0.22393      0.00239    0.22631     0.22154
log_probs/max                         -2.13881     0.03352    -2.10529    -2.17232
log_probs/min                         -4.38946     0.35988    -4.02958    -4.74934
mean/mean                             0.00719      0.00006    0.00725     0.00713
mean/std                              0.00505      0.00005    0.00510     0.00499
mean/max                              0.01502      0.00003    0.01505     0.01499
mean/min                              -0.00197     0.00007    -0.00191    -0.00204
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 163 50
freq 22
sample: [0, 7, 3, 4, 1, 2, 9, 6, 8, 5]
replay_buffer._size: [24750 24750 24750 24750 24750 24750 24750 24750 24750 24750]
train_time 0.12643122673034668
eval time 0.002118349075317383
2023-08-22 20:47:48,283 MainThread INFO: EPOCH:163
2023-08-22 20:47:48,284 MainThread INFO: Time Consumed:0.13226056098937988s
2023-08-22 20:47:48,284 MainThread INFO: Total Frames:246000s
 82%|████████▏ | 164/200 [03:11<01:01,  1.70s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1312.37603
Train_Epoch_Reward                    3097.70890
Running_Training_Average_Rewards      671.20501
Explore_Time                          0.00321
Train___Time                          0.12643
Eval____Time                          0.00212
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.34757
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.20249
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.75718
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.53516
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.38596
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.48848
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.78446
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13347.23212
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.48520
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.01714
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.66941      0.17099   7.84040     7.49842
alpha_0                               0.90627      0.00014   0.90641     0.90614
alpha_1                               0.90620      0.00014   0.90633     0.90606
alpha_2                               0.90624      0.00014   0.90638     0.90611
alpha_3                               0.90621      0.00014   0.90635     0.90608
alpha_4                               0.90623      0.00014   0.90636     0.90609
alpha_5                               0.90626      0.00014   0.90640     0.90613
alpha_6                               0.90623      0.00014   0.90637     0.90609
alpha_7                               0.90626      0.00014   0.90639     0.90612
alpha_8                               0.90623      0.00014   0.90637     0.90609
alpha_9                               0.90624      0.00014   0.90638     0.90611
Alpha_loss                            -0.66078     0.00199   -0.65879    -0.66277
Training/policy_loss                  -3.09648     0.01020   -3.08628    -3.10669
Training/qf1_loss                     1048.22336   27.03177  1075.25513  1021.19159
Training/qf2_loss                     1046.63547   27.06644  1073.70190  1019.56903
Training/pf_norm                      0.09904      0.00070   0.09975     0.09834
Training/qf1_norm                     38.83577     0.70203   39.53780    38.13374
Training/qf2_norm                     43.13185     0.60320   43.73505    42.52865
log_std/mean                          -0.13589     0.00003   -0.13586    -0.13592
log_std/std                           0.00771      0.00003   0.00774     0.00768
log_std/max                           -0.12167     0.00009   -0.12159    -0.12176
log_std/min                           -0.15002     0.00002   -0.15000    -0.15005
log_probs/mean                        -2.73208     0.01001   -2.72206    -2.74209
log_probs/std                         0.23315      0.02768   0.26083     0.20547
log_probs/max                         -2.17517     0.04846   -2.12671    -2.22363
log_probs/min                         -4.52414     0.45370   -4.07044    -4.97784
mean/mean                             0.00746      0.00006   0.00752     0.00740
mean/std                              0.00483      0.00007   0.00490     0.00476
mean/max                              0.01493      0.00006   0.01500     0.01487
mean/min                              -0.00169     0.00008   -0.00162    -0.00177
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 164 50
freq 22
sample: [8, 9, 7, 4, 1, 3, 0, 5, 6, 2]
replay_buffer._size: [24900 24900 24900 24900 24900 24900 24900 24900 24900 24900]
train_time 0.13017702102661133
eval time 0.0024292469024658203
2023-08-22 20:47:49,985 MainThread INFO: EPOCH:164
2023-08-22 20:47:49,985 MainThread INFO: Time Consumed:0.13553118705749512s
2023-08-22 20:47:49,985 MainThread INFO: Total Frames:247500s
 82%|████████▎ | 165/200 [03:13<00:59,  1.70s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1310.71223
Train_Epoch_Reward                    25752.60487
Running_Training_Average_Rewards      1272.17023
Explore_Time                          0.00241
Train___Time                          0.13018
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.66706
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.13300
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.76656
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.54090
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.41466
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.51314
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.80436
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13332.91719
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.42781
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.08520
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.87939      0.66938    8.54877     7.21001
alpha_0                               0.90573      0.00014    0.90586     0.90559
alpha_1                               0.90565      0.00014    0.90579     0.90551
alpha_2                               0.90570      0.00014    0.90583     0.90556
alpha_3                               0.90567      0.00014    0.90581     0.90553
alpha_4                               0.90568      0.00014    0.90582     0.90555
alpha_5                               0.90572      0.00014    0.90585     0.90558
alpha_6                               0.90568      0.00014    0.90582     0.90555
alpha_7                               0.90571      0.00014    0.90585     0.90558
alpha_8                               0.90569      0.00014    0.90582     0.90555
alpha_9                               0.90570      0.00014    0.90583     0.90556
Alpha_loss                            -0.66473     0.00139    -0.66334    -0.66613
Training/policy_loss                  -3.10408     0.00597    -3.09811    -3.11006
Training/qf1_loss                     1193.51385   238.33124  1431.84509  955.18262
Training/qf2_loss                     1191.85861   238.20218  1430.06079  953.65643
Training/pf_norm                      0.10203      0.02994    0.13197     0.07209
Training/qf1_norm                     39.97094     2.64786    42.61880    37.32307
Training/qf2_norm                     44.46510     3.03576    47.50086    41.42934
log_std/mean                          -0.13600     0.00002    -0.13598    -0.13601
log_std/std                           0.00764      0.00001    0.00765     0.00763
log_std/max                           -0.12213     0.00018    -0.12194    -0.12231
log_std/min                           -0.15004     0.00016    -0.14988    -0.15020
log_probs/mean                        -2.73115     0.00387    -2.72728    -2.73502
log_probs/std                         0.22581      0.01152    0.23733     0.21429
log_probs/max                         -2.16490     0.00467    -2.16023    -2.16957
log_probs/min                         -4.56316     0.32984    -4.23331    -4.89300
mean/mean                             0.00771      0.00007    0.00778     0.00763
mean/std                              0.00462      0.00006    0.00467     0.00456
mean/max                              0.01495      0.00009    0.01505     0.01486
mean/min                              -0.00143     0.00010    -0.00132    -0.00153
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 165 50
freq 22
sample: [8, 0, 5, 1, 6, 7, 2, 3, 9, 4]
replay_buffer._size: [25050 25050 25050 25050 25050 25050 25050 25050 25050 25050]
train_time 0.17144060134887695
eval time 0.002328157424926758
2023-08-22 20:47:51,816 MainThread INFO: EPOCH:165
2023-08-22 20:47:51,817 MainThread INFO: Time Consumed:0.17754530906677246s
2023-08-22 20:47:51,817 MainThread INFO: Total Frames:249000s
 83%|████████▎ | 166/200 [03:15<00:59,  1.74s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1308.07815
Train_Epoch_Reward                    18104.67176
Running_Training_Average_Rewards      1565.16618
Explore_Time                          0.00294
Train___Time                          0.17144
Eval____Time                          0.00233
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.21942
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.06664
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.77567
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.55521
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44103
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.54242
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.82912
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13306.51585
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.37296
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16198
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.77127      0.54841    8.31968     7.22286
alpha_0                               0.90518      0.00014    0.90532     0.90505
alpha_1                               0.90511      0.00014    0.90524     0.90497
alpha_2                               0.90515      0.00014    0.90529     0.90502
alpha_3                               0.90512      0.00014    0.90526     0.90499
alpha_4                               0.90514      0.00014    0.90527     0.90500
alpha_5                               0.90517      0.00014    0.90531     0.90504
alpha_6                               0.90514      0.00014    0.90528     0.90500
alpha_7                               0.90517      0.00014    0.90530     0.90503
alpha_8                               0.90514      0.00014    0.90528     0.90500
alpha_9                               0.90515      0.00014    0.90529     0.90502
Alpha_loss                            -0.66961     0.00075    -0.66886    -0.67036
Training/policy_loss                  -3.11815     0.00037    -3.11778    -3.11852
Training/qf1_loss                     1180.97995   294.65884  1475.63879  886.32111
Training/qf2_loss                     1179.41745   294.53787  1473.95532  884.87958
Training/pf_norm                      0.11166      0.03701    0.14867     0.07465
Training/qf1_norm                     39.97545     2.16336    42.13882    37.81209
Training/qf2_norm                     44.15729     2.53965    46.69693    41.61764
log_std/mean                          -0.13608     0.00001    -0.13607    -0.13608
log_std/std                           0.00758      0.00001    0.00760     0.00757
log_std/max                           -0.12224     0.00006    -0.12218    -0.12230
log_std/min                           -0.14975     0.00003    -0.14972    -0.14978
log_probs/mean                        -2.73948     0.00265    -2.73684    -2.74213
log_probs/std                         0.23955      0.01238    0.25193     0.22717
log_probs/max                         -2.20766     0.03653    -2.17113    -2.24420
log_probs/min                         -4.86662     0.30511    -4.56151    -5.17173
mean/mean                             0.00793      0.00006    0.00799     0.00788
mean/std                              0.00447      0.00000    0.00447     0.00447
mean/max                              0.01529      0.00015    0.01544     0.01514
mean/min                              -0.00109     0.00005    -0.00104    -0.00113
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 166 50
freq 22
sample: [2, 6, 8, 3, 4, 1, 5, 9, 0, 7]
replay_buffer._size: [25200 25200 25200 25200 25200 25200 25200 25200 25200 25200]
train_time 0.13719940185546875
eval time 0.0025348663330078125
2023-08-22 20:47:53,553 MainThread INFO: EPOCH:166
2023-08-22 20:47:53,554 MainThread INFO: Time Consumed:0.14283323287963867s
2023-08-22 20:47:53,554 MainThread INFO: Total Frames:250500s
 84%|████████▎ | 167/200 [03:17<00:57,  1.74s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1305.16735
Train_Epoch_Reward                    10521.48938
Running_Training_Average_Rewards      1812.62553
Explore_Time                          0.00255
Train___Time                          0.13720
Eval____Time                          0.00253
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.81498
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.04160
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.76390
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.60492
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.48112
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.58338
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.86347
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13254.67076
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.35596
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.25677
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.22669      0.37634    8.60303     7.85034
alpha_0                               0.90464      0.00014    0.90477     0.90450
alpha_1                               0.90456      0.00014    0.90470     0.90443
alpha_2                               0.90461      0.00014    0.90475     0.90447
alpha_3                               0.90458      0.00014    0.90472     0.90444
alpha_4                               0.90459      0.00014    0.90473     0.90446
alpha_5                               0.90463      0.00014    0.90476     0.90449
alpha_6                               0.90460      0.00014    0.90473     0.90446
alpha_7                               0.90462      0.00014    0.90476     0.90449
alpha_8                               0.90460      0.00014    0.90473     0.90446
alpha_9                               0.90461      0.00014    0.90475     0.90447
Alpha_loss                            -0.67301     0.00077    -0.67224    -0.67377
Training/policy_loss                  -3.12085     0.00012    -3.12073    -3.12097
Training/qf1_loss                     1255.04883   127.64575  1382.69458  1127.40308
Training/qf2_loss                     1253.50079   127.77045  1381.27124  1125.73035
Training/pf_norm                      0.08998      0.00801    0.09799     0.08196
Training/qf1_norm                     42.61608     1.87908    44.49516    40.73700
Training/qf2_norm                     46.76229     1.51791    48.28020    45.24438
log_std/mean                          -0.13617     0.00004    -0.13613    -0.13621
log_std/std                           0.00753      0.00001    0.00754     0.00752
log_std/max                           -0.12250     0.00020    -0.12230    -0.12270
log_std/min                           -0.14989     0.00002    -0.14986    -0.14991
log_probs/mean                        -2.73294     0.00245    -2.73050    -2.73539
log_probs/std                         0.24254      0.00350    0.24604     0.23904
log_probs/max                         -2.14121     0.05069    -2.09052    -2.19190
log_probs/min                         -4.64962     0.00299    -4.64663    -4.65261
mean/mean                             0.00815      0.00005    0.00820     0.00809
mean/std                              0.00453      0.00002    0.00455     0.00451
mean/max                              0.01597      0.00016    0.01613     0.01580
mean/min                              -0.00093     0.00003    -0.00089    -0.00096
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 167 50
freq 22
sample: [8, 2, 1, 5, 3, 0, 9, 4, 7, 6]
replay_buffer._size: [25350 25350 25350 25350 25350 25350 25350 25350 25350 25350]
train_time 0.13981914520263672
eval time 0.002734661102294922
2023-08-22 20:47:55,438 MainThread INFO: EPOCH:167
2023-08-22 20:47:55,438 MainThread INFO: Time Consumed:0.1455545425415039s
2023-08-22 20:47:55,438 MainThread INFO: Total Frames:252000s
 84%|████████▍ | 168/200 [03:19<00:57,  1.79s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1301.93020
Train_Epoch_Reward                    26457.41529
Running_Training_Average_Rewards      1836.11921
Explore_Time                          0.00248
Train___Time                          0.13982
Eval____Time                          0.00273
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.76900
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.03798
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.75720
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.63055
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.49966
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.60288
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.88115
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13238.28497
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.35314
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.30358
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.93595      0.35982    8.29576     7.57613
alpha_0                               0.90410      0.00014    0.90423     0.90396
alpha_1                               0.90402      0.00014    0.90416     0.90388
alpha_2                               0.90407      0.00014    0.90420     0.90393
alpha_3                               0.90404      0.00014    0.90417     0.90390
alpha_4                               0.90405      0.00014    0.90419     0.90391
alpha_5                               0.90408      0.00014    0.90422     0.90395
alpha_6                               0.90405      0.00014    0.90419     0.90392
alpha_7                               0.90408      0.00014    0.90422     0.90395
alpha_8                               0.90405      0.00014    0.90419     0.90392
alpha_9                               0.90407      0.00014    0.90420     0.90393
Alpha_loss                            -0.67706     0.00113    -0.67593    -0.67820
Training/policy_loss                  -3.12911     0.00292    -3.12619    -3.13203
Training/qf1_loss                     1075.39148   112.76013  1188.15161  962.63135
Training/qf2_loss                     1073.72937   112.60571  1186.33508  961.12366
Training/pf_norm                      0.10356      0.03549    0.13905     0.06807
Training/qf1_norm                     41.29545     1.34899    42.64444    39.94646
Training/qf2_norm                     45.74447     1.80641    47.55088    43.93806
log_std/mean                          -0.13635     0.00003    -0.13632    -0.13639
log_std/std                           0.00749      0.00000    0.00749     0.00749
log_std/max                           -0.12282     0.00007    -0.12276    -0.12289
log_std/min                           -0.14990     0.00008    -0.14982    -0.14998
log_probs/mean                        -2.73305     0.00122    -2.73183    -2.73426
log_probs/std                         0.22555      0.00482    0.23036     0.22073
log_probs/max                         -2.16883     0.03305    -2.13577    -2.20188
log_probs/min                         -4.57834     0.14211    -4.43624    -4.72045
mean/mean                             0.00837      0.00006    0.00842     0.00831
mean/std                              0.00467      0.00004    0.00471     0.00463
mean/max                              0.01659      0.00016    0.01675     0.01644
mean/min                              -0.00086     0.00001    -0.00085    -0.00087
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 168 50
freq 22
sample: [2, 4, 9, 1, 3, 7, 0, 8, 6, 5]
replay_buffer._size: [25500 25500 25500 25500 25500 25500 25500 25500 25500 25500]
train_time 0.12649178504943848
eval time 0.002340555191040039
2023-08-22 20:47:57,057 MainThread INFO: EPOCH:168
2023-08-22 20:47:57,058 MainThread INFO: Time Consumed:0.1323862075805664s
2023-08-22 20:47:57,058 MainThread INFO: Total Frames:253500s
 84%|████████▍ | 169/200 [03:20<00:53,  1.73s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1299.81989
Train_Epoch_Reward                    5389.06995
Running_Training_Average_Rewards      1412.26582
Explore_Time                          0.00287
Train___Time                          0.12649
Eval____Time                          0.00234
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.70176
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.03297
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.75986
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.63899
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.51152
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.61612
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.88969
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13243.07491
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.34752
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33435
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.83634      0.17657   8.01291     7.65977
alpha_0                               0.90355      0.00014   0.90369     0.90342
alpha_1                               0.90348      0.00014   0.90361     0.90334
alpha_2                               0.90352      0.00014   0.90366     0.90339
alpha_3                               0.90349      0.00014   0.90363     0.90336
alpha_4                               0.90351      0.00014   0.90364     0.90337
alpha_5                               0.90354      0.00014   0.90368     0.90341
alpha_6                               0.90351      0.00014   0.90364     0.90337
alpha_7                               0.90354      0.00014   0.90367     0.90340
alpha_8                               0.90351      0.00014   0.90365     0.90337
alpha_9                               0.90352      0.00014   0.90366     0.90339
Alpha_loss                            -0.68125     0.00099   -0.68026    -0.68224
Training/policy_loss                  -3.13897     0.00120   -3.13777    -3.14017
Training/qf1_loss                     1061.93951   18.90167  1080.84119  1043.03784
Training/qf2_loss                     1060.32782   18.68121  1079.00903  1041.64661
Training/pf_norm                      0.09074      0.01032   0.10105     0.08042
Training/qf1_norm                     41.20084     0.36489   41.56573    40.83594
Training/qf2_norm                     45.45903     1.00856   46.46759    44.45046
log_std/mean                          -0.13637     0.00000   -0.13637    -0.13637
log_std/std                           0.00743      0.00001   0.00744     0.00742
log_std/max                           -0.12300     0.00008   -0.12292    -0.12307
log_std/min                           -0.14992     0.00019   -0.14974    -0.15011
log_probs/mean                        -2.73438     0.00022   -2.73416    -2.73460
log_probs/std                         0.23562      0.00053   0.23615     0.23508
log_probs/max                         -2.18686     0.03601   -2.15085    -2.22288
log_probs/min                         -4.92488     0.25922   -4.66566    -5.18410
mean/mean                             0.00851      0.00002   0.00853     0.00849
mean/std                              0.00492      0.00004   0.00496     0.00487
mean/max                              0.01711      0.00004   0.01715     0.01707
mean/min                              -0.00108     0.00006   -0.00103    -0.00114
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 169 50
freq 22
sample: [8, 9, 6, 1, 4, 5, 7, 0, 3, 2]
replay_buffer._size: [25650 25650 25650 25650 25650 25650 25650 25650 25650 25650]
train_time 0.12534761428833008
eval time 0.0020186901092529297
2023-08-22 20:47:58,692 MainThread INFO: EPOCH:169
2023-08-22 20:47:58,692 MainThread INFO: Time Consumed:0.1309037208557129s
2023-08-22 20:47:58,692 MainThread INFO: Total Frames:255000s
 85%|████████▌ | 170/200 [03:22<00:51,  1.70s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1300.72058
Train_Epoch_Reward                    13803.13769
Running_Training_Average_Rewards      1521.65410
Explore_Time                          0.00286
Train___Time                          0.12535
Eval____Time                          0.00202
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.00566
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.01412
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.77294
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.60947
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.49207
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.59325
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.86554
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13280.94066
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.32920
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33304
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.93522      0.60560    8.54082     7.32963
alpha_0                               0.90301      0.00014    0.90315     0.90287
alpha_1                               0.90293      0.00014    0.90307     0.90280
alpha_2                               0.90298      0.00014    0.90312     0.90284
alpha_3                               0.90295      0.00014    0.90309     0.90281
alpha_4                               0.90296      0.00014    0.90310     0.90283
alpha_5                               0.90300      0.00014    0.90313     0.90286
alpha_6                               0.90297      0.00014    0.90310     0.90283
alpha_7                               0.90300      0.00014    0.90313     0.90286
alpha_8                               0.90297      0.00014    0.90310     0.90283
alpha_9                               0.90298      0.00014    0.90312     0.90285
Alpha_loss                            -0.68525     0.00137    -0.68387    -0.68662
Training/policy_loss                  -3.14783     0.00572    -3.14211    -3.15355
Training/qf1_loss                     1298.40875   175.01642  1473.42517  1123.39233
Training/qf2_loss                     1296.83447   174.81555  1471.65002  1122.01892
Training/pf_norm                      0.07270      0.00031    0.07301     0.07239
Training/qf1_norm                     41.96441     2.38298    44.34739    39.58142
Training/qf2_norm                     46.11770     2.97188    49.08958    43.14582
log_std/mean                          -0.13640     0.00002    -0.13639    -0.13642
log_std/std                           0.00739      0.00002    0.00741     0.00738
log_std/max                           -0.12326     0.00007    -0.12319    -0.12332
log_std/min                           -0.15023     0.00020    -0.15003    -0.15043
log_probs/mean                        -2.73392     0.00356    -2.73037    -2.73748
log_probs/std                         0.25360      0.00250    0.25611     0.25110
log_probs/max                         -2.18096     0.04282    -2.13814    -2.22378
log_probs/min                         -6.89134     1.71561    -5.17573    -8.60694
mean/mean                             0.00865      0.00002    0.00867     0.00863
mean/std                              0.00505      0.00002    0.00507     0.00503
mean/max                              0.01742      0.00006    0.01748     0.01736
mean/min                              -0.00114     0.00000    -0.00113    -0.00114
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 170 50
freq 22
sample: [5, 6, 1, 9, 0, 8, 2, 4, 7, 3]
replay_buffer._size: [25800 25800 25800 25800 25800 25800 25800 25800 25800 25800]
train_time 0.14127683639526367
eval time 0.002438783645629883
2023-08-22 20:48:00,462 MainThread INFO: EPOCH:170
2023-08-22 20:48:00,462 MainThread INFO: Time Consumed:0.14768052101135254s
2023-08-22 20:48:00,462 MainThread INFO: Total Frames:256500s
 86%|████████▌ | 171/200 [03:24<00:50,  1.73s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1303.16438
Train_Epoch_Reward                    9987.20732
Running_Training_Average_Rewards      972.64717
Explore_Time                          0.00325
Train___Time                          0.14128
Eval____Time                          0.00244
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.56830
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.98576
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.78061
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.58486
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47559
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.56762
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83307
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13310.20326
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.30481
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33876
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.61733      0.14319    8.76052     8.47414
alpha_0                               0.90247      0.00014    0.90260     0.90233
alpha_1                               0.90239      0.00014    0.90253     0.90225
alpha_2                               0.90244      0.00014    0.90257     0.90230
alpha_3                               0.90241      0.00014    0.90254     0.90227
alpha_4                               0.90242      0.00014    0.90256     0.90229
alpha_5                               0.90246      0.00014    0.90259     0.90232
alpha_6                               0.90242      0.00014    0.90256     0.90229
alpha_7                               0.90245      0.00014    0.90259     0.90232
alpha_8                               0.90242      0.00014    0.90256     0.90229
alpha_9                               0.90244      0.00014    0.90257     0.90230
Alpha_loss                            -0.68940     0.00089    -0.68851    -0.69029
Training/policy_loss                  -3.15336     0.00106    -3.15229    -3.15442
Training/qf1_loss                     1384.81873   167.06934  1551.88806  1217.74939
Training/qf2_loss                     1383.13257   167.09619  1550.22876  1216.03638
Training/pf_norm                      0.10065      0.01336    0.11400     0.08729
Training/qf1_norm                     45.37613     0.63203    46.00816    44.74410
Training/qf2_norm                     49.84866     0.69894    50.54760    49.14972
log_std/mean                          -0.13642     0.00000    -0.13641    -0.13642
log_std/std                           0.00736      0.00001    0.00737     0.00734
log_std/max                           -0.12341     0.00003    -0.12339    -0.12344
log_std/min                           -0.14994     0.00007    -0.14987    -0.15001
log_probs/mean                        -2.73495     0.00123    -2.73372    -2.73618
log_probs/std                         0.23214      0.00381    0.23595     0.22834
log_probs/max                         -2.18468     0.04476    -2.13992    -2.22944
log_probs/min                         -4.61755     0.08326    -4.53429    -4.70082
mean/mean                             0.00874      0.00004    0.00878     0.00869
mean/std                              0.00515      0.00003    0.00518     0.00511
mean/max                              0.01760      0.00011    0.01771     0.01749
mean/min                              -0.00110     0.00003    -0.00107    -0.00113
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 171 50
freq 22
sample: [6, 0, 9, 5, 4, 1, 7, 8, 2, 3]
replay_buffer._size: [25950 25950 25950 25950 25950 25950 25950 25950 25950 25950]
train_time 0.1529698371887207
eval time 0.003142118453979492
2023-08-22 20:48:02,187 MainThread INFO: EPOCH:171
2023-08-22 20:48:02,187 MainThread INFO: Time Consumed:0.15977978706359863s
2023-08-22 20:48:02,187 MainThread INFO: Total Frames:258000s
 86%|████████▌ | 172/200 [03:25<00:48,  1.73s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1305.91391
Train_Epoch_Reward                    11342.48095
Running_Training_Average_Rewards      1171.09420
Explore_Time                          0.00296
Train___Time                          0.15297
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.20978
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.97201
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.78189
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.57562
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.46569
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.54722
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.80497
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13325.72521
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.29377
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.34620
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.53157      0.05517    8.58674     8.47640
alpha_0                               0.90192      0.00014    0.90206     0.90179
alpha_1                               0.90185      0.00014    0.90198     0.90171
alpha_2                               0.90189      0.00014    0.90203     0.90176
alpha_3                               0.90187      0.00014    0.90200     0.90173
alpha_4                               0.90188      0.00014    0.90201     0.90174
alpha_5                               0.90191      0.00014    0.90205     0.90178
alpha_6                               0.90188      0.00014    0.90202     0.90175
alpha_7                               0.90191      0.00014    0.90205     0.90178
alpha_8                               0.90188      0.00014    0.90202     0.90175
alpha_9                               0.90190      0.00014    0.90203     0.90176
Alpha_loss                            -0.69364     0.00120    -0.69245    -0.69484
Training/policy_loss                  -3.16450     0.00357    -3.16093    -3.16808
Training/qf1_loss                     1419.25793   114.82080  1534.07874  1304.43713
Training/qf2_loss                     1417.53418   114.72827  1532.26245  1302.80591
Training/pf_norm                      0.10495      0.01432    0.11927     0.09063
Training/qf1_norm                     45.35831     0.23741    45.59572    45.12091
Training/qf2_norm                     49.91439     0.50691    50.42131    49.40748
log_std/mean                          -0.13649     0.00003    -0.13646    -0.13652
log_std/std                           0.00733      0.00001    0.00733     0.00732
log_std/max                           -0.12350     0.00015    -0.12335    -0.12365
log_std/min                           -0.15004     0.00007    -0.14997    -0.15011
log_probs/mean                        -2.73684     0.00181    -2.73503    -2.73865
log_probs/std                         0.23979      0.00145    0.24124     0.23834
log_probs/max                         -2.14579     0.03567    -2.11012    -2.18146
log_probs/min                         -5.09008     0.00005    -5.09003    -5.09013
mean/mean                             0.00897      0.00008    0.00905     0.00889
mean/std                              0.00532      0.00004    0.00535     0.00528
mean/max                              0.01818      0.00015    0.01833     0.01803
mean/min                              -0.00091     0.00007    -0.00083    -0.00098
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 172 50
freq 22
sample: [5, 1, 0, 9, 3, 6, 2, 4, 7, 8]
replay_buffer._size: [26100 26100 26100 26100 26100 26100 26100 26100 26100 26100]
train_time 0.1386575698852539
eval time 0.002169370651245117
2023-08-22 20:48:03,980 MainThread INFO: EPOCH:172
2023-08-22 20:48:03,980 MainThread INFO: Time Consumed:0.14404606819152832s
2023-08-22 20:48:03,980 MainThread INFO: Total Frames:259500s
 86%|████████▋ | 173/200 [03:27<00:47,  1.74s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1309.68826
Train_Epoch_Reward                    24321.54061
Running_Training_Average_Rewards      1521.70763
Explore_Time                          0.00253
Train___Time                          0.13866
Eval____Time                          0.00217
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.94248
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.96130
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.80513
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.55228
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.48168
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.55360
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.80241
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13392.86773
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.28816
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.32472
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.68444      0.16265   7.84709     7.52179
alpha_0                               0.90138      0.00014   0.90152     0.90125
alpha_1                               0.90131      0.00014   0.90144     0.90117
alpha_2                               0.90135      0.00014   0.90149     0.90122
alpha_3                               0.90132      0.00014   0.90146     0.90119
alpha_4                               0.90134      0.00014   0.90147     0.90120
alpha_5                               0.90137      0.00014   0.90151     0.90123
alpha_6                               0.90134      0.00014   0.90147     0.90120
alpha_7                               0.90137      0.00014   0.90150     0.90123
alpha_8                               0.90134      0.00014   0.90148     0.90120
alpha_9                               0.90136      0.00014   0.90149     0.90122
Alpha_loss                            -0.69787     0.00052   -0.69735    -0.69839
Training/policy_loss                  -3.17673     0.00397   -3.17276    -3.18070
Training/qf1_loss                     1123.03876   14.55463  1137.59338  1108.48413
Training/qf2_loss                     1121.45013   14.34198  1135.79211  1107.10815
Training/pf_norm                      0.09795      0.00876   0.10671     0.08918
Training/qf1_norm                     41.93057     0.34995   42.28051    41.58062
Training/qf2_norm                     46.08864     0.95547   47.04411    45.13317
log_std/mean                          -0.13668     0.00006   -0.13663    -0.13674
log_std/std                           0.00732      0.00000   0.00732     0.00731
log_std/max                           -0.12363     0.00003   -0.12360    -0.12365
log_std/min                           -0.15018     0.00007   -0.15011    -0.15025
log_probs/mean                        -2.73852     0.00475   -2.73377    -2.74327
log_probs/std                         0.24057      0.00606   0.24664     0.23451
log_probs/max                         -2.18691     0.03200   -2.15490    -2.21891
log_probs/min                         -4.97599     0.02790   -4.94809    -5.00389
mean/mean                             0.00929      0.00006   0.00936     0.00923
mean/std                              0.00547      0.00002   0.00549     0.00545
mean/max                              0.01871      0.00008   0.01878     0.01863
mean/min                              -0.00057     0.00011   -0.00046    -0.00068
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 173 50
freq 22
sample: [5, 2, 0, 6, 1, 9, 7, 3, 4, 8]
replay_buffer._size: [26250 26250 26250 26250 26250 26250 26250 26250 26250 26250]
train_time 0.11443066596984863
eval time 0.0020401477813720703
snapshot at best
2023-08-22 20:48:06,231 MainThread INFO: EPOCH:173
2023-08-22 20:48:06,231 MainThread INFO: Time Consumed:0.654137372970581s
2023-08-22 20:48:06,231 MainThread INFO: Total Frames:261000s
 87%|████████▋ | 174/200 [03:29<00:49,  1.89s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1316.14718
Train_Epoch_Reward                    6509.12928
Running_Training_Average_Rewards      1405.77169
Explore_Time                          0.00329
Train___Time                          0.11443
Eval____Time                          0.00204
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.47369
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.91744
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.87140
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.49790
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.52180
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.59306
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83217
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13503.76399
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.25213
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.27305
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.44252      0.20605   7.64856    7.23647
alpha_0                               0.90084      0.00014   0.90097    0.90070
alpha_1                               0.90077      0.00014   0.90090    0.90063
alpha_2                               0.90081      0.00014   0.90094    0.90067
alpha_3                               0.90078      0.00014   0.90092    0.90065
alpha_4                               0.90080      0.00014   0.90093    0.90066
alpha_5                               0.90083      0.00014   0.90096    0.90069
alpha_6                               0.90080      0.00014   0.90093    0.90066
alpha_7                               0.90083      0.00014   0.90096    0.90069
alpha_8                               0.90080      0.00014   0.90093    0.90066
alpha_9                               0.90081      0.00014   0.90095    0.90068
Alpha_loss                            -0.70199     0.00077   -0.70122   -0.70276
Training/policy_loss                  -3.18417     0.00041   -3.18376   -3.18459
Training/qf1_loss                     930.65942    53.35339  984.01282  877.30603
Training/qf2_loss                     929.01160    53.18652  982.19812  875.82507
Training/pf_norm                      0.07437      0.00506   0.07943    0.06931
Training/qf1_norm                     40.96551     0.79157   41.75708   40.17393
Training/qf2_norm                     45.27789     1.25698   46.53487   44.02092
log_std/mean                          -0.13685     0.00004   -0.13681   -0.13688
log_std/std                           0.00733      0.00000   0.00734    0.00733
log_std/max                           -0.12361     0.00007   -0.12354   -0.12368
log_std/min                           -0.15043     0.00014   -0.15029   -0.15056
log_probs/mean                        -2.73918     0.00231   -2.73687   -2.74148
log_probs/std                         0.26052      0.00785   0.26837    0.25266
log_probs/max                         -2.10525     0.01533   -2.08992   -2.12058
log_probs/min                         -5.82179     0.71050   -5.11129   -6.53229
mean/mean                             0.00959      0.00007   0.00966    0.00952
mean/std                              0.00555      0.00001   0.00556    0.00553
mean/max                              0.01911      0.00009   0.01920    0.01902
mean/min                              -0.00005     0.00014   0.00009    -0.00019
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 174 50
freq 22
sample: [5, 6, 4, 3, 0, 7, 2, 1, 8, 9]
replay_buffer._size: [26400 26400 26400 26400 26400 26400 26400 26400 26400 26400]
train_time 0.12333440780639648
eval time 0.0022704601287841797
snapshot at best
2023-08-22 20:48:07,899 MainThread INFO: EPOCH:174
2023-08-22 20:48:07,899 MainThread INFO: Time Consumed:0.6375346183776855s
2023-08-22 20:48:07,899 MainThread INFO: Total Frames:262500s
 88%|████████▊ | 175/200 [03:31<00:45,  1.83s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1326.15872
Train_Epoch_Reward                    16937.85249
Running_Training_Average_Rewards      1592.28408
Explore_Time                          0.00289
Train___Time                          0.12333
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.18233
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.89423
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.95266
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.44966
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.58176
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.65576
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.88409
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13629.10883
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.23391
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20005
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.88018      0.42851    8.30868     7.45167
alpha_0                               0.90030      0.00014    0.90043     0.90016
alpha_1                               0.90022      0.00014    0.90036     0.90009
alpha_2                               0.90027      0.00014    0.90040     0.90013
alpha_3                               0.90024      0.00014    0.90038     0.90010
alpha_4                               0.90025      0.00014    0.90039     0.90012
alpha_5                               0.90029      0.00014    0.90042     0.90015
alpha_6                               0.90026      0.00014    0.90039     0.90012
alpha_7                               0.90029      0.00014    0.90042     0.90015
alpha_8                               0.90026      0.00014    0.90039     0.90012
alpha_9                               0.90027      0.00014    0.90041     0.90014
Alpha_loss                            -0.70487     0.00148    -0.70339    -0.70635
Training/policy_loss                  -3.18148     0.00685    -3.17463    -3.18832
Training/qf1_loss                     1162.43820   255.09036  1417.52856  907.34784
Training/qf2_loss                     1160.70862   254.96265  1415.67126  905.74597
Training/pf_norm                      0.09702      0.01315    0.11017     0.08387
Training/qf1_norm                     43.12712     1.84002    44.96714    41.28711
Training/qf2_norm                     47.63538     2.24660    49.88198    45.38878
log_std/mean                          -0.13706     0.00007    -0.13698    -0.13713
log_std/std                           0.00733      0.00001    0.00734     0.00733
log_std/max                           -0.12405     0.00004    -0.12401    -0.12409
log_std/min                           -0.15077     0.00003    -0.15074    -0.15079
log_probs/mean                        -2.72799     0.00450    -2.72349    -2.73249
log_probs/std                         0.23354      0.00806    0.24160     0.22549
log_probs/max                         -2.11913     0.00360    -2.11553    -2.12273
log_probs/min                         -4.58808     0.06501    -4.52308    -4.65309
mean/mean                             0.00986      0.00006    0.00993     0.00980
mean/std                              0.00559      0.00003    0.00562     0.00556
mean/max                              0.01946      0.00012    0.01958     0.01935
mean/min                              0.00046      0.00010    0.00056     0.00036
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 175 50
freq 22
sample: [2, 0, 1, 8, 4, 3, 9, 5, 7, 6]
replay_buffer._size: [26550 26550 26550 26550 26550 26550 26550 26550 26550 26550]
train_time 0.1279287338256836
eval time 0.0030121803283691406
snapshot at best
2023-08-22 20:48:09,717 MainThread INFO: EPOCH:175
2023-08-22 20:48:09,717 MainThread INFO: Time Consumed:0.674767017364502s
2023-08-22 20:48:09,717 MainThread INFO: Total Frames:264000s
 88%|████████▊ | 176/200 [03:33<00:43,  1.82s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1337.23525
Train_Epoch_Reward                    14392.04397
Running_Training_Average_Rewards      1261.30086
Explore_Time                          0.00320
Train___Time                          0.12793
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.78681
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.87146
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.02704
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.41848
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.64853
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.72843
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.94793
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13724.24685
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.22141
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.14512
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.91098      0.33873    8.24971     7.57224
alpha_0                               0.89976      0.00014    0.89989     0.89962
alpha_1                               0.89968      0.00014    0.89982     0.89955
alpha_2                               0.89973      0.00014    0.89986     0.89959
alpha_3                               0.89970      0.00014    0.89983     0.89956
alpha_4                               0.89971      0.00014    0.89985     0.89958
alpha_5                               0.89974      0.00014    0.89988     0.89961
alpha_6                               0.89972      0.00014    0.89985     0.89958
alpha_7                               0.89974      0.00014    0.89988     0.89961
alpha_8                               0.89972      0.00014    0.89985     0.89958
alpha_9                               0.89973      0.00014    0.89987     0.89960
Alpha_loss                            -0.70936     0.00113    -0.70823    -0.71048
Training/policy_loss                  -3.19514     0.00171    -3.19343    -3.19685
Training/qf1_loss                     1063.00455   112.61618  1175.62073  950.38837
Training/qf2_loss                     1061.25232   112.54907  1173.80139  948.70325
Training/pf_norm                      0.11882      0.01794    0.13676     0.10088
Training/qf1_norm                     43.50802     1.46041    44.96843    42.04760
Training/qf2_norm                     48.05989     1.65260    49.71249    46.40730
log_std/mean                          -0.13736     0.00006    -0.13730    -0.13742
log_std/std                           0.00734      0.00000    0.00734     0.00734
log_std/max                           -0.12435     0.00009    -0.12426    -0.12444
log_std/min                           -0.15143     0.00014    -0.15128    -0.15157
log_probs/mean                        -2.73220     0.00108    -2.73112    -2.73328
log_probs/std                         0.23623      0.00164    0.23787     0.23460
log_probs/max                         -2.11290     0.03978    -2.07312    -2.15268
log_probs/min                         -5.87750     0.13379    -5.74371    -6.01129
mean/mean                             0.01010      0.00004    0.01014     0.01005
mean/std                              0.00571      0.00003    0.00574     0.00568
mean/max                              0.02003      0.00014    0.02018     0.01989
mean/min                              0.00077      0.00005    0.00082     0.00073
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 176 50
freq 22
sample: [7, 8, 5, 1, 9, 6, 2, 3, 0, 4]
replay_buffer._size: [26700 26700 26700 26700 26700 26700 26700 26700 26700 26700]
train_time 0.16690897941589355
eval time 0.0027723312377929688
snapshot at best
2023-08-22 20:48:11,506 MainThread INFO: EPOCH:176
2023-08-22 20:48:11,507 MainThread INFO: Time Consumed:0.6638119220733643s
2023-08-22 20:48:11,507 MainThread INFO: Total Frames:265500s
 88%|████████▊ | 177/200 [03:35<00:41,  1.81s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1346.47326
Train_Epoch_Reward                    12105.87045
Running_Training_Average_Rewards      1447.85890
Explore_Time                          0.00331
Train___Time                          0.16691
Eval____Time                          0.00277
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.02895
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.85406
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.07953
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.39607
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.69261
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.77475
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.98927
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13781.79873
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.21000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.10184
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.93156      0.14210   8.07366     7.78947
alpha_0                               0.89922      0.00014   0.89935     0.89908
alpha_1                               0.89914      0.00014   0.89928     0.89901
alpha_2                               0.89919      0.00013   0.89932     0.89905
alpha_3                               0.89916      0.00014   0.89929     0.89902
alpha_4                               0.89917      0.00014   0.89931     0.89904
alpha_5                               0.89920      0.00014   0.89934     0.89907
alpha_6                               0.89917      0.00014   0.89931     0.89904
alpha_7                               0.89920      0.00014   0.89934     0.89907
alpha_8                               0.89917      0.00014   0.89931     0.89904
alpha_9                               0.89919      0.00014   0.89933     0.89905
Alpha_loss                            -0.71337     0.00036   -0.71301    -0.71373
Training/policy_loss                  -3.20258     0.00312   -3.19946    -3.20570
Training/qf1_loss                     1235.91077   64.17273  1300.08350  1171.73804
Training/qf2_loss                     1234.26770   64.20251  1298.47021  1170.06519
Training/pf_norm                      0.10260      0.00691   0.10951     0.09569
Training/qf1_norm                     44.37109     0.47796   44.84904    43.89313
Training/qf2_norm                     48.63440     0.55115   49.18555    48.08326
log_std/mean                          -0.13761     0.00011   -0.13751    -0.13772
log_std/std                           0.00731      0.00000   0.00732     0.00731
log_std/max                           -0.12442     0.00014   -0.12428    -0.12455
log_std/min                           -0.15171     0.00025   -0.15146    -0.15196
log_probs/mean                        -2.73185     0.00615   -2.72570    -2.73801
log_probs/std                         0.23366      0.01174   0.24541     0.22192
log_probs/max                         -2.11704     0.01719   -2.09985    -2.13423
log_probs/min                         -5.01308     0.20077   -4.81231    -5.21384
mean/mean                             0.01036      0.00009   0.01045     0.01027
mean/std                              0.00590      0.00005   0.00595     0.00584
mean/max                              0.02084      0.00025   0.02108     0.02059
mean/min                              0.00098      0.00007   0.00105     0.00091
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 177 50
freq 22
sample: [8, 6, 7, 2, 5, 0, 4, 9, 1, 3]
replay_buffer._size: [26850 26850 26850 26850 26850 26850 26850 26850 26850 26850]
train_time 0.13379168510437012
eval time 0.002841472625732422
snapshot at best
2023-08-22 20:48:13,405 MainThread INFO: EPOCH:177
2023-08-22 20:48:13,406 MainThread INFO: Time Consumed:0.6800756454467773s
2023-08-22 20:48:13,406 MainThread INFO: Total Frames:267000s
 89%|████████▉ | 178/200 [03:37<00:40,  1.84s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1352.09690
Train_Epoch_Reward                    2624.89004
Running_Training_Average_Rewards      970.76015
Explore_Time                          0.00318
Train___Time                          0.13379
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.66303
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.84194
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.09809
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.39452
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.71540
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.80045
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.01204
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13791.61122
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.20950
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.09249
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.23822      0.07963   8.31785     8.15859
alpha_0                               0.89867      0.00014   0.89881     0.89854
alpha_1                               0.89860      0.00014   0.89874     0.89847
alpha_2                               0.89865      0.00013   0.89878     0.89851
alpha_3                               0.89862      0.00013   0.89875     0.89848
alpha_4                               0.89863      0.00013   0.89877     0.89850
alpha_5                               0.89866      0.00014   0.89880     0.89853
alpha_6                               0.89863      0.00014   0.89877     0.89850
alpha_7                               0.89866      0.00014   0.89880     0.89853
alpha_8                               0.89863      0.00013   0.89877     0.89850
alpha_9                               0.89865      0.00014   0.89878     0.89851
Alpha_loss                            -0.71762     0.00091   -0.71671    -0.71852
Training/policy_loss                  -3.21433     0.00159   -3.21274    -3.21592
Training/qf1_loss                     1136.26770   54.75024  1191.01794  1081.51746
Training/qf2_loss                     1134.44702   54.65967  1189.10669  1079.78735
Training/pf_norm                      0.10407      0.01343   0.11750     0.09064
Training/qf1_norm                     45.85263     0.42879   46.28141    45.42384
Training/qf2_norm                     50.59649     0.68305   51.27954    49.91344
log_std/mean                          -0.13789     0.00008   -0.13781    -0.13797
log_std/std                           0.00730      0.00001   0.00731     0.00729
log_std/max                           -0.12473     0.00006   -0.12468    -0.12479
log_std/min                           -0.15231     0.00016   -0.15214    -0.15247
log_probs/mean                        -2.73376     0.00098   -2.73278    -2.73474
log_probs/std                         0.25001      0.00194   0.25195     0.24807
log_probs/max                         -2.15345     0.01119   -2.14226    -2.16465
log_probs/min                         -5.24262     0.09219   -5.15043    -5.33481
mean/mean                             0.01068      0.00009   0.01077     0.01060
mean/std                              0.00616      0.00006   0.00622     0.00610
mean/max                              0.02187      0.00025   0.02211     0.02162
mean/min                              0.00120      0.00007   0.00127     0.00113
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 178 50
freq 22
sample: [6, 5, 8, 1, 7, 9, 4, 2, 0, 3]
replay_buffer._size: [27000 27000 27000 27000 27000 27000 27000 27000 27000 27000]
train_time 0.13534903526306152
eval time 0.0022902488708496094
snapshot at best
2023-08-22 20:48:15,346 MainThread INFO: EPOCH:178
2023-08-22 20:48:15,346 MainThread INFO: Time Consumed:0.8212072849273682s
2023-08-22 20:48:15,346 MainThread INFO: Total Frames:268500s
 90%|████████▉ | 179/200 [03:39<00:39,  1.87s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1355.06049
Train_Epoch_Reward                    12244.25418
Running_Training_Average_Rewards      899.16716
Explore_Time                          0.00316
Train___Time                          0.13535
Eval____Time                          0.00229
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.82350
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.82396
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.12876
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.38262
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.74370
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.83245
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.04357
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13818.41508
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.20218
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.07499
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.32927      0.54881    8.87808     7.78045
alpha_0                               0.89813      0.00014    0.89827     0.89800
alpha_1                               0.89806      0.00013    0.89820     0.89793
alpha_2                               0.89811      0.00013    0.89824     0.89797
alpha_3                               0.89808      0.00013    0.89821     0.89794
alpha_4                               0.89809      0.00013    0.89823     0.89796
alpha_5                               0.89812      0.00013    0.89826     0.89799
alpha_6                               0.89809      0.00013    0.89823     0.89796
alpha_7                               0.89812      0.00014    0.89826     0.89799
alpha_8                               0.89810      0.00013    0.89823     0.89796
alpha_9                               0.89811      0.00014    0.89824     0.89797
Alpha_loss                            -0.72137     0.00129    -0.72007    -0.72266
Training/policy_loss                  -3.22131     0.00356    -3.21775    -3.22487
Training/qf1_loss                     1299.06891   250.44452  1549.51343  1048.62439
Training/qf2_loss                     1297.32391   250.34369  1547.66760  1046.98022
Training/pf_norm                      0.08955      0.03046    0.12001     0.05909
Training/qf1_norm                     46.88399     2.56803    49.45203    44.31596
Training/qf2_norm                     51.39115     2.85269    54.24384    48.53846
log_std/mean                          -0.13817     0.00005    -0.13811    -0.13822
log_std/std                           0.00727      0.00001    0.00728     0.00726
log_std/max                           -0.12492     0.00007    -0.12485    -0.12500
log_std/min                           -0.15255     0.00006    -0.15249    -0.15260
log_probs/mean                        -2.73099     0.00264    -2.72835    -2.73364
log_probs/std                         0.23138      0.01066    0.24204     0.22072
log_probs/max                         -2.09910     0.00775    -2.09135    -2.10685
log_probs/min                         -4.86762     0.02718    -4.84045    -4.89480
mean/mean                             0.01091      0.00003    0.01094     0.01088
mean/std                              0.00640      0.00005    0.00645     0.00634
mean/max                              0.02267      0.00016    0.02283     0.02251
mean/min                              0.00150      0.00006    0.00156     0.00143
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 179 50
freq 22
sample: [4, 1, 0, 3, 2, 7, 5, 6, 8, 9]
replay_buffer._size: [27150 27150 27150 27150 27150 27150 27150 27150 27150 27150]
train_time 0.15361428260803223
eval time 0.0034956932067871094
snapshot at best
2023-08-22 20:48:16,925 MainThread INFO: EPOCH:179
2023-08-22 20:48:16,925 MainThread INFO: Time Consumed:0.6783225536346436s
2023-08-22 20:48:16,925 MainThread INFO: Total Frames:270000s
 90%|█████████ | 180/200 [03:40<00:35,  1.78s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1357.11791
Train_Epoch_Reward                    9482.24198
Running_Training_Average_Rewards      811.71287
Explore_Time                          0.00338
Train___Time                          0.15361
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.50547
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.81377
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.16213
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.37639
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.77522
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.86660
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.07504
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13850.21718
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.20270
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.04575
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.18269      0.00293    8.18562     8.17975
alpha_0                               0.89759      0.00014    0.89773     0.89746
alpha_1                               0.89752      0.00013    0.89766     0.89739
alpha_2                               0.89757      0.00013    0.89770     0.89743
alpha_3                               0.89754      0.00013    0.89767     0.89740
alpha_4                               0.89755      0.00013    0.89769     0.89742
alpha_5                               0.89758      0.00013    0.89772     0.89745
alpha_6                               0.89755      0.00013    0.89769     0.89742
alpha_7                               0.89758      0.00013    0.89772     0.89745
alpha_8                               0.89756      0.00013    0.89769     0.89742
alpha_9                               0.89757      0.00013    0.89770     0.89743
Alpha_loss                            -0.72665     0.00100    -0.72565    -0.72766
Training/policy_loss                  -3.24022     0.00121    -3.23902    -3.24143
Training/qf1_loss                     1178.79871   103.08508  1281.88379  1075.71362
Training/qf2_loss                     1176.91321   103.02979  1279.94299  1073.88342
Training/pf_norm                      0.09673      0.00575    0.10248     0.09098
Training/qf1_norm                     46.18583     0.04060    46.22643    46.14523
Training/qf2_norm                     51.07344     0.12959    51.20303    50.94385
log_std/mean                          -0.13830     0.00003    -0.13827    -0.13833
log_std/std                           0.00725      0.00000    0.00725     0.00724
log_std/max                           -0.12493     0.00011    -0.12482    -0.12505
log_std/min                           -0.15280     0.00008    -0.15271    -0.15288
log_probs/mean                        -2.74250     0.00010    -2.74240    -2.74259
log_probs/std                         0.25200      0.00409    0.25609     0.24791
log_probs/max                         -2.13779     0.03030    -2.10749    -2.16809
log_probs/min                         -5.15617     0.17935    -4.97682    -5.33552
mean/mean                             0.01099      0.00000    0.01099     0.01099
mean/std                              0.00668      0.00008    0.00676     0.00660
mean/max                              0.02325      0.00009    0.02333     0.02316
mean/min                              0.00164      0.00001    0.00165     0.00163
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 180 50
freq 22
sample: [8, 4, 5, 2, 3, 1, 6, 7, 0, 9]
replay_buffer._size: [27300 27300 27300 27300 27300 27300 27300 27300 27300 27300]
train_time 0.1358966827392578
eval time 0.0024940967559814453
snapshot at best
2023-08-22 20:48:18,750 MainThread INFO: EPOCH:180
2023-08-22 20:48:18,750 MainThread INFO: Time Consumed:0.6347377300262451s
2023-08-22 20:48:18,751 MainThread INFO: Total Frames:271500s
 90%|█████████ | 181/200 [03:42<00:34,  1.80s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1360.86975
Train_Epoch_Reward                    17609.87081
Running_Training_Average_Rewards      1311.21223
Explore_Time                          0.00286
Train___Time                          0.13590
Eval____Time                          0.00249
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.58097
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.82543
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.19451
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.36237
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.79373
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.89026
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.09649
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13907.29849
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.22861
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.98706
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.17395      0.50853    8.68248     7.66543
alpha_0                               0.89705      0.00013    0.89719     0.89692
alpha_1                               0.89698      0.00013    0.89712     0.89685
alpha_2                               0.89703      0.00013    0.89716     0.89689
alpha_3                               0.89700      0.00013    0.89713     0.89686
alpha_4                               0.89702      0.00013    0.89715     0.89688
alpha_5                               0.89704      0.00013    0.89718     0.89691
alpha_6                               0.89701      0.00013    0.89715     0.89688
alpha_7                               0.89704      0.00013    0.89718     0.89691
alpha_8                               0.89702      0.00013    0.89715     0.89688
alpha_9                               0.89703      0.00013    0.89716     0.89690
Alpha_loss                            -0.72911     0.00120    -0.72791    -0.73031
Training/policy_loss                  -3.23589     0.00213    -3.23376    -3.23802
Training/qf1_loss                     1141.28180   169.20721  1310.48901  972.07458
Training/qf2_loss                     1139.52161   169.02441  1308.54602  970.49719
Training/pf_norm                      0.08867      0.00059    0.08926     0.08808
Training/qf1_norm                     46.75669     2.40249    49.15918    44.35419
Training/qf2_norm                     51.26606     2.90255    54.16861    48.36351
log_std/mean                          -0.13837     0.00001    -0.13835    -0.13838
log_std/std                           0.00717      0.00002    0.00719     0.00716
log_std/max                           -0.12510     0.00003    -0.12507    -0.12513
log_std/min                           -0.15275     0.00013    -0.15262    -0.15289
log_probs/mean                        -2.72777     0.00171    -2.72606    -2.72948
log_probs/std                         0.22266      0.01250    0.23516     0.21016
log_probs/max                         -2.17656     0.05118    -2.12539    -2.22774
log_probs/min                         -4.90472     0.82907    -4.07565    -5.73379
mean/mean                             0.01101      0.00000    0.01101     0.01100
mean/std                              0.00700      0.00006    0.00706     0.00694
mean/max                              0.02371      0.00008    0.02379     0.02363
mean/min                              0.00142      0.00014    0.00156     0.00127
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 181 50
freq 22
sample: [4, 1, 3, 2, 6, 7, 5, 8, 0, 9]
replay_buffer._size: [27450 27450 27450 27450 27450 27450 27450 27450 27450 27450]
train_time 0.13228869438171387
eval time 0.002454519271850586
snapshot at best
2023-08-22 20:48:20,031 MainThread INFO: EPOCH:181
2023-08-22 20:48:20,031 MainThread INFO: Time Consumed:0.6306068897247314s
2023-08-22 20:48:20,031 MainThread INFO: Total Frames:273000s
 91%|█████████ | 182/200 [03:43<00:29,  1.64s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1367.07558
Train_Epoch_Reward                    3953.98327
Running_Training_Average_Rewards      1034.86987
Explore_Time                          0.00195
Train___Time                          0.13229
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.89279
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.84211
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.22975
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.32307
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.79280
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.89001
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.09245
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14006.74826
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.26070
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89024
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.88012      0.39926   8.27938     7.48087
alpha_0                               0.89651      0.00013   0.89665     0.89638
alpha_1                               0.89644      0.00013   0.89658     0.89631
alpha_2                               0.89649      0.00013   0.89662     0.89636
alpha_3                               0.89646      0.00013   0.89659     0.89632
alpha_4                               0.89648      0.00013   0.89661     0.89634
alpha_5                               0.89651      0.00013   0.89664     0.89637
alpha_6                               0.89647      0.00013   0.89661     0.89634
alpha_7                               0.89650      0.00013   0.89664     0.89637
alpha_8                               0.89648      0.00013   0.89661     0.89634
alpha_9                               0.89649      0.00013   0.89663     0.89636
Alpha_loss                            -0.73350     0.00032   -0.73318    -0.73382
Training/policy_loss                  -3.24906     0.00361   -3.24544    -3.25267
Training/qf1_loss                     1080.71405   19.61603  1100.33008  1061.09802
Training/qf2_loss                     1079.02490   19.47827  1098.50317  1059.54663
Training/pf_norm                      0.12699      0.02073   0.14772     0.10626
Training/qf1_norm                     45.64164     2.01737   47.65901    43.62427
Training/qf2_norm                     49.92189     2.36688   52.28878    47.55501
log_std/mean                          -0.13839     0.00002   -0.13836    -0.13841
log_std/std                           0.00713      0.00001   0.00714     0.00712
log_std/max                           -0.12518     0.00001   -0.12517    -0.12519
log_std/min                           -0.15280     0.00011   -0.15269    -0.15291
log_probs/mean                        -2.73096     0.00637   -2.72460    -2.73733
log_probs/std                         0.23615      0.00861   0.24476     0.22755
log_probs/max                         -2.16214     0.00088   -2.16125    -2.16302
log_probs/min                         -4.60448     0.23977   -4.36471    -4.84426
mean/mean                             0.01107      0.00002   0.01110     0.01105
mean/std                              0.00726      0.00005   0.00731     0.00721
mean/max                              0.02433      0.00018   0.02451     0.02416
mean/min                              0.00094      0.00010   0.00104     0.00084
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 182 50
freq 22
sample: [6, 8, 2, 1, 7, 3, 9, 0, 4, 5]
replay_buffer._size: [27545 27531 27508 27528 27520 27547 27525 27522 27503 27501]
train_time 1.6423780918121338
eval time 0.0023963451385498047
snapshot at best
2023-08-22 20:48:22,267 MainThread INFO: EPOCH:182
2023-08-22 20:48:22,267 MainThread INFO: Time Consumed:2.151301622390747s
2023-08-22 20:48:22,267 MainThread INFO: Total Frames:274500s
 92%|█████████▏| 183/200 [03:45<00:30,  1.82s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1374.31223
Train_Epoch_Reward                    6067.86193
Running_Training_Average_Rewards      921.05720
Explore_Time                          0.00199
Train___Time                          1.64238
Eval____Time                          0.00240
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.25770
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.86545
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.25476
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.31314
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.81049
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.91478
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.11330
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14072.14959
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.30291
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.82371
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.16186      1.39673    10.55859    7.76514
alpha_0                               0.89598      0.00013    0.89611     0.89584
alpha_1                               0.89591      0.00013    0.89604     0.89577
alpha_2                               0.89595      0.00013    0.89609     0.89582
alpha_3                               0.89592      0.00013    0.89606     0.89579
alpha_4                               0.89594      0.00013    0.89607     0.89580
alpha_5                               0.89597      0.00013    0.89610     0.89583
alpha_6                               0.89594      0.00013    0.89607     0.89580
alpha_7                               0.89597      0.00013    0.89610     0.89583
alpha_8                               0.89594      0.00013    0.89608     0.89581
alpha_9                               0.89595      0.00013    0.89609     0.89582
Alpha_loss                            -0.73769     0.00137    -0.73632    -0.73906
Training/policy_loss                  -3.25748     0.00376    -3.25372    -3.26124
Training/qf1_loss                     1600.69543   511.07361  2111.76904  1089.62183
Training/qf2_loss                     1598.76526   510.90222  2109.66748  1087.86304
Training/pf_norm                      0.13671      0.01084    0.14755     0.12587
Training/qf1_norm                     52.00241     6.95331    58.95573    45.04910
Training/qf2_norm                     56.98558     7.41070    64.39628    49.57488
log_std/mean                          -0.13852     0.00005    -0.13847    -0.13858
log_std/std                           0.00705      0.00002    0.00707     0.00703
log_std/max                           -0.12566     0.00011    -0.12554    -0.12577
log_std/min                           -0.15260     0.00008    -0.15253    -0.15268
log_probs/mean                        -2.73224     0.00328    -2.72896    -2.73552
log_probs/std                         0.22915      0.00813    0.23728     0.22102
log_probs/max                         -2.13858     0.04228    -2.09630    -2.18085
log_probs/min                         -4.82313     0.25333    -4.56979    -5.07646
mean/mean                             0.01104      0.00003    0.01107     0.01101
mean/std                              0.00740      0.00004    0.00744     0.00736
mean/max                              0.02484      0.00013    0.02496     0.02471
mean/min                              0.00058      0.00010    0.00068     0.00048
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 183 50
freq 22
sample: [8, 7, 9, 4, 1, 6, 5, 2, 0, 3]
replay_buffer._size: [27750 27750 27750 27750 27750 27750 27750 27750 27750 27750]
train_time 0.1253795623779297
eval time 0.0026373863220214844
snapshot at best
2023-08-22 20:48:24,113 MainThread INFO: EPOCH:183
2023-08-22 20:48:24,113 MainThread INFO: Time Consumed:0.6373405456542969s
2023-08-22 20:48:24,113 MainThread INFO: Total Frames:276000s
 92%|█████████▏| 184/200 [03:47<00:29,  1.83s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1379.77533
Train_Epoch_Reward                    10857.76512
Running_Training_Average_Rewards      695.98701
Explore_Time                          0.00278
Train___Time                          0.12538
Eval____Time                          0.00264
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.19902
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.91247
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.24887
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.35182
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.84434
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.95357
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.14605
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14073.06041
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.36343
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.80856
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.35527      0.29827    8.65353     8.05700
alpha_0                               0.89544      0.00013    0.89557     0.89530
alpha_1                               0.89537      0.00013    0.89550     0.89523
alpha_2                               0.89541      0.00013    0.89555     0.89528
alpha_3                               0.89538      0.00013    0.89552     0.89525
alpha_4                               0.89540      0.00013    0.89553     0.89527
alpha_5                               0.89543      0.00013    0.89556     0.89529
alpha_6                               0.89540      0.00013    0.89553     0.89526
alpha_7                               0.89543      0.00013    0.89556     0.89529
alpha_8                               0.89540      0.00013    0.89554     0.89527
alpha_9                               0.89541      0.00013    0.89555     0.89528
Alpha_loss                            -0.74229     0.00216    -0.74013    -0.74444
Training/policy_loss                  -3.27064     0.01266    -3.25797    -3.28330
Training/qf1_loss                     1218.27863   166.97565  1385.25427  1051.30298
Training/qf2_loss                     1216.39160   166.86523  1383.25684  1049.52637
Training/pf_norm                      0.09311      0.01823    0.11134     0.07488
Training/qf1_norm                     48.60282     1.41811    50.02093    47.18471
Training/qf2_norm                     53.39811     1.73875    55.13686    51.65936
log_std/mean                          -0.13873     0.00006    -0.13866    -0.13879
log_std/std                           0.00703      0.00000    0.00703     0.00703
log_std/max                           -0.12602     0.00002    -0.12601    -0.12604
log_std/min                           -0.15287     0.00015    -0.15272    -0.15302
log_probs/mean                        -2.73723     0.01041    -2.72683    -2.74764
log_probs/std                         0.22740      0.01234    0.23974     0.21506
log_probs/max                         -2.15344     0.00493    -2.14850    -2.15837
log_probs/min                         -4.34847     0.23947    -4.10900    -4.58794
mean/mean                             0.01094      0.00001    0.01096     0.01093
mean/std                              0.00755      0.00005    0.00760     0.00750
mean/max                              0.02541      0.00017    0.02558     0.02523
mean/min                              0.00027      0.00007    0.00034     0.00020
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 184 50
freq 22
sample: [9, 3, 8, 1, 7, 6, 2, 0, 4, 5]
replay_buffer._size: [27900 27900 27900 27900 27900 27900 27900 27900 27900 27900]
train_time 0.15853524208068848
eval time 0.002857208251953125
2023-08-22 20:48:25,624 MainThread INFO: EPOCH:184
2023-08-22 20:48:25,624 MainThread INFO: Time Consumed:0.16464018821716309s
2023-08-22 20:48:25,624 MainThread INFO: Total Frames:277500s
 92%|█████████▎| 185/200 [03:49<00:26,  1.74s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1379.85123
Train_Epoch_Reward                    4742.60835
Running_Training_Average_Rewards      722.27451
Explore_Time                          0.00252
Train___Time                          0.15854
Eval____Time                          0.00286
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.81027
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.99534
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.18855
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.44210
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.86261
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.97739
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.16747
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13999.55866
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.46302
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.84049
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.68174      0.33845   8.02019     7.34329
alpha_0                               0.89490      0.00013   0.89503     0.89476
alpha_1                               0.89483      0.00013   0.89496     0.89469
alpha_2                               0.89488      0.00013   0.89501     0.89474
alpha_3                               0.89484      0.00013   0.89498     0.89471
alpha_4                               0.89486      0.00013   0.89500     0.89473
alpha_5                               0.89489      0.00013   0.89503     0.89476
alpha_6                               0.89486      0.00013   0.89499     0.89472
alpha_7                               0.89489      0.00013   0.89502     0.89475
alpha_8                               0.89487      0.00013   0.89500     0.89473
alpha_9                               0.89488      0.00013   0.89501     0.89474
Alpha_loss                            -0.74655     0.00051   -0.74605    -0.74706
Training/policy_loss                  -3.28383     0.00023   -3.28361    -3.28406
Training/qf1_loss                     1134.06476   12.46771  1146.53247  1121.59705
Training/qf2_loss                     1132.47382   12.49176  1144.96558  1119.98206
Training/pf_norm                      0.12870      0.02065   0.14935     0.10805
Training/qf1_norm                     45.95493     1.81055   47.76548    44.14437
Training/qf2_norm                     49.92564     1.76550   51.69114    48.16014
log_std/mean                          -0.13880     0.00001   -0.13879    -0.13880
log_std/std                           0.00700      0.00001   0.00701     0.00699
log_std/max                           -0.12609     0.00001   -0.12608    -0.12610
log_std/min                           -0.15296     0.00013   -0.15283    -0.15309
log_probs/mean                        -2.73922     0.00456   -2.73467    -2.74378
log_probs/std                         0.25350      0.01102   0.26451     0.24248
log_probs/max                         -2.13248     0.05019   -2.08228    -2.18267
log_probs/min                         -5.03808     0.05205   -4.98603    -5.09012
mean/mean                             0.01098      0.00004   0.01101     0.01094
mean/std                              0.00771      0.00003   0.00774     0.00768
mean/max                              0.02602      0.00013   0.02615     0.02589
mean/min                              0.00001      0.00005   0.00006     -0.00003
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 185 50
freq 22
sample: [0, 4, 2, 7, 8, 9, 1, 5, 6, 3]
replay_buffer._size: [28050 28050 28050 28050 28050 28050 28050 28050 28050 28050]
train_time 0.1300649642944336
eval time 0.0024106502532958984
2023-08-22 20:48:27,367 MainThread INFO: EPOCH:185
2023-08-22 20:48:27,367 MainThread INFO: Time Consumed:0.13612103462219238s
2023-08-22 20:48:27,367 MainThread INFO: Total Frames:279000s
 93%|█████████▎| 186/200 [03:51<00:24,  1.74s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1375.08426
Train_Epoch_Reward                    15917.18109
Running_Training_Average_Rewards      1050.58515
Explore_Time                          0.00295
Train___Time                          0.13006
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.72765
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.06493
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.13761
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.52729
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.89041
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.01242
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.19753
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13921.46047
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.54289
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.87550
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.54428      1.00865    9.55293     7.53563
alpha_0                               0.89436      0.00013    0.89449     0.89423
alpha_1                               0.89429      0.00013    0.89443     0.89416
alpha_2                               0.89434      0.00013    0.89447     0.89420
alpha_3                               0.89431      0.00013    0.89444     0.89417
alpha_4                               0.89432      0.00013    0.89446     0.89419
alpha_5                               0.89435      0.00013    0.89449     0.89422
alpha_6                               0.89432      0.00013    0.89445     0.89418
alpha_7                               0.89435      0.00013    0.89449     0.89422
alpha_8                               0.89433      0.00013    0.89446     0.89419
alpha_9                               0.89434      0.00013    0.89447     0.89420
Alpha_loss                            -0.75049     0.00115    -0.74933    -0.75164
Training/policy_loss                  -3.29168     0.00290    -3.28877    -3.29458
Training/qf1_loss                     1321.18927   275.91742  1597.10669  1045.27185
Training/qf2_loss                     1319.30688   275.74390  1595.05078  1043.56299
Training/pf_norm                      0.07329      0.00175    0.07504     0.07155
Training/qf1_norm                     50.34105     4.89495    55.23600    45.44609
Training/qf2_norm                     55.13156     5.38798    60.51954    49.74358
log_std/mean                          -0.13885     0.00001    -0.13884    -0.13886
log_std/std                           0.00699      0.00001    0.00700     0.00698
log_std/max                           -0.12619     0.00018    -0.12601    -0.12637
log_std/min                           -0.15333     0.00012    -0.15321    -0.15346
log_probs/mean                        -2.73817     0.00126    -2.73691    -2.73943
log_probs/std                         0.22195      0.00179    0.22374     0.22016
log_probs/max                         -2.14368     0.00526    -2.13842    -2.14893
log_probs/min                         -4.71816     0.29828    -4.41988    -5.01644
mean/mean                             0.01108      0.00002    0.01110     0.01106
mean/std                              0.00772      0.00000    0.00772     0.00772
mean/max                              0.02626      0.00001    0.02628     0.02625
mean/min                              -0.00004     0.00002    -0.00002    -0.00005
------------------------------------  -----------  ---------  ----------  ----------
epoch, update_end_epoch 186 50
freq 22
sample: [5, 6, 2, 7, 0, 3, 8, 4, 9, 1]
replay_buffer._size: [28200 28200 28200 28200 28200 28200 28200 28200 28200 28200]
train_time 0.6026911735534668
eval time 0.003465414047241211
2023-08-22 20:48:29,262 MainThread INFO: EPOCH:186
2023-08-22 20:48:29,262 MainThread INFO: Time Consumed:0.6100404262542725s
2023-08-22 20:48:29,263 MainThread INFO: Total Frames:280500s
 94%|█████████▎| 187/200 [03:52<00:23,  1.79s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1369.03344
Train_Epoch_Reward                    14796.79726
Running_Training_Average_Rewards      1181.88622
Explore_Time                          0.00298
Train___Time                          0.60269
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.93781
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.10147
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.13799
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.58768
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.95344
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.08383
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.25994
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13884.24789
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.58096
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.89718
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.44819      0.22678   8.67497     8.22141
alpha_0                               0.89382      0.00013   0.89396     0.89369
alpha_1                               0.89375      0.00013   0.89389     0.89362
alpha_2                               0.89380      0.00013   0.89393     0.89367
alpha_3                               0.89377      0.00013   0.89390     0.89363
alpha_4                               0.89379      0.00013   0.89392     0.89365
alpha_5                               0.89382      0.00013   0.89395     0.89368
alpha_6                               0.89378      0.00013   0.89392     0.89365
alpha_7                               0.89381      0.00013   0.89395     0.89368
alpha_8                               0.89379      0.00013   0.89393     0.89366
alpha_9                               0.89380      0.00013   0.89394     0.89367
Alpha_loss                            -0.75419     0.00098   -0.75321    -0.75516
Training/policy_loss                  -3.29630     0.00287   -3.29342    -3.29917
Training/qf1_loss                     1367.20380   50.09674  1417.30054  1317.10706
Training/qf2_loss                     1365.43158   50.00787  1415.43945  1315.42371
Training/pf_norm                      0.09718      0.00462   0.10180     0.09256
Training/qf1_norm                     50.37720     1.31775   51.69494    49.05945
Training/qf2_norm                     54.83440     1.53344   56.36784    53.30096
log_std/mean                          -0.13881     0.00001   -0.13880    -0.13882
log_std/std                           0.00699      0.00001   0.00700     0.00699
log_std/max                           -0.12639     0.00003   -0.12636    -0.12643
log_std/min                           -0.15340     0.00007   -0.15333    -0.15347
log_probs/mean                        -2.73505     0.00032   -2.73472    -2.73537
log_probs/std                         0.23285      0.00026   0.23311     0.23258
log_probs/max                         -2.15187     0.00783   -2.14403    -2.15970
log_probs/min                         -4.66866     0.18080   -4.48786    -4.84946
mean/mean                             0.01118      0.00004   0.01122     0.01114
mean/std                              0.00780      0.00005   0.00785     0.00775
mean/max                              0.02659      0.00016   0.02675     0.02642
mean/min                              -0.00007     0.00001   -0.00006    -0.00009
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 187 50
freq 22
sample: [8, 7, 5, 4, 9, 0, 1, 2, 3, 6]
replay_buffer._size: [28350 28350 28350 28350 28350 28350 28350 28350 28350 28350]
train_time 0.14380407333374023
eval time 0.0026865005493164062
2023-08-22 20:48:31,372 MainThread INFO: EPOCH:187
2023-08-22 20:48:31,372 MainThread INFO: Time Consumed:0.15002059936523438s
2023-08-22 20:48:31,372 MainThread INFO: Total Frames:282000s
 94%|█████████▍| 188/200 [03:55<00:22,  1.88s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1363.87244
Train_Epoch_Reward                    3181.79959
Running_Training_Average_Rewards      1129.85926
Explore_Time                          0.00275
Train___Time                          0.14380
Eval____Time                          0.00269
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.51405
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.12592
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.13832
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.62280
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.99306
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.12756
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.29703
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13849.31410
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.60311
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.91083
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.44381      0.17387    7.61768     7.26994
alpha_0                               0.89329      0.00013    0.89342     0.89315
alpha_1                               0.89322      0.00013    0.89335     0.89308
alpha_2                               0.89326      0.00013    0.89340     0.89313
alpha_3                               0.89323      0.00013    0.89337     0.89310
alpha_4                               0.89325      0.00013    0.89338     0.89312
alpha_5                               0.89328      0.00013    0.89341     0.89315
alpha_6                               0.89324      0.00013    0.89338     0.89311
alpha_7                               0.89328      0.00013    0.89341     0.89314
alpha_8                               0.89325      0.00013    0.89339     0.89312
alpha_9                               0.89326      0.00013    0.89340     0.89313
Alpha_loss                            -0.75768     0.00113    -0.75655    -0.75882
Training/policy_loss                  -3.30437     0.00414    -3.30024    -3.30851
Training/qf1_loss                     986.27948    109.40936  1095.68884  876.87012
Training/qf2_loss                     984.65155    109.33209  1093.98364  875.31946
Training/pf_norm                      0.11017      0.00321    0.11338     0.10696
Training/qf1_norm                     45.30750     0.88012    46.18763    44.42738
Training/qf2_norm                     49.35535     1.09734    50.45269    48.25801
log_std/mean                          -0.13874     0.00004    -0.13871    -0.13878
log_std/std                           0.00693      0.00001    0.00695     0.00692
log_std/max                           -0.12652     0.00011    -0.12641    -0.12663
log_std/min                           -0.15304     0.00000    -0.15304    -0.15305
log_probs/mean                        -2.73012     0.00109    -2.72903    -2.73121
log_probs/std                         0.22698      0.01335    0.24033     0.21363
log_probs/max                         -2.18252     0.04043    -2.14209    -2.22295
log_probs/min                         -4.67685     0.51773    -4.15912    -5.19458
mean/mean                             0.01134      0.00003    0.01137     0.01131
mean/std                              0.00800      0.00005    0.00806     0.00795
mean/max                              0.02726      0.00019    0.02744     0.02707
mean/min                              0.00002      0.00006    0.00007     -0.00004
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 188 50
freq 22
sample: [7, 2, 9, 0, 5, 4, 6, 3, 1, 8]
replay_buffer._size: [28500 28500 28500 28500 28500 28500 28500 28500 28500 28500]
train_time 0.1262648105621338
eval time 0.0022749900817871094
2023-08-22 20:48:33,276 MainThread INFO: EPOCH:188
2023-08-22 20:48:33,276 MainThread INFO: Time Consumed:0.1316537857055664s
2023-08-22 20:48:33,276 MainThread INFO: Total Frames:283500s
 94%|█████████▍| 189/200 [03:56<00:20,  1.89s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1359.78894
Train_Epoch_Reward                    2252.43795
Running_Training_Average_Rewards      674.36783
Explore_Time                          0.00249
Train___Time                          0.12626
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.14609
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.14843
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.12891
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.65607
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.02123
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.15525
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.32041
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13804.10787
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.62244
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.92997
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.46232      0.08503   8.54734     8.37729
alpha_0                               0.89275      0.00013   0.89288     0.89262
alpha_1                               0.89268      0.00013   0.89281     0.89255
alpha_2                               0.89272      0.00013   0.89286     0.89259
alpha_3                               0.89269      0.00013   0.89283     0.89256
alpha_4                               0.89271      0.00013   0.89285     0.89258
alpha_5                               0.89274      0.00013   0.89288     0.89261
alpha_6                               0.89271      0.00013   0.89284     0.89257
alpha_7                               0.89274      0.00013   0.89287     0.89261
alpha_8                               0.89272      0.00013   0.89285     0.89258
alpha_9                               0.89273      0.00013   0.89286     0.89259
Alpha_loss                            -0.76269     0.00043   -0.76226    -0.76313
Training/policy_loss                  -3.31815     0.00226   -3.31589    -3.32041
Training/qf1_loss                     1319.60577   64.76031  1384.36609  1254.84546
Training/qf2_loss                     1317.48132   64.67480  1382.15613  1252.80652
Training/pf_norm                      0.08840      0.00359   0.09199     0.08481
Training/qf1_norm                     50.42016     0.18175   50.60191    50.23841
Training/qf2_norm                     55.76708     0.39717   56.16425    55.36990
log_std/mean                          -0.13854     0.00005   -0.13849    -0.13858
log_std/std                           0.00689      0.00001   0.00690     0.00688
log_std/max                           -0.12653     0.00002   -0.12651    -0.12655
log_std/min                           -0.15307     0.00005   -0.15303    -0.15312
log_probs/mean                        -2.73865     0.00511   -2.73354    -2.74376
log_probs/std                         0.22389      0.00194   0.22583     0.22195
log_probs/max                         -2.11763     0.03964   -2.07799    -2.15728
log_probs/min                         -4.67458     0.28511   -4.38947    -4.95969
mean/mean                             0.01148      0.00005   0.01153     0.01144
mean/std                              0.00812      0.00004   0.00817     0.00808
mean/max                              0.02788      0.00017   0.02806     0.02771
mean/min                              0.00030      0.00004   0.00034     0.00026
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 189 50
freq 22
sample: [7, 4, 6, 2, 5, 8, 3, 9, 0, 1]
replay_buffer._size: [28650 28650 28650 28650 28650 28650 28650 28650 28650 28650]
train_time 0.17727947235107422
eval time 0.0032715797424316406
2023-08-22 20:48:35,041 MainThread INFO: EPOCH:189
2023-08-22 20:48:35,042 MainThread INFO: Time Consumed:0.18474602699279785s
2023-08-22 20:48:35,042 MainThread INFO: Total Frames:285000s
 95%|█████████▌| 190/200 [03:58<00:18,  1.85s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1354.67337
Train_Epoch_Reward                    13562.76824
Running_Training_Average_Rewards      633.23353
Explore_Time                          0.00331
Train___Time                          0.17728
Eval____Time                          0.00327
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.71903
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.14620
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.10012
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.68320
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.01147
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.14363
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.30758
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13728.93901
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.61592
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.97122
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.80660      0.45202    8.25862     7.35457
alpha_0                               0.89221      0.00013    0.89235     0.89208
alpha_1                               0.89214      0.00013    0.89228     0.89201
alpha_2                               0.89219      0.00013    0.89232     0.89205
alpha_3                               0.89216      0.00013    0.89229     0.89202
alpha_4                               0.89218      0.00013    0.89231     0.89205
alpha_5                               0.89221      0.00013    0.89234     0.89207
alpha_6                               0.89217      0.00013    0.89230     0.89204
alpha_7                               0.89220      0.00013    0.89234     0.89207
alpha_8                               0.89218      0.00013    0.89232     0.89205
alpha_9                               0.89219      0.00013    0.89232     0.89206
Alpha_loss                            -0.76579     0.00137    -0.76442    -0.76716
Training/policy_loss                  -3.32355     0.00653    -3.31702    -3.33008
Training/qf1_loss                     1095.99951   182.76770  1278.76721  913.23181
Training/qf2_loss                     1094.29144   182.86078  1277.15222  911.43066
Training/pf_norm                      0.09158      0.01968    0.11126     0.07190
Training/qf1_norm                     48.08093     2.65186    50.73280    45.42907
Training/qf2_norm                     52.29592     2.42855    54.72448    49.86737
log_std/mean                          -0.13838     0.00003    -0.13835    -0.13840
log_std/std                           0.00685      0.00000    0.00685     0.00685
log_std/max                           -0.12667     0.00004    -0.12663    -0.12670
log_std/min                           -0.15297     0.00001    -0.15296    -0.15298
log_probs/mean                        -2.73025     0.00319    -2.72706    -2.73343
log_probs/std                         0.22568      0.00111    0.22679     0.22457
log_probs/max                         -2.12208     0.03641    -2.08567    -2.15849
log_probs/min                         -4.49237     0.02638    -4.46599    -4.51875
mean/mean                             0.01170      0.00006    0.01176     0.01164
mean/std                              0.00830      0.00003    0.00833     0.00827
mean/max                              0.02865      0.00018    0.02882     0.02847
mean/min                              0.00062      0.00011    0.00073     0.00051
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 190 50
freq 22
sample: [1, 2, 9, 8, 3, 4, 7, 0, 6, 5]
replay_buffer._size: [28800 28800 28800 28800 28800 28800 28800 28800 28800 28800]
train_time 0.13617277145385742
eval time 0.002781391143798828
2023-08-22 20:48:37,023 MainThread INFO: EPOCH:190
2023-08-22 20:48:37,024 MainThread INFO: Time Consumed:0.1424112319946289s
2023-08-22 20:48:37,024 MainThread INFO: Total Frames:286500s
 96%|█████████▌| 191/200 [04:00<00:17,  1.89s/it]------------------------------------  -----------  -------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1349.11887
Train_Epoch_Reward                    14468.41807
Running_Training_Average_Rewards      1009.45414
Explore_Time                          0.00272
Train___Time                          0.13617
Eval____Time                          0.00278
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.06050
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.13665
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.09270
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.69647
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.00493
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.14113
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.30462
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13687.38653
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.60088
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.00214
mean_success_rate                     0.00000

Name                                  Mean         Std      Max         Min
Reward_Mean                           8.17973      0.12163  8.30136     8.05809
alpha_0                               0.89168      0.00013  0.89181     0.89154
alpha_1                               0.89161      0.00013  0.89174     0.89147
alpha_2                               0.89165      0.00013  0.89178     0.89152
alpha_3                               0.89162      0.00013  0.89176     0.89149
alpha_4                               0.89164      0.00013  0.89178     0.89151
alpha_5                               0.89167      0.00013  0.89180     0.89154
alpha_6                               0.89163      0.00013  0.89177     0.89150
alpha_7                               0.89167      0.00013  0.89180     0.89153
alpha_8                               0.89165      0.00013  0.89178     0.89151
alpha_9                               0.89165      0.00013  0.89179     0.89152
Alpha_loss                            -0.77027     0.00025  -0.77002    -0.77051
Training/policy_loss                  -3.33506     0.00417  -3.33089    -3.33923
Training/qf1_loss                     1184.04346   1.03894  1185.08240  1183.00452
Training/qf2_loss                     1182.27972   0.96344  1183.24316  1181.31628
Training/pf_norm                      0.09561      0.00737  0.10297     0.08824
Training/qf1_norm                     50.39226     0.63361  51.02586    49.75865
Training/qf2_norm                     54.74619     0.41883  55.16503    54.32736
log_std/mean                          -0.13820     0.00002  -0.13818    -0.13822
log_std/std                           0.00680      0.00000  0.00680     0.00680
log_std/max                           -0.12676     0.00004  -0.12673    -0.12680
log_std/min                           -0.15259     0.00007  -0.15252    -0.15267
log_probs/mean                        -2.73405     0.00669  -2.72736    -2.74074
log_probs/std                         0.22862      0.00284  0.23146     0.22578
log_probs/max                         -2.18617     0.02634  -2.15982    -2.21251
log_probs/min                         -5.08003     0.31777  -4.76226    -5.39780
mean/mean                             0.01194      0.00008  0.01202     0.01187
mean/std                              0.00836      0.00001  0.00837     0.00835
mean/max                              0.02919      0.00013  0.02932     0.02906
mean/min                              0.00118      0.00018  0.00136     0.00100
------------------------------------  -----------  -------  ----------  ----------
epoch, update_end_epoch 191 50
freq 22
sample: [0, 1, 6, 5, 3, 9, 2, 7, 4, 8]
replay_buffer._size: [28950 28950 28950 28950 28950 28950 28950 28950 28950 28950]
train_time 0.2408428192138672
eval time 0.002569913864135742
2023-08-22 20:48:38,714 MainThread INFO: EPOCH:191
2023-08-22 20:48:38,714 MainThread INFO: Time Consumed:0.24662137031555176s
2023-08-22 20:48:38,714 MainThread INFO: Total Frames:288000s
 96%|█████████▌| 192/200 [04:02<00:14,  1.84s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1343.41130
Train_Epoch_Reward                    7881.70584
Running_Training_Average_Rewards      1197.09641
Explore_Time                          0.00260
Train___Time                          0.24084
Eval____Time                          0.00257
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.40030
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.11066
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.08579
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.70763
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.99870
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.14098
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.30298
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13629.12132
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.57038
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.05203
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.73630      0.41486   7.15117    6.32144
alpha_0                               0.89114      0.00013   0.89127    0.89101
alpha_1                               0.89107      0.00013   0.89121    0.89094
alpha_2                               0.89111      0.00013   0.89125    0.89098
alpha_3                               0.89109      0.00013   0.89122    0.89095
alpha_4                               0.89111      0.00013   0.89124    0.89097
alpha_5                               0.89113      0.00013   0.89127    0.89100
alpha_6                               0.89110      0.00013   0.89123    0.89096
alpha_7                               0.89113      0.00013   0.89127    0.89100
alpha_8                               0.89111      0.00013   0.89124    0.89098
alpha_9                               0.89112      0.00013   0.89125    0.89099
Alpha_loss                            -0.77366     0.00062   -0.77305   -0.77428
Training/policy_loss                  -3.33980     0.00035   -3.33945   -3.34014
Training/qf1_loss                     818.98798    98.50568  917.49365  720.48230
Training/qf2_loss                     817.26303    98.55972  915.82275  718.70331
Training/pf_norm                      0.10407      0.01487   0.11894    0.08919
Training/qf1_norm                     42.75501     2.15112   44.90614   40.60389
Training/qf2_norm                     46.97825     2.01842   48.99667   44.95983
log_std/mean                          -0.13801     0.00008   -0.13793   -0.13810
log_std/std                           0.00675      0.00003   0.00678    0.00671
log_std/max                           -0.12677     0.00014   -0.12663   -0.12691
log_std/min                           -0.15225     0.00008   -0.15217   -0.15234
log_probs/mean                        -2.72835     0.00344   -2.72491   -2.73179
log_probs/std                         0.24870      0.00915   0.25785    0.23956
log_probs/max                         -2.12744     0.02133   -2.10612   -2.14877
log_probs/min                         -6.80208     0.56891   -6.23317   -7.37099
mean/mean                             0.01228      0.00010   0.01238    0.01219
mean/std                              0.00839      0.00000   0.00840    0.00839
mean/max                              0.02973      0.00016   0.02989    0.02956
mean/min                              0.00171      0.00012   0.00183    0.00159
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 192 50
freq 22
sample: [5, 6, 8, 3, 9, 7, 4, 1, 2, 0]
replay_buffer._size: [29100 29100 29100 29100 29100 29100 29100 29100 29100 29100]
train_time 0.12459921836853027
eval time 0.0022652149200439453
2023-08-22 20:48:40,579 MainThread INFO: EPOCH:192
2023-08-22 20:48:40,579 MainThread INFO: Time Consumed:0.13024091720581055s
2023-08-22 20:48:40,579 MainThread INFO: Total Frames:289500s
 96%|█████████▋| 193/200 [04:04<00:12,  1.84s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1338.48988
Train_Epoch_Reward                    2034.64202
Running_Training_Average_Rewards      812.82553
Explore_Time                          0.00267
Train___Time                          0.12460
Eval____Time                          0.00227
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.91993
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.06880
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.10081
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.70973
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.02093
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.16577
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.32385
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13590.53137
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.52439
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.09905
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.41322      0.15838   7.57160    7.25484
alpha_0                               0.89061      0.00013   0.89074    0.89047
alpha_1                               0.89054      0.00013   0.89067    0.89040
alpha_2                               0.89058      0.00013   0.89071    0.89044
alpha_3                               0.89055      0.00013   0.89069    0.89042
alpha_4                               0.89057      0.00013   0.89071    0.89044
alpha_5                               0.89060      0.00013   0.89073    0.89046
alpha_6                               0.89056      0.00013   0.89070    0.89043
alpha_7                               0.89060      0.00013   0.89073    0.89046
alpha_8                               0.89058      0.00013   0.89071    0.89044
alpha_9                               0.89058      0.00013   0.89072    0.89045
Alpha_loss                            -0.77820     0.00033   -0.77787   -0.77853
Training/policy_loss                  -3.35346     0.00412   -3.34934   -3.35758
Training/qf1_loss                     958.09399    28.48425  986.57825  929.60974
Training/qf2_loss                     956.47424    28.41968  984.89392  928.05457
Training/pf_norm                      0.13994      0.01017   0.15011    0.12977
Training/qf1_norm                     47.05172     0.86573   47.91744   46.18599
Training/qf2_norm                     50.99739     1.03144   52.02883   49.96595
log_std/mean                          -0.13784     0.00005   -0.13779   -0.13789
log_std/std                           0.00670      0.00002   0.00672    0.00668
log_std/max                           -0.12641     0.00004   -0.12638   -0.12645
log_std/min                           -0.15225     0.00003   -0.15223   -0.15228
log_probs/mean                        -2.73264     0.00588   -2.72677   -2.73852
log_probs/std                         0.22899      0.00558   0.23457    0.22341
log_probs/max                         -2.16845     0.03573   -2.13273   -2.20418
log_probs/min                         -5.13751     0.00636   -5.13115   -5.14388
mean/mean                             0.01263      0.00008   0.01272    0.01255
mean/std                              0.00835      0.00001   0.00836    0.00834
mean/max                              0.03018      0.00012   0.03030    0.03007
mean/min                              0.00229      0.00016   0.00245    0.00213
------------------------------------  -----------  --------  ---------  ---------
epoch, update_end_epoch 193 50
freq 22
sample: [8, 7, 1, 2, 4, 5, 6, 3, 9, 0]
replay_buffer._size: [29250 29250 29250 29250 29250 29250 29250 29250 29250 29250]
train_time 0.1378934383392334
eval time 0.0026400089263916016
2023-08-22 20:48:42,620 MainThread INFO: EPOCH:193
2023-08-22 20:48:42,620 MainThread INFO: Time Consumed:0.14376163482666016s
2023-08-22 20:48:42,620 MainThread INFO: Total Frames:291000s
 97%|█████████▋| 194/200 [04:06<00:11,  1.90s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1334.67187
Train_Epoch_Reward                    14310.61863
Running_Training_Average_Rewards      807.56555
Explore_Time                          0.00263
Train___Time                          0.13789
Eval____Time                          0.00264
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.23784
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.01956
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.13291
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.70774
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.06269
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.21218
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.36734
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13574.15381
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.46909
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.13836
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.81180      0.67423    8.48602     7.13757
alpha_0                               0.89007      0.00013    0.89020     0.88994
alpha_1                               0.89000      0.00013    0.89014     0.88987
alpha_2                               0.89004      0.00013    0.89018     0.88991
alpha_3                               0.89002      0.00013    0.89015     0.88988
alpha_4                               0.89004      0.00013    0.89017     0.88991
alpha_5                               0.89006      0.00013    0.89020     0.88993
alpha_6                               0.89003      0.00013    0.89016     0.88989
alpha_7                               0.89006      0.00013    0.89019     0.88993
alpha_8                               0.89004      0.00013    0.89017     0.88991
alpha_9                               0.89005      0.00013    0.89018     0.88991
Alpha_loss                            -0.78296     0.00065    -0.78231    -0.78360
Training/policy_loss                  -3.36908     0.00032    -3.36876    -3.36940
Training/qf1_loss                     1137.79819   182.40433  1320.20251  955.39386
Training/qf2_loss                     1135.98544   182.21329  1318.19873  953.77216
Training/pf_norm                      0.12084      0.04974    0.17058     0.07110
Training/qf1_norm                     49.19083     3.48422    52.67505    45.70662
Training/qf2_norm                     53.64104     3.99173    57.63277    49.64931
log_std/mean                          -0.13763     0.00008    -0.13754    -0.13771
log_std/std                           0.00664      0.00002    0.00666     0.00662
log_std/max                           -0.12629     0.00008    -0.12622    -0.12637
log_std/min                           -0.15144     0.00005    -0.15139    -0.15148
log_probs/mean                        -2.73875     0.00314    -2.73561    -2.74189
log_probs/std                         0.22937      0.00192    0.23129     0.22745
log_probs/max                         -2.17063     0.01598    -2.15464    -2.18661
log_probs/min                         -4.39149     0.07726    -4.31423    -4.46875
mean/mean                             0.01301      0.00011    0.01312     0.01290
mean/std                              0.00837      0.00001    0.00838     0.00836
mean/max                              0.03072      0.00016    0.03087     0.03056
mean/min                              0.00310      0.00026    0.00335     0.00284
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 194 50
freq 22
sample: [8, 0, 3, 6, 9, 7, 1, 5, 2, 4]
replay_buffer._size: [29400 29400 29400 29400 29400 29400 29400 29400 29400 29400]
train_time 0.11935067176818848
eval time 0.0022516250610351562
2023-08-22 20:48:44,442 MainThread INFO: EPOCH:194
2023-08-22 20:48:44,443 MainThread INFO: Time Consumed:0.12480759620666504s
2023-08-22 20:48:44,443 MainThread INFO: Total Frames:292500s
 98%|█████████▊| 195/200 [04:08<00:09,  1.88s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1331.35522
Train_Epoch_Reward                    11474.76756
Running_Training_Average_Rewards      927.33427
Explore_Time                          0.00266
Train___Time                          0.11935
Eval____Time                          0.00225
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.73439
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.96378
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.14493
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.71282
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.07998
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.23625
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.38862
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13534.12319
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.41007
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.19989
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.65077      0.16100   7.81177     7.48978
alpha_0                               0.88954      0.00013   0.88967     0.88940
alpha_1                               0.88947      0.00013   0.88960     0.88933
alpha_2                               0.88951      0.00013   0.88964     0.88937
alpha_3                               0.88948      0.00013   0.88962     0.88935
alpha_4                               0.88950      0.00013   0.88964     0.88937
alpha_5                               0.88953      0.00013   0.88966     0.88939
alpha_6                               0.88949      0.00013   0.88963     0.88936
alpha_7                               0.88953      0.00013   0.88966     0.88939
alpha_8                               0.88951      0.00013   0.88964     0.88937
alpha_9                               0.88951      0.00013   0.88965     0.88938
Alpha_loss                            -0.78576     0.00137   -0.78439    -0.78713
Training/policy_loss                  -3.37006     0.00398   -3.36608    -3.37404
Training/qf1_loss                     988.78961    48.65009  1037.43970  940.13953
Training/qf2_loss                     986.97122    48.61740  1035.58862  938.35382
Training/pf_norm                      0.07008      0.01289   0.08297     0.05719
Training/qf1_norm                     48.70893     0.72568   49.43461    47.98325
Training/qf2_norm                     53.14330     0.83129   53.97459    52.31202
log_std/mean                          -0.13731     0.00007   -0.13724    -0.13738
log_std/std                           0.00656      0.00003   0.00658     0.00653
log_std/max                           -0.12596     0.00012   -0.12583    -0.12608
log_std/min                           -0.15109     0.00016   -0.15093    -0.15126
log_probs/mean                        -2.72809     0.00308   -2.72501    -2.73117
log_probs/std                         0.21395      0.00462   0.21857     0.20933
log_probs/max                         -2.16437     0.00440   -2.15997    -2.16877
log_probs/min                         -4.30296     0.16147   -4.14149    -4.46444
mean/mean                             0.01342      0.00009   0.01350     0.01333
mean/std                              0.00829      0.00003   0.00832     0.00827
mean/max                              0.03119      0.00005   0.03124     0.03114
mean/min                              0.00405      0.00020   0.00425     0.00385
------------------------------------  -----------  --------  ----------  ---------
epoch, update_end_epoch 195 50
freq 22
sample: [7, 8, 6, 9, 4, 5, 3, 0, 1, 2]
replay_buffer._size: [29550 29550 29550 29550 29550 29550 29550 29550 29550 29550]
train_time 0.13131189346313477
eval time 0.002371072769165039
2023-08-22 20:48:46,519 MainThread INFO: EPOCH:195
2023-08-22 20:48:46,519 MainThread INFO: Time Consumed:0.13710927963256836s
2023-08-22 20:48:46,519 MainThread INFO: Total Frames:294000s
 98%|█████████▊| 196/200 [04:10<00:07,  1.94s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1327.88353
Train_Epoch_Reward                    4911.29449
Running_Training_Average_Rewards      1023.22269
Explore_Time                          0.00286
Train___Time                          0.13131
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.24062
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.87837
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.16295
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.71256
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.10122
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.25384
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.39939
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13484.79538
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.32109
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.27800
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.74909      0.01100   7.76009     7.73809
alpha_0                               0.88900      0.00013   0.88914     0.88887
alpha_1                               0.88893      0.00013   0.88907     0.88880
alpha_2                               0.88897      0.00013   0.88911     0.88884
alpha_3                               0.88895      0.00013   0.88908     0.88881
alpha_4                               0.88897      0.00013   0.88910     0.88884
alpha_5                               0.88899      0.00013   0.88913     0.88886
alpha_6                               0.88896      0.00013   0.88909     0.88883
alpha_7                               0.88899      0.00013   0.88912     0.88886
alpha_8                               0.88897      0.00013   0.88911     0.88884
alpha_9                               0.88898      0.00013   0.88911     0.88885
Alpha_loss                            -0.79097     0.00073   -0.79024    -0.79170
Training/policy_loss                  -3.39015     0.00054   -3.38962    -3.39069
Training/qf1_loss                     1081.10007   72.50357  1153.60364  1008.59650
Training/qf2_loss                     1079.15857   72.36804  1151.52661  1006.79053
Training/pf_norm                      0.09108      0.00450   0.09558     0.08658
Training/qf1_norm                     49.71540     0.03018   49.74558    49.68521
Training/qf2_norm                     54.46070     0.37733   54.83803    54.08338
log_std/mean                          -0.13696     0.00011   -0.13685    -0.13707
log_std/std                           0.00650      0.00001   0.00650     0.00649
log_std/max                           -0.12558     0.00010   -0.12549    -0.12568
log_std/min                           -0.15074     0.00015   -0.15059    -0.15089
log_probs/mean                        -2.73805     0.00241   -2.73564    -2.74047
log_probs/std                         0.22827      0.00119   0.22946     0.22708
log_probs/max                         -2.15927     0.02246   -2.13681    -2.18173
log_probs/min                         -4.79082     0.45574   -4.33508    -5.24656
mean/mean                             0.01375      0.00007   0.01383     0.01368
mean/std                              0.00819      0.00004   0.00822     0.00815
mean/max                              0.03143      0.00000   0.03143     0.03142
mean/min                              0.00484      0.00018   0.00502     0.00465
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 196 50
freq 22
sample: [2, 4, 3, 6, 1, 8, 0, 7, 5, 9]
replay_buffer._size: [29700 29700 29700 29700 29700 29700 29700 29700 29700 29700]
train_time 0.8365404605865479
eval time 0.003142118453979492
2023-08-22 20:48:48,678 MainThread INFO: EPOCH:196
2023-08-22 20:49:14,252 MainThread INFO: Time Consumed:0.8421533107757568s
2023-08-22 20:49:14,252 MainThread INFO: Total Frames:295500s
 98%|█████████▊| 197/200 [04:37<00:29,  9.67s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1323.48582
Train_Epoch_Reward                    7165.11647
Running_Training_Average_Rewards      785.03928
Explore_Time                          0.00192
Train___Time                          0.83654
Eval____Time                          0.00314
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.15587
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.80579
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.18732
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.71737
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.13033
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.28080
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.42303
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13435.16238
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.25173
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33540
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           8.02206      0.18156   8.20362     7.84049
alpha_0                               0.88847      0.00013   0.88860     0.88833
alpha_1                               0.88840      0.00013   0.88853     0.88826
alpha_2                               0.88844      0.00013   0.88857     0.88831
alpha_3                               0.88841      0.00013   0.88855     0.88828
alpha_4                               0.88844      0.00013   0.88857     0.88830
alpha_5                               0.88846      0.00013   0.88859     0.88833
alpha_6                               0.88843      0.00013   0.88856     0.88829
alpha_7                               0.88846      0.00013   0.88859     0.88832
alpha_8                               0.88844      0.00013   0.88857     0.88830
alpha_9                               0.88845      0.00013   0.88858     0.88831
Alpha_loss                            -0.79514     0.00134   -0.79380    -0.79647
Training/policy_loss                  -3.39817     0.00464   -3.39353    -3.40281
Training/qf1_loss                     1261.77081   93.72687  1355.49768  1168.04395
Training/qf2_loss                     1259.65118   93.60785  1353.25903  1166.04333
Training/pf_norm                      0.11905      0.01859   0.13764     0.10046
Training/qf1_norm                     50.99292     1.35287   52.34579    49.64006
Training/qf2_norm                     56.14152     1.04551   57.18703    55.09602
log_std/mean                          -0.13650     0.00013   -0.13637    -0.13663
log_std/std                           0.00643      0.00003   0.00646     0.00640
log_std/max                           -0.12517     0.00000   -0.12517    -0.12517
log_std/min                           -0.15000     0.00040   -0.14959    -0.15040
log_probs/mean                        -2.73903     0.00274   -2.73629    -2.74176
log_probs/std                         0.23920      0.00476   0.24395     0.23444
log_probs/max                         -2.09223     0.04495   -2.04728    -2.13718
log_probs/min                         -4.70935     0.05405   -4.65531    -4.76340
mean/mean                             0.01403      0.00008   0.01411     0.01396
mean/std                              0.00806      0.00003   0.00809     0.00803
mean/max                              0.03144      0.00004   0.03148     0.03140
mean/min                              0.00501      0.00001   0.00502     0.00500
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 197 50
freq 22
sample: [5, 8, 0, 7, 3, 4, 9, 2, 1, 6]
replay_buffer._size: [29850 29850 29850 29850 29850 29850 29850 29850 29850 29850]
train_time 0.13375449180603027
eval time 0.002337932586669922
2023-08-22 20:49:14,505 MainThread INFO: EPOCH:197
2023-08-22 20:49:14,505 MainThread INFO: Time Consumed:0.13929438591003418s
2023-08-22 20:49:14,505 MainThread INFO: Total Frames:297000s
 99%|█████████▉| 198/200 [04:38<00:13,  6.84s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1318.58753
Train_Epoch_Reward                    16203.86462
Running_Training_Average_Rewards      942.67585
Explore_Time                          0.00258
Train___Time                          0.13375
Eval____Time                          0.00234
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.65507
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.73867
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.20848
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.71940
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.14706
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.29979
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.44210
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13391.08438
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.18465
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.38525
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.93147      0.41540   8.34687     7.51607
alpha_0                               0.88793      0.00013   0.88807     0.88780
alpha_1                               0.88786      0.00013   0.88800     0.88773
alpha_2                               0.88791      0.00013   0.88804     0.88777
alpha_3                               0.88788      0.00013   0.88801     0.88775
alpha_4                               0.88790      0.00013   0.88804     0.88777
alpha_5                               0.88793      0.00013   0.88806     0.88779
alpha_6                               0.88789      0.00013   0.88803     0.88776
alpha_7                               0.88792      0.00013   0.88806     0.88779
alpha_8                               0.88790      0.00013   0.88804     0.88777
alpha_9                               0.88791      0.00013   0.88805     0.88778
Alpha_loss                            -0.79868     0.00092   -0.79776    -0.79960
Training/policy_loss                  -3.40933     0.00304   -3.40630    -3.41237
Training/qf1_loss                     1171.69318   95.90436  1267.59753  1075.78882
Training/qf2_loss                     1169.82184   95.80487  1265.62671  1074.01697
Training/pf_norm                      0.10583      0.00979   0.11562     0.09605
Training/qf1_norm                     51.27986     1.99103   53.27089    49.28883
Training/qf2_norm                     55.80804     2.24843   58.05647    53.55961
log_std/mean                          -0.13600     0.00012   -0.13588    -0.13612
log_std/std                           0.00634      0.00001   0.00635     0.00633
log_std/max                           -0.12480     0.00018   -0.12462    -0.12497
log_std/min                           -0.14905     0.00010   -0.14895    -0.14915
log_probs/mean                        -2.73475     0.00077   -2.73398    -2.73553
log_probs/std                         0.23173      0.00033   0.23206     0.23140
log_probs/max                         -2.12255     0.01803   -2.10451    -2.14058
log_probs/min                         -4.71129     0.31413   -4.39715    -5.02542
mean/mean                             0.01430      0.00005   0.01435     0.01425
mean/std                              0.00809      0.00003   0.00812     0.00807
mean/max                              0.03170      0.00015   0.03185     0.03155
mean/min                              0.00494      0.00004   0.00498     0.00490
------------------------------------  -----------  --------  ----------  ----------
epoch, update_end_epoch 198 50
freq 22
sample: [6, 7, 2, 5, 9, 4, 8, 1, 0, 3]
replay_buffer._size: [30000 30000 30000 30000 30000 30000 30000 30000 30000 30000]
train_time 0.1212010383605957
eval time 0.002710580825805664
2023-08-22 20:49:16,326 MainThread INFO: EPOCH:198
2023-08-22 20:49:16,326 MainThread INFO: Time Consumed:0.12720465660095215s
2023-08-22 20:49:16,326 MainThread INFO: Total Frames:298500s
100%|█████████▉| 199/200 [04:40<00:05,  5.34s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1313.97215
Train_Epoch_Reward                    5792.75615
Running_Training_Average_Rewards      972.05791
Explore_Time                          0.00259
Train___Time                          0.12120
Eval____Time                          0.00271
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.39363
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.66182
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.22532
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.71070
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.15216
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.30142
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.44321
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13351.41577
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.11415
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.42754
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.47850      0.49848    7.97698     6.98002
alpha_0                               0.88740      0.00013    0.88753     0.88727
alpha_1                               0.88733      0.00013    0.88746     0.88720
alpha_2                               0.88737      0.00013    0.88751     0.88724
alpha_3                               0.88735      0.00013    0.88748     0.88721
alpha_4                               0.88737      0.00013    0.88750     0.88723
alpha_5                               0.88739      0.00013    0.88753     0.88726
alpha_6                               0.88736      0.00013    0.88749     0.88723
alpha_7                               0.88739      0.00013    0.88752     0.88726
alpha_8                               0.88737      0.00013    0.88750     0.88724
alpha_9                               0.88738      0.00013    0.88751     0.88725
Alpha_loss                            -0.80321     0.00060    -0.80261    -0.80381
Training/policy_loss                  -3.42085     0.00081    -3.42004    -3.42166
Training/qf1_loss                     1068.20782   202.16779  1270.37561  866.04004
Training/qf2_loss                     1066.52371   202.20016  1268.72388  864.32355
Training/pf_norm                      0.09797      0.01063    0.10860     0.08735
Training/qf1_norm                     49.23397     2.95828    52.19225    46.27569
Training/qf2_norm                     53.24555     2.92963    56.17518    50.31591
log_std/mean                          -0.13561     0.00008    -0.13553    -0.13569
log_std/std                           0.00632      0.00000    0.00632     0.00631
log_std/max                           -0.12430     0.00012    -0.12418    -0.12442
log_std/min                           -0.14909     0.00018    -0.14891    -0.14927
log_probs/mean                        -2.73878     0.00348    -2.73530    -2.74226
log_probs/std                         0.25078      0.00087    0.25166     0.24991
log_probs/max                         -2.19567     0.01863    -2.17704    -2.21430
log_probs/min                         -5.02735     0.39043    -4.63692    -5.41778
mean/mean                             0.01448      0.00003    0.01450     0.01445
mean/std                              0.00806      0.00002    0.00807     0.00804
mean/max                              0.03190      0.00003    0.03193     0.03187
mean/min                              0.00492      0.00002    0.00494     0.00490
------------------------------------  -----------  ---------  ----------  ---------
epoch, update_end_epoch 199 50
freq 22
sample: [2, 3, 0, 6, 9, 5, 8, 1, 7, 4]
replay_buffer._size: [30150 30150 30150 30150 30150 30150 30150 30150 30150 30150]
train_time 0.17072272300720215
eval time 0.0028672218322753906
2023-08-22 20:49:18,414 MainThread INFO: EPOCH:199
2023-08-22 20:49:18,415 MainThread INFO: Time Consumed:0.1775496006011963s
2023-08-22 20:49:18,415 MainThread INFO: Total Frames:300000s
100%|██████████| 200/200 [04:42<00:00,  4.37s/it]100%|██████████| 200/200 [04:42<00:00,  1.41s/it]
------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1309.07310
Train_Epoch_Reward                    4548.18748
Running_Training_Average_Rewards      884.82694
Explore_Time                          0.00331
Train___Time                          0.17072
Eval____Time                          0.00287
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.01628
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.61762
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.22009
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.72401
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.15849
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.30437
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.44845
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13298.95124
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.07673
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.48197
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.94464      0.11842   8.06306     7.82622
alpha_0                               0.88687      0.00013   0.88700     0.88673
alpha_1                               0.88680      0.00013   0.88693     0.88666
alpha_2                               0.88684      0.00013   0.88697     0.88671
alpha_3                               0.88681      0.00013   0.88695     0.88668
alpha_4                               0.88683      0.00013   0.88697     0.88670
alpha_5                               0.88686      0.00013   0.88699     0.88673
alpha_6                               0.88683      0.00013   0.88696     0.88669
alpha_7                               0.88686      0.00013   0.88699     0.88672
alpha_8                               0.88684      0.00013   0.88697     0.88670
alpha_9                               0.88685      0.00013   0.88698     0.88671
Alpha_loss                            -0.80754     0.00097   -0.80658    -0.80851
Training/policy_loss                  -3.43332     0.00296   -3.43036    -3.43628
Training/qf1_loss                     1239.29919   31.13586  1270.43506  1208.16333
Training/qf2_loss                     1237.34418   31.11322  1268.45740  1206.23096
Training/pf_norm                      0.09126      0.00382   0.09508     0.08745
Training/qf1_norm                     51.90671     0.62790   52.53461    51.27881
Training/qf2_norm                     56.62695     0.67023   57.29718    55.95671
log_std/mean                          -0.13532     0.00005   -0.13527    -0.13537
log_std/std                           0.00630      0.00001   0.00631     0.00628
log_std/max                           -0.12403     0.00015   -0.12388    -0.12418
log_std/min                           -0.14879     0.00025   -0.14854    -0.14904
log_probs/mean                        -2.74114     0.00039   -2.74075    -2.74153
log_probs/std                         0.25116      0.01335   0.26451     0.23781
log_probs/max                         -2.14063     0.02992   -2.11071    -2.17055
log_probs/min                         -6.16368     1.39827   -4.76540    -7.56195
mean/mean                             0.01449      0.00001   0.01450     0.01448
mean/std                              0.00808      0.00003   0.00812     0.00805
mean/max                              0.03196      0.00000   0.03196     0.03195
mean/min                              0.00490      0.00002   0.00492     0.00487
------------------------------------  -----------  --------  ----------  ----------
snapshot at finish
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 283, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 390, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 317, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 312, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 428, in train
    self.collector.terminate()
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/base.py", line 266, in terminate
    p.join()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
