W&B disabled.
2023-10-11 00:17:33,468 MainThread INFO: Experiment Name:testing_must_mtsac
2023-10-11 00:17:33,468 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      40,
      40
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      20,
      20
    ]
  },
  "traj_encoder": {
    "latent_size": 256
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 1000,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "generator_lr": 0.0001,
    "batch_size": 1280,
    "min_pool": 10000,
    "success_traj_update_only": true,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 200,
    "update_end_epoch": 1000,
    "mask_update_interval": 25,
    "eval_episodes": 3,
    "recent_traj_window": 10,
    "sl_optim_times": 5,
    "use_trajectory_info": 0
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
wandb: Tracking run with wandb version 0.15.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
2023-10-11 00:18:53,500 MainThread INFO: Finished Pretrain
  0%|          | 0/1000 [00:00<?, ?it/s]sample: [2, 8, 9, 4, 6, 7, 0, 1, 5, 3]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
train_time 68.41182255744934
snapshot at best
2023-10-11 00:20:03,497 MainThread INFO: EPOCH:0
2023-10-11 00:20:03,497 MainThread INFO: Time Consumed:69.8551414012909s
2023-10-11 00:20:03,498 MainThread INFO: Total Frames:1500s
/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/algo/rl_algo.py:385: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/1000 [01:11<19:46:10, 71.24s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1138.35236
Train_Epoch_Reward                    34653.09029
Running_Training_Average_Rewards      3465.30903
Explore_Time                          0.00319
Train___Time                          68.41182
Eval____Time                          0.00318
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.57535
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.72365
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.61218
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.18159
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.40606
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.32430
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.33251
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11633.62045
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.86230
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.07890
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           15.48734     0.95589    18.82344    12.34076
alpha_0                               0.97038      0.01685    0.99970     0.94164
alpha_1                               0.97039      0.01685    0.99970     0.94165
alpha_2                               0.97040      0.01684    0.99970     0.94166
alpha_3                               0.97041      0.01684    0.99970     0.94168
alpha_4                               0.97040      0.01684    0.99970     0.94167
alpha_5                               0.97041      0.01684    0.99970     0.94167
alpha_6                               0.97040      0.01684    0.99970     0.94167
alpha_7                               0.97041      0.01684    0.99970     0.94169
alpha_8                               0.97040      0.01684    0.99970     0.94167
alpha_9                               0.97040      0.01684    0.99970     0.94168
Alpha_loss                            -0.20126     0.11692    -0.00000    -0.40386
Training/policy_loss                  -2.90779     0.21240    -2.66702    -3.47402
Training/qf1_loss                     3702.60796   492.81595  5350.84863  1987.65393
Training/qf2_loss                     3702.52228   492.89066  5350.90527  1986.89331
Training/pf_norm                      0.20123      0.10929    0.49369     0.08328
Training/qf1_norm                     65.11361     22.62755   127.81975   39.12137
Training/qf2_norm                     65.51913     23.04836   134.92825   38.70345
log_std/mean                          -0.10195     0.04527    -0.00112    -0.14714
log_std/std                           0.00694      0.00320    0.01544     0.00126
log_std/max                           -0.08826     0.04026    0.00152     -0.13503
log_std/min                           -0.11738     0.05159    -0.00393    -0.17272
log_probs/mean                        -2.72482     0.01715    -2.67015    -2.75345
log_probs/std                         0.27637      0.06340    0.43793     0.20562
log_probs/max                         -1.95330     0.29130    -1.18761    -2.24963
log_probs/min                         -4.86686     0.78177    -3.58838    -8.81209
mean/mean                             0.00129      0.00271    0.00626     -0.00453
mean/std                              0.00536      0.00182    0.00949     0.00180
mean/max                              0.01192      0.00554    0.02550     0.00306
mean/min                              -0.00759     0.00378    -0.00175    -0.01758
------------------------------------  -----------  ---------  ----------  ----------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/13/model
sample: [7, 9, 4, 5, 8, 6, 1, 0, 3, 2]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
train_time 3.8976058959960938
2023-10-11 00:20:08,727 MainThread INFO: EPOCH:1
2023-10-11 00:20:08,728 MainThread INFO: Time Consumed:3.90604829788208s
2023-10-11 00:20:08,728 MainThread INFO: Total Frames:3000s
  0%|          | 2/1000 [01:15<8:46:45, 31.67s/it] ------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1137.95893
Train_Epoch_Reward                    12369.67282
Running_Training_Average_Rewards      2351.13816
Explore_Time                          0.00255
Train___Time                          3.89761
Eval____Time                          0.00254
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.50961
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.72365
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.61218
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.18159
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.40606
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.32430
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.33251
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11633.62045
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.86230
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.07890
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           13.62590     0.90779    16.35128    11.41939
alpha_0                               0.91381      0.01581    0.94136     0.88689
alpha_1                               0.91381      0.01582    0.94137     0.88685
alpha_2                               0.91383      0.01582    0.94138     0.88684
alpha_3                               0.91384      0.01583    0.94140     0.88686
alpha_4                               0.91382      0.01582    0.94139     0.88686
alpha_5                               0.91382      0.01583    0.94139     0.88684
alpha_6                               0.91382      0.01583    0.94139     0.88684
alpha_7                               0.91385      0.01582    0.94141     0.88690
alpha_8                               0.91383      0.01582    0.94139     0.88689
alpha_9                               0.91383      0.01583    0.94140     0.88684
Alpha_loss                            -0.60436     0.11497    -0.40479    -0.80119
Training/policy_loss                  -5.18368     1.15472    -3.46819    -7.40991
Training/qf1_loss                     2899.75061   461.64995  4380.45898  1931.16992
Training/qf2_loss                     2901.22143   461.50014  4383.14062  1933.82751
Training/pf_norm                      0.13448      0.02616    0.23245     0.08840
Training/qf1_norm                     257.31386    95.74897   470.99286   97.89458
Training/qf2_norm                     251.95782    93.47474   459.87781   94.91599
log_std/mean                          -0.13708     0.00534    -0.12890    -0.15315
log_std/std                           0.00744      0.00255    0.01437     0.00470
log_std/max                           -0.11972     0.00661    -0.10596    -0.13236
log_std/min                           -0.15622     0.01287    -0.14291    -0.19713
log_probs/mean                        -2.72063     0.01775    -2.65293    -2.74950
log_probs/std                         0.28073      0.05172    0.42822     0.21277
log_probs/max                         -1.90983     0.22774    -1.24851    -2.20939
log_probs/min                         -4.99913     0.68917    -3.93792    -7.83792
mean/mean                             0.02157      0.01361    0.04739     0.00112
mean/std                              0.05473      0.03886    0.13844     0.00570
mean/max                              0.10880      0.07807    0.29701     0.01849
mean/min                              -0.07979     0.06024    -0.00492    -0.21194
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 2, 5, 3, 8, 4, 1, 6, 7, 9]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
train_time 3.7504725456237793
2023-10-11 00:20:12,546 MainThread INFO: EPOCH:2
2023-10-11 00:20:12,547 MainThread INFO: Time Consumed:3.758230209350586s
2023-10-11 00:20:12,547 MainThread INFO: Total Frames:4500s
  0%|          | 3/1000 [01:19<5:14:55, 18.95s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1135.76819
Train_Epoch_Reward                    22906.44079
Running_Training_Average_Rewards      2330.97346
Explore_Time                          0.00237
Train___Time                          3.75047
Eval____Time                          0.00217
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.55228
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.29808
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.26805
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.21359
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.38221
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.59345
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.20918
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11609.88148
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.42974
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.25300
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           12.58287     0.81924    14.44451    10.24069
alpha_0                               0.86237      0.01340    0.88662     0.84075
alpha_1                               0.86115      0.01447    0.88658     0.83684
alpha_2                               0.86083      0.01475    0.88658     0.83577
alpha_3                               0.86100      0.01462    0.88659     0.83629
alpha_4                               0.86109      0.01455    0.88660     0.83647
alpha_5                               0.86096      0.01461    0.88658     0.83628
alpha_6                               0.86094      0.01466    0.88658     0.83608
alpha_7                               0.86111      0.01456    0.88664     0.83650
alpha_8                               0.86138      0.01432    0.88663     0.83732
alpha_9                               0.86105      0.01457    0.88658     0.83644
Alpha_loss                            -0.95814     0.08131    -0.80118    -1.07928
Training/policy_loss                  -10.69700    2.06764    -7.43744    -14.61910
Training/qf1_loss                     2184.13326   381.89461  3284.90674  1248.81445
Training/qf2_loss                     2193.46708   381.63886  3291.19458  1252.31421
Training/pf_norm                      0.19729      0.04665    0.35022     0.10412
Training/qf1_norm                     546.46317    100.42351  790.38452   347.04230
Training/qf2_norm                     528.07637    95.18462   760.38324   336.08902
log_std/mean                          -0.16601     0.01457    -0.14525    -0.19527
log_std/std                           0.03128      0.01093    0.05405     0.01425
log_std/max                           -0.12528     0.00652    -0.10957    -0.13711
log_std/min                           -0.27568     0.05269    -0.19736    -0.37864
log_probs/mean                        -2.43701     0.18564    -2.01316    -2.69100
log_probs/std                         0.77793      0.23795    1.23829     0.40979
log_probs/max                         0.65355      1.30117    3.13102     -1.48742
log_probs/min                         -5.87002     0.92064    -4.47221    -11.20004
mean/mean                             0.09080      0.02912    0.15030     0.04806
mean/std                              0.30131      0.09851    0.47788     0.13919
mean/max                              0.72267      0.24068    1.09618     0.29939
mean/min                              -0.65057     0.25592    -0.21335    -1.07043
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 2, 9, 4, 7, 1, 3, 5, 6, 0]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
train_time 3.9342002868652344
2023-10-11 00:20:16,550 MainThread INFO: EPOCH:3
2023-10-11 00:20:16,551 MainThread INFO: Time Consumed:3.942044496536255s
2023-10-11 00:20:16,551 MainThread INFO: Total Frames:6000s
  0%|          | 4/1000 [01:23<3:36:38, 13.05s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               642.99837
Train_Epoch_Reward                    11719.32626
Running_Training_Average_Rewards      1566.51466
Explore_Time                          0.00248
Train___Time                          3.93420
Eval____Time                          0.00220
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.77960
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.79668
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.76360
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -37.47751
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.67968
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -44.81386
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.36620
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6782.39761
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.24529
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.49151
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.57977     0.91001    13.47063    8.19310
alpha_0                               0.82398      0.00942    0.84056     0.80762
alpha_1                               0.81472      0.01253    0.83661     0.79322
alpha_2                               0.81191      0.01355    0.83552     0.78878
alpha_3                               0.81332      0.01302    0.83605     0.79106
alpha_4                               0.81336      0.01311    0.83624     0.79088
alpha_5                               0.81361      0.01281    0.83605     0.79177
alpha_6                               0.81265      0.01328    0.83584     0.79000
alpha_7                               0.81363      0.01297    0.83626     0.79146
alpha_8                               0.81543      0.01242    0.83709     0.79412
alpha_9                               0.81364      0.01286    0.83620     0.79179
Alpha_loss                            -1.19135     0.07964    -1.06602    -1.34879
Training/policy_loss                  -19.32661    2.77933    -14.66005   -24.26111
Training/qf1_loss                     1583.85092   342.39821  2617.28052  734.89368
Training/qf2_loss                     1608.30591   342.19778  2641.70996  759.97736
Training/pf_norm                      0.27362      0.05061    0.42215     0.16436
Training/qf1_norm                     613.05384    95.10524   910.98303   393.63977
Training/qf2_norm                     576.63109    92.07885   872.60413   358.20459
log_std/mean                          -0.21418     0.00624    -0.19619    -0.22775
log_std/std                           0.06601      0.00601    0.07571     0.05412
log_std/max                           -0.13269     0.00630    -0.12104    -0.14418
log_std/min                           -0.43484     0.02240    -0.38468    -0.47278
log_probs/mean                        -1.80705     0.08830    -1.61127    -2.08615
log_probs/std                         1.38102      0.05460    1.49042     1.19837
log_probs/max                         3.43392      0.30617    4.39794     2.61609
log_probs/min                         -6.81025     0.92170    -5.14011    -10.09194
mean/mean                             0.14828      0.01873    0.16736     0.10103
mean/std                              0.55880      0.02633    0.59827     0.48081
mean/max                              1.12902      0.03831    1.19233     1.03767
mean/min                              -1.23219     0.05069    -1.07876    -1.31361
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 3, 2, 4, 6, 1, 7, 9, 8, 5]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
train_time 4.275014400482178
2023-10-11 00:20:20,894 MainThread INFO: EPOCH:4
2023-10-11 00:20:20,895 MainThread INFO: Time Consumed:4.282905101776123s
2023-10-11 00:20:20,895 MainThread INFO: Total Frames:7500s
  0%|          | 5/1000 [01:27<2:44:23,  9.91s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               98.32961
Train_Epoch_Reward                    12534.77545
Running_Training_Average_Rewards      1572.01808
Explore_Time                          0.00257
Train___Time                          4.27501
Eval____Time                          0.00218
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.25474
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.25074
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.76229
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.43142
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.06255
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.24686
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.72024
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1536.41515
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -40.27771
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -71.11254
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.31603      0.85843    11.07890    6.81790
alpha_0                               0.78554      0.01386    0.80744     0.76174
alpha_1                               0.77027      0.01354    0.79301     0.74678
alpha_2                               0.76576      0.01313    0.78855     0.74367
alpha_3                               0.76808      0.01327    0.79083     0.74567
alpha_4                               0.76758      0.01350    0.79065     0.74449
alpha_5                               0.76918      0.01321    0.79155     0.74646
alpha_6                               0.76717      0.01321    0.78978     0.74453
alpha_7                               0.76839      0.01345    0.79124     0.74524
alpha_8                               0.77123      0.01342    0.79391     0.74832
alpha_9                               0.76948      0.01301    0.79158     0.74698
Alpha_loss                            -1.64356     0.14648    -1.34614    -1.81387
Training/policy_loss                  -29.20144    3.07330    -24.27390   -34.94413
Training/qf1_loss                     1243.48270   311.86112  2175.06274  593.74890
Training/qf2_loss                     1288.09889   313.77774  2209.18750  629.70654
Training/pf_norm                      0.33692      0.07927    0.55971     0.17194
Training/qf1_norm                     521.20595    121.32895  781.33765   139.23149
Training/qf2_norm                     490.91415    116.19974  745.30707   144.58604
log_std/mean                          -0.17314     0.02045    -0.14974    -0.20931
log_std/std                           0.05237      0.01142    0.07165     0.03443
log_std/max                           -0.09968     0.01545    -0.08217    -0.12864
log_std/min                           -0.34890     0.06377    -0.25726    -0.47450
log_probs/mean                        -2.28489     0.23613    -1.73541    -2.58196
log_probs/std                         0.92811      0.23585    1.40310     0.61810
log_probs/max                         0.87932      1.24875    3.62137     -0.97746
log_probs/min                         -6.14008     0.86314    -4.78143    -10.03703
mean/mean                             -0.10705     0.14427    0.11056     -0.33387
mean/std                              0.33804      0.12841    0.57793     0.17145
mean/max                              0.45387      0.32055    1.03746     0.09015
mean/min                              -0.92293     0.21730    -0.57483    -1.30154
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 9, 1, 4, 8, 3, 5, 2, 6, 0]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
train_time 4.896266460418701
2023-10-11 00:20:25,869 MainThread INFO: EPOCH:5
2023-10-11 00:20:25,869 MainThread INFO: Time Consumed:4.904729843139648s
2023-10-11 00:20:25,869 MainThread INFO: Total Frames:9000s
  1%|          | 6/1000 [01:32<2:16:23,  8.23s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               57.43074
Train_Epoch_Reward                    1164.78288
Running_Training_Average_Rewards      847.29615
Explore_Time                          0.00318
Train___Time                          4.89627
Eval____Time                          0.00218
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.71021
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.18539
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -66.56084
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.37833
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.71481
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.24298
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -75.02524
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1155.46189
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.17720
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -76.15945
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.09093     0.81737    10.49901    5.98479
alpha_0                               0.74506     0.00960    0.76155     0.72891
alpha_1                               0.72512     0.01201    0.74655     0.70511
alpha_2                               0.72357     0.01153    0.74347     0.70389
alpha_3                               0.72552     0.01163    0.74547     0.70545
alpha_4                               0.72388     0.01157    0.74427     0.70434
alpha_5                               0.72527     0.01202    0.74624     0.70485
alpha_6                               0.72279     0.01235    0.74431     0.70181
alpha_7                               0.72467     0.01132    0.74502     0.70593
alpha_8                               0.72750     0.01205    0.74811     0.70683
alpha_9                               0.72459     0.01275    0.74676     0.70292
Alpha_loss                            -1.85840    0.07037    -1.70841    -1.96637
Training/policy_loss                  -38.23931   2.26110    -35.01565   -42.79210
Training/qf1_loss                     972.24779   233.55874  1740.26404  419.24130
Training/qf2_loss                     1019.80693  240.60545  1806.07190  447.87384
Training/pf_norm                      0.33831     0.05591    0.50729     0.21027
Training/qf1_norm                     301.74390   134.84461  758.43311   73.84456
Training/qf2_norm                     339.82617   134.54998  803.66907   99.88081
log_std/mean                          -0.21694    0.01104    -0.20301    -0.24180
log_std/std                           0.07334     0.00672    0.09149     0.06418
log_std/max                           -0.11847    0.01219    -0.09944    -0.14093
log_std/min                           -0.47707    0.02634    -0.41756    -0.53436
log_probs/mean                        -1.81356    0.11426    -1.46806    -1.99158
log_probs/std                         1.38148     0.07332    1.59047     1.24652
log_probs/max                         3.37528     0.50983    4.70450     2.35968
log_probs/min                         -6.84611    0.97543    -5.06631    -10.39025
mean/mean                             -0.08018    0.17443    0.22032     -0.35375
mean/std                              0.53869     0.05688    0.61517     0.39939
mean/max                              1.13987     0.29227    1.50417     0.40893
mean/min                              -1.21249    0.10878    -1.00652    -1.39614
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 1, 8, 7, 9, 4, 2, 0, 6, 5]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
train_time 4.2056262493133545
2023-10-11 00:20:30,148 MainThread INFO: EPOCH:6
2023-10-11 00:20:30,148 MainThread INFO: Time Consumed:4.214228868484497s
2023-10-11 00:20:30,149 MainThread INFO: Total Frames:10500s
  1%|          | 7/1000 [01:36<1:54:53,  6.94s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               -12.20163
Train_Epoch_Reward                    1264.58709
Running_Training_Average_Rewards      498.80485
Explore_Time                          0.00313
Train___Time                          4.20563
Eval____Time                          0.00240
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -87.56603
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -92.54527
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -25.76512
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.03949
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -38.81215
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.09626
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.97845
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 432.72707
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -50.16082
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -63.77977
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           8.02375     0.84047    10.62640    6.20069
alpha_0                               0.71240     0.01065    0.72877     0.69289
alpha_1                               0.68568     0.01149    0.70492     0.66538
alpha_2                               0.68394     0.01169    0.70370     0.66371
alpha_3                               0.68541     0.01142    0.70525     0.66600
alpha_4                               0.68526     0.01117    0.70416     0.66572
alpha_5                               0.68493     0.01149    0.70465     0.66501
alpha_6                               0.68123     0.01190    0.70161     0.66080
alpha_7                               0.68787     0.01063    0.70576     0.66929
alpha_8                               0.68666     0.01162    0.70663     0.66665
alpha_9                               0.68247     0.01164    0.70271     0.66257
Alpha_loss                            -2.21985    0.17579    -1.90610    -2.49029
Training/policy_loss                  -46.34358   2.02108    -42.63662   -50.29427
Training/qf1_loss                     876.80420   216.01704  1580.40344  365.26208
Training/qf2_loss                     898.53826   224.58473  1615.64587  376.82910
Training/pf_norm                      0.36723     0.06493    0.52950     0.22132
Training/qf1_norm                     255.79721   167.09651  770.47211   28.88901
Training/qf2_norm                     302.40259   171.62666  825.45880   55.57685
log_std/mean                          -0.22809    0.00860    -0.21481    -0.24773
log_std/std                           0.08767     0.00518    0.09768     0.07883
log_std/max                           -0.10902    0.00705    -0.09725    -0.12543
log_std/min                           -0.52909    0.01780    -0.49857    -0.57662
log_probs/mean                        -1.90150    0.22516    -1.40906    -2.18867
log_probs/std                         1.24407     0.18877    1.68607     1.00026
log_probs/max                         2.43228     1.19902    5.30990     0.60649
log_probs/min                         -6.79448    0.80479    -5.00590    -11.25417
mean/mean                             0.27861     0.06323    0.38525     0.19547
mean/std                              0.44988     0.08917    0.63062     0.35319
mean/max                              1.45899     0.05970    1.59253     1.38483
mean/min                              -0.70495    0.23836    -0.39776    -1.09929
------------------------------------  ----------  ---------  ----------  ---------
sample: [9, 4, 2, 7, 1, 0, 3, 5, 8, 6]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
train_time 4.540714263916016
2023-10-11 00:20:34,768 MainThread INFO: EPOCH:7
2023-10-11 00:20:34,769 MainThread INFO: Time Consumed:4.549744129180908s
2023-10-11 00:20:34,769 MainThread INFO: Total Frames:12000s
  1%|          | 8/1000 [01:41<1:42:30,  6.20s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               925.40219
Train_Epoch_Reward                    -149.49523
Running_Training_Average_Rewards      75.99582
Explore_Time                          0.00318
Train___Time                          4.54071
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.13522
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.72763
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.52593
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2352.52970
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.72807
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -97.03986
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.90868
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6692.12472
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -11.77324
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           542.20611
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.84737     0.75356    9.76238     5.57359
alpha_0                               0.67238     0.01155    0.69267     0.65301
alpha_1                               0.64485     0.01166    0.66517     0.62504
alpha_2                               0.64373     0.01141    0.66351     0.62420
alpha_3                               0.64670     0.01114    0.66581     0.62749
alpha_4                               0.64612     0.01119    0.66552     0.62693
alpha_5                               0.64476     0.01157    0.66480     0.62501
alpha_6                               0.64102     0.01127    0.66059     0.62172
alpha_7                               0.65045     0.01089    0.66910     0.63157
alpha_8                               0.64700     0.01127    0.66645     0.62762
alpha_9                               0.64353     0.01085    0.66238     0.62501
Alpha_loss                            -2.68614    0.12722    -2.46245    -2.88410
Training/policy_loss                  -54.45502   2.46782    -50.10098   -58.54202
Training/qf1_loss                     806.23892   201.19120  1361.25574  389.09192
Training/qf2_loss                     809.35918   202.78127  1368.78223  390.38559
Training/pf_norm                      0.31546     0.06652    0.59801     0.18042
Training/qf1_norm                     257.38436   161.17999  758.63745   35.33326
Training/qf2_norm                     271.77165   163.02876  771.20764   36.34876
log_std/mean                          -0.23033    0.00726    -0.21798    -0.24546
log_std/std                           0.09602     0.00284    0.10325     0.09041
log_std/max                           -0.12012    0.00879    -0.10203    -0.13256
log_std/min                           -0.53926    0.00890    -0.52402    -0.55915
log_probs/mean                        -2.17926    0.05759    -2.03701    -2.29449
log_probs/std                         1.01991     0.03732    1.10326     0.93485
log_probs/max                         1.27457     0.34400    2.00936     0.70908
log_probs/min                         -6.82102    0.92856    -5.20576    -9.80633
mean/mean                             0.17477     0.04896    0.24006     0.09022
mean/std                              0.39185     0.01320    0.41941     0.37036
mean/max                              1.50346     0.04865    1.59015     1.38271
mean/min                              -0.61918    0.05241    -0.51039    -0.69292
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 7, 3, 8, 0, 5, 6, 9, 1, 4]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
train_time 4.179421663284302
2023-10-11 00:20:39,017 MainThread INFO: EPOCH:8
2023-10-11 00:20:39,017 MainThread INFO: Time Consumed:4.188387870788574s
2023-10-11 00:20:39,018 MainThread INFO: Total Frames:13500s
  1%|          | 9/1000 [01:45<1:32:50,  5.62s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               615.63114
Train_Epoch_Reward                    11517.92987
Running_Training_Average_Rewards      421.10072
Explore_Time                          0.00300
Train___Time                          4.17942
Eval____Time                          0.00232
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.13444
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -64.77646
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -29.43924
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.22562
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -65.16783
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.20651
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.25918
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6691.20344
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.26816
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -60.41463
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.04418      0.91217    12.15364    7.15345
alpha_0                               0.63920      0.00638    0.65283     0.63089
alpha_1                               0.60633      0.01061    0.62485     0.58827
alpha_2                               0.60555      0.01042    0.62401     0.58794
alpha_3                               0.60902      0.01034    0.62730     0.59174
alpha_4                               0.60914      0.00982    0.62674     0.59284
alpha_5                               0.60628      0.01049    0.62482     0.58865
alpha_6                               0.60300      0.01059    0.62153     0.58499
alpha_7                               0.61354      0.01006    0.63138     0.59671
alpha_8                               0.61001      0.00962    0.62743     0.59402
alpha_9                               0.60662      0.01058    0.62483     0.58858
Alpha_loss                            -2.85636     0.03778    -2.78220    -2.94563
Training/policy_loss                  -65.30702    3.41342    -58.52911   -71.33344
Training/qf1_loss                     1091.01969   270.90670  2077.10986  478.88144
Training/qf2_loss                     1093.02590   272.41712  2083.37280  477.28424
Training/pf_norm                      0.34161      0.06841    0.55279     0.17772
Training/qf1_norm                     392.90622    255.85629  1391.65967  42.02443
Training/qf2_norm                     400.71903    253.74872  1380.23206  50.76990
log_std/mean                          -0.26043     0.01519    -0.23318    -0.28238
log_std/std                           0.11025      0.00746    0.12330     0.10065
log_std/max                           -0.11499     0.00732    -0.10137    -0.12704
log_std/min                           -0.61783     0.03678    -0.53680    -0.67600
log_probs/mean                        -1.76863     0.27071    -1.36427    -2.23094
log_probs/std                         1.54999      0.31853    2.05271     0.98073
log_probs/max                         4.70655      1.70580    7.21388     1.32865
log_probs/min                         -6.82078     0.96186    -5.27645    -11.26703
mean/mean                             0.23830      0.05361    0.33177     0.14181
mean/std                              0.51834      0.07320    0.60827     0.39522
mean/max                              1.97294      0.17720    2.19139     1.57807
mean/min                              -0.99028     0.24988    -0.55487    -1.32449
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 9, 5, 4, 2, 8, 1, 3, 6, 7]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
train_time 4.238837718963623
snapshot at best
2023-10-11 00:20:43,884 MainThread INFO: EPOCH:9
2023-10-11 00:20:43,884 MainThread INFO: Time Consumed:4.684600353240967s
2023-10-11 00:20:43,884 MainThread INFO: Total Frames:15000s
  1%|          | 10/1000 [01:50<1:28:26,  5.36s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               3838.09897
Train_Epoch_Reward                    10093.01891
Running_Training_Average_Rewards      715.38178
Explore_Time                          0.00362
Train___Time                          4.23884
Eval____Time                          0.00244
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.24151
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.96384
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.80649
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.68663
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.67043
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -43.83837
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -50.11760
1                                     0.00000
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 38835.39629
0                                     1.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.37273
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.70902
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.85078      0.97014    11.84148    6.14683
alpha_0                               0.62371      0.00535    0.63085     0.61352
alpha_1                               0.57056      0.00993    0.58809     0.55391
alpha_2                               0.57054      0.00999    0.58776     0.55336
alpha_3                               0.57590      0.00892    0.59157     0.56041
alpha_4                               0.57665      0.00938    0.59268     0.56055
alpha_5                               0.57225      0.00913    0.58848     0.55672
alpha_6                               0.56783      0.00964    0.58481     0.55143
alpha_7                               0.58041      0.00928    0.59655     0.56422
alpha_8                               0.57845      0.00890    0.59387     0.56317
alpha_9                               0.57319      0.00829    0.58840     0.55904
Alpha_loss                            -3.01104     0.10540    -2.85668    -3.24376
Training/policy_loss                  -75.74601    2.65820    -71.14088   -80.31649
Training/qf1_loss                     1192.72097   274.96281  2033.05469  613.74725
Training/qf2_loss                     1187.94493   275.63064  2025.89624  605.02032
Training/pf_norm                      0.44525      0.09568    0.71001     0.23575
Training/qf1_norm                     382.79762    268.47554  1448.24536  46.18013
Training/qf2_norm                     385.47340    265.26021  1434.50562  46.18522
log_std/mean                          -0.28517     0.00680    -0.26889    -0.29974
log_std/std                           0.12850      0.00437    0.13606     0.11785
log_std/max                           -0.11152     0.00667    -0.09359    -0.12256
log_std/min                           -0.68770     0.02955    -0.64063    -0.73309
log_probs/mean                        -1.45312     0.08007    -1.27205    -1.61592
log_probs/std                         1.73199      0.14710    2.09865     1.48950
log_probs/max                         5.28992      1.00767    7.66753     3.88397
log_probs/min                         -7.18689     0.90973    -5.53832    -10.48860
mean/mean                             0.07062      0.10751    0.27162     -0.06700
mean/std                              0.65209      0.02650    0.69531     0.60939
mean/max                              2.19630      0.03712    2.29249     2.13625
mean/min                              -1.20445     0.09532    -1.05923    -1.35439
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 9, 5, 0, 3, 1, 2, 6, 4, 8]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
train_time 5.11074686050415
2023-10-11 00:20:49,339 MainThread INFO: EPOCH:10
2023-10-11 00:20:49,340 MainThread INFO: Time Consumed:5.120752811431885s
2023-10-11 00:20:49,340 MainThread INFO: Total Frames:16500s
  1%|          | 11/1000 [01:55<1:28:50,  5.39s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               903.34751
Train_Epoch_Reward                    31796.11599
Running_Training_Average_Rewards      1780.23549
Explore_Time                          0.00313
Train___Time                          5.11075
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.70023
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -60.96531
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.85988
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -13.53477
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.97202
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.47296
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -55.09356
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9505.71558
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.52281
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.11889
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.40410      0.97260    11.32326    5.99463
alpha_0                               0.60016      0.00819    0.61342     0.58743
alpha_1                               0.53901      0.00798    0.55375     0.52572
alpha_2                               0.53658      0.00945    0.55319     0.52065
alpha_3                               0.54377      0.00959    0.56025     0.52757
alpha_4                               0.54515      0.00863    0.56039     0.53067
alpha_5                               0.54024      0.00939    0.55656     0.52426
alpha_6                               0.53520      0.00913    0.55126     0.51974
alpha_7                               0.54668      0.01019    0.56405     0.52917
alpha_8                               0.54679      0.00966    0.56301     0.53005
alpha_9                               0.54414      0.00837    0.55889     0.52990
Alpha_loss                            -3.45380     0.07041    -3.24117    -3.61480
Training/policy_loss                  -83.87313    2.46112    -79.70660   -88.11581
Training/qf1_loss                     1199.30148   284.63817  2176.42603  592.12085
Training/qf2_loss                     1195.43554   285.25805  2173.60791  586.78680
Training/pf_norm                      0.48635      0.10614    0.70059     0.27566
Training/qf1_norm                     426.91674    284.34734  1540.12036  80.92715
Training/qf2_norm                     426.55886    280.82545  1512.96533  79.68828
log_std/mean                          -0.27531     0.00770    -0.26262    -0.29187
log_std/std                           0.12039      0.00988    0.13194     0.10506
log_std/max                           -0.11771     0.01267    -0.09548    -0.15037
log_std/min                           -0.67317     0.02637    -0.61564    -0.71836
log_probs/mean                        -1.68975     0.11733    -1.43015    -1.91945
log_probs/std                         1.50008      0.15817    1.82553     1.27421
log_probs/max                         3.80777      1.20621    6.00318     1.79543
log_probs/min                         -7.01545     0.96355    -5.27658    -11.62827
mean/mean                             0.06662      0.04578    0.12931     -0.02718
mean/std                              0.59555      0.03239    0.64526     0.54174
mean/max                              2.17411      0.04368    2.28830     2.09189
mean/min                              -1.34186     0.10536    -1.12273    -1.49605
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 2, 8, 5, 7, 1, 9, 3, 6, 0]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
train_time 4.380539417266846
2023-10-11 00:20:53,801 MainThread INFO: EPOCH:11
2023-10-11 00:20:53,801 MainThread INFO: Time Consumed:4.3890321254730225s
2023-10-11 00:20:53,801 MainThread INFO: Total Frames:18000s
  1%|          | 12/1000 [02:00<1:24:04,  5.11s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               14.48407
Train_Epoch_Reward                    10627.52478
Running_Training_Average_Rewards      1750.55532
Explore_Time                          0.00254
Train___Time                          4.38054
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.79002
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.28264
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.49670
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.00337
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.49823
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.04589
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.80266
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 584.47486
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.37472
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.33995
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.78831      0.90108    10.62342    5.62432
alpha_0                               0.57471      0.00829    0.58734     0.56066
alpha_1                               0.51231      0.00759    0.52558     0.49908
alpha_2                               0.50577      0.00839    0.52050     0.49152
alpha_3                               0.51149      0.00907    0.52741     0.49608
alpha_4                               0.51496      0.00930    0.53053     0.49886
alpha_5                               0.50871      0.00859    0.52410     0.49439
alpha_6                               0.50452      0.00866    0.51959     0.48970
alpha_7                               0.51228      0.00941    0.52899     0.49651
alpha_8                               0.51348      0.00953    0.52989     0.49734
alpha_9                               0.51641      0.00755    0.52975     0.50323
Alpha_loss                            -3.80038     0.09254    -3.58808    -3.97266
Training/policy_loss                  -91.16491    2.15514    -87.92483   -95.41203
Training/qf1_loss                     1130.47810   277.56812  2079.86694  414.19174
Training/qf2_loss                     1129.64825   278.33414  2080.91016  415.77792
Training/pf_norm                      0.42594      0.07818    0.65130     0.18488
Training/qf1_norm                     379.09226    304.60199  1598.81641  55.98656
Training/qf2_norm                     378.68967    298.05756  1574.97815  66.15992
log_std/mean                          -0.26132     0.00721    -0.25064    -0.27574
log_std/std                           0.10731      0.00840    0.12341     0.09390
log_std/max                           -0.10201     0.00886    -0.08926    -0.12017
log_std/min                           -0.59211     0.02608    -0.54384    -0.65140
log_probs/mean                        -1.71601     0.05716    -1.52542    -1.86650
log_probs/std                         1.50372      0.11769    1.79129     1.31013
log_probs/max                         3.93636      0.98574    6.29817     2.33149
log_probs/min                         -6.98903     0.87511    -5.54540    -10.83679
mean/mean                             -0.06534     0.09905    0.09754     -0.17760
mean/std                              0.58455      0.01758    0.63165     0.56246
mean/max                              1.94605      0.15691    2.30195     1.76749
mean/min                              -1.41917     0.10114    -1.24107    -1.54839
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 7, 1, 4, 0, 6, 8, 5, 2, 3]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
train_time 4.223540544509888
2023-10-11 00:20:58,099 MainThread INFO: EPOCH:12
2023-10-11 00:20:58,099 MainThread INFO: Time Consumed:4.232534646987915s
2023-10-11 00:20:58,100 MainThread INFO: Total Frames:19500s
  1%|▏         | 13/1000 [02:04<1:19:58,  4.86s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               86.14640
Train_Epoch_Reward                    1325.11265
Running_Training_Average_Rewards      1458.29178
Explore_Time                          0.00261
Train___Time                          4.22354
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -32.42484
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.76801
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.64862
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.48782
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.69495
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.55439
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -42.98542
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1199.15292
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.43270
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.69216
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.53542     0.89030    10.24076    5.28555
alpha_0                               0.54897     0.00749    0.56056     0.53497
alpha_1                               0.48511     0.00807    0.49894     0.47115
alpha_2                               0.47768     0.00788    0.49138     0.46423
alpha_3                               0.48117     0.00846    0.49593     0.46669
alpha_4                               0.48329     0.00889    0.49870     0.46819
alpha_5                               0.48036     0.00801    0.49425     0.46652
alpha_6                               0.47496     0.00842    0.48955     0.46057
alpha_7                               0.48156     0.00848    0.49635     0.46704
alpha_8                               0.48254     0.00839    0.49719     0.46836
alpha_9                               0.48917     0.00813    0.50309     0.47508
Alpha_loss                            -4.18110    0.15724    -3.86539    -4.48610
Training/policy_loss                  -98.85162   2.14914    -95.02089   -102.86131
Training/qf1_loss                     1094.00953  259.24929  1891.01404  482.59921
Training/qf2_loss                     1089.93210  259.49239  1890.40649  478.59854
Training/pf_norm                      0.32419     0.07714    0.58848     0.18947
Training/qf1_norm                     414.70768   278.59017  1499.52600  51.62868
Training/qf2_norm                     412.22462   274.02111  1480.81750  66.00786
log_std/mean                          -0.24907    0.00965    -0.23371    -0.27244
log_std/std                           0.10516     0.00450    0.11279     0.09726
log_std/max                           -0.08096    0.01540    -0.05909    -0.11911
log_std/min                           -0.59700    0.02760    -0.54236    -0.66358
log_probs/mean                        -1.77645    0.09555    -1.53620    -1.98355
log_probs/std                         1.48021     0.12718    1.83501     1.27237
log_probs/max                         4.52575     0.68133    6.36220     3.17185
log_probs/min                         -6.96744    0.93885    -5.34900    -11.67122
mean/mean                             -0.15470    0.03616    -0.09578    -0.20583
mean/std                              0.55157     0.02679    0.63172     0.52013
mean/max                              1.30364     0.27059    1.76599     0.88026
mean/min                              -1.66719    0.06308    -1.55501    -1.81380
------------------------------------  ----------  ---------  ----------  ----------
sample: [3, 9, 5, 4, 7, 6, 0, 8, 1, 2]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
train_time 4.9271745681762695
2023-10-11 00:21:03,103 MainThread INFO: EPOCH:13
2023-10-11 00:21:03,103 MainThread INFO: Time Consumed:4.936371326446533s
2023-10-11 00:21:03,104 MainThread INFO: Total Frames:21000s
  1%|▏         | 14/1000 [02:09<1:20:39,  4.91s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               730.37630
Train_Epoch_Reward                    970.11365
Running_Training_Average_Rewards      430.75837
Explore_Time                          0.00305
Train___Time                          4.92717
Eval____Time                          0.00260
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.41750
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -72.91544
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.35975
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.16476
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.86311
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.88365
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.46285
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7897.34410
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -82.18220
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.33189
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.70953     0.91982    10.40364    5.58990
alpha_0                               0.51866     0.00924    0.53482     0.50354
alpha_1                               0.45709     0.00810    0.47101     0.44317
alpha_2                               0.45082     0.00770    0.46409     0.43760
alpha_3                               0.45242     0.00816    0.46654     0.43846
alpha_4                               0.45396     0.00800    0.46804     0.44043
alpha_5                               0.45232     0.00817    0.46638     0.43829
alpha_6                               0.44661     0.00792    0.46043     0.43315
alpha_7                               0.45309     0.00792    0.46690     0.43961
alpha_8                               0.45554     0.00717    0.46822     0.44349
alpha_9                               0.46069     0.00825    0.47494     0.44658
Alpha_loss                            -4.63528    0.10782    -4.40186    -4.85107
Training/policy_loss                  -106.34758  2.21335    -102.20380  -110.77632
Training/qf1_loss                     1194.60313  282.07425  2179.07349  513.42755
Training/qf2_loss                     1187.37455  282.21578  2174.63550  506.13647
Training/pf_norm                      0.31700     0.08142    0.57825     0.13803
Training/qf1_norm                     445.18412   310.46737  1624.07117  42.38294
Training/qf2_norm                     442.42248   304.58680  1607.24951  47.56446
log_std/mean                          -0.23815    0.00406    -0.23014    -0.24680
log_std/std                           0.10269     0.00276    0.10828     0.09811
log_std/max                           -0.06631    0.00638    -0.05694    -0.08437
log_std/min                           -0.60662    0.04318    -0.54037    -0.68489
log_probs/mean                        -1.92735    0.05261    -1.77219    -2.07408
log_probs/std                         1.30573     0.07899    1.50051     1.10466
log_probs/max                         2.93766     0.58166    4.26281     1.47766
log_probs/min                         -6.85634    1.02608    -5.36366    -12.06101
mean/mean                             -0.16422    0.02110    -0.12810    -0.20113
mean/std                              0.50168     0.01722    0.52902     0.47037
mean/max                              1.01993     0.08076    1.17010     0.85797
mean/min                              -1.85335    0.08258    -1.65430    -1.97871
------------------------------------  ----------  ---------  ----------  ----------
sample: [4, 7, 2, 9, 6, 1, 5, 8, 0, 3]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
train_time 4.157292366027832
2023-10-11 00:21:07,345 MainThread INFO: EPOCH:14
2023-10-11 00:21:07,346 MainThread INFO: Time Consumed:4.165642976760864s
2023-10-11 00:21:07,346 MainThread INFO: Total Frames:22500s
  2%|▏         | 15/1000 [02:13<1:17:12,  4.70s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1135.49699
Train_Epoch_Reward                    8511.83563
Running_Training_Average_Rewards      360.23540
Explore_Time                          0.00232
Train___Time                          4.15729
Eval____Time                          0.00237
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.79271
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.94220
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.54101
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -11.90980
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -41.75664
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.77146
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.27170
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10019.69118
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -41.87638
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1648.14065
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.48344      1.03648    10.32115    5.34456
alpha_0                               0.48829      0.00948    0.50341     0.47158
alpha_1                               0.42905      0.00813    0.44303     0.41512
alpha_2                               0.42432      0.00762    0.43747     0.41134
alpha_3                               0.42479      0.00778    0.43832     0.41151
alpha_4                               0.42789      0.00703    0.44030     0.41604
alpha_5                               0.42468      0.00770    0.43815     0.41154
alpha_6                               0.42067      0.00697    0.43302     0.40891
alpha_7                               0.42611      0.00780    0.43948     0.41270
alpha_8                               0.43076      0.00752    0.44337     0.41775
alpha_9                               0.43249      0.00806    0.44644     0.41869
Alpha_loss                            -5.14482     0.17556    -4.79641    -5.39477
Training/policy_loss                  -113.39738   1.91765    -110.12743  -116.90061
Training/qf1_loss                     1196.35040   290.89972  2165.78638  611.83484
Training/qf2_loss                     1185.22037   290.04499  2144.70752  598.06653
Training/pf_norm                      0.37596      0.08875    0.71277     0.18755
Training/qf1_norm                     515.95375    353.87657  1913.58960  60.52204
Training/qf2_norm                     509.76513    345.60206  1845.95813  61.24055
log_std/mean                          -0.22202     0.01240    -0.20827    -0.24678
log_std/std                           0.09510      0.00662    0.10597     0.08352
log_std/max                           -0.08774     0.00658    -0.07534    -0.09743
log_std/min                           -0.60037     0.03318    -0.54298    -0.66764
log_probs/mean                        -2.10669     0.09980    -1.86227    -2.22254
log_probs/std                         1.16217      0.13696    1.46475     1.00647
log_probs/max                         2.31380      0.90851    4.22420     0.99866
log_probs/min                         -6.72580     0.89335    -5.11146    -9.69672
mean/mean                             -0.03523     0.08653    0.07962     -0.17423
mean/std                              0.45612      0.02682    0.50700     0.42255
mean/max                              1.07107      0.10612    1.23796     0.83181
mean/min                              -1.75603     0.07792    -1.62662    -1.89236
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 2, 4, 7, 3, 1, 8, 5, 6, 0]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
train_time 4.3291096687316895
2023-10-11 00:21:11,746 MainThread INFO: EPOCH:15
2023-10-11 00:21:11,746 MainThread INFO: Time Consumed:4.337677001953125s
2023-10-11 00:21:11,747 MainThread INFO: Total Frames:24000s
  2%|▏         | 16/1000 [02:18<1:15:39,  4.61s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1059.34313
Train_Epoch_Reward                    13034.67708
Running_Training_Average_Rewards      750.55421
Explore_Time                          0.00284
Train___Time                          4.32911
Eval____Time                          0.00245
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.84863
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.17105
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.75644
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -19.98684
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -31.08134
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -51.03214
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.06991
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10935.06441
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.24501
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.44174
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.18656      0.91019    9.65664     4.83013
alpha_0                               0.45626      0.00837    0.47142     0.44283
alpha_1                               0.40182      0.00750    0.41498     0.38916
alpha_2                               0.39876      0.00715    0.41121     0.38662
alpha_3                               0.39872      0.00725    0.41138     0.38638
alpha_4                               0.40436      0.00672    0.41593     0.39288
alpha_5                               0.39875      0.00725    0.41141     0.38637
alpha_6                               0.39741      0.00659    0.40880     0.38603
alpha_7                               0.39978      0.00731    0.41257     0.38735
alpha_8                               0.40483      0.00740    0.41762     0.39230
alpha_9                               0.40531      0.00755    0.41855     0.39248
Alpha_loss                            -5.57477     0.08757    -5.30762    -5.78038
Training/policy_loss                  -119.71066   1.86386    -116.70238  -123.74182
Training/qf1_loss                     1126.31149   261.21203  1874.61560  531.62347
Training/qf2_loss                     1114.25085   260.87947  1864.42993  514.05225
Training/pf_norm                      0.31788      0.07388    0.58152     0.18698
Training/qf1_norm                     495.49890    296.84336  1809.39758  100.36146
Training/qf2_norm                     490.81017    290.35374  1776.94312  105.09378
log_std/mean                          -0.21638     0.00413    -0.21078    -0.22627
log_std/std                           0.08666      0.00431    0.09531     0.07924
log_std/max                           -0.10092     0.00425    -0.09238    -0.11132
log_std/min                           -0.55099     0.02490    -0.51537    -0.63234
log_probs/mean                        -2.16046     0.05344    -2.02447    -2.26911
log_probs/std                         1.17099      0.10351    1.39058     1.01214
log_probs/max                         3.11066      0.84020    4.94278     1.54727
log_probs/min                         -6.53662     0.84885    -4.95782    -10.00009
mean/mean                             -0.01337     0.04860    0.06117     -0.12470
mean/std                              0.44429      0.01583    0.46940     0.42014
mean/max                              1.14925      0.06187    1.26891     1.03267
mean/min                              -1.63908     0.05653    -1.54352    -1.80612
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 3, 1, 8, 2, 9, 7, 0, 5, 4]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
train_time 5.46885871887207
2023-10-11 00:21:17,290 MainThread INFO: EPOCH:16
2023-10-11 00:21:17,290 MainThread INFO: Time Consumed:5.4770612716674805s
2023-10-11 00:21:17,291 MainThread INFO: Total Frames:25500s
  2%|▏         | 17/1000 [02:23<1:20:10,  4.89s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               531.77366
Train_Epoch_Reward                    7796.05499
Running_Training_Average_Rewards      978.08559
Explore_Time                          0.00291
Train___Time                          5.46886
Eval____Time                          0.00206
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.70546
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -57.30844
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.87816
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -10.57273
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.24784
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -46.94665
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.69545
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5597.15805
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -49.95331
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.11336
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.02413     0.86330    9.23864     4.75849
alpha_0                               0.42812     0.00848    0.44270     0.41464
alpha_1                               0.37724     0.00677    0.38904     0.36560
alpha_2                               0.37550     0.00632    0.38650     0.36452
alpha_3                               0.37442     0.00678    0.38626     0.36289
alpha_4                               0.38240     0.00586    0.39276     0.37249
alpha_5                               0.37452     0.00670    0.38625     0.36309
alpha_6                               0.37478     0.00639    0.38592     0.36391
alpha_7                               0.37565     0.00660    0.38723     0.36436
alpha_8                               0.38137     0.00617    0.39218     0.37059
alpha_9                               0.38040     0.00686    0.39236     0.36858
Alpha_loss                            -5.80758    0.11041    -5.60314    -6.06639
Training/policy_loss                  -125.78273  1.71539    -122.70644  -128.59082
Training/qf1_loss                     1126.43401  243.23133  1915.52307  601.35046
Training/qf2_loss                     1114.71601  242.20656  1897.01440  591.47058
Training/pf_norm                      0.37621     0.10536    0.60655     0.18131
Training/qf1_norm                     471.42550   299.89408  1504.19128  78.90124
Training/qf2_norm                     466.56408   291.41565  1467.42371  77.98801
log_std/mean                          -0.22252    0.00406    -0.21353    -0.22877
log_std/std                           0.09016     0.00739    0.10353     0.08088
log_std/max                           -0.10023    0.00740    -0.08361    -0.11285
log_std/min                           -0.59872    0.07050    -0.49818    -0.71709
log_probs/mean                        -2.01426    0.04624    -1.90925    -2.18513
log_probs/std                         1.25524     0.08122    1.48802     1.12270
log_probs/max                         3.12061     1.10449    5.27817     1.12492
log_probs/min                         -6.70481    0.86600    -5.20634    -10.20897
mean/mean                             0.10973     0.08455    0.22446     -0.04528
mean/std                              0.48140     0.01996    0.51834     0.44374
mean/max                              1.33557     0.20460    1.72787     1.03200
mean/min                              -1.29535    0.27363    -0.75083    -1.71135
------------------------------------  ----------  ---------  ----------  ----------
sample: [7, 6, 8, 5, 4, 3, 2, 0, 1, 9]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
train_time 4.408000946044922
2023-10-11 00:21:21,811 MainThread INFO: EPOCH:17
2023-10-11 00:21:21,811 MainThread INFO: Time Consumed:4.448966979980469s
2023-10-11 00:21:21,811 MainThread INFO: Total Frames:27000s
  2%|▏         | 18/1000 [02:28<1:18:27,  4.79s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               259.43603
Train_Epoch_Reward                    3883.91578
Running_Training_Average_Rewards      823.82160
Explore_Time                          0.00287
Train___Time                          4.40800
Eval____Time                          0.03378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.90262
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -66.26484
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.02625
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2204.51478
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.33967
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -48.37219
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.67757
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 679.61450
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -47.31285
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -12.87298
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.18282     0.99184    10.47302    4.85994
alpha_0                               0.40308     0.00633    0.41452     0.39275
alpha_1                               0.35435     0.00635    0.36549     0.34357
alpha_2                               0.35372     0.00609    0.36441     0.34334
alpha_3                               0.35179     0.00630    0.36278     0.34109
alpha_4                               0.36308     0.00529    0.37239     0.35406
alpha_5                               0.35202     0.00628    0.36298     0.34134
alpha_6                               0.35318     0.00614    0.36380     0.34264
alpha_7                               0.35366     0.00599    0.36425     0.34343
alpha_8                               0.36035     0.00571    0.37048     0.35062
alpha_9                               0.35709     0.00646    0.36846     0.34615
Alpha_loss                            -6.04371    0.06993    -5.89292    -6.23838
Training/policy_loss                  -132.34121  1.89399    -128.03162  -135.88022
Training/qf1_loss                     1249.53684  343.32189  2498.51904  576.92267
Training/qf2_loss                     1235.97038  341.85029  2481.61792  561.08826
Training/pf_norm                      0.30807     0.06235    0.47343     0.17155
Training/qf1_norm                     552.57674   396.78232  2245.33569  93.21213
Training/qf2_norm                     546.99169   387.98035  2205.57227  100.38399
log_std/mean                          -0.23213    0.00646    -0.22037    -0.24655
log_std/std                           0.10504     0.00569    0.11618     0.09489
log_std/max                           -0.09920    0.00844    -0.08333    -0.11507
log_std/min                           -0.69562    0.02952    -0.63997    -0.75760
log_probs/mean                        -1.88360    0.09177    -1.72929    -2.11116
log_probs/std                         1.41197     0.08302    1.63401     1.23326
log_probs/max                         3.92504     0.55470    5.47032     2.77751
log_probs/min                         -6.80255    0.98700    -5.05950    -10.23248
mean/mean                             0.21534     0.02737    0.25944     0.16840
mean/std                              0.50370     0.02754    0.53925     0.45559
mean/max                              2.04822     0.15213    2.21458     1.73031
mean/min                              -0.76453    0.09894    -0.60667    -0.95395
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 3, 7, 4, 1, 9, 2, 6, 8, 0]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
train_time 4.4022345542907715
2023-10-11 00:21:26,331 MainThread INFO: EPOCH:18
2023-10-11 00:21:26,331 MainThread INFO: Time Consumed:4.410821914672852s
2023-10-11 00:21:26,332 MainThread INFO: Total Frames:28500s
  2%|▏         | 19/1000 [02:32<1:16:50,  4.70s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1697.63545
Train_Epoch_Reward                    812.32420
Running_Training_Average_Rewards      416.40983
Explore_Time                          0.00298
Train___Time                          4.40223
Eval____Time                          0.00239
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.46957
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.07446
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -38.70017
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2450.00319
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -53.08991
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.88646
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.87442
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14845.81054
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -41.15718
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -16.20705
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.19802      1.02814    10.07537    4.75848
alpha_0                               0.38361      0.00515    0.39265     0.37450
alpha_1                               0.33322      0.00587    0.34346     0.32330
alpha_2                               0.33309      0.00584    0.34324     0.32313
alpha_3                               0.33081      0.00585    0.34099     0.32082
alpha_4                               0.34539      0.00493    0.35396     0.33693
alpha_5                               0.33100      0.00589    0.34123     0.32092
alpha_6                               0.33234      0.00586    0.34254     0.32229
alpha_7                               0.33316      0.00585    0.34333     0.32316
alpha_8                               0.34078      0.00565    0.35053     0.33109
alpha_9                               0.33566      0.00596    0.34605     0.32555
Alpha_loss                            -6.34924     0.12358    -6.09737    -6.55232
Training/policy_loss                  -138.81244   1.85243    -134.94286  -142.14989
Training/qf1_loss                     1225.84350   335.06352  2233.96143  513.28943
Training/qf2_loss                     1210.35348   333.52935  2210.84302  506.83560
Training/pf_norm                      0.27806      0.06643    0.46166     0.11448
Training/qf1_norm                     600.20257    419.84596  2062.20703  104.24749
Training/qf2_norm                     591.78640    409.45313  2029.26965  110.23755
log_std/mean                          -0.23118     0.00327    -0.22678    -0.23930
log_std/std                           0.11137      0.00339    0.12063     0.10732
log_std/max                           -0.10117     0.00679    -0.08783    -0.11262
log_std/min                           -0.68396     0.02203    -0.64351    -0.73743
log_probs/mean                        -1.83737     0.05136    -1.68193    -1.96881
log_probs/std                         1.51799      0.07182    1.68652     1.38905
log_probs/max                         4.21294      0.60183    5.76843     2.90403
log_probs/min                         -6.68087     0.91665    -4.86255    -10.55723
mean/mean                             0.17504      0.03878    0.24145     0.12447
mean/std                              0.53774      0.01336    0.56294     0.51367
mean/max                              2.20043      0.04692    2.29870     2.09768
mean/min                              -0.62917     0.13655    -0.37325    -0.81719
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 0, 6, 2, 3, 5, 1, 4, 7, 8]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
train_time 5.936556577682495
2023-10-11 00:21:32,348 MainThread INFO: EPOCH:19
2023-10-11 00:21:32,348 MainThread INFO: Time Consumed:5.946632623672485s
2023-10-11 00:21:32,348 MainThread INFO: Total Frames:30000s
  2%|▏         | 20/1000 [02:38<1:23:12,  5.09s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               895.82204
Train_Epoch_Reward                    19223.74175
Running_Training_Average_Rewards      797.33272
Explore_Time                          0.00433
Train___Time                          5.93656
Eval____Time                          0.00238
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.95970
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -71.91360
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.01121
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2443.47383
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.41838
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.65907
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.93595
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6960.92062
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.73489
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.54127
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           6.99652      1.02890    9.31438     4.81359
alpha_0                               0.36594      0.00568    0.37441     0.35536
alpha_1                               0.31376      0.00536    0.32321     0.30469
alpha_2                               0.31336      0.00556    0.32303     0.30393
alpha_3                               0.31129      0.00538    0.32072     0.30213
alpha_4                               0.32860      0.00489    0.33684     0.32018
alpha_5                               0.31127      0.00546    0.32082     0.30193
alpha_6                               0.31257      0.00554    0.32219     0.30308
alpha_7                               0.31325      0.00569    0.32306     0.30354
alpha_8                               0.32106      0.00570    0.33099     0.31145
alpha_9                               0.31601      0.00538    0.32545     0.30684
Alpha_loss                            -6.73757     0.17292    -6.34727    -6.99071
Training/policy_loss                  -144.61187   1.61092    -141.49014  -148.31985
Training/qf1_loss                     1206.38638   330.12260  2185.41235  414.51276
Training/qf2_loss                     1192.17627   329.72635  2171.73682  402.27615
Training/pf_norm                      0.37921      0.12245    0.76768     0.18304
Training/qf1_norm                     647.90636    393.57504  1792.47717  131.98967
Training/qf2_norm                     637.18871    380.99347  1756.25830  138.77730
log_std/mean                          -0.22871     0.00664    -0.21757    -0.24255
log_std/std                           0.11061      0.00378    0.11814     0.10360
log_std/max                           -0.10066     0.00731    -0.08693    -0.11721
log_std/min                           -0.67664     0.02636    -0.63178    -0.71886
log_probs/mean                        -1.87725     0.08728    -1.62378    -2.04770
log_probs/std                         1.48767      0.17650    1.92932     1.22629
log_probs/max                         3.99046      1.37512    6.99184     1.63609
log_probs/min                         -6.91105     0.97615    -5.11127    -10.61408
mean/mean                             0.09323      0.09725    0.27708     -0.03321
mean/std                              0.53802      0.01248    0.56365     0.51087
mean/max                              2.10652      0.07796    2.31432     2.01107
mean/min                              -0.70991     0.13037    -0.51783    -1.07837
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 6, 0, 2, 5, 9, 7, 3, 1, 4]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
train_time 6.184040784835815
2023-10-11 00:21:38,611 MainThread INFO: EPOCH:20
2023-10-11 00:21:38,612 MainThread INFO: Time Consumed:6.193345069885254s
2023-10-11 00:21:38,612 MainThread INFO: Total Frames:31500s
  2%|▏         | 21/1000 [02:45<1:29:28,  5.48s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               425.30034
Train_Epoch_Reward                    9304.30340
Running_Training_Average_Rewards      978.01231
Explore_Time                          0.00306
Train___Time                          6.18404
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.87096
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -77.24047
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.97047
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2518.91010
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.52925
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.76561
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.94433
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2184.44585
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -73.69705
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.33436
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.78127     1.31086     11.50020    5.00793
alpha_0                               0.35064     0.00184     0.35526     0.34821
alpha_1                               0.29529     0.00537     0.30459     0.28615
alpha_2                               0.29500     0.00505     0.30384     0.28641
alpha_3                               0.29375     0.00476     0.30204     0.28552
alpha_4                               0.31343     0.00378     0.32011     0.30734
alpha_5                               0.29327     0.00487     0.30184     0.28498
alpha_6                               0.29400     0.00518     0.30299     0.28512
alpha_7                               0.29443     0.00508     0.30345     0.28590
alpha_8                               0.30278     0.00464     0.31135     0.29526
alpha_9                               0.29760     0.00530     0.30675     0.28845
Alpha_loss                            -6.54416    0.15641     -6.23270    -6.94461
Training/policy_loss                  -151.59135  2.10950     -147.68907  -155.58109
Training/qf1_loss                     2062.27768  1227.14844  7629.41943  634.10754
Training/qf2_loss                     2044.42526  1223.61080  7588.95801  627.01923
Training/pf_norm                      0.43101     0.15945     0.94132     0.21903
Training/qf1_norm                     829.41537   606.52873   3080.71973  77.65257
Training/qf2_norm                     819.20906   595.69841   3039.67041  83.74703
log_std/mean                          -0.25003    0.01331     -0.22412    -0.27905
log_std/std                           0.12836     0.00906     0.14455     0.11280
log_std/max                           -0.08036    0.03448     0.00868     -0.12288
log_std/min                           -0.68679    0.03728     -0.59716    -0.75371
log_probs/mean                        -1.40309    0.19031     -1.02604    -1.89626
log_probs/std                         2.12978     0.21959     2.54413     1.51904
log_probs/max                         7.82952     1.02804     9.65315     4.57544
log_probs/min                         -6.97585    1.13529     -4.97949    -12.41180
mean/mean                             0.18240     0.06826     0.29639     0.05439
mean/std                              0.66495     0.05698     0.77690     0.54578
mean/max                              2.25855     0.08732     2.42932     2.07271
mean/min                              -1.63276    0.28279     -1.07996    -1.98752
------------------------------------  ----------  ----------  ----------  ----------
sample: [0, 2, 3, 1, 4, 8, 5, 7, 9, 6]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
train_time 5.733469009399414
2023-10-11 00:21:44,570 MainThread INFO: EPOCH:21
2023-10-11 00:21:44,571 MainThread INFO: Time Consumed:5.7450480461120605s
2023-10-11 00:21:44,571 MainThread INFO: Total Frames:33000s
  2%|▏         | 22/1000 [02:51<1:31:07,  5.59s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2987.86884
Train_Epoch_Reward                    2300.72692
Running_Training_Average_Rewards      1027.62574
Explore_Time                          0.00571
Train___Time                          5.73347
Eval____Time                          0.00242
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.01051
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -92.04905
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -61.58951
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.13145
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -30.62066
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.01897
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.16739
1                                     0.00000
reach-v1_success_rate                 1.00000
reach-v1_eval_rewards                 28568.85461
0                                     1.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.83370
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1795.25500
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.59419      1.21465     11.16395    4.35281
alpha_0                               0.34692      0.00151     0.34820     0.34304
alpha_1                               0.27767      0.00476     0.28606     0.26956
alpha_2                               0.27802      0.00478     0.28632     0.26988
alpha_3                               0.27714      0.00474     0.28544     0.26911
alpha_4                               0.30054      0.00401     0.30728     0.29348
alpha_5                               0.27657      0.00478     0.28489     0.26844
alpha_6                               0.27646      0.00491     0.28503     0.26811
alpha_7                               0.27743      0.00489     0.28582     0.26906
alpha_8                               0.28786      0.00436     0.29519     0.28027
alpha_9                               0.27993      0.00472     0.28836     0.27191
Alpha_loss                            -6.85785     0.18377     -6.57193    -7.29957
Training/policy_loss                  -158.30849   1.99256     -154.41409  -162.13843
Training/qf1_loss                     2020.04670   1148.15224  6889.44043  429.69189
Training/qf2_loss                     2001.45335   1145.85444  6897.83350  424.49072
Training/pf_norm                      0.45653      0.15766     0.85891     0.17407
Training/qf1_norm                     797.94949    553.54561   2918.62598  117.41636
Training/qf2_norm                     789.72631    543.10763   2911.38232  102.78039
log_std/mean                          -0.25513     0.01364     -0.22491    -0.27838
log_std/std                           0.13062      0.00615     0.14366     0.12099
log_std/max                           -0.07750     0.05375     0.06435     -0.12558
log_std/min                           -0.68318     0.02948     -0.62964    -0.75042
log_probs/mean                        -1.40343     0.10476     -1.23725    -1.68345
log_probs/std                         2.13618      0.21790     2.55258     1.66700
log_probs/max                         7.52727      0.99790     9.46826     5.08968
log_probs/min                         -6.80402     0.93383     -4.83810    -11.31483
mean/mean                             0.06762      0.06301     0.19916     -0.02159
mean/std                              0.68694      0.02922     0.73093     0.61947
mean/max                              2.29220      0.06668     2.44272     2.19073
mean/min                              -1.90473     0.11425     -1.63574    -2.06186
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 8, 7, 2, 4, 1, 3, 0, 6, 9]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
train_time 6.464019060134888
2023-10-11 00:21:51,122 MainThread INFO: EPOCH:22
2023-10-11 00:21:51,122 MainThread INFO: Time Consumed:6.472636938095093s
2023-10-11 00:21:51,122 MainThread INFO: Total Frames:34500s
  2%|▏         | 23/1000 [02:57<1:35:41,  5.88s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               498.96773
Train_Epoch_Reward                    37671.62277
Running_Training_Average_Rewards      1642.55510
Explore_Time                          0.00274
Train___Time                          6.46402
Eval____Time                          0.00247
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.00563
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -79.82001
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.32873
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.39762
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -68.49518
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.41357
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.55944
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5412.15616
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.54827
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.91036
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.61119      1.38155     11.35591    4.74073
alpha_0                               0.33950      0.00221     0.34300     0.33547
alpha_1                               0.26143      0.00462     0.26948     0.25356
alpha_2                               0.26190      0.00458     0.26980     0.25402
alpha_3                               0.26127      0.00448     0.26903     0.25363
alpha_4                               0.28675      0.00395     0.29341     0.28012
alpha_5                               0.26051      0.00453     0.26836     0.25276
alpha_6                               0.26005      0.00458     0.26803     0.25225
alpha_7                               0.26107      0.00456     0.26898     0.25323
alpha_8                               0.27308      0.00403     0.28019     0.26611
alpha_9                               0.26368      0.00469     0.27183     0.25570
Alpha_loss                            -7.22905     0.17659     -6.83622    -7.59518
Training/policy_loss                  -164.50119   2.06857     -160.56555  -168.67714
Training/qf1_loss                     2064.04275   1274.05440  7137.63135  512.65594
Training/qf2_loss                     2042.93657   1270.87935  7102.92334  496.82599
Training/pf_norm                      0.39449      0.09376     0.72155     0.18351
Training/qf1_norm                     912.49753    692.26641   3527.09082  126.31846
Training/qf2_norm                     897.24159    678.21738   3463.87378  122.57076
log_std/mean                          -0.24347     0.01561     -0.21703    -0.27452
log_std/std                           0.13355      0.00649     0.14726     0.12155
log_std/max                           -0.08788     0.02094     -0.05586    -0.13712
log_std/min                           -0.69153     0.02735     -0.61823    -0.74554
log_probs/mean                        -1.44978     0.11192     -1.16830    -1.66197
log_probs/std                         2.10785      0.13295     2.54785     1.84494
log_probs/max                         7.34104      0.70951     9.36607     5.73980
log_probs/min                         -6.76755     0.99683     -4.77404    -11.23560
mean/mean                             0.13525      0.06428     0.20716     0.02221
mean/std                              0.66833      0.02714     0.73476     0.62944
mean/max                              2.36974      0.06557     2.51948     2.24045
mean/min                              -1.78984     0.13454     -1.54010    -2.03211
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 7, 4, 8, 0, 5, 1, 3, 9, 6]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
train_time 4.414301872253418
2023-10-11 00:21:55,615 MainThread INFO: EPOCH:23
2023-10-11 00:21:55,616 MainThread INFO: Time Consumed:4.423604726791382s
2023-10-11 00:21:55,616 MainThread INFO: Total Frames:36000s
  2%|▏         | 24/1000 [03:02<1:28:51,  5.46s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               966.93256
Train_Epoch_Reward                    6120.79540
Running_Training_Average_Rewards      1536.43817
Explore_Time                          0.00336
Train___Time                          4.41430
Eval____Time                          0.00230
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.09963
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -80.71934
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -64.94713
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.15779
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -62.61377
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -94.06626
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.56644
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10231.22877
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.97785
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.75498
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.42804      1.17531     10.29286    4.98421
alpha_0                               0.33657      0.00081     0.33764     0.33540
alpha_1                               0.24586      0.00434     0.25348     0.23855
alpha_2                               0.24631      0.00437     0.25394     0.23893
alpha_3                               0.24655      0.00405     0.25356     0.23961
alpha_4                               0.27371      0.00395     0.28007     0.26668
alpha_5                               0.24540      0.00420     0.25268     0.23823
alpha_6                               0.24480      0.00421     0.25217     0.23764
alpha_7                               0.24560      0.00434     0.25315     0.23822
alpha_8                               0.25958      0.00368     0.26603     0.25351
alpha_9                               0.24817      0.00427     0.25562     0.24087
Alpha_loss                            -7.24993     0.16316     -6.82027    -7.60820
Training/policy_loss                  -170.79522   1.86687     -167.06029  -174.67870
Training/qf1_loss                     1997.34557   1086.06957  6516.93457  589.91962
Training/qf2_loss                     1972.68320   1083.17961  6484.98730  572.31726
Training/pf_norm                      0.34215      0.08982     0.59329     0.17070
Training/qf1_norm                     820.43075    544.07666   2845.88867  127.64484
Training/qf2_norm                     809.59752    534.86762   2812.89185  132.15025
log_std/mean                          -0.25953     0.00972     -0.24549    -0.28723
log_std/std                           0.13539      0.00695     0.15453     0.12151
log_std/max                           -0.07930     0.02244     -0.01705    -0.11512
log_std/min                           -0.67829     0.03712     -0.58055    -0.75622
log_probs/mean                        -1.20937     0.11565     -0.77162    -1.42967
log_probs/std                         2.45120      0.13572     2.75439     2.11710
log_probs/max                         9.08869      0.72213     10.38732    6.95315
log_probs/min                         -6.79890     1.04414     -5.23172    -11.01598
mean/mean                             0.13079      0.04705     0.20668     0.04448
mean/std                              0.73497      0.02659     0.84084     0.70186
mean/max                              2.36690      0.05762     2.50845     2.29695
mean/min                              -1.97653     0.06233     -1.86128    -2.16897
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 8, 7, 5, 1, 3, 6, 0, 9, 4]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
train_time 6.590473890304565
2023-10-11 00:22:02,287 MainThread INFO: EPOCH:24
2023-10-11 00:22:02,288 MainThread INFO: Time Consumed:6.600508689880371s
2023-10-11 00:22:02,288 MainThread INFO: Total Frames:37500s
  2%|▎         | 25/1000 [03:08<1:34:38,  5.82s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               932.22798
Train_Epoch_Reward                    12288.96524
Running_Training_Average_Rewards      1869.37945
Explore_Time                          0.00408
Train___Time                          6.59047
Eval____Time                          0.00217
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.04183
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -86.06473
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -71.01689
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.08551
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -57.19432
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.53487
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.70196
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9832.11380
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -72.52549
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -9.66842
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.45320      1.21419     10.74707    4.80371
alpha_0                               0.34222      0.00302     0.34588     0.33740
alpha_1                               0.23149      0.00405     0.23848     0.22454
alpha_2                               0.23196      0.00400     0.23886     0.22505
alpha_3                               0.23319      0.00371     0.23954     0.22659
alpha_4                               0.26036      0.00360     0.26661     0.25391
alpha_5                               0.23176      0.00371     0.23816     0.22518
alpha_6                               0.23067      0.00398     0.23757     0.22389
alpha_7                               0.23161      0.00377     0.23815     0.22496
alpha_8                               0.24920      0.00274     0.25347     0.24374
alpha_9                               0.23363      0.00415     0.24080     0.22649
Alpha_loss                            -7.20965     0.47615     -6.40692    -8.00463
Training/policy_loss                  -176.93926   1.86649     -173.15491  -180.52351
Training/qf1_loss                     2052.34598   1110.45081  6191.66113  619.87213
Training/qf2_loss                     2024.29597   1106.34547  6156.72168  609.62067
Training/pf_norm                      0.35577      0.09776     0.60111     0.18732
Training/qf1_norm                     871.87436    617.67011   2919.31860  140.70418
Training/qf2_norm                     862.91010    605.61386   2896.16138  118.28535
log_std/mean                          -0.26040     0.02402     -0.22107    -0.30363
log_std/std                           0.14806      0.00477     0.15758     0.13874
log_std/max                           -0.07350     0.03316     -0.02308    -0.13343
log_std/min                           -0.69562     0.02383     -0.62119    -0.75242
log_probs/mean                        -0.95106     0.30148     -0.39762    -1.44917
log_probs/std                         2.66411      0.22320     3.06216     2.28897
log_probs/max                         9.00883      0.91952     11.07957    7.64152
log_probs/min                         -6.83102     1.02647     -5.01604    -10.22142
mean/mean                             0.07295      0.03660     0.12784     0.01170
mean/std                              0.80595      0.06936     0.90283     0.69905
mean/max                              2.41070      0.05571     2.52455     2.29830
mean/min                              -2.18053     0.10111     -1.98096    -2.32223
------------------------------------  -----------  ----------  ----------  ----------
start to update mask
sample: [6, 8, 3, 7, 5, 0, 4, 9, 1, 2]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
train_time 69.72739052772522
2023-10-11 00:23:20,060 MainThread INFO: EPOCH:25
2023-10-11 00:23:20,061 MainThread INFO: Time Consumed:69.75196146965027s
2023-10-11 00:23:20,061 MainThread INFO: Total Frames:39000s
  3%|▎         | 26/1000 [04:26<7:24:58, 27.41s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               749.06919
Train_Epoch_Reward                    14746.26946
Running_Training_Average_Rewards      1105.20100
Explore_Time                          0.01914
Train___Time                          69.72739
Eval____Time                          0.00206
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -84.61851
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.60216
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.50908
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.49569
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.69392
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.89419
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.78416
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8095.36885
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.77283
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.30638
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.49206      1.24939     11.56176     4.58091
alpha_0                               0.33221      0.00656     0.34587      0.32562
alpha_1                               0.21826      0.00333     0.22448      0.21350
alpha_2                               0.21890      0.00320     0.22499      0.21459
alpha_3                               0.22042      0.00313     0.22652      0.21651
alpha_4                               0.24489      0.00466     0.25384      0.23891
alpha_5                               0.21933      0.00295     0.22511      0.21565
alpha_6                               0.21781      0.00319     0.22382      0.21344
alpha_7                               0.21919      0.00289     0.22489      0.21572
alpha_8                               0.23656      0.00353     0.24367      0.23268
alpha_9                               0.21998      0.00343     0.22642      0.21513
Alpha_loss                            -6.30059     2.95780     2.53406      -9.36430
Training/policy_loss                  -108.75955   15.66404    -74.73201    -153.75655
Training/qf1_loss                     5511.65403   2171.75157  12450.11426  1644.28259
Training/qf2_loss                     4316.68058   2088.38149  12128.64258  1285.16150
Training/pf_norm                      4.84074      1.35717     10.80807     2.42401
Training/qf1_norm                     4459.59601   2174.58402  13636.79590  1004.69531
Training/qf2_norm                     3641.12708   2390.09454  14525.09473  981.65222
log_std/mean                          -0.34724     0.14072     -0.18934     -0.69028
log_std/std                           0.12873      0.04078     0.21436      0.06501
log_std/max                           -0.06734     0.11029     0.19879      -0.36443
log_std/min                           -0.71816     0.23454     -0.34727     -1.22359
log_probs/mean                        -0.27215     2.09599     5.83678      -2.55305
log_probs/std                         1.98135      0.93667     5.44069      0.63519
log_probs/max                         5.88111      4.41707     21.23076     -0.05006
log_probs/min                         -7.17586     1.34569     -4.04669     -15.90877
mean/mean                             0.36196      0.22454     0.87132      -0.01238
mean/std                              0.76873      0.33756     1.56503      0.24344
mean/max                              2.20105      0.84579     4.78861      0.68572
mean/min                              -1.35827     0.62376     -0.45017     -3.27636
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 8, 4, 5, 6, 0, 3, 2, 1, 9]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
train_time 5.725847482681274
2023-10-11 00:23:25,863 MainThread INFO: EPOCH:26
2023-10-11 00:23:25,863 MainThread INFO: Time Consumed:5.735339403152466s
2023-10-11 00:23:25,864 MainThread INFO: Total Frames:40500s
  3%|▎         | 27/1000 [04:32<5:39:27, 20.93s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               850.86929
Train_Epoch_Reward                    8173.99792
Running_Training_Average_Rewards      1173.64109
Explore_Time                          0.00236
Train___Time                          5.72585
Eval____Time                          0.00369
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -83.79232
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -81.29647
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -44.92368
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.02384
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.12225
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.93946
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.35567
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8981.78814
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.55338
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.08815
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.41720     1.30690     12.18639    4.38710
alpha_0                               0.33630     0.00292     0.34020     0.32929
alpha_1                               0.21496     0.00073     0.21568     0.21342
alpha_2                               0.21457     0.00072     0.21544     0.21289
alpha_3                               0.21782     0.00066     0.21854     0.21652
alpha_4                               0.23645     0.00248     0.23889     0.23098
alpha_5                               0.21672     0.00083     0.21784     0.21555
alpha_6                               0.21030     0.00187     0.21343     0.20731
alpha_7                               0.21551     0.00166     0.21741     0.21196
alpha_8                               0.23522     0.00151     0.23711     0.23286
alpha_9                               0.21691     0.00100     0.21786     0.21502
Alpha_loss                            -0.68895    2.34755     4.14639     -4.09943
Training/policy_loss                  -129.15721  7.28189     -111.27480  -137.85916
Training/qf1_loss                     2233.65707  1103.36148  7303.90527  568.59998
Training/qf2_loss                     2996.87619  1414.71639  8661.39258  741.84045
Training/pf_norm                      1.57765     0.84313     5.22506     0.91272
Training/qf1_norm                     703.83351   531.58509   2535.24463  88.84592
Training/qf2_norm                     1549.62336  1011.15827  3983.03735  245.55554
log_std/mean                          -0.58490    0.07426     -0.48255    -0.73955
log_std/std                           0.20333     0.05053     0.28044     0.12328
log_std/max                           0.09463     0.35924     0.59215     -0.44501
log_std/min                           -1.03494    0.15583     -0.77567    -1.28790
log_probs/mean                        3.57469     1.58018     6.85154     1.22394
log_probs/std                         2.85331     0.38100     3.46362     2.05806
log_probs/max                         10.68075    1.78085     14.02512    6.85761
log_probs/min                         -7.10059    1.54267     -2.87033    -13.24587
mean/mean                             0.55674     0.22415     0.89832     0.20366
mean/std                              1.36582     0.16688     1.65745     1.08398
mean/max                              2.50357     0.18566     2.88646     2.16633
mean/min                              -2.29117    0.23757     -1.89550    -2.68567
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 1, 8, 5, 0, 9, 3, 7, 2, 4]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
train_time 5.638551950454712
2023-10-11 00:23:31,594 MainThread INFO: EPOCH:27
2023-10-11 00:23:31,594 MainThread INFO: Time Consumed:5.647509813308716s
2023-10-11 00:23:31,595 MainThread INFO: Total Frames:42000s
  3%|▎         | 28/1000 [04:38<4:25:10, 16.37s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               723.72165
Train_Epoch_Reward                    9742.60796
Running_Training_Average_Rewards      1088.76251
Explore_Time                          0.00295
Train___Time                          5.63855
Eval____Time                          0.00234
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.90652
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.18619
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -84.33205
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -67.63816
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.38523
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.97704
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.32012
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7964.45715
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -76.16510
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.33027
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.60214     1.22101     11.27013    4.61332
alpha_0                               0.32990     0.00505     0.33890     0.32253
alpha_1                               0.21339     0.00071     0.21478     0.21238
alpha_2                               0.20912     0.00237     0.21286     0.20499
alpha_3                               0.21234     0.00251     0.21670     0.20825
alpha_4                               0.22301     0.00445     0.23090     0.21587
alpha_5                               0.21581     0.00143     0.21774     0.21316
alpha_6                               0.20544     0.00113     0.20728     0.20343
alpha_7                               0.20950     0.00117     0.21193     0.20783
alpha_8                               0.22832     0.00371     0.23455     0.22199
alpha_9                               0.21496     0.00131     0.21705     0.21264
Alpha_loss                            -3.98806    0.41125     -3.20668    -4.79028
Training/policy_loss                  -139.73406  2.09162     -136.15039  -143.66299
Training/qf1_loss                     2250.78476  1013.37555  5799.44678  608.33118
Training/qf2_loss                     2260.46911  1007.78771  5784.91895  633.83337
Training/pf_norm                      0.73792     0.16468     1.08906     0.33936
Training/qf1_norm                     457.39499   297.75674   1765.64172  118.81268
Training/qf2_norm                     459.36252   276.70595   1754.86230  112.13676
log_std/mean                          -0.58247    0.05564     -0.49004    -0.67548
log_std/std                           0.22515     0.01298     0.24155     0.17694
log_std/max                           -0.18678    0.04347     -0.12306    -0.32500
log_std/min                           -1.47514    0.07420     -1.23476    -1.58358
log_probs/mean                        1.33200     0.28426     1.88187     0.78359
log_probs/std                         2.24428     0.09111     2.43557     2.06674
log_probs/max                         7.03334     0.69327     8.82605     5.56676
log_probs/min                         -7.58029    1.24795     -5.31573    -11.95378
mean/mean                             0.11792     0.04416     0.20275     0.03363
mean/std                              1.13384     0.05701     1.21654     1.04643
mean/max                              2.21057     0.08134     2.37599     1.99662
mean/min                              -2.07202    0.11860     -1.87427    -2.34833
------------------------------------  ----------  ----------  ----------  ----------
sample: [5, 7, 3, 0, 1, 6, 2, 8, 9, 4]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
train_time 6.159595012664795
2023-10-11 00:23:37,834 MainThread INFO: EPOCH:28
2023-10-11 00:23:37,834 MainThread INFO: Time Consumed:6.16789436340332s
2023-10-11 00:23:37,834 MainThread INFO: Total Frames:43500s
  3%|▎         | 29/1000 [04:44<3:35:41, 13.33s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1593.74883
Train_Epoch_Reward                    7430.52029
Running_Training_Average_Rewards      844.90421
Explore_Time                          0.00268
Train___Time                          6.15960
Eval____Time                          0.00214
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.93888
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.21104
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.16701
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.43532
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -88.15785
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -106.77450
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -84.19620
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16570.22297
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.56759
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.28628
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.65291      1.41791     11.07625    4.44140
alpha_0                               0.31782      0.00233     0.32248     0.31452
alpha_1                               0.21015      0.00135     0.21236     0.20765
alpha_2                               0.20091      0.00234     0.20494     0.19669
alpha_3                               0.20418      0.00231     0.20821     0.20009
alpha_4                               0.21024      0.00319     0.21581     0.20469
alpha_5                               0.20919      0.00244     0.21313     0.20499
alpha_6                               0.20097      0.00136     0.20340     0.19854
alpha_7                               0.20624      0.00096     0.20781     0.20442
alpha_8                               0.21613      0.00318     0.22193     0.21080
alpha_9                               0.20990      0.00162     0.21262     0.20711
Alpha_loss                            -4.10126     0.20112     -3.64277    -4.52654
Training/policy_loss                  -146.60779   2.08419     -142.96246  -150.44936
Training/qf1_loss                     2362.89604   1202.07170  7216.71240  682.05457
Training/qf2_loss                     2356.41637   1195.22874  7172.42041  682.71124
Training/pf_norm                      0.48836      0.09300     0.80493     0.26652
Training/qf1_norm                     548.79561    351.28600   1915.66003  106.40276
Training/qf2_norm                     544.13304    338.91603   1896.60742  114.74273
log_std/mean                          -0.48868     0.01845     -0.45668    -0.52830
log_std/std                           0.22654      0.00490     0.23426     0.21712
log_std/max                           -0.03135     0.07495     0.07776     -0.16766
log_std/min                           -1.48186     0.02715     -1.42353    -1.54011
log_probs/mean                        1.36150      0.12740     1.66410     1.08257
log_probs/std                         2.19014      0.05406     2.33119     2.03909
log_probs/max                         6.58416      0.31404     7.51074     5.89419
log_probs/min                         -7.73974     1.24896     -5.08784    -13.09437
mean/mean                             0.07770      0.04079     0.16373     0.00914
mean/std                              1.17537      0.01934     1.21778     1.13858
mean/max                              2.13284      0.10389     2.32119     1.88566
mean/min                              -1.99149     0.07362     -1.90344    -2.17428
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 0, 8, 6, 2, 4, 5, 3, 1, 9]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
train_time 5.370271682739258
2023-10-11 00:23:43,298 MainThread INFO: EPOCH:29
2023-10-11 00:23:43,299 MainThread INFO: Time Consumed:5.399967432022095s
2023-10-11 00:23:43,299 MainThread INFO: Total Frames:45000s
  3%|▎         | 30/1000 [04:49<2:57:42, 10.99s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1420.60761
Train_Epoch_Reward                    18200.38528
Running_Training_Average_Rewards      1179.11712
Explore_Time                          0.00226
Train___Time                          5.37027
Eval____Time                          0.02422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.61815
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.36454
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.00395
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.90262
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -97.08301
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.76512
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.78321
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14802.88747
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.36833
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.92241
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.57853      1.45231     11.51090    4.20022
alpha_0                               0.31651      0.00266     0.32261     0.31379
alpha_1                               0.20410      0.00207     0.20762     0.20056
alpha_2                               0.19180      0.00277     0.19664     0.18712
alpha_3                               0.19535      0.00264     0.20005     0.19109
alpha_4                               0.19954      0.00288     0.20463     0.19466
alpha_5                               0.20097      0.00237     0.20495     0.19684
alpha_6                               0.19513      0.00185     0.19851     0.19231
alpha_7                               0.20139      0.00185     0.20440     0.19811
alpha_8                               0.20622      0.00240     0.21075     0.20231
alpha_9                               0.20441      0.00157     0.20709     0.20169
Alpha_loss                            -4.23250     0.31861     -3.55079    -4.90443
Training/policy_loss                  -152.90611   2.07605     -148.93565  -157.38684
Training/qf1_loss                     2303.62824   1231.86304  7008.36035  687.56415
Training/qf2_loss                     2285.98976   1223.81555  6964.56396  696.95636
Training/pf_norm                      0.45690      0.11246     0.79524     0.25879
Training/qf1_norm                     604.41841    422.65609   2075.23438  124.64026
Training/qf2_norm                     593.88256    397.71234   2004.55200  140.83246
log_std/mean                          -0.47688     0.00929     -0.45495    -0.50120
log_std/std                           0.21516      0.00651     0.22875     0.20487
log_std/max                           -0.04059     0.03244     0.03487     -0.07791
log_std/min                           -1.42488     0.03036     -1.34110    -1.48573
log_probs/mean                        1.40779      0.23910     1.89852     0.89730
log_probs/std                         2.40083      0.13423     2.67275     2.12254
log_probs/max                         8.97826      1.12500     10.64213    6.12238
log_probs/min                         -7.74216     1.40416     -4.88160    -16.93939
mean/mean                             0.04559      0.04377     0.17397     -0.03390
mean/std                              1.19167      0.04124     1.26243     1.11824
mean/max                              2.35578      0.09731     2.51254     2.13205
mean/min                              -2.02419     0.07401     -1.88561    -2.14340
------------------------------------  -----------  ----------  ----------  ----------
sample: [7, 0, 5, 3, 4, 8, 2, 1, 9, 6]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
train_time 5.48353385925293
2023-10-11 00:23:48,969 MainThread INFO: EPOCH:30
2023-10-11 00:23:48,969 MainThread INFO: Time Consumed:5.5254716873168945s
2023-10-11 00:23:48,969 MainThread INFO: Total Frames:46500s
  3%|▎         | 31/1000 [04:55<2:31:32,  9.38s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1243.95704
Train_Epoch_Reward                    15108.59881
Running_Training_Average_Rewards      1357.98348
Explore_Time                          0.00271
Train___Time                          5.48353
Eval____Time                          0.03518
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.12204
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.48005
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.18586
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.89620
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -92.82965
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.02061
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -83.27459
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13052.84881
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.30106
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -74.16838
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.65901      1.51827     12.61715    4.54547
alpha_0                               0.33048      0.00451     0.33739     0.32270
alpha_1                               0.19768      0.00167     0.20052     0.19466
alpha_2                               0.18331      0.00182     0.18707     0.18093
alpha_3                               0.18766      0.00190     0.19105     0.18448
alpha_4                               0.18935      0.00316     0.19461     0.18371
alpha_5                               0.19222      0.00265     0.19680     0.18767
alpha_6                               0.19052      0.00098     0.19229     0.18888
alpha_7                               0.19470      0.00196     0.19808     0.19124
alpha_8                               0.19900      0.00186     0.20227     0.19595
alpha_9                               0.19818      0.00209     0.20167     0.19423
Alpha_loss                            -3.71855     0.34315     -2.69808    -4.27564
Training/policy_loss                  -158.76398   1.86307     -154.43553  -162.98433
Training/qf1_loss                     2369.34180   1168.99866  6715.14697  586.76019
Training/qf2_loss                     2345.04259   1160.41176  6674.50488  587.11151
Training/pf_norm                      0.46765      0.09420     0.74144     0.29744
Training/qf1_norm                     678.93342    504.77437   2949.42114  118.76895
Training/qf2_norm                     669.52388    477.16469   2905.47241  148.41882
log_std/mean                          -0.49149     0.01593     -0.46150    -0.52250
log_std/std                           0.20098      0.01517     0.22287     0.18078
log_std/max                           0.05016      0.09842     0.19681     -0.07809
log_std/min                           -1.26471     0.06848     -1.13540    -1.37029
log_probs/mean                        1.79838      0.21756     2.43568     1.44576
log_probs/std                         2.52506      0.05517     2.70026     2.38319
log_probs/max                         9.35691      0.69338     10.62526    7.26542
log_probs/min                         -7.57470     1.27645     -5.26485    -14.01452
mean/mean                             0.20943      0.03248     0.29860     0.17461
mean/std                              1.24514      0.02839     1.31485     1.20336
mean/max                              2.41806      0.06224     2.53443     2.31784
mean/min                              -2.16033     0.05442     -2.02878    -2.24968
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 5, 4, 3, 1, 6, 7, 9, 8, 0]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
train_time 5.613969326019287
2023-10-11 00:23:54,694 MainThread INFO: EPOCH:31
2023-10-11 00:23:54,694 MainThread INFO: Time Consumed:5.621906995773315s
2023-10-11 00:23:54,695 MainThread INFO: Total Frames:48000s
  3%|▎         | 32/1000 [05:01<2:13:34,  8.28s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               394.43423
Train_Epoch_Reward                    12914.33612
Running_Training_Average_Rewards      1540.77734
Explore_Time                          0.00269
Train___Time                          5.61397
Eval____Time                          0.00211
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.84725
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -88.50969
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.34016
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.67172
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.03873
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -101.07299
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -87.60273
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4579.36860
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.24148
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -73.70153
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.60224      1.34242     11.35557    4.61873
alpha_0                               0.34276      0.00318     0.34751     0.33742
alpha_1                               0.19068      0.00249     0.19462     0.18637
alpha_2                               0.17915      0.00126     0.18092     0.17662
alpha_3                               0.18178      0.00155     0.18445     0.17908
alpha_4                               0.17770      0.00334     0.18364     0.17207
alpha_5                               0.18333      0.00248     0.18762     0.17917
alpha_6                               0.18798      0.00052     0.18887     0.18694
alpha_7                               0.18767      0.00220     0.19121     0.18368
alpha_8                               0.19260      0.00216     0.19592     0.18870
alpha_9                               0.18868      0.00315     0.19418     0.18344
Alpha_loss                            -4.00140     0.42722     -3.13831    -4.87194
Training/policy_loss                  -163.86796   1.78689     -160.24396  -168.50972
Training/qf1_loss                     2403.47988   1148.98815  7183.50928  593.01184
Training/qf2_loss                     2374.74272   1142.04773  7126.77490  583.97430
Training/pf_norm                      0.56965      0.16224     1.01382     0.26116
Training/qf1_norm                     651.29328    450.12607   2254.44067  116.85931
Training/qf2_norm                     645.01101    429.25495   2217.01050  128.62364
log_std/mean                          -0.47840     0.01659     -0.44602    -0.50740
log_std/std                           0.16813      0.00674     0.18278     0.15583
log_std/max                           -0.10146     0.01944     -0.06116    -0.14337
log_std/min                           -1.02068     0.07306     -0.90043    -1.17149
log_probs/mean                        1.66736      0.25926     2.18475     1.12015
log_probs/std                         2.57503      0.10280     2.84186     2.30063
log_probs/max                         8.92193      0.66138     10.37809    7.30202
log_probs/min                         -7.68374     1.34600     -5.18329    -12.87696
mean/mean                             0.17008      0.07107     0.27030     0.02826
mean/std                              1.23838      0.03457     1.29904     1.16084
mean/max                              2.51725      0.10272     2.70222     2.33486
mean/min                              -2.23252     0.09122     -2.02890    -2.37181
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 6, 1, 2, 0, 7, 8, 5, 9, 4]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
train_time 6.286096096038818
2023-10-11 00:24:01,070 MainThread INFO: EPOCH:32
2023-10-11 00:24:01,071 MainThread INFO: Time Consumed:6.294818878173828s
2023-10-11 00:24:01,071 MainThread INFO: Total Frames:49500s
  3%|▎         | 33/1000 [05:07<2:04:08,  7.70s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1294.11937
Train_Epoch_Reward                    4589.98373
Running_Training_Average_Rewards      1087.09729
Explore_Time                          0.00262
Train___Time                          6.28610
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.14477
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.31528
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -77.73416
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.28592
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.41599
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.67857
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -89.61462
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13643.49475
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.13021
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -73.98150
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.77323      1.39544     13.27910    4.39525
alpha_0                               0.35230      0.00288     0.35829     0.34755
alpha_1                               0.18226      0.00254     0.18633     0.17767
alpha_2                               0.17442      0.00121     0.17660     0.17254
alpha_3                               0.17670      0.00133     0.17905     0.17463
alpha_4                               0.16732      0.00254     0.17201     0.16307
alpha_5                               0.17603      0.00176     0.17913     0.17316
alpha_6                               0.18575      0.00072     0.18693     0.18478
alpha_7                               0.17935      0.00249     0.18363     0.17530
alpha_8                               0.18484      0.00227     0.18866     0.18123
alpha_9                               0.17897      0.00247     0.18340     0.17459
Alpha_loss                            -3.62672     0.51435     -2.58944    -4.83764
Training/policy_loss                  -169.14982   2.17811     -164.95049  -173.63332
Training/qf1_loss                     2427.37071   1080.86636  7551.29688  659.35876
Training/qf2_loss                     2389.67741   1073.03541  7489.23926  640.69641
Training/pf_norm                      0.50475      0.18628     1.20992     0.24422
Training/qf1_norm                     692.40426    486.60889   3382.29834  160.92143
Training/qf2_norm                     681.16177    463.65221   3333.26392  167.25159
log_std/mean                          -0.47916     0.02221     -0.42827    -0.51286
log_std/std                           0.15829      0.00364     0.16747     0.15230
log_std/max                           -0.11648     0.02968     -0.06480    -0.17905
log_std/min                           -0.90813     0.04095     -0.83048    -0.98999
log_probs/mean                        1.94341      0.32317     2.57667     1.18678
log_probs/std                         2.51488      0.13326     2.77591     2.22129
log_probs/max                         9.02832      0.82245     10.19593    7.06301
log_probs/min                         -7.62191     1.30597     -5.22739    -12.07610
mean/mean                             0.19982      0.09054     0.35071     0.07318
mean/std                              1.27554      0.03621     1.33779     1.19022
mean/max                              2.61542      0.07556     2.72146     2.47115
mean/min                              -2.21503     0.06255     -2.08837    -2.31476
------------------------------------  -----------  ----------  ----------  ----------
sample: [0, 9, 4, 6, 1, 3, 5, 2, 7, 8]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
train_time 5.66163969039917
2023-10-11 00:24:06,802 MainThread INFO: EPOCH:33
2023-10-11 00:24:06,803 MainThread INFO: Time Consumed:5.669605493545532s
2023-10-11 00:24:06,803 MainThread INFO: Total Frames:51000s
  3%|▎         | 34/1000 [05:13<1:54:45,  7.13s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1247.70168
Train_Epoch_Reward                    14137.17991
Running_Training_Average_Rewards      1054.71666
Explore_Time                          0.00260
Train___Time                          5.66164
Eval____Time                          0.00243
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.50201
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.78459
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.30012
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2327.35210
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.65909
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.87427
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -87.33072
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10784.23187
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.50944
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.60692
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.65748      1.30078     10.91877    4.78830
alpha_0                               0.36685      0.00491     0.37688     0.35838
alpha_1                               0.17298      0.00268     0.17763     0.16855
alpha_2                               0.17070      0.00108     0.17252     0.16929
alpha_3                               0.17321      0.00083     0.17462     0.17183
alpha_4                               0.15898      0.00217     0.16302     0.15562
alpha_5                               0.17062      0.00142     0.17314     0.16857
alpha_6                               0.18467      0.00009     0.18482     0.18453
alpha_7                               0.17166      0.00211     0.17527     0.16829
alpha_8                               0.17813      0.00185     0.18121     0.17504
alpha_9                               0.16955      0.00278     0.17454     0.16489
Alpha_loss                            -3.12717     0.56648     -1.70029    -4.09655
Training/policy_loss                  -174.46315   1.97389     -170.33546  -178.90178
Training/qf1_loss                     2319.81048   1002.01619  7182.11182  820.32776
Training/qf2_loss                     2275.82363   994.25702   7134.30615  796.95190
Training/pf_norm                      0.49018      0.16663     1.12684     0.23493
Training/qf1_norm                     731.34359    475.84425   2514.78125  139.56691
Training/qf2_norm                     726.88420    454.48772   2443.27588  152.61707
log_std/mean                          -0.47931     0.02033     -0.44312    -0.52162
log_std/std                           0.15146      0.00371     0.15799     0.14446
log_std/max                           -0.05414     0.02876     0.01382     -0.10733
log_std/min                           -0.84892     0.03331     -0.79491    -0.93901
log_probs/mean                        2.30510      0.34989     3.18916     1.70666
log_probs/std                         2.69215      0.09344     2.92241     2.50103
log_probs/max                         9.79106      0.74049     11.70822    8.46139
log_probs/min                         -7.56015     1.21835     -4.98739    -11.42855
mean/mean                             0.20509      0.06710     0.33733     0.10358
mean/std                              1.33373      0.04303     1.44065     1.26785
mean/max                              2.59690      0.05432     2.70207     2.49177
mean/min                              -2.27340     0.05370     -2.18984    -2.38370
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 2, 8, 6, 3, 9, 4, 7, 0, 1]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
train_time 5.799412250518799
2023-10-11 00:24:12,913 MainThread INFO: EPOCH:34
2023-10-11 00:24:12,914 MainThread INFO: Time Consumed:5.961357355117798s
2023-10-11 00:24:12,914 MainThread INFO: Total Frames:52500s
  4%|▎         | 35/1000 [05:19<1:49:37,  6.82s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1002.99321
Train_Epoch_Reward                    14841.23522
Running_Training_Average_Rewards      1118.94663
Explore_Time                          0.15618
Train___Time                          5.79941
Eval____Time                          0.00224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.75991
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.91916
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.24780
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           2448.62799
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.32338
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.59602
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -88.03984
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8215.70840
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.27942
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.23881
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.65342      1.38892     11.51941    4.68890
alpha_0                               0.38566      0.00468     0.39342     0.37699
alpha_1                               0.16374      0.00272     0.16850     0.15907
alpha_2                               0.16645      0.00180     0.16927     0.16317
alpha_3                               0.17023      0.00078     0.17182     0.16897
alpha_4                               0.15238      0.00178     0.15559     0.14947
alpha_5                               0.16587      0.00155     0.16855     0.16317
alpha_6                               0.18442      0.00029     0.18509     0.18410
alpha_7                               0.16436      0.00226     0.16826     0.16046
alpha_8                               0.17214      0.00153     0.17501     0.16969
alpha_9                               0.15992      0.00280     0.16484     0.15526
Alpha_loss                            -3.38849     0.36321     -2.49356    -4.00679
Training/policy_loss                  -179.50582   1.96081     -174.55276  -184.86218
Training/qf1_loss                     2318.96167   1062.55051  7132.92041  750.78357
Training/qf2_loss                     2266.91121   1051.93674  7029.96582  726.59796
Training/pf_norm                      0.50335      0.16335     0.99482     0.24529
Training/qf1_norm                     809.57576    526.46531   2882.81128  181.01903
Training/qf2_norm                     793.63737    496.50132   2774.70483  170.66107
log_std/mean                          -0.45796     0.02002     -0.42108    -0.49417
log_std/std                           0.14972      0.00542     0.15922     0.13801
log_std/max                           -0.03820     0.02918     0.01464     -0.09683
log_std/min                           -0.85602     0.04580     -0.77833    -0.94533
log_probs/mean                        2.19450      0.21436     2.70623     1.81616
log_probs/std                         2.73914      0.07516     2.92793     2.55132
log_probs/max                         9.62179      0.44661     10.97024    8.43942
log_probs/min                         -7.56391     1.18308     -5.39539    -11.87485
mean/mean                             0.11000      0.06833     0.23330     -0.01085
mean/std                              1.33545      0.02975     1.38825     1.27185
mean/max                              2.60966      0.04972     2.72212     2.47703
mean/min                              -2.27919     0.05296     -2.18653    -2.37652
------------------------------------  -----------  ----------  ----------  ----------
sample: [2, 7, 4, 6, 9, 3, 8, 1, 0, 5]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
train_time 5.5641679763793945
2023-10-11 00:24:18,626 MainThread INFO: EPOCH:35
2023-10-11 00:24:18,627 MainThread INFO: Time Consumed:5.610457420349121s
2023-10-11 00:24:18,627 MainThread INFO: Total Frames:54000s
  4%|▎         | 36/1000 [05:25<1:44:04,  6.48s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               765.82063
Train_Epoch_Reward                    10538.49413
Running_Training_Average_Rewards      1317.23031
Explore_Time                          0.04108
Train___Time                          5.56417
Eval____Time                          0.00209
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.92750
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.96541
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.95771
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.76245
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.49378
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.32884
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -82.75587
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8338.42959
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.18990
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.84185
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.75418      1.46124     11.16638    4.02399
alpha_0                               0.40296      0.00614     0.41407     0.39350
alpha_1                               0.15487      0.00246     0.15903     0.15051
alpha_2                               0.16152      0.00068     0.16313     0.16027
alpha_3                               0.16757      0.00091     0.16896     0.16592
alpha_4                               0.14728      0.00143     0.14945     0.14444
alpha_5                               0.16101      0.00126     0.16314     0.15877
alpha_6                               0.18610      0.00065     0.18738     0.18510
alpha_7                               0.15693      0.00195     0.16042     0.15345
alpha_8                               0.16691      0.00157     0.16967     0.16441
alpha_9                               0.15152      0.00199     0.15521     0.14821
Alpha_loss                            -2.68764     0.33449     -1.88586    -3.60235
Training/policy_loss                  -184.77407   2.11347     -180.13213  -191.31061
Training/qf1_loss                     2415.45714   1105.52496  6678.00488  738.37366
Training/qf2_loss                     2354.80083   1092.72037  6591.51562  711.13922
Training/pf_norm                      0.44743      0.10968     0.72560     0.26348
Training/qf1_norm                     890.97545    554.55127   2629.92017  166.01463
Training/qf2_norm                     879.38028    530.61673   2545.67334  192.38460
log_std/mean                          -0.46638     0.01444     -0.44065    -0.49342
log_std/std                           0.14961      0.00646     0.16308     0.13813
log_std/max                           -0.05703     0.01542     -0.03055    -0.09086
log_std/min                           -0.94605     0.03978     -0.86825    -1.02252
log_probs/mean                        2.63612      0.19178     3.11564     2.13009
log_probs/std                         2.79002      0.11104     3.01211     2.47794
log_probs/max                         10.07166     0.55380     11.79919    8.91632
log_probs/min                         -7.35862     1.17426     -5.42111    -11.06380
mean/mean                             0.23680      0.06884     0.36297     0.08212
mean/std                              1.38905      0.01794     1.43247     1.33598
mean/max                              2.64653      0.05262     2.74135     2.50213
mean/min                              -2.33709     0.05659     -2.22274    -2.44726
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 7, 1, 3, 5, 2, 8, 0, 4, 9]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
train_time 5.5437798500061035
2023-10-11 00:24:24,248 MainThread INFO: EPOCH:36
2023-10-11 00:24:24,248 MainThread INFO: Time Consumed:5.552405834197998s
2023-10-11 00:24:24,248 MainThread INFO: Total Frames:55500s
  4%|▎         | 37/1000 [05:30<1:39:50,  6.22s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               803.72192
Train_Epoch_Reward                    10125.26474
Running_Training_Average_Rewards      1183.49980
Explore_Time                          0.00269
Train___Time                          5.54378
Eval____Time                          0.00248
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.27916
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.23632
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.04897
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.58012
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.01002
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -115.91038
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.45771
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8720.59176
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.45677
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.39312
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.42999      1.37601     11.62262    3.72514
alpha_0                               0.42422      0.00542     0.43327     0.41419
alpha_1                               0.14583      0.00254     0.15047     0.14166
alpha_2                               0.15716      0.00192     0.16026     0.15410
alpha_3                               0.16421      0.00109     0.16591     0.16251
alpha_4                               0.14176      0.00139     0.14441     0.13949
alpha_5                               0.15507      0.00213     0.15875     0.15180
alpha_6                               0.18920      0.00098     0.19114     0.18740
alpha_7                               0.14952      0.00232     0.15342     0.14560
alpha_8                               0.16181      0.00175     0.16439     0.15876
alpha_9                               0.14492      0.00195     0.14818     0.14161
Alpha_loss                            -3.24395     0.56612     -2.17839    -4.29330
Training/policy_loss                  -189.05827   2.03358     -184.75064  -194.15274
Training/qf1_loss                     2329.96307   1009.04241  6531.00195  721.74725
Training/qf2_loss                     2267.16255   998.51854   6429.53027  682.69360
Training/pf_norm                      0.46376      0.11581     0.84786     0.22885
Training/qf1_norm                     880.49728    532.12539   2867.01733  180.77489
Training/qf2_norm                     868.45277    516.86128   2780.21533  171.82674
log_std/mean                          -0.45961     0.01843     -0.42828    -0.49974
log_std/std                           0.14769      0.00476     0.15794     0.13882
log_std/max                           -0.07989     0.01207     -0.05463    -0.12275
log_std/min                           -0.99940     0.03929     -0.88946    -1.07111
log_probs/mean                        2.36649      0.31404     2.98689     1.79438
log_probs/std                         2.82552      0.10467     3.01615     2.51677
log_probs/max                         9.80294      0.64604     11.29475    8.24984
log_probs/min                         -7.55313     1.23357     -4.86666    -11.83663
mean/mean                             0.05678      0.04589     0.20351     0.00393
mean/std                              1.37319      0.04284     1.45890     1.30122
mean/max                              2.71460      0.05493     2.88151     2.56914
mean/min                              -2.34607     0.06468     -2.20272    -2.45013
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 8, 7, 3, 4, 5, 2, 1, 0, 9]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
train_time 5.621209621429443
2023-10-11 00:24:29,946 MainThread INFO: EPOCH:37
2023-10-11 00:24:29,947 MainThread INFO: Time Consumed:5.628870487213135s
2023-10-11 00:24:29,947 MainThread INFO: Total Frames:57000s
  4%|▍         | 38/1000 [05:36<1:37:13,  6.06s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               767.25746
Train_Epoch_Reward                    9247.07227
Running_Training_Average_Rewards      997.02770
Explore_Time                          0.00255
Train___Time                          5.62121
Eval____Time                          0.00203
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.13329
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.36957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.00212
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.73416
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -90.27429
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -117.55767
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -81.08694
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8395.96276
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.80675
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.42334
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.59893     1.27460     12.37487    4.51463
alpha_0                               0.44386     0.00742     0.45683     0.43335
alpha_1                               0.13783     0.00226     0.14162     0.13399
alpha_2                               0.15152     0.00136     0.15406     0.14874
alpha_3                               0.16109     0.00067     0.16248     0.15961
alpha_4                               0.13675     0.00165     0.13946     0.13390
alpha_5                               0.14998     0.00101     0.15176     0.14787
alpha_6                               0.19296     0.00128     0.19454     0.19115
alpha_7                               0.14177     0.00210     0.14556     0.13805
alpha_8                               0.15635     0.00110     0.15872     0.15419
alpha_9                               0.13849     0.00161     0.14157     0.13572
Alpha_loss                            -2.83056    0.57532     -1.62542    -4.05523
Training/policy_loss                  -194.03510  2.25200     -188.15366  -201.48743
Training/qf1_loss                     2445.41590  1083.57191  6951.79785  814.41766
Training/qf2_loss                     2373.80212  1070.51559  6807.97900  778.83826
Training/pf_norm                      0.52239     0.12070     0.87046     0.30559
Training/qf1_norm                     871.84376   544.08455   3566.30566  230.60310
Training/qf2_norm                     855.04729   515.10426   3394.84814  232.35519
log_std/mean                          -0.46890    0.01408     -0.44036    -0.50780
log_std/std                           0.15167     0.00359     0.15914     0.14402
log_std/max                           0.04735     0.05231     0.12543     -0.07840
log_std/min                           -0.99120    0.03107     -0.91442    -1.04829
log_probs/mean                        2.64018     0.32256     3.28185     1.93413
log_probs/std                         2.96633     0.14843     3.27995     2.67513
log_probs/max                         11.67279    0.93730     14.33880    8.91489
log_probs/min                         -7.60939    1.45253     -5.05894    -16.17436
mean/mean                             0.11725     0.07309     0.23003     0.00117
mean/std                              1.41014     0.04579     1.50417     1.32111
mean/max                              2.95568     0.26751     3.38311     2.57000
mean/min                              -2.48442    0.14318     -2.28884    -2.80476
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 0, 1, 9, 5, 4, 8, 3, 7, 2]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
train_time 6.809832334518433
2023-10-11 00:24:36,841 MainThread INFO: EPOCH:38
2023-10-11 00:24:36,842 MainThread INFO: Time Consumed:6.826260805130005s
2023-10-11 00:24:36,842 MainThread INFO: Total Frames:58500s
  4%|▍         | 39/1000 [05:43<1:41:21,  6.33s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1263.59469
Train_Epoch_Reward                    8309.93087
Running_Training_Average_Rewards      922.74226
Explore_Time                          0.00230
Train___Time                          6.80983
Eval____Time                          0.00977
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.80075
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.51679
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -78.93427
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.27829
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -82.76761
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.25661
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -73.36171
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13321.42808
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -71.74125
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.82390
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.47995      1.29605    11.25414    3.83968
alpha_0                               0.46962      0.00744    0.48311     0.45694
alpha_1                               0.13114      0.00156    0.13396     0.12854
alpha_2                               0.14612      0.00157    0.14871     0.14359
alpha_3                               0.15835      0.00081    0.15959     0.15719
alpha_4                               0.13185      0.00112    0.13387     0.13002
alpha_5                               0.14640      0.00088    0.14785     0.14499
alpha_6                               0.19664      0.00129    0.19949     0.19446
alpha_7                               0.13455      0.00197    0.13801     0.13127
alpha_8                               0.15225      0.00103    0.15416     0.15082
alpha_9                               0.13310      0.00151    0.13569     0.13064
Alpha_loss                            -2.16953     0.48352    -0.90249    -3.04113
Training/policy_loss                  -199.09076   2.59248    -193.27234  -205.88919
Training/qf1_loss                     2206.61544   822.27610  5601.54004  644.70117
Training/qf2_loss                     2132.29407   808.59232  5465.42871  605.67987
Training/pf_norm                      0.49853      0.12734    0.93827     0.26750
Training/qf1_norm                     889.04654    549.67712  3344.47534  180.90712
Training/qf2_norm                     874.26906    524.62600  3234.97241  196.29721
log_std/mean                          -0.49622     0.01927    -0.44466    -0.52857
log_std/std                           0.16243      0.00349    0.16883     0.15297
log_std/max                           0.18844      0.02245    0.22544     0.11462
log_std/min                           -1.02580     0.03592    -0.91161    -1.08550
log_probs/mean                        3.02182      0.27666    3.74680     2.53354
log_probs/std                         2.91841      0.12536    3.18874     2.63129
log_probs/max                         12.36163     0.62878    13.91878    10.96811
log_probs/min                         -7.36904     1.34460    -4.90214    -12.97116
mean/mean                             0.04386      0.04613    0.12886     -0.01854
mean/std                              1.46648      0.03859    1.55503     1.39407
mean/max                              3.01092      0.23858    3.46480     2.68153
mean/min                              -2.78495     0.04678    -2.68105    -2.89520
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 5, 3, 2, 6, 4, 7, 0, 1, 8]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
train_time 5.467083215713501
2023-10-11 00:24:42,491 MainThread INFO: EPOCH:39
2023-10-11 00:24:42,492 MainThread INFO: Time Consumed:5.475625514984131s
2023-10-11 00:24:42,492 MainThread INFO: Total Frames:60000s
  4%|▍         | 40/1000 [05:48<1:37:44,  6.11s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1003.84375
Train_Epoch_Reward                    13095.33569
Running_Training_Average_Rewards      1021.74463
Explore_Time                          0.00291
Train___Time                          5.46708
Eval____Time                          0.00231
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.65904
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.00718
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.38736
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.44504
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -85.96984
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.63207
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.97119
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10709.38931
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -75.36704
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.51303
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.45607      1.27438    11.53299    4.72452
alpha_0                               0.49801      0.00752    0.50984     0.48327
alpha_1                               0.12606      0.00132    0.12851     0.12380
alpha_2                               0.14127      0.00115    0.14357     0.13932
alpha_3                               0.15651      0.00039    0.15722     0.15597
alpha_4                               0.12758      0.00135    0.13000     0.12526
alpha_5                               0.14538      0.00050    0.14599     0.14472
alpha_6                               0.20242      0.00150    0.20501     0.19953
alpha_7                               0.12768      0.00206    0.13124     0.12418
alpha_8                               0.15039      0.00027    0.15082     0.14984
alpha_9                               0.12863      0.00121    0.13063     0.12649
Alpha_loss                            -1.77207     0.32912    -1.01019    -2.56032
Training/policy_loss                  -203.94957   2.23827    -197.43770  -209.41553
Training/qf1_loss                     2266.95909   958.78118  5453.87939  728.95636
Training/qf2_loss                     2192.60503   943.98872  5392.69922  704.29224
Training/pf_norm                      0.43633      0.10115    0.80675     0.22923
Training/qf1_norm                     946.16332    566.82552  3188.71533  246.09758
Training/qf2_norm                     925.70578    535.01157  3090.13745  254.69974
log_std/mean                          -0.48914     0.01109    -0.46857    -0.50894
log_std/std                           0.17306      0.00438    0.18219     0.16608
log_std/max                           0.20644      0.02144    0.26552     0.14539
log_std/min                           -1.04328     0.04977    -0.91647    -1.13895
log_probs/mean                        3.24741      0.16523    3.63357     2.81821
log_probs/std                         3.05181      0.10599    3.34036     2.80634
log_probs/max                         13.25132     0.84611    15.31217    10.88844
log_probs/min                         -7.48680     1.52096    -4.71425    -16.24850
mean/mean                             0.10793      0.05732    0.18948     -0.00364
mean/std                              1.50254      0.02123    1.54779     1.45251
mean/max                              3.26168      0.25242    3.62561     2.85723
mean/min                              -3.06239     0.12048    -2.81900    -3.32924
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 1, 6, 4, 3, 2, 8, 5, 9, 0]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
train_time 7.098573207855225
2023-10-11 00:24:49,667 MainThread INFO: EPOCH:40
2023-10-11 00:24:49,667 MainThread INFO: Time Consumed:7.106897354125977s
2023-10-11 00:24:49,667 MainThread INFO: Total Frames:61500s
  4%|▍         | 41/1000 [05:56<1:42:45,  6.43s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               390.75407
Train_Epoch_Reward                    11496.74229
Running_Training_Average_Rewards      1096.73363
Explore_Time                          0.00275
Train___Time                          7.09857
Eval____Time                          0.00212
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.01761
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.39592
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.90630
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -66.36108
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.73532
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.15439
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -74.73439
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4625.69977
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -79.14350
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.71057
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.40898      1.41136    11.38194    4.51410
alpha_0                               0.51723      0.00359    0.52339     0.50995
alpha_1                               0.12198      0.00106    0.12378     0.12009
alpha_2                               0.13868      0.00024    0.13930     0.13808
alpha_3                               0.15615      0.00023    0.15648     0.15579
alpha_4                               0.12338      0.00118    0.12524     0.12117
alpha_5                               0.14565      0.00028    0.14591     0.14479
alpha_6                               0.20778      0.00143    0.20948     0.20504
alpha_7                               0.12069      0.00199    0.12415     0.11720
alpha_8                               0.14884      0.00065    0.14983     0.14742
alpha_9                               0.12458      0.00110    0.12647     0.12243
Alpha_loss                            -1.66352     0.47522    -0.63894    -2.71596
Training/policy_loss                  -208.22622   2.29005    -202.34981  -213.89848
Training/qf1_loss                     2208.80661   971.65787  7035.48584  605.71497
Training/qf2_loss                     2132.04983   957.53213  6888.88770  557.53455
Training/pf_norm                      0.44868      0.11229    0.85426     0.24127
Training/qf1_norm                     1015.07104   671.89201  3777.82031  208.91527
Training/qf2_norm                     999.68320    656.29478  3777.57935  212.37476
log_std/mean                          -0.47651     0.01231    -0.45611    -0.49677
log_std/std                           0.18375      0.00813    0.20429     0.17146
log_std/max                           0.22140      0.04564    0.32267     0.14139
log_std/min                           -1.11849     0.04562    -1.00837    -1.20577
log_probs/mean                        3.26245      0.24548    3.80792     2.65864
log_probs/std                         2.87743      0.08536    3.10234     2.64435
log_probs/max                         12.63286     0.71156    14.61320    10.97898
log_probs/min                         -7.30478     1.37610    -4.70275    -11.58743
mean/mean                             0.18316      0.06260    0.25136     0.05537
mean/std                              1.50025      0.03863    1.57330     1.42729
mean/max                              2.91132      0.12586    3.17141     2.63190
mean/min                              -2.90340     0.08380    -2.67866    -3.05339
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 9, 2, 8, 7, 3, 1, 4, 5, 0]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
train_time 5.680333375930786
2023-10-11 00:24:55,423 MainThread INFO: EPOCH:41
2023-10-11 00:24:55,423 MainThread INFO: Time Consumed:5.688803195953369s
2023-10-11 00:24:55,424 MainThread INFO: Total Frames:63000s
  4%|▍         | 42/1000 [06:01<1:39:43,  6.25s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               396.00421
Train_Epoch_Reward                    4765.00648
Running_Training_Average_Rewards      978.56948
Explore_Time                          0.00263
Train___Time                          5.68033
Eval____Time                          0.00268
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.88053
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.43267
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.73807
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.06155
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -86.66736
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.50788
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.97330
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4635.97960
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.26512
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.41103
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           7.47447     1.50397     13.17579    4.32919
alpha_0                               0.53617     0.00721     0.54905     0.52349
alpha_1                               0.11776     0.00148     0.12007     0.11506
alpha_2                               0.13789     0.00066     0.13950     0.13712
alpha_3                               0.15765     0.00106     0.15963     0.15630
alpha_4                               0.11961     0.00088     0.12115     0.11814
alpha_5                               0.14263     0.00120     0.14477     0.14114
alpha_6                               0.21149     0.00150     0.21441     0.20948
alpha_7                               0.11408     0.00165     0.11716     0.11149
alpha_8                               0.14691     0.00019     0.14740     0.14669
alpha_9                               0.12046     0.00095     0.12240     0.11921
Alpha_loss                            -1.24764    0.55659     -0.15428    -2.12906
Training/policy_loss                  -212.29996  2.43281     -205.99394  -218.79350
Training/qf1_loss                     2262.70695  1017.62661  6368.74219  910.00549
Training/qf2_loss                     2184.17817  1002.75227  6258.73828  889.31738
Training/pf_norm                      0.51005     0.11272     0.90818     0.27401
Training/qf1_norm                     1059.37788  770.51329   4756.77197  259.43964
Training/qf2_norm                     1048.22885  753.42141   4785.64941  273.75320
log_std/mean                          -0.48331    0.00820     -0.46198    -0.49831
log_std/std                           0.18193     0.01213     0.20288     0.16040
log_std/max                           0.18163     0.10431     0.31949     0.01362
log_std/min                           -1.14954    0.05144     -1.02060    -1.26089
log_probs/mean                        3.52611     0.28851     4.10527     3.04644
log_probs/std                         2.91563     0.12455     3.20504     2.68648
log_probs/max                         12.07052    0.70669     13.91379    10.02211
log_probs/min                         -7.26267    1.35925     -4.83228    -12.98328
mean/mean                             0.29846     0.08830     0.45684     0.18553
mean/std                              1.51731     0.03200     1.57803     1.45820
mean/max                              3.09993     0.26815     3.58271     2.67787
mean/min                              -2.63144    0.13272     -2.39180    -2.92641
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 7, 4, 1, 9, 2, 0, 3, 8, 5]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
train_time 6.976731300354004
2023-10-11 00:25:02,562 MainThread INFO: EPOCH:42
2023-10-11 00:25:02,563 MainThread INFO: Time Consumed:6.986361742019653s
2023-10-11 00:25:02,563 MainThread INFO: Total Frames:64500s
  4%|▍         | 43/1000 [06:09<1:43:35,  6.50s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               543.68433
Train_Epoch_Reward                    4537.04528
Running_Training_Average_Rewards      693.29313
Explore_Time                          0.00377
Train___Time                          6.97673
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.69452
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.21959
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.27341
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.38301
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.96167
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -114.67277
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.98167
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4568.39008
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.24800
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           1486.88781
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.21767     1.41493    11.01245    3.94050
alpha_0                               0.55737     0.00563    0.56920     0.54919
alpha_1                               0.11281     0.00122    0.11503     0.11070
alpha_2                               0.13711     0.00148    0.13958     0.13525
alpha_3                               0.15902     0.00048    0.15971     0.15807
alpha_4                               0.11629     0.00085    0.11813     0.11487
alpha_5                               0.13775     0.00169    0.14112     0.13571
alpha_6                               0.21492     0.00025    0.21559     0.21444
alpha_7                               0.10831     0.00189    0.11147     0.10515
alpha_8                               0.14840     0.00088    0.14947     0.14711
alpha_9                               0.11725     0.00109    0.11920     0.11554
Alpha_loss                            -1.94568    0.54297    -0.82776    -3.05392
Training/policy_loss                  -215.94157  2.67310    -209.10225  -222.49496
Training/qf1_loss                     2062.37802  978.19721  5532.23145  617.34882
Training/qf2_loss                     1985.18050  958.97154  5436.86670  579.82593
Training/pf_norm                      0.53453     0.15765    0.92015     0.24579
Training/qf1_norm                     1110.57158  682.21437  3413.34399  291.62396
Training/qf2_norm                     1096.51700  652.43329  3376.58691  292.48499
log_std/mean                          -0.48778    0.01548    -0.45747    -0.51632
log_std/std                           0.17713     0.01433    0.20889     0.15627
log_std/max                           0.02987     0.03580    0.09133     -0.04293
log_std/min                           -1.22187    0.08040    -1.03151    -1.36184
log_probs/mean                        3.15349     0.29641    3.74091     2.55774
log_probs/std                         2.83582     0.08584    3.07027     2.60312
log_probs/max                         12.00769    0.97861    15.42720    9.43421
log_probs/min                         -7.29373    1.14816    -4.72910    -11.19030
mean/mean                             0.08688     0.08519    0.23820     -0.06297
mean/std                              1.48494     0.03996    1.55453     1.40835
mean/max                              3.03857     0.29460    3.58976     2.37369
mean/min                              -2.87466    0.13311    -2.53670    -3.06599
------------------------------------  ----------  ---------  ----------  ----------
sample: [6, 8, 4, 5, 0, 1, 7, 2, 3, 9]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
train_time 5.985953092575073
2023-10-11 00:25:08,626 MainThread INFO: EPOCH:43
2023-10-11 00:25:08,627 MainThread INFO: Time Consumed:5.995549917221069s
2023-10-11 00:25:08,627 MainThread INFO: Total Frames:66000s
  4%|▍         | 44/1000 [06:15<1:41:26,  6.37s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1022.21730
Train_Epoch_Reward                    6076.41419
Running_Training_Average_Rewards      512.61553
Explore_Time                          0.00361
Train___Time                          5.98595
Eval____Time                          0.00235
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.61263
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.61680
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -79.54753
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.76195
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.26372
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.73386
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -53.84865
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10857.59018
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.78651
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -10.24551
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.06502      1.23937    10.94939    4.41981
alpha_0                               0.58726      0.01051    0.60476     0.56935
alpha_1                               0.10846      0.00125    0.11067     0.10631
alpha_2                               0.13268      0.00156    0.13523     0.12985
alpha_3                               0.15510      0.00210    0.15805     0.15101
alpha_4                               0.11239      0.00154    0.11484     0.10966
alpha_5                               0.13460      0.00065    0.13569     0.13360
alpha_6                               0.21547      0.00032    0.21590     0.21488
alpha_7                               0.10221      0.00165    0.10512     0.09944
alpha_8                               0.15058      0.00050    0.15149     0.14948
alpha_9                               0.11307      0.00153    0.11552     0.11032
Alpha_loss                            -2.23162     0.51801    -1.03275    -3.44765
Training/policy_loss                  -220.23108   2.55775    -214.29892  -227.71750
Training/qf1_loss                     2021.98380   864.51434  5329.00098  576.50323
Training/qf2_loss                     1954.38359   852.17853  5272.35449  554.88684
Training/pf_norm                      0.48571      0.10665    0.82651     0.26337
Training/qf1_norm                     1007.30084   625.49376  3777.14917  259.04080
Training/qf2_norm                     997.75132    612.50601  3736.57153  251.09868
log_std/mean                          -0.47587     0.01260    -0.45239    -0.50691
log_std/std                           0.16455      0.00395    0.17594     0.15534
log_std/max                           0.03497      0.02780    0.08860     -0.01510
log_std/min                           -1.31009     0.06075    -1.12728    -1.41568
log_probs/mean                        3.07397      0.27386    3.69026     2.43587
log_probs/std                         2.83568      0.06913    3.01883     2.66142
log_probs/max                         11.31821     0.89027    14.62202    9.67389
log_probs/min                         -7.41932     1.50533    -4.91747    -12.79605
mean/mean                             0.14556      0.02548    0.20013     0.08222
mean/std                              1.47474      0.03638    1.54790     1.39336
mean/max                              3.20122      0.22449    3.63767     2.75147
mean/min                              -2.94514     0.09031    -2.78041    -3.14524
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 5, 0, 7, 8, 1, 3, 4, 2, 6]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
train_time 7.76728081703186
2023-10-11 00:25:16,476 MainThread INFO: EPOCH:44
2023-10-11 00:25:16,476 MainThread INFO: Time Consumed:7.776531219482422s
2023-10-11 00:25:16,477 MainThread INFO: Total Frames:67500s
  4%|▍         | 45/1000 [06:22<1:48:22,  6.81s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               369.64109
Train_Epoch_Reward                    10323.07972
Running_Training_Average_Rewards      697.88464
Explore_Time                          0.00324
Train___Time                          7.76728
Eval____Time                          0.00244
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -80.10526
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -90.27058
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -22.10948
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.00743
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.49182
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -111.11190
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.96967
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4270.16029
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.67955
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.00370
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.04776      1.43113     11.85048    3.66684
alpha_0                               0.61385      0.00441     0.62009     0.60487
alpha_1                               0.10370      0.00158     0.10629     0.10093
alpha_2                               0.12757      0.00113     0.12982     0.12574
alpha_3                               0.14540      0.00335     0.15096     0.13897
alpha_4                               0.10666      0.00181     0.10963     0.10347
alpha_5                               0.13139      0.00171     0.13358     0.12819
alpha_6                               0.21707      0.00109     0.21862     0.21540
alpha_7                               0.09707      0.00119     0.09942     0.09549
alpha_8                               0.15317      0.00087     0.15419     0.15151
alpha_9                               0.10790      0.00129     0.11029     0.10548
Alpha_loss                            -2.55362     0.41520     -1.40398    -3.42493
Training/policy_loss                  -224.34585   2.52908     -217.03325  -230.35266
Training/qf1_loss                     2018.41755   1040.32048  5690.62109  477.22861
Training/qf2_loss                     1957.22339   1022.64763  5538.41016  480.58331
Training/pf_norm                      0.56656      0.14635     1.10087     0.27566
Training/qf1_norm                     1186.09748   794.38468   4560.29834  297.72220
Training/qf2_norm                     1180.38336   784.41188   4485.85010  266.05667
log_std/mean                          -0.43496     0.02412     -0.39238    -0.47606
log_std/std                           0.17006      0.00681     0.19056     0.15774
log_std/max                           0.08362      0.05920     0.18023     -0.02121
log_std/min                           -1.24246     0.05989     -1.01199    -1.33566
log_probs/mean                        2.86774      0.23103     3.45567     2.42969
log_probs/std                         2.86268      0.07523     3.02372     2.68766
log_probs/max                         11.68407     0.80817     14.22142    9.58096
log_probs/min                         -7.47580     1.33119     -4.12472    -11.47102
mean/mean                             0.11454      0.04396     0.21037     0.03469
mean/std                              1.47509      0.02554     1.54134     1.42717
mean/max                              3.60083      0.28244     4.05732     2.99603
mean/min                              -2.91315     0.11311     -2.73777    -3.17391
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 0, 8, 9, 6, 5, 1, 2, 7, 3]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
train_time 5.531691074371338
2023-10-11 00:25:22,078 MainThread INFO: EPOCH:45
2023-10-11 00:25:22,078 MainThread INFO: Time Consumed:5.540153980255127s
2023-10-11 00:25:22,079 MainThread INFO: Total Frames:69000s
  5%|▍         | 46/1000 [06:28<1:42:32,  6.45s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               375.41152
Train_Epoch_Reward                    3860.83714
Running_Training_Average_Rewards      675.34437
Explore_Time                          0.00275
Train___Time                          5.53169
Eval____Time                          0.00241
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.91284
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.51010
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.15019
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -38.06643
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -87.87167
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -110.43008
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.78738
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4329.20779
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.23772
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.12621
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std         Max         Min
Reward_Mean                           6.98048     1.32337     11.29939    3.79603
alpha_0                               0.62700     0.00370     0.63129     0.61992
alpha_1                               0.09743     0.00228     0.10090     0.09326
alpha_2                               0.12394     0.00075     0.12571     0.12309
alpha_3                               0.13248     0.00371     0.13889     0.12625
alpha_4                               0.10132     0.00091     0.10344     0.09999
alpha_5                               0.12701     0.00043     0.12817     0.12660
alpha_6                               0.21605     0.00113     0.21747     0.21414
alpha_7                               0.09481     0.00067     0.09549     0.09336
alpha_8                               0.15409     0.00059     0.15477     0.15282
alpha_9                               0.10259     0.00160     0.10545     0.09997
Alpha_loss                            -2.56652    0.41095     -1.27548    -3.45668
Training/policy_loss                  -228.25207  2.80210     -222.11028  -237.90524
Training/qf1_loss                     2112.72052  1094.05204  8265.02832  535.84314
Training/qf2_loss                     2056.66724  1083.36219  8200.80469  511.14264
Training/pf_norm                      0.55762     0.12801     0.93848     0.28926
Training/qf1_norm                     1139.25864  692.31123   4062.74072  370.31198
Training/qf2_norm                     1132.35496  691.22878   4164.02588  318.97397
log_std/mean                          -0.42060    0.01277     -0.39691    -0.44843
log_std/std                           0.20955     0.00997     0.23764     0.19103
log_std/max                           0.30070     0.06388     0.45748     0.17424
log_std/min                           -1.28285    0.04350     -1.09389    -1.35885
log_probs/mean                        2.86981     0.22390     3.53402     2.36667
log_probs/std                         3.00060     0.07523     3.21920     2.80935
log_probs/max                         12.42624    0.84674     14.28816    10.68798
log_probs/min                         -7.31096    1.29593     -4.57770    -12.43525
mean/mean                             0.13796     0.10699     0.36056     -0.01681
mean/std                              1.47131     0.03918     1.56570     1.41174
mean/max                              3.62048     0.19179     4.03812     3.23090
mean/min                              -2.71975    0.20917     -2.29681    -3.12470
------------------------------------  ----------  ----------  ----------  ----------
sample: [1, 3, 2, 9, 8, 4, 5, 6, 0, 7]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
train_time 5.627061605453491
2023-10-11 00:25:27,786 MainThread INFO: EPOCH:46
2023-10-11 00:25:27,787 MainThread INFO: Time Consumed:5.637175798416138s
2023-10-11 00:25:27,787 MainThread INFO: Total Frames:70500s
  5%|▍         | 47/1000 [06:34<1:38:53,  6.23s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               534.36447
Train_Epoch_Reward                    4064.87484
Running_Training_Average_Rewards      608.29306
Explore_Time                          0.00390
Train___Time                          5.62706
Eval____Time                          0.00284
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.41110
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -89.34709
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.16847
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.61387
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.45851
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -119.66855
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -65.13750
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5959.99541
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -83.32171
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.22390
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           7.01597     1.29005    11.71342    3.77456
alpha_0                               0.63871     0.00546    0.64740     0.63127
alpha_1                               0.08958     0.00192    0.09321     0.08663
alpha_2                               0.12145     0.00087    0.12333     0.12042
alpha_3                               0.12097     0.00290    0.12619     0.11614
alpha_4                               0.09879     0.00051    0.09997     0.09812
alpha_5                               0.12498     0.00075    0.12675     0.12408
alpha_6                               0.21254     0.00172    0.21455     0.20911
alpha_7                               0.09185     0.00092    0.09334     0.09020
alpha_8                               0.15213     0.00126    0.15314     0.14922
alpha_9                               0.09686     0.00162    0.09994     0.09436
Alpha_loss                            -2.72307    0.55399    -1.38037    -3.81148
Training/policy_loss                  -231.94429  3.05583    -221.84148  -239.17056
Training/qf1_loss                     1948.66465  849.61601  6381.36768  456.31036
Training/qf2_loss                     1889.68495  834.92331  6257.30176  452.16592
Training/pf_norm                      0.57641     0.15899    1.01199     0.29534
Training/qf1_norm                     1176.08440  720.50890  4523.89404  295.79385
Training/qf2_norm                     1170.06019  712.88137  4359.40967  272.03555
log_std/mean                          -0.44946    0.01497    -0.42426    -0.49653
log_std/std                           0.22568     0.01187    0.24336     0.19889
log_std/max                           0.42314     0.05877    0.52200     0.30577
log_std/min                           -1.40313    0.06312    -1.20219    -1.50644
log_probs/mean                        2.82760     0.27010    3.52505     2.30156
log_probs/std                         2.91287     0.08935    3.18102     2.68738
log_probs/max                         11.99079    1.12879    14.91482    9.77974
log_probs/min                         -7.40277    1.22508    -5.08224    -12.08853
mean/mean                             0.10149     0.07482    0.24494     -0.01273
mean/std                              1.45935     0.03787    1.55252     1.38521
mean/max                              3.60531     0.24161    4.03992     3.09516
mean/min                              -2.96647    0.24702    -2.40521    -3.40432
------------------------------------  ----------  ---------  ----------  ----------
sample: [4, 3, 5, 9, 7, 6, 1, 2, 0, 8]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
train_time 8.121465921401978
2023-10-11 00:25:35,987 MainThread INFO: EPOCH:47
2023-10-11 00:25:35,987 MainThread INFO: Time Consumed:8.132037162780762s
2023-10-11 00:25:35,988 MainThread INFO: Total Frames:72000s
  5%|▍         | 48/1000 [06:42<1:48:11,  6.82s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               456.07677
Train_Epoch_Reward                    6023.10674
Running_Training_Average_Rewards      464.96062
Explore_Time                          0.00469
Train___Time                          8.12147
Eval____Time                          0.00251
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.71801
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.09877
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.06942
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.53608
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.48357
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.27324
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.06820
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5121.68595
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -80.29397
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.37698
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.94336     1.21615    10.12263    4.18308
alpha_0                               0.65924     0.00692    0.67271     0.64753
alpha_1                               0.08538     0.00053    0.08661     0.08484
alpha_2                               0.12052     0.00023    0.12096     0.12021
alpha_3                               0.11168     0.00272    0.11610     0.10712
alpha_4                               0.09780     0.00030    0.09812     0.09733
alpha_5                               0.12469     0.00024    0.12494     0.12409
alpha_6                               0.20448     0.00387    0.20949     0.19821
alpha_7                               0.08852     0.00087    0.09018     0.08730
alpha_8                               0.14458     0.00333    0.14921     0.13938
alpha_9                               0.09269     0.00079    0.09434     0.09154
Alpha_loss                            -1.95143    0.44030    -0.91560    -2.85831
Training/policy_loss                  -235.92291  3.29503    -225.70920  -245.79953
Training/qf1_loss                     1994.62617  906.22751  5229.60498  695.22156
Training/qf2_loss                     1941.66578  895.80756  5161.23584  676.37268
Training/pf_norm                      0.55852     0.13216    0.91123     0.27450
Training/qf1_norm                     1154.86495  624.90215  3334.96362  357.17889
Training/qf2_norm                     1155.58504  629.96866  3414.28857  328.33185
log_std/mean                          -0.46901    0.01284    -0.44090    -0.49507
log_std/std                           0.19589     0.00301    0.20288     0.18677
log_std/max                           0.30360     0.04454    0.38517     0.21339
log_std/min                           -1.48776    0.07166    -1.24580    -1.60587
log_probs/mean                        3.15508     0.22382    3.64883     2.72231
log_probs/std                         2.94100     0.12036    3.17493     2.65182
log_probs/max                         12.92486    0.81599    15.44108    11.16017
log_probs/min                         -7.23784    1.28867    -4.81650    -11.40979
mean/mean                             0.18139     0.07973    0.30638     0.04230
mean/std                              1.50561     0.02551    1.55759     1.45432
mean/max                              4.07229     0.13413    4.40882     3.82252
mean/min                              -3.04467    0.24971    -2.53240    -3.72427
------------------------------------  ----------  ---------  ----------  ----------
sample: [2, 3, 5, 6, 7, 8, 9, 4, 1, 0]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
train_time 5.6066505908966064
2023-10-11 00:25:41,675 MainThread INFO: EPOCH:48
2023-10-11 00:25:41,675 MainThread INFO: Time Consumed:5.617696523666382s
2023-10-11 00:25:41,676 MainThread INFO: Total Frames:73500s
  5%|▍         | 49/1000 [06:48<1:42:42,  6.48s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               435.53598
Train_Epoch_Reward                    6872.02565
Running_Training_Average_Rewards      565.33357
Explore_Time                          0.00507
Train___Time                          5.60665
Eval____Time                          0.00256
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.93632
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -87.07455
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.06216
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.28097
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.20204
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -116.76781
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -70.36252
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4952.09287
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -90.99705
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.04965
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.92502     1.23779    10.60649    3.69855
alpha_0                               0.68897     0.00805    0.70375     0.67292
alpha_1                               0.08503     0.00019    0.08538     0.08475
alpha_2                               0.11804     0.00159    0.12020     0.11577
alpha_3                               0.10307     0.00229    0.10708     0.09928
alpha_4                               0.09737     0.00025    0.09787     0.09704
alpha_5                               0.11960     0.00339    0.12408     0.11356
alpha_6                               0.19250     0.00319    0.19814     0.18705
alpha_7                               0.08658     0.00039    0.08729     0.08580
alpha_8                               0.13553     0.00211    0.13935     0.13191
alpha_9                               0.09024     0.00077    0.09153     0.08930
Alpha_loss                            -1.96618    0.36443    -1.14205    -2.66290
Training/policy_loss                  -239.99038  3.28479    -231.49918  -249.32358
Training/qf1_loss                     1878.37624  746.79916  4291.92676  642.48999
Training/qf2_loss                     1823.94916  736.25924  4184.79590  627.81012
Training/pf_norm                      0.53032     0.12165    1.03167     0.30872
Training/qf1_norm                     1179.25846  648.69627  3648.35889  404.20065
Training/qf2_norm                     1175.57273  652.70725  3619.26562  342.34695
log_std/mean                          -0.44960    0.01724    -0.42524    -0.49259
log_std/std                           0.22320     0.01271    0.24057     0.19528
log_std/max                           0.43133     0.11999    0.68674     0.21509
log_std/min                           -1.43455    0.05245    -1.18807    -1.55258
log_probs/mean                        3.14534     0.18287    3.53161     2.76992
log_probs/std                         3.05651     0.11852    3.42064     2.79538
log_probs/max                         13.42297    1.34329    17.50317    10.93571
log_probs/min                         -7.31236    1.24492    -4.94218    -13.14290
mean/mean                             0.11508     0.07796    0.23805     -0.03776
mean/std                              1.51492     0.02132    1.56382     1.47606
mean/max                              4.04930     0.14149    4.32569     3.65873
mean/min                              -3.22398    0.19060    -2.87640    -3.75037
------------------------------------  ----------  ---------  ----------  ----------
sample: [8, 5, 3, 9, 2, 6, 7, 0, 4, 1]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
train_time 6.092541456222534
2023-10-11 00:25:47,845 MainThread INFO: EPOCH:49
2023-10-11 00:25:47,845 MainThread INFO: Time Consumed:6.101735591888428s
2023-10-11 00:25:47,845 MainThread INFO: Total Frames:75000s
  5%|▌         | 50/1000 [06:54<1:41:07,  6.39s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               383.98325
Train_Epoch_Reward                    4736.67339
Running_Training_Average_Rewards      587.72686
Explore_Time                          0.00336
Train___Time                          6.09254
Eval____Time                          0.00252
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.61556
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.21452
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.02226
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -56.97825
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.72122
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -118.12796
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.91454
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4437.67216
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -95.80898
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.43639
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std        Max         Min
Reward_Mean                           6.84629     1.33775    12.48206    3.75349
alpha_0                               0.72150     0.01046    0.74014     0.70398
alpha_1                               0.08605     0.00031    0.08659     0.08538
alpha_2                               0.11339     0.00181    0.11577     0.11029
alpha_3                               0.09583     0.00191    0.09925     0.09268
alpha_4                               0.09883     0.00085    0.10055     0.09788
alpha_5                               0.10791     0.00299    0.11350     0.10318
alpha_6                               0.18113     0.00387    0.18701     0.17464
alpha_7                               0.08532     0.00028    0.08579     0.08474
alpha_8                               0.12895     0.00137    0.13187     0.12678
alpha_9                               0.08835     0.00065    0.08934     0.08748
Alpha_loss                            -1.81089    0.41475    -0.48603    -2.64946
Training/policy_loss                  -244.20217  3.78415    -233.74759  -254.16182
Training/qf1_loss                     1852.19502  947.40930  6401.21729  586.76233
Training/qf2_loss                     1803.71980  934.97964  6310.54834  562.83710
Training/pf_norm                      0.60560     0.15602    1.16118     0.30469
Training/qf1_norm                     1225.69091  759.25996  5602.95850  305.42679
Training/qf2_norm                     1226.43918  766.70950  5748.85400  301.99695
log_std/mean                          -0.45319    0.01207    -0.43022    -0.48223
log_std/std                           0.25003     0.00746    0.26534     0.23473
log_std/max                           0.78526     0.14695    1.04890     0.43572
log_std/min                           -1.42007    0.05619    -1.18580    -1.49527
log_probs/mean                        3.23533     0.19468    3.84954     2.85565
log_probs/std                         3.20292     0.10745    3.53422     2.97879
log_probs/max                         14.70751    1.09013    17.27324    11.10588
log_probs/min                         -7.33814    1.39005    -4.86148    -12.45979
mean/mean                             0.06223     0.10654    0.21422     -0.09894
mean/std                              1.52279     0.02763    1.59992     1.46273
mean/max                              4.14033     0.16423    4.34112     3.41334
mean/min                              -3.55282    0.32394    -3.02145    -4.19496
------------------------------------  ----------  ---------  ----------  ----------
start to update mask
sample: [7, 0, 1, 4, 6, 9, 5, 2, 3, 8]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
train_time 67.82917928695679
2023-10-11 00:27:04,842 MainThread INFO: EPOCH:50
2023-10-11 00:27:04,842 MainThread INFO: Time Consumed:67.83776831626892s
2023-10-11 00:27:04,843 MainThread INFO: Total Frames:76500s
  5%|▌         | 51/1000 [08:11<7:16:04, 27.57s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               459.97728
Train_Epoch_Reward                    4989.41728
Running_Training_Average_Rewards      553.27054
Explore_Time                          0.00297
Train___Time                          67.82918
Eval____Time                          0.00219
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.64060
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -83.12550
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -15.02207
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.88926
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.28375
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -130.81747
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -71.65865
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4844.07725
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -97.30730
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           355.44012
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           6.70622      1.32021      10.42042     3.33182
alpha_0                               0.73170      0.01389      0.74801      0.70420
alpha_1                               0.08376      0.00190      0.08665      0.08041
alpha_2                               0.10482      0.00338      0.11028      0.09906
alpha_3                               0.09050      0.00141      0.09266      0.08804
alpha_4                               0.09704      0.00282      0.10056      0.09206
alpha_5                               0.09921      0.00247      0.10315      0.09470
alpha_6                               0.16601      0.00545      0.17461      0.15694
alpha_7                               0.08214      0.00185      0.08474      0.07874
alpha_8                               0.12300      0.00324      0.12676      0.11682
alpha_9                               0.08496      0.00176      0.08776      0.08189
Alpha_loss                            -5.67800     1.92968      1.57461      -10.46267
Training/policy_loss                  -94.88401    20.42210     -45.06100    -154.44870
Training/qf1_loss                     10867.89621  9621.28004   75543.98438  2425.93750
Training/qf2_loss                     6647.59280   6004.38964   52702.08594  1113.97144
Training/pf_norm                      6.82681      2.00006      14.41771     2.57815
Training/qf1_norm                     13037.63133  10224.68264  61056.94531  1790.03918
Training/qf2_norm                     8792.67465   7370.13929   52794.76172  2177.94946
log_std/mean                          -0.19134     0.14603      0.08935      -0.52281
log_std/std                           0.26313      0.02939      0.33230      0.18982
log_std/max                           0.73033      0.22731      1.31985      0.23819
log_std/min                           -1.06516     0.28051      -0.47860     -2.18188
log_probs/mean                        1.40890      0.94155      4.64687      -0.92102
log_probs/std                         3.62275      0.54860      5.66803      2.32616
log_probs/max                         17.98734     4.60124      35.26291     8.90969
log_probs/min                         -7.56336     1.03280      -5.50475     -13.34450
mean/mean                             0.23727      0.11683      0.62300      -0.07262
mean/std                              1.33685      0.15492      1.77973      0.85392
mean/max                              4.47297      0.93572      7.19157      2.52948
mean/min                              -3.84726     0.76861      -2.40679     -5.68689
------------------------------------  -----------  -----------  -----------  ----------
sample: [6, 2, 0, 7, 9, 5, 3, 1, 8, 4]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
train_time 5.662307262420654
2023-10-11 00:27:10,583 MainThread INFO: EPOCH:51
2023-10-11 00:27:10,584 MainThread INFO: Time Consumed:5.671798229217529s
2023-10-11 00:27:10,584 MainThread INFO: Total Frames:78000s
  5%|▌         | 52/1000 [08:17<5:32:06, 21.02s/it]  5%|▌         | 52/1000 [08:20<2:32:04,  9.62s/it]
------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               395.52351
Train_Epoch_Reward                    6755.10423
Running_Training_Average_Rewards      549.37316
Explore_Time                          0.00312
Train___Time                          5.66231
Eval____Time                          0.00262
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.12827
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -63.69925
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.20602
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.39146
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.88006
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -124.38925
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -72.34093
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4566.25451
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -97.75194
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.23223
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean        Std         Max          Min
Reward_Mean                           6.61002     1.13891     9.40547      3.87872
alpha_0                               0.66635     0.01547     0.70374      0.65077
alpha_1                               0.07919     0.00098     0.08038      0.07706
alpha_2                               0.09255     0.00337     0.09899      0.08728
alpha_3                               0.08531     0.00115     0.08800      0.08418
alpha_4                               0.09165     0.00112     0.09365      0.09026
alpha_5                               0.08985     0.00242     0.09465      0.08721
alpha_6                               0.14703     0.00451     0.15684      0.14209
alpha_7                               0.07685     0.00097     0.07869      0.07560
alpha_8                               0.11140     0.00212     0.11674      0.10958
alpha_9                               0.08165     0.00066     0.08268      0.08072
Alpha_loss                            -3.78063    3.03403     -0.00275     -8.78655
Training/policy_loss                  -107.79952  10.47916    -82.69587    -121.04337
Training/qf1_loss                     2288.40771  1035.62487  5550.72559   711.25336
Training/qf2_loss                     2862.68696  1671.90417  8035.47119   674.34216
Training/pf_norm                      3.11132     2.23862     8.70205      1.01254
Training/qf1_norm                     1543.08244  1534.59548  7009.13672   264.01669
Training/qf2_norm                     2581.28056  2747.38941  10842.33691  242.43730
log_std/mean                          -0.37925    0.17124     -0.11142     -0.57750
log_std/std                           0.26289     0.03900     0.32347      0.19809
log_std/max                           0.51738     0.18708     0.88664      0.26363
log_std/min                           -1.24571    0.30411     -0.70801     -1.67952
log_probs/mean                        2.14315     1.46113     3.94124      -0.32853
log_probs/std                         4.15130     0.47286     4.88526      3.12177
log_probs/max                         22.26253    3.36697     28.47823     15.63927
log_probs/min                         -7.24989    1.13599     -5.09938     -11.73730
mean/mean                             0.08599     0.04356     0.18386      0.00304
mean/std                              1.39665     0.19026     1.62172      1.02794
mean/max                              4.12043     0.62631     5.05773      2.95878
mean/min                              -4.81324    0.41279     -4.06270     -5.38947
------------------------------------  ----------  ----------  -----------  ----------
sample: [0, 6, 4, 9, 1, 3, 8, 7, 5, 2]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
wandb: Waiting for W&B process to finish... (failed 255).
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
wandb: 
wandb: Run history:
wandb:                                    0 ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    4 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁███▁▁▁▁▁▁▁▁▁██████
wandb:                                    6 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    7 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    8 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                                    9 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                           Alpha_loss ██▇▇▇▆▆▅▅▅▄▃▃▂▂▂▂▂▂▁▅▄▄▅▅▅▆▆▅▆▇▆▇▆▆▅▇▇▇▆
wandb:                         Eval____Time ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Explore_Time ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                      Policy_sim_loss ▁█
wandb:                          Q1_sim_loss ▁█
wandb:                          Q2_sim_loss ▁█
wandb:                          Reward_Mean █▆▆▄▃▃▃▂▄▂▂▄▁▂▂▂▁▃▃▂▄▃▃▅▂▃▁▃▂▂▂▁▂▁▃▁▂▂▂▂
wandb:              Running_Average_Rewards ▃▃▃▂▁▁▃█▃▁▂▃▃▁▄▃▂▂▃▃▃▂▄▃▂▃▃▂▂▂▃▂▂▃▂▂▂▂▂▂
wandb:     Running_Training_Average_Rewards █▆▆▄▃▂▁▂▅▄▂▂▂▃▂▂▃▄▄▅▃▃▃▄▄▃▃▄▃▃▃▃▃▂▂▂▂▂▂▂
wandb:                   Train_Epoch_Reward ▇▃▅▃▁▁▁▃▇▃▁▃▃▂▁▅▃█▂▃▃▃▂▄▃▂▄▃▃▃▃▃▂▂▃▂▂▂▂▂
wandb:                         Train___Time █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                     Training/pf_norm ▁▁▂▂▂▂▂▃▄▂▂▂▄▂▂▃▂▃▂▂█▄▃▃▃▂▃▄▃▄▃▃▃▃▃▅▄▄▄▆
wandb:                 Training/policy_loss ███▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▄▄▄▃▃▃▃▃▃▂▂▂▂▁▂▁▁▁▁▅
wandb:                    Training/qf1_loss ▆▄▃▂▂▂▁▁▂▁▂▃▂▂▁▂▄▂▄▂█▇▄▆▃▄▂▇▃▃▃▂▃▂▅▂▄▃▃▃
wandb:                    Training/qf1_norm ▁▂▃▃▁▂▂▂▃▁▁▆▂▂▂▃▃▃▃▃▄▃▄▇▂▄▄▅▂▂▂▄▂▃█▂▂▃█▂
wandb:                    Training/qf2_loss ▆▄▃▂▂▂▁▁▂▁▂▃▂▂▁▂▄▂▄▂█▇▄▆▃▄▂▇▃▃▃▂▃▂▄▂▄▃▃▃
wandb:                    Training/qf2_norm ▁▂▃▃▂▂▂▂▃▁▁▆▂▂▂▃▃▃▃▃▄▃▃▇▂▄▄▅▃▂▂▅▂▃█▂▂▃█▂
wandb:                              alpha_0 █▇▇▇▆▅▅▄▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▅
wandb:                              alpha_1 ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_2 ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_3 ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:                              alpha_4 ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_5 ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_6 ██▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▁▁▁▁
wandb:                              alpha_7 ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_8 ██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                              alpha_9 ██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: button-press-topdown-v1_eval_rewards ▇▆▇▇▅▁█▅▃▃▃▆▅▇█▆▄▇▃▂▂▄▃▃▄▅▄▄▄▄▄▂▃▅▂▄▄▄▃▄
wandb: button-press-topdown-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 door-v1_eval_rewards ████▇▁▇▆▅▅▄█▄▄█▄▃▃▃▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▅
wandb:                 door-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         drawer-close-v1_eval_rewards ▇▇▇▆▃▇▇▇▇█▅██▇▅▄▅▇▃▂▅▁▇▇▇▂▁▂▂▂▁▁▁▁▇▇▇▇▇▇
wandb:         drawer-close-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁███▁▁▁▁▁▁▁▁▁██████
wandb:          drawer-open-v1_eval_rewards ▁▁▁▁▁▁█▁▁▁▁▁▁▇███▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          drawer-open-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                        log_probs/max ▁▁▂▂▃▂▂▃▃▃▂▂▃▃▃▃▃▄▄▄▃▃▃▃▄▄▄▄▄▄▅▅▄▄▄▄▅▅▅█
wandb:                       log_probs/mean ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▆▅▅▆▆▇▇▇▆▇█▇█▇▇▇███▇
wandb:                        log_probs/min █▆▆▆▄▇▄▅▇▇▇▄▆▄▇▆▆▇▄▇▅▁▃▅▇▆▆▇▆█▅▅▅▅▃▄▆▇▃▇
wandb:                        log_probs/std ▁▁▃▃▃▂▂▄▄▄▃▃▃▃▃▃▅▅▆▅▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:                          log_std/max ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▃▂▂▂▂▂▂▃▄▅▃▃▄▅▄▅█▅
wandb:                         log_std/mean ██▇▇▇▇▇▆▆▆▇▇▇▇▇▇▆▆▆▇▁▃▄▄▃▃▃▄▄▃▃▃▃▄▄▄▃▄▄▃
wandb:                          log_std/min ██▇▇▆▆▆▅▆▆▆▆▆▅▅▅▆▅▅▅▃▁▂▃▄▄▄▄▄▄▃▃▃▂▂▂▁▂▂▁
wandb:                          log_std/std ▁▁▂▂▃▃▃▄▃▃▃▃▃▃▃▃▄▄▄▄▅▆▆▅▄▄▄▄▄▄▅▅▄▄▅▆▅▆▆█
wandb:                             mean/max ▁▁▃▃▃▃▄▅▅▄▃▃▃▄▅▄▅▅▅▅▅▄▅▅▅▅▅▅▅▆▆▆▆▆▇▆████
wandb:                            mean/mean ▄▅▆▅▇▇▆▃▅▂▁▅▃▆▇▅▅▇▅▅▇▅▅▇▆█▅▇▄▅▅██▆▅▆▇▇▇▆
wandb:                             mean/min ██▆▆▆▇▇▆▆▅▅▅▅▇▇▆▅▅▄▅▅▅▅▄▄▄▄▄▄▃▃▃▄▃▃▄▃▃▂▁
wandb:                             mean/std ▁▂▃▄▄▃▃▄▄▄▃▃▃▃▃▃▄▄▅▄▆▆▆▇▇▇▇▇▇▇█████▇████
wandb:                    mean_success_rate ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁▁███▁▁▁▁▁▁▁▁▁██████
wandb:      ped-insert-side-v1_eval_rewards ███▆▃▆▄▂▃▄▄▆▇█▅▅▄▃▄▄▅▁▁▁▁▁▁▁▁▁▂▂▂▃▃▁▂▃▄▃
wandb:      ped-insert-side-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           pick-place-v1_eval_rewards ███▆▅▂▃▆▄▅▄▅▆▆▅▄▄▅▃▅▅▂▂▄▃▁▁▁▂▁▂▂▂▂▂▂▂▂▁▁
wandb:           pick-place-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 push-v1_eval_rewards ██▇▆▂▆▅▅▄█▃▆▆▇▇▅▆█▅▇▆▂▂▂▁▁▁▂▃▂▂▂▃▄▆▃▅▃▃▃
wandb:                 push-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                reach-v1_eval_rewards ▃▃▃▂▁▁▂█▃▁▂▃▃▁▄▂▁▂▃▃▃▂▄▃▂▃▂▂▃▂▃▂▂▃▂▂▂▂▂▂
wandb:                reach-v1_success_rate ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    save_traj_mod_sum ▁▁▁▁▁▁▁▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█
wandb:                   task_policy_mask_0 ▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃███████████████████▁
wandb:                   task_policy_mask_1 ▁███████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁
wandb:                   task_policy_mask_2 █▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅
wandb:                   task_policy_mask_3 ▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:                   task_policy_mask_4 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█
wandb:                   task_policy_mask_5 ▅███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃
wandb:                   task_policy_mask_6 ▆▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂███████████████████▁
wandb:                   task_policy_mask_7 ▃███████████████████▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁
wandb:                   task_policy_mask_8 ▅███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   task_policy_mask_9 ▅███████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄
wandb:         window-close-v1_eval_rewards ▇▇▇▇▅▅█▅▄▅▂▆▄▅▆▃▃▄▄▃▄▃▄▅▅▅▅▅▄▂▃▃▂▂▂▂▂▂▁▁
wandb:         window-close-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          window-open-v1_eval_rewards ▁▁▁▁▁▁▄▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          window-open-v1_success_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                    0 0.0
wandb:                                    1 0.0
wandb:                                    2 0.0
wandb:                                    3 0.0
wandb:                                    4 0.0
wandb:                                    5 1.0
wandb:                                    6 0.0
wandb:                                    7 0.0
wandb:                                    8 0.0
wandb:                                    9 0.0
wandb:                           Alpha_loss -2.01608
wandb:                         Eval____Time 0.00262
wandb:                         Explore_Time 0.00312
wandb:                      Policy_sim_loss 3.19814
wandb:                          Q1_sim_loss 3.20782
wandb:                          Q2_sim_loss 3.19624
wandb:                          Reward_Mean 6.34454
wandb:              Running_Average_Rewards 395.52351
wandb:     Running_Training_Average_Rewards 549.37316
wandb:                   Train_Epoch_Reward 6755.10423
wandb:                         Train___Time 5.66231
wandb:                     Training/pf_norm 1.01254
wandb:                 Training/policy_loss -118.94285
wandb:                    Training/qf1_loss 1897.10522
wandb:                    Training/qf1_norm 387.23444
wandb:                    Training/qf2_loss 1834.85901
wandb:                    Training/qf2_norm 382.27817
wandb:                              alpha_0 0.65077
wandb:                              alpha_1 0.07706
wandb:                              alpha_2 0.08728
wandb:                              alpha_3 0.08524
wandb:                              alpha_4 0.09365
wandb:                              alpha_5 0.08721
wandb:                              alpha_6 0.14209
wandb:                              alpha_7 0.07839
wandb:                              alpha_8 0.10999
wandb:                              alpha_9 0.08171
wandb: button-press-topdown-v1_eval_rewards -67.12827
wandb: button-press-topdown-v1_success_rate 0.0
wandb:                 door-v1_eval_rewards -63.69925
wandb:                 door-v1_success_rate 0.0
wandb:         drawer-close-v1_eval_rewards -19.20602
wandb:         drawer-close-v1_success_rate 1.0
wandb:          drawer-open-v1_eval_rewards -68.39146
wandb:          drawer-open-v1_success_rate 0.0
wandb:                        log_probs/max 25.59635
wandb:                       log_probs/mean 3.14027
wandb:                        log_probs/min -5.50837
wandb:                        log_probs/std 4.0984
wandb:                          log_std/max 0.44543
wandb:                         log_std/mean -0.52888
wandb:                          log_std/min -1.47574
wandb:                          log_std/std 0.32286
wandb:                             mean/max 4.15475
wandb:                            mean/mean 0.10956
wandb:                             mean/min -4.27516
wandb:                             mean/std 1.49389
wandb:                    mean_success_rate 0.1
wandb:      ped-insert-side-v1_eval_rewards -74.88006
wandb:      ped-insert-side-v1_success_rate 0.0
wandb:           pick-place-v1_eval_rewards -124.38925
wandb:           pick-place-v1_success_rate 0.0
wandb:                 push-v1_eval_rewards -72.34093
wandb:                 push-v1_success_rate 0.0
wandb:                reach-v1_eval_rewards 4566.25451
wandb:                reach-v1_success_rate 0.0
wandb:                    save_traj_mod_sum 3
wandb:                   task_policy_mask_0 230
wandb:                   task_policy_mask_1 282
wandb:                   task_policy_mask_2 301
wandb:                   task_policy_mask_3 310
wandb:                   task_policy_mask_4 384
wandb:                   task_policy_mask_5 314
wandb:                   task_policy_mask_6 261
wandb:                   task_policy_mask_7 280
wandb:                   task_policy_mask_8 306
wandb:                   task_policy_mask_9 308
wandb:         window-close-v1_eval_rewards -97.75194
wandb:         window-close-v1_success_rate 0.0
wandb:          window-open-v1_eval_rewards -23.23223
wandb:          window-open-v1_success_rate 0.0
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/wandb/offline-run-20231011_001847-hqfnftvz
wandb: Find logs at: ./wandb/offline-run-20231011_001847-hqfnftvz/logs
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 327, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 322, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/algo/rl_algo.py", line 427, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer, epoch,self.use_trajectory_info)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/algo/off_policy/must_sac.py", line 413, in update_per_epoch
    batch = self.replay_buffer.random_batch(self.batch_size,
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/DST_RL/./torchrl/replay_buffers/shared/base.py", line 90, in random_batch
    random_list.append(np.random.randint(0, self._size[i], batch_size))
  File "mtrand.pyx", line 765, in numpy.random.mtrand.RandomState.randint
  File "_bounded_integers.pyx", line 1228, in numpy.random._bounded_integers._rand_int64
  File "<__array_function__ internals>", line 179, in prod
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/sentry_sdk/worker.py", line 95, in flush
    self._wait_flush(timeout, callback)
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
    if not self._timed_queue_join(timeout - initial_timeout):
  File "/lustre04/scratch/qianxi/sparse_training/sep_t3s/venv/lib/python3.8/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    queue.all_tasks_done.wait(timeout=delay)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/threading.py", line 306, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 691, in _finalize_manager
    process.join(timeout=1.0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.8.10/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
