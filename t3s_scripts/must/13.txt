W&B disabled.
2023-11-22 12:18:59,530 MainThread INFO: Experiment Name:testing_must_mtsac
2023-11-22 12:18:59,530 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      40,
      40,
      40
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      20,
      20,
      20
    ]
  },
  "traj_encoder": {
    "latent_size": 256
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "generator": {
    "one_hot_mlp_hidden": 256,
    "generator_mlp_hidden": 256,
    "one_hot_result_dim": 64
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 20,
    "num_epochs": 1000,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "generator_lr": 0.0001,
    "batch_size": 1280,
    "min_pool": 10000,
    "success_traj_update_only": true,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 5,
    "update_end_epoch": 1000,
    "mask_update_interval": 25,
    "eval_episodes": 3,
    "recent_traj_window": 10,
    "sl_optim_times": 5,
    "use_trajectory_info": 0,
    "use_sl_loss": 0
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/home/qianxi/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
2023-11-22 12:20:35,080 MainThread INFO: EPOCH:0
2023-11-22 12:20:35,080 MainThread INFO: Time Consumed:0.003702402114868164s
2023-11-22 12:20:35,080 MainThread INFO: Total Frames:1500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                19836.19240
Running_Training_Average_Rewards  1983.61924

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
2023-11-22 12:20:35,086 MainThread INFO: EPOCH:1
2023-11-22 12:20:35,086 MainThread INFO: Time Consumed:0.0030815601348876953s
2023-11-22 12:20:35,086 MainThread INFO: Total Frames:3000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                6207.51196
Running_Training_Average_Rewards  1302.18522

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
2023-11-22 12:20:35,382 MainThread INFO: EPOCH:2
2023-11-22 12:20:35,383 MainThread INFO: Time Consumed:0.2955780029296875s
2023-11-22 12:20:35,383 MainThread INFO: Total Frames:4500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                19009.01141
Running_Training_Average_Rewards  1501.75719

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
2023-11-22 12:20:35,644 MainThread INFO: EPOCH:3
2023-11-22 12:20:35,644 MainThread INFO: Time Consumed:0.26024508476257324s
2023-11-22 12:20:35,644 MainThread INFO: Total Frames:6000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                7759.47490
Running_Training_Average_Rewards  1099.19994

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
2023-11-22 12:20:35,927 MainThread INFO: EPOCH:4
2023-11-22 12:20:35,927 MainThread INFO: Time Consumed:0.28189539909362793s
2023-11-22 12:20:35,927 MainThread INFO: Total Frames:7500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                11057.03628
Running_Training_Average_Rewards  1260.85075

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
2023-11-22 12:20:36,205 MainThread INFO: EPOCH:5
2023-11-22 12:20:36,206 MainThread INFO: Time Consumed:0.27683281898498535s
2023-11-22 12:20:36,206 MainThread INFO: Total Frames:9000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                3879.53599
Running_Training_Average_Rewards  756.53491

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
2023-11-22 12:20:36,533 MainThread INFO: EPOCH:6
2023-11-22 12:20:36,533 MainThread INFO: Time Consumed:0.3256843090057373s
2023-11-22 12:20:36,533 MainThread INFO: Total Frames:10500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                6623.82865
Running_Training_Average_Rewards  718.68003

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
2023-11-22 12:20:36,836 MainThread INFO: EPOCH:7
2023-11-22 12:20:36,836 MainThread INFO: Time Consumed:0.30211687088012695s
2023-11-22 12:20:36,836 MainThread INFO: Total Frames:12000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                10454.73199
Running_Training_Average_Rewards  698.60322

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
2023-11-22 12:20:37,172 MainThread INFO: EPOCH:8
2023-11-22 12:20:37,173 MainThread INFO: Time Consumed:0.33518433570861816s
2023-11-22 12:20:37,173 MainThread INFO: Total Frames:13500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                1645.22039
Running_Training_Average_Rewards  624.12603

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
2023-11-22 12:20:37,497 MainThread INFO: EPOCH:9
2023-11-22 12:20:37,497 MainThread INFO: Time Consumed:0.3234395980834961s
2023-11-22 12:20:37,497 MainThread INFO: Total Frames:15000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                11405.92089
Running_Training_Average_Rewards  783.52911

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
2023-11-22 12:20:37,850 MainThread INFO: EPOCH:10
2023-11-22 12:20:37,850 MainThread INFO: Time Consumed:0.35132718086242676s
2023-11-22 12:20:37,850 MainThread INFO: Total Frames:16500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                5359.60119
Running_Training_Average_Rewards  613.69142

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
2023-11-22 12:20:38,199 MainThread INFO: EPOCH:11
2023-11-22 12:20:38,199 MainThread INFO: Time Consumed:0.34773945808410645s
2023-11-22 12:20:38,199 MainThread INFO: Total Frames:18000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                15013.30460
Running_Training_Average_Rewards  1059.29422

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
2023-11-22 12:20:38,546 MainThread INFO: EPOCH:12
2023-11-22 12:20:38,546 MainThread INFO: Time Consumed:0.34569239616394043s
2023-11-22 12:20:38,546 MainThread INFO: Total Frames:19500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                15940.33105
Running_Training_Average_Rewards  1210.44123

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
2023-11-22 12:20:38,878 MainThread INFO: EPOCH:13
2023-11-22 12:20:38,878 MainThread INFO: Time Consumed:0.33086681365966797s
2023-11-22 12:20:38,878 MainThread INFO: Total Frames:21000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                7036.98875
Running_Training_Average_Rewards  1266.35415

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
2023-11-22 12:20:39,237 MainThread INFO: EPOCH:14
2023-11-22 12:20:39,237 MainThread INFO: Time Consumed:0.3577878475189209s
2023-11-22 12:20:39,237 MainThread INFO: Total Frames:22500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                1660.60141
Running_Training_Average_Rewards  821.26404

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
2023-11-22 12:20:39,594 MainThread INFO: EPOCH:15
2023-11-22 12:20:39,594 MainThread INFO: Time Consumed:0.35604095458984375s
2023-11-22 12:20:39,594 MainThread INFO: Total Frames:24000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                22689.97032
Running_Training_Average_Rewards  1046.25202

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
2023-11-22 12:20:39,969 MainThread INFO: EPOCH:16
2023-11-22 12:20:39,969 MainThread INFO: Time Consumed:0.37425875663757324s
2023-11-22 12:20:39,969 MainThread INFO: Total Frames:25500s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                4190.54251
Running_Training_Average_Rewards  951.37047

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
2023-11-22 12:20:40,794 MainThread INFO: EPOCH:17
2023-11-22 12:20:40,794 MainThread INFO: Time Consumed:0.8237767219543457s
2023-11-22 12:20:40,794 MainThread INFO: Total Frames:27000s
--------------------------------  ----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                2286.45255
Running_Training_Average_Rewards  972.23218

Name                              Mean        Std  Max  Min
--------------------------------  ----------  ---  ---  ---
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
2023-11-22 12:20:41,327 MainThread INFO: EPOCH:18
2023-11-22 12:20:41,328 MainThread INFO: Time Consumed:0.5324697494506836s
2023-11-22 12:20:41,328 MainThread INFO: Total Frames:28500s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                14492.84900
Running_Training_Average_Rewards  698.99480

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
2023-11-22 12:20:42,158 MainThread INFO: EPOCH:19
2023-11-22 12:20:42,159 MainThread INFO: Time Consumed:0.8295905590057373s
2023-11-22 12:20:42,159 MainThread INFO: Total Frames:30000s
--------------------------------  -----------  ---  ---  ---
Name                              Value
Train_Epoch_Reward                11316.32934
Running_Training_Average_Rewards  936.52103

Name                              Mean         Std  Max  Min
--------------------------------  -----------  ---  ---  ---
2023-11-22 12:20:42,160 MainThread INFO: Finished Pretrain
  0%|          | 0/1000 [00:00<?, ?it/s]sample: [2, 8, 9, 4, 6, 7, 0, 1, 5, 3]
replay_buffer._size: [3175 3173 3170 3169 3175 3174 3174 3165 3172 3167]
train_time 4.522349834442139
snapshot at best
2023-11-22 12:20:50,015 MainThread INFO: EPOCH:0
2023-11-22 12:20:50,015 MainThread INFO: Time Consumed:7.094965934753418s
2023-11-22 12:20:50,015 MainThread INFO: Total Frames:31500s
/scratch/qianxi/DST/DST_RL/./torchrl/algo/rl_algo.py:351: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/1000 [00:10<2:52:32, 10.36s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1167.89798
Train_Epoch_Reward                    9545.35851
Running_Training_Average_Rewards      1178.48456
Explore_Time                          0.00220
Train___Time                          4.52235
Eval____Time                          0.00522
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.49553
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.53754
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.66115
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.43620
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24477
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.87245
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07229
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11928.74657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.75771
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.68909
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.11264      0.19829   7.48384    6.94504
alpha_0                               0.99910      0.00042   0.99970    0.99850
alpha_1                               0.99910      0.00042   0.99970    0.99850
alpha_2                               0.99910      0.00042   0.99970    0.99850
alpha_3                               0.99910      0.00042   0.99970    0.99850
alpha_4                               0.99910      0.00042   0.99970    0.99850
alpha_5                               0.99910      0.00042   0.99970    0.99850
alpha_6                               0.99910      0.00042   0.99970    0.99850
alpha_7                               0.99910      0.00042   0.99970    0.99850
alpha_8                               0.99910      0.00042   0.99970    0.99850
alpha_9                               0.99910      0.00042   0.99970    0.99850
Alpha_loss                            -0.00401     0.00283   -0.00000   -0.00802
Training/policy_loss                  -2.67727     0.00882   -2.66289   -2.69050
Training/qf1_loss                     879.73005    57.73362  975.56366  798.58832
Training/qf2_loss                     879.72349    57.73301  975.55725  798.58685
Training/pf_norm                      0.25374      0.01297   0.26696    0.23804
Training/qf1_norm                     6.80696      0.71983   7.89504    5.96760
Training/qf2_norm                     6.72592      0.45907   7.24078    6.05915
log_std/mean                          -0.00147     0.00088   -0.00013   -0.00254
log_std/std                           0.00102      0.00020   0.00132    0.00072
log_std/max                           0.00021      0.00052   0.00091    -0.00038
log_std/min                           -0.00454     0.00124   -0.00288   -0.00660
log_probs/mean                        -2.67966     0.00904   -2.66446   -2.69258
log_probs/std                         0.42706      0.00635   0.43895    0.42001
log_probs/max                         -1.22384     0.07994   -1.15748   -1.37983
log_probs/min                         -4.02668     0.04627   -3.96963   -4.09151
mean/mean                             0.00032      0.00004   0.00036    0.00027
mean/std                              0.00167      0.00013   0.00183    0.00146
mean/max                              0.00376      0.00057   0.00484    0.00316
mean/min                              -0.00261     0.00044   -0.00212   -0.00333
------------------------------------  -----------  --------  ---------  ---------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/13/model
sample: [4, 9, 3, 8, 6, 0, 2, 7, 5, 1]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
train_time 0.5552678108215332
snapshot at best
2023-11-22 12:20:53,836 MainThread INFO: EPOCH:1
2023-11-22 12:20:53,836 MainThread INFO: Time Consumed:1.2525501251220703s
2023-11-22 12:20:53,836 MainThread INFO: Total Frames:33000s
  0%|          | 2/1000 [00:11<1:24:19,  5.07s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1168.54132
Train_Epoch_Reward                    14735.19792
Running_Training_Average_Rewards      1186.56286
Explore_Time                          0.00410
Train___Time                          0.55527
Eval____Time                          0.00299
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.06215
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.53754
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.66115
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.43620
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24477
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.87245
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07229
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11928.74657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.75771
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.68909
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.83196      0.40117   7.42375    6.17337
alpha_0                               0.99760      0.00042   0.99820    0.99700
alpha_1                               0.99760      0.00042   0.99820    0.99701
alpha_2                               0.99760      0.00042   0.99820    0.99700
alpha_3                               0.99760      0.00042   0.99820    0.99700
alpha_4                               0.99760      0.00042   0.99820    0.99700
alpha_5                               0.99760      0.00042   0.99820    0.99700
alpha_6                               0.99760      0.00042   0.99820    0.99700
alpha_7                               0.99760      0.00042   0.99820    0.99701
alpha_8                               0.99760      0.00042   0.99820    0.99700
alpha_9                               0.99760      0.00042   0.99820    0.99700
Alpha_loss                            -0.01404     0.00284   -0.01004   -0.01804
Training/policy_loss                  -2.68099     0.01413   -2.65698   -2.69835
Training/qf1_loss                     790.82557    80.29677  921.21552  673.54816
Training/qf2_loss                     790.82284    80.29524  921.21027  673.54773
Training/pf_norm                      0.26036      0.02114   0.28672    0.23079
Training/qf1_norm                     7.40216      0.33273   7.88837    6.86398
Training/qf2_norm                     6.06361      0.24241   6.42228    5.66588
log_std/mean                          -0.00441     0.00090   -0.00315   -0.00569
log_std/std                           0.00166      0.00018   0.00192    0.00142
log_std/max                           -0.00138     0.00048   -0.00071   -0.00207
log_std/min                           -0.00908     0.00119   -0.00743   -0.01079
log_probs/mean                        -2.68536     0.01426   -2.66087   -2.70319
log_probs/std                         0.42780      0.00652   0.43680    0.41690
log_probs/max                         -1.30364     0.02230   -1.27435   -1.32500
log_probs/min                         -4.49458     0.44514   -3.92001   -4.98122
mean/mean                             0.00043      0.00004   0.00047    0.00037
mean/std                              0.00193      0.00004   0.00198    0.00186
mean/max                              0.00533      0.00022   0.00559    0.00493
mean/min                              -0.00234     0.00005   -0.00228   -0.00241
------------------------------------  -----------  --------  ---------  ---------
sample: [0, 6, 4, 5, 1, 8, 7, 9, 2, 3]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
train_time 0.5752239227294922
snapshot at best
2023-11-22 12:20:55,744 MainThread INFO: EPOCH:2
2023-11-22 12:20:55,745 MainThread INFO: Time Consumed:1.771669626235962s
2023-11-22 12:20:55,745 MainThread INFO: Total Frames:34500s
  0%|          | 3/1000 [00:13<1:00:15,  3.63s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1177.42020
Train_Epoch_Reward                    15914.83574
Running_Training_Average_Rewards      1339.84641
Explore_Time                          0.00261
Train___Time                          0.57522
Eval____Time                          0.00348
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.04476
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.36094
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.73277
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.28848
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.10831
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.97776
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.07037
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12021.88933
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.76786
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.33607
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           7.29161      0.33756   7.66551    6.72494
alpha_0                               0.99611      0.00042   0.99671    0.99551
alpha_1                               0.99611      0.00042   0.99671    0.99551
alpha_2                               0.99611      0.00042   0.99670    0.99551
alpha_3                               0.99611      0.00042   0.99670    0.99551
alpha_4                               0.99611      0.00042   0.99670    0.99551
alpha_5                               0.99611      0.00042   0.99670    0.99551
alpha_6                               0.99611      0.00042   0.99671    0.99551
alpha_7                               0.99611      0.00042   0.99671    0.99551
alpha_8                               0.99611      0.00042   0.99671    0.99551
alpha_9                               0.99611      0.00042   0.99671    0.99551
Alpha_loss                            -0.02406     0.00285   -0.02009   -0.02809
Training/policy_loss                  -2.67496     0.01361   -2.65049   -2.68967
Training/qf1_loss                     949.04333    55.72860  985.71240  839.85291
Training/qf2_loss                     949.04772    55.73041  985.72021  839.85382
Training/pf_norm                      0.25764      0.02894   0.31318    0.23493
Training/qf1_norm                     8.02590      0.36490   8.46022    7.38930
Training/qf2_norm                     6.61562      0.31605   7.00518    6.06019
log_std/mean                          -0.00773     0.00098   -0.00635   -0.00913
log_std/std                           0.00237      0.00022   0.00269    0.00206
log_std/max                           -0.00322     0.00056   -0.00244   -0.00402
log_std/min                           -0.01356     0.00134   -0.01168   -0.01547
log_probs/mean                        -2.68137     0.01374   -2.65642   -2.69533
log_probs/std                         0.41577      0.00910   0.42559    0.39886
log_probs/max                         -1.38632     0.14606   -1.25525   -1.66411
log_probs/min                         -4.13017     0.48824   -3.61710   -5.00445
mean/mean                             0.00049      0.00008   0.00064    0.00041
mean/std                              0.00200      0.00002   0.00202    0.00198
mean/max                              0.00560      0.00011   0.00574    0.00546
mean/min                              -0.00214     0.00008   -0.00202   -0.00223
------------------------------------  -----------  --------  ---------  ---------
sample: [3, 2, 4, 5, 7, 8, 0, 6, 9, 1]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
train_time 0.5871779918670654
snapshot at best
2023-11-22 12:20:57,534 MainThread INFO: EPOCH:3
2023-11-22 12:20:57,535 MainThread INFO: Time Consumed:1.6765143871307373s
2023-11-22 12:20:57,535 MainThread INFO: Total Frames:36000s
  0%|          | 4/1000 [00:15<48:11,  2.90s/it]  ------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1185.53664
Train_Epoch_Reward                    3929.49937
Running_Training_Average_Rewards      1152.65110
Explore_Time                          0.00278
Train___Time                          0.58718
Eval____Time                          0.00282
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.36568
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.32423
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.77854
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.28302
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.15754
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.00262
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.10291
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12102.45630
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.75379
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.32162
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.54027      0.22093   7.82463     7.23305
alpha_0                               0.99462      0.00042   0.99521     0.99402
alpha_1                               0.99461      0.00042   0.99521     0.99402
alpha_2                               0.99461      0.00042   0.99521     0.99401
alpha_3                               0.99461      0.00042   0.99521     0.99402
alpha_4                               0.99461      0.00042   0.99521     0.99402
alpha_5                               0.99461      0.00042   0.99521     0.99402
alpha_6                               0.99462      0.00042   0.99521     0.99402
alpha_7                               0.99462      0.00042   0.99521     0.99402
alpha_8                               0.99462      0.00042   0.99521     0.99402
alpha_9                               0.99462      0.00042   0.99521     0.99402
Alpha_loss                            -0.03407     0.00283   -0.03002    -0.03802
Training/policy_loss                  -2.67199     0.01163   -2.66009    -2.68621
Training/qf1_loss                     1043.65210   57.03040  1101.88867  944.23535
Training/qf2_loss                     1043.66396   57.02992  1101.89856  944.24768
Training/pf_norm                      0.25237      0.01469   0.27034     0.22698
Training/qf1_norm                     8.61434      0.12421   8.74650     8.39122
Training/qf2_norm                     7.22684      0.07456   7.31302     7.09290
log_std/mean                          -0.01137     0.00108   -0.00986    -0.01290
log_std/std                           0.00318      0.00023   0.00351     0.00285
log_std/max                           -0.00533     0.00064   -0.00444    -0.00624
log_std/min                           -0.01854     0.00146   -0.01649    -0.02062
log_probs/mean                        -2.68029     0.01167   -2.66902    -2.69496
log_probs/std                         0.41357      0.00093   0.41473     0.41224
log_probs/max                         -1.40965     0.04084   -1.35343    -1.47193
log_probs/min                         -3.86750     0.29291   -3.59605    -4.35618
mean/mean                             0.00083      0.00007   0.00089     0.00072
mean/std                              0.00220      0.00010   0.00233     0.00205
mean/max                              0.00607      0.00019   0.00633     0.00583
mean/min                              -0.00305     0.00040   -0.00247    -0.00358
------------------------------------  -----------  --------  ----------  ---------
sample: [0, 3, 7, 2, 5, 1, 4, 6, 9, 8]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
train_time 0.5928730964660645
snapshot at best
2023-11-22 12:20:58,794 MainThread INFO: EPOCH:4
2023-11-22 12:20:58,794 MainThread INFO: Time Consumed:1.1377990245819092s
2023-11-22 12:20:58,794 MainThread INFO: Total Frames:37500s
  0%|          | 5/1000 [00:16<38:19,  2.31s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1193.12283
Train_Epoch_Reward                    33002.48297
Running_Training_Average_Rewards      1761.56060
Explore_Time                          0.00359
Train___Time                          0.59287
Eval____Time                          0.00374
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.05569
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.33949
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.87232
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.39348
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21394
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.07460
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20480
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12181.53815
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.78168
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.37381
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.21024      0.66307    8.02747     6.53820
alpha_0                               0.99313      0.00042    0.99372     0.99253
alpha_1                               0.99312      0.00042    0.99372     0.99253
alpha_2                               0.99312      0.00042    0.99372     0.99252
alpha_3                               0.99312      0.00042    0.99372     0.99253
alpha_4                               0.99312      0.00042    0.99372     0.99253
alpha_5                               0.99312      0.00042    0.99372     0.99253
alpha_6                               0.99312      0.00042    0.99372     0.99253
alpha_7                               0.99313      0.00042    0.99372     0.99253
alpha_8                               0.99312      0.00042    0.99372     0.99253
alpha_9                               0.99313      0.00042    0.99372     0.99253
Alpha_loss                            -0.04414     0.00282    -0.04018    -0.04809
Training/policy_loss                  -2.67829     0.00831    -2.66821    -2.68911
Training/qf1_loss                     932.93109    138.80665  1129.50708  792.57410
Training/qf2_loss                     932.95039    138.80925  1129.52808  792.59283
Training/pf_norm                      0.23717      0.02614    0.26679     0.19839
Training/qf1_norm                     8.73033      0.75066    9.76603     7.90901
Training/qf2_norm                     7.40089      0.66930    8.34057     6.67098
log_std/mean                          -0.01536     0.00118    -0.01370    -0.01705
log_std/std                           0.00403      0.00025    0.00439     0.00368
log_std/max                           -0.00775     0.00074    -0.00672    -0.00881
log_std/min                           -0.02405     0.00166    -0.02174    -0.02644
log_probs/mean                        -2.68830     0.00823    -2.67874    -2.69952
log_probs/std                         0.40446      0.00512    0.41172     0.39770
log_probs/max                         -1.32942     0.04736    -1.24646    -1.38558
log_probs/min                         -4.13016     0.44584    -3.56724    -4.89976
mean/mean                             0.00077      0.00004    0.00083     0.00072
mean/std                              0.00241      0.00003    0.00244     0.00236
mean/max                              0.00635      0.00005    0.00642     0.00626
mean/min                              -0.00410     0.00017    -0.00385    -0.00437
------------------------------------  -----------  ---------  ----------  ---------
sample: [4, 5, 7, 9, 6, 1, 2, 3, 0, 8]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
train_time 0.7575359344482422
snapshot at best
2023-11-22 12:21:00,686 MainThread INFO: EPOCH:5
2023-11-22 12:21:00,686 MainThread INFO: Time Consumed:1.4457063674926758s
2023-11-22 12:21:00,686 MainThread INFO: Total Frames:39000s
  1%|          | 6/1000 [00:18<35:51,  2.16s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1206.18994
Train_Epoch_Reward                    19170.37574
Running_Training_Average_Rewards      1870.07860
Explore_Time                          0.00388
Train___Time                          0.75754
Eval____Time                          0.10187
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.04617
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.38871
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.96028
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.48272
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.24228
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13903
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.29558
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12314.65719
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.85050
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.35253
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.37153      0.35623    7.94395     6.99186
alpha_0                               0.99164      0.00042    0.99223     0.99104
alpha_1                               0.99163      0.00042    0.99223     0.99104
alpha_2                               0.99163      0.00042    0.99222     0.99103
alpha_3                               0.99163      0.00042    0.99223     0.99104
alpha_4                               0.99163      0.00042    0.99223     0.99104
alpha_5                               0.99164      0.00042    0.99223     0.99104
alpha_6                               0.99163      0.00042    0.99223     0.99104
alpha_7                               0.99164      0.00042    0.99223     0.99104
alpha_8                               0.99164      0.00042    0.99223     0.99104
alpha_9                               0.99164      0.00042    0.99223     0.99104
Alpha_loss                            -0.05425     0.00288    -0.05012    -0.05826
Training/policy_loss                  -2.68469     0.00795    -2.67196    -2.69459
Training/qf1_loss                     1003.00414   103.34118  1137.95129  898.59583
Training/qf2_loss                     1003.03115   103.34093  1137.97705  898.62463
Training/pf_norm                      0.22633      0.02358    0.26768     0.19605
Training/qf1_norm                     9.38817      0.29599    9.75753     8.92693
Training/qf2_norm                     8.08811      0.23475    8.34419     7.69711
log_std/mean                          -0.01975     0.00130    -0.01793    -0.02160
log_std/std                           0.00493      0.00026    0.00530     0.00457
log_std/max                           -0.01047     0.00080    -0.00934    -0.01160
log_std/min                           -0.03018     0.00176    -0.02769    -0.03268
log_probs/mean                        -2.69617     0.00825    -2.68282    -2.70615
log_probs/std                         0.39442      0.00335    0.39828     0.39040
log_probs/max                         -1.43854     0.05253    -1.36755    -1.51964
log_probs/min                         -4.33940     0.38086    -3.70581    -4.83220
mean/mean                             0.00053      0.00009    0.00066     0.00044
mean/std                              0.00244      0.00003    0.00248     0.00240
mean/max                              0.00625      0.00017    0.00646     0.00602
mean/min                              -0.00478     0.00011    -0.00462    -0.00492
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 8, 5, 3, 6, 0, 9, 1, 7, 4]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
train_time 0.5745823383331299
snapshot at best
2023-11-22 12:21:02,609 MainThread INFO: EPOCH:6
2023-11-22 12:21:02,609 MainThread INFO: Time Consumed:1.3215909004211426s
2023-11-22 12:21:02,609 MainThread INFO: Total Frames:40500s
  1%|          | 7/1000 [00:20<34:37,  2.09s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1214.56691
Train_Epoch_Reward                    8283.22066
Running_Training_Average_Rewards      2015.20265
Explore_Time                          0.00398
Train___Time                          0.57458
Eval____Time                          0.00303
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.20214
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.46203
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.94930
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.53257
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.26681
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14390
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30750
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12396.73825
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.83194
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.37291
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.52669      0.08052   7.63573     7.38990
alpha_0                               0.99015      0.00042   0.99074     0.98955
alpha_1                               0.99015      0.00042   0.99074     0.98955
alpha_2                               0.99014      0.00042   0.99074     0.98955
alpha_3                               0.99014      0.00042   0.99074     0.98955
alpha_4                               0.99014      0.00042   0.99074     0.98955
alpha_5                               0.99015      0.00042   0.99074     0.98956
alpha_6                               0.99015      0.00042   0.99074     0.98955
alpha_7                               0.99015      0.00042   0.99074     0.98956
alpha_8                               0.99015      0.00042   0.99074     0.98955
alpha_9                               0.99015      0.00042   0.99074     0.98955
Alpha_loss                            -0.06433     0.00283   -0.06030    -0.06827
Training/policy_loss                  -2.68690     0.00552   -2.67896    -2.69396
Training/qf1_loss                     980.90880    28.47844  1029.65198  953.50244
Training/qf2_loss                     980.94437    28.47905  1029.68982  953.53955
Training/pf_norm                      0.24243      0.01076   0.25481     0.22451
Training/qf1_norm                     10.12351     0.18330   10.39371    9.88140
Training/qf2_norm                     8.83491      0.21565   9.17096     8.54824
log_std/mean                          -0.02454     0.00142   -0.02255    -0.02657
log_std/std                           0.00585      0.00027   0.00623     0.00548
log_std/max                           -0.01346     0.00087   -0.01221    -0.01467
log_std/min                           -0.03674     0.00202   -0.03399    -0.03966
log_probs/mean                        -2.69947     0.00549   -2.69181    -2.70679
log_probs/std                         0.38918      0.00576   0.39864     0.38288
log_probs/max                         -1.46111     0.06737   -1.36836    -1.55305
log_probs/min                         -4.41099     0.54266   -3.90302    -5.45734
mean/mean                             0.00056      0.00007   0.00064     0.00047
mean/std                              0.00235      0.00003   0.00237     0.00230
mean/max                              0.00599      0.00009   0.00608     0.00585
mean/min                              -0.00463     0.00020   -0.00431    -0.00484
------------------------------------  -----------  --------  ----------  ---------
sample: [0, 8, 1, 4, 7, 2, 5, 3, 9, 6]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
train_time 0.5686213970184326
snapshot at best
2023-11-22 12:21:04,676 MainThread INFO: EPOCH:7
2023-11-22 12:21:04,677 MainThread INFO: Time Consumed:1.4186854362487793s
2023-11-22 12:21:04,677 MainThread INFO: Total Frames:42000s
  1%|          | 8/1000 [00:22<34:24,  2.08s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1220.90493
Train_Epoch_Reward                    2925.75452
Running_Training_Average_Rewards      1012.64503
Explore_Time                          0.00478
Train___Time                          0.56862
Eval____Time                          0.11396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.79455
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.54270
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.90017
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.61324
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.25113
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.14552
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30822
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12458.86221
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.78193
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.47543
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.44134      0.45853   7.93217     6.60885
alpha_0                               0.98866      0.00042   0.98926     0.98807
alpha_1                               0.98866      0.00042   0.98925     0.98807
alpha_2                               0.98866      0.00042   0.98925     0.98806
alpha_3                               0.98866      0.00042   0.98925     0.98806
alpha_4                               0.98866      0.00042   0.98925     0.98806
alpha_5                               0.98867      0.00042   0.98926     0.98807
alpha_6                               0.98866      0.00042   0.98926     0.98807
alpha_7                               0.98866      0.00042   0.98926     0.98807
alpha_8                               0.98866      0.00042   0.98926     0.98807
alpha_9                               0.98866      0.00042   0.98926     0.98807
Alpha_loss                            -0.07440     0.00287   -0.07036    -0.07851
Training/policy_loss                  -2.68752     0.00527   -2.67845    -2.69415
Training/qf1_loss                     966.50385    98.38431  1111.87598  805.68439
Training/qf2_loss                     966.54781    98.38741  1111.92310  805.72253
Training/pf_norm                      0.23270      0.02424   0.25408     0.18880
Training/qf1_norm                     10.64810     0.62553   11.29646    9.57613
Training/qf2_norm                     9.40042      0.56911   10.00863    8.41628
log_std/mean                          -0.02988     0.00160   -0.02765    -0.03217
log_std/std                           0.00683      0.00028   0.00723     0.00643
log_std/max                           -0.01653     0.00091   -0.01525    -0.01783
log_std/min                           -0.04425     0.00228   -0.04104    -0.04746
log_probs/mean                        -2.70081     0.00538   -2.69164    -2.70770
log_probs/std                         0.37158      0.01050   0.38990     0.36174
log_probs/max                         -1.52030     0.06694   -1.44674    -1.62267
log_probs/min                         -4.22036     0.48523   -3.52372    -4.82899
mean/mean                             0.00051      0.00009   0.00062     0.00038
mean/std                              0.00230      0.00001   0.00233     0.00229
mean/max                              0.00670      0.00020   0.00691     0.00636
mean/min                              -0.00377     0.00025   -0.00339    -0.00413
------------------------------------  -----------  --------  ----------  ---------
sample: [4, 8, 9, 7, 0, 2, 6, 5, 3, 1]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
train_time 0.6152818202972412
2023-11-22 12:21:06,227 MainThread INFO: EPOCH:8
2023-11-22 12:21:07,588 MainThread INFO: Time Consumed:0.7728958129882812s
2023-11-22 12:21:07,588 MainThread INFO: Total Frames:43500s
  1%|          | 9/1000 [00:25<38:37,  2.34s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1219.91254
Train_Epoch_Reward                    18469.34287
Running_Training_Average_Rewards      989.27727
Explore_Time                          0.00391
Train___Time                          0.61528
Eval____Time                          0.15268
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.71907
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.56786
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.88280
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.75879
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19417
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.15637
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.30942
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12444.12858
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.75657
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.65815
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.98914      0.37401   7.43141    6.45124
alpha_0                               0.98718      0.00042   0.98777    0.98659
alpha_1                               0.98718      0.00042   0.98777    0.98658
alpha_2                               0.98717      0.00042   0.98777    0.98658
alpha_3                               0.98717      0.00042   0.98777    0.98658
alpha_4                               0.98717      0.00042   0.98777    0.98658
alpha_5                               0.98718      0.00042   0.98778    0.98659
alpha_6                               0.98718      0.00042   0.98777    0.98658
alpha_7                               0.98718      0.00042   0.98777    0.98659
alpha_8                               0.98718      0.00042   0.98777    0.98659
alpha_9                               0.98718      0.00042   0.98777    0.98659
Alpha_loss                            -0.08454     0.00285   -0.08055   -0.08865
Training/policy_loss                  -2.69295     0.00430   -2.68706   -2.69899
Training/qf1_loss                     886.14746    63.08869  966.15985  791.73767
Training/qf2_loss                     886.19689    63.09112  966.20978  791.77948
Training/pf_norm                      0.21507      0.01613   0.23900    0.19317
Training/qf1_norm                     10.71802     0.52172   11.16977   9.78287
Training/qf2_norm                     9.57600      0.49052   10.04107   8.69624
log_std/mean                          -0.03587     0.00179   -0.03336   -0.03843
log_std/std                           0.00785      0.00029   0.00826    0.00744
log_std/max                           -0.02012     0.00113   -0.01855   -0.02173
log_std/min                           -0.05297     0.00263   -0.04926   -0.05668
log_probs/mean                        -2.70664     0.00435   -2.70067   -2.71276
log_probs/std                         0.37062      0.01178   0.39242    0.35939
log_probs/max                         -1.60088     0.06400   -1.49349   -1.69184
log_probs/min                         -4.85179     1.20400   -3.81566   -7.15906
mean/mean                             0.00033      0.00008   0.00039    0.00018
mean/std                              0.00240      0.00008   0.00254    0.00233
mean/max                              0.00719      0.00010   0.00736    0.00705
mean/min                              -0.00340     0.00038   -0.00304   -0.00403
------------------------------------  -----------  --------  ---------  ---------
sample: [4, 1, 3, 8, 7, 9, 0, 5, 6, 2]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
train_time 0.5599343776702881
2023-11-22 12:21:08,469 MainThread INFO: EPOCH:9
2023-11-22 12:21:08,470 MainThread INFO: Time Consumed:0.6697287559509277s
2023-11-22 12:21:08,470 MainThread INFO: Total Frames:45000s
  1%|          | 10/1000 [00:26<31:12,  1.89s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1207.16729
Train_Epoch_Reward                    7584.75645
Running_Training_Average_Rewards      965.99513
Explore_Time                          0.00268
Train___Time                          0.55993
Eval____Time                          0.10651
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.02352
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.67788
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.78161
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.91716
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.10627
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.13502
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.28373
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12326.24816
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.76009
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.88996
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.64952      0.70593    8.53909     6.83844
alpha_0                               0.98570      0.00042    0.98629     0.98511
alpha_1                               0.98570      0.00042    0.98629     0.98510
alpha_2                               0.98569      0.00042    0.98628     0.98510
alpha_3                               0.98569      0.00042    0.98628     0.98510
alpha_4                               0.98569      0.00042    0.98628     0.98510
alpha_5                               0.98570      0.00042    0.98629     0.98511
alpha_6                               0.98570      0.00042    0.98629     0.98510
alpha_7                               0.98570      0.00042    0.98629     0.98511
alpha_8                               0.98570      0.00042    0.98629     0.98511
alpha_9                               0.98570      0.00042    0.98629     0.98511
Alpha_loss                            -0.09458     0.00282    -0.09059    -0.09858
Training/policy_loss                  -2.69098     0.00176    -2.68916    -2.69392
Training/qf1_loss                     1040.43834   187.00272  1244.81702  806.64319
Training/qf2_loss                     1040.50355   187.01011  1244.88928  806.70007
Training/pf_norm                      0.22985      0.02126    0.26567     0.20142
Training/qf1_norm                     12.28435     0.97937    13.55869    11.02896
Training/qf2_norm                     11.07002     0.87688    12.27838    9.89861
log_std/mean                          -0.04256     0.00200    -0.03976    -0.04541
log_std/std                           0.00892      0.00031    0.00936     0.00847
log_std/max                           -0.02435     0.00126    -0.02256    -0.02614
log_std/min                           -0.06260     0.00276    -0.05867    -0.06648
log_probs/mean                        -2.70444     0.00189    -2.70245    -2.70756
log_probs/std                         0.35394      0.00526    0.36064     0.34869
log_probs/max                         -1.64180     0.01799    -1.62403    -1.66358
log_probs/min                         -4.05415     0.24251    -3.72894    -4.32399
mean/mean                             -0.00024     0.00023    0.00007     -0.00055
mean/std                              0.00293      0.00021    0.00326     0.00267
mean/max                              0.00772      0.00014    0.00799     0.00762
mean/min                              -0.00527     0.00066    -0.00442    -0.00627
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 3, 1, 5, 2, 4, 9, 7, 0, 6]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
train_time 2.537320852279663
2023-11-22 12:21:11,132 MainThread INFO: EPOCH:10
2023-11-22 12:21:11,133 MainThread INFO: Time Consumed:2.5427348613739014s
2023-11-22 12:21:11,133 MainThread INFO: Total Frames:46500s
  1%|          | 11/1000 [00:29<35:04,  2.13s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1196.25930
Train_Epoch_Reward                    7395.66228
Running_Training_Average_Rewards      1114.99205
Explore_Time                          0.00223
Train___Time                          2.53732
Eval____Time                          0.00272
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.57596
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.74734
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.61985
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04601
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.04339
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.07290
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.20367
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12212.74003
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.76591
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.07199
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.16426      0.86780    8.66056     6.19498
alpha_0                               0.98422      0.00042    0.98481     0.98363
alpha_1                               0.98421      0.00042    0.98481     0.98362
alpha_2                               0.98421      0.00042    0.98480     0.98362
alpha_3                               0.98421      0.00042    0.98480     0.98361
alpha_4                               0.98421      0.00042    0.98480     0.98362
alpha_5                               0.98422      0.00042    0.98481     0.98363
alpha_6                               0.98422      0.00042    0.98481     0.98362
alpha_7                               0.98422      0.00042    0.98481     0.98363
alpha_8                               0.98422      0.00042    0.98481     0.98363
alpha_9                               0.98422      0.00042    0.98481     0.98363
Alpha_loss                            -0.10475     0.00295    -0.10056    -0.10899
Training/policy_loss                  -2.69752     0.00866    -2.68697    -2.71107
Training/qf1_loss                     978.64437    237.69824  1384.29395  743.81903
Training/qf2_loss                     978.71563    237.70688  1384.38611  743.87970
Training/pf_norm                      0.20505      0.02308    0.24566     0.18429
Training/qf1_norm                     12.38060     1.25593    14.69786    11.01045
Training/qf2_norm                     11.26176     1.13376    13.32708    10.03012
log_std/mean                          -0.05001     0.00220    -0.04691    -0.05314
log_std/std                           0.01006      0.00033    0.01052     0.00959
log_std/max                           -0.02905     0.00141    -0.02706    -0.03107
log_std/min                           -0.07291     0.00302    -0.06860    -0.07707
log_probs/mean                        -2.71038     0.00863    -2.70001    -2.72378
log_probs/std                         0.33705      0.00872    0.35091     0.32484
log_probs/max                         -1.70008     0.04333    -1.66751    -1.78455
log_probs/min                         -4.42822     0.48661    -3.68437    -5.20243
mean/mean                             -0.00086     0.00011    -0.00068    -0.00098
mean/std                              0.00387      0.00025    0.00418     0.00349
mean/max                              0.00872      0.00037    0.00922     0.00822
mean/min                              -0.00771     0.00058    -0.00681    -0.00847
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 7, 0, 2, 8, 5, 4, 9, 6, 3]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
train_time 2.8236281871795654
2023-11-22 12:21:14,092 MainThread INFO: EPOCH:11
2023-11-22 12:21:14,092 MainThread INFO: Time Consumed:2.834200859069824s
2023-11-22 12:21:14,092 MainThread INFO: Total Frames:48000s
  1%|          | 12/1000 [00:31<39:10,  2.38s/it]------------------------------------  -----------  --------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1185.98848
Train_Epoch_Reward                    6573.58257
Running_Training_Average_Rewards      718.46671
Explore_Time                          0.00698
Train___Time                          2.82363
Eval____Time                          0.00306
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.41032
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.90624
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.39337
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.21661
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.90543
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93446
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.01541
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12111.78120
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.82852
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.28601
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.66766      0.21493   8.00701     7.39142
alpha_0                               0.98274      0.00042   0.98333     0.98215
alpha_1                               0.98273      0.00042   0.98333     0.98214
alpha_2                               0.98273      0.00042   0.98332     0.98214
alpha_3                               0.98273      0.00042   0.98332     0.98213
alpha_4                               0.98273      0.00042   0.98332     0.98214
alpha_5                               0.98274      0.00042   0.98333     0.98215
alpha_6                               0.98274      0.00042   0.98333     0.98215
alpha_7                               0.98275      0.00042   0.98334     0.98216
alpha_8                               0.98274      0.00042   0.98334     0.98215
alpha_9                               0.98275      0.00042   0.98334     0.98216
Alpha_loss                            -0.11500     0.00288   -0.11081    -0.11919
Training/policy_loss                  -2.70849     0.01060   -2.69793    -2.72447
Training/qf1_loss                     1155.60532   91.78837  1286.66565  1036.14612
Training/qf2_loss                     1155.69424   91.78767  1286.75256  1036.23291
Training/pf_norm                      0.16527      0.03677   0.22300     0.11280
Training/qf1_norm                     13.94653     0.31426   14.45906    13.64597
Training/qf2_norm                     12.77719     0.31185   13.20068    12.45672
log_std/mean                          -0.05806     0.00233   -0.05478    -0.06138
log_std/std                           0.01121      0.00032   0.01167     0.01075
log_std/max                           -0.03444     0.00163   -0.03216    -0.03678
log_std/min                           -0.08419     0.00323   -0.07968    -0.08884
log_probs/mean                        -2.72025     0.01074   -2.70920    -2.73688
log_probs/std                         0.31539      0.00761   0.32474     0.30465
log_probs/max                         -1.73559     0.05513   -1.67435    -1.80381
log_probs/min                         -4.21027     0.26174   -3.80092    -4.51083
mean/mean                             -0.00091     0.00006   -0.00082    -0.00098
mean/std                              0.00449      0.00011   0.00461     0.00431
mean/max                              0.00995      0.00027   0.01026     0.00952
mean/min                              -0.00925     0.00032   -0.00879    -0.00966
------------------------------------  -----------  --------  ----------  ----------
sample: [4, 1, 0, 3, 8, 9, 2, 5, 7, 6]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
train_time 2.790825128555298
2023-11-22 12:21:17,003 MainThread INFO: EPOCH:12
2023-11-22 12:21:17,003 MainThread INFO: Time Consumed:2.796919345855713s
2023-11-22 12:21:17,003 MainThread INFO: Total Frames:49500s
  1%|▏         | 13/1000 [00:34<41:55,  2.55s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1184.88814
Train_Epoch_Reward                    6120.88402
Running_Training_Average_Rewards      669.67096
Explore_Time                          0.00283
Train___Time                          2.79083
Eval____Time                          0.00272
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.14733
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.00448
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.25950
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.24495
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.76404
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.84647
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.85495
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12106.24049
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.90401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.33332
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.18110      0.55201    9.09128     7.49307
alpha_0                               0.98127      0.00042    0.98186     0.98068
alpha_1                               0.98126      0.00042    0.98185     0.98066
alpha_2                               0.98125      0.00042    0.98184     0.98066
alpha_3                               0.98125      0.00042    0.98184     0.98066
alpha_4                               0.98126      0.00042    0.98185     0.98067
alpha_5                               0.98126      0.00042    0.98185     0.98068
alpha_6                               0.98126      0.00042    0.98185     0.98067
alpha_7                               0.98127      0.00042    0.98186     0.98068
alpha_8                               0.98127      0.00042    0.98186     0.98068
alpha_9                               0.98127      0.00042    0.98186     0.98068
Alpha_loss                            -0.12502     0.00288    -0.12091    -0.12900
Training/policy_loss                  -2.70605     0.01147    -2.68801    -2.72051
Training/qf1_loss                     1352.95381   200.19486  1690.54004  1115.35620
Training/qf2_loss                     1353.06311   200.20356  1690.66870  1115.45374
Training/pf_norm                      0.18817      0.02767    0.23047     0.15560
Training/qf1_norm                     15.70750     0.95280    17.41897    14.58049
Training/qf2_norm                     14.52514     0.86494    16.08160    13.52360
log_std/mean                          -0.06666     0.00255    -0.06308    -0.07029
log_std/std                           0.01237      0.00033    0.01284     0.01190
log_std/max                           -0.04041     0.00179    -0.03791    -0.04299
log_std/min                           -0.09601     0.00349    -0.09118    -0.10106
log_probs/mean                        -2.71579     0.01163    -2.69746    -2.73009
log_probs/std                         0.31062      0.00259    0.31460     0.30772
log_probs/max                         -1.81330     0.07105    -1.71154    -1.89301
log_probs/min                         -4.29377     0.39062    -3.70159    -4.92370
mean/mean                             -0.00073     0.00005    -0.00067    -0.00080
mean/std                              0.00449      0.00011    0.00460     0.00432
mean/max                              0.01004      0.00024    0.01028     0.00966
mean/min                              -0.00929     0.00031    -0.00875    -0.00960
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 8, 4, 1, 5, 7, 0, 9, 3, 6]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
train_time 2.5343177318573
2023-11-22 12:21:19,937 MainThread INFO: EPOCH:13
2023-11-22 12:21:19,938 MainThread INFO: Time Consumed:2.7904913425445557s
2023-11-22 12:21:19,938 MainThread INFO: Total Frames:51000s
  1%|▏         | 14/1000 [00:37<43:40,  2.66s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1198.95440
Train_Epoch_Reward                    31968.83799
Running_Training_Average_Rewards      1488.77682
Explore_Time                          0.00407
Train___Time                          2.53432
Eval____Time                          0.25159
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.52585
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.88284
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.28574
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.07647
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.60547
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.81740
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.74940
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12239.48352
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.80081
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.19557
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.35472      0.41856    8.96681     7.85750
alpha_0                               0.97979      0.00042    0.98038     0.97921
alpha_1                               0.97978      0.00042    0.98037     0.97919
alpha_2                               0.97978      0.00042    0.98037     0.97919
alpha_3                               0.97977      0.00042    0.98036     0.97918
alpha_4                               0.97978      0.00042    0.98037     0.97919
alpha_5                               0.97979      0.00042    0.98038     0.97920
alpha_6                               0.97979      0.00042    0.98038     0.97920
alpha_7                               0.97980      0.00042    0.98039     0.97921
alpha_8                               0.97979      0.00042    0.98038     0.97920
alpha_9                               0.97980      0.00042    0.98039     0.97921
Alpha_loss                            -0.13528     0.00292    -0.13110    -0.13951
Training/policy_loss                  -2.71684     0.00641    -2.70863    -2.72664
Training/qf1_loss                     1445.05244   235.56582  1813.09497  1209.57922
Training/qf2_loss                     1445.17295   235.57680  1813.22778  1209.68872
Training/pf_norm                      0.16450      0.01324    0.17705     0.14028
Training/qf1_norm                     17.08579     0.83612    18.16335    16.04213
Training/qf2_norm                     16.01528     0.75458    17.00982    14.98984
log_std/mean                          -0.07620     0.00282    -0.07223    -0.08020
log_std/std                           0.01363      0.00038    0.01417     0.01310
log_std/max                           -0.04694     0.00187    -0.04429    -0.04961
log_std/min                           -0.10929     0.00394    -0.10377    -0.11491
log_probs/mean                        -2.72408     0.00607    -2.71689    -2.73283
log_probs/std                         0.28741      0.00767    0.29825     0.27799
log_probs/max                         -1.84433     0.07508    -1.70399    -1.91024
log_probs/min                         -4.28515     0.37513    -3.78584    -4.69673
mean/mean                             -0.00124     0.00021    -0.00093    -0.00153
mean/std                              0.00397      0.00013    0.00417     0.00380
mean/max                              0.00867      0.00043    0.00931     0.00807
mean/min                              -0.00781     0.00041    -0.00722    -0.00834
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 9, 4, 2, 0, 7, 3, 1, 6, 8]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
train_time 3.255200147628784
2023-11-22 12:21:23,332 MainThread INFO: EPOCH:14
2023-11-22 12:21:23,333 MainThread INFO: Time Consumed:3.2617368698120117s
2023-11-22 12:21:23,333 MainThread INFO: Total Frames:52500s
  2%|▏         | 15/1000 [00:41<47:24,  2.89s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1207.61153
Train_Epoch_Reward                    34692.98625
Running_Training_Average_Rewards      2426.09028
Explore_Time                          0.00301
Train___Time                          3.25520
Eval____Time                          0.00301
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.95526
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.85767
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.35138
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.10954
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.52718
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.88309
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.76135
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12327.49656
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.78955
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.14620
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.99778      0.74612    9.20452     6.86694
alpha_0                               0.97832      0.00042    0.97891     0.97774
alpha_1                               0.97831      0.00042    0.97890     0.97772
alpha_2                               0.97831      0.00042    0.97890     0.97772
alpha_3                               0.97830      0.00042    0.97889     0.97771
alpha_4                               0.97831      0.00042    0.97890     0.97772
alpha_5                               0.97832      0.00042    0.97891     0.97773
alpha_6                               0.97831      0.00042    0.97890     0.97772
alpha_7                               0.97833      0.00042    0.97892     0.97774
alpha_8                               0.97832      0.00042    0.97891     0.97773
alpha_9                               0.97832      0.00042    0.97891     0.97774
Alpha_loss                            -0.14535     0.00288    -0.14127    -0.14941
Training/policy_loss                  -2.71831     0.00295    -2.71491    -2.72203
Training/qf1_loss                     1262.22646   204.92650  1553.65332  960.85632
Training/qf2_loss                     1262.36340   204.94245  1553.82007  960.96521
Training/pf_norm                      0.15247      0.02283    0.17770     0.12270
Training/qf1_norm                     17.64160     1.50824    20.22640    15.51967
Training/qf2_norm                     16.56177     1.39487    18.98293    14.65232
log_std/mean                          -0.08638     0.00296    -0.08222    -0.09059
log_std/std                           0.01497      0.00037    0.01549     0.01444
log_std/max                           -0.05377     0.00205    -0.05093    -0.05673
log_std/min                           -0.12330     0.00406    -0.11760    -0.12880
log_probs/mean                        -2.72193     0.00231    -2.71931    -2.72589
log_probs/std                         0.27853      0.00568    0.28324     0.26851
log_probs/max                         -1.89970     0.06502    -1.82299    -2.01152
log_probs/min                         -4.52974     0.36820    -4.02368    -5.12110
mean/mean                             -0.00161     0.00007    -0.00149    -0.00167
mean/std                              0.00383      0.00002    0.00386     0.00380
mean/max                              0.00754      0.00029    0.00796     0.00711
mean/min                              -0.00960     0.00096    -0.00813    -0.01077
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 9, 2, 4, 1, 5, 6, 8, 3, 7]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
train_time 2.7994139194488525
snapshot at best
2023-11-22 12:21:27,036 MainThread INFO: EPOCH:15
2023-11-22 12:21:27,036 MainThread INFO: Time Consumed:3.56203293800354s
2023-11-22 12:21:27,036 MainThread INFO: Total Frames:54000s
  2%|▏         | 16/1000 [00:44<51:24,  3.13s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1236.21465
Train_Epoch_Reward                    16515.63423
Running_Training_Average_Rewards      2772.58195
Explore_Time                          0.00290
Train___Time                          2.79941
Eval____Time                          0.29399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.14278
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.01922
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.46858
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.12092
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.47008
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.93713
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.78357
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12610.86544
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.91304
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.86357
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.91645      0.48642    8.57746     7.10068
alpha_0                               0.97686      0.00041    0.97744     0.97627
alpha_1                               0.97683      0.00042    0.97742     0.97625
alpha_2                               0.97683      0.00042    0.97742     0.97625
alpha_3                               0.97683      0.00042    0.97742     0.97624
alpha_4                               0.97684      0.00042    0.97743     0.97625
alpha_5                               0.97685      0.00042    0.97744     0.97626
alpha_6                               0.97684      0.00042    0.97743     0.97626
alpha_7                               0.97686      0.00042    0.97745     0.97627
alpha_8                               0.97685      0.00042    0.97744     0.97626
alpha_9                               0.97685      0.00042    0.97744     0.97626
Alpha_loss                            -0.15565     0.00289    -0.15160    -0.15968
Training/policy_loss                  -2.73113     0.00662    -2.72116    -2.74182
Training/qf1_loss                     1218.82312   124.42779  1330.37952  989.44031
Training/qf2_loss                     1218.97622   124.44030  1330.53284  989.56738
Training/pf_norm                      0.15363      0.01128    0.16878     0.13638
Training/qf1_norm                     18.72971     1.28475    20.27975    16.59793
Training/qf2_norm                     17.67495     1.22937    19.20100    15.64795
log_std/mean                          -0.09723     0.00320    -0.09277    -0.10181
log_std/std                           0.01632      0.00040    0.01689     0.01576
log_std/max                           -0.06130     0.00223    -0.05822    -0.06445
log_std/min                           -0.13888     0.00441    -0.13268    -0.14550
log_probs/mean                        -2.73043     0.00641    -2.72026    -2.74040
log_probs/std                         0.27912      0.00718    0.28810     0.26793
log_probs/max                         -1.97250     0.04068    -1.90428    -2.02641
log_probs/min                         -4.90288     0.19729    -4.60670    -5.14741
mean/mean                             -0.00117     0.00021    -0.00087    -0.00142
mean/std                              0.00400      0.00006    0.00411     0.00393
mean/max                              0.00659      0.00018    0.00690     0.00642
mean/min                              -0.01132     0.00006    -0.01123    -0.01142
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 7, 8, 9, 4, 0, 2, 3, 5, 1]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
train_time 0.5839509963989258
snapshot at best
2023-11-22 12:21:30,513 MainThread INFO: EPOCH:16
2023-11-22 12:21:30,513 MainThread INFO: Time Consumed:1.5520391464233398s
2023-11-22 12:21:30,513 MainThread INFO: Total Frames:55500s
  2%|▏         | 17/1000 [00:48<52:56,  3.23s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1268.57311
Train_Epoch_Reward                    12201.12801
Running_Training_Average_Rewards      2113.65828
Explore_Time                          0.00292
Train___Time                          0.58395
Eval____Time                          0.40722
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.90910
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.15615
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.72954
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.03009
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.75192
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17409
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.09056
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12939.04947
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.92613
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.55075
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.61677      0.10374   7.71002     7.41439
alpha_0                               0.97539      0.00041   0.97598     0.97480
alpha_1                               0.97536      0.00042   0.97595     0.97478
alpha_2                               0.97536      0.00042   0.97595     0.97478
alpha_3                               0.97536      0.00041   0.97595     0.97478
alpha_4                               0.97537      0.00042   0.97596     0.97478
alpha_5                               0.97538      0.00042   0.97597     0.97479
alpha_6                               0.97537      0.00042   0.97596     0.97479
alpha_7                               0.97539      0.00041   0.97598     0.97480
alpha_8                               0.97538      0.00042   0.97597     0.97479
alpha_9                               0.97538      0.00042   0.97597     0.97479
Alpha_loss                            -0.16586     0.00302   -0.16145    -0.17011
Training/policy_loss                  -2.74007     0.00921   -2.72296    -2.75037
Training/qf1_loss                     1074.51897   52.95074  1151.45947  993.25500
Training/qf2_loss                     1074.67104   52.95398  1151.61548  993.40918
Training/pf_norm                      0.12887      0.04903   0.22246     0.08347
Training/qf1_norm                     19.42650     0.50249   20.09958    18.69082
Training/qf2_norm                     18.54165     0.50359   19.25900    17.89767
log_std/mean                          -0.10877     0.00317   -0.10416    -0.11315
log_std/std                           0.01767      0.00034   0.01813     0.01716
log_std/max                           -0.06952     0.00238   -0.06609    -0.07283
log_std/min                           -0.15489     0.00433   -0.14865    -0.16084
log_probs/mean                        -2.73370     0.00798   -2.71870    -2.74155
log_probs/std                         0.26542      0.01330   0.28730     0.24803
log_probs/max                         -2.04784     0.04049   -1.99264    -2.11615
log_probs/min                         -5.24627     0.83134   -3.90398    -6.19428
mean/mean                             -0.00108     0.00016   -0.00084    -0.00125
mean/std                              0.00454      0.00027   0.00492     0.00416
mean/max                              0.00661      0.00011   0.00672     0.00640
mean/min                              -0.01254     0.00074   -0.01150    -0.01353
------------------------------------  -----------  --------  ----------  ---------
sample: [3, 8, 5, 6, 1, 9, 7, 4, 2, 0]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
train_time 0.6819617748260498
snapshot at best
2023-11-22 12:21:34,137 MainThread INFO: EPOCH:17
2023-11-22 12:21:34,137 MainThread INFO: Time Consumed:1.5122075080871582s
2023-11-22 12:21:34,137 MainThread INFO: Total Frames:57000s
  2%|▏         | 18/1000 [00:52<54:48,  3.35s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1281.17651
Train_Epoch_Reward                    8025.55121
Running_Training_Average_Rewards      1224.74378
Explore_Time                          0.00313
Train___Time                          0.68196
Eval____Time                          0.37174
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.78397
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.09198
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.89756
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.92801
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.01833
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.34438
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.32602
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13060.39659
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.85114
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.39013
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.66862      0.79451    8.99929     6.59464
alpha_0                               0.97392      0.00041    0.97451     0.97334
alpha_1                               0.97389      0.00042    0.97448     0.97331
alpha_2                               0.97390      0.00041    0.97448     0.97331
alpha_3                               0.97390      0.00041    0.97448     0.97331
alpha_4                               0.97390      0.00041    0.97449     0.97332
alpha_5                               0.97391      0.00041    0.97450     0.97333
alpha_6                               0.97391      0.00041    0.97449     0.97332
alpha_7                               0.97392      0.00041    0.97451     0.97334
alpha_8                               0.97391      0.00041    0.97450     0.97332
alpha_9                               0.97391      0.00041    0.97450     0.97333
Alpha_loss                            -0.17600     0.00293    -0.17201    -0.18018
Training/policy_loss                  -2.74743     0.00591    -2.73897    -2.75512
Training/qf1_loss                     1111.79703   219.94879  1437.56836  790.06207
Training/qf2_loss                     1111.96521   219.96111  1437.75623  790.20117
Training/pf_norm                      0.12219      0.02565    0.15136     0.07702
Training/qf1_norm                     20.99862     2.11461    24.71557    18.28184
Training/qf2_norm                     20.15403     2.12168    23.97735    17.53625
log_std/mean                          -0.11875     0.00249    -0.11514    -0.12220
log_std/std                           0.01868      0.00024    0.01901     0.01834
log_std/max                           -0.07733     0.00205    -0.07439    -0.08020
log_std/min                           -0.16857     0.00347    -0.16373    -0.17356
log_probs/mean                        -2.73393     0.00472    -2.72678    -2.73872
log_probs/std                         0.24350      0.00488    0.24794     0.23451
log_probs/max                         -2.05747     0.03863    -2.02054    -2.12694
log_probs/min                         -4.77654     0.54894    -3.96243    -5.58279
mean/mean                             -0.00165     0.00028    -0.00129    -0.00205
mean/std                              0.00551      0.00025    0.00586     0.00512
mean/max                              0.00706      0.00013    0.00728     0.00689
mean/min                              -0.01499     0.00066    -0.01399    -0.01593
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 0, 1, 4, 6, 5, 9, 3, 7, 2]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
train_time 0.5741372108459473
snapshot at best
2023-11-22 12:21:37,858 MainThread INFO: EPOCH:18
2023-11-22 12:21:37,858 MainThread INFO: Time Consumed:1.456089735031128s
2023-11-22 12:21:37,858 MainThread INFO: Total Frames:58500s
  2%|▏         | 19/1000 [00:55<56:30,  3.46s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1298.48542
Train_Epoch_Reward                    6033.27949
Running_Training_Average_Rewards      875.33196
Explore_Time                          0.00614
Train___Time                          0.57414
Eval____Time                          0.41056
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.76023
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.22625
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.02110
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.94729
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.21403
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.43370
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.51679
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13239.14774
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.99338
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.18083
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.97489      0.73877    8.83650     6.98677
alpha_0                               0.97246      0.00041    0.97305     0.97188
alpha_1                               0.97243      0.00041    0.97301     0.97184
alpha_2                               0.97243      0.00041    0.97302     0.97185
alpha_3                               0.97244      0.00041    0.97302     0.97185
alpha_4                               0.97244      0.00041    0.97302     0.97185
alpha_5                               0.97245      0.00041    0.97303     0.97186
alpha_6                               0.97244      0.00041    0.97303     0.97186
alpha_7                               0.97246      0.00041    0.97305     0.97188
alpha_8                               0.97245      0.00041    0.97303     0.97186
alpha_9                               0.97245      0.00041    0.97304     0.97186
Alpha_loss                            -0.18616     0.00286    -0.18225    -0.19024
Training/policy_loss                  -2.75668     0.00429    -2.74917    -2.76145
Training/qf1_loss                     1175.42399   257.02485  1438.71863  785.61121
Training/qf2_loss                     1175.61295   257.04397  1438.90796  785.77625
Training/pf_norm                      0.11606      0.03576    0.18470     0.09098
Training/qf1_norm                     23.33168     2.28144    26.24450    20.51794
Training/qf2_norm                     22.52513     2.26709    25.48859    19.72370
log_std/mean                          -0.12625     0.00171    -0.12372    -0.12854
log_std/std                           0.01937      0.00014    0.01955     0.01915
log_std/max                           -0.08377     0.00151    -0.08156    -0.08568
log_std/min                           -0.17846     0.00232    -0.17466    -0.18165
log_probs/mean                        -2.73472     0.00366    -2.72880    -2.73998
log_probs/std                         0.24792      0.01371    0.27262     0.23465
log_probs/max                         -2.11921     0.03367    -2.07722    -2.17736
log_probs/min                         -5.23812     0.65270    -4.36044    -6.25263
mean/mean                             -0.00266     0.00028    -0.00229    -0.00308
mean/std                              0.00623      0.00009    0.00635     0.00608
mean/max                              0.00692      0.00047    0.00741     0.00619
mean/min                              -0.01694     0.00031    -0.01642    -0.01737
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 4, 6, 9, 2, 8, 5, 1, 0, 3]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
train_time 0.5729148387908936
snapshot at best
2023-11-22 12:21:42,108 MainThread INFO: EPOCH:19
2023-11-22 12:21:42,108 MainThread INFO: Time Consumed:1.9935173988342285s
2023-11-22 12:21:42,108 MainThread INFO: Total Frames:60000s
  2%|▏         | 20/1000 [01:00<1:00:32,  3.71s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1315.59039
Train_Epoch_Reward                    17125.39039
Running_Training_Average_Rewards      1039.47404
Explore_Time                          0.00287
Train___Time                          0.57291
Eval____Time                          0.37166
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.37418
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.46617
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.09362
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.99350
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.33103
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.46727
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.65423
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13409.41896
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11808
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.01701
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.04001      0.44631    8.67962     7.38919
alpha_0                               0.97100      0.00041    0.97159     0.97042
alpha_1                               0.97096      0.00041    0.97155     0.97038
alpha_2                               0.97097      0.00041    0.97155     0.97038
alpha_3                               0.97097      0.00041    0.97156     0.97039
alpha_4                               0.97097      0.00041    0.97156     0.97039
alpha_5                               0.97099      0.00041    0.97157     0.97040
alpha_6                               0.97098      0.00041    0.97156     0.97039
alpha_7                               0.97100      0.00041    0.97158     0.97041
alpha_8                               0.97098      0.00041    0.97157     0.97040
alpha_9                               0.97099      0.00041    0.97157     0.97040
Alpha_loss                            -0.19627     0.00287    -0.19208    -0.20020
Training/policy_loss                  -2.76615     0.00578    -2.75717    -2.77334
Training/qf1_loss                     1201.82351   222.70081  1603.80994  946.75232
Training/qf2_loss                     1202.02644   222.69906  1603.99695  946.93665
Training/pf_norm                      0.11317      0.01488    0.13611     0.09264
Training/qf1_norm                     25.33050     1.48660    27.85627    23.23768
Training/qf2_norm                     24.61741     1.49496    27.15955    22.52766
log_std/mean                          -0.13130     0.00121    -0.12957    -0.13300
log_std/std                           0.01966      0.00005    0.01974     0.01960
log_std/max                           -0.08829     0.00136    -0.08640    -0.09014
log_std/min                           -0.18402     0.00094    -0.18258    -0.18545
log_probs/mean                        -2.73385     0.00518    -2.72915    -2.74116
log_probs/std                         0.23862      0.00884    0.25328     0.22951
log_probs/max                         -2.11500     0.01725    -2.10089    -2.14891
log_probs/min                         -5.05674     1.08974    -3.95081    -7.04917
mean/mean                             -0.00358     0.00018    -0.00327    -0.00376
mean/std                              0.00652      0.00004    0.00658     0.00645
mean/max                              0.00672      0.00034    0.00728     0.00628
mean/min                              -0.01736     0.00039    -0.01675    -0.01781
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 0, 1, 3, 5, 4, 2, 7, 8, 9]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
train_time 0.6250040531158447
2023-11-22 12:21:45,411 MainThread INFO: EPOCH:20
2023-11-22 12:21:45,411 MainThread INFO: Time Consumed:1.3309144973754883s
2023-11-22 12:21:45,411 MainThread INFO: Total Frames:61500s
  2%|▏         | 21/1000 [01:03<58:21,  3.58s/it]  ------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1304.40279
Train_Epoch_Reward                    11167.15799
Running_Training_Average_Rewards      1144.19426
Explore_Time                          0.00423
Train___Time                          0.62500
Eval____Time                          0.70077
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.65313
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.74618
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.06948
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.29837
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44809
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.54552
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76421
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13296.85223
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.24616
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.05315
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.90925      0.51092    8.68531     7.35250
alpha_0                               0.96954      0.00041    0.97013     0.96896
alpha_1                               0.96950      0.00041    0.97009     0.96892
alpha_2                               0.96951      0.00041    0.97009     0.96892
alpha_3                               0.96952      0.00041    0.97010     0.96893
alpha_4                               0.96951      0.00041    0.97010     0.96893
alpha_5                               0.96952      0.00041    0.97011     0.96894
alpha_6                               0.96952      0.00041    0.97010     0.96893
alpha_7                               0.96954      0.00041    0.97012     0.96895
alpha_8                               0.96952      0.00041    0.97011     0.96894
alpha_9                               0.96952      0.00041    0.97011     0.96894
Alpha_loss                            -0.20654     0.00293    -0.20244    -0.21065
Training/policy_loss                  -2.78234     0.00625    -2.77391    -2.78950
Training/qf1_loss                     1233.28102   194.11498  1451.39233  973.25946
Training/qf2_loss                     1233.48501   194.11449  1451.61389  973.47913
Training/pf_norm                      0.10540      0.01633    0.12756     0.08127
Training/qf1_norm                     26.90030     1.84966    30.05148    24.64002
Training/qf2_norm                     26.32698     1.93993    29.59060    24.02217
log_std/mean                          -0.13509     0.00085    -0.13377    -0.13617
log_std/std                           0.01973      0.00002    0.01976     0.01970
log_std/max                           -0.09306     0.00136    -0.09108    -0.09483
log_std/min                           -0.18597     0.00041    -0.18531    -0.18639
log_probs/mean                        -2.73801     0.00377    -2.73191    -2.74332
log_probs/std                         0.24599      0.01486    0.26906     0.22666
log_probs/max                         -2.14260     0.02597    -2.10432    -2.18217
log_probs/min                         -5.16464     0.68692    -4.26144    -6.29862
mean/mean                             -0.00338     0.00022    -0.00303    -0.00364
mean/std                              0.00646      0.00004    0.00651     0.00642
mean/max                              0.00770      0.00010    0.00787     0.00755
mean/min                              -0.01800     0.00050    -0.01713    -0.01853
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 3, 0, 4, 6, 2, 1, 5, 8, 7]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
train_time 4.475820779800415
2023-11-22 12:21:50,012 MainThread INFO: EPOCH:21
2023-11-22 12:21:50,012 MainThread INFO: Time Consumed:4.481298446655273s
2023-11-22 12:21:50,012 MainThread INFO: Total Frames:63000s
  2%|▏         | 22/1000 [01:07<1:03:21,  3.89s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1287.40260
Train_Epoch_Reward                    13462.07854
Running_Training_Average_Rewards      1391.82090
Explore_Time                          0.00227
Train___Time                          4.47582
Eval____Time                          0.00278
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.78160
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.77071
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.07830
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.42850
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.52716
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.53979
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.89306
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13130.36347
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11671
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.20165
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           7.72628      0.30622    8.17679     7.40977
alpha_0                               0.96809      0.00041    0.96867     0.96751
alpha_1                               0.96804      0.00041    0.96863     0.96746
alpha_2                               0.96805      0.00041    0.96863     0.96746
alpha_3                               0.96806      0.00041    0.96864     0.96748
alpha_4                               0.96805      0.00041    0.96864     0.96747
alpha_5                               0.96806      0.00041    0.96865     0.96748
alpha_6                               0.96806      0.00041    0.96864     0.96748
alpha_7                               0.96808      0.00041    0.96866     0.96749
alpha_8                               0.96807      0.00041    0.96865     0.96748
alpha_9                               0.96807      0.00041    0.96865     0.96748
Alpha_loss                            -0.21657     0.00283    -0.21269    -0.22071
Training/policy_loss                  -2.79331     0.00445    -2.78853    -2.80175
Training/qf1_loss                     1119.15629   126.93620  1228.51807  881.15509
Training/qf2_loss                     1119.33892   126.94576  1228.70483  881.31604
Training/pf_norm                      0.11655      0.01044    0.13560     0.10616
Training/qf1_norm                     28.46658     1.31090    30.99430    27.42689
Training/qf2_norm                     28.18127     1.39143    30.89604    27.09562
log_std/mean                          -0.13650     0.00009    -0.13639    -0.13664
log_std/std                           0.01951      0.00012    0.01968     0.01934
log_std/max                           -0.09492     0.00033    -0.09440    -0.09539
log_std/min                           -0.18388     0.00130    -0.18195    -0.18539
log_probs/mean                        -2.73475     0.00349    -2.72991    -2.74000
log_probs/std                         0.22778      0.00548    0.23823     0.22259
log_probs/max                         -2.13991     0.04204    -2.09403    -2.20295
log_probs/min                         -4.53480     0.27887    -4.33904    -5.07784
mean/mean                             -0.00245     0.00025    -0.00207    -0.00280
mean/std                              0.00641      0.00004    0.00648     0.00635
mean/max                              0.00773      0.00015    0.00793     0.00748
mean/min                              -0.01785     0.00052    -0.01711    -0.01854
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 8, 3, 6, 9, 7, 5, 4, 2, 0]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
train_time 3.9042227268218994
2023-11-22 12:21:54,613 MainThread INFO: EPOCH:22
2023-11-22 12:21:54,613 MainThread INFO: Time Consumed:4.459233522415161s
2023-11-22 12:21:54,613 MainThread INFO: Total Frames:64500s
  2%|▏         | 23/1000 [01:12<1:06:42,  4.10s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1282.39932
Train_Epoch_Reward                    20406.57437
Running_Training_Average_Rewards      1501.19370
Explore_Time                          0.00300
Train___Time                          3.90422
Eval____Time                          0.55143
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.38387
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.44925
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.14093
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.15341
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47777
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.45984
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.91868
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13073.89044
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.66118
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.25236
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.87682      0.33501   8.34943     7.32802
alpha_0                               0.96664      0.00041   0.96722     0.96605
alpha_1                               0.96659      0.00041   0.96717     0.96600
alpha_2                               0.96659      0.00041   0.96717     0.96601
alpha_3                               0.96660      0.00041   0.96719     0.96602
alpha_4                               0.96660      0.00041   0.96718     0.96601
alpha_5                               0.96661      0.00041   0.96719     0.96602
alpha_6                               0.96660      0.00041   0.96719     0.96602
alpha_7                               0.96662      0.00041   0.96720     0.96604
alpha_8                               0.96661      0.00041   0.96719     0.96603
alpha_9                               0.96661      0.00041   0.96719     0.96603
Alpha_loss                            -0.22654     0.00277   -0.22261    -0.23028
Training/policy_loss                  -2.80527     0.00482   -2.79903    -2.81173
Training/qf1_loss                     1067.43040   53.53518  1126.39038  997.57001
Training/qf2_loss                     1067.59218   53.54048  1126.55127  997.73474
Training/pf_norm                      0.11312      0.01725   0.13184     0.08090
Training/qf1_norm                     31.16972     1.39758   32.66093    28.68897
Training/qf2_norm                     31.18107     1.45865   32.70783    28.54279
log_std/mean                          -0.13606     0.00017   -0.13579    -0.13628
log_std/std                           0.01913      0.00009   0.01926     0.01900
log_std/max                           -0.09332     0.00057   -0.09262    -0.09408
log_std/min                           -0.17815     0.00189   -0.17488    -0.18057
log_probs/mean                        -2.72970     0.00556   -2.72062    -2.73652
log_probs/std                         0.23174      0.00458   0.23642     0.22470
log_probs/max                         -2.18068     0.03376   -2.13437    -2.23024
log_probs/min                         -4.54979     0.35794   -4.02218    -5.02159
mean/mean                             -0.00106     0.00054   -0.00025    -0.00178
mean/std                              0.00632      0.00008   0.00640     0.00620
mean/max                              0.00929      0.00085   0.01057     0.00816
mean/min                              -0.01552     0.00097   -0.01389    -0.01659
------------------------------------  -----------  --------  ----------  ---------
sample: [5, 4, 2, 6, 8, 3, 1, 7, 9, 0]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
train_time 4.7992963790893555
2023-11-22 12:21:59,562 MainThread INFO: EPOCH:23
2023-11-22 12:21:59,562 MainThread INFO: Time Consumed:4.8066253662109375s
2023-11-22 12:21:59,562 MainThread INFO: Total Frames:66000s
  2%|▏         | 24/1000 [01:17<1:10:49,  4.35s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1288.61546
Train_Epoch_Reward                    10472.78185
Running_Training_Average_Rewards      1478.04783
Explore_Time                          0.00327
Train___Time                          4.79930
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.74882
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.19370
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.12942
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.81103
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.42422
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.39801
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.84418
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13136.20844
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.30838
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.19604
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.38553      0.70458    9.72245     7.84687
alpha_0                               0.96518      0.00041    0.96576     0.96460
alpha_1                               0.96513      0.00041    0.96571     0.96455
alpha_2                               0.96514      0.00041    0.96572     0.96456
alpha_3                               0.96515      0.00041    0.96573     0.96457
alpha_4                               0.96514      0.00041    0.96572     0.96456
alpha_5                               0.96515      0.00041    0.96573     0.96457
alpha_6                               0.96515      0.00041    0.96573     0.96457
alpha_7                               0.96517      0.00041    0.96575     0.96459
alpha_8                               0.96516      0.00041    0.96574     0.96458
alpha_9                               0.96516      0.00041    0.96574     0.96458
Alpha_loss                            -0.23665     0.00287    -0.23262    -0.24074
Training/policy_loss                  -2.82433     0.00716    -2.81634    -2.83369
Training/qf1_loss                     1204.34661   151.15950  1479.04321  1047.84534
Training/qf2_loss                     1204.49529   151.17802  1479.20740  1047.93628
Training/pf_norm                      0.11038      0.01730    0.12805     0.07938
Training/qf1_norm                     35.46678     1.92652    39.09986    33.54807
Training/qf2_norm                     35.73457     2.04604    39.56392    33.67234
log_std/mean                          -0.13583     0.00005    -0.13578    -0.13590
log_std/std                           0.01888      0.00007    0.01899     0.01878
log_std/max                           -0.09176     0.00035    -0.09123    -0.09225
log_std/min                           -0.17333     0.00146    -0.17091    -0.17539
log_probs/mean                        -2.72920     0.00397    -2.72154    -2.73282
log_probs/std                         0.23100      0.00751    0.23863     0.21793
log_probs/max                         -2.12905     0.04302    -2.06125    -2.18650
log_probs/min                         -5.05540     0.50909    -4.26177    -5.68108
mean/mean                             0.00094      0.00056    0.00170     0.00013
mean/std                              0.00602      0.00012    0.00619     0.00588
mean/max                              0.01249      0.00068    0.01346     0.01143
mean/min                              -0.01149     0.00123    -0.00977    -0.01324
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 8, 5, 2, 3, 7, 4, 1, 0]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
train_time 4.1046669483184814
2023-11-22 12:22:04,579 MainThread INFO: EPOCH:24
2023-11-22 12:22:04,580 MainThread INFO: Time Consumed:4.890060663223267s
2023-11-22 12:22:04,580 MainThread INFO: Total Frames:67500s
  2%|▎         | 25/1000 [01:22<1:13:59,  4.55s/it]  2%|▎         | 25/1000 [01:30<59:01,  3.63s/it]  
------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1292.69898
Train_Epoch_Reward                    11962.64489
Running_Training_Average_Rewards      1428.06670
Explore_Time                          0.00722
Train___Time                          4.10467
Eval____Time                          0.77758
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.52869
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.74346
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.16008
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.38812
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.36393
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.34435
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.72779
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13177.25443
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.84419
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.16398
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.40959      0.34278    8.95516     7.89044
alpha_0                               0.96373      0.00041    0.96431     0.96315
alpha_1                               0.96368      0.00041    0.96426     0.96310
alpha_2                               0.96369      0.00041    0.96427     0.96311
alpha_3                               0.96370      0.00041    0.96428     0.96312
alpha_4                               0.96369      0.00041    0.96427     0.96311
alpha_5                               0.96370      0.00041    0.96428     0.96312
alpha_6                               0.96370      0.00041    0.96428     0.96312
alpha_7                               0.96372      0.00041    0.96430     0.96314
alpha_8                               0.96371      0.00041    0.96429     0.96313
alpha_9                               0.96371      0.00041    0.96429     0.96313
Alpha_loss                            -0.24690     0.00287    -0.24276    -0.25087
Training/policy_loss                  -2.84998     0.00813    -2.83826    -2.85856
Training/qf1_loss                     1268.32744   146.86481  1437.62476  1096.59375
Training/qf2_loss                     1268.43948   146.89173  1437.75488  1096.63794
Training/pf_norm                      0.10240      0.01234    0.11902     0.08348
Training/qf1_norm                     38.40115     1.96933    41.16390    35.11756
Training/qf2_norm                     38.92704     2.05205    41.38298    35.25085
log_std/mean                          -0.13566     0.00002    -0.13564    -0.13571
log_std/std                           0.01856      0.00010    0.01869     0.01840
log_std/max                           -0.09103     0.00024    -0.09066    -0.09140
log_std/min                           -0.17073     0.00030    -0.17043    -0.17128
log_probs/mean                        -2.73269     0.00465    -2.72997    -2.74198
log_probs/std                         0.23587      0.00404    0.24040     0.22983
log_probs/max                         -2.14173     0.01866    -2.10781    -2.16290
log_probs/min                         -5.06632     0.34015    -4.57706    -5.48220
mean/mean                             0.00254      0.00040    0.00315     0.00200
mean/std                              0.00595      0.00001    0.00596     0.00594
mean/max                              0.01456      0.00032    0.01501     0.01404
mean/min                              -0.00826     0.00073    -0.00743    -0.00934
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 1, 8, 4, 7, 5, 2, 6, 0, 3]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 323, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/collector/para/async_mt.py", line 463, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 336, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 332, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/algo/rl_algo.py", line 383, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer, epoch,self.use_trajectory_info)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/algo/off_policy/must_sac.py", line 344, in update_per_epoch
    mask_buffer_copy = self.get_masks(self.task_nums,self.task_nums)
  File "/scratch/qianxi/DST/DST_RL/./torchrl/algo/off_policy/must_sac.py", line 57, in get_masks
    self.state_trajectory[t_id] = self.clip_by_window(self.state_trajectory[t_id],recent_window)
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/qianxi/.local/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/home/qianxi/.local/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 335, in _bootstrap
    util._flush_std_streams()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 439, in _flush_std_streams
    sys.stderr.flush()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 335, in _bootstrap
    util._flush_std_streams()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 439, in _flush_std_streams
    sys.stderr.flush()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 335, in _bootstrap
    util._flush_std_streams()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 439, in _flush_std_streams
    sys.stderr.flush()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 335, in _bootstrap
    util._flush_std_streams()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 439, in _flush_std_streams
    sys.stderr.flush()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 335, in _bootstrap
    util._flush_std_streams()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 439, in _flush_std_streams
    sys.stderr.flush()
KeyboardInterrupt
