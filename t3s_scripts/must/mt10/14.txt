task start
Use seed 14
2023-08-01 19:37:37,738 MainThread INFO: Experiment Name:must_mtsac
2023-08-01 19:37:37,738 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      400,
      400
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      256,
      128
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      256,
      128
    ],
    "latent_size": 128
  },
  "sparse_training": {
    "pruning_ratio": 0.8
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 10000,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 100,
    "update_end_epoch": 7000,
    "mask_update_interval": 50,
    "eval_episodes": 3
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2023-08-01 19:38:37,252 MainThread INFO: Finished Pretrain
  0%|          | 0/10000 [00:00<?, ?it/s]self.update_end_epoch 7000
sample: [9, 5, 3, 2, 8, 0, 6, 1, 7, 4]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [12306.33, -21.13, -20.67, -43.13, -24.07, -17.52, -48.74, -20.31, -26.44, -27.0]
return_array_smooth: [12306.33, -21.13, -20.67, -43.13, -24.07, -17.52, -48.74, -20.31, -26.44, -27.0][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
snapshot at best
2023-08-01 19:38:51,989 MainThread INFO: EPOCH:0
2023-08-01 19:38:51,989 MainThread INFO: Time Consumed:14.705188035964966s
2023-08-01 19:38:51,989 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:415: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/10000 [00:15<43:55:56, 15.82s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1205.73256
Train_Epoch_Reward                    17890.22316
Running_Training_Average_Rewards      1789.02232
Explore_Time                          0.03245
Train___Time                          13.68709
Eval____Time                          0.00884
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.73625
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.13499
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.51825
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.06794
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.31105
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.67025
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.13030
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12306.33398
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00236
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.43702
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           9.01384      0.52048   10.78549    8.04120
alpha_0                               0.98499      0.00854   0.99970     0.97043
alpha_1                               0.98498      0.00855   0.99970     0.97039
alpha_2                               0.98498      0.00855   0.99970     0.97040
alpha_3                               0.98498      0.00854   0.99970     0.97041
alpha_4                               0.98497      0.00855   0.99970     0.97039
alpha_5                               0.98498      0.00854   0.99970     0.97041
alpha_6                               0.98498      0.00855   0.99970     0.97040
alpha_7                               0.98498      0.00854   0.99970     0.97040
alpha_8                               0.98499      0.00854   0.99970     0.97041
alpha_9                               0.98499      0.00854   0.99970     0.97042
Alpha_loss                            -0.10010     0.05841   -0.00000    -0.20012
Training/policy_loss                  -3.28842     0.55342   -2.66969    -4.52414
Training/qf1_loss                     1073.96469   86.87770  1355.08752  902.64502
Training/qf2_loss                     1073.70688   86.91688  1355.07800  902.45471
Training/pf_norm                      0.21843      0.09320   0.51880     0.13244
Training/qf1_norm                     66.85764     35.12104  144.74179   28.09126
Training/qf2_norm                     68.26556     35.67714  146.99257   28.67814
log_std/mean                          -0.10931     0.04318   -0.00177    -0.14802
log_std/std                           0.00692      0.00306   0.01089     0.00161
log_std/max                           -0.09404     0.03715   0.00153     -0.13069
log_std/min                           -0.12290     0.04826   -0.00560    -0.16053
log_probs/mean                        -2.72624     0.01629   -2.66592    -2.75054
log_probs/std                         0.26861      0.05843   0.43927     0.21099
log_probs/max                         -1.99497     0.25897   -1.26456    -2.25554
log_probs/min                         -4.86127     0.79460   -3.58372    -7.71297
mean/mean                             -0.00180     0.00431   0.00392     -0.01170
mean/std                              0.01135      0.00362   0.01646     0.00184
mean/max                              0.02221      0.00620   0.03107     0.00163
mean/min                              -0.02729     0.01097   -0.00571    -0.04449
------------------------------------  -----------  --------  ----------  ---------
snapshot at 0
history save at ./log/must_mtsac/mt10/14/model
self.update_end_epoch 7000
sample: [9, 7, 4, 3, 6, 5, 0, 8, 2, 1]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [12148.68, -22.92, -21.84, -46.19, -27.65, -17.66, -46.73, -21.99, -25.32, -29.9]
return_array_smooth: [12227.51, -22.03, -21.26, -44.66, -25.86, -17.59, -47.73, -21.15, -25.88, -28.45][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:01,139 MainThread INFO: EPOCH:1
2023-08-01 19:39:01,141 MainThread INFO: Time Consumed:8.035742044448853s
2023-08-01 19:39:01,141 MainThread INFO: Total Frames:3000s
  0%|          | 2/10000 [00:23<31:21:53, 11.29s/it]------------------------------------  -----------  --------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1188.84760
Train_Epoch_Reward                    13221.21679
Running_Training_Average_Rewards      1555.57200
Explore_Time                          0.00554
Train___Time                          8.02266
Eval____Time                          0.00684
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.73277
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.18864
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.66345
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.65000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.98654
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.84023
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.92473
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12148.67648
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.89542
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.31866
mean_success_rate                     0.00000

Name                                  Mean         Std       Max         Min
Reward_Mean                           7.14931      0.55595   9.28354     6.10773
alpha_0                               0.95588      0.00827   0.97013     0.94179
alpha_1                               0.95583      0.00828   0.97010     0.94169
alpha_2                               0.95582      0.00829   0.97011     0.94168
alpha_3                               0.95585      0.00828   0.97012     0.94171
alpha_4                               0.95583      0.00828   0.97010     0.94170
alpha_5                               0.95585      0.00828   0.97012     0.94174
alpha_6                               0.95583      0.00828   0.97011     0.94170
alpha_7                               0.95584      0.00828   0.97011     0.94171
alpha_8                               0.95584      0.00829   0.97012     0.94171
alpha_9                               0.95586      0.00828   0.97013     0.94173
Alpha_loss                            -0.30214     0.05816   -0.20207    -0.40236
Training/policy_loss                  -5.73346     0.58666   -4.55519    -6.73706
Training/qf1_loss                     736.83758    94.32700  1059.40759  573.89337
Training/qf2_loss                     736.66057    94.17848  1058.85046  574.05194
Training/pf_norm                      0.16187      0.02112   0.21886     0.11955
Training/qf1_norm                     216.02337    60.08465  355.55103   114.26679
Training/qf2_norm                     217.85026    60.09702  357.64072   116.07151
log_std/mean                          -0.13505     0.00355   -0.12959    -0.14197
log_std/std                           0.01206      0.00363   0.01960     0.00830
log_std/max                           -0.11539     0.00338   -0.11012    -0.12285
log_std/min                           -0.16809     0.02278   -0.14817    -0.22222
log_probs/mean                        -2.72985     0.00772   -2.71143    -2.74709
log_probs/std                         0.25111      0.02004   0.30900     0.20844
log_probs/max                         -1.96401     0.19661   -1.43391    -2.20588
log_probs/min                         -5.01579     0.69601   -4.00479    -7.48367
mean/mean                             -0.01376     0.00247   -0.01051    -0.01894
mean/std                              0.03529      0.01628   0.07132     0.01656
mean/max                              0.06856      0.02684   0.12213     0.01839
mean/min                              -0.13356     0.10170   -0.04473    -0.37522
------------------------------------  -----------  --------  ----------  ---------
self.update_end_epoch 7000
sample: [2, 8, 4, 1, 5, 0, 7, 3, 6, 9]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [12148.68, -22.92, -21.84, -46.19, -27.65, -17.66, -52.49, -21.99, -25.32, -29.9]
return_array_smooth: [12201.23, -22.33, -21.45, -45.17, -26.46, -17.62, -49.32, -21.43, -25.69, -28.93][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:09,313 MainThread INFO: EPOCH:2
2023-08-01 19:39:09,314 MainThread INFO: Time Consumed:7.9964683055877686s
2023-08-01 19:39:09,314 MainThread INFO: Total Frames:4500s
  0%|          | 3/10000 [00:32<27:24:12,  9.87s/it]------------------------------------  -----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               1188.27154
Train_Epoch_Reward                    8854.85487
Running_Training_Average_Rewards      1332.20983
Explore_Time                          0.01316
Train___Time                          7.97539
Eval____Time                          0.00728
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.49337
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.18864
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.66345
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.65000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.98654
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.84023
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.92473
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12148.67648
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.89542
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.31866
mean_success_rate                     0.00000

Name                                  Mean         Std       Max        Min
Reward_Mean                           6.00699      0.50616   7.61341    4.71716
alpha_0                               0.92813      0.00767   0.94151    0.91519
alpha_1                               0.92756      0.00804   0.94141    0.91385
alpha_2                               0.92756      0.00803   0.94140    0.91385
alpha_3                               0.92758      0.00804   0.94143    0.91386
alpha_4                               0.92757      0.00803   0.94142    0.91387
alpha_5                               0.92762      0.00803   0.94146    0.91390
alpha_6                               0.92757      0.00803   0.94141    0.91387
alpha_7                               0.92758      0.00803   0.94142    0.91387
alpha_8                               0.92758      0.00804   0.94143    0.91386
alpha_9                               0.92760      0.00803   0.94145    0.91389
Alpha_loss                            -0.50057     0.05636   -0.40346   -0.59779
Training/policy_loss                  -8.24263     0.96580   -6.74747   -10.06188
Training/qf1_loss                     438.58940    83.71779  688.22150  252.73465
Training/qf2_loss                     439.11563    83.60281  688.30634  252.87943
Training/pf_norm                      0.17136      0.02238   0.21570    0.12278
Training/qf1_norm                     290.60066    36.37429  359.81717  189.11484
Training/qf2_norm                     292.58876    36.50820  361.86819  190.88678
log_std/mean                          -0.13833     0.00262   -0.13346   -0.14449
log_std/std                           0.02202      0.00601   0.03247    0.01364
log_std/max                           -0.11109     0.00503   -0.10064   -0.12010
log_std/min                           -0.25271     0.04939   -0.16990   -0.33815
log_probs/mean                        -2.68883     0.02152   -2.64938   -2.73473
log_probs/std                         0.38223      0.05271   0.48099    0.27230
log_probs/max                         -0.55137     0.48216   0.36536    -1.47504
log_probs/min                         -5.37874     0.60148   -4.08304   -7.06131
mean/mean                             -0.02101     0.00390   -0.01445   -0.02791
mean/std                              0.12111      0.02629   0.15791    0.07198
mean/max                              0.28997      0.08531   0.38671    0.12327
mean/min                              -0.65948     0.14569   -0.37912   -0.89127
------------------------------------  -----------  --------  ---------  ---------
self.update_end_epoch 7000
sample: [3, 9, 0, 1, 4, 8, 5, 2, 6, 7]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [1196.56, -21.79, -19.78, -46.32, -30.82, -21.88, -50.5, -23.6, -26.61, -28.88]
return_array_smooth: [8497.97, -22.55, -21.15, -46.23, -28.71, -19.07, -49.91, -22.52, -25.75, -29.56][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:18,783 MainThread INFO: EPOCH:3
2023-08-01 19:39:18,784 MainThread INFO: Time Consumed:9.267746686935425s
2023-08-01 19:39:18,784 MainThread INFO: Total Frames:6000s
  0%|          | 4/10000 [00:41<26:58:06,  9.71s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               92.63704
Train_Epoch_Reward                    2450.46136
Running_Training_Average_Rewards      817.55110
Explore_Time                          0.01434
Train___Time                          9.24692
Eval____Time                          0.00588
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.50345
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.32376
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.88321
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.82284
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.59778
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.78355
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.79143
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1196.56489
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.88333
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.60514
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           5.04556     0.46037   6.50091    3.79045
alpha_0                               0.90202     0.00770   0.91494    0.88892
alpha_1                               0.90013     0.00780   0.91357    0.88683
alpha_2                               0.90014     0.00780   0.91358    0.88684
alpha_3                               0.90015     0.00780   0.91359    0.88685
alpha_4                               0.90016     0.00779   0.91360    0.88687
alpha_5                               0.90019     0.00780   0.91363    0.88688
alpha_6                               0.90017     0.00779   0.91360    0.88687
alpha_7                               0.90016     0.00780   0.91360    0.88686
alpha_8                               0.90015     0.00780   0.91359    0.88685
alpha_9                               0.90018     0.00780   0.91362    0.88688
Alpha_loss                            -0.69992    0.05672   -0.60025   -0.77694
Training/policy_loss                  -12.02218   0.99543   -10.09819  -13.55049
Training/qf1_loss                     275.72210   29.80510  372.27267  215.28685
Training/qf2_loss                     275.88754   29.92875  372.80438  215.26729
Training/pf_norm                      0.27025     0.11528   0.59486    0.12765
Training/qf1_norm                     88.59427    60.39363  319.44846  14.12159
Training/qf2_norm                     89.80021    61.13959  321.98239  14.29232
log_std/mean                          -0.13669    0.01247   -0.12701   -0.17464
log_std/std                           0.02327     0.01782   0.09274    0.00980
log_std/max                           -0.10224    0.01281   -0.07812   -0.12655
log_std/min                           -0.22991    0.10067   -0.14446   -0.54742
log_probs/mean                        -2.68412    0.06150   -2.43201   -2.74457
log_probs/std                         0.39181     0.16624   1.08220    0.23616
log_probs/max                         -0.57844    1.15884   3.30342    -1.86658
log_probs/min                         -5.27399    0.81031   -4.17282   -8.02460
mean/mean                             0.00238     0.02880   0.07234    -0.03185
mean/std                              0.11337     0.06392   0.31141    0.04113
mean/max                              0.34215     0.28004   1.31421    0.04622
mean/min                              -0.51386    0.31033   -0.07812   -1.05058
------------------------------------  ----------  --------  ---------  ---------
self.update_end_epoch 7000
sample: [2, 0, 8, 7, 5, 3, 9, 1, 4, 6]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [626.09, -21.49, -18.7, -45.9, -27.49, -24.74, -54.62, -21.34, -25.74, -26.48]
return_array_smooth: [4657.11, -22.07, -20.11, -46.14, -28.65, -21.43, -52.54, -22.31, -25.89, -28.42][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:27,442 MainThread INFO: EPOCH:4
2023-08-01 19:39:27,443 MainThread INFO: Time Consumed:8.453866481781006s
2023-08-01 19:39:27,443 MainThread INFO: Total Frames:7500s
  0%|          | 5/10000 [00:50<25:59:59,  9.36s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               35.95819
Train_Epoch_Reward                    2310.85884
Running_Training_Average_Rewards      453.87250
Explore_Time                          0.00523
Train___Time                          8.44205
Eval____Time                          0.00602
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.61961
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.90155
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.73982
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.48773
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.33639
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.70061
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.49459
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 626.08840
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.48147
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.74477
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           4.32543     0.48376   5.50750    3.01199
alpha_0                               0.87934     0.00584   0.88871    0.86861
alpha_1                               0.87352     0.00757   0.88656    0.86061
alpha_2                               0.87354     0.00757   0.88657    0.86064
alpha_3                               0.87355     0.00756   0.88659    0.86064
alpha_4                               0.87356     0.00757   0.88660    0.86064
alpha_5                               0.87358     0.00756   0.88662    0.86068
alpha_6                               0.87357     0.00756   0.88660    0.86066
alpha_7                               0.87355     0.00757   0.88660    0.86063
alpha_8                               0.87355     0.00756   0.88658    0.86064
alpha_9                               0.87359     0.00756   0.88662    0.86068
Alpha_loss                            -0.88011    0.06498   -0.76645   -0.98757
Training/policy_loss                  -13.79695   0.48133   -13.16878  -14.77902
Training/qf1_loss                     262.78725   27.45635  325.74789  188.16336
Training/qf2_loss                     262.87984   27.45887  325.83575  188.23053
Training/pf_norm                      0.23178     0.05880   0.46630    0.14972
Training/qf1_norm                     68.93976    46.83485  225.11275  14.80224
Training/qf2_norm                     69.41824    47.11895  226.49585  15.01297
log_std/mean                          -0.14639    0.00808   -0.13619   -0.17438
log_std/std                           0.05895     0.01278   0.09792    0.04541
log_std/max                           -0.11109    0.00529   -0.09808   -0.12229
log_std/min                           -0.45842    0.05387   -0.38072   -0.59673
log_probs/mean                        -2.54330    0.07718   -2.35813   -2.64372
log_probs/std                         0.79290     0.21956   1.26415    0.51220
log_probs/max                         2.02686     1.35686   4.36387    0.15189
log_probs/min                         -5.99544    0.95023   -4.31915   -9.47262
mean/mean                             0.04079     0.01292   0.07533    0.01995
mean/std                              0.25236     0.04775   0.33792    0.19523
mean/max                              1.19846     0.07125   1.36894    1.12673
mean/min                              -0.56550    0.30887   -0.11714   -1.10920
------------------------------------  ----------  --------  ---------  ---------
self.update_end_epoch 7000
sample: [7, 6, 1, 2, 9, 4, 5, 3, 0, 8]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [942.51, -20.69, -40.88, -31.91, -16.3, -24.57, -38.65, -21.01, -27.75, -16.64]
return_array_smooth: [921.72, -21.33, -26.45, -41.38, -24.87, -23.73, -47.92, -21.98, -26.7, -24.0][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:36,212 MainThread INFO: EPOCH:5
2023-08-01 19:39:36,213 MainThread INFO: Time Consumed:8.571285963058472s
2023-08-01 19:39:36,213 MainThread INFO: Total Frames:9000s
  0%|          | 6/10000 [00:59<25:24:45,  9.15s/it]------------------------------------  ---------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               70.41159
Train_Epoch_Reward                    548.72505
Running_Training_Average_Rewards      177.00151
Explore_Time                          0.01001
Train___Time                          8.55529
Eval____Time                          0.00531
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.64755
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.91307
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.56987
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.29626
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.01151
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.87509
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.69120
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 942.50694
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -16.64073
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.74578
mean_success_rate                     0.00000

Name                                  Mean       Std       Max        Min
Reward_Mean                           4.59285    0.49789   6.13019    3.61803
alpha_0                               0.85789    0.00565   0.86837    0.84898
alpha_1                               0.84770    0.00734   0.86035    0.83518
alpha_2                               0.84773    0.00734   0.86038    0.83519
alpha_3                               0.84773    0.00734   0.86039    0.83520
alpha_4                               0.84773    0.00734   0.86039    0.83520
alpha_5                               0.84779    0.00733   0.86042    0.83528
alpha_6                               0.84774    0.00734   0.86040    0.83521
alpha_7                               0.84772    0.00734   0.86037    0.83519
alpha_8                               0.84773    0.00734   0.86038    0.83519
alpha_9                               0.84776    0.00735   0.86042    0.83523
Alpha_loss                            -1.06610   0.04468   -0.98742   -1.14694
Training/policy_loss                  -16.33095  0.84896   -14.81826  -17.72425
Training/qf1_loss                     296.35499  31.00556  366.12003  233.79570
Training/qf2_loss                     296.53273  31.03865  366.26682  233.95938
Training/pf_norm                      0.21724    0.05287   0.32798    0.12108
Training/qf1_norm                     79.45776   50.56185  292.89923  8.92262
Training/qf2_norm                     79.89423   50.83174  294.48422  9.06460
log_std/mean                          -0.15297   0.00648   -0.14093   -0.16300
log_std/std                           0.06339    0.01043   0.07828    0.04593
log_std/max                           -0.10788   0.00555   -0.09396   -0.11554
log_std/min                           -0.43894   0.03065   -0.36656   -0.48813
log_probs/mean                        -2.49868   0.07414   -2.37194   -2.64646
log_probs/std                         0.92163    0.20997   1.25863    0.54162
log_probs/max                         2.75523    1.21008   4.39535    0.23776
log_probs/min                         -6.11615   1.01257   -4.61224   -11.72256
mean/mean                             -0.00030   0.00759   0.01920    -0.01136
mean/std                              0.28410    0.04524   0.34417    0.19824
mean/max                              1.21097    0.03189   1.25848    1.13695
mean/min                              -0.93325   0.19993   -0.41900   -1.22105
------------------------------------  ---------  --------  ---------  ---------
self.update_end_epoch 7000
sample: [7, 4, 9, 0, 2, 5, 3, 6, 1, 8]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [6049.48, -24.69, -22.46, -44.83, -24.32, -25.68, -50.5, -22.54, -26.07, -30.51]
return_array_smooth: [2539.36, -22.29, -27.35, -40.88, -22.7, -25.0, -47.92, -21.63, -26.52, -24.54][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:45,985 MainThread INFO: EPOCH:6
2023-08-01 19:39:45,986 MainThread INFO: Time Consumed:9.574065446853638s
2023-08-01 19:39:45,986 MainThread INFO: Total Frames:10500s
  0%|          | 7/10000 [01:08<25:54:27,  9.33s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               577.78740
Train_Epoch_Reward                    702.10939
Running_Training_Average_Rewards      118.72311
Explore_Time                          0.00592
Train___Time                          9.56180
Eval____Time                          0.00560
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.50483
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.83423
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -25.68326
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.31611
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.53608
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.46395
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.68935
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6049.48060
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.51232
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.06648
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.23122     0.65543    6.92268     3.96777
alpha_0                               0.84244     0.00339    0.84883     0.83751
alpha_1                               0.82265     0.00712    0.83493     0.81050
alpha_2                               0.82267     0.00712    0.83494     0.81051
alpha_3                               0.82267     0.00713    0.83495     0.81051
alpha_4                               0.82267     0.00712    0.83495     0.81052
alpha_5                               0.82275     0.00712    0.83503     0.81060
alpha_6                               0.82267     0.00713    0.83496     0.81051
alpha_7                               0.82267     0.00713    0.83494     0.81050
alpha_8                               0.82265     0.00713    0.83494     0.81049
alpha_9                               0.82269     0.00713    0.83498     0.81053
Alpha_loss                            -1.22060    0.04126    -1.14074    -1.28755
Training/policy_loss                  -19.77536   1.12164    -17.75547   -21.81818
Training/qf1_loss                     603.23831   211.95561  1185.70837  275.13525
Training/qf2_loss                     603.23505   211.85656  1185.51257  275.32437
Training/pf_norm                      0.22639     0.05883    0.47159     0.13638
Training/qf1_norm                     122.80066   95.06480   433.86621   13.36322
Training/qf2_norm                     123.52364   95.56018   436.01144   13.47236
log_std/mean                          -0.16453    0.00546    -0.15719    -0.17988
log_std/std                           0.09351     0.01079    0.11928     0.07682
log_std/max                           -0.11195    0.00419    -0.10315    -0.11867
log_std/min                           -0.50280    0.02978    -0.45828    -0.56280
log_probs/mean                        -2.29143    0.08049    -2.06715    -2.46670
log_probs/std                         1.50911     0.21706    2.09117     1.08034
log_probs/max                         5.48379     0.85037    7.73360     3.91589
log_probs/min                         -5.91241    1.00735    -4.11038    -8.91334
mean/mean                             -0.01210    0.00676    -0.00377    -0.02534
mean/std                              0.39219     0.03400    0.47345     0.34344
mean/max                              1.36909     0.09424    1.59052     1.22697
mean/min                              -1.36964    0.08461    -1.21900    -1.59219
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [1, 0, 6, 9, 8, 4, 3, 2, 5, 7]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [10580.38, -20.0, -21.44, -43.09, -27.0, -24.32, -49.77, -19.22, -23.93, -28.56]
return_array_smooth: [5857.46, -21.79, -28.26, -39.94, -22.54, -24.86, -46.31, -20.92, -25.91, -25.24][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:39:55,653 MainThread INFO: EPOCH:7
2023-08-01 19:39:55,653 MainThread INFO: Time Consumed:9.484486818313599s
2023-08-01 19:39:55,653 MainThread INFO: Total Frames:12000s
  0%|          | 8/10000 [01:18<26:17:09,  9.47s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1032.30426
Train_Epoch_Reward                    9188.55006
Running_Training_Average_Rewards      347.97948
Explore_Time                          0.00753
Train___Time                          9.46995
Eval____Time                          0.00592
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.77459
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.08731
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.32013
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.00067
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.22449
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.44479
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.99914
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10580.38173
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.55691
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.93108
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.01888      0.70871    7.53175     3.26011
alpha_0                               0.83533      0.00126    0.83747     0.83307
alpha_1                               0.79835      0.00692    0.81026     0.78654
alpha_2                               0.79835      0.00692    0.81026     0.78654
alpha_3                               0.79835      0.00692    0.81027     0.78655
alpha_4                               0.79836      0.00691    0.81027     0.78657
alpha_5                               0.79845      0.00691    0.81035     0.78666
alpha_6                               0.79835      0.00691    0.81027     0.78656
alpha_7                               0.79834      0.00692    0.81026     0.78654
alpha_8                               0.79833      0.00691    0.81025     0.78653
alpha_9                               0.79837      0.00692    0.81029     0.78656
Alpha_loss                            -1.37912     0.05371    -1.28729    -1.47497
Training/policy_loss                  -22.88911    0.74058    -21.76770   -24.27481
Training/qf1_loss                     641.02973    223.11178  1227.72546  253.86333
Training/qf2_loss                     640.94221    222.99878  1227.45117  254.20288
Training/pf_norm                      0.25306      0.05669    0.37794     0.13345
Training/qf1_norm                     142.56226    111.05923  654.74866   16.68470
Training/qf2_norm                     143.38222    111.60466  658.13214   16.82075
log_std/mean                          -0.17136     0.00238    -0.16657    -0.17597
log_std/std                           0.11243      0.00482    0.11999     0.10408
log_std/max                           -0.11458     0.00379    -0.10831    -0.12174
log_std/min                           -0.55038     0.02030    -0.50860    -0.60437
log_probs/mean                        -2.14925     0.02920    -2.07230    -2.21614
log_probs/std                         1.90770      0.06990    2.08889     1.75554
log_probs/max                         6.94019      0.30571    7.57093     6.10453
log_probs/min                         -5.38347     0.89932    -4.08187    -9.69972
mean/mean                             -0.00484     0.00211    -0.00079    -0.00869
mean/std                              0.45620      0.00750    0.47246     0.44441
mean/max                              1.54157      0.02696    1.59333     1.49558
mean/min                              -1.49199     0.03983    -1.44692    -1.59208
------------------------------------  -----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [7, 2, 1, 0, 8, 4, 9, 6, 5, 3]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [8062.3, -23.78, -20.38, -41.66, -32.36, -29.81, -50.58, -23.88, -26.49, -26.42]
return_array_smooth: [8230.72, -22.82, -21.43, -43.19, -27.89, -26.61, -50.29, -21.88, -25.49, -28.5][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:05,608 MainThread INFO: EPOCH:8
2023-08-01 19:40:05,609 MainThread INFO: Time Consumed:9.729171514511108s
2023-08-01 19:40:05,609 MainThread INFO: Total Frames:13500s
  0%|          | 9/10000 [01:28<26:37:36,  9.59s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               778.69480
Train_Epoch_Reward                    13118.88642
Running_Training_Average_Rewards      766.98486
Explore_Time                          0.01547
Train___Time                          9.70675
Eval____Time                          0.00619
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.57920
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.66101
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -29.81244
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.36305
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.87924
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.37757
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.77759
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8062.30302
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.41839
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.48656
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.17769      0.88885    8.04684     3.24116
alpha_0                               0.83096      0.00107    0.83302     0.82938
alpha_1                               0.77474      0.00671    0.78631     0.76329
alpha_2                               0.77475      0.00671    0.78631     0.76330
alpha_3                               0.77475      0.00671    0.78631     0.76330
alpha_4                               0.77477      0.00671    0.78633     0.76332
alpha_5                               0.77484      0.00672    0.78642     0.76338
alpha_6                               0.77476      0.00671    0.78632     0.76331
alpha_7                               0.77474      0.00671    0.78630     0.76329
alpha_8                               0.77473      0.00671    0.78630     0.76328
alpha_9                               0.77477      0.00671    0.78633     0.76332
Alpha_loss                            -1.55675     0.04934    -1.46824    -1.64354
Training/policy_loss                  -26.10950    0.98283    -24.30572   -27.53499
Training/qf1_loss                     735.16755    258.19965  1772.59070  349.18384
Training/qf2_loss                     734.93419    258.09518  1771.80786  348.98068
Training/pf_norm                      0.24756      0.06337    0.42547     0.12442
Training/qf1_norm                     195.95876    150.14028  726.78949   15.91207
Training/qf2_norm                     197.00244    150.96259  731.25439   16.02304
log_std/mean                          -0.17203     0.00143    -0.16866    -0.17448
log_std/std                           0.11468      0.00361    0.12179     0.10844
log_std/max                           -0.11877     0.00325    -0.11235    -0.12437
log_std/min                           -0.55041     0.01420    -0.52614    -0.58099
log_probs/mean                        -2.12429     0.03071    -2.05532    -2.19504
log_probs/std                         1.97583      0.08023    2.14724     1.78530
log_probs/max                         7.18191      0.33065    7.92593     6.24064
log_probs/min                         -5.28733     0.84669    -3.89471    -8.86355
mean/mean                             -0.00557     0.00145    -0.00218    -0.00853
mean/std                              0.46578      0.00789    0.48441     0.45310
mean/max                              1.54315      0.02419    1.59729     1.50168
mean/min                              -1.53411     0.02057    -1.49641    -1.58640
------------------------------------  -----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [8, 1, 5, 2, 9, 0, 3, 7, 4, 6]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [8033.5, -21.22, -22.43, -41.16, -29.97, -21.63, -48.79, -20.84, -27.79, -27.91]
return_array_smooth: [8892.06, -21.66, -21.42, -41.97, -29.78, -25.25, -49.72, -21.32, -26.07, -27.63][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:15,770 MainThread INFO: EPOCH:9
2023-08-01 19:40:15,771 MainThread INFO: Time Consumed:9.997159719467163s
2023-08-01 19:40:15,771 MainThread INFO: Total Frames:15000s
  0%|          | 10/10000 [01:38<27:06:13,  9.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               777.17578
Train_Epoch_Reward                    8066.09049
Running_Training_Average_Rewards      1012.45090
Explore_Time                          0.00555
Train___Time                          9.98356
Eval____Time                          0.00734
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.79458
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.15754
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.62621
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.96664
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.84178
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.43481
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.21724
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8033.50318
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.91349
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.79315
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.14635     0.70186    7.30039     3.63176
alpha_0                               0.82769     0.00099    0.82936     0.82600
alpha_1                               0.75184     0.00651    0.76306     0.74073
alpha_2                               0.75185     0.00651    0.76307     0.74074
alpha_3                               0.75185     0.00651    0.76307     0.74074
alpha_4                               0.75188     0.00651    0.76309     0.74077
alpha_5                               0.75191     0.00652    0.76315     0.74079
alpha_6                               0.75186     0.00651    0.76308     0.74075
alpha_7                               0.75183     0.00651    0.76306     0.74072
alpha_8                               0.75183     0.00651    0.76305     0.74072
alpha_9                               0.75188     0.00651    0.76309     0.74077
Alpha_loss                            -1.73791    0.05201    -1.64820    -1.82819
Training/policy_loss                  -29.20930   0.95033    -27.39432   -30.71643
Training/qf1_loss                     786.71350   195.29750  1360.93091  367.23483
Training/qf2_loss                     786.32946   195.20620  1360.44458  366.92529
Training/pf_norm                      0.23482     0.06545    0.45884     0.12613
Training/qf1_norm                     172.18543   141.14847  700.49097   26.93015
Training/qf2_norm                     172.98006   141.80493  703.84570   27.29847
log_std/mean                          -0.17329    0.00265    -0.16874    -0.17775
log_std/std                           0.11594     0.00352    0.12227     0.10721
log_std/max                           -0.11752    0.00586    -0.10647    -0.12577
log_std/min                           -0.55640    0.01785    -0.52112    -0.60211
log_probs/mean                        -2.11903    0.02515    -2.04858    -2.18567
log_probs/std                         1.99695     0.06337    2.15814     1.84688
log_probs/max                         7.26585     0.25172    7.79920     6.51898
log_probs/min                         -5.60705    1.20516    -3.96975    -9.94241
mean/mean                             -0.00405    0.00221    0.00086     -0.00663
mean/std                              0.46827     0.00624    0.48217     0.45615
mean/max                              1.55998     0.03022    1.63387     1.49702
mean/min                              -1.53688    0.02341    -1.49640    -1.58902
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [3, 6, 1, 4, 5, 2, 9, 8, 0, 7]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7875.32, -21.6, -22.64, -43.57, -29.04, -24.16, -51.94, -21.04, -26.54, -27.46]
return_array_smooth: [7990.37, -22.2, -21.82, -42.13, -30.46, -25.2, -50.44, -21.92, -26.94, -27.26][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:25,557 MainThread INFO: EPOCH:10
2023-08-01 19:40:25,558 MainThread INFO: Time Consumed:9.610082387924194s
2023-08-01 19:40:25,558 MainThread INFO: Total Frames:16500s
  0%|          | 11/10000 [01:48<27:08:22,  9.78s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               760.73266
Train_Epoch_Reward                    8541.84782
Running_Training_Average_Rewards      990.89416
Explore_Time                          0.00514
Train___Time                          9.59647
Eval____Time                          0.00741
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.94499
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.57050
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.15538
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.03910
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.03717
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.64280
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.60209
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7875.31830
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.45889
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.54077
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.17961     0.68902    7.15239     3.53243
alpha_0                               0.82434     0.00088    0.82597     0.82291
alpha_1                               0.72962     0.00632    0.74051     0.71884
alpha_2                               0.72963     0.00632    0.74052     0.71884
alpha_3                               0.72963     0.00632    0.74051     0.71884
alpha_4                               0.72965     0.00632    0.74054     0.71887
alpha_5                               0.72967     0.00632    0.74056     0.71888
alpha_6                               0.72964     0.00632    0.74053     0.71885
alpha_7                               0.72961     0.00632    0.74050     0.71882
alpha_8                               0.72962     0.00632    0.74050     0.71883
alpha_9                               0.72965     0.00632    0.74054     0.71887
Alpha_loss                            -1.91815    0.05136    -1.82576    -2.01047
Training/policy_loss                  -32.49397   1.07880    -30.61598   -34.30048
Training/qf1_loss                     836.40758   216.93780  1319.80054  418.67343
Training/qf2_loss                     835.85461   216.82766  1319.06506  418.30908
Training/pf_norm                      0.24343     0.05257    0.41920     0.12077
Training/qf1_norm                     188.93109   124.41093  609.57690   22.72958
Training/qf2_norm                     189.94915   124.99363  612.33679   23.26792
log_std/mean                          -0.17292    0.00262    -0.16773    -0.17759
log_std/std                           0.11730     0.00351    0.12577     0.10911
log_std/max                           -0.11864    0.00219    -0.11470    -0.12349
log_std/min                           -0.56008    0.02060    -0.52121    -0.60195
log_probs/mean                        -2.10956    0.02884    -2.04389    -2.17232
log_probs/std                         2.02267     0.06955    2.16728     1.86950
log_probs/max                         7.37661     0.25104    7.84736     6.76368
log_probs/min                         -5.42722    0.99016    -4.22472    -9.96324
mean/mean                             -0.00236    0.00120    0.00092     -0.00417
mean/std                              0.47198     0.00653    0.48509     0.45550
mean/max                              1.57486     0.02321    1.63929     1.53370
mean/min                              -1.58245    0.03552    -1.49971    -1.65486
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [6, 7, 2, 0, 3, 8, 9, 1, 5, 4]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7922.14, -20.89, -20.48, -42.56, -27.73, -23.69, -55.17, -21.11, -24.51, -26.75]
return_array_smooth: [7943.65, -21.23, -21.85, -42.43, -28.91, -23.16, -51.97, -21.0, -26.28, -27.37][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:36,204 MainThread INFO: EPOCH:11
2023-08-01 19:40:36,204 MainThread INFO: Time Consumed:10.47166395187378s
2023-08-01 19:40:36,204 MainThread INFO: Total Frames:18000s
  0%|          | 12/10000 [01:59<27:51:00, 10.04s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               765.92559
Train_Epoch_Reward                    9030.15514
Running_Training_Average_Rewards      854.60311
Explore_Time                          0.00681
Train___Time                          10.45719
Eval____Time                          0.00694
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.17399
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.55559
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.68741
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.73380
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.10661
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.48208
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.88528
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7922.13818
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.74690
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.51056
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.43264     0.97270    8.07151     3.66116
alpha_0                               0.82271     0.00014    0.82302     0.82251
alpha_1                               0.70805     0.00613    0.71862     0.69759
alpha_2                               0.70806     0.00613    0.71863     0.69760
alpha_3                               0.70806     0.00613    0.71863     0.69759
alpha_4                               0.70809     0.00613    0.71865     0.69762
alpha_5                               0.70810     0.00613    0.71867     0.69764
alpha_6                               0.70807     0.00613    0.71864     0.69761
alpha_7                               0.70804     0.00613    0.71861     0.69757
alpha_8                               0.70805     0.00613    0.71862     0.69759
alpha_9                               0.70809     0.00613    0.71865     0.69762
Alpha_loss                            -2.08878    0.05142    -2.00432    -2.18022
Training/policy_loss                  -35.99385   0.88501    -34.29727   -37.52142
Training/qf1_loss                     971.05908   296.01870  1981.06116  362.12851
Training/qf2_loss                     970.25531   295.83267  1979.78613  361.35852
Training/pf_norm                      0.26214     0.08022    0.53913     0.12890
Training/qf1_norm                     288.12253   197.73688  1042.38086  29.43726
Training/qf2_norm                     289.45638   198.64154  1047.57019  29.51239
log_std/mean                          -0.17616    0.00223    -0.17217    -0.18066
log_std/std                           0.12265     0.00264    0.13043     0.11772
log_std/max                           -0.11839    0.00368    -0.10903    -0.12358
log_std/min                           -0.58971    0.01674    -0.56166    -0.62254
log_probs/mean                        -2.05224    0.02845    -1.94620    -2.12225
log_probs/std                         2.17893     0.07326    2.43387     1.97989
log_probs/max                         7.88121     0.27465    8.58313     7.19268
log_probs/min                         -5.16445    0.87945    -4.00761    -10.47785
mean/mean                             -0.00542    0.00277    -0.00107    -0.00986
mean/std                              0.49454     0.00706    0.51208     0.47813
mean/max                              1.63877     0.02646    1.71211     1.58284
mean/min                              -1.68614    0.02461    -1.64226    -1.74598
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [9, 4, 5, 8, 6, 3, 1, 7, 0, 2]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7728.42, -20.89, -22.29, -43.09, -28.3, -19.4, -52.2, -21.44, -24.33, -27.23]
return_array_smooth: [7841.96, -21.12, -21.8, -43.07, -28.36, -22.41, -53.11, -21.19, -25.13, -27.14][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:46,323 MainThread INFO: EPOCH:12
2023-08-01 19:40:46,324 MainThread INFO: Time Consumed:9.918449640274048s
2023-08-01 19:40:46,324 MainThread INFO: Total Frames:19500s
  0%|          | 13/10000 [02:09<27:56:35, 10.07s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.92612
Train_Epoch_Reward                    8593.40315
Running_Training_Average_Rewards      872.18020
Explore_Time                          0.00852
Train___Time                          9.90287
Eval____Time                          0.00642
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.20136
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.09165
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.39550
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.30469
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.43667
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.28794
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.88715
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7728.42379
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.22801
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.32962
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.34314     0.81852    7.32723     3.62770
alpha_0                               0.82362     0.00046    0.82475     0.82303
alpha_1                               0.68713     0.00595    0.69738     0.67697
alpha_2                               0.68714     0.00595    0.69740     0.67698
alpha_3                               0.68713     0.00595    0.69738     0.67697
alpha_4                               0.68715     0.00595    0.69741     0.67700
alpha_5                               0.68717     0.00596    0.69743     0.67701
alpha_6                               0.68714     0.00595    0.69740     0.67699
alpha_7                               0.68712     0.00595    0.69736     0.67697
alpha_8                               0.68713     0.00595    0.69738     0.67697
alpha_9                               0.68715     0.00595    0.69741     0.67699
Alpha_loss                            -2.26701    0.04962    -2.17649    -2.35971
Training/policy_loss                  -39.28750   1.24637    -37.25787   -41.36874
Training/qf1_loss                     975.28847   262.12078  1663.52429  510.23996
Training/qf2_loss                     974.26822   261.91638  1661.70349  509.56729
Training/pf_norm                      0.25435     0.06405    0.44500     0.11520
Training/qf1_norm                     258.32615   179.68956  748.63495   34.51786
Training/qf2_norm                     259.56047   180.43834  752.01672   34.77153
log_std/mean                          -0.17521    0.00214    -0.17120    -0.17906
log_std/std                           0.12522     0.00434    0.13381     0.11912
log_std/max                           -0.11619    0.00506    -0.10598    -0.12295
log_std/min                           -0.58292    0.01366    -0.55823    -0.60885
log_probs/mean                        -2.03315    0.02859    -1.95730    -2.08197
log_probs/std                         2.24154     0.07345    2.43543     2.11419
log_probs/max                         8.10733     0.27491    8.93599     7.35924
log_probs/min                         -5.25619    1.03993    -3.99714    -10.74181
mean/mean                             -0.00647    0.00249    -0.00221    -0.01051
mean/std                              0.50424     0.00807    0.52500     0.49180
mean/max                              1.64733     0.03290    1.72654     1.57800
mean/min                              -1.68318    0.02528    -1.62717    -1.74145
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [1, 9, 2, 0, 6, 4, 5, 8, 7, 3]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7835.03, -19.71, -21.18, -44.44, -27.13, -20.16, -50.73, -18.75, -25.24, -26.92]
return_array_smooth: [7828.53, -20.5, -21.32, -43.36, -27.72, -21.08, -52.7, -20.43, -24.69, -26.96][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:40:57,353 MainThread INFO: EPOCH:13
2023-08-01 19:40:57,353 MainThread INFO: Time Consumed:10.870434761047363s
2023-08-01 19:40:57,353 MainThread INFO: Total Frames:21000s
  0%|          | 14/10000 [02:20<28:46:49, 10.38s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               758.07650
Train_Epoch_Reward                    9649.89722
Running_Training_Average_Rewards      909.11518
Explore_Time                          0.00888
Train___Time                          10.85424
Eval____Time                          0.00658
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.72863
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.43554
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.15708
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.13125
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.75197
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.18270
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.71487
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7835.02625
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.91986
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.23932
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.29065     0.89259    8.52963     3.52986
alpha_0                               0.82587     0.00067    0.82739     0.82478
alpha_1                               0.66682     0.00577    0.67677     0.65697
alpha_2                               0.66683     0.00577    0.67678     0.65698
alpha_3                               0.66682     0.00577    0.67677     0.65697
alpha_4                               0.66684     0.00577    0.67679     0.65699
alpha_5                               0.66685     0.00578    0.67680     0.65699
alpha_6                               0.66683     0.00578    0.67679     0.65698
alpha_7                               0.66681     0.00578    0.67677     0.65696
alpha_8                               0.66682     0.00578    0.67677     0.65696
alpha_9                               0.66684     0.00578    0.67679     0.65698
Alpha_loss                            -2.44693    0.04989    -2.34531    -2.53242
Training/policy_loss                  -42.35861   0.96671    -40.81026   -44.18642
Training/qf1_loss                     951.68703   264.01969  1757.43884  433.00778
Training/qf2_loss                     950.32108   263.70858  1755.17566  432.65802
Training/pf_norm                      0.26310     0.07716    0.49746     0.12223
Training/qf1_norm                     294.73219   236.60818  1335.28735  44.06202
Training/qf2_norm                     295.86295   237.49812  1340.27197  44.50023
log_std/mean                          -0.17499    0.00243    -0.17084    -0.17930
log_std/std                           0.12541     0.00465    0.13745     0.11774
log_std/max                           -0.11808    0.00295    -0.11193    -0.12334
log_std/min                           -0.58029    0.02169    -0.54223    -0.63477
log_probs/mean                        -2.02361    0.03247    -1.94042    -2.09337
log_probs/std                         2.26259     0.08882    2.45197     2.06310
log_probs/max                         8.11768     0.31845    8.89701     7.32811
log_probs/min                         -5.15330    0.88690    -3.96729    -10.26644
mean/mean                             -0.00423    0.00165    -0.00212    -0.00788
mean/std                              0.50563     0.00979    0.52477     0.48689
mean/max                              1.67724     0.03308    1.75859     1.61514
mean/min                              -1.64774    0.03025    -1.58120    -1.70388
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [4, 7, 3, 8, 5, 2, 1, 9, 6, 0]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7722.33, -21.86, -22.2, -43.34, -28.59, -23.44, -48.35, -21.41, -24.8, -27.16]
return_array_smooth: [7761.93, -20.82, -21.89, -43.62, -28.01, -21.0, -50.43, -20.53, -24.79, -27.1][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:41:07,712 MainThread INFO: EPOCH:14
2023-08-01 19:41:07,712 MainThread INFO: Time Consumed:10.173289060592651s
2023-08-01 19:41:07,712 MainThread INFO: Total Frames:22500s
  0%|          | 15/10000 [02:30<28:42:47, 10.35s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               746.11828
Train_Epoch_Reward                    8703.55088
Running_Training_Average_Rewards      898.22837
Explore_Time                          0.01234
Train___Time                          10.15401
Eval____Time                          0.00620
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.35005
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.33904
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.44214
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.59219
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.41496
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.19771
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.85637
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7722.33223
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.15676
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.80023
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.36135     0.79127    7.34076     3.49466
alpha_0                               0.83008     0.00160    0.83305     0.82744
alpha_1                               0.64712     0.00561    0.65678     0.63755
alpha_2                               0.64711     0.00561    0.65678     0.63755
alpha_3                               0.64712     0.00561    0.65677     0.63755
alpha_4                               0.64713     0.00560    0.65679     0.63757
alpha_5                               0.64713     0.00561    0.65679     0.63757
alpha_6                               0.64712     0.00561    0.65678     0.63756
alpha_7                               0.64710     0.00560    0.65676     0.63754
alpha_8                               0.64710     0.00561    0.65676     0.63753
alpha_9                               0.64713     0.00560    0.65678     0.63757
Alpha_loss                            -2.62291    0.05163    -2.53319    -2.71785
Training/policy_loss                  -45.80431   1.04060    -43.98671   -47.75850
Training/qf1_loss                     988.38350   285.59830  1899.05786  415.79184
Training/qf2_loss                     986.58284   285.18858  1896.13635  414.39590
Training/pf_norm                      0.27735     0.07227    0.45444     0.15435
Training/qf1_norm                     283.32662   189.66146  924.40637   48.06048
Training/qf2_norm                     284.62900   190.51375  929.69812   48.07834
log_std/mean                          -0.17440    0.00218    -0.16995    -0.17790
log_std/std                           0.12758     0.00300    0.13353     0.12127
log_std/max                           -0.11757    0.00339    -0.11067    -0.12191
log_std/min                           -0.58674    0.01336    -0.56207    -0.62018
log_probs/mean                        -1.98993    0.03055    -1.91156    -2.06988
log_probs/std                         2.36005     0.07793    2.53719     2.12390
log_probs/max                         8.49130     0.28749    9.04483     7.87269
log_probs/min                         -5.02904    0.85044    -3.99612    -9.81632
mean/mean                             -0.00710    0.00353    -0.00205    -0.01623
mean/std                              0.52050     0.00710    0.53452     0.50673
mean/max                              1.71360     0.02834    1.78145     1.66670
mean/min                              -1.68914    0.03160    -1.63618    -1.75322
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [0, 1, 5, 3, 7, 2, 8, 9, 4, 6]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7823.55, -23.55, -22.44, -41.91, -27.24, -23.84, -45.76, -21.88, -24.23, -27.78]
return_array_smooth: [7793.64, -21.71, -21.94, -43.23, -27.65, -22.48, -48.28, -20.68, -24.76, -27.29][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:41:18,902 MainThread INFO: EPOCH:15
2023-08-01 19:41:18,903 MainThread INFO: Time Consumed:11.012018918991089s
2023-08-01 19:41:18,903 MainThread INFO: Total Frames:24000s
  0%|          | 16/10000 [02:41<29:26:15, 10.61s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               756.49293
Train_Epoch_Reward                    8563.51699
Running_Training_Average_Rewards      897.23217
Explore_Time                          0.00799
Train___Time                          10.99664
Eval____Time                          0.00630
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.75617
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.91007
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.83672
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.23854
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.88061
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.43593
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.55334
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7823.55042
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.78245
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.22732
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.44090     0.85364    7.41442     3.71697
alpha_0                               0.83656     0.00204    0.84048     0.83312
alpha_1                               0.62799     0.00544    0.63736     0.61871
alpha_2                               0.62799     0.00544    0.63736     0.61871
alpha_3                               0.62799     0.00544    0.63736     0.61871
alpha_4                               0.62800     0.00544    0.63738     0.61872
alpha_5                               0.62801     0.00544    0.63738     0.61873
alpha_6                               0.62799     0.00544    0.63737     0.61871
alpha_7                               0.62797     0.00544    0.63735     0.61869
alpha_8                               0.62797     0.00544    0.63734     0.61869
alpha_9                               0.62801     0.00544    0.63738     0.61873
Alpha_loss                            -2.80246    0.05062    -2.71040    -2.89432
Training/policy_loss                  -49.15894   1.07347    -47.47737   -51.07821
Training/qf1_loss                     1050.48385  268.50825  1711.16882  481.55380
Training/qf2_loss                     1048.25561  268.02491  1707.27087  480.56235
Training/pf_norm                      0.29404     0.08544    0.53962     0.13456
Training/qf1_norm                     334.81164   211.34754  1023.65564  52.65834
Training/qf2_norm                     336.13923   212.05774  1026.89392  53.09075
log_std/mean                          -0.17568    0.00309    -0.16869    -0.18077
log_std/std                           0.12955     0.00333    0.13617     0.12383
log_std/max                           -0.11983    0.00380    -0.11119    -0.12624
log_std/min                           -0.59589    0.02035    -0.56861    -0.65095
log_probs/mean                        -1.97398    0.03284    -1.87673    -2.05959
log_probs/std                         2.40879     0.08701    2.64634     2.18653
log_probs/max                         8.68428     0.29535    9.33542     8.02568
log_probs/min                         -5.08262    0.90235    -3.71114    -8.73720
mean/mean                             -0.01272    0.00290    -0.00686    -0.01826
mean/std                              0.52867     0.00978    0.54361     0.50452
mean/max                              1.71361     0.04048    1.78897     1.62476
mean/min                              -1.76986    0.03848    -1.65667    -1.82908
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [9, 0, 7, 2, 3, 4, 5, 8, 6, 1]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7651.65, -20.97, -23.03, -43.83, -26.17, -22.37, -48.59, -20.71, -26.57, -30.14]
return_array_smooth: [7732.51, -22.13, -22.56, -43.03, -27.33, -23.22, -47.57, -21.34, -25.2, -28.36][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:41:29,222 MainThread INFO: EPOCH:16
2023-08-01 19:41:29,223 MainThread INFO: Time Consumed:10.144938230514526s
2023-08-01 19:41:29,223 MainThread INFO: Total Frames:25500s
  0%|          | 17/10000 [02:52<29:09:25, 10.51s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               738.92683
Train_Epoch_Reward                    7765.40868
Running_Training_Average_Rewards      834.41588
Explore_Time                          0.01912
Train___Time                          10.11862
Eval____Time                          0.00639
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.59453
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.82863
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.36898
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.17094
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.71343
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.03215
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97014
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7651.65348
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.14046
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.56588
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.42537     0.92024    7.33002     3.54153
alpha_0                               0.84595     0.00319    0.85135     0.84058
alpha_1                               0.60943     0.00528    0.61853     0.60042
alpha_2                               0.60943     0.00528    0.61852     0.60042
alpha_3                               0.60943     0.00528    0.61852     0.60041
alpha_4                               0.60943     0.00528    0.61853     0.60043
alpha_5                               0.60945     0.00528    0.61854     0.60044
alpha_6                               0.60943     0.00528    0.61852     0.60042
alpha_7                               0.60941     0.00528    0.61850     0.60040
alpha_8                               0.60941     0.00528    0.61850     0.60040
alpha_9                               0.60944     0.00528    0.61854     0.60044
Alpha_loss                            -2.98039    0.05392    -2.88974    -3.08443
Training/policy_loss                  -52.59637   0.99979    -51.04175   -54.86874
Training/qf1_loss                     1050.97338  304.16783  1933.64160  459.32779
Training/qf2_loss                     1048.31247  303.59794  1929.10193  458.04684
Training/pf_norm                      0.29482     0.09919    0.72103     0.14511
Training/qf1_norm                     373.27668   210.81153  979.71619   92.29324
Training/qf2_norm                     374.66338   211.50246  984.42139   92.63506
log_std/mean                          -0.17640    0.00288    -0.17217    -0.18218
log_std/std                           0.13239     0.00400    0.14020     0.12449
log_std/max                           -0.11517    0.00511    -0.10557    -0.12419
log_std/min                           -0.60962    0.02062    -0.56601    -0.64714
log_probs/mean                        -1.94520    0.02985    -1.88180    -2.04877
log_probs/std                         2.49287     0.07089    2.63171     2.25178
log_probs/max                         8.96862     0.23655    9.44840     8.34738
log_probs/min                         -5.26717    1.08119    -3.85188    -11.69148
mean/mean                             -0.01262    0.00203    -0.00914    -0.01644
mean/std                              0.53895     0.00658    0.55119     0.52443
mean/max                              1.75469     0.02672    1.80293     1.69591
mean/min                              -1.79529    0.02914    -1.73109    -1.84638
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [1, 3, 9, 8, 5, 6, 7, 4, 2, 0]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7736.43, -20.94, -22.03, -43.06, -24.93, -21.94, -43.41, -21.18, -26.81, -28.42]
return_array_smooth: [7737.21, -21.82, -22.5, -42.93, -26.11, -22.72, -45.92, -21.26, -25.87, -28.78][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:41:39,909 MainThread INFO: EPOCH:17
2023-08-01 19:41:39,909 MainThread INFO: Time Consumed:10.519128561019897s
2023-08-01 19:41:39,910 MainThread INFO: Total Frames:27000s
  0%|          | 18/10000 [03:02<29:18:47, 10.57s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               748.37135
Train_Epoch_Reward                    8783.29759
Running_Training_Average_Rewards      837.07411
Explore_Time                          0.37657
Train___Time                          10.13608
Eval____Time                          0.00576
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.40906
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.06013
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.93954
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.92501
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.17698
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.02828
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.94044
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7736.42930
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.42271
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.81362
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.50343     0.96053    8.88163     3.27815
alpha_0                               0.85647     0.00286    0.86147     0.85145
alpha_1                               0.59141     0.00512    0.60024     0.58267
alpha_2                               0.59141     0.00512    0.60024     0.58266
alpha_3                               0.59141     0.00512    0.60023     0.58267
alpha_4                               0.59142     0.00513    0.60025     0.58267
alpha_5                               0.59143     0.00513    0.60026     0.58269
alpha_6                               0.59141     0.00512    0.60024     0.58267
alpha_7                               0.59140     0.00512    0.60022     0.58266
alpha_8                               0.59139     0.00512    0.60022     0.58265
alpha_9                               0.59144     0.00512    0.60026     0.58270
Alpha_loss                            -3.16620    0.05329    -3.06173    -3.25666
Training/policy_loss                  -55.67363   1.23424    -53.48227   -58.07885
Training/qf1_loss                     1086.37035  297.47333  1881.27661  432.78488
Training/qf2_loss                     1083.12704  296.82133  1875.05237  430.91940
Training/pf_norm                      0.29716     0.09285    0.53335     0.14194
Training/qf1_norm                     388.60391   290.11008  1662.34607  89.19451
Training/qf2_norm                     389.94322   290.91092  1667.15857  89.98257
log_std/mean                          -0.17484    0.00443    -0.16761    -0.18474
log_std/std                           0.13116     0.00490    0.14194     0.12220
log_std/max                           -0.11526    0.00495    -0.10966    -0.12701
log_std/min                           -0.61391    0.02050    -0.57124    -0.65369
log_probs/mean                        -1.95918    0.03436    -1.86150    -2.02549
log_probs/std                         2.45480     0.09680    2.71359     2.26094
log_probs/max                         8.81272     0.29110    9.53141     7.97362
log_probs/min                         -5.55109    1.26735    -3.74544    -9.88184
mean/mean                             -0.01461    0.00282    -0.00944    -0.01962
mean/std                              0.53318     0.01035    0.56190     0.51312
mean/max                              1.70502     0.04621    1.81068     1.62116
mean/min                              -1.80159    0.02677    -1.74154    -1.85539
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [3, 9, 8, 2, 5, 6, 7, 1, 4, 0]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7585.45, -20.55, -21.22, -42.53, -27.88, -19.06, -51.97, -21.01, -25.74, -28.27]
return_array_smooth: [7657.84, -20.82, -22.09, -43.14, -26.32, -21.12, -47.99, -20.97, -26.37, -28.94][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:41:50,836 MainThread INFO: EPOCH:18
2023-08-01 19:41:50,836 MainThread INFO: Time Consumed:10.72181749343872s
2023-08-01 19:41:50,836 MainThread INFO: Total Frames:28500s
  0%|          | 19/10000 [03:13<29:39:20, 10.70s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               732.72203
Train_Epoch_Reward                    8222.79504
Running_Training_Average_Rewards      825.71671
Explore_Time                          0.02176
Train___Time                          10.69040
Eval____Time                          0.00894
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.97162
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.52602
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.06069
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.87752
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.01260
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22167
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.55071
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7585.44724
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.26965
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.73645
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.52173     0.86118    8.00738     3.25111
alpha_0                               0.86855     0.00446    0.87670     0.86158
alpha_1                               0.57393     0.00497    0.58250     0.56545
alpha_2                               0.57393     0.00497    0.58249     0.56545
alpha_3                               0.57393     0.00497    0.58250     0.56545
alpha_4                               0.57393     0.00497    0.58249     0.56545
alpha_5                               0.57395     0.00497    0.58251     0.56546
alpha_6                               0.57393     0.00497    0.58250     0.56545
alpha_7                               0.57392     0.00497    0.58248     0.56544
alpha_8                               0.57391     0.00497    0.58247     0.56543
alpha_9                               0.57396     0.00497    0.58253     0.56549
Alpha_loss                            -3.34159    0.05113    -3.25027    -3.43468
Training/policy_loss                  -59.17524   1.07148    -57.13728   -61.20761
Training/qf1_loss                     1103.38098  258.75712  1878.86353  522.66437
Training/qf2_loss                     1099.53487  258.02820  1872.30823  520.93097
Training/pf_norm                      0.29819     0.08775    0.57734     0.13412
Training/qf1_norm                     373.41153   242.64178  1251.80310  90.42744
Training/qf2_norm                     374.90982   243.27377  1255.85815  91.35279
log_std/mean                          -0.17675    0.00187    -0.17294    -0.18046
log_std/std                           0.13506     0.00367    0.14267     0.12822
log_std/max                           -0.11605    0.00238    -0.11175    -0.12343
log_std/min                           -0.61051    0.01396    -0.58193    -0.63496
log_probs/mean                        -1.91058    0.03164    -1.83598    -1.99090
log_probs/std                         2.58930     0.08520    2.80309     2.37638
log_probs/max                         9.27453     0.31384    9.80921     8.53036
log_probs/min                         -5.11296    0.90200    -3.88886    -8.63684
mean/mean                             -0.00473    0.00713    0.00423     -0.01836
mean/std                              0.55155     0.00994    0.56770     0.53281
mean/max                              1.76070     0.03806    1.82463     1.69089
mean/min                              -1.82388    0.01942    -1.78025    -1.86172
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [9, 1, 3, 7, 8, 4, 0, 6, 2, 5]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7780.63, -19.57, -20.39, -43.53, -27.16, -17.04, -47.81, -20.29, -28.6, -29.06]
return_array_smooth: [7700.83, -20.35, -21.21, -43.04, -26.65, -19.35, -47.73, -20.83, -27.05, -28.58][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:42:01,800 MainThread INFO: EPOCH:19
2023-08-01 19:42:01,800 MainThread INFO: Time Consumed:10.777249336242676s
2023-08-01 19:42:01,800 MainThread INFO: Total Frames:30000s
  0%|          | 20/10000 [03:24<29:52:08, 10.77s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               752.71790
Train_Epoch_Reward                    7812.17897
Running_Training_Average_Rewards      827.27572
Explore_Time                          0.01382
Train___Time                          10.75644
Eval____Time                          0.00627
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.80817
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.52972
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.04102
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.16181
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.28840
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.38991
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.57378
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7780.62693
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.05598
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.59913
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.46425     1.05727    8.34231     2.50464
alpha_0                               0.88550     0.00503    0.89436     0.87687
alpha_1                               0.55697     0.00482    0.56528     0.54874
alpha_2                               0.55697     0.00482    0.56528     0.54874
alpha_3                               0.55697     0.00482    0.56528     0.54874
alpha_4                               0.55697     0.00482    0.56528     0.54874
alpha_5                               0.55698     0.00483    0.56529     0.54874
alpha_6                               0.55697     0.00482    0.56528     0.54874
alpha_7                               0.55696     0.00482    0.56527     0.54873
alpha_8                               0.55695     0.00482    0.56526     0.54872
alpha_9                               0.55701     0.00482    0.56532     0.54878
Alpha_loss                            -3.52536    0.05270    -3.43088    -3.61326
Training/policy_loss                  -62.32300   1.05191    -60.35955   -64.65971
Training/qf1_loss                     1068.46197  335.08742  2073.35425  460.35422
Training/qf2_loss                     1064.08867  334.01285  2065.32300  458.56070
Training/pf_norm                      0.32325     0.11229    0.61365     0.12950
Training/qf1_norm                     459.11368   316.99118  1616.06714  96.54160
Training/qf2_norm                     460.34141   317.62870  1620.08167  97.25434
log_std/mean                          -0.17890    0.00272    -0.17296    -0.18304
log_std/std                           0.13701     0.00377    0.14491     0.13084
log_std/max                           -0.11819    0.00334    -0.11247    -0.12502
log_std/min                           -0.61685    0.01485    -0.58782    -0.65011
log_probs/mean                        -1.89932    0.03328    -1.80706    -1.99090
log_probs/std                         2.62161     0.08668    2.86382     2.38019
log_probs/max                         9.38244     0.26725    10.27934    8.56337
log_probs/min                         -5.01763    0.67649    -3.97792    -6.81013
mean/mean                             -0.00452    0.00356    0.00129     -0.01427
mean/std                              0.55600     0.00841    0.57973     0.53958
mean/max                              1.77318     0.03668    1.85737     1.68875
mean/min                              -1.86129    0.03589    -1.80051    -1.97223
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [7, 1, 9, 8, 3, 4, 2, 0, 5, 6]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7439.04, -22.37, -24.26, -43.42, -27.15, -22.24, -43.9, -21.25, -26.76, -30.08]
return_array_smooth: [7601.7, -20.83, -21.96, -43.16, -27.4, -19.45, -47.89, -20.85, -27.03, -29.14][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:42:12,774 MainThread INFO: EPOCH:20
2023-08-01 19:42:12,774 MainThread INFO: Time Consumed:10.77838134765625s
2023-08-01 19:42:12,774 MainThread INFO: Total Frames:31500s
  0%|          | 21/10000 [03:35<29:58:54, 10.82s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               717.76066
Train_Epoch_Reward                    8688.77964
Running_Training_Average_Rewards      824.12512
Explore_Time                          0.00958
Train___Time                          10.76243
Eval____Time                          0.00560
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.90388
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.42137
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.23888
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.14899
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.24871
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.25868
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.36804
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7439.03659
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.08277
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.75870
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.63390     0.96539    8.01440     3.48141
alpha_0                               0.90440     0.00598    0.91539     0.89457
alpha_1                               0.54050     0.00468    0.54857     0.53251
alpha_2                               0.54051     0.00468    0.54857     0.53252
alpha_3                               0.54051     0.00468    0.54857     0.53253
alpha_4                               0.54051     0.00468    0.54857     0.53252
alpha_5                               0.54051     0.00468    0.54858     0.53253
alpha_6                               0.54051     0.00468    0.54858     0.53252
alpha_7                               0.54050     0.00468    0.54857     0.53252
alpha_8                               0.54050     0.00468    0.54856     0.53251
alpha_9                               0.54055     0.00468    0.54861     0.53257
Alpha_loss                            -3.70771    0.05130    -3.61182    -3.80050
Training/policy_loss                  -65.81756   1.10314    -63.85326   -67.94739
Training/qf1_loss                     1120.62840  262.86732  1796.91370  581.25732
Training/qf2_loss                     1115.36996  261.80446  1788.49731  576.93256
Training/pf_norm                      0.31665     0.09967    0.55577     0.12330
Training/qf1_norm                     455.03927   288.37682  1519.18445  107.16925
Training/qf2_norm                     456.36698   288.84403  1523.78223  108.45857
log_std/mean                          -0.17688    0.00252    -0.17142    -0.18115
log_std/std                           0.13776     0.00399    0.14766     0.13135
log_std/max                           -0.12002    0.00372    -0.11150    -0.12539
log_std/min                           -0.61801    0.01593    -0.58598    -0.65856
log_probs/mean                        -1.87663    0.03762    -1.79419    -1.96695
log_probs/std                         2.68667     0.10126    2.90968     2.47576
log_probs/max                         9.63801     0.31940    10.46091    9.08880
log_probs/min                         -4.94692    0.90872    -3.91577    -10.05609
mean/mean                             -0.01549    0.00136    -0.01353    -0.01868
mean/std                              0.56670     0.01227    0.58971     0.54714
mean/max                              1.76592     0.03165    1.83357     1.71560
mean/min                              -1.95021    0.04792    -1.86149    -2.04353
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [7, 9, 2, 6, 3, 0, 1, 4, 5, 8]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7498.48, -20.75, -20.85, -44.23, -25.0, -20.11, -46.45, -19.35, -24.04, -30.24]
return_array_smooth: [7572.71, -20.9, -21.83, -43.73, -26.44, -19.8, -46.05, -20.3, -26.46, -29.79][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:42:24,415 MainThread INFO: EPOCH:21
2023-08-01 19:42:24,416 MainThread INFO: Time Consumed:11.449176788330078s
2023-08-01 19:42:24,416 MainThread INFO: Total Frames:33000s
  0%|          | 22/10000 [03:47<30:41:19, 11.07s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               724.74593
Train_Epoch_Reward                    7933.51083
Running_Training_Average_Rewards      814.48231
Explore_Time                          0.00668
Train___Time                          11.43531
Eval____Time                          0.00631
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.45068
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.22606
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.11063
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.00130
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.34976
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.85294
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.75080
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7498.47839
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.24065
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.03625
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.36857     0.85045    8.04428     3.41665
alpha_0                               0.92870     0.00765    0.94171     0.91565
alpha_1                               0.52452     0.00454    0.53235     0.51677
alpha_2                               0.52454     0.00454    0.53236     0.51679
alpha_3                               0.52454     0.00454    0.53237     0.51680
alpha_4                               0.52454     0.00454    0.53236     0.51679
alpha_5                               0.52454     0.00455    0.53237     0.51678
alpha_6                               0.52454     0.00454    0.53236     0.51679
alpha_7                               0.52453     0.00454    0.53236     0.51678
alpha_8                               0.52452     0.00454    0.53235     0.51677
alpha_9                               0.52459     0.00454    0.53241     0.51685
Alpha_loss                            -3.89141    0.05509    -3.78945    -3.98202
Training/policy_loss                  -68.94489   0.94818    -66.75809   -71.33562
Training/qf1_loss                     1036.92763  268.82866  1899.55005  425.89267
Training/qf2_loss                     1031.46082  267.71125  1888.90491  422.49698
Training/pf_norm                      0.34662     0.11126    0.70824     0.12336
Training/qf1_norm                     429.50006   301.94934  1861.93970  116.85523
Training/qf2_norm                     430.50907   302.88037  1868.08228  116.56124
log_std/mean                          -0.17593    0.00155    -0.17328    -0.17948
log_std/std                           0.14262     0.00387    0.14942     0.13346
log_std/max                           -0.11278    0.00184    -0.10919    -0.11744
log_std/min                           -0.63493    0.01976    -0.58572    -0.66811
log_probs/mean                        -1.84181    0.02953    -1.78730    -1.92648
log_probs/std                         2.78865     0.07409    2.92743     2.55347
log_probs/max                         9.97791     0.24065    10.40512    9.23137
log_probs/min                         -5.12480    1.00490    -3.94979    -11.52259
mean/mean                             -0.01780    0.00409    -0.01200    -0.02538
mean/std                              0.58057     0.00628    0.59196     0.56005
mean/max                              1.81860     0.02224    1.86546     1.77702
mean/min                              -2.00625    0.03483    -1.92111    -2.06789
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [6, 1, 3, 4, 9, 8, 0, 2, 7, 5]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7328.76, -23.23, -18.62, -47.37, -25.12, -23.43, -48.07, -19.48, -23.32, -33.12]
return_array_smooth: [7422.09, -22.12, -21.24, -45.0, -25.76, -21.93, -46.14, -20.03, -24.71, -31.15][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:42:36,789 MainThread INFO: EPOCH:22
2023-08-01 19:42:36,790 MainThread INFO: Time Consumed:12.191474437713623s
2023-08-01 19:42:36,790 MainThread INFO: Total Frames:34500s
  0%|          | 23/10000 [03:59<31:44:14, 11.45s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               706.69999
Train_Epoch_Reward                    7983.78010
Running_Training_Average_Rewards      820.20235
Explore_Time                          0.00746
Train___Time                          12.17617
Eval____Time                          0.00713
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.06966
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.36551
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.42974
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.12186
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.47883
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.62040
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.22956
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7328.75828
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.12119
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.32168
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.41834     0.95376    8.66241     3.62574
alpha_0                               0.95647     0.00855    0.97113     0.94198
alpha_1                               0.50902     0.00441    0.51661     0.50149
alpha_2                               0.50903     0.00441    0.51663     0.50151
alpha_3                               0.50905     0.00441    0.51664     0.50153
alpha_4                               0.50903     0.00441    0.51663     0.50151
alpha_5                               0.50903     0.00440    0.51663     0.50152
alpha_6                               0.50903     0.00441    0.51663     0.50151
alpha_7                               0.50903     0.00441    0.51662     0.50151
alpha_8                               0.50902     0.00441    0.51662     0.50150
alpha_9                               0.50910     0.00441    0.51669     0.50158
Alpha_loss                            -4.07888    0.05518    -3.98254    -4.17075
Training/policy_loss                  -72.37496   1.33899    -69.39323   -75.86684
Training/qf1_loss                     1024.00366  286.99520  1915.00452  480.81543
Training/qf2_loss                     1018.02443  285.65560  1905.85437  478.75400
Training/pf_norm                      0.36145     0.11428    0.88144     0.13111
Training/qf1_norm                     493.95758   305.50706  1973.68726  139.12752
Training/qf2_norm                     495.51644   306.39491  1977.47778  139.09055
log_std/mean                          -0.17434    0.00243    -0.17182    -0.17998
log_std/std                           0.14150     0.00329    0.15142     0.13621
log_std/max                           -0.10660    0.00439    -0.09971    -0.11469
log_std/min                           -0.63476    0.02324    -0.59858    -0.67512
log_probs/mean                        -1.82005    0.03072    -1.74068    -1.88129
log_probs/std                         2.84821     0.07934    3.08826     2.69649
log_probs/max                         10.15378    0.28457    10.80809    9.48660
log_probs/min                         -4.98480    0.69251    -4.01736    -7.74018
mean/mean                             -0.01750    0.00208    -0.01356    -0.02341
mean/std                              0.58863     0.00750    0.61116     0.57710
mean/max                              1.85931     0.03658    1.94048     1.78480
mean/min                              -2.04989    0.01936    -2.01814    -2.11639
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [8, 0, 2, 3, 7, 4, 6, 1, 5, 9]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7393.46, -19.92, -19.5, -45.02, -25.26, -19.42, -47.14, -18.42, -28.38, -30.42]
return_array_smooth: [7406.9, -21.3, -19.66, -45.54, -25.13, -20.99, -47.22, -19.08, -25.24, -31.26][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:42:48,923 MainThread INFO: EPOCH:23
2023-08-01 19:42:48,923 MainThread INFO: Time Consumed:11.937052965164185s
2023-08-01 19:42:48,923 MainThread INFO: Total Frames:36000s
  0%|          | 24/10000 [04:11<32:18:22, 11.66s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               713.99816
Train_Epoch_Reward                    7371.22466
Running_Training_Average_Rewards      776.28385
Explore_Time                          0.01017
Train___Time                          11.91941
Eval____Time                          0.00668
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.14065
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.02168
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.42274
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.26252
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.41518
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.50095
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.92031
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7393.46145
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.42006
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.37571
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.29710     0.92335    8.23458     3.18149
alpha_0                               0.98751     0.00955    1.00406     0.97146
alpha_1                               0.49397     0.00428    0.50134     0.48667
alpha_2                               0.49399     0.00428    0.50136     0.48669
alpha_3                               0.49400     0.00428    0.50138     0.48671
alpha_4                               0.49399     0.00428    0.50136     0.48669
alpha_5                               0.49400     0.00428    0.50137     0.48670
alpha_6                               0.49399     0.00428    0.50136     0.48668
alpha_7                               0.49399     0.00428    0.50136     0.48669
alpha_8                               0.49398     0.00428    0.50135     0.48669
alpha_9                               0.49406     0.00427    0.50143     0.48677
Alpha_loss                            -4.26769    0.05616    -4.16971    -4.36621
Training/policy_loss                  -75.56995   1.29566    -72.15709   -78.42483
Training/qf1_loss                     996.15229   258.13679  1798.26062  510.68106
Training/qf2_loss                     989.84600   256.55498  1787.48364  507.33560
Training/pf_norm                      0.38295     0.12912    0.77335     0.16017
Training/qf1_norm                     494.24769   303.43809  2003.69092  127.48402
Training/qf2_norm                     494.87526   303.27389  2004.62036  127.15469
log_std/mean                          -0.17515    0.00246    -0.16918    -0.18105
log_std/std                           0.14292     0.00328    0.15111     0.13634
log_std/max                           -0.10666    0.00456    -0.10020    -0.11258
log_std/min                           -0.63345    0.01316    -0.60324    -0.66699
log_probs/mean                        -1.80094    0.03331    -1.72030    -1.88006
log_probs/std                         2.90276     0.09014    3.13578     2.69673
log_probs/max                         10.35581    0.25945    10.99674    9.86312
log_probs/min                         -5.00156    0.83226    -3.91846    -8.83778
mean/mean                             -0.01859    0.00319    -0.01305    -0.02412
mean/std                              0.59600     0.00801    0.61353     0.57924
mean/max                              1.88081     0.03189    1.96130     1.82248
mean/min                              -2.07804    0.03412    -1.99958    -2.15596
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [5, 9, 8, 1, 6, 0, 4, 7, 3, 2]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7427.64, -22.31, -21.21, -44.29, -22.99, -23.56, -53.25, -19.78, -23.66, -31.14]
return_array_smooth: [7383.29, -21.82, -19.78, -45.56, -24.46, -22.14, -49.49, -19.23, -25.12, -31.56][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:43:00,680 MainThread INFO: EPOCH:24
2023-08-01 19:43:00,682 MainThread INFO: Time Consumed:11.550973653793335s
2023-08-01 19:43:00,682 MainThread INFO: Total Frames:37500s
  0%|          | 25/10000 [04:23<32:22:50, 11.69s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               716.54410
Train_Epoch_Reward                    7252.47849
Running_Training_Average_Rewards      753.58277
Explore_Time                          0.01307
Train___Time                          11.53081
Eval____Time                          0.00640
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.24866
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.29319
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.56148
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.98909
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.78230
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.20673
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.31463
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7427.63753
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.13901
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.66145
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.35230     0.89686    8.01915     3.42406
alpha_0                               1.02177     0.01052    1.04035     1.00439
alpha_1                               0.47937     0.00415    0.48652     0.47228
alpha_2                               0.47939     0.00415    0.48654     0.47231
alpha_3                               0.47940     0.00415    0.48656     0.47232
alpha_4                               0.47939     0.00415    0.48654     0.47231
alpha_5                               0.47940     0.00415    0.48656     0.47233
alpha_6                               0.47938     0.00415    0.48654     0.47229
alpha_7                               0.47938     0.00415    0.48654     0.47230
alpha_8                               0.47939     0.00415    0.48654     0.47231
alpha_9                               0.47947     0.00415    0.48662     0.47239
Alpha_loss                            -4.45860    0.05547    -4.35942    -4.55447
Training/policy_loss                  -79.20217   1.36928    -76.67435   -82.46991
Training/qf1_loss                     995.20376   262.85354  1748.95544  483.60651
Training/qf2_loss                     988.83069   261.47880  1736.72815  480.45132
Training/pf_norm                      0.42733     0.13498    0.97533     0.13446
Training/qf1_norm                     509.27621   339.81131  1739.62708  148.41350
Training/qf2_norm                     510.60270   341.44390  1744.11523  147.64549
log_std/mean                          -0.17547    0.00378    -0.16700    -0.18110
log_std/std                           0.14599     0.00392    0.15300     0.13702
log_std/max                           -0.10823    0.00303    -0.10143    -0.11440
log_std/min                           -0.65058    0.01685    -0.60620    -0.68433
log_probs/mean                        -1.77498    0.04044    -1.70472    -1.88471
log_probs/std                         2.98060     0.11115    3.17478     2.66841
log_probs/max                         10.65306    0.34889    11.29377    9.86433
log_probs/min                         -5.03486    0.90297    -3.75355    -9.59550
mean/mean                             -0.02335    0.00427    -0.01376    -0.02803
mean/std                              0.60746     0.01189    0.63315     0.58019
mean/max                              1.86551     0.05197    1.95510     1.76453
mean/min                              -2.09051    0.03258    -2.02174    -2.15421
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [3, 6, 7, 2, 5, 9, 4, 8, 0, 1]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7415.72, -20.07, -20.12, -42.51, -24.23, -18.52, -51.13, -18.91, -30.12, -27.89]
return_array_smooth: [7412.27, -20.77, -20.28, -43.94, -24.16, -20.5, -50.51, -19.04, -27.38, -29.82][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:43:12,926 MainThread INFO: EPOCH:25
2023-08-01 19:43:12,926 MainThread INFO: Time Consumed:12.079923629760742s
2023-08-01 19:43:12,926 MainThread INFO: Total Frames:39000s
  0%|          | 26/10000 [04:35<32:51:39, 11.86s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               716.22045
Train_Epoch_Reward                    7636.51321
Running_Training_Average_Rewards      742.00721
Explore_Time                          0.01647
Train___Time                          12.05727
Eval____Time                          0.00546
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.12572
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.51450
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.52425
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.23468
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.91260
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.12328
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.07113
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7415.71965
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.89249
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.11652
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.26336     0.91416    7.88857     3.04001
alpha_0                               1.06027     0.01136    1.07966     1.04075
alpha_1                               0.46520     0.00403    0.47214     0.45833
alpha_2                               0.46523     0.00403    0.47217     0.45836
alpha_3                               0.46524     0.00403    0.47218     0.45836
alpha_4                               0.46523     0.00403    0.47217     0.45835
alpha_5                               0.46526     0.00402    0.47219     0.45839
alpha_6                               0.46521     0.00403    0.47215     0.45834
alpha_7                               0.46521     0.00403    0.47216     0.45834
alpha_8                               0.46522     0.00403    0.47217     0.45835
alpha_9                               0.46531     0.00403    0.47225     0.45843
Alpha_loss                            -4.65094    0.05719    -4.55044    -4.75150
Training/policy_loss                  -82.33368   1.38939    -79.38838   -85.96886
Training/qf1_loss                     917.72282   257.99491  1785.40076  432.56509
Training/qf2_loss                     911.46461   256.24640  1772.70923  430.71426
Training/pf_norm                      0.43888     0.14206    0.80485     0.14331
Training/qf1_norm                     546.60344   351.98028  1685.96216  159.95114
Training/qf2_norm                     546.94350   353.23243  1683.34033  156.68950
log_std/mean                          -0.17553    0.00277    -0.17010    -0.18106
log_std/std                           0.14758     0.00347    0.15397     0.13761
log_std/max                           -0.10610    0.00246    -0.10117    -0.10930
log_std/min                           -0.65373    0.01650    -0.62066    -0.68660
log_probs/mean                        -1.75750    0.03371    -1.67122    -1.84458
log_probs/std                         3.02809     0.08965    3.24562     2.79809
log_probs/max                         10.80853    0.30459    11.49424    9.99924
log_probs/min                         -5.01412    0.91961    -3.89690    -9.85015
mean/mean                             -0.01777    0.00352    -0.01371    -0.02755
mean/std                              0.61443     0.00819    0.63323     0.59827
mean/max                              1.88881     0.04419    2.00234     1.80739
mean/min                              -2.12653    0.03122    -2.05851    -2.17135
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [1, 7, 2, 9, 0, 5, 4, 6, 8, 3]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7093.49, -26.51, -28.67, -43.52, -30.44, -27.38, -53.72, -23.64, -28.87, -32.7]
return_array_smooth: [7312.28, -22.96, -23.33, -43.44, -25.89, -23.16, -52.7, -20.78, -27.55, -30.58][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:43:25,460 MainThread INFO: EPOCH:26
2023-08-01 19:43:25,460 MainThread INFO: Time Consumed:12.362748146057129s
2023-08-01 19:43:25,460 MainThread INFO: Total Frames:40500s
  0%|          | 27/10000 [04:48<33:23:56, 12.06s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               679.80351
Train_Epoch_Reward                    7303.70388
Running_Training_Average_Rewards      739.75652
Explore_Time                          0.01277
Train___Time                          12.34250
Eval____Time                          0.00680
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.71657
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.52480
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -27.38032
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.44486
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.64097
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.66939
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.50810
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7093.49455
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.70013
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.87431
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.28207     0.94427    8.98083     3.05267
alpha_0                               1.09943     0.01168    1.12052     1.08006
alpha_1                               0.45145     0.00391    0.45819     0.44479
alpha_2                               0.45148     0.00391    0.45822     0.44482
alpha_3                               0.45149     0.00391    0.45822     0.44481
alpha_4                               0.45148     0.00391    0.45821     0.44481
alpha_5                               0.45152     0.00391    0.45825     0.44485
alpha_6                               0.45146     0.00391    0.45820     0.44479
alpha_7                               0.45146     0.00391    0.45820     0.44480
alpha_8                               0.45148     0.00391    0.45821     0.44481
alpha_9                               0.45155     0.00391    0.45829     0.44489
Alpha_loss                            -4.84471    0.05668    -4.74154    -4.94958
Training/policy_loss                  -85.70723   1.77238    -81.25002   -89.98586
Training/qf1_loss                     909.29396   273.02213  1877.55945  368.04062
Training/qf2_loss                     903.04923   271.32838  1864.58142  365.78708
Training/pf_norm                      0.43369     0.14299    0.85050     0.17971
Training/qf1_norm                     546.60652   361.37483  2378.64429  134.67934
Training/qf2_norm                     546.37070   362.38990  2387.01782  136.91714
log_std/mean                          -0.17393    0.00269    -0.16908    -0.17748
log_std/std                           0.14816     0.00388    0.15411     0.14182
log_std/max                           -0.10516    0.00294    -0.09997    -0.11083
log_std/min                           -0.65630    0.01645    -0.61276    -0.68199
log_probs/mean                        -1.74392    0.04232    -1.65982    -1.83258
log_probs/std                         3.06566     0.11443    3.30678     2.82253
log_probs/max                         10.91247    0.36703    11.68656    10.06988
log_probs/min                         -5.03294    0.79365    -4.04251    -8.21945
mean/mean                             -0.02420    0.00699    -0.01459    -0.03541
mean/std                              0.62005     0.01319    0.64145     0.59581
mean/max                              1.87600     0.04275    1.94039     1.80503
mean/min                              -2.16947    0.03667    -2.08084    -2.23211
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [9, 8, 7, 3, 1, 4, 5, 6, 0, 2]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7188.75, -19.3, -21.33, -44.24, -27.63, -23.83, -55.81, -17.87, -23.45, -30.23]
return_array_smooth: [7232.65, -21.96, -23.37, -43.43, -27.44, -23.24, -53.55, -20.14, -27.48, -30.28][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:43:37,611 MainThread INFO: EPOCH:27
2023-08-01 19:43:37,611 MainThread INFO: Time Consumed:11.953891038894653s
2023-08-01 19:43:37,612 MainThread INFO: Total Frames:42000s
  0%|          | 28/10000 [05:00<33:28:26, 12.08s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               692.50596
Train_Epoch_Reward                    6616.37205
Running_Training_Average_Rewards      718.55297
Explore_Time                          0.01427
Train___Time                          11.93184
Eval____Time                          0.00648
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.80978
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.24064
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.82640
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.63159
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.86953
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.32728
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.30217
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7188.75065
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.23394
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.44970
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.33376     0.90939    8.52114     2.65358
alpha_0                               1.14376     0.01331    1.16673     1.12097
alpha_1                               0.43812     0.00379    0.44466     0.43165
alpha_2                               0.43814     0.00379    0.44468     0.43167
alpha_3                               0.43814     0.00379    0.44468     0.43167
alpha_4                               0.43814     0.00379    0.44467     0.43167
alpha_5                               0.43819     0.00379    0.44472     0.43172
alpha_6                               0.43812     0.00380    0.44466     0.43164
alpha_7                               0.43813     0.00379    0.44466     0.43165
alpha_8                               0.43814     0.00379    0.44468     0.43167
alpha_9                               0.43821     0.00380    0.44475     0.43173
Alpha_loss                            -5.04433    0.05703    -4.94097    -5.13896
Training/policy_loss                  -89.39122   1.71506    -84.26592   -93.64896
Training/qf1_loss                     887.29028   242.91921  1660.27930  363.84344
Training/qf2_loss                     881.46389   241.31156  1647.27527  361.54135
Training/pf_norm                      0.49104     0.17308    1.01877     0.17532
Training/qf1_norm                     570.18244   336.39118  2067.95386  162.57837
Training/qf2_norm                     569.83281   336.94371  2067.78101  161.28578
log_std/mean                          -0.17626    0.00241    -0.17167    -0.18384
log_std/std                           0.14729     0.00332    0.15541     0.14058
log_std/max                           -0.10786    0.00305    -0.10367    -0.11457
log_std/min                           -0.64546    0.01691    -0.60881    -0.68347
log_probs/mean                        -1.70585    0.03268    -1.62426    -1.78148
log_probs/std                         3.17663     0.08736    3.41244     3.00283
log_probs/max                         11.29701    0.24814    11.92459    10.79549
log_probs/min                         -4.91145    0.66765    -3.87251    -7.17969
mean/mean                             -0.00724    0.00277    -0.00124    -0.01361
mean/std                              0.63373     0.00675    0.65283     0.62257
mean/max                              1.96036     0.02714    2.03796     1.90920
mean/min                              -2.19331    0.03298    -2.14317    -2.27374
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [3, 5, 4, 2, 6, 1, 8, 7, 9, 0]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7126.55, -22.62, -20.95, -40.97, -26.13, -32.06, -48.62, -18.04, -22.37, -29.54]
return_array_smooth: [7136.27, -22.81, -23.65, -42.91, -28.07, -27.76, -52.72, -19.85, -24.9, -30.82][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:43:50,829 MainThread INFO: EPOCH:28
2023-08-01 19:43:50,829 MainThread INFO: Time Consumed:12.998273372650146s
2023-08-01 19:43:50,829 MainThread INFO: Total Frames:43500s
  0%|          | 29/10000 [05:13<34:25:13, 12.43s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               686.52440
Train_Epoch_Reward                    7291.00436
Running_Training_Average_Rewards      707.03601
Explore_Time                          0.01369
Train___Time                          12.97750
Eval____Time                          0.00630
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.62398
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.96878
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -32.06174
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.12624
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.04226
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94785
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.62496
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7126.55475
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.54079
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.37411
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.16436     0.97165    7.42470     3.07639
alpha_0                               1.19157     0.01413    1.21576     1.16719
alpha_1                               0.42518     0.00368    0.43152     0.41890
alpha_2                               0.42520     0.00368    0.43154     0.41891
alpha_3                               0.42519     0.00368    0.43154     0.41891
alpha_4                               0.42519     0.00368    0.43154     0.41891
alpha_5                               0.42525     0.00368    0.43159     0.41897
alpha_6                               0.42517     0.00368    0.43151     0.41888
alpha_7                               0.42519     0.00368    0.43153     0.41891
alpha_8                               0.42519     0.00368    0.43154     0.41891
alpha_9                               0.42526     0.00368    0.43160     0.41897
Alpha_loss                            -5.24416    0.05702    -5.14178    -5.34653
Training/policy_loss                  -92.60232   1.97755    -87.82646   -97.96367
Training/qf1_loss                     836.87470   238.80335  1448.13965  408.75806
Training/qf2_loss                     832.27824   237.27445  1440.18640  407.03458
Training/pf_norm                      0.49055     0.17512    1.07421     0.17875
Training/qf1_norm                     631.22472   367.99053  1713.01294  184.86798
Training/qf2_norm                     630.77625   367.96497  1717.29529  184.13107
log_std/mean                          -0.17828    0.00200    -0.17446    -0.18306
log_std/std                           0.15050     0.00324    0.15702     0.14268
log_std/max                           -0.11162    0.00278    -0.10544    -0.11663
log_std/min                           -0.66292    0.01725    -0.62768    -0.69724
log_probs/mean                        -1.67977    0.03089    -1.59171    -1.75804
log_probs/std                         3.25220     0.08111    3.50757     3.05488
log_probs/max                         11.55156    0.23212    12.08729    11.02475
log_probs/min                         -4.97767    0.77347    -3.79910    -7.27843
mean/mean                             -0.01043    0.00355    -0.00583    -0.01761
mean/std                              0.64531     0.00635    0.65952     0.63469
mean/max                              2.03913     0.03597    2.11669     1.96849
mean/min                              -2.21702    0.02909    -2.14660    -2.26471
------------------------------------  ----------  ---------  ----------  ---------
self.update_end_epoch 7000
sample: [4, 7, 3, 1, 2, 5, 0, 8, 9, 6]
replay_buffer._size: [4652 4654 4654 4655 4652 4654 4652 4650 4651 4650]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7092.91, -21.65, -21.12, -39.79, -24.69, -29.7, -43.32, -19.44, -22.87, -25.96]
return_array_smooth: [7136.07, -21.19, -21.13, -41.67, -26.15, -28.53, -49.25, -18.45, -22.9, -28.58][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:44:03,653 MainThread INFO: EPOCH:29
2023-08-01 19:44:03,654 MainThread INFO: Time Consumed:12.560153245925903s
2023-08-01 19:44:03,654 MainThread INFO: Total Frames:45000s
  0%|          | 30/10000 [05:26<34:47:30, 12.56s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               684.43657
Train_Epoch_Reward                    6847.88331
Running_Training_Average_Rewards      691.84199
Explore_Time                          0.08907
Train___Time                          12.46476
Eval____Time                          0.00563
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.31954
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.78818
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -29.69842
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.69292
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.43594
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.12414
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.65339
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7092.91070
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.95756
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.87491
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.18170     0.92749    7.40415     2.05139
alpha_0                               1.24110     0.01446    1.26603     1.21626
alpha_1                               0.41261     0.00357    0.41877     0.40652
alpha_2                               0.41263     0.00357    0.41879     0.40653
alpha_3                               0.41263     0.00357    0.41878     0.40653
alpha_4                               0.41263     0.00357    0.41878     0.40653
alpha_5                               0.41269     0.00357    0.41884     0.40659
alpha_6                               0.41260     0.00357    0.41876     0.40650
alpha_7                               0.41263     0.00357    0.41878     0.40653
alpha_8                               0.41263     0.00357    0.41879     0.40653
alpha_9                               0.41269     0.00358    0.41885     0.40658
Alpha_loss                            -5.44448    0.05841    -5.34054    -5.55161
Training/policy_loss                  -96.08471   1.82597    -91.75561   -101.19570
Training/qf1_loss                     828.46495   218.71233  1423.36121  290.77618
Training/qf2_loss                     824.60015   217.30226  1415.37292  290.68256
Training/pf_norm                      0.52998     0.18513    1.26767     0.15618
Training/qf1_norm                     655.61259   362.44441  2004.32361  167.62500
Training/qf2_norm                     656.07550   364.27337  2011.60779  163.88026
log_std/mean                          -0.17849    0.00273    -0.17045    -0.18299
log_std/std                           0.15003     0.00359    0.15682     0.13999
log_std/max                           -0.10810    0.00292    -0.10429    -0.11450
log_std/min                           -0.66326    0.02089    -0.61915    -0.69948
log_probs/mean                        -1.67114    0.03231    -1.59005    -1.76494
log_probs/std                         3.28065     0.08659    3.45555     3.00325
log_probs/max                         11.61664    0.29392    12.19004    10.82764
log_probs/min                         -5.02992    1.02250    -3.75032    -10.77362
mean/mean                             -0.00574    0.00238    -0.00138    -0.00852
mean/std                              0.64859     0.00869    0.66313     0.62890
mean/max                              2.10162     0.04607    2.18588     1.99721
mean/min                              -2.18898    0.03674    -2.12441    -2.26851
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [7, 0, 6, 9, 3, 5, 4, 2, 8, 1]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [6983.73, -24.35, -22.58, -39.15, -28.59, -25.23, -50.21, -21.8, -24.92, -26.36]
return_array_smooth: [7067.73, -22.88, -21.55, -39.97, -26.47, -29.0, -47.39, -19.76, -23.39, -27.29][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:44:16,403 MainThread INFO: EPOCH:30
2023-08-01 19:44:16,404 MainThread INFO: Time Consumed:12.46686601638794s
2023-08-01 19:44:16,404 MainThread INFO: Total Frames:46500s
  0%|          | 31/10000 [05:39<34:53:31, 12.60s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               672.05160
Train_Epoch_Reward                    7006.13441
Running_Training_Average_Rewards      704.83407
Explore_Time                          0.03545
Train___Time                          12.42525
Eval____Time                          0.00521
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.21448
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.15324
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -25.22918
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.59303
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.80430
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.58499
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.34993
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6983.73299
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.36300
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.92480
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.38581     0.93998    8.00135     3.11454
alpha_0                               1.29209     0.01494    1.31750     1.26653
alpha_1                               0.40042     0.00347    0.40640     0.39451
alpha_2                               0.40043     0.00347    0.40641     0.39451
alpha_3                               0.40044     0.00347    0.40641     0.39452
alpha_4                               0.40044     0.00347    0.40641     0.39452
alpha_5                               0.40049     0.00347    0.40647     0.39457
alpha_6                               0.40041     0.00347    0.40638     0.39449
alpha_7                               0.40043     0.00347    0.40641     0.39452
alpha_8                               0.40043     0.00347    0.40641     0.39451
alpha_9                               0.40048     0.00347    0.40646     0.39456
Alpha_loss                            -5.64425    0.05569    -5.53725    -5.74777
Training/policy_loss                  -100.11582  2.26475    -95.53594   -106.64282
Training/qf1_loss                     824.72797   218.34670  1303.23560  406.60983
Training/qf2_loss                     821.64726   217.35708  1298.11646  404.87506
Training/pf_norm                      0.57037     0.20366    1.35251     0.20829
Training/qf1_norm                     704.72000   374.80485  1706.50146  207.63106
Training/qf2_norm                     704.69413   376.26717  1719.32471  204.40849
log_std/mean                          -0.17616    0.00418    -0.16941    -0.18321
log_std/std                           0.14864     0.00368    0.15584     0.13911
log_std/max                           -0.11085    0.00446    -0.10288    -0.11716
log_std/min                           -0.65536    0.01669    -0.62025    -0.68801
log_probs/mean                        -1.66081    0.02708    -1.59375    -1.73327
log_probs/std                         3.30854     0.07462    3.44568     3.06887
log_probs/max                         11.72807    0.21627    12.21277    11.02035
log_probs/min                         -4.86842    0.59946    -3.76716    -6.83987
mean/mean                             -0.01208    0.01207    0.00236     -0.02991
mean/std                              0.65176     0.00666    0.66275     0.63290
mean/max                              2.12882     0.03373    2.18391     2.04117
mean/min                              -2.21773    0.03860    -2.12577    -2.29096
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [9, 4, 7, 1, 3, 2, 5, 8, 0, 6]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [6979.98, -22.79, -20.38, -40.57, -28.98, -22.63, -48.02, -21.21, -28.01, -26.44]
return_array_smooth: [7018.87, -22.93, -21.36, -39.84, -27.42, -25.85, -47.19, -20.82, -25.27, -26.25][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:44:29,509 MainThread INFO: EPOCH:31
2023-08-01 19:44:29,510 MainThread INFO: Time Consumed:12.91714334487915s
2023-08-01 19:44:29,510 MainThread INFO: Total Frames:48000s
  0%|          | 32/10000 [05:52<35:19:55, 12.76s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               672.09541
Train_Epoch_Reward                    6719.82789
Running_Training_Average_Rewards      685.79485
Explore_Time                          0.01365
Train___Time                          12.89697
Eval____Time                          0.00581
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.02347
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.57066
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.62910
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.97756
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.20714
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.37687
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.78576
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6979.97624
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.44040
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.01120
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.21866     1.01864    8.50457     3.52689
alpha_0                               1.34357     0.01509    1.36971     1.31801
alpha_1                               0.38860     0.00336    0.39439     0.38285
alpha_2                               0.38860     0.00336    0.39439     0.38286
alpha_3                               0.38861     0.00337    0.39441     0.38287
alpha_4                               0.38860     0.00337    0.39440     0.38286
alpha_5                               0.38865     0.00337    0.39445     0.38291
alpha_6                               0.38858     0.00336    0.39437     0.38284
alpha_7                               0.38860     0.00336    0.39440     0.38286
alpha_8                               0.38860     0.00336    0.39439     0.38286
alpha_9                               0.38864     0.00337    0.39444     0.38290
Alpha_loss                            -5.84210    0.06028    -5.73105    -5.94749
Training/policy_loss                  -102.63976  2.32558    -97.15884   -109.05492
Training/qf1_loss                     802.95848   220.76650  1430.04041  317.74356
Training/qf2_loss                     800.62717   219.79318  1424.03601  317.28195
Training/pf_norm                      0.53821     0.17691    1.14703     0.21119
Training/qf1_norm                     747.24655   448.80120  2097.52563  182.68909
Training/qf2_norm                     748.12447   449.56217  2085.70996  181.26102
log_std/mean                          -0.17717    0.00422    -0.16783    -0.18413
log_std/std                           0.15099     0.00436    0.15833     0.14243
log_std/max                           -0.10512    0.00376    -0.09924    -0.11272
log_std/min                           -0.65587    0.01652    -0.62652    -0.68655
log_probs/mean                        -1.65448    0.03197    -1.58223    -1.73828
log_probs/std                         3.32520     0.08666    3.49964     3.09898
log_probs/max                         11.78277    0.24655    12.23483    11.09379
log_probs/min                         -4.92170    0.78412    -3.66374    -8.15864
mean/mean                             -0.01796    0.00629    -0.01114    -0.02999
mean/std                              0.65363     0.00710    0.66776     0.63463
mean/max                              2.05363     0.02575    2.09972     1.97263
mean/min                              -2.24468    0.03056    -2.19079    -2.32913
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [9, 7, 3, 1, 4, 2, 8, 6, 0, 5]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7024.61, -15.49, -16.13, -43.67, -25.93, -20.5, -54.21, -14.21, -27.02, -29.16]
return_array_smooth: [6996.11, -20.88, -19.7, -41.13, -27.83, -22.78, -50.82, -19.07, -26.65, -27.32][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:44:42,521 MainThread INFO: EPOCH:32
2023-08-01 19:44:42,522 MainThread INFO: Time Consumed:12.815051317214966s
2023-08-01 19:44:42,522 MainThread INFO: Total Frames:49500s
  0%|          | 33/10000 [06:05<35:30:59, 12.83s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               677.82930
Train_Epoch_Reward                    6758.59143
Running_Training_Average_Rewards      682.81846
Explore_Time                          0.00809
Train___Time                          12.80082
Eval____Time                          0.00552
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.21114
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.66836
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.49528
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.93047
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -14.20741
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -16.13258
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.49124
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7024.60894
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.15868
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.02079
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.06085     1.01742    7.87264     2.51706
alpha_0                               1.39643     0.01549    1.42298     1.37024
alpha_1                               0.37711     0.00326    0.38274     0.37154
alpha_2                               0.37712     0.00326    0.38274     0.37155
alpha_3                               0.37713     0.00326    0.38275     0.37156
alpha_4                               0.37712     0.00327    0.38275     0.37155
alpha_5                               0.37716     0.00327    0.38279     0.37158
alpha_6                               0.37710     0.00327    0.38273     0.37153
alpha_7                               0.37712     0.00327    0.38275     0.37155
alpha_8                               0.37712     0.00327    0.38274     0.37154
alpha_9                               0.37715     0.00327    0.38278     0.37157
Alpha_loss                            -6.04307    0.06073    -5.92972    -6.16971
Training/policy_loss                  -105.68748  2.68541    -99.52206   -111.50112
Training/qf1_loss                     758.32897   231.51356  1372.48376  316.28790
Training/qf2_loss                     756.86336   230.73189  1368.46899  316.11383
Training/pf_norm                      0.62602     0.23645    1.46626     0.24450
Training/qf1_norm                     836.35877   524.74168  2782.01440  168.80948
Training/qf2_norm                     837.21331   525.49660  2788.27271  165.47736
log_std/mean                          -0.17819    0.00249    -0.17457    -0.18341
log_std/std                           0.15157     0.00417    0.15884     0.14332
log_std/max                           -0.10686    0.00393    -0.10042    -0.11369
log_std/min                           -0.65936    0.01731    -0.62455    -0.70323
log_probs/mean                        -1.64921    0.04005    -1.55155    -1.74645
log_probs/std                         3.34474     0.10711    3.57746     3.07334
log_probs/max                         11.84085    0.30605    12.47274    11.16360
log_probs/min                         -5.04491    0.79665    -3.97812    -7.72155
mean/mean                             -0.01702    0.00537    -0.00852    -0.02901
mean/std                              0.65600     0.01079    0.67696     0.63890
mean/max                              2.05597     0.04359    2.14065     1.96803
mean/min                              -2.24068    0.03423    -2.18724    -2.32669
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [5, 4, 1, 8, 0, 3, 9, 7, 2, 6]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7138.75, -20.19, -28.54, -38.64, -24.11, -20.16, -48.86, -20.07, -28.72, -25.13]
return_array_smooth: [7047.78, -19.49, -21.68, -40.96, -26.34, -21.09, -50.37, -18.5, -27.92, -26.91][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:44:56,605 MainThread INFO: EPOCH:33
2023-08-01 19:44:56,606 MainThread INFO: Time Consumed:13.884902238845825s
2023-08-01 19:44:56,606 MainThread INFO: Total Frames:51000s
  0%|          | 34/10000 [06:19<36:32:25, 13.20s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               688.43321
Train_Epoch_Reward                    6796.57186
Running_Training_Average_Rewards      675.83304
Explore_Time                          0.00957
Train___Time                          13.86851
Eval____Time                          0.00590
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.86135
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -38.64085
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.15501
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.11053
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.07379
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.54048
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.18620
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7138.74968
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.13049
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.71887
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.12539     1.02350    7.48205     2.11051
alpha_0                               1.44911     0.01489    1.47487     1.42353
alpha_1                               0.36597     0.00317    0.37143     0.36057
alpha_2                               0.36598     0.00317    0.37144     0.36057
alpha_3                               0.36599     0.00317    0.37145     0.36058
alpha_4                               0.36597     0.00317    0.37143     0.36056
alpha_5                               0.36600     0.00317    0.37147     0.36059
alpha_6                               0.36596     0.00317    0.37142     0.36055
alpha_7                               0.36598     0.00317    0.37144     0.36058
alpha_8                               0.36597     0.00317    0.37143     0.36056
alpha_9                               0.36600     0.00317    0.37146     0.36059
Alpha_loss                            -6.23324    0.06109    -6.12230    -6.34510
Training/policy_loss                  -108.88294  3.15622    -100.81274  -117.21568
Training/qf1_loss                     742.42676   184.50228  1231.12854  245.01639
Training/qf2_loss                     741.41022   184.03435  1229.41113  246.27278
Training/pf_norm                      0.62269     0.21502    1.22122     0.16518
Training/qf1_norm                     749.02706   426.69821  2298.43604  233.66438
Training/qf2_norm                     749.96646   428.55175  2307.40454  231.59914
log_std/mean                          -0.17561    0.00281    -0.17042    -0.18164
log_std/std                           0.15031     0.00522    0.16192     0.14029
log_std/max                           -0.10454    0.00368    -0.09470    -0.10953
log_std/min                           -0.65918    0.02920    -0.60243    -0.71510
log_probs/mean                        -1.66526    0.03521    -1.59770    -1.76334
log_probs/std                         3.29607     0.10012    3.52525     3.01660
log_probs/max                         11.69330    0.27891    12.25007    11.04010
log_probs/min                         -4.99003    0.66267    -3.91170    -7.07701
mean/mean                             -0.02221    0.00535    -0.01501    -0.02958
mean/std                              0.65043     0.00914    0.66623     0.63123
mean/max                              2.02716     0.03674    2.10327     1.93932
mean/min                              -2.21399    0.03367    -2.14046    -2.28010
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [4, 7, 8, 5, 2, 0, 3, 1, 6, 9]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7010.68, -20.97, -27.73, -42.66, -28.24, -14.82, -52.82, -19.04, -28.35, -28.48]
return_array_smooth: [7058.01, -18.88, -24.14, -41.66, -26.09, -18.49, -51.96, -17.77, -28.03, -27.59][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:45:10,163 MainThread INFO: EPOCH:34
2023-08-01 19:45:10,163 MainThread INFO: Time Consumed:13.390110731124878s
2023-08-01 19:45:10,163 MainThread INFO: Total Frames:52500s
  0%|          | 35/10000 [06:32<36:51:06, 13.31s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               674.75643
Train_Epoch_Reward                    6979.15548
Running_Training_Average_Rewards      684.47729
Explore_Time                          0.01097
Train___Time                          13.37048
Eval____Time                          0.00797
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.81580
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.66025
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.81690
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.24090
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.04140
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.73490
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97459
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7010.67835
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.48233
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.34699
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.05862     0.94189    7.18386     2.84253
alpha_0                               1.50203     0.01555    1.52895     1.47540
alpha_1                               0.35516     0.00307    0.36046     0.34992
alpha_2                               0.35516     0.00308    0.36046     0.34991
alpha_3                               0.35517     0.00308    0.36047     0.34992
alpha_4                               0.35515     0.00308    0.36045     0.34990
alpha_5                               0.35518     0.00308    0.36049     0.34993
alpha_6                               0.35514     0.00307    0.36044     0.34990
alpha_7                               0.35517     0.00308    0.36047     0.34992
alpha_8                               0.35515     0.00308    0.36045     0.34990
alpha_9                               0.35517     0.00308    0.36048     0.34992
Alpha_loss                            -6.43636    0.05978    -6.33837    -6.53903
Training/policy_loss                  -111.27585  3.35885    -104.74291  -118.72981
Training/qf1_loss                     720.05620   189.64708  1225.23267  286.15121
Training/qf2_loss                     719.42332   189.32145  1223.05554  286.79831
Training/pf_norm                      0.60297     0.19192    1.11424     0.17393
Training/qf1_norm                     744.87883   412.29809  2264.45288  185.65439
Training/qf2_norm                     745.87938   413.47748  2269.47192  184.02470
log_std/mean                          -0.17783    0.00223    -0.17344    -0.18225
log_std/std                           0.15026     0.00411    0.15813     0.14194
log_std/max                           -0.10942    0.00382    -0.09689    -0.11737
log_std/min                           -0.66254    0.01645    -0.62847    -0.70216
log_probs/mean                        -1.65297    0.03112    -1.58360    -1.71473
log_probs/std                         3.33869     0.08526    3.52517     3.18096
log_probs/max                         11.85743    0.24806    12.47878    11.28406
log_probs/min                         -5.03316    0.79401    -3.86184    -8.30324
mean/mean                             -0.01384    0.00227    -0.01073    -0.01858
mean/std                              0.65627     0.00721    0.67243     0.64236
mean/max                              2.04813     0.02905    2.12089     2.00659
mean/min                              -2.25250    0.02946    -2.18839    -2.31490
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [3, 9, 6, 5, 4, 7, 2, 0, 1, 8]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7041.07, -22.84, -20.0, -40.66, -23.44, -18.96, -42.2, -22.6, -23.68, -27.07]
return_array_smooth: [7063.5, -21.33, -25.42, -40.65, -25.26, -17.98, -47.96, -20.57, -26.91, -26.89][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:45:24,370 MainThread INFO: EPOCH:35
2023-08-01 19:45:24,371 MainThread INFO: Time Consumed:14.043748617172241s
2023-08-01 19:45:24,371 MainThread INFO: Total Frames:54000s
  0%|          | 36/10000 [06:47<37:36:31, 13.59s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               679.96391
Train_Epoch_Reward                    6629.75180
Running_Training_Average_Rewards      680.18264
Explore_Time                          0.00860
Train___Time                          14.02771
Eval____Time                          0.00673
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.20037
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.66270
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.95670
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.43995
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.59865
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.99568
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.83612
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7041.07362
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.06550
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.67886
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.06650     0.92183    7.11252     2.87789
alpha_0                               1.55722     0.01609    1.58437     1.52951
alpha_1                               0.34467     0.00298    0.34981     0.33958
alpha_2                               0.34467     0.00298    0.34981     0.33958
alpha_3                               0.34467     0.00299    0.34982     0.33958
alpha_4                               0.34465     0.00299    0.34979     0.33955
alpha_5                               0.34468     0.00299    0.34983     0.33959
alpha_6                               0.34465     0.00298    0.34979     0.33956
alpha_7                               0.34467     0.00299    0.34981     0.33958
alpha_8                               0.34465     0.00299    0.34980     0.33956
alpha_9                               0.34467     0.00299    0.34982     0.33958
Alpha_loss                            -6.63278    0.05400    -6.52005    -6.76006
Training/policy_loss                  -114.39177  3.33288    -106.91257  -120.66315
Training/qf1_loss                     725.03415   198.85943  1302.15649  349.06885
Training/qf2_loss                     724.84771   198.49215  1300.47791  350.21982
Training/pf_norm                      0.64638     0.22543    1.54758     0.17139
Training/qf1_norm                     817.78349   433.35850  2422.10498  189.25888
Training/qf2_norm                     819.71916   434.45163  2432.20312  193.03821
log_std/mean                          -0.17863    0.00335    -0.17105    -0.18586
log_std/std                           0.15191     0.00356    0.15862     0.14289
log_std/max                           -0.10902    0.00388    -0.10289    -0.11867
log_std/min                           -0.66561    0.02317    -0.61826    -0.71082
log_probs/mean                        -1.65013    0.03155    -1.56961    -1.73982
log_probs/std                         3.34422     0.08807    3.53467     3.10660
log_probs/max                         11.83357    0.29119    12.41087    11.21115
log_probs/min                         -5.07002    0.83087    -3.83746    -8.61204
mean/mean                             -0.01065    0.00508    -0.00303    -0.01894
mean/std                              0.65626     0.00823    0.67465     0.63943
mean/max                              2.07489     0.04702    2.16659     1.99458
mean/min                              -2.22786    0.03785    -2.16074    -2.30825
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [5, 4, 7, 3, 8, 0, 2, 6, 9, 1]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7111.18, -17.99, -15.4, -40.65, -22.97, -20.19, -45.86, -19.35, -25.36, -27.74]
return_array_smooth: [7054.31, -20.6, -21.04, -41.32, -24.88, -17.99, -46.96, -20.33, -25.79, -27.76][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:45:39,533 MainThread INFO: EPOCH:36
2023-08-01 19:45:39,534 MainThread INFO: Time Consumed:14.95882248878479s
2023-08-01 19:45:39,534 MainThread INFO: Total Frames:55500s
  0%|          | 37/10000 [07:02<38:54:50, 14.06s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               687.56716
Train_Epoch_Reward                    6678.11446
Running_Training_Average_Rewards      676.23406
Explore_Time                          0.02382
Train___Time                          14.92755
Eval____Time                          0.00665
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.85640
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.65080
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.19120
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.97321
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.35146
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -15.40417
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.99092
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7111.18035
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.73523
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.35532
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.21039     1.00820    7.51772     2.54767
alpha_0                               1.61247     0.01612    1.63978     1.58491
alpha_1                               0.33449     0.00290    0.33948     0.32954
alpha_2                               0.33449     0.00290    0.33948     0.32955
alpha_3                               0.33449     0.00290    0.33947     0.32954
alpha_4                               0.33446     0.00290    0.33945     0.32952
alpha_5                               0.33449     0.00290    0.33948     0.32955
alpha_6                               0.33446     0.00290    0.33946     0.32952
alpha_7                               0.33448     0.00290    0.33947     0.32954
alpha_8                               0.33446     0.00290    0.33946     0.32952
alpha_9                               0.33448     0.00290    0.33948     0.32954
Alpha_loss                            -6.82560    0.05274    -6.71240    -6.93021
Training/policy_loss                  -116.96443  3.72548    -107.29176  -126.00893
Training/qf1_loss                     714.26249   190.01866  1189.36035  211.56905
Training/qf2_loss                     714.08760   189.70697  1188.23560  211.36670
Training/pf_norm                      0.64034     0.20816    1.10401     0.23889
Training/qf1_norm                     914.58669   476.74691  2349.72046  253.02448
Training/qf2_norm                     916.07722   477.74009  2349.21094  252.26224
log_std/mean                          -0.17822    0.00242    -0.17391    -0.18278
log_std/std                           0.14799     0.00426    0.15935     0.14084
log_std/max                           -0.11144    0.00476    -0.10277    -0.11804
log_std/min                           -0.65498    0.02108    -0.61061    -0.70022
log_probs/mean                        -1.65616    0.03007    -1.58900    -1.71192
log_probs/std                         3.32448     0.08184    3.50488     3.18101
log_probs/max                         11.79165    0.27370    12.24421    10.74280
log_probs/min                         -4.99514    0.65213    -3.99993    -6.88987
mean/mean                             -0.01967    0.00647    -0.00710    -0.02649
mean/std                              0.65433     0.00754    0.67067     0.64065
mean/max                              2.08417     0.03639    2.19728     2.03029
mean/min                              -2.22812    0.03006    -2.17702    -2.28430
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [0, 6, 3, 1, 4, 5, 2, 8, 7, 9]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7067.51, -19.51, -27.73, -40.15, -29.53, -12.94, -51.58, -18.99, -26.68, -27.09]
return_array_smooth: [7073.25, -20.11, -21.04, -40.49, -25.31, -17.36, -46.54, -20.31, -25.24, -27.3][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:45:53,976 MainThread INFO: EPOCH:37
2023-08-01 19:45:53,976 MainThread INFO: Time Consumed:14.245994329452515s
2023-08-01 19:45:53,976 MainThread INFO: Total Frames:57000s
  0%|          | 38/10000 [07:16<39:13:41, 14.18s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               681.33196
Train_Epoch_Reward                    6824.77039
Running_Training_Average_Rewards      671.08789
Explore_Time                          0.01891
Train___Time                          14.21987
Eval____Time                          0.00647
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.57688
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.14501
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.94366
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.53026
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.99009
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.72547
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.51149
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7067.50852
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.08756
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.67852
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.09092     0.91046    7.05293     3.20503
alpha_0                               1.66756     0.01589    1.69502     1.64032
alpha_1                               0.32461     0.00281    0.32945     0.31981
alpha_2                               0.32461     0.00281    0.32945     0.31981
alpha_3                               0.32460     0.00281    0.32945     0.31981
alpha_4                               0.32458     0.00281    0.32942     0.31978
alpha_5                               0.32460     0.00281    0.32945     0.31980
alpha_6                               0.32458     0.00281    0.32942     0.31978
alpha_7                               0.32460     0.00281    0.32944     0.31980
alpha_8                               0.32458     0.00281    0.32942     0.31978
alpha_9                               0.32460     0.00281    0.32944     0.31980
Alpha_loss                            -7.01577    0.05908    -6.91175    -7.12328
Training/policy_loss                  -120.04194  4.17649    -111.67767  -131.66518
Training/qf1_loss                     680.15907   168.30027  1066.36560  355.50812
Training/qf2_loss                     680.11327   168.09900  1065.85205  356.35083
Training/pf_norm                      0.69018     0.25388    1.77555     0.22180
Training/qf1_norm                     901.51179   487.99584  2438.64209  194.26143
Training/qf2_norm                     902.84982   488.50761  2440.74683  191.68202
log_std/mean                          -0.17612    0.00346    -0.16943    -0.18308
log_std/std                           0.15081     0.00391    0.15842     0.14380
log_std/max                           -0.11122    0.00478    -0.09990    -0.11852
log_std/min                           -0.65573    0.01770    -0.61867    -0.69004
log_probs/mean                        -1.66161    0.03520    -1.58279    -1.77960
log_probs/std                         3.30433     0.09329    3.47231     3.03702
log_probs/max                         11.71984    0.25931    12.33927    11.02480
log_probs/min                         -4.88875    0.64916    -3.55203    -6.59042
mean/mean                             -0.01494    0.00507    -0.00806    -0.02456
mean/std                              0.65125     0.00730    0.66517     0.63595
mean/max                              2.05940     0.02807    2.11953     2.01018
mean/min                              -2.20058    0.03210    -2.14097    -2.27925
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [5, 9, 1, 0, 3, 8, 2, 4, 6, 7]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [6996.02, -15.31, -35.69, -42.53, -31.72, -11.8, -53.55, -17.91, -29.97, -28.28]
return_array_smooth: [7058.24, -17.6, -26.27, -41.11, -28.07, -14.98, -50.33, -18.75, -27.33, -27.7][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:46:08,037 MainThread INFO: EPOCH:38
2023-08-01 19:46:08,038 MainThread INFO: Time Consumed:13.873229265213013s
2023-08-01 19:46:08,038 MainThread INFO: Total Frames:58500s
  0%|          | 39/10000 [07:30<39:06:00, 14.13s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               672.92631
Train_Epoch_Reward                    6766.34506
Running_Training_Average_Rewards      675.64100
Explore_Time                          0.01131
Train___Time                          13.85517
Eval____Time                          0.00607
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.54796
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.53223
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.79748
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.71859
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.91222
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -35.68782
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.31172
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6996.01699
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.28049
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.96537
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.08585     0.95628    7.15538     2.93638
alpha_0                               1.72432     0.01676    1.75307     1.69558
alpha_1                               0.31502     0.00273    0.31972     0.31037
alpha_2                               0.31501     0.00273    0.31972     0.31036
alpha_3                               0.31502     0.00273    0.31971     0.31036
alpha_4                               0.31499     0.00273    0.31969     0.31034
alpha_5                               0.31500     0.00273    0.31971     0.31035
alpha_6                               0.31498     0.00273    0.31968     0.31033
alpha_7                               0.31500     0.00273    0.31970     0.31035
alpha_8                               0.31499     0.00273    0.31969     0.31033
alpha_9                               0.31500     0.00273    0.31970     0.31035
Alpha_loss                            -7.21640    0.05687    -7.09822    -7.33174
Training/policy_loss                  -122.55366  4.36704    -113.10361  -135.63652
Training/qf1_loss                     669.86140   171.27437  1177.58948  301.27808
Training/qf2_loss                     670.00004   171.22845  1177.52405  302.14932
Training/pf_norm                      0.73115     0.24657    1.63742     0.19540
Training/qf1_norm                     947.31181   577.99440  2903.62939  104.90493
Training/qf2_norm                     949.39060   579.49894  2933.11719  105.33178
log_std/mean                          -0.17785    0.00255    -0.17128    -0.18313
log_std/std                           0.14891     0.00452    0.15565     0.14019
log_std/max                           -0.11470    0.00249    -0.10914    -0.11942
log_std/min                           -0.65197    0.02258    -0.60399    -0.69252
log_probs/mean                        -1.65049    0.03296    -1.57549    -1.72586
log_probs/std                         3.33479     0.09162    3.54891     3.12339
log_probs/max                         11.88168    0.28462    12.57770    11.25373
log_probs/min                         -4.93124    0.57740    -3.97140    -8.22683
mean/mean                             -0.01347    0.00316    -0.00988    -0.02017
mean/std                              0.65657     0.00971    0.67817     0.63737
mean/max                              2.06892     0.03376    2.13444     2.01186
mean/min                              -2.21761    0.03457    -2.14469    -2.28158
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [4, 9, 1, 6, 3, 2, 5, 0, 7, 8]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7107.35, -16.74, -17.02, -40.03, -24.51, -15.21, -45.02, -18.11, -25.62, -24.93]
return_array_smooth: [7056.96, -17.19, -26.81, -40.9, -28.59, -13.32, -50.05, -18.34, -27.42, -26.77][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:46:22,633 MainThread INFO: EPOCH:39
2023-08-01 19:46:22,633 MainThread INFO: Time Consumed:14.438005208969116s
2023-08-01 19:46:22,633 MainThread INFO: Total Frames:60000s
  0%|          | 40/10000 [07:45<39:28:43, 14.27s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               688.01408
Train_Epoch_Reward                    6634.23659
Running_Training_Average_Rewards      674.17840
Explore_Time                          0.01008
Train___Time                          14.42194
Eval____Time                          0.00529
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.02471
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.02838
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.21371
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.51202
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.11478
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -17.02085
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.74367
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7107.35455
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.93331
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.62233
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.10234     0.94980    7.66017     2.77591
alpha_0                               1.78119     0.01587    1.80877     1.75366
alpha_1                               0.30572     0.00265    0.31028     0.30120
alpha_2                               0.30571     0.00265    0.31027     0.30119
alpha_3                               0.30571     0.00265    0.31027     0.30119
alpha_4                               0.30568     0.00265    0.31024     0.30117
alpha_5                               0.30570     0.00265    0.31026     0.30118
alpha_6                               0.30567     0.00265    0.31023     0.30115
alpha_7                               0.30570     0.00265    0.31026     0.30118
alpha_8                               0.30568     0.00265    0.31024     0.30116
alpha_9                               0.30570     0.00265    0.31026     0.30118
Alpha_loss                            -7.39596    0.06434    -7.29384    -7.54032
Training/policy_loss                  -124.90754  4.34899    -116.14103  -137.83974
Training/qf1_loss                     679.62869   164.52043  1123.56848  337.81454
Training/qf2_loss                     679.93046   164.32343  1122.67371  336.89719
Training/pf_norm                      0.72148     0.21527    1.30758     0.26904
Training/qf1_norm                     993.74924   629.55793  3830.56519  164.71436
Training/qf2_norm                     996.29194   631.12794  3843.77832  166.75092
log_std/mean                          -0.17399    0.00788    -0.16153    -0.18774
log_std/std                           0.14993     0.00386    0.15824     0.14243
log_std/max                           -0.10537    0.00963    -0.09166    -0.12073
log_std/min                           -0.64889    0.01952    -0.61591    -0.68804
log_probs/mean                        -1.67733    0.03756    -1.60218    -1.77698
log_probs/std                         3.25933     0.11046    3.46743     2.95614
log_probs/max                         11.56793    0.36031    12.37943    10.51556
log_probs/min                         -4.90144    0.69426    -3.79468    -8.63536
mean/mean                             -0.02768    0.00249    -0.02069    -0.03139
mean/std                              0.64545     0.01127    0.66752     0.61552
mean/max                              2.01556     0.04267    2.11047     1.91713
mean/min                              -2.21399    0.03561    -2.12944    -2.28898
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [1, 3, 6, 2, 7, 8, 4, 0, 9, 5]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7119.32, -16.02, -21.9, -40.67, -30.94, -16.48, -45.61, -17.26, -25.82, -26.12]
return_array_smooth: [7074.23, -16.03, -24.87, -41.08, -29.06, -14.5, -48.06, -17.76, -27.14, -26.44][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:46:37,275 MainThread INFO: EPOCH:40
2023-08-01 19:46:37,276 MainThread INFO: Time Consumed:14.477134466171265s
2023-08-01 19:46:37,276 MainThread INFO: Total Frames:61500s
  0%|          | 41/10000 [08:00<39:47:07, 14.38s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               687.85045
Train_Epoch_Reward                    7021.91767
Running_Training_Average_Rewards      680.74998
Explore_Time                          0.01036
Train___Time                          14.46009
Eval____Time                          0.00602
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.60508
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.67333
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.47845
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.94436
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.25974
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.90070
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.02350
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7119.32412
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.11610
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.81839
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.99173     1.08662    8.57289     3.03535
alpha_0                               1.83603     0.01536    1.86237     1.80936
alpha_1                               0.29668     0.00257    0.30111     0.29230
alpha_2                               0.29668     0.00257    0.30110     0.29229
alpha_3                               0.29668     0.00257    0.30110     0.29229
alpha_4                               0.29665     0.00257    0.30108     0.29227
alpha_5                               0.29666     0.00257    0.30109     0.29228
alpha_6                               0.29664     0.00257    0.30106     0.29226
alpha_7                               0.29666     0.00257    0.30109     0.29228
alpha_8                               0.29665     0.00257    0.30107     0.29227
alpha_9                               0.29666     0.00257    0.30109     0.29228
Alpha_loss                            -7.57174    0.05786    -7.45568    -7.70910
Training/policy_loss                  -126.44847  5.65162    -113.93040  -142.91975
Training/qf1_loss                     639.00524   182.30044  1440.61914  268.83054
Training/qf2_loss                     639.23255   182.20715  1440.15198  268.56403
Training/pf_norm                      0.69096     0.22082    1.79053     0.30435
Training/qf1_norm                     1022.47580  629.56349  3133.71338  196.90688
Training/qf2_norm                     1024.37678  631.25620  3140.19141  195.93506
log_std/mean                          -0.17729    0.00200    -0.17414    -0.18277
log_std/std                           0.14680     0.00434    0.15653     0.13884
log_std/max                           -0.11034    0.00446    -0.10465    -0.11999
log_std/min                           -0.64353    0.02293    -0.60886    -0.68466
log_probs/mean                        -1.70414    0.02623    -1.63966    -1.76221
log_probs/std                         3.17798     0.07367    3.38411     3.00282
log_probs/max                         11.32814    0.22467    11.78450    10.70224
log_probs/min                         -4.90701    0.65469    -3.92524    -7.74386
mean/mean                             -0.02310    0.00361    -0.01635    -0.02790
mean/std                              0.63486     0.00620    0.64823     0.62289
mean/max                              2.00124     0.05111    2.12559     1.93117
mean/min                              -2.19022    0.02706    -2.13278    -2.24674
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [1, 4, 8, 7, 9, 3, 0, 6, 5, 2]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7025.82, -17.96, -18.64, -40.53, -25.11, -18.29, -46.98, -18.4, -28.15, -27.24]
return_array_smooth: [7084.17, -16.91, -19.19, -40.41, -26.85, -16.66, -45.87, -17.93, -26.53, -26.1][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:46:51,690 MainThread INFO: EPOCH:41
2023-08-01 19:46:51,690 MainThread INFO: Time Consumed:14.12411093711853s
2023-08-01 19:46:51,690 MainThread INFO: Total Frames:63000s
  0%|          | 42/10000 [08:14<39:48:20, 14.39s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               678.45065
Train_Epoch_Reward                    6974.48088
Running_Training_Average_Rewards      687.68784
Explore_Time                          1.28255
Train___Time                          12.83566
Eval____Time                          0.00526
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.98368
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.52750
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.28946
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.10841
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.40420
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -18.64073
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.95907
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7025.81857
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.24496
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.15408
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.08517     1.01010    7.56222     3.06235
alpha_0                               1.89125     0.01662    1.91982     1.86292
alpha_1                               0.28792     0.00249    0.29222     0.28366
alpha_2                               0.28791     0.00249    0.29221     0.28366
alpha_3                               0.28791     0.00249    0.29220     0.28366
alpha_4                               0.28789     0.00249    0.29218     0.28363
alpha_5                               0.28790     0.00249    0.29219     0.28365
alpha_6                               0.28788     0.00249    0.29217     0.28362
alpha_7                               0.28790     0.00249    0.29219     0.28364
alpha_8                               0.28788     0.00249    0.29218     0.28363
alpha_9                               0.28790     0.00249    0.29219     0.28364
Alpha_loss                            -7.77409    0.05637    -7.66121    -7.88384
Training/policy_loss                  -129.15037  5.52141    -114.03542  -143.65016
Training/qf1_loss                     656.83784   169.72060  1117.12854  342.12048
Training/qf2_loss                     657.05997   169.59427  1117.48865  342.55515
Training/pf_norm                      0.67911     0.20961    1.19819     0.25180
Training/qf1_norm                     1001.19476  635.06640  3197.63037  215.60907
Training/qf2_norm                     1003.60637  635.99248  3196.97192  219.36324
log_std/mean                          -0.17732    0.00152    -0.17283    -0.17921
log_std/std                           0.14692     0.00292    0.15093     0.14173
log_std/max                           -0.10799    0.00390    -0.09643    -0.11330
log_std/min                           -0.64816    0.01662    -0.61569    -0.68208
log_probs/mean                        -1.68627    0.02357    -1.63981    -1.75188
log_probs/std                         3.22843     0.06262    3.36671     3.07653
log_probs/max                         11.48498    0.21629    12.01372    10.84592
log_probs/min                         -5.07387    0.84268    -3.94329    -8.36876
mean/mean                             -0.02201    0.00233    -0.01826    -0.02696
mean/std                              0.64334     0.00554    0.65318     0.63218
mean/max                              1.99597     0.03310    2.05318     1.93695
mean/min                              -2.23576    0.02834    -2.18150    -2.28553
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [7, 5, 2, 8, 6, 3, 0, 1, 4, 9]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7116.35, -13.73, -13.57, -43.09, -21.18, -17.71, -51.67, -14.05, -25.44, -27.92]
return_array_smooth: [7087.16, -15.91, -18.04, -41.43, -25.74, -17.49, -48.09, -16.57, -26.47, -27.09][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:47:06,444 MainThread INFO: EPOCH:42
2023-08-01 19:47:06,446 MainThread INFO: Time Consumed:12.970345973968506s
2023-08-01 19:47:06,446 MainThread INFO: Total Frames:64500s
  0%|          | 43/10000 [08:29<40:06:36, 14.50s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               688.79832
Train_Epoch_Reward                    7288.65538
Running_Training_Average_Rewards      709.50180
Explore_Time                          0.83258
Train___Time                          12.13033
Eval____Time                          0.00683
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.66932
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.09356
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.70660
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.17967
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -14.04642
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -13.57412
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.73470
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7116.34868
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.91781
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.44324
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.04360     0.88253    7.47637     3.30902
alpha_0                               1.94942     0.01689    1.97791     1.92039
alpha_1                               0.27941     0.00242    0.28358     0.27529
alpha_2                               0.27941     0.00242    0.28357     0.27528
alpha_3                               0.27941     0.00242    0.28357     0.27528
alpha_4                               0.27938     0.00242    0.28355     0.27525
alpha_5                               0.27940     0.00242    0.28357     0.27526
alpha_6                               0.27937     0.00242    0.28354     0.27525
alpha_7                               0.27939     0.00242    0.28356     0.27526
alpha_8                               0.27937     0.00242    0.28354     0.27524
alpha_9                               0.27939     0.00242    0.28356     0.27526
Alpha_loss                            -7.96046    0.05091    -7.85775    -8.06694
Training/policy_loss                  -130.88647  5.82923    -118.54187  -145.53372
Training/qf1_loss                     622.94549   140.44573  987.64130   370.54648
Training/qf2_loss                     623.22525   140.34639  987.28967   370.92938
Training/pf_norm                      0.79621     0.29207    1.50591     0.27696
Training/qf1_norm                     1067.01250  606.03858  3252.84473  191.22212
Training/qf2_norm                     1069.39645  607.72482  3264.43359  192.97923
log_std/mean                          -0.17646    0.00365    -0.17214    -0.18259
log_std/std                           0.15035     0.00427    0.15883     0.14046
log_std/max                           -0.10459    0.00481    -0.09496    -0.11095
log_std/min                           -0.65217    0.02102    -0.61116    -0.70252
log_probs/mean                        -1.69499    0.03444    -1.61979    -1.77926
log_probs/std                         3.20320     0.08983    3.41379     2.95400
log_probs/max                         11.39231    0.28608    12.03947    10.67762
log_probs/min                         -4.95694    0.62209    -4.05648    -7.41999
mean/mean                             -0.01931    0.00304    -0.01557    -0.02417
mean/std                              0.63792     0.00966    0.65754     0.61878
mean/max                              1.97851     0.02889    2.06053     1.93561
mean/min                              -2.19460    0.03858    -2.12099    -2.26905
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [4, 0, 3, 2, 5, 6, 9, 8, 1, 7]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7112.9, -15.68, -31.52, -43.08, -27.75, -24.59, -50.77, -24.15, -29.19, -28.79]
return_array_smooth: [7085.02, -15.79, -21.24, -42.23, -24.68, -20.2, -49.81, -18.87, -27.6, -27.98][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:47:21,431 MainThread INFO: EPOCH:43
2023-08-01 19:47:21,434 MainThread INFO: Time Consumed:14.78586220741272s
2023-08-01 19:47:21,434 MainThread INFO: Total Frames:66000s
  0%|          | 44/10000 [08:44<40:30:31, 14.65s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               683.73959
Train_Epoch_Reward                    6801.12614
Running_Training_Average_Rewards      702.14208
Explore_Time                          0.00534
Train___Time                          14.77198
Eval____Time                          0.00785
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.76562
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.07589
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -24.59308
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.75186
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.14893
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -31.51956
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.67647
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7112.90461
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.78715
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.19017
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.04474     0.96822    7.89166     2.70772
alpha_0                               2.00629     0.01628    2.03457     1.97846
alpha_1                               0.27116     0.00235    0.27520     0.26715
alpha_2                               0.27115     0.00235    0.27520     0.26715
alpha_3                               0.27115     0.00235    0.27520     0.26714
alpha_4                               0.27113     0.00235    0.27517     0.26712
alpha_5                               0.27114     0.00235    0.27518     0.26713
alpha_6                               0.27112     0.00235    0.27516     0.26712
alpha_7                               0.27113     0.00235    0.27518     0.26712
alpha_8                               0.27112     0.00235    0.27516     0.26711
alpha_9                               0.27113     0.00235    0.27518     0.26713
Alpha_loss                            -8.14207    0.06069    -8.02582    -8.29150
Training/policy_loss                  -132.86716  5.27811    -118.60949  -143.59676
Training/qf1_loss                     640.41708   160.52535  1260.25964  328.78171
Training/qf2_loss                     640.76051   160.46254  1260.62170  328.62515
Training/pf_norm                      0.74800     0.28447    1.64211     0.27652
Training/qf1_norm                     1073.58948  714.34268  3796.49927  224.54398
Training/qf2_norm                     1076.50384  716.76720  3806.77100  228.71759
log_std/mean                          -0.17705    0.00459    -0.16826    -0.18635
log_std/std                           0.14855     0.00292    0.15572     0.14315
log_std/max                           -0.10628    0.00306    -0.10014    -0.11170
log_std/min                           -0.65346    0.00945    -0.63344    -0.67303
log_probs/mean                        -1.71187    0.03133    -1.63229    -1.77120
log_probs/std                         3.15757     0.08199    3.34136     2.98057
log_probs/max                         11.23752    0.22365    11.72837    10.63361
log_probs/min                         -4.95123    0.67803    -3.91544    -7.55704
mean/mean                             -0.02398    0.00406    -0.01766    -0.02879
mean/std                              0.63198     0.00659    0.64937     0.62076
mean/max                              2.00084     0.03111    2.06485     1.93409
mean/min                              -2.17863    0.03083    -2.11167    -2.23844
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [5, 1, 3, 6, 8, 4, 0, 7, 9, 2]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7101.22, -15.57, -32.32, -41.35, -33.09, -17.96, -53.45, -20.21, -29.69, -29.72]
return_array_smooth: [7110.16, -15.0, -25.8, -42.51, -27.34, -20.09, -51.96, -19.47, -28.11, -28.81][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:47:36,751 MainThread INFO: EPOCH:44
2023-08-01 19:47:36,752 MainThread INFO: Time Consumed:15.148931503295898s
2023-08-01 19:47:36,752 MainThread INFO: Total Frames:67500s
  0%|          | 45/10000 [08:59<41:05:26, 14.86s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               682.78696
Train_Epoch_Reward                    6809.05744
Running_Training_Average_Rewards      696.62797
Explore_Time                          0.02413
Train___Time                          15.11733
Eval____Time                          0.00672
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.44587
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.35144
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.96169
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -33.08688
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.20821
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -32.31685
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.57464
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7101.22028
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.71917
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.68593
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.07619     0.89219    7.43442     3.09282
alpha_0                               2.06453     0.01733    2.09434     2.03515
alpha_1                               0.26315     0.00228    0.26707     0.25926
alpha_2                               0.26314     0.00228    0.26707     0.25925
alpha_3                               0.26314     0.00228    0.26706     0.25925
alpha_4                               0.26311     0.00228    0.26704     0.25923
alpha_5                               0.26312     0.00228    0.26705     0.25924
alpha_6                               0.26311     0.00228    0.26704     0.25923
alpha_7                               0.26312     0.00228    0.26704     0.25923
alpha_8                               0.26311     0.00228    0.26703     0.25922
alpha_9                               0.26312     0.00228    0.26705     0.25923
Alpha_loss                            -8.33567    0.05964    -8.19837    -8.45457
Training/policy_loss                  -134.59060  5.76978    -119.70731  -148.10338
Training/qf1_loss                     631.78263   163.93031  1243.48853  321.08261
Training/qf2_loss                     632.06914   163.93670  1243.72644  321.11115
Training/pf_norm                      0.78354     0.26867    1.82060     0.18952
Training/qf1_norm                     1054.53543  653.77149  3283.28979  250.55759
Training/qf2_norm                     1056.34770  656.14163  3296.46924  252.64621
log_std/mean                          -0.17676    0.00194    -0.17294    -0.18041
log_std/std                           0.14744     0.00356    0.15520     0.14096
log_std/max                           -0.09833    0.00823    -0.08804    -0.11033
log_std/min                           -0.64984    0.01459    -0.62483    -0.67733
log_probs/mean                        -1.70758    0.03242    -1.63903    -1.80656
log_probs/std                         3.16624     0.08697    3.35014     2.94889
log_probs/max                         11.20836    0.28164    11.90170    10.64933
log_probs/min                         -5.02056    0.92102    -3.63120    -10.44079
mean/mean                             -0.02937    0.00443    -0.02032    -0.03643
mean/std                              0.63134     0.00802    0.65166     0.61919
mean/max                              2.01687     0.03455    2.09019     1.94842
mean/min                              -2.14897    0.02859    -2.08794    -2.21754
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [3, 7, 0, 1, 6, 8, 9, 4, 5, 2]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [6985.45, -18.21, -27.14, -41.16, -24.07, -15.59, -52.61, -21.02, -29.48, -28.92]
return_array_smooth: [7066.53, -16.49, -30.32, -41.86, -28.3, -19.38, -52.27, -21.79, -29.45, -29.14][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:47:53,080 MainThread INFO: EPOCH:45
2023-08-01 19:47:53,082 MainThread INFO: Time Consumed:16.154396533966064s
2023-08-01 19:47:53,082 MainThread INFO: Total Frames:69000s
  0%|          | 46/10000 [09:15<42:18:35, 15.30s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               672.72479
Train_Epoch_Reward                    6974.88378
Running_Training_Average_Rewards      686.16891
Explore_Time                          0.00662
Train___Time                          16.13481
Eval____Time                          0.01224
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.61096
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.16306
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.59009
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.07323
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.01920
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.13547
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.20784
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6985.45166
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.91960
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.48431
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.98579     0.97829    7.88281     2.35051
alpha_0                               2.12461     0.01709    2.15296     2.09493
alpha_1                               0.25538     0.00221    0.25918     0.25161
alpha_2                               0.25537     0.00221    0.25918     0.25159
alpha_3                               0.25537     0.00221    0.25917     0.25160
alpha_4                               0.25534     0.00221    0.25915     0.25157
alpha_5                               0.25535     0.00221    0.25916     0.25158
alpha_6                               0.25534     0.00221    0.25915     0.25157
alpha_7                               0.25534     0.00221    0.25915     0.25157
alpha_8                               0.25533     0.00221    0.25915     0.25156
alpha_9                               0.25534     0.00221    0.25915     0.25157
Alpha_loss                            -8.50984    0.04924    -8.39884    -8.64519
Training/policy_loss                  -136.89023  6.28878    -124.51304  -152.25798
Training/qf1_loss                     591.51541   168.07150  1297.61340  266.57712
Training/qf2_loss                     591.85803   167.85366  1296.86646  267.76483
Training/pf_norm                      0.90128     0.32671    1.65838     0.39049
Training/qf1_norm                     1156.12360  681.05078  3404.87061  144.01007
Training/qf2_norm                     1160.84361  681.20620  3396.16479  148.34450
log_std/mean                          -0.17517    0.00335    -0.16869    -0.18253
log_std/std                           0.14716     0.00550    0.15819     0.13733
log_std/max                           -0.10351    0.00367    -0.09543    -0.10903
log_std/min                           -0.64625    0.02194    -0.60951    -0.69010
log_probs/mean                        -1.72428    0.04516    -1.58502    -1.80816
log_probs/std                         3.11034     0.12894    3.48014     2.88591
log_probs/max                         11.06746    0.43513    12.21889    10.02074
log_probs/min                         -4.90890    0.67671    -3.74262    -7.14871
mean/mean                             -0.02641    0.00289    -0.02254    -0.03361
mean/std                              0.62615     0.01575    0.66868     0.59760
mean/max                              2.03927     0.04986    2.16614     1.91921
mean/min                              -2.15129    0.04284    -2.06103    -2.25743
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [6, 0, 3, 1, 2, 7, 4, 8, 5, 9]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7014.79, -15.12, -34.98, -42.52, -30.59, -16.01, -54.8, -22.26, -31.63, -30.52]
return_array_smooth: [7033.82, -16.3, -31.48, -41.68, -29.25, -16.52, -53.62, -21.16, -30.27, -29.72][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:48:09,586 MainThread INFO: EPOCH:46
2023-08-01 19:48:09,589 MainThread INFO: Time Consumed:16.335880756378174s
2023-08-01 19:48:09,589 MainThread INFO: Total Frames:70500s
  0%|          | 47/10000 [09:32<43:16:34, 15.65s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               673.63778
Train_Epoch_Reward                    6807.68616
Running_Training_Average_Rewards      686.38758
Explore_Time                          0.01589
Train___Time                          16.31275
Eval____Time                          0.00664
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.79652
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.52366
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.00741
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.58517
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.25549
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -34.97723
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.11696
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7014.78970
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.52445
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.62505
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.91246     0.97787    7.19625     2.73914
alpha_0                               2.18149     0.01630    2.20956     2.15349
alpha_1                               0.24783     0.00215    0.25153     0.24417
alpha_2                               0.24782     0.00214    0.25152     0.24416
alpha_3                               0.24783     0.00214    0.25152     0.24417
alpha_4                               0.24780     0.00214    0.25150     0.24415
alpha_5                               0.24780     0.00215    0.25150     0.24414
alpha_6                               0.24780     0.00214    0.25150     0.24414
alpha_7                               0.24780     0.00214    0.25149     0.24414
alpha_8                               0.24779     0.00214    0.25149     0.24413
alpha_9                               0.24780     0.00214    0.25149     0.24414
Alpha_loss                            -8.68444    0.05736    -8.53387    -8.79341
Training/policy_loss                  -137.04222  7.16578    -118.36908  -156.94414
Training/qf1_loss                     584.90098   133.94854  971.97675   239.90392
Training/qf2_loss                     585.25885   133.93436  972.36591   240.47913
Training/pf_norm                      0.82487     0.35418    2.12729     0.31917
Training/qf1_norm                     1076.43112  654.04899  2869.67212  180.57445
Training/qf2_norm                     1077.38475  652.63126  2872.66455  182.28381
log_std/mean                          -0.17620    0.00295    -0.17004    -0.18126
log_std/std                           0.14630     0.00409    0.15737     0.13817
log_std/max                           -0.08995    0.00892    -0.07823    -0.10274
log_std/min                           -0.64555    0.01950    -0.61049    -0.68043
log_probs/mean                        -1.74425    0.03282    -1.64720    -1.83580
log_probs/std                         3.05550     0.09094    3.30599     2.80927
log_probs/max                         10.89272    0.28693    11.43709    10.00293
log_probs/min                         -5.18350    1.05933    -3.86152    -12.28385
mean/mean                             -0.03451    0.00683    -0.02589    -0.04605
mean/std                              0.61890     0.00854    0.63744     0.59777
mean/max                              1.97073     0.06812    2.08205     1.86874
mean/min                              -2.13163    0.03353    -2.05933    -2.18909
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [2, 3, 9, 0, 8, 5, 7, 4, 1, 6]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7010.67, -14.9, -32.17, -41.15, -27.63, -10.95, -52.35, -19.04, -30.83, -28.55]
return_array_smooth: [7003.64, -16.08, -31.43, -41.61, -27.43, -14.18, -53.25, -20.77, -30.65, -29.33][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:48:25,820 MainThread INFO: EPOCH:47
2023-08-01 19:48:25,858 MainThread INFO: Time Consumed:16.057788848876953s
2023-08-01 19:48:25,858 MainThread INFO: Total Frames:72000s
  0%|          | 48/10000 [09:48<43:48:02, 15.84s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               675.30923
Train_Epoch_Reward                    6641.63789
Running_Training_Average_Rewards      680.80693
Explore_Time                          0.01299
Train___Time                          16.03909
Eval____Time                          0.00504
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.34653
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.15322
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.95298
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.63133
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.04245
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -32.16894
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.90431
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7010.67328
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.54675
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.83451
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.96689     0.86756    7.63412     3.08099
alpha_0                               2.23817     0.01627    2.26671     2.21014
alpha_1                               0.24051     0.00208    0.24410     0.23695
alpha_2                               0.24051     0.00208    0.24409     0.23696
alpha_3                               0.24052     0.00208    0.24410     0.23697
alpha_4                               0.24049     0.00208    0.24408     0.23694
alpha_5                               0.24048     0.00208    0.24406     0.23692
alpha_6                               0.24048     0.00208    0.24407     0.23693
alpha_7                               0.24048     0.00208    0.24407     0.23693
alpha_8                               0.24047     0.00208    0.24406     0.23692
alpha_9                               0.24048     0.00208    0.24407     0.23693
Alpha_loss                            -8.86464    0.06904    -8.73601    -9.00898
Training/policy_loss                  -138.70623  6.81840    -121.09174  -153.21928
Training/qf1_loss                     578.13892   153.23842  1101.37109  318.64032
Training/qf2_loss                     578.46829   153.11278  1101.07678  319.15869
Training/pf_norm                      0.78909     0.27544    1.78436     0.33701
Training/qf1_norm                     1140.82554  706.19911  4126.73047  214.39304
Training/qf2_norm                     1142.98724  708.60278  4136.30371  217.26102
log_std/mean                          -0.17527    0.00562    -0.16446    -0.18443
log_std/std                           0.14677     0.00558    0.15625     0.13863
log_std/max                           -0.09947    0.00535    -0.09135    -0.10646
log_std/min                           -0.65716    0.02052    -0.61084    -0.68133
log_probs/mean                        -1.75242    0.02999    -1.68108    -1.80853
log_probs/std                         3.02700     0.08461    3.21975     2.84664
log_probs/max                         10.76774    0.27585    11.41987    10.01907
log_probs/min                         -5.02210    0.72009    -3.95919    -7.97144
mean/mean                             -0.03370    0.00545    -0.02474    -0.04103
mean/std                              0.61494     0.00797    0.63194     0.59900
mean/max                              1.96519     0.04230    2.06922     1.88882
mean/min                              -2.12946    0.02641    -2.06384    -2.18102
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [4, 0, 3, 9, 2, 1, 7, 6, 5, 8]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7055.9, -15.09, -35.83, -42.7, -25.53, -19.04, -52.58, -26.07, -31.18, -29.71]
return_array_smooth: [7027.12, -15.04, -34.33, -42.13, -27.91, -15.33, -53.24, -22.46, -31.21, -29.59][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:48:41,527 MainThread INFO: EPOCH:48
2023-08-01 19:48:41,528 MainThread INFO: Time Consumed:15.543830871582031s
2023-08-01 19:48:41,528 MainThread INFO: Total Frames:73500s
  0%|          | 49/10000 [10:04<43:37:45, 15.78s/it]------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               677.81751
Train_Epoch_Reward                    6724.87654
Running_Training_Average_Rewards      672.47335
Explore_Time                          0.01101
Train___Time                          15.52594
Eval____Time                          0.00627
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.57874
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70092
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.03762
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.52722
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -26.07378
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -35.83391
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.08961
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7055.90327
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.70729
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.17912
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.08367     0.95963    8.15034     2.90926
alpha_0                               2.29705     0.01732    2.32572     2.26731
alpha_1                               0.23340     0.00202    0.23688     0.22995
alpha_2                               0.23341     0.00202    0.23689     0.22996
alpha_3                               0.23342     0.00202    0.23690     0.22998
alpha_4                               0.23340     0.00201    0.23687     0.22996
alpha_5                               0.23337     0.00202    0.23685     0.22992
alpha_6                               0.23337     0.00202    0.23686     0.22993
alpha_7                               0.23338     0.00202    0.23686     0.22993
alpha_8                               0.23337     0.00202    0.23685     0.22992
alpha_9                               0.23338     0.00202    0.23686     0.22993
Alpha_loss                            -9.04131    0.04935    -8.93551    -9.14829
Training/policy_loss                  -141.20557  7.41877    -118.22121  -158.81084
Training/qf1_loss                     601.09702   166.34906  1104.49011  216.65312
Training/qf2_loss                     601.37834   166.34910  1105.89917  216.82678
Training/pf_norm                      0.79428     0.26708    1.78017     0.30827
Training/qf1_norm                     1299.64273  787.36921  3703.05786  167.45749
Training/qf2_norm                     1302.93703  791.62879  3714.69019  165.09315
log_std/mean                          -0.17701    0.00566    -0.16661    -0.18823
log_std/std                           0.14286     0.00601    0.15726     0.13474
log_std/max                           -0.10041    0.00377    -0.09258    -0.10573
log_std/min                           -0.64035    0.02027    -0.60071    -0.67797
log_probs/mean                        -1.75529    0.03739    -1.67491    -1.87359
log_probs/std                         3.00600     0.10031    3.25897     2.73650
log_probs/max                         10.74928    0.33215    11.26730    9.89509
log_probs/min                         -5.05775    0.84859    -3.86345    -8.56241
mean/mean                             -0.03780    0.00556    -0.02754    -0.04715
mean/std                              0.61427     0.00998    0.62822     0.59142
mean/max                              1.93567     0.05588    2.01485     1.82743
mean/min                              -2.09925    0.02230    -2.05811    -2.15670
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
sample: [1, 0, 4, 8, 5, 2, 6, 3, 7, 9]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
[1;36;40msuccess_rate_array: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
success_rate_array_smooth:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0][0m
[1;36;40mreturn_array: [7015.2, -16.5, -36.57, -40.9, -27.33, -16.41, -55.89, -27.15, -32.75, -30.23]
return_array_smooth: [7027.26, -15.5, -34.86, -41.59, -26.83, -15.47, -53.6, -24.09, -31.59, -29.49][0m
[1;36;40mp: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1][0m
2023-08-01 19:48:57,442 MainThread INFO: EPOCH:49
2023-08-01 19:48:57,442 MainThread INFO: Time Consumed:15.744686603546143s
2023-08-01 19:48:57,442 MainThread INFO: Total Frames:75000s
  0%|          | 50/10000 [10:20<43:44:00, 15.82s/it]  0%|          | 50/10000 [11:09<37:01:42, 13.40s/it]
------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               673.14849
Train_Epoch_Reward                    6367.49247
Running_Training_Average_Rewards      657.80023
Explore_Time                          0.02117
Train___Time                          15.71403
Eval____Time                          0.00886
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.88640
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.90112
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.40583
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.32965
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.14730
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -36.56644
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.50128
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7015.20034
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.22760
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.74982
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.81225     0.93068    6.56571     2.34666
alpha_0                               2.35195     0.01528    2.37831     2.32623
alpha_1                               0.22651     0.00196    0.22988     0.22316
alpha_2                               0.22652     0.00196    0.22989     0.22317
alpha_3                               0.22653     0.00196    0.22991     0.22319
alpha_4                               0.22652     0.00196    0.22990     0.22318
alpha_5                               0.22648     0.00196    0.22986     0.22313
alpha_6                               0.22648     0.00196    0.22986     0.22314
alpha_7                               0.22648     0.00196    0.22986     0.22314
alpha_8                               0.22648     0.00196    0.22986     0.22313
alpha_9                               0.22649     0.00196    0.22987     0.22314
Alpha_loss                            -9.20043    0.06338    -9.05815    -9.32653
Training/policy_loss                  -141.04925  7.01589    -125.05639  -160.16377
Training/qf1_loss                     547.79712   140.25716  944.48578   230.11401
Training/qf2_loss                     548.11879   140.19842  944.03595   230.36397
Training/pf_norm                      0.88528     0.31077    2.03371     0.37859
Training/qf1_norm                     1061.47940  604.43784  3631.62622  153.04076
Training/qf2_norm                     1062.41696  602.44741  3650.87915  154.19499
log_std/mean                          -0.17650    0.00303    -0.17097    -0.18292
log_std/std                           0.14302     0.00296    0.14855     0.13479
log_std/max                           -0.10334    0.00179    -0.09910    -0.10642
log_std/min                           -0.63847    0.01480    -0.61368    -0.67802
log_probs/mean                        -1.79389    0.03208    -1.72382    -1.89850
log_probs/std                         2.89914     0.08359    3.10294     2.62961
log_probs/max                         10.35512    0.29558    10.96446    9.67619
log_probs/min                         -5.03909    0.63048    -3.87089    -7.28783
mean/mean                             -0.03618    0.00361    -0.02896    -0.04171
mean/std                              0.59838     0.00878    0.61433     0.58078
mean/max                              1.92918     0.04424    1.99981     1.85253
mean/min                              -2.06628    0.03429    -1.99047    -2.12576
------------------------------------  ----------  ---------  ----------  ----------
self.update_end_epoch 7000
start to update mask
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 757, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 280, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 387, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 285, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 281, in experiment
    agent.train(env.num_tasks,params)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 423, in train
    self.update_masks(TASK_SAMPLE_NUM, task_amount, epoch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 317, in update_masks
    loss = self.train_trajectory_encoder(trajectories, self.traj_encoder_optimizer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 194, in train_trajectory_encoder
    optimizer.zero_grad()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 235, in join
    ret = self._internal_proc.wait()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
