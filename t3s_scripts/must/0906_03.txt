W&B disabled.
2023-09-06 13:22:28,060 MainThread INFO: Experiment Name:testing_must_mtsac
2023-09-06 13:22:28,060 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      20,
      20
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      24,
      24
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      24,
      24
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 200,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "success_traj_update_only": 1,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 10,
    "mask_update_interval": 25,
    "update_end_epoch": 20,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2023-09-06 13:23:37,585 MainThread INFO: Finished Pretrain
  0%|          | 0/200 [00:00<?, ?it/s]sample: [6, 5, 0, 3, 9, 8, 4, 2, 1, 7]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6459035873413086 4.9591064453125e-05
train_time 1.6460075378417969
snapshot at best
2023-09-06 13:23:46,797 MainThread INFO: EPOCH:0
2023-09-06 13:23:46,797 MainThread INFO: Time Consumed:9.191689014434814s
2023-09-06 13:23:46,797 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:374: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/200 [00:10<34:05, 10.28s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.47201
Train_Epoch_Reward                    39696.04411
Running_Training_Average_Rewards      3969.60441
Explore_Time                          0.00708
Train___Time                          1.64601
Eval____Time                          6.49379
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.25500
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70769
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54272
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.32778
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47798
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19324
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18179
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11265.71170
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97841
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.32703
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           12.78039     2.11505     16.35612    10.18441
alpha_0                               0.99835      0.00086     0.99970     0.99700
alpha_1                               0.99835      0.00086     0.99970     0.99700
alpha_2                               0.99835      0.00086     0.99970     0.99700
alpha_3                               0.99835      0.00086     0.99970     0.99700
alpha_4                               0.99835      0.00086     0.99970     0.99700
alpha_5                               0.99835      0.00086     0.99970     0.99700
alpha_6                               0.99835      0.00086     0.99970     0.99700
alpha_7                               0.99835      0.00086     0.99970     0.99701
alpha_8                               0.99835      0.00086     0.99970     0.99700
alpha_9                               0.99835      0.00086     0.99970     0.99700
Alpha_loss                            -0.00902     0.00576     -0.00000    -0.01804
Training/policy_loss                  -2.67936     0.00863     -2.66752    -2.69321
Training/qf1_loss                     4597.36838   1226.04766  6549.59326  3005.55444
Training/qf2_loss                     4597.44534   1226.05518  6549.67236  3005.61597
Training/pf_norm                      0.45518      0.02319     0.50186     0.42294
Training/qf1_norm                     34.12918     4.73749     41.77980    28.30823
Training/qf2_norm                     33.35682     4.58189     41.09167    27.71423
log_std/mean                          -0.00235     0.00200     0.00077     -0.00549
log_std/std                           0.00197      0.00006     0.00207     0.00190
log_std/max                           0.00044      0.00184     0.00339     -0.00244
log_std/min                           -0.00630     0.00201     -0.00328    -0.00969
log_probs/mean                        -2.68239     0.00864     -2.67069    -2.69640
log_probs/std                         0.43139      0.01052     0.44893     0.41645
log_probs/max                         -1.28868     0.08447     -1.16921    -1.41658
log_probs/min                         -4.45868     0.89961     -3.68902    -6.38591
mean/mean                             -0.00053     0.00031     -0.00002    -0.00090
mean/std                              0.00208      0.00045     0.00284     0.00135
mean/max                              0.00270      0.00041     0.00339     0.00225
mean/min                              -0.00403     0.00121     -0.00239    -0.00610
------------------------------------  -----------  ----------  ----------  ----------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [1, 8, 7, 3, 4, 2, 6, 5, 9, 0]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.0353314876556396 1.7881393432617188e-05
train_time 1.035400390625
2023-09-06 13:23:48,921 MainThread INFO: EPOCH:1
2023-09-06 13:23:48,921 MainThread INFO: Time Consumed:1.041945219039917s
2023-09-06 13:23:48,921 MainThread INFO: Total Frames:3000s
  1%|          | 2/200 [00:11<16:09,  4.90s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.31470
Train_Epoch_Reward                    11984.82166
Running_Training_Average_Rewards      2584.04329
Explore_Time                          0.00302
Train___Time                          1.03540
Eval____Time                          0.00296
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.40109
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70769
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54272
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.32778
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47798
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19324
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18179
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11265.71170
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97841
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.32703
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.30537     1.22500     12.39415    8.40657
alpha_0                               0.99536      0.00086     0.99670     0.99402
alpha_1                               0.99536      0.00086     0.99670     0.99401
alpha_2                               0.99536      0.00086     0.99670     0.99401
alpha_3                               0.99536      0.00086     0.99671     0.99402
alpha_4                               0.99536      0.00086     0.99671     0.99402
alpha_5                               0.99536      0.00086     0.99671     0.99402
alpha_6                               0.99536      0.00086     0.99671     0.99402
alpha_7                               0.99536      0.00086     0.99671     0.99402
alpha_8                               0.99536      0.00086     0.99671     0.99402
alpha_9                               0.99536      0.00086     0.99671     0.99402
Alpha_loss                            -0.02910     0.00576     -0.02009    -0.03817
Training/policy_loss                  -2.68653     0.00675     -2.67350    -2.69465
Training/qf1_loss                     3474.43204   1026.57813  5537.72119  2017.06482
Training/qf2_loss                     3474.52004   1026.58579  5537.82373  2017.13501
Training/pf_norm                      0.42570      0.01880     0.45574     0.39598
Training/qf1_norm                     28.77786     2.75020     33.58698    24.48628
Training/qf2_norm                     28.17041     2.66074     32.66702    24.07280
log_std/mean                          -0.00954     0.00216     -0.00621    -0.01299
log_std/std                           0.00228      0.00013     0.00250     0.00210
log_std/max                           -0.00602     0.00188     -0.00310    -0.00901
log_std/min                           -0.01462     0.00264     -0.01056    -0.01884
log_probs/mean                        -2.68992     0.00676     -2.67687    -2.69808
log_probs/std                         0.41680      0.01272     0.43995     0.39527
log_probs/max                         -1.33237     0.10665     -1.17002    -1.46382
log_probs/min                         -4.63400     0.96678     -3.77223    -7.37168
mean/mean                             -0.00128     0.00019     -0.00095    -0.00154
mean/std                              0.00348      0.00030     0.00394     0.00301
mean/max                              0.00402      0.00015     0.00421     0.00379
mean/min                              -0.00908     0.00145     -0.00673    -0.01119
------------------------------------  -----------  ----------  ----------  ----------
sample: [1, 9, 2, 4, 6, 3, 0, 7, 5, 8]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.299736499786377 1.8835067749023438e-05
train_time 1.299823522567749
snapshot at best
2023-09-06 13:23:51,295 MainThread INFO: EPOCH:2
2023-09-06 13:23:51,296 MainThread INFO: Time Consumed:2.2008721828460693s
2023-09-06 13:23:51,296 MainThread INFO: Total Frames:4500s
  2%|▏         | 3/200 [00:13<12:18,  3.75s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1101.52239
Train_Epoch_Reward                    3998.65399
Running_Training_Average_Rewards      1855.98399
Explore_Time                          0.00399
Train___Time                          1.29982
Eval____Time                          0.00289
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.59755
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.70769
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.54272
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.32778
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47798
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.19324
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.18179
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11265.71170
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.97841
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.32703
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.34895     1.31788    13.10205    8.64460
alpha_0                               0.99238      0.00086    0.99372     0.99104
alpha_1                               0.99237      0.00086    0.99372     0.99103
alpha_2                               0.99238      0.00085    0.99372     0.99104
alpha_3                               0.99238      0.00085    0.99372     0.99104
alpha_4                               0.99238      0.00086    0.99372     0.99104
alpha_5                               0.99238      0.00086    0.99372     0.99104
alpha_6                               0.99238      0.00086    0.99372     0.99104
alpha_7                               0.99238      0.00086    0.99372     0.99104
alpha_8                               0.99238      0.00085    0.99372     0.99104
alpha_9                               0.99238      0.00086    0.99372     0.99104
Alpha_loss                            -0.04921     0.00582    -0.04011    -0.05829
Training/policy_loss                  -2.69031     0.01229    -2.67020    -2.70634
Training/qf1_loss                     3311.95406   781.36571  4290.58838  1811.06702
Training/qf2_loss                     3312.07706   781.38018  4290.73828  1811.15002
Training/pf_norm                      0.41348      0.03084    0.46676     0.36284
Training/qf1_norm                     31.54023     3.18286    35.74664    25.01927
Training/qf2_norm                     30.81436     3.02729    35.03510    24.60799
log_std/mean                          -0.01758     0.00246    -0.01379    -0.02150
log_std/std                           0.00289      0.00024    0.00328     0.00255
log_std/max                           -0.01265     0.00192    -0.00968    -0.01569
log_std/min                           -0.02456     0.00312    -0.01982    -0.02954
log_probs/mean                        -2.69346     0.01229    -2.67341    -2.70941
log_probs/std                         0.40293      0.00615    0.41316     0.39223
log_probs/max                         -1.42485     0.06083    -1.34083    -1.55526
log_probs/min                         -4.40839     0.48760    -3.72983    -5.25297
mean/mean                             -0.00178     0.00008    -0.00164    -0.00190
mean/std                              0.00453      0.00027    0.00491     0.00406
mean/max                              0.00508      0.00069    0.00590     0.00392
mean/min                              -0.01328     0.00090    -0.01169    -0.01459
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 6, 1, 0, 3, 2, 8, 9, 7, 5]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.0492253303527832 1.9311904907226562e-05
train_time 1.0493049621582031
2023-09-06 13:23:52,444 MainThread INFO: EPOCH:3
2023-09-06 13:23:52,445 MainThread INFO: Time Consumed:1.0571351051330566s
2023-09-06 13:23:52,445 MainThread INFO: Total Frames:6000s
  2%|▏         | 4/200 [00:14<08:53,  2.72s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1091.24432
Train_Epoch_Reward                    5300.30786
Running_Training_Average_Rewards      709.45945
Explore_Time                          0.00352
Train___Time                          1.04930
Eval____Time                          0.00317
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.81315
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.16527
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.31815
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.63312
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44531
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.15602
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98778
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10956.79566
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.38444
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.51420
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           11.02798     0.78173    12.55170    9.49596
alpha_0                               0.98940      0.00085    0.99074     0.98806
alpha_1                               0.98940      0.00085    0.99074     0.98806
alpha_2                               0.98941      0.00085    0.99074     0.98807
alpha_3                               0.98941      0.00085    0.99075     0.98807
alpha_4                               0.98941      0.00085    0.99074     0.98807
alpha_5                               0.98941      0.00085    0.99074     0.98807
alpha_6                               0.98940      0.00085    0.99074     0.98806
alpha_7                               0.98940      0.00085    0.99074     0.98807
alpha_8                               0.98941      0.00085    0.99074     0.98807
alpha_9                               0.98940      0.00085    0.99074     0.98807
Alpha_loss                            -0.06940     0.00586    -0.06033    -0.07864
Training/policy_loss                  -2.70079     0.01131    -2.68256    -2.71817
Training/qf1_loss                     3296.36343   613.48273  4439.33447  2226.84839
Training/qf2_loss                     3296.51445   613.48949  4439.52734  2226.98462
Training/pf_norm                      0.35748      0.03680    0.41714     0.28454
Training/qf1_norm                     31.37183     1.82141    35.35819    27.79968
Training/qf2_norm                     30.52314     1.77625    34.25373    27.14419
log_std/mean                          -0.02661     0.00272    -0.02240    -0.03094
log_std/std                           0.00383      0.00029    0.00430     0.00338
log_std/max                           -0.01968     0.00213    -0.01640    -0.02308
log_std/min                           -0.03580     0.00329    -0.03067    -0.04099
log_probs/mean                        -2.70291     0.01109    -2.68477    -2.71966
log_probs/std                         0.37929      0.00802    0.38999     0.36499
log_probs/max                         -1.44835     0.05879    -1.36923    -1.55185
log_probs/min                         -4.42602     0.45154    -4.02050    -5.19337
mean/mean                             -0.00210     0.00006    -0.00197    -0.00216
mean/std                              0.00457      0.00032    0.00494     0.00404
mean/max                              0.00621      0.00007    0.00631     0.00603
mean/min                              -0.01416     0.00071    -0.01294    -0.01491
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 8, 0, 9, 7, 4, 3, 5, 2, 6]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.3604669570922852 6.365776062011719e-05
train_time 1.360598087310791
2023-09-06 13:23:53,983 MainThread INFO: EPOCH:4
2023-09-06 13:23:53,983 MainThread INFO: Time Consumed:1.3685483932495117s
2023-09-06 13:23:53,983 MainThread INFO: Total Frames:7500s
  2%|▎         | 5/200 [00:16<07:28,  2.30s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1072.21149
Train_Epoch_Reward                    27753.89604
Running_Training_Average_Rewards      1235.09526
Explore_Time                          0.00384
Train___Time                          1.36060
Eval____Time                          0.00362
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.02677
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.28910
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.27451
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.77499
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44375
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.17336
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.85365
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10694.66534
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.42688
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.81335
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.76596      0.83876    11.70124    8.65626
alpha_0                               0.98643      0.00085    0.98776     0.98509
alpha_1                               0.98643      0.00085    0.98776     0.98509
alpha_2                               0.98644      0.00085    0.98777     0.98511
alpha_3                               0.98645      0.00085    0.98778     0.98511
alpha_4                               0.98644      0.00085    0.98778     0.98511
alpha_5                               0.98644      0.00085    0.98778     0.98511
alpha_6                               0.98643      0.00085    0.98777     0.98510
alpha_7                               0.98644      0.00085    0.98777     0.98510
alpha_8                               0.98644      0.00085    0.98777     0.98510
alpha_9                               0.98644      0.00085    0.98777     0.98510
Alpha_loss                            -0.08959     0.00580    -0.08058    -0.09867
Training/policy_loss                  -2.70816     0.00581    -2.69830    -2.71606
Training/qf1_loss                     2705.37542   457.11022  3416.85938  2203.65186
Training/qf2_loss                     2705.54739   457.12448  3417.03906  2203.80835
Training/pf_norm                      0.34979      0.01591    0.38313     0.32480
Training/qf1_norm                     29.14452     1.94079    33.34803    26.58203
Training/qf2_norm                     28.17215     1.82889    32.28249    25.81500
log_std/mean                          -0.03655     0.00302    -0.03191    -0.04139
log_std/std                           0.00498      0.00037    0.00559     0.00442
log_std/max                           -0.02741     0.00232    -0.02385    -0.03114
log_std/min                           -0.04790     0.00372    -0.04218    -0.05384
log_probs/mean                        -2.70793     0.00570    -2.69901    -2.71681
log_probs/std                         0.36517      0.00662    0.37478     0.35091
log_probs/max                         -1.55420     0.08298    -1.43013    -1.68879
log_probs/min                         -4.35795     0.48538    -3.53501    -5.19462
mean/mean                             -0.00233     0.00011    -0.00209    -0.00244
mean/std                              0.00367      0.00015    0.00396     0.00350
mean/max                              0.00528      0.00050    0.00617     0.00476
mean/min                              -0.01181     0.00073    -0.01049    -0.01283
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 3, 4, 0, 5, 2, 7, 8, 9, 1]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.4585447311401367 2.5272369384765625e-05
train_time 1.4586305618286133
2023-09-06 13:23:55,606 MainThread INFO: EPOCH:5
2023-09-06 13:23:55,606 MainThread INFO: Time Consumed:1.466052532196045s
2023-09-06 13:23:55,606 MainThread INFO: Total Frames:9000s
  3%|▎         | 6/200 [00:18<06:40,  2.06s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1058.35958
Train_Epoch_Reward                    6344.55862
Running_Training_Average_Rewards      1313.29208
Explore_Time                          0.00396
Train___Time                          1.45863
Eval____Time                          0.00294
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.28596
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.31367
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.36322
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.54664
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.35099
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.09291
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.66949
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10856.30545
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.39723
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.46526
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.64192      0.93798    10.56556    7.16751
alpha_0                               0.98347      0.00085    0.98480     0.98214
alpha_1                               0.98347      0.00085    0.98480     0.98214
alpha_2                               0.98348      0.00085    0.98481     0.98215
alpha_3                               0.98349      0.00085    0.98482     0.98216
alpha_4                               0.98349      0.00085    0.98482     0.98216
alpha_5                               0.98348      0.00085    0.98481     0.98215
alpha_6                               0.98347      0.00085    0.98480     0.98214
alpha_7                               0.98348      0.00085    0.98481     0.98215
alpha_8                               0.98348      0.00085    0.98481     0.98215
alpha_9                               0.98348      0.00085    0.98481     0.98215
Alpha_loss                            -0.10979     0.00577    -0.10071    -0.11894
Training/policy_loss                  -2.71522     0.00929    -2.69829    -2.73243
Training/qf1_loss                     2649.99894   748.06606  3662.10010  1028.49219
Training/qf2_loss                     2650.20311   748.08148  3662.31567  1028.63867
Training/pf_norm                      0.31554      0.03002    0.36612     0.27330
Training/qf1_norm                     29.45147     2.36988    31.58821    23.16393
Training/qf2_norm                     28.40781     2.27310    30.53196    22.38750
log_std/mean                          -0.04782     0.00343    -0.04251    -0.05327
log_std/std                           0.00640      0.00044    0.00708     0.00572
log_std/max                           -0.03616     0.00267    -0.03199    -0.04039
log_std/min                           -0.06211     0.00446    -0.05526    -0.06918
log_probs/mean                        -2.71096     0.00950    -2.69265    -2.72969
log_probs/std                         0.33981      0.00715    0.35273     0.32922
log_probs/max                         -1.70283     0.06014    -1.62120    -1.84207
log_probs/min                         -4.20496     0.38515    -3.53778    -4.84503
mean/mean                             -0.00087     0.00072    0.00026     -0.00190
mean/std                              0.00328      0.00007    0.00345     0.00322
mean/max                              0.00579      0.00063    0.00686     0.00498
mean/min                              -0.00804     0.00131    -0.00618    -0.01009
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 5, 0, 2, 8, 1, 6, 3, 9, 4]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.4527926445007324 1.8835067749023438e-05
train_time 1.4528491497039795
2023-09-06 13:23:57,215 MainThread INFO: EPOCH:6
2023-09-06 13:23:57,215 MainThread INFO: Time Consumed:1.4599146842956543s
2023-09-06 13:23:57,215 MainThread INFO: Total Frames:10500s
  4%|▎         | 7/200 [00:19<06:10,  1.92s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1065.06222
Train_Epoch_Reward                    6813.69687
Running_Training_Average_Rewards      1363.73838
Explore_Time                          0.00354
Train___Time                          1.45285
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.33268
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.38954
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.62576
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.34938
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43228
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.23472
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.74815
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11167.98378
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.40741
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.00622
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.38287      0.83305    10.66122    8.49405
alpha_0                               0.98051      0.00085    0.98184     0.97919
alpha_1                               0.98052      0.00085    0.98184     0.97919
alpha_2                               0.98053      0.00085    0.98186     0.97921
alpha_3                               0.98054      0.00085    0.98187     0.97921
alpha_4                               0.98054      0.00085    0.98186     0.97922
alpha_5                               0.98053      0.00085    0.98186     0.97921
alpha_6                               0.98052      0.00085    0.98184     0.97919
alpha_7                               0.98052      0.00085    0.98185     0.97920
alpha_8                               0.98053      0.00085    0.98185     0.97921
alpha_9                               0.98052      0.00085    0.98185     0.97920
Alpha_loss                            -0.13006     0.00587    -0.12087    -0.13947
Training/policy_loss                  -2.72611     0.00847    -2.71300    -2.74503
Training/qf1_loss                     2344.23240   691.97430  3670.84839  1530.09827
Training/qf2_loss                     2344.49272   691.98380  3671.13745  1530.35767
Training/pf_norm                      0.27605      0.03810    0.31703     0.18375
Training/qf1_norm                     29.86954     1.98288    33.29826    27.82607
Training/qf2_norm                     28.49485     1.89915    31.47788    26.39617
log_std/mean                          -0.06037     0.00374    -0.05455    -0.06626
log_std/std                           0.00798      0.00046    0.00871     0.00726
log_std/max                           -0.04623     0.00312    -0.04134    -0.05110
log_std/min                           -0.07820     0.00472    -0.07086    -0.08579
log_probs/mean                        -2.71591     0.00750    -2.70425    -2.73174
log_probs/std                         0.31967      0.00703    0.33205     0.30747
log_probs/max                         -1.72968     0.05671    -1.60988    -1.81108
log_probs/min                         -4.40984     0.31461    -4.02324    -4.96237
mean/mean                             0.00107      0.00034    0.00158     0.00048
mean/std                              0.00354      0.00026    0.00396     0.00323
mean/max                              0.00835      0.00085    0.00962     0.00715
mean/min                              -0.00761     0.00106    -0.00631    -0.00930
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 8, 3, 2, 9, 4, 0, 5, 6, 1]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.423743486404419 1.8358230590820312e-05
train_time 1.4238202571868896
snapshot at best
2023-09-06 13:23:59,663 MainThread INFO: EPOCH:7
2023-09-06 13:23:59,663 MainThread INFO: Time Consumed:2.2793025970458984s
2023-09-06 13:23:59,663 MainThread INFO: Total Frames:12000s
  4%|▍         | 8/200 [00:22<06:39,  2.08s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1094.54429
Train_Epoch_Reward                    7133.29601
Running_Training_Average_Rewards      676.38505
Explore_Time                          0.00372
Train___Time                          1.42382
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.16893
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.07555
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.06826
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.04715
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.55814
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.39459
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.82468
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11583.93346
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.13199
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.61314
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.96267      1.04232    10.75001    6.76060
alpha_0                               0.97757      0.00084    0.97890     0.97625
alpha_1                               0.97757      0.00084    0.97889     0.97625
alpha_2                               0.97759      0.00084    0.97891     0.97627
alpha_3                               0.97759      0.00085    0.97892     0.97627
alpha_4                               0.97760      0.00084    0.97892     0.97628
alpha_5                               0.97759      0.00084    0.97891     0.97626
alpha_6                               0.97757      0.00084    0.97890     0.97625
alpha_7                               0.97758      0.00084    0.97890     0.97626
alpha_8                               0.97759      0.00084    0.97891     0.97627
alpha_9                               0.97758      0.00084    0.97890     0.97626
Alpha_loss                            -0.15036     0.00586    -0.14116    -0.15941
Training/policy_loss                  -2.73947     0.00870    -2.72378    -2.75338
Training/qf1_loss                     2269.92363   750.70269  3600.01807  1055.67114
Training/qf2_loss                     2270.22198   750.73520  3600.33521  1055.90393
Training/pf_norm                      0.25889      0.03419    0.30480     0.19113
Training/qf1_norm                     29.73275     2.67094    33.99427    23.99060
Training/qf2_norm                     28.25517     2.50810    32.52095    22.87534
log_std/mean                          -0.07352     0.00385    -0.06754    -0.07958
log_std/std                           0.00955      0.00044    0.01025     0.00886
log_std/max                           -0.05730     0.00335    -0.05214    -0.06267
log_std/min                           -0.09476     0.00483    -0.08737    -0.10236
log_probs/mean                        -2.72128     0.00758    -2.70584    -2.73301
log_probs/std                         0.29706      0.00779    0.30692     0.28578
log_probs/max                         -1.79338     0.08588    -1.61438    -1.90359
log_probs/min                         -4.28872     0.34751    -3.78906    -5.04348
mean/mean                             0.00139      0.00017    0.00159     0.00106
mean/std                              0.00462      0.00033    0.00503     0.00407
mean/max                              0.01032      0.00028    0.01060     0.00977
mean/min                              -0.01183     0.00143    -0.00968    -0.01402
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 4, 0, 1, 3, 6, 8, 5, 2, 7]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.0519742965698242 1.9550323486328125e-05
train_time 1.0520639419555664
snapshot at best
2023-09-06 13:24:01,491 MainThread INFO: EPOCH:8
2023-09-06 13:24:01,491 MainThread INFO: Time Consumed:1.7330868244171143s
2023-09-06 13:24:01,491 MainThread INFO: Total Frames:13500s
  4%|▍         | 9/200 [00:23<06:22,  2.00s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1136.55381
Train_Epoch_Reward                    20343.51996
Running_Training_Average_Rewards      1143.01709
Explore_Time                          0.00339
Train___Time                          1.05206
Eval____Time                          0.00329
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.12232
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.03271
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.47727
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.86781
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.74942
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.58656
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.99753
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12118.99614
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.01294
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.04389
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.99453      0.52840    9.83446     8.16667
alpha_0                               0.97464      0.00084    0.97596     0.97332
alpha_1                               0.97463      0.00084    0.97595     0.97332
alpha_2                               0.97466      0.00084    0.97597     0.97334
alpha_3                               0.97465      0.00084    0.97598     0.97333
alpha_4                               0.97467      0.00084    0.97599     0.97335
alpha_5                               0.97465      0.00084    0.97597     0.97333
alpha_6                               0.97464      0.00084    0.97596     0.97332
alpha_7                               0.97465      0.00084    0.97596     0.97333
alpha_8                               0.97465      0.00084    0.97597     0.97333
alpha_9                               0.97465      0.00084    0.97597     0.97333
Alpha_loss                            -0.17070     0.00584    -0.16163    -0.17977
Training/policy_loss                  -2.75488     0.00720    -2.74399    -2.76622
Training/qf1_loss                     2036.35597   523.64700  2941.76392  1255.94824
Training/qf2_loss                     2036.72606   523.66151  2942.08862  1256.25195
Training/pf_norm                      0.21660      0.03286    0.28346     0.17214
Training/qf1_norm                     31.10242     1.57276    34.18447    28.36861
Training/qf2_norm                     29.25649     1.38449    31.49122    26.96336
log_std/mean                          -0.08727     0.00399    -0.08097    -0.09347
log_std/std                           0.01106      0.00041    0.01166     0.01038
log_std/max                           -0.06930     0.00341    -0.06386    -0.07466
log_std/min                           -0.11161     0.00484    -0.10386    -0.11915
log_probs/mean                        -2.72629     0.00567    -2.71840    -2.73469
log_probs/std                         0.28176      0.00943    0.30490     0.26724
log_probs/max                         -1.89343     0.04932    -1.79614    -1.97538
log_probs/min                         -4.89937     0.68078    -4.02235    -6.43889
mean/mean                             0.00095      0.00012    0.00124     0.00083
mean/std                              0.00507      0.00007    0.00518     0.00494
mean/max                              0.00897      0.00049    0.00987     0.00816
mean/min                              -0.01521     0.00048    -0.01437    -0.01576
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 0, 8, 2, 1, 6, 5, 7, 9, 3]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.198387861251831 2.8848648071289062e-05
train_time 1.1988093852996826
snapshot at best
2023-09-06 13:24:03,645 MainThread INFO: EPOCH:9
2023-09-06 13:24:03,646 MainThread INFO: Time Consumed:2.059251070022583s
2023-09-06 13:24:03,646 MainThread INFO: Total Frames:15000s
  5%|▌         | 10/200 [00:26<06:29,  2.05s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1171.91237
Train_Epoch_Reward                    3157.09249
Running_Training_Average_Rewards      1021.13028
Explore_Time                          0.00409
Train___Time                          1.19881
Eval____Time                          0.00376
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.62438
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.34544
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40637
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.98860
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.71230
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.49989
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.97790
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12214.89907
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.24120
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.88867
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.86031      1.20141    11.01345    7.05654
alpha_0                               0.97171      0.00084    0.97302     0.97039
alpha_1                               0.97171      0.00084    0.97302     0.97039
alpha_2                               0.97173      0.00084    0.97304     0.97041
alpha_3                               0.97172      0.00084    0.97304     0.97041
alpha_4                               0.97175      0.00084    0.97306     0.97043
alpha_5                               0.97173      0.00084    0.97304     0.97041
alpha_6                               0.97171      0.00084    0.97303     0.97039
alpha_7                               0.97172      0.00084    0.97303     0.97040
alpha_8                               0.97172      0.00084    0.97304     0.97041
alpha_9                               0.97172      0.00084    0.97304     0.97040
Alpha_loss                            -0.19105     0.00588    -0.18196    -0.20019
Training/policy_loss                  -2.77258     0.01007    -2.75957    -2.78976
Training/qf1_loss                     1923.53824   824.53323  3456.86963  977.24554
Training/qf2_loss                     1923.97963   824.60220  3457.47119  977.64496
Training/pf_norm                      0.16488      0.04249    0.24527     0.11324
Training/qf1_norm                     32.15776     3.76648    39.24422    26.98036
Training/qf2_norm                     29.97602     3.44415    35.96925    24.71200
log_std/mean                          -0.10056     0.00358    -0.09485    -0.10607
log_std/std                           0.01228      0.00031    0.01280     0.01182
log_std/max                           -0.08086     0.00317    -0.07567    -0.08583
log_std/min                           -0.12766     0.00442    -0.12075    -0.13450
log_probs/mean                        -2.73054     0.00828    -2.71857    -2.74764
log_probs/std                         0.26570      0.01211    0.28428     0.24650
log_probs/max                         -1.97021     0.05335    -1.89850    -2.08354
log_probs/min                         -4.95672     0.55698    -3.99409    -5.98030
mean/mean                             0.00161      0.00007    0.00167     0.00144
mean/std                              0.00489      0.00017    0.00512     0.00458
mean/max                              0.01021      0.00014    0.01037     0.01000
mean/min                              -0.01355     0.00087    -0.01213    -0.01482
------------------------------------  -----------  ---------  ----------  ---------
sample: [0, 2, 9, 6, 1, 3, 7, 4, 5, 8]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.1481029987335205 5.91278076171875e-05
train_time 1.1482341289520264
snapshot at best
2023-09-06 13:24:05,793 MainThread INFO: EPOCH:10
2023-09-06 13:24:05,793 MainThread INFO: Time Consumed:2.055246114730835s
2023-09-06 13:24:05,794 MainThread INFO: Total Frames:16500s
  6%|▌         | 11/200 [00:28<06:33,  2.08s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1207.27205
Train_Epoch_Reward                    18395.00944
Running_Training_Average_Rewards      1396.52073
Explore_Time                          0.00436
Train___Time                          1.14823
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.09146
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.20278
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.57663
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.73020
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.47943
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.22205
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.76998
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12631.56482
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.11347
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.53724
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.38470      0.88173    10.91589    8.03351
alpha_0                               0.96879      0.00084    0.97010     0.96747
alpha_1                               0.96879      0.00084    0.97010     0.96748
alpha_2                               0.96881      0.00084    0.97012     0.96750
alpha_3                               0.96880      0.00084    0.97011     0.96749
alpha_4                               0.96883      0.00084    0.97014     0.96752
alpha_5                               0.96881      0.00084    0.97012     0.96750
alpha_6                               0.96879      0.00084    0.97010     0.96748
alpha_7                               0.96880      0.00084    0.97011     0.96749
alpha_8                               0.96880      0.00084    0.97012     0.96749
alpha_9                               0.96880      0.00084    0.97011     0.96749
Alpha_loss                            -0.21127     0.00580    -0.20217    -0.22046
Training/policy_loss                  -2.78822     0.00638    -2.78051    -2.79905
Training/qf1_loss                     2064.00208   714.78974  3433.81885  1219.24158
Training/qf2_loss                     2064.51808   714.83666  3434.44336  1219.65332
Training/pf_norm                      0.14804      0.02822    0.19718     0.10572
Training/qf1_norm                     35.25307     2.85240    40.29486    30.71738
Training/qf2_norm                     32.77692     2.65766    37.24590    28.87326
log_std/mean                          -0.11213     0.00305    -0.10726    -0.11691
log_std/std                           0.01322      0.00018    0.01345     0.01287
log_std/max                           -0.09130     0.00297    -0.08673    -0.09596
log_std/min                           -0.14126     0.00329    -0.13595    -0.14661
log_probs/mean                        -2.72958     0.00458    -2.72124    -2.74039
log_probs/std                         0.24570      0.01253    0.27700     0.22808
log_probs/max                         -2.03172     0.04337    -1.96368    -2.11396
log_probs/min                         -4.60886     0.51012    -4.07753    -5.69028
mean/mean                             0.00111      0.00031    0.00143     0.00053
mean/std                              0.00434      0.00008    0.00453     0.00425
mean/max                              0.01057      0.00015    0.01082     0.01038
mean/min                              -0.01143     0.00032    -0.01111    -0.01203
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 7, 0, 2, 4, 6, 8, 9, 1, 5]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.147878646850586 6.604194641113281e-05
train_time 1.1480095386505127
snapshot at best
2023-09-06 13:24:07,767 MainThread INFO: EPOCH:11
2023-09-06 13:24:07,767 MainThread INFO: Time Consumed:1.8775875568389893s
2023-09-06 13:24:07,767 MainThread INFO: Total Frames:18000s
  6%|▌         | 12/200 [00:30<06:24,  2.05s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1224.90298
Train_Epoch_Reward                    13573.07310
Running_Training_Average_Rewards      1170.83917
Explore_Time                          0.00382
Train___Time                          1.14801
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.78388
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.04405
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.51852
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.59429
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.19105
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94140
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.45654
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12638.16168
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.95419
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.64430
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.75859      1.20412    11.84148    7.78052
alpha_0                               0.96587      0.00084    0.96718     0.96456
alpha_1                               0.96588      0.00083    0.96719     0.96457
alpha_2                               0.96590      0.00083    0.96721     0.96460
alpha_3                               0.96589      0.00083    0.96720     0.96458
alpha_4                               0.96592      0.00083    0.96723     0.96461
alpha_5                               0.96590      0.00083    0.96721     0.96460
alpha_6                               0.96588      0.00083    0.96719     0.96457
alpha_7                               0.96589      0.00083    0.96720     0.96458
alpha_8                               0.96589      0.00083    0.96720     0.96459
alpha_9                               0.96589      0.00083    0.96720     0.96458
Alpha_loss                            -0.23151     0.00579    -0.22243    -0.24026
Training/policy_loss                  -2.80811     0.00764    -2.79908    -2.82245
Training/qf1_loss                     2214.37776   781.89436  3798.45508  1137.73987
Training/qf2_loss                     2214.97501   781.97539  3799.21167  1138.21094
Training/pf_norm                      0.12637      0.02124    0.16669     0.09435
Training/qf1_norm                     38.26428     3.93577    44.61441    31.63446
Training/qf2_norm                     35.33860     3.48298    40.84421    29.41025
log_std/mean                          -0.12162     0.00218    -0.11791    -0.12475
log_std/std                           0.01367      0.00007    0.01377     0.01353
log_std/max                           -0.10004     0.00185    -0.09682    -0.10247
log_std/min                           -0.15073     0.00187    -0.14733    -0.15322
log_probs/mean                        -2.72937     0.00564    -2.71937    -2.73610
log_probs/std                         0.23527      0.01506    0.25759     0.20444
log_probs/max                         -2.05291     0.05121    -1.97245    -2.14267
log_probs/min                         -4.68356     0.77474    -3.84001    -6.44218
mean/mean                             -0.00027     0.00036    0.00037     -0.00066
mean/std                              0.00467      0.00025    0.00509     0.00432
mean/max                              0.01209      0.00066    0.01311     0.01089
mean/min                              -0.01272     0.00015    -0.01243    -0.01293
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 0, 7, 5, 2, 1, 8, 9, 3, 6]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.2069919109344482 2.6464462280273438e-05
train_time 1.2070887088775635
2023-09-06 13:24:09,079 MainThread INFO: EPOCH:12
2023-09-06 13:24:09,079 MainThread INFO: Time Consumed:1.2153751850128174s
2023-09-06 13:24:09,079 MainThread INFO: Total Frames:19500s
  6%|▋         | 13/200 [00:31<05:41,  1.82s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1221.75463
Train_Epoch_Reward                    26941.11476
Running_Training_Average_Rewards      1963.63991
Explore_Time                          0.00446
Train___Time                          1.20709
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.56069
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.31198
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.19253
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.88586
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.07865
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.73686
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.35850
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12117.03208
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.08712
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.05601
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.01358     0.75789    11.24136    9.09496
alpha_0                               0.96297      0.00083    0.96427     0.96166
alpha_1                               0.96298      0.00083    0.96428     0.96167
alpha_2                               0.96300      0.00083    0.96431     0.96170
alpha_3                               0.96299      0.00083    0.96429     0.96169
alpha_4                               0.96301      0.00083    0.96432     0.96171
alpha_5                               0.96300      0.00083    0.96431     0.96170
alpha_6                               0.96298      0.00083    0.96428     0.96167
alpha_7                               0.96299      0.00083    0.96429     0.96169
alpha_8                               0.96300      0.00083    0.96430     0.96169
alpha_9                               0.96299      0.00083    0.96429     0.96168
Alpha_loss                            -0.25202     0.00576    -0.24310    -0.26106
Training/policy_loss                  -2.83929     0.00744    -2.82747    -2.85255
Training/qf1_loss                     2258.02676   499.83705  3257.99927  1672.84900
Training/qf2_loss                     2258.73157   499.89162  3258.84668  1673.48694
Training/pf_norm                      0.11920      0.02168    0.17513     0.09247
Training/qf1_norm                     41.57958     2.79694    46.97353    38.23603
Training/qf2_norm                     38.06140     2.35830    42.54742    35.07127
log_std/mean                          -0.12740     0.00121    -0.12534    -0.12913
log_std/std                           0.01355      0.00009    0.01371     0.01339
log_std/max                           -0.10454     0.00074    -0.10309    -0.10560
log_std/min                           -0.15509     0.00081    -0.15326    -0.15591
log_probs/mean                        -2.73660     0.00547    -2.72758    -2.74476
log_probs/std                         0.23821      0.00637    0.25008     0.23031
log_probs/max                         -2.11553     0.04765    -2.03057    -2.17857
log_probs/min                         -4.71462     0.35155    -4.12423    -5.20585
mean/mean                             -0.00030     0.00012    -0.00009    -0.00046
mean/std                              0.00630      0.00083    0.00767     0.00524
mean/max                              0.01471      0.00098    0.01642     0.01328
mean/min                              -0.01321     0.00118    -0.01183    -0.01521
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 2, 0, 7, 8, 6, 9, 1, 5, 4]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6605546474456787 2.1219253540039062e-05
train_time 1.660635232925415
2023-09-06 13:24:10,923 MainThread INFO: EPOCH:13
2023-09-06 13:24:10,923 MainThread INFO: Time Consumed:1.6707532405853271s
2023-09-06 13:24:10,923 MainThread INFO: Total Frames:21000s
  7%|▋         | 14/200 [00:33<05:40,  1.83s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1181.60842
Train_Epoch_Reward                    10249.99542
Running_Training_Average_Rewards      1692.13944
Explore_Time                          0.00521
Train___Time                          1.66064
Eval____Time                          0.00437
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.52215
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.63309
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.77935
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.24661
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.11347
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.67484
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.51198
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11431.87482
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.29199
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.64601
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           10.27793     1.50697     12.57784    7.98891
alpha_0                               0.96007      0.00083     0.96137     0.95877
alpha_1                               0.96008      0.00083     0.96139     0.95878
alpha_2                               0.96011      0.00083     0.96141     0.95881
alpha_3                               0.96010      0.00083     0.96140     0.95880
alpha_4                               0.96012      0.00083     0.96142     0.95882
alpha_5                               0.96011      0.00083     0.96141     0.95881
alpha_6                               0.96008      0.00083     0.96139     0.95879
alpha_7                               0.96010      0.00083     0.96140     0.95880
alpha_8                               0.96010      0.00083     0.96140     0.95881
alpha_9                               0.96009      0.00083     0.96139     0.95879
Alpha_loss                            -0.27231     0.00590     -0.26351    -0.28198
Training/policy_loss                  -2.86767     0.01410     -2.84976    -2.89456
Training/qf1_loss                     2322.48994   1015.42877  4158.34912  1036.29968
Training/qf2_loss                     2323.24795   1015.52154  4159.24707  1036.85828
Training/pf_norm                      0.13307      0.02386     0.17558     0.10619
Training/qf1_norm                     44.93563     5.63572     53.48261    35.71901
Training/qf2_norm                     41.08323     5.16387     48.92365    33.03222
log_std/mean                          -0.13069     0.00067     -0.12951    -0.13154
log_std/std                           0.01307      0.00019     0.01334     0.01277
log_std/max                           -0.10671     0.00040     -0.10612    -0.10735
log_std/min                           -0.15766     0.00068     -0.15630    -0.15854
log_probs/mean                        -2.73705     0.00987     -2.72205    -2.75018
log_probs/std                         0.24042      0.01144     0.25331     0.21738
log_probs/max                         -2.10891     0.05618     -2.02160    -2.18446
log_probs/min                         -5.01286     0.45733     -4.29311    -5.93678
mean/mean                             -0.00041     0.00014     -0.00015    -0.00056
mean/std                              0.00846      0.00023     0.00869     0.00793
mean/max                              0.01825      0.00071     0.01923     0.01694
mean/min                              -0.01635     0.00096     -0.01459    -0.01743
------------------------------------  -----------  ----------  ----------  ----------
sample: [6, 2, 1, 7, 9, 5, 4, 3, 8, 0]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.750525951385498 1.9311904907226562e-05
train_time 1.7506325244903564
2023-09-06 13:24:12,933 MainThread INFO: EPOCH:14
2023-09-06 13:24:12,933 MainThread INFO: Time Consumed:1.7991364002227783s
2023-09-06 13:24:12,933 MainThread INFO: Total Frames:22500s
  8%|▊         | 15/200 [00:35<05:51,  1.90s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1113.71310
Train_Epoch_Reward                    14821.76866
Running_Training_Average_Rewards      1733.76263
Explore_Time                          0.04471
Train___Time                          1.75063
Eval____Time                          0.00321
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.97710
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.77550
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.27582
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.50931
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.87554
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.45719
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.41685
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10603.16993
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.42529
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.28361
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.10572     0.60246    10.67987    8.78081
alpha_0                               0.95719      0.00083    0.95848     0.95589
alpha_1                               0.95720      0.00083    0.95850     0.95590
alpha_2                               0.95722      0.00083    0.95852     0.95593
alpha_3                               0.95722      0.00083    0.95851     0.95592
alpha_4                               0.95724      0.00083    0.95853     0.95594
alpha_5                               0.95723      0.00083    0.95852     0.95593
alpha_6                               0.95720      0.00083    0.95850     0.95591
alpha_7                               0.95721      0.00083    0.95851     0.95592
alpha_8                               0.95722      0.00083    0.95852     0.95593
alpha_9                               0.95721      0.00083    0.95850     0.95591
Alpha_loss                            -0.29238     0.00573    -0.28386    -0.30143
Training/policy_loss                  -2.89564     0.00966    -2.88439    -2.91318
Training/qf1_loss                     1974.40056   359.60509  2450.95093  1258.76050
Training/qf2_loss                     1975.16031   359.65183  2451.84155  1259.44128
Training/pf_norm                      0.13316      0.03371    0.19026     0.08070
Training/qf1_norm                     46.91410     2.32189    48.80894    41.26794
Training/qf2_norm                     42.97638     2.02876    45.25944    37.78715
log_std/mean                          -0.13148     0.00011    -0.13131    -0.13166
log_std/std                           0.01236      0.00021    0.01272     0.01208
log_std/max                           -0.10782     0.00043    -0.10745    -0.10898
log_std/min                           -0.15854     0.00042    -0.15788    -0.15920
log_probs/mean                        -2.73260     0.00563    -2.72613    -2.74656
log_probs/std                         0.23617      0.01159    0.25800     0.21291
log_probs/max                         -2.12748     0.04346    -2.05412    -2.20889
log_probs/min                         -4.92805     0.50681    -4.22260    -6.01906
mean/mean                             -0.00003     0.00007    0.00008     -0.00014
mean/std                              0.00754      0.00046    0.00835     0.00684
mean/max                              0.01720      0.00129    0.01936     0.01530
mean/min                              -0.01233     0.00065    -0.01159    -0.01386
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 0, 1, 6, 9, 3, 7, 4, 5, 8]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.0134620666503906 5.650520324707031e-05
train_time 2.0135860443115234
2023-09-06 13:24:15,131 MainThread INFO: EPOCH:15
2023-09-06 13:24:15,132 MainThread INFO: Time Consumed:2.0344066619873047s
2023-09-06 13:24:15,132 MainThread INFO: Total Frames:24000s
  8%|▊         | 16/200 [00:37<06:05,  1.99s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1071.17812
Train_Epoch_Reward                    29280.10474
Running_Training_Average_Rewards      1811.72896
Explore_Time                          0.01719
Train___Time                          2.01359
Eval____Time                          0.00312
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.60356
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.77194
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.28017
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.26194
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.62290
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.21685
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.09880
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10846.88658
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.33338
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.98238
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.12574     0.74274    11.05057    8.46463
alpha_0                               0.95431      0.00082    0.95560     0.95302
alpha_1                               0.95432      0.00082    0.95562     0.95303
alpha_2                               0.95435      0.00082    0.95564     0.95306
alpha_3                               0.95434      0.00082    0.95564     0.95305
alpha_4                               0.95436      0.00082    0.95566     0.95307
alpha_5                               0.95435      0.00082    0.95564     0.95306
alpha_6                               0.95433      0.00082    0.95562     0.95304
alpha_7                               0.95434      0.00082    0.95563     0.95305
alpha_8                               0.95435      0.00082    0.95564     0.95306
alpha_9                               0.95433      0.00082    0.95562     0.95304
Alpha_loss                            -0.31267     0.00577    -0.30378    -0.32186
Training/policy_loss                  -2.93413     0.01132    -2.91636    -2.95457
Training/qf1_loss                     2187.02272   421.41826  2688.28516  1267.37341
Training/qf2_loss                     2187.84182   421.41272  2689.06909  1268.06702
Training/pf_norm                      0.12121      0.02409    0.15281     0.07269
Training/qf1_norm                     50.33872     3.57911    55.48268    43.56648
Training/qf2_norm                     45.86787     3.23752    51.08267    39.78416
log_std/mean                          -0.13158     0.00005    -0.13150    -0.13164
log_std/std                           0.01164      0.00027    0.01203     0.01126
log_std/max                           -0.10988     0.00065    -0.10885    -0.11094
log_std/min                           -0.15927     0.00032    -0.15880    -0.15977
log_probs/mean                        -2.73339     0.00401    -2.72650    -2.74085
log_probs/std                         0.24511      0.01350    0.27390     0.21852
log_probs/max                         -2.09387     0.04002    -2.03028    -2.17587
log_probs/min                         -5.35212     0.85296    -4.15389    -7.49386
mean/mean                             0.00086      0.00058    0.00187     0.00015
mean/std                              0.00566      0.00045    0.00656     0.00525
mean/max                              0.01235      0.00114    0.01456     0.01075
mean/min                              -0.01159     0.00019    -0.01129    -0.01190
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 7, 4, 1, 9, 3, 2, 5, 0, 6]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.0013978481292725 3.147125244140625e-05
train_time 2.0014889240264893
2023-09-06 13:24:17,280 MainThread INFO: EPOCH:16
2023-09-06 13:24:17,280 MainThread INFO: Time Consumed:2.008770227432251s
2023-09-06 13:24:17,280 MainThread INFO: Total Frames:25500s
  8%|▊         | 17/200 [00:39<06:12,  2.03s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1073.41239
Train_Epoch_Reward                    17383.26652
Running_Training_Average_Rewards      2049.50466
Explore_Time                          0.00344
Train___Time                          2.00149
Eval____Time                          0.00310
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.52087
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.34211
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.74938
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.73797
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.42892
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.05515
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.88529
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11495.53634
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.93557
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.39763
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.52822      0.86124    10.81550    7.93294
alpha_0                               0.95144      0.00082    0.95273     0.95016
alpha_1                               0.95146      0.00082    0.95275     0.95017
alpha_2                               0.95149      0.00082    0.95277     0.95020
alpha_3                               0.95148      0.00082    0.95277     0.95019
alpha_4                               0.95150      0.00082    0.95278     0.95021
alpha_5                               0.95149      0.00082    0.95277     0.95020
alpha_6                               0.95147      0.00082    0.95275     0.95018
alpha_7                               0.95148      0.00082    0.95276     0.95019
alpha_8                               0.95148      0.00082    0.95277     0.95020
alpha_9                               0.95147      0.00082    0.95275     0.95018
Alpha_loss                            -0.33300     0.00584    -0.32378    -0.34205
Training/policy_loss                  -2.97865     0.01439    -2.95547    -3.00062
Training/qf1_loss                     1733.60863   391.33633  2301.76050  1052.31897
Training/qf2_loss                     1734.25328   391.30894  2302.27539  1052.95447
Training/pf_norm                      0.13594      0.03667    0.19310     0.08551
Training/qf1_norm                     50.32192     3.26008    55.15590    44.95570
Training/qf2_norm                     46.41671     3.51554    51.71421    40.97217
log_std/mean                          -0.13133     0.00014    -0.13114    -0.13160
log_std/std                           0.01081      0.00022    0.01116     0.01044
log_std/max                           -0.11210     0.00053    -0.11110    -0.11266
log_std/min                           -0.15753     0.00092    -0.15531    -0.15879
log_probs/mean                        -2.73517     0.00461    -2.72652    -2.74168
log_probs/std                         0.23821      0.02198    0.30253     0.22416
log_probs/max                         -2.14740     0.03657    -2.05937    -2.18914
log_probs/min                         -5.15640     1.42261    -4.07271    -9.24689
mean/mean                             0.00191      0.00026    0.00227     0.00149
mean/std                              0.00565      0.00013    0.00582     0.00542
mean/max                              0.01468      0.00043    0.01518     0.01371
mean/min                              -0.01298     0.00120    -0.01128    -0.01460
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 5, 3, 7, 2, 1, 4, 6, 0, 9]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8717362880706787 1.811981201171875e-05
train_time 1.8718161582946777
2023-09-06 13:24:19,338 MainThread INFO: EPOCH:17
2023-09-06 13:24:19,372 MainThread INFO: Time Consumed:1.8791916370391846s
2023-09-06 13:24:19,372 MainThread INFO: Total Frames:27000s
  9%|▉         | 18/200 [00:41<06:13,  2.05s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1136.10957
Train_Epoch_Reward                    12178.51680
Running_Training_Average_Rewards      1961.39627
Explore_Time                          0.00343
Train___Time                          1.87182
Eval____Time                          0.00338
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.61520
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.77612
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.56272
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.08706
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.68861
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.34954
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.31211
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12487.50701
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.34953
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.67725
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.86609      0.78995    11.27890    8.68588
alpha_0                               0.94859      0.00082    0.94987     0.94730
alpha_1                               0.94860      0.00082    0.94989     0.94732
alpha_2                               0.94863      0.00082    0.94992     0.94735
alpha_3                               0.94862      0.00082    0.94990     0.94734
alpha_4                               0.94864      0.00082    0.94992     0.94735
alpha_5                               0.94863      0.00082    0.94991     0.94735
alpha_6                               0.94861      0.00082    0.94989     0.94732
alpha_7                               0.94862      0.00082    0.94990     0.94734
alpha_8                               0.94863      0.00082    0.94991     0.94735
alpha_9                               0.94861      0.00082    0.94989     0.94732
Alpha_loss                            -0.35329     0.00600    -0.34351    -0.36269
Training/policy_loss                  -3.02751     0.01884    -2.99127    -3.05611
Training/qf1_loss                     1896.20590   478.05162  2903.08374  1280.92175
Training/qf2_loss                     1896.84681   478.19342  2904.04956  1281.37354
Training/pf_norm                      0.11310      0.02070    0.15102     0.08816
Training/qf1_norm                     55.41012     4.05216    62.58058    49.88790
Training/qf2_norm                     51.13506     3.29350    56.60606    46.42607
log_std/mean                          -0.13124     0.00026    -0.13098    -0.13175
log_std/std                           0.01005      0.00018    0.01032     0.00977
log_std/max                           -0.11326     0.00050    -0.11264    -0.11419
log_std/min                           -0.15533     0.00064    -0.15434    -0.15649
log_probs/mean                        -2.73586     0.00680    -2.72276    -2.74390
log_probs/std                         0.24833      0.02452    0.30280     0.21861
log_probs/max                         -2.15268     0.04350    -2.04232    -2.19247
log_probs/min                         -5.38208     0.92225    -4.15980    -7.47146
mean/mean                             0.00150      0.00004    0.00159     0.00142
mean/std                              0.00604      0.00019    0.00640     0.00582
mean/max                              0.01415      0.00014    0.01440     0.01395
mean/min                              -0.01403     0.00035    -0.01369    -0.01479
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 7, 8, 6, 5, 2, 9, 0, 3, 1]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.9635515213012695 1.9311904907226562e-05
train_time 1.9643187522888184
snapshot at best
2023-09-06 13:24:22,246 MainThread INFO: EPOCH:18
2023-09-06 13:24:22,246 MainThread INFO: Time Consumed:2.7078800201416016s
2023-09-06 13:24:22,246 MainThread INFO: Total Frames:28500s
 10%|▉         | 19/200 [00:44<06:54,  2.29s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1197.65859
Train_Epoch_Reward                    7193.52531
Running_Training_Average_Rewards      1225.17695
Explore_Time                          0.00399
Train___Time                          1.96432
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.48122
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.86870
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.62928
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.90418
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.71793
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.27826
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.55180
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12691.38595
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.49146
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.27771
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.87858      0.66720    11.08411    8.67000
alpha_0                               0.94574      0.00082    0.94702     0.94446
alpha_1                               0.94576      0.00082    0.94704     0.94448
alpha_2                               0.94579      0.00082    0.94707     0.94451
alpha_3                               0.94577      0.00082    0.94705     0.94449
alpha_4                               0.94579      0.00082    0.94707     0.94451
alpha_5                               0.94579      0.00082    0.94707     0.94451
alpha_6                               0.94576      0.00082    0.94704     0.94448
alpha_7                               0.94577      0.00082    0.94705     0.94450
alpha_8                               0.94578      0.00082    0.94706     0.94450
alpha_9                               0.94576      0.00082    0.94704     0.94448
Alpha_loss                            -0.37343     0.00582    -0.36456    -0.38258
Training/policy_loss                  -3.08001     0.01790    -3.05109    -3.10641
Training/qf1_loss                     2171.54430   337.36334  2810.62109  1718.60339
Training/qf2_loss                     2172.01267   337.36998  2810.97339  1718.92712
Training/pf_norm                      0.12885      0.02244    0.15865     0.08198
Training/qf1_norm                     58.59653     3.67823    65.80479    50.97308
Training/qf2_norm                     54.69029     3.55026    62.20929    47.96310
log_std/mean                          -0.13193     0.00004    -0.13185    -0.13201
log_std/std                           0.00931      0.00027    0.00971     0.00888
log_std/max                           -0.11454     0.00012    -0.11429    -0.11480
log_std/min                           -0.15340     0.00067    -0.15223    -0.15441
log_probs/mean                        -2.73374     0.00731    -2.72004    -2.74178
log_probs/std                         0.24331      0.01592    0.27265     0.22158
log_probs/max                         -2.13305     0.04873    -2.05298    -2.19574
log_probs/min                         -5.18195     0.77182    -4.15882    -6.44422
mean/mean                             0.00097      0.00057    0.00163     0.00004
mean/std                              0.00695      0.00025    0.00733     0.00653
mean/max                              0.01406      0.00039    0.01462     0.01329
mean/min                              -0.01778     0.00195    -0.01529    -0.02104
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 9, 4, 1, 3, 0, 2, 5, 6, 7]
replay_buffer._size: [3150 3150 3150 3150 3150 3150 3150 3150 3150 3150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.32151198387146 1.9311904907226562e-05
train_time 1.3215975761413574
snapshot at best
2023-09-06 13:24:24,330 MainThread INFO: EPOCH:19
2023-09-06 13:24:24,331 MainThread INFO: Time Consumed:1.9805245399475098s
2023-09-06 13:24:24,331 MainThread INFO: Total Frames:30000s
 10%|█         | 20/200 [00:46<06:41,  2.23s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1241.95480
Train_Epoch_Reward                    11487.89495
Running_Training_Average_Rewards      1028.66457
Explore_Time                          0.00300
Train___Time                          1.32160
Eval____Time                          0.00535
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.45585
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.83781
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.61761
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.76523
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.65811
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.12693
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.73068
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12828.03546
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.46517
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.00832
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.18570      0.74950    10.65471    8.23782
alpha_0                               0.94290      0.00081    0.94417     0.94162
alpha_1                               0.94292      0.00081    0.94419     0.94164
alpha_2                               0.94295      0.00081    0.94423     0.94168
alpha_3                               0.94293      0.00081    0.94421     0.94166
alpha_4                               0.94295      0.00081    0.94422     0.94167
alpha_5                               0.94295      0.00081    0.94422     0.94168
alpha_6                               0.94292      0.00081    0.94420     0.94165
alpha_7                               0.94294      0.00081    0.94421     0.94166
alpha_8                               0.94294      0.00081    0.94422     0.94167
alpha_9                               0.94292      0.00081    0.94419     0.94164
Alpha_loss                            -0.39356     0.00594    -0.38439    -0.40298
Training/policy_loss                  -3.13841     0.02072    -3.10741    -3.17337
Training/qf1_loss                     1627.60767   354.84479  2238.93872  1169.97742
Training/qf2_loss                     1627.94751   354.85276  2239.35474  1170.48071
Training/pf_norm                      0.13329      0.02135    0.16606     0.10109
Training/qf1_norm                     58.71236     3.92055    65.76495    53.49681
Training/qf2_norm                     54.94395     3.84852    61.60396    49.76722
log_std/mean                          -0.13194     0.00018    -0.13164    -0.13209
log_std/std                           0.00848      0.00025    0.00886     0.00811
log_std/max                           -0.11482     0.00035    -0.11433    -0.11540
log_std/min                           -0.15267     0.00062    -0.15172    -0.15348
log_probs/mean                        -2.73186     0.00670    -2.72337    -2.74850
log_probs/std                         0.22830      0.01847    0.26918     0.20480
log_probs/max                         -2.12078     0.03300    -2.08065    -2.17054
log_probs/min                         -4.49773     0.56388    -3.72849    -5.35634
mean/mean                             -0.00070     0.00032    -0.00011    -0.00115
mean/std                              0.00778      0.00017    0.00806     0.00747
mean/max                              0.01188      0.00095    0.01327     0.01036
mean/min                              -0.02428     0.00116    -0.02207    -0.02589
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 0, 9, 3, 7, 8, 5, 2, 1, 6]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.3837594985961914 3.528594970703125e-05
train_time 1.3838701248168945
snapshot at best
2023-09-06 13:24:26,784 MainThread INFO: EPOCH:20
2023-09-06 13:24:26,784 MainThread INFO: Time Consumed:2.2016618251800537s
2023-09-06 13:24:26,784 MainThread INFO: Total Frames:31500s
 10%|█         | 21/200 [00:49<06:50,  2.29s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1263.76111
Train_Epoch_Reward                    3721.50906
Running_Training_Average_Rewards      746.76431
Explore_Time                          0.00473
Train___Time                          1.38387
Eval____Time                          0.00366
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.78589
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.44411
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.50037
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -22.87250
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.75596
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.28347
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.86188
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13134.46657
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.96943
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.71485
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.95749      0.38611    9.42568     8.43475
alpha_0                               0.94007      0.00081    0.94134     0.93879
alpha_1                               0.94009      0.00081    0.94136     0.93881
alpha_2                               0.94013      0.00081    0.94140     0.93886
alpha_3                               0.94010      0.00081    0.94137     0.93883
alpha_4                               0.94012      0.00081    0.94139     0.93884
alpha_5                               0.94012      0.00081    0.94139     0.93885
alpha_6                               0.94009      0.00081    0.94136     0.93882
alpha_7                               0.94011      0.00081    0.94138     0.93884
alpha_8                               0.94011      0.00081    0.94138     0.93884
alpha_9                               0.94009      0.00081    0.94136     0.93882
Alpha_loss                            -0.41399     0.00565    -0.40510    -0.42285
Training/policy_loss                  -3.20973     0.01849    -3.18157    -3.23838
Training/qf1_loss                     1626.04860   275.32778  2073.79980  1232.06482
Training/qf2_loss                     1626.18256   275.36338  2073.87744  1231.87988
Training/pf_norm                      0.11348      0.01797    0.14494     0.08450
Training/qf1_norm                     60.79669     2.97340    64.89578    55.73073
Training/qf2_norm                     57.52324     2.72001    61.52916    52.98786
log_std/mean                          -0.13133     0.00022    -0.13102    -0.13167
log_std/std                           0.00756      0.00022    0.00792     0.00722
log_std/max                           -0.11636     0.00021    -0.11613    -0.11681
log_std/min                           -0.14978     0.00107    -0.14837    -0.15157
log_probs/mean                        -2.73520     0.00780    -2.72172    -2.74859
log_probs/std                         0.23705      0.01319    0.25496     0.20944
log_probs/max                         -2.17469     0.02934    -2.11322    -2.20955
log_probs/min                         -5.01510     0.76601    -3.78431    -6.00804
mean/mean                             -0.00117     0.00005    -0.00112    -0.00125
mean/std                              0.00877      0.00030    0.00928     0.00824
mean/max                              0.01220      0.00076    0.01344     0.01086
mean/min                              -0.02691     0.00043    -0.02628    -0.02772
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 2, 7, 5, 1, 4, 0, 3, 9, 6]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.5748109817504883 2.1696090698242188e-05
train_time 1.5749125480651855
2023-09-06 13:24:28,469 MainThread INFO: EPOCH:21
2023-09-06 13:24:28,469 MainThread INFO: Time Consumed:1.5874216556549072s
2023-09-06 13:24:28,469 MainThread INFO: Total Frames:33000s
 11%|█         | 22/200 [00:50<06:17,  2.12s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1274.59196
Train_Epoch_Reward                    7278.16744
Running_Training_Average_Rewards      749.58572
Explore_Time                          0.00469
Train___Time                          1.57491
Eval____Time                          0.00715
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.64207
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.17544
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27398
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.24661
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.02725
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.68857
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.04461
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13016.82924
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.59804
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.02174
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.25368      0.80751    10.38311    7.99422
alpha_0                               0.93724      0.00081    0.93851     0.93597
alpha_1                               0.93727      0.00081    0.93853     0.93600
alpha_2                               0.93731      0.00081    0.93858     0.93604
alpha_3                               0.93728      0.00081    0.93855     0.93602
alpha_4                               0.93729      0.00081    0.93856     0.93603
alpha_5                               0.93730      0.00081    0.93857     0.93604
alpha_6                               0.93727      0.00081    0.93854     0.93600
alpha_7                               0.93729      0.00081    0.93856     0.93602
alpha_8                               0.93729      0.00081    0.93856     0.93602
alpha_9                               0.93727      0.00081    0.93854     0.93600
Alpha_loss                            -0.43410     0.00570    -0.42491    -0.44333
Training/policy_loss                  -3.28204     0.02098    -3.24805    -3.31864
Training/qf1_loss                     1753.60651   354.09093  2290.82788  1259.63538
Training/qf2_loss                     1753.72700   354.05138  2291.07617  1259.91638
Training/pf_norm                      0.11857      0.02256    0.14991     0.07621
Training/qf1_norm                     66.80037     5.30849    74.49621    59.08715
Training/qf2_norm                     63.02758     5.11194    68.92589    55.53267
log_std/mean                          -0.13136     0.00011    -0.13114    -0.13151
log_std/std                           0.00690      0.00019    0.00712     0.00659
log_std/max                           -0.11733     0.00047    -0.11677    -0.11817
log_std/min                           -0.14880     0.00027    -0.14829    -0.14925
log_probs/mean                        -2.73314     0.00479    -2.72697    -2.74445
log_probs/std                         0.23009      0.01346    0.25754     0.21265
log_probs/max                         -2.13577     0.03691    -2.08156    -2.20195
log_probs/min                         -4.72027     0.42379    -4.18361    -5.51692
mean/mean                             -0.00090     0.00017    -0.00059    -0.00107
mean/std                              0.00950      0.00006    0.00958     0.00935
mean/max                              0.01465      0.00064    0.01590     0.01381
mean/min                              -0.02779     0.00054    -0.02658    -0.02838
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 0, 6, 1, 3, 8, 4, 9, 7, 5]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.1606504917144775 1.9550323486328125e-05
train_time 2.160717487335205
snapshot at best
2023-09-06 13:24:31,517 MainThread INFO: EPOCH:22
2023-09-06 13:24:31,517 MainThread INFO: Time Consumed:2.917665958404541s
2023-09-06 13:24:31,517 MainThread INFO: Total Frames:34500s
 12%|█▏        | 23/200 [00:54<07:03,  2.39s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1285.84347
Train_Epoch_Reward                    7136.09993
Running_Training_Average_Rewards      604.52588
Explore_Time                          0.00359
Train___Time                          2.16072
Eval____Time                          0.00349
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.60187
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.38510
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.29560
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.33355
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14114
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.94787
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.14637
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13163.64337
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.85891
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.01790
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.74334      0.37836    9.46427     8.06596
alpha_0                               0.93443      0.00081    0.93569     0.93317
alpha_1                               0.93445      0.00081    0.93572     0.93319
alpha_2                               0.93450      0.00081    0.93576     0.93323
alpha_3                               0.93447      0.00081    0.93574     0.93321
alpha_4                               0.93448      0.00081    0.93575     0.93322
alpha_5                               0.93449      0.00081    0.93576     0.93323
alpha_6                               0.93446      0.00081    0.93572     0.93319
alpha_7                               0.93448      0.00081    0.93574     0.93321
alpha_8                               0.93448      0.00081    0.93574     0.93322
alpha_9                               0.93445      0.00081    0.93572     0.93319
Alpha_loss                            -0.45450     0.00582    -0.44550    -0.46360
Training/policy_loss                  -3.36251     0.02413    -3.32799    -3.39901
Training/qf1_loss                     1568.21084   239.43563  2070.19653  1260.43457
Training/qf2_loss                     1568.04564   239.43080  2070.02905  1260.26367
Training/pf_norm                      0.11952      0.01807    0.15240     0.09766
Training/qf1_norm                     66.84054     2.42104    70.61915    62.95404
Training/qf2_norm                     63.88132     2.21583    67.43739    60.51778
log_std/mean                          -0.13207     0.00033    -0.13161    -0.13255
log_std/std                           0.00629      0.00020    0.00667     0.00605
log_std/max                           -0.11885     0.00049    -0.11793    -0.11954
log_std/min                           -0.14905     0.00050    -0.14817    -0.14990
log_probs/mean                        -2.73563     0.00561    -2.72313    -2.74441
log_probs/std                         0.23278      0.01529    0.25653     0.21007
log_probs/max                         -2.12905     0.02288    -2.09654    -2.16572
log_probs/min                         -4.97333     0.65663    -4.02984    -5.80624
mean/mean                             -0.00092     0.00019    -0.00064    -0.00125
mean/std                              0.00907      0.00013    0.00928     0.00884
mean/max                              0.01686      0.00031    0.01720     0.01619
mean/min                              -0.02525     0.00053    -0.02434    -0.02618
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 6, 4, 7, 0, 1, 2, 5, 9, 3]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.4625325202941895 6.437301635742188e-05
train_time 1.462662696838379
snapshot at best
2023-09-06 13:24:33,984 MainThread INFO: EPOCH:23
2023-09-06 13:24:33,984 MainThread INFO: Time Consumed:2.358182907104492s
2023-09-06 13:24:33,985 MainThread INFO: Total Frames:36000s
 12%|█▏        | 24/200 [00:56<07:04,  2.41s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1288.80055
Train_Epoch_Reward                    22498.57097
Running_Training_Average_Rewards      1230.42794
Explore_Time                          0.00304
Train___Time                          1.46266
Eval____Time                          0.00331
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.36035
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.19440
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.37211
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.22131
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.00874
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.82136
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.96740
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13236.84071
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.78548
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.11919
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.44571      0.59286    10.73882    8.59442
alpha_0                               0.93162      0.00081    0.93288     0.93036
alpha_1                               0.93165      0.00080    0.93291     0.93039
alpha_2                               0.93169      0.00080    0.93295     0.93043
alpha_3                               0.93167      0.00080    0.93293     0.93041
alpha_4                               0.93168      0.00080    0.93294     0.93042
alpha_5                               0.93169      0.00080    0.93295     0.93043
alpha_6                               0.93166      0.00080    0.93291     0.93040
alpha_7                               0.93167      0.00080    0.93293     0.93041
alpha_8                               0.93168      0.00080    0.93294     0.93042
alpha_9                               0.93165      0.00080    0.93291     0.93039
Alpha_loss                            -0.47472     0.00587    -0.46548    -0.48390
Training/policy_loss                  -3.44760     0.02567    -3.40827    -3.48625
Training/qf1_loss                     1862.20593   394.45620  2446.47290  1237.12256
Training/qf2_loss                     1862.01345   394.54818  2446.47485  1236.88647
Training/pf_norm                      0.12931      0.01979    0.17149     0.09498
Training/qf1_norm                     76.33125     5.13225    88.49152    69.20592
Training/qf2_norm                     72.75627     4.68410    84.49894    67.62632
log_std/mean                          -0.13296     0.00016    -0.13263    -0.13311
log_std/std                           0.00592      0.00008    0.00609     0.00583
log_std/max                           -0.11917     0.00044    -0.11854    -0.11998
log_std/min                           -0.14978     0.00051    -0.14895    -0.15033
log_probs/mean                        -2.73531     0.00230    -2.73136    -2.73932
log_probs/std                         0.23232      0.01275    0.25741     0.21773
log_probs/max                         -2.15056     0.04607    -2.08543    -2.21549
log_probs/min                         -4.89221     0.42332    -4.26290    -5.88140
mean/mean                             -0.00166     0.00014    -0.00141    -0.00183
mean/std                              0.00866      0.00007    0.00880     0.00854
mean/max                              0.01782      0.00033    0.01831     0.01733
mean/min                              -0.02409     0.00023    -0.02358    -0.02437
------------------------------------  -----------  ---------  ----------  ----------
sample: [6, 5, 3, 8, 4, 7, 9, 0, 1, 2]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.3863959312438965 1.9311904907226562e-05
train_time 1.3864693641662598
2023-09-06 13:24:35,480 MainThread INFO: EPOCH:24
2023-09-06 13:24:35,481 MainThread INFO: Time Consumed:1.3947031497955322s
2023-09-06 13:24:35,481 MainThread INFO: Total Frames:37500s
 12%|█▎        | 25/200 [00:57<06:14,  2.14s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1291.77803
Train_Epoch_Reward                    2065.39249
Running_Training_Average_Rewards      1056.66878
Explore_Time                          0.00365
Train___Time                          1.38647
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.52913
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.06498
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.14748
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.20480
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.61639
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.43270
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.60733
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13110.06893
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.72296
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.30756
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.91990      0.81218    10.47041    7.88725
alpha_0                               0.92882      0.00080    0.93008     0.92757
alpha_1                               0.92886      0.00080    0.93011     0.92760
alpha_2                               0.92890      0.00080    0.93015     0.92764
alpha_3                               0.92888      0.00080    0.93013     0.92762
alpha_4                               0.92888      0.00080    0.93014     0.92762
alpha_5                               0.92889      0.00080    0.93015     0.92764
alpha_6                               0.92887      0.00080    0.93012     0.92761
alpha_7                               0.92888      0.00080    0.93013     0.92762
alpha_8                               0.92888      0.00080    0.93014     0.92763
alpha_9                               0.92885      0.00080    0.93011     0.92759
Alpha_loss                            -0.49475     0.00561    -0.48602    -0.50290
Training/policy_loss                  -3.53466     0.02575    -3.49996    -3.56683
Training/qf1_loss                     1588.49141   394.52511  2630.38574  1127.77087
Training/qf2_loss                     1588.00223   394.55235  2629.84814  1127.14832
Training/pf_norm                      0.13241      0.03039    0.17918     0.07533
Training/qf1_norm                     76.27441     6.75708    86.02921    68.00096
Training/qf2_norm                     73.45694     6.10170    82.79403    66.04138
log_std/mean                          -0.13359     0.00067    -0.13293    -0.13484
log_std/std                           0.00596      0.00010    0.00613     0.00579
log_std/max                           -0.11899     0.00066    -0.11817    -0.12035
log_std/min                           -0.15147     0.00091    -0.15041    -0.15355
log_probs/mean                        -2.73248     0.00624    -2.71982    -2.74253
log_probs/std                         0.24401      0.02106    0.28336     0.20915
log_probs/max                         -2.14944     0.02780    -2.10107    -2.19217
log_probs/min                         -5.04829     0.66362    -4.03782    -6.16438
mean/mean                             -0.00130     0.00018    -0.00111    -0.00158
mean/std                              0.00965      0.00083    0.01116     0.00869
mean/max                              0.02079      0.00181    0.02427     0.01868
mean/min                              -0.02645     0.00141    -0.02468    -0.02898
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 3, 2, 4, 6, 1, 8, 7, 5, 0]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.3512187004089355 6.508827209472656e-05
train_time 2.3513381481170654
2023-09-06 13:24:37,984 MainThread INFO: EPOCH:25
2023-09-06 13:24:37,984 MainThread INFO: Time Consumed:2.362459421157837s
2023-09-06 13:24:37,984 MainThread INFO: Total Frames:39000s
 13%|█▎        | 26/200 [01:00<06:31,  2.25s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1284.98287
Train_Epoch_Reward                    9849.21527
Running_Training_Average_Rewards      1147.10596
Explore_Time                          0.00652
Train___Time                          2.35134
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.33646
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.11671
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.94184
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.36890
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.51428
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.33109
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.65831
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12963.64404
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.79050
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.52580
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.79812      0.54301    9.75083     7.76169
alpha_0                               0.92604      0.00080    0.92729     0.92478
alpha_1                               0.92607      0.00080    0.92732     0.92482
alpha_2                               0.92611      0.00080    0.92736     0.92486
alpha_3                               0.92609      0.00080    0.92734     0.92484
alpha_4                               0.92609      0.00080    0.92734     0.92484
alpha_5                               0.92611      0.00080    0.92736     0.92485
alpha_6                               0.92608      0.00080    0.92733     0.92483
alpha_7                               0.92609      0.00080    0.92734     0.92484
alpha_8                               0.92610      0.00080    0.92735     0.92485
alpha_9                               0.92606      0.00080    0.92731     0.92481
Alpha_loss                            -0.51529     0.00606    -0.50594    -0.52473
Training/policy_loss                  -3.63452     0.03162    -3.58849    -3.68327
Training/qf1_loss                     1643.88318   467.75461  2542.95630  1145.37805
Training/qf2_loss                     1643.20874   467.73702  2542.19312  1144.65466
Training/pf_norm                      0.12069      0.02249    0.15155     0.08334
Training/qf1_norm                     79.33072     4.41074    86.24217    69.20078
Training/qf2_norm                     76.71704     4.36658    83.81158    66.59782
log_std/mean                          -0.13580     0.00040    -0.13515    -0.13633
log_std/std                           0.00635      0.00012    0.00653     0.00616
log_std/max                           -0.12022     0.00030    -0.11970    -0.12062
log_std/min                           -0.15461     0.00124    -0.15268    -0.15659
log_probs/mean                        -2.73658     0.00639    -2.72489    -2.74701
log_probs/std                         0.23376      0.01039    0.24579     0.21242
log_probs/max                         -2.15365     0.02313    -2.11354    -2.19242
log_probs/min                         -4.80166     0.51604    -3.77124    -5.49912
mean/mean                             -0.00142     0.00008    -0.00123    -0.00150
mean/std                              0.01256      0.00061    0.01340     0.01149
mean/max                              0.02692      0.00112    0.02846     0.02486
mean/min                              -0.03142     0.00141    -0.02907    -0.03367
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 8, 9, 2, 5, 6, 3, 4, 1, 7]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.5924041271209717 2.002716064453125e-05
train_time 2.5924906730651855
2023-09-06 13:24:40,759 MainThread INFO: EPOCH:26
2023-09-06 13:24:40,760 MainThread INFO: Time Consumed:2.6032872200012207s
2023-09-06 13:24:40,760 MainThread INFO: Total Frames:40500s
 14%|█▎        | 27/200 [01:03<06:57,  2.41s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1280.43111
Train_Epoch_Reward                    9988.54334
Running_Training_Average_Rewards      730.10504
Explore_Time                          0.00641
Train___Time                          2.59249
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.67337
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.62475
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.79827
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.62040
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.71853
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.65978
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.98493
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13104.38306
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.28620
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.57929
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.62092      0.52794    9.78795     7.93964
alpha_0                               0.92326      0.00080    0.92450     0.92201
alpha_1                               0.92329      0.00080    0.92454     0.92205
alpha_2                               0.92333      0.00080    0.92458     0.92208
alpha_3                               0.92331      0.00080    0.92456     0.92206
alpha_4                               0.92331      0.00080    0.92456     0.92206
alpha_5                               0.92333      0.00080    0.92458     0.92208
alpha_6                               0.92331      0.00080    0.92456     0.92206
alpha_7                               0.92331      0.00080    0.92456     0.92207
alpha_8                               0.92332      0.00080    0.92457     0.92207
alpha_9                               0.92328      0.00080    0.92453     0.92203
Alpha_loss                            -0.53549     0.00604    -0.52594    -0.54451
Training/policy_loss                  -3.73467     0.03355    -3.67914    -3.78392
Training/qf1_loss                     1421.17646   310.56180  2038.92029  1062.96155
Training/qf2_loss                     1420.17125   310.45021  2037.54553  1062.32251
Training/pf_norm                      0.14593      0.03061    0.21154     0.10572
Training/qf1_norm                     81.19868     3.99639    90.85212    76.34522
Training/qf2_norm                     79.25480     4.39833    89.02579    73.47932
log_std/mean                          -0.13640     0.00006    -0.13636    -0.13653
log_std/std                           0.00694      0.00024    0.00737     0.00658
log_std/max                           -0.12016     0.00021    -0.11981    -0.12037
log_std/min                           -0.15670     0.00069    -0.15557    -0.15808
log_probs/mean                        -2.73608     0.00660    -2.72461    -2.75054
log_probs/std                         0.23352      0.01302    0.25592     0.21103
log_probs/max                         -2.14645     0.04584    -2.06670    -2.20343
log_probs/min                         -5.07205     0.69347    -4.23074    -6.64826
mean/mean                             -0.00191     0.00032    -0.00149    -0.00249
mean/std                              0.01500      0.00097    0.01669     0.01358
mean/max                              0.02914      0.00048    0.03009     0.02843
mean/min                              -0.03877     0.00310    -0.03430    -0.04410
------------------------------------  -----------  ---------  ----------  ----------
sample: [4, 3, 8, 9, 1, 0, 2, 5, 6, 7]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.145169496536255 2.0265579223632812e-05
train_time 2.145259141921997
snapshot at best
2023-09-06 13:24:43,651 MainThread INFO: EPOCH:27
2023-09-06 13:24:43,651 MainThread INFO: Time Consumed:2.7296700477600098s
2023-09-06 13:24:43,652 MainThread INFO: Total Frames:42000s
 14%|█▍        | 28/200 [01:06<07:18,  2.55s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1297.33396
Train_Epoch_Reward                    10799.68798
Running_Training_Average_Rewards      1021.24822
Explore_Time                          0.00819
Train___Time                          2.14526
Eval____Time                          0.00454
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.36820
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.78407
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -17.94822
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.46723
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.63229
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.69731
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.88601
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13620.87167
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.36318
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.20414
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.16791      0.52476    10.47186    8.47587
alpha_0                               0.92048      0.00080    0.92173     0.91924
alpha_1                               0.92053      0.00079    0.92177     0.91928
alpha_2                               0.92056      0.00079    0.92181     0.91932
alpha_3                               0.92054      0.00079    0.92179     0.91930
alpha_4                               0.92054      0.00080    0.92179     0.91930
alpha_5                               0.92056      0.00079    0.92180     0.91932
alpha_6                               0.92054      0.00079    0.92178     0.91930
alpha_7                               0.92055      0.00079    0.92179     0.91930
alpha_8                               0.92055      0.00079    0.92180     0.91931
alpha_9                               0.92050      0.00080    0.92175     0.91926
Alpha_loss                            -0.55544     0.00544    -0.54729    -0.56408
Training/policy_loss                  -3.83805     0.02582    -3.80055    -3.87659
Training/qf1_loss                     1767.72286   470.10323  3049.75488  1297.04041
Training/qf2_loss                     1766.50565   470.18776  3048.99072  1295.69666
Training/pf_norm                      0.11313      0.02027    0.14679     0.09059
Training/qf1_norm                     90.69084     4.89769    103.48668   86.37258
Training/qf2_norm                     88.67577     4.43816    99.58774    84.69879
log_std/mean                          -0.13681     0.00013    -0.13668    -0.13702
log_std/std                           0.00725      0.00021    0.00744     0.00680
log_std/max                           -0.12084     0.00055    -0.12003    -0.12196
log_std/min                           -0.15748     0.00088    -0.15599    -0.15832
log_probs/mean                        -2.73263     0.00629    -2.72084    -2.74438
log_probs/std                         0.23401      0.01451    0.26817     0.21558
log_probs/max                         -2.13803     0.04040    -2.06722    -2.21021
log_probs/min                         -4.73178     0.46060    -4.29581    -5.79629
mean/mean                             -0.00283     0.00021    -0.00253    -0.00309
mean/std                              0.01901      0.00114    0.02067     0.01717
mean/max                              0.03247      0.00135    0.03463     0.03043
mean/min                              -0.04938     0.00250    -0.04521    -0.05293
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 1, 8, 0, 2, 9, 6, 3, 4, 5]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.5151100158691406 2.574920654296875e-05
train_time 1.5152137279510498
snapshot at best
2023-09-06 13:24:46,378 MainThread INFO: EPOCH:28
2023-09-06 13:24:46,379 MainThread INFO: Time Consumed:2.2803475856781006s
2023-09-06 13:24:46,379 MainThread INFO: Total Frames:43500s
 14%|█▍        | 29/200 [01:08<07:25,  2.61s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1344.37094
Train_Epoch_Reward                    12405.39765
Running_Training_Average_Rewards      1106.45430
Explore_Time                          0.00342
Train___Time                          1.51521
Eval____Time                          0.00315
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.36236
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.39683
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.27116
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.52203
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.04599
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.28182
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.24249
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14376.78478
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.86574
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.62681
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.26457      0.58127    9.03022     7.18023
alpha_0                               0.91772      0.00079    0.91896     0.91648
alpha_1                               0.91777      0.00079    0.91901     0.91653
alpha_2                               0.91780      0.00079    0.91904     0.91656
alpha_3                               0.91778      0.00079    0.91902     0.91654
alpha_4                               0.91778      0.00079    0.91902     0.91654
alpha_5                               0.91780      0.00079    0.91904     0.91656
alpha_6                               0.91778      0.00079    0.91902     0.91654
alpha_7                               0.91779      0.00079    0.91903     0.91655
alpha_8                               0.91779      0.00079    0.91903     0.91655
alpha_9                               0.91774      0.00079    0.91898     0.91650
Alpha_loss                            -0.57596     0.00569    -0.56691    -0.58497
Training/policy_loss                  -3.94932     0.03181    -3.89781    -4.00189
Training/qf1_loss                     1291.51949   269.03788  1664.81531  819.25079
Training/qf2_loss                     1290.10624   268.93991  1663.18103  818.31305
Training/pf_norm                      0.13262      0.02065    0.16112     0.10268
Training/qf1_norm                     85.72547     6.19566    93.41306    75.62238
Training/qf2_norm                     84.26100     6.09307    92.40366    73.35863
log_std/mean                          -0.13682     0.00016    -0.13658    -0.13703
log_std/std                           0.00622      0.00028    0.00670     0.00584
log_std/max                           -0.12283     0.00042    -0.12206    -0.12359
log_std/min                           -0.15382     0.00133    -0.15213    -0.15612
log_probs/mean                        -2.73607     0.00480    -2.73102    -2.74789
log_probs/std                         0.24161      0.01538    0.26244     0.21079
log_probs/max                         -2.13263     0.03064    -2.07801    -2.20111
log_probs/min                         -4.93170     0.56834    -3.96335    -5.99186
mean/mean                             -0.00216     0.00052    -0.00132    -0.00295
mean/std                              0.02294      0.00125    0.02513     0.02107
mean/max                              0.03882      0.00231    0.04286     0.03528
mean/min                              -0.05702     0.00209    -0.05349    -0.06048
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 8, 9, 5, 0, 4, 7, 2, 3, 6]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.5698583126068115 5.555152893066406e-05
train_time 1.5699844360351562
snapshot at best
2023-09-06 13:24:49,084 MainThread INFO: EPOCH:29
2023-09-06 13:24:49,085 MainThread INFO: Time Consumed:2.518855333328247s
2023-09-06 13:24:49,085 MainThread INFO: Total Frames:45000s
 15%|█▌        | 30/200 [01:11<07:27,  2.63s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1402.74432
Train_Epoch_Reward                    8736.49523
Running_Training_Average_Rewards      1064.71936
Explore_Time                          0.02217
Train___Time                          1.56998
Eval____Time                          0.00472
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.29917
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.09809
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.40400
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.88799
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.79905
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.25010
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.69460
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14848.82381
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.34819
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.40347
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.50147      0.57319    9.39546     7.56740
alpha_0                               0.91497      0.00079    0.91620     0.91373
alpha_1                               0.91502      0.00079    0.91625     0.91378
alpha_2                               0.91505      0.00079    0.91629     0.91381
alpha_3                               0.91502      0.00079    0.91626     0.91379
alpha_4                               0.91502      0.00079    0.91626     0.91379
alpha_5                               0.91504      0.00079    0.91628     0.91381
alpha_6                               0.91503      0.00079    0.91626     0.91379
alpha_7                               0.91503      0.00079    0.91627     0.91380
alpha_8                               0.91504      0.00079    0.91628     0.91381
alpha_9                               0.91499      0.00079    0.91623     0.91375
Alpha_loss                            -0.59587     0.00572    -0.58756    -0.60425
Training/policy_loss                  -4.06041     0.03218    -4.01372    -4.10065
Training/qf1_loss                     1282.45049   291.87353  1794.51392  930.11066
Training/qf2_loss                     1280.65490   291.74164  1792.27148  928.44550
Training/pf_norm                      0.11457      0.02132    0.15646     0.09441
Training/qf1_norm                     92.28580     5.61571    99.13861    82.60850
Training/qf2_norm                     91.39055     5.69339    98.95214    81.86140
log_std/mean                          -0.13693     0.00017    -0.13654    -0.13714
log_std/std                           0.00578      0.00005    0.00586     0.00571
log_std/max                           -0.12274     0.00084    -0.12142    -0.12453
log_std/min                           -0.15244     0.00022    -0.15201    -0.15276
log_probs/mean                        -2.73242     0.00919    -2.71781    -2.75017
log_probs/std                         0.23750      0.01062    0.25752     0.21989
log_probs/max                         -2.09047     0.04205    -2.02994    -2.15819
log_probs/min                         -4.69528     0.33905    -4.12517    -5.29949
mean/mean                             -0.00018     0.00054    0.00059     -0.00115
mean/std                              0.02727      0.00092    0.02855     0.02563
mean/max                              0.04736      0.00189    0.05017     0.04405
mean/min                              -0.06362     0.00126    -0.06150    -0.06534
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 1, 2, 6, 5, 8, 3, 7, 4, 0]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6823086738586426 2.5033950805664062e-05
train_time 1.6823985576629639
snapshot at best
2023-09-06 13:24:51,773 MainThread INFO: EPOCH:30
2023-09-06 13:24:51,774 MainThread INFO: Time Consumed:2.566541910171509s
2023-09-06 13:24:51,774 MainThread INFO: Total Frames:46500s
 16%|█▌        | 31/200 [01:14<07:29,  2.66s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1479.49337
Train_Epoch_Reward                    16597.57751
Running_Training_Average_Rewards      1257.98235
Explore_Time                          0.00380
Train___Time                          1.68240
Eval____Time                          0.00372
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.83017
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.46262
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.90386
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.88937
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.20919
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95054
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.28820
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15923.10900
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.54390
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.03875
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.62178      0.86025    9.83120     7.09770
alpha_0                               0.91222      0.00079    0.91346     0.91099
alpha_1                               0.91228      0.00079    0.91351     0.91105
alpha_2                               0.91231      0.00079    0.91354     0.91108
alpha_3                               0.91228      0.00079    0.91351     0.91104
alpha_4                               0.91228      0.00079    0.91351     0.91105
alpha_5                               0.91230      0.00079    0.91353     0.91106
alpha_6                               0.91228      0.00079    0.91352     0.91105
alpha_7                               0.91229      0.00079    0.91352     0.91106
alpha_8                               0.91230      0.00079    0.91353     0.91106
alpha_9                               0.91224      0.00079    0.91348     0.91101
Alpha_loss                            -0.61616     0.00554    -0.60732    -0.62493
Training/policy_loss                  -4.17634     0.02961    -4.12714    -4.22021
Training/qf1_loss                     1359.38370   366.07377  2105.02393  815.67517
Training/qf2_loss                     1357.28585   365.84438  2102.59644  813.83063
Training/pf_norm                      0.11621      0.02004    0.15704     0.09302
Training/qf1_norm                     97.56836     9.38023    111.79602   81.50565
Training/qf2_norm                     96.98340     9.37175    111.22797   81.18496
log_std/mean                          -0.13621     0.00017    -0.13594    -0.13649
log_std/std                           0.00562      0.00019    0.00584     0.00531
log_std/max                           -0.12181     0.00034    -0.12121    -0.12233
log_std/min                           -0.15170     0.00084    -0.15011    -0.15272
log_probs/mean                        -2.73320     0.00648    -2.72279    -2.74596
log_probs/std                         0.24053      0.01324    0.26455     0.21812
log_probs/max                         -2.09831     0.04303    -2.05441    -2.20177
log_probs/min                         -4.94394     0.44768    -4.43705    -5.88181
mean/mean                             0.00086      0.00015    0.00100     0.00050
mean/std                              0.02973      0.00057    0.03058     0.02883
mean/max                              0.05236      0.00099    0.05375     0.05053
mean/min                              -0.06762     0.00098    -0.06600    -0.06944
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 8, 1, 3, 9, 2, 6, 5, 4, 0]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.4973595142364502 1.9311904907226562e-05
train_time 1.497443675994873
snapshot at best
2023-09-06 13:24:54,584 MainThread INFO: EPOCH:31
2023-09-06 13:24:54,585 MainThread INFO: Time Consumed:2.407144546508789s
2023-09-06 13:24:54,585 MainThread INFO: Total Frames:48000s
 16%|█▌        | 32/200 [01:17<07:34,  2.70s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1565.77675
Train_Epoch_Reward                    7974.84483
Running_Training_Average_Rewards      1110.29725
Explore_Time                          0.00402
Train___Time                          1.49744
Eval____Time                          0.00359
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.31862
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.65473
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.42000
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.82433
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.90024
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.63171
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.81636
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16967.74638
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.64862
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.86091
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.40306      0.80433    9.83757     7.08079
alpha_0                               0.90949      0.00078    0.91072     0.90826
alpha_1                               0.90955      0.00078    0.91077     0.90832
alpha_2                               0.90957      0.00079    0.91080     0.90834
alpha_3                               0.90954      0.00078    0.91077     0.90831
alpha_4                               0.90954      0.00078    0.91077     0.90831
alpha_5                               0.90956      0.00078    0.91079     0.90833
alpha_6                               0.90955      0.00078    0.91078     0.90832
alpha_7                               0.90956      0.00078    0.91079     0.90833
alpha_8                               0.90956      0.00078    0.91079     0.90833
alpha_9                               0.90950      0.00078    0.91073     0.90828
Alpha_loss                            -0.63650     0.00565    -0.62712    -0.64594
Training/policy_loss                  -4.29636     0.03371    -4.23731    -4.35540
Training/qf1_loss                     1276.25200   406.24618  2288.94897  784.49548
Training/qf2_loss                     1273.86452   406.02712  2286.11499  782.25824
Training/pf_norm                      0.14389      0.02452    0.18863     0.11496
Training/qf1_norm                     99.06800     9.27734    114.75851   83.53966
Training/qf2_norm                     98.98877     9.41012    114.97124   83.75123
log_std/mean                          -0.13646     0.00025    -0.13592    -0.13669
log_std/std                           0.00511      0.00009    0.00525     0.00496
log_std/max                           -0.12311     0.00044    -0.12221    -0.12377
log_std/min                           -0.15060     0.00032    -0.14983    -0.15095
log_probs/mean                        -2.73447     0.00679    -2.72730    -2.75211
log_probs/std                         0.24210      0.01684    0.28461     0.22080
log_probs/max                         -2.07820     0.03239    -2.02605    -2.14650
log_probs/min                         -4.95052     0.67035    -4.08086    -6.52936
mean/mean                             -0.00010     0.00020    0.00031     -0.00034
mean/std                              0.03139      0.00037    0.03194     0.03072
mean/max                              0.05571      0.00116    0.05747     0.05409
mean/min                              -0.07117     0.00083    -0.07001    -0.07226
------------------------------------  -----------  ---------  ----------  ---------
sample: [7, 6, 9, 0, 2, 1, 3, 4, 5, 8]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7574925422668457 2.1696090698242188e-05
train_time 1.757690191268921
snapshot at best
2023-09-06 13:24:57,200 MainThread INFO: EPOCH:32
2023-09-06 13:24:57,201 MainThread INFO: Time Consumed:2.452322244644165s
2023-09-06 13:24:57,201 MainThread INFO: Total Frames:49500s
 16%|█▋        | 33/200 [01:19<07:25,  2.67s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1640.96113
Train_Epoch_Reward                    5655.91720
Running_Training_Average_Rewards      1007.61132
Explore_Time                          0.00440
Train___Time                          1.75769
Eval____Time                          0.00391
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.65311
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.92585
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.34673
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.95058
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.82695
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.69280
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.93432
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17102.31791
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.92845
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.88856
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.46375      0.37864    9.23886     8.00744
alpha_0                               0.90676      0.00078    0.90799     0.90554
alpha_1                               0.90682      0.00078    0.90804     0.90559
alpha_2                               0.90684      0.00078    0.90807     0.90562
alpha_3                               0.90681      0.00078    0.90804     0.90559
alpha_4                               0.90682      0.00078    0.90804     0.90559
alpha_5                               0.90683      0.00078    0.90806     0.90561
alpha_6                               0.90682      0.00078    0.90805     0.90560
alpha_7                               0.90683      0.00078    0.90806     0.90561
alpha_8                               0.90683      0.00078    0.90806     0.90561
alpha_9                               0.90678      0.00078    0.90800     0.90555
Alpha_loss                            -0.65665     0.00596    -0.64656    -0.66599
Training/policy_loss                  -4.41430     0.03523    -4.35316    -4.47259
Training/qf1_loss                     1362.38808   236.87117  1687.26758  975.44318
Training/qf2_loss                     1359.81871   236.87867  1685.00232  972.64301
Training/pf_norm                      0.12049      0.01924    0.14852     0.08660
Training/qf1_norm                     104.52702    5.41981    117.04431   96.30987
Training/qf2_norm                     104.44319    4.82164    115.62707   98.38508
log_std/mean                          -0.13719     0.00043    -0.13666    -0.13803
log_std/std                           0.00496      0.00009    0.00506     0.00474
log_std/max                           -0.12344     0.00035    -0.12287    -0.12425
log_std/min                           -0.15054     0.00038    -0.14970    -0.15094
log_probs/mean                        -2.73369     0.00686    -2.72044    -2.74377
log_probs/std                         0.24684      0.01413    0.26619     0.23053
log_probs/max                         -2.05517     0.05659    -1.95189    -2.14082
log_probs/min                         -5.11204     0.49225    -4.31616    -5.60895
mean/mean                             -0.00009     0.00016    0.00013     -0.00037
mean/std                              0.03224      0.00027    0.03282     0.03197
mean/max                              0.05869      0.00074    0.06013     0.05763
mean/min                              -0.07286     0.00061    -0.07212    -0.07424
------------------------------------  -----------  ---------  ----------  ---------
sample: [5, 0, 4, 6, 3, 1, 7, 8, 9, 2]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6117393970489502 2.1696090698242188e-05
train_time 1.6118273735046387
snapshot at best
2023-09-06 13:24:59,969 MainThread INFO: EPOCH:33
2023-09-06 13:24:59,969 MainThread INFO: Time Consumed:2.421518325805664s
2023-09-06 13:24:59,969 MainThread INFO: Total Frames:51000s
 17%|█▋        | 34/200 [01:22<07:27,  2.70s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1689.03846
Train_Epoch_Reward                    11363.79908
Running_Training_Average_Rewards      833.15204
Explore_Time                          0.00508
Train___Time                          1.61183
Eval____Time                          0.00475
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.96837
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.02963
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.32350
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.96587
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.88953
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89786
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.93594
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17370.26823
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.04176
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.90349
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.08032      0.79396    9.71539     6.64871
alpha_0                               0.90404      0.00078    0.90527     0.90282
alpha_1                               0.90410      0.00078    0.90532     0.90288
alpha_2                               0.90412      0.00078    0.90534     0.90290
alpha_3                               0.90409      0.00078    0.90532     0.90287
alpha_4                               0.90410      0.00078    0.90532     0.90288
alpha_5                               0.90412      0.00078    0.90534     0.90289
alpha_6                               0.90410      0.00078    0.90533     0.90288
alpha_7                               0.90411      0.00078    0.90534     0.90289
alpha_8                               0.90412      0.00078    0.90534     0.90290
alpha_9                               0.90406      0.00078    0.90528     0.90284
Alpha_loss                            -0.67662     0.00587    -0.66664    -0.68628
Training/policy_loss                  -4.53265     0.03624    -4.46531    -4.59265
Training/qf1_loss                     1301.18757   536.03558  2564.66260  700.40674
Training/qf2_loss                     1298.39144   535.92514  2561.78564  697.98621
Training/pf_norm                      0.11604      0.01942    0.14271     0.08212
Training/qf1_norm                     104.21131    10.18961   124.25362   86.59323
Training/qf2_norm                     104.38885    10.09712   123.95326   86.70112
log_std/mean                          -0.13822     0.00029    -0.13769    -0.13858
log_std/std                           0.00448      0.00012    0.00464     0.00430
log_std/max                           -0.12528     0.00064    -0.12406    -0.12633
log_std/min                           -0.14991     0.00064    -0.14897    -0.15060
log_probs/mean                        -2.73120     0.00492    -2.72237    -2.73977
log_probs/std                         0.24526      0.01690    0.26956     0.22103
log_probs/max                         -2.06452     0.05054    -1.97315    -2.15535
log_probs/min                         -5.13891     0.71249    -4.00150    -6.50172
mean/mean                             -0.00055     0.00014    -0.00023    -0.00070
mean/std                              0.03393      0.00042    0.03443     0.03307
mean/max                              0.06078      0.00032    0.06115     0.06032
mean/min                              -0.07645     0.00083    -0.07486    -0.07735
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 0, 8, 5, 4, 9, 2, 6, 7, 1]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.4891107082366943 1.9311904907226562e-05
train_time 1.4891901016235352
2023-09-06 13:25:01,853 MainThread INFO: EPOCH:34
2023-09-06 13:25:01,853 MainThread INFO: Time Consumed:1.4983985424041748s
2023-09-06 13:25:01,854 MainThread INFO: Total Frames:52500s
 18%|█▊        | 35/200 [01:24<06:45,  2.46s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1695.40454
Train_Epoch_Reward                    14869.22278
Running_Training_Average_Rewards      1062.96464
Explore_Time                          0.00437
Train___Time                          1.48919
Eval____Time                          0.00421
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.85307
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.28368
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.27984
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.29481
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.86039
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.84956
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.20788
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17163.68132
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.28205
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.11677
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.43107      0.42513    9.31485     7.90884
alpha_0                               0.90133      0.00078    0.90255     0.90011
alpha_1                               0.90139      0.00078    0.90261     0.90017
alpha_2                               0.90141      0.00078    0.90263     0.90020
alpha_3                               0.90138      0.00078    0.90260     0.90016
alpha_4                               0.90138      0.00078    0.90260     0.90017
alpha_5                               0.90141      0.00078    0.90262     0.90019
alpha_6                               0.90139      0.00078    0.90261     0.90018
alpha_7                               0.90140      0.00078    0.90262     0.90019
alpha_8                               0.90141      0.00078    0.90263     0.90019
alpha_9                               0.90135      0.00078    0.90257     0.90013
Alpha_loss                            -0.69667     0.00539    -0.68866    -0.70518
Training/policy_loss                  -4.65166     0.03041    -4.60513    -4.70110
Training/qf1_loss                     1323.29731   246.75423  1732.18750  1018.77295
Training/qf2_loss                     1320.17399   246.54640  1728.58362  1016.29553
Training/pf_norm                      0.12156      0.02666    0.17122     0.09411
Training/qf1_norm                     112.60592    6.74707    126.18213   103.66202
Training/qf2_norm                     113.11395    6.69202    126.48193   104.42606
log_std/mean                          -0.13729     0.00033    -0.13668    -0.13766
log_std/std                           0.00436      0.00004    0.00441     0.00430
log_std/max                           -0.12567     0.00044    -0.12485    -0.12639
log_std/min                           -0.14902     0.00023    -0.14868    -0.14936
log_probs/mean                        -2.72975     0.00614    -2.72083    -2.74026
log_probs/std                         0.23732      0.01343    0.25495     0.21017
log_probs/max                         -2.05882     0.05725    -1.95866    -2.14183
log_probs/min                         -4.72692     0.50309    -4.01291    -5.72697
mean/mean                             0.00013      0.00010    0.00022     -0.00011
mean/std                              0.03523      0.00055    0.03629     0.03454
mean/max                              0.06291      0.00105    0.06493     0.06170
mean/min                              -0.07872     0.00103    -0.07748    -0.08091
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 8, 0, 5, 3, 9, 4, 6, 1, 2]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.6709234714508057 1.9311904907226562e-05
train_time 2.671004295349121
snapshot at best
2023-09-06 13:25:05,553 MainThread INFO: EPOCH:35
2023-09-06 13:25:05,554 MainThread INFO: Time Consumed:3.509216785430908s
2023-09-06 13:25:05,554 MainThread INFO: Total Frames:54000s
 18%|█▊        | 36/200 [01:28<07:43,  2.83s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1716.77995
Train_Epoch_Reward                    7246.62644
Running_Training_Average_Rewards      1115.98828
Explore_Time                          0.01111
Train___Time                          2.67100
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.83173
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.27377
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.50376
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.37311
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -18.93210
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.83839
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.55527
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17750.10429
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.35254
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.01074
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.32637      0.49888    8.89683     7.19307
alpha_0                               0.89863      0.00077    0.89984     0.89742
alpha_1                               0.89869      0.00077    0.89990     0.89747
alpha_2                               0.89871      0.00077    0.89993     0.89750
alpha_3                               0.89868      0.00078    0.89989     0.89746
alpha_4                               0.89868      0.00077    0.89990     0.89747
alpha_5                               0.89871      0.00077    0.89992     0.89749
alpha_6                               0.89870      0.00077    0.89991     0.89748
alpha_7                               0.89870      0.00077    0.89992     0.89749
alpha_8                               0.89871      0.00077    0.89992     0.89750
alpha_9                               0.89865      0.00077    0.89986     0.89743
Alpha_loss                            -0.71691     0.00558    -0.70899    -0.72428
Training/policy_loss                  -4.77061     0.03601    -4.71547    -4.81879
Training/qf1_loss                     1349.24487   267.79250  1707.77856  800.58038
Training/qf2_loss                     1345.89431   267.73249  1704.75610  797.26917
Training/pf_norm                      0.11998      0.01634    0.14534     0.08959
Training/qf1_norm                     115.56819    7.06791    126.35335   98.16531
Training/qf2_norm                     116.25485    6.82753    125.81329   99.74123
log_std/mean                          -0.13589     0.00030    -0.13553    -0.13640
log_std/std                           0.00425      0.00008    0.00437     0.00413
log_std/max                           -0.12508     0.00058    -0.12426    -0.12623
log_std/min                           -0.14834     0.00089    -0.14719    -0.14982
log_probs/mean                        -2.73013     0.00946    -2.71415    -2.74614
log_probs/std                         0.24345      0.01610    0.28549     0.22187
log_probs/max                         -2.03975     0.04973    -1.91269    -2.10316
log_probs/min                         -4.74730     0.71355    -4.04940    -6.67227
mean/mean                             0.00032      0.00009    0.00043     0.00015
mean/std                              0.03757      0.00061    0.03854     0.03655
mean/max                              0.06628      0.00076    0.06719     0.06501
mean/min                              -0.08272     0.00091    -0.08131    -0.08403
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 5, 0, 6, 2, 4, 1, 9, 7, 8]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.780778408050537 3.409385681152344e-05
train_time 1.7808873653411865
snapshot at best
2023-09-06 13:25:08,364 MainThread INFO: EPOCH:36
2023-09-06 13:25:08,364 MainThread INFO: Time Consumed:2.5852160453796387s
2023-09-06 13:25:08,364 MainThread INFO: Total Frames:55500s
 18%|█▊        | 37/200 [01:30<07:40,  2.83s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1745.65766
Train_Epoch_Reward                    19727.47073
Running_Training_Average_Rewards      1394.77733
Explore_Time                          0.00490
Train___Time                          1.78089
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.24960
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.38016
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.66340
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.49466
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.02980
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.89089
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.89402
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18237.54762
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.42301
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.87849
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.53785      0.67321    9.50023     7.63078
alpha_0                               0.89594      0.00077    0.89715     0.89473
alpha_1                               0.89599      0.00077    0.89720     0.89479
alpha_2                               0.89602      0.00077    0.89723     0.89481
alpha_3                               0.89598      0.00077    0.89719     0.89477
alpha_4                               0.89599      0.00077    0.89720     0.89478
alpha_5                               0.89601      0.00077    0.89722     0.89481
alpha_6                               0.89600      0.00077    0.89721     0.89480
alpha_7                               0.89601      0.00077    0.89722     0.89480
alpha_8                               0.89602      0.00077    0.89723     0.89481
alpha_9                               0.89595      0.00077    0.89716     0.89474
Alpha_loss                            -0.73664     0.00555    -0.72795    -0.74556
Training/policy_loss                  -4.88951     0.03433    -4.83597    -4.94621
Training/qf1_loss                     1368.82429   339.78531  2099.92896  862.78827
Training/qf2_loss                     1365.19286   339.70554  2096.12256  859.61664
Training/pf_norm                      0.12459      0.02990    0.16743     0.08480
Training/qf1_norm                     123.45600    10.55657   138.44788   111.22351
Training/qf2_norm                     124.27642    10.44948   138.93033   111.77328
log_std/mean                          -0.13630     0.00060    -0.13557    -0.13737
log_std/std                           0.00423      0.00011    0.00441     0.00407
log_std/max                           -0.12556     0.00070    -0.12461    -0.12698
log_std/min                           -0.15084     0.00148    -0.14800    -0.15359
log_probs/mean                        -2.72589     0.00890    -2.70924    -2.73966
log_probs/std                         0.24526      0.01883    0.28296     0.22802
log_probs/max                         -2.05291     0.03965    -2.00095    -2.13267
log_probs/min                         -5.00379     1.01794    -4.05149    -7.18093
mean/mean                             0.00002      0.00034    0.00041     -0.00060
mean/std                              0.03927      0.00027    0.03961     0.03869
mean/max                              0.06805      0.00053    0.06869     0.06694
mean/min                              -0.08550     0.00100    -0.08427    -0.08707
------------------------------------  -----------  ---------  ----------  ---------
sample: [3, 9, 7, 5, 6, 0, 4, 2, 8, 1]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7976593971252441 1.9073486328125e-05
train_time 1.7980046272277832
snapshot at best
2023-09-06 13:25:11,316 MainThread INFO: EPOCH:37
2023-09-06 13:25:11,316 MainThread INFO: Time Consumed:2.5155036449432373s
2023-09-06 13:25:11,316 MainThread INFO: Total Frames:57000s
 19%|█▉        | 38/200 [01:33<07:43,  2.86s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1799.78218
Train_Epoch_Reward                    7439.91182
Running_Training_Average_Rewards      1147.13363
Explore_Time                          0.00480
Train___Time                          1.79800
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.91897
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.54482
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.88902
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.54565
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.20222
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.95114
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.34166
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18784.18789
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.55718
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.84837
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.08347      0.44335    10.20408    8.60667
alpha_0                               0.89325      0.00077    0.89446     0.89205
alpha_1                               0.89331      0.00077    0.89452     0.89211
alpha_2                               0.89334      0.00077    0.89454     0.89213
alpha_3                               0.89330      0.00077    0.89451     0.89209
alpha_4                               0.89330      0.00077    0.89451     0.89210
alpha_5                               0.89333      0.00077    0.89454     0.89212
alpha_6                               0.89332      0.00077    0.89453     0.89212
alpha_7                               0.89332      0.00077    0.89453     0.89211
alpha_8                               0.89334      0.00077    0.89454     0.89213
alpha_9                               0.89327      0.00077    0.89447     0.89206
Alpha_loss                            -0.75710     0.00594    -0.74799    -0.76636
Training/policy_loss                  -5.00858     0.03327    -4.95917    -5.05989
Training/qf1_loss                     1506.48761   307.25078  2341.27832  1279.36316
Training/qf2_loss                     1502.09692   307.01555  2336.33398  1275.03247
Training/pf_norm                      0.13374      0.02301    0.16677     0.09268
Training/qf1_norm                     135.91286    6.63754    152.45038   126.43468
Training/qf2_norm                     137.57701    6.86893    154.42598   128.53305
log_std/mean                          -0.13813     0.00017    -0.13770    -0.13832
log_std/std                           0.00453      0.00010    0.00471     0.00440
log_std/max                           -0.12739     0.00078    -0.12629    -0.12861
log_std/min                           -0.15500     0.00114    -0.15326    -0.15679
log_probs/mean                        -2.72830     0.00455    -2.71950    -2.73670
log_probs/std                         0.23894      0.01133    0.25749     0.21517
log_probs/max                         -2.04777     0.04181    -1.95986    -2.10963
log_probs/min                         -4.66574     0.27572    -4.08104    -5.01873
mean/mean                             -0.00102     0.00022    -0.00075    -0.00151
mean/std                              0.03876      0.00063    0.03962     0.03780
mean/max                              0.06699      0.00119    0.06849     0.06493
mean/min                              -0.08558     0.00115    -0.08400    -0.08718
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 3, 2, 5, 0, 6, 1, 9, 7, 4]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.6185407638549805 3.933906555175781e-05
train_time 1.6186604499816895
snapshot at best
2023-09-06 13:25:14,133 MainThread INFO: EPOCH:38
2023-09-06 13:25:14,133 MainThread INFO: Time Consumed:2.4031014442443848s
2023-09-06 13:25:14,133 MainThread INFO: Total Frames:58500s
 20%|█▉        | 39/200 [01:36<07:37,  2.84s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1853.34839
Train_Epoch_Reward                    34675.77149
Running_Training_Average_Rewards      2061.43847
Explore_Time                          0.00378
Train___Time                          1.61866
Eval____Time                          0.00447
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.30626
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.61184
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.95505
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.53464
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.61301
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.49402
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.27382
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19366.67849
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.61675
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.85377
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.86278      0.93973    11.28973    7.92307
alpha_0                               0.89058      0.00077    0.89178     0.88938
alpha_1                               0.89064      0.00077    0.89184     0.88943
alpha_2                               0.89066      0.00077    0.89186     0.88946
alpha_3                               0.89062      0.00077    0.89183     0.88942
alpha_4                               0.89062      0.00077    0.89183     0.88942
alpha_5                               0.89065      0.00077    0.89186     0.88945
alpha_6                               0.89065      0.00077    0.89185     0.88945
alpha_7                               0.89064      0.00077    0.89185     0.88944
alpha_8                               0.89066      0.00077    0.89187     0.88946
alpha_9                               0.89059      0.00077    0.89179     0.88939
Alpha_loss                            -0.77831     0.00578    -0.76880    -0.78728
Training/policy_loss                  -5.12940     0.03376    -5.07294    -5.17892
Training/qf1_loss                     1387.32291   455.95390  2592.35327  1056.03308
Training/qf2_loss                     1383.04948   455.80554  2587.95679  1051.71179
Training/pf_norm                      0.12691      0.01628    0.15818     0.09449
Training/qf1_norm                     138.02025    17.45420   184.22960   121.72608
Training/qf2_norm                     139.25402    17.00343   183.66397   123.16891
log_std/mean                          -0.13845     0.00041    -0.13798    -0.13930
log_std/std                           0.00500      0.00012    0.00517     0.00483
log_std/max                           -0.12752     0.00027    -0.12723    -0.12808
log_std/min                           -0.15666     0.00159    -0.15379    -0.15916
log_probs/mean                        -2.73720     0.00445    -2.73001    -2.74690
log_probs/std                         0.26231      0.01863    0.29159     0.23967
log_probs/max                         -2.04855     0.06436    -1.98564    -2.20186
log_probs/min                         -5.52466     0.73416    -4.49586    -6.50213
mean/mean                             -0.00196     0.00010    -0.00168    -0.00206
mean/std                              0.03865      0.00087    0.04011     0.03766
mean/max                              0.06565      0.00141    0.06814     0.06414
mean/min                              -0.08637     0.00202    -0.08369    -0.08986
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 2, 1, 7, 4, 3, 0, 5, 6, 9]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.7379662990570068 6.413459777832031e-05
train_time 1.7381322383880615
snapshot at best
2023-09-06 13:25:17,025 MainThread INFO: EPOCH:39
2023-09-06 13:25:17,026 MainThread INFO: Time Consumed:2.5071589946746826s
2023-09-06 13:25:17,026 MainThread INFO: Total Frames:60000s
 20%|██        | 40/200 [01:39<07:37,  2.86s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1892.21898
Train_Epoch_Reward                    21515.38099
Running_Training_Average_Rewards      2121.03548
Explore_Time                          0.00311
Train___Time                          1.73813
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.34388
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.34686
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.76835
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.43047
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.69650
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.62779
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.00500
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19413.48843
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.34927
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.15912
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.48646      0.64056    11.03593    8.66688
alpha_0                               0.88791      0.00077    0.88911     0.88671
alpha_1                               0.88797      0.00077    0.88917     0.88677
alpha_2                               0.88799      0.00077    0.88919     0.88679
alpha_3                               0.88795      0.00077    0.88915     0.88675
alpha_4                               0.88795      0.00077    0.88915     0.88675
alpha_5                               0.88798      0.00077    0.88918     0.88678
alpha_6                               0.88798      0.00077    0.88918     0.88678
alpha_7                               0.88797      0.00076    0.88917     0.88677
alpha_8                               0.88799      0.00077    0.88919     0.88680
alpha_9                               0.88792      0.00077    0.88912     0.88672
Alpha_loss                            -0.79765     0.00544    -0.78940    -0.80744
Training/policy_loss                  -5.23961     0.03019    -5.19208    -5.29735
Training/qf1_loss                     1589.64645   380.60763  2588.18066  1173.34778
Training/qf2_loss                     1585.02352   380.33369  2583.01562  1169.32703
Training/pf_norm                      0.13281      0.02359    0.16669     0.09165
Training/qf1_norm                     153.61978    10.58745   178.78348   142.40233
Training/qf2_norm                     154.82735    10.65413   179.92091   142.51302
log_std/mean                          -0.14054     0.00046    -0.13964    -0.14117
log_std/std                           0.00484      0.00019    0.00510     0.00454
log_std/max                           -0.12941     0.00053    -0.12856    -0.13029
log_std/min                           -0.15847     0.00086    -0.15653    -0.15950
log_probs/mean                        -2.72974     0.00728    -2.71404    -2.73690
log_probs/std                         0.24659      0.01648    0.28008     0.22330
log_probs/max                         -2.06100     0.04923    -1.97487    -2.13811
log_probs/min                         -4.82667     0.72824    -3.93235    -6.55354
mean/mean                             -0.00156     0.00018    -0.00137    -0.00188
mean/std                              0.04227      0.00111    0.04397     0.04051
mean/max                              0.07196      0.00198    0.07459     0.06826
mean/min                              -0.09443     0.00290    -0.08991    -0.09971
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 4, 3, 8, 7, 1, 6, 9, 2, 5]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.9159941673278809 2.0742416381835938e-05
train_time 1.9160985946655273
snapshot at best
2023-09-06 13:25:20,204 MainThread INFO: EPOCH:40
2023-09-06 13:25:20,204 MainThread INFO: Time Consumed:2.7910573482513428s
2023-09-06 13:25:20,204 MainThread INFO: Total Frames:61500s
 20%|██        | 41/200 [01:42<07:49,  2.96s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1939.31128
Train_Epoch_Reward                    17927.09351
Running_Training_Average_Rewards      2470.60820
Explore_Time                          0.00474
Train___Time                          1.91610
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.84217
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.54971
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.88361
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.45539
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.14695
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.95207
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.18309
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20201.73563
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.48908
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.07554
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.09405      0.88866    9.97275     6.74202
alpha_0                               0.88525      0.00076    0.88644     0.88405
alpha_1                               0.88531      0.00076    0.88650     0.88411
alpha_2                               0.88533      0.00076    0.88653     0.88413
alpha_3                               0.88529      0.00076    0.88649     0.88410
alpha_4                               0.88528      0.00076    0.88648     0.88409
alpha_5                               0.88532      0.00076    0.88652     0.88412
alpha_6                               0.88532      0.00076    0.88651     0.88412
alpha_7                               0.88531      0.00076    0.88651     0.88412
alpha_8                               0.88534      0.00076    0.88653     0.88414
alpha_9                               0.88526      0.00076    0.88645     0.88406
Alpha_loss                            -0.81761     0.00629    -0.80874    -0.82796
Training/policy_loss                  -5.35398     0.03678    -5.30082    -5.41179
Training/qf1_loss                     1475.31807   312.73161  1853.67175  757.20526
Training/qf2_loss                     1470.57349   312.29878  1848.12305  753.51190
Training/pf_norm                      0.12786      0.02522    0.16320     0.08392
Training/qf1_norm                     152.24419    15.01263   167.31180   111.87843
Training/qf2_norm                     153.66840    15.21091   167.56314   112.92043
log_std/mean                          -0.14157     0.00028    -0.14122    -0.14208
log_std/std                           0.00462      0.00013    0.00491     0.00450
log_std/max                           -0.13037     0.00036    -0.12985    -0.13100
log_std/min                           -0.15600     0.00085    -0.15401    -0.15720
log_probs/mean                        -2.72774     0.00777    -2.71067    -2.73846
log_probs/std                         0.25416      0.01207    0.27438     0.23571
log_probs/max                         -2.01905     0.04706    -1.92302    -2.06756
log_probs/min                         -5.29274     0.69495    -4.54823    -6.43761
mean/mean                             -0.00303     0.00069    -0.00198    -0.00425
mean/std                              0.04503      0.00042    0.04553     0.04422
mean/max                              0.07406      0.00049    0.07476     0.07304
mean/min                              -0.10458     0.00224    -0.10085    -0.10790
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 5, 2, 8, 3, 6, 9, 0, 7, 4]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8160972595214844 5.602836608886719e-05
train_time 1.8162262439727783
snapshot at best
2023-09-06 13:25:23,121 MainThread INFO: EPOCH:41
2023-09-06 13:25:23,122 MainThread INFO: Time Consumed:2.616415023803711s
2023-09-06 13:25:23,122 MainThread INFO: Total Frames:63000s
 21%|██        | 42/200 [01:45<07:45,  2.95s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               2006.97920
Train_Epoch_Reward                    27819.67107
Running_Training_Average_Rewards      2242.07152
Explore_Time                          0.00381
Train___Time                          1.81623
Eval____Time                          0.00539
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.87322
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.71176
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.15658
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.42350
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.03405
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -22.83093
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.46319
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 21391.16628
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.56484
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.65150
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.06561      0.70397    10.27910    8.07771
alpha_0                               0.88260      0.00076    0.88379     0.88141
alpha_1                               0.88266      0.00076    0.88385     0.88147
alpha_2                               0.88268      0.00076    0.88387     0.88148
alpha_3                               0.88264      0.00076    0.88383     0.88145
alpha_4                               0.88263      0.00076    0.88382     0.88144
alpha_5                               0.88267      0.00076    0.88386     0.88147
alpha_6                               0.88267      0.00076    0.88386     0.88148
alpha_7                               0.88266      0.00076    0.88385     0.88147
alpha_8                               0.88269      0.00076    0.88388     0.88150
alpha_9                               0.88260      0.00076    0.88380     0.88141
Alpha_loss                            -0.83771     0.00573    -0.82838    -0.84593
Training/policy_loss                  -5.46685     0.03177    -5.41779    -5.51324
Training/qf1_loss                     1458.75453   411.63064  2248.40088  992.69678
Training/qf2_loss                     1454.15969   411.30734  2243.35620  988.77832
Training/pf_norm                      0.12726      0.03035    0.18796     0.08853
Training/qf1_norm                     158.21865    13.18334   180.91325   141.22838
Training/qf2_norm                     158.99550    13.42022   181.57222   141.90620
log_std/mean                          -0.14240     0.00015    -0.14212    -0.14259
log_std/std                           0.00553      0.00032    0.00601     0.00504
log_std/max                           -0.12921     0.00069    -0.12786    -0.13037
log_std/min                           -0.15640     0.00045    -0.15560    -0.15697
log_probs/mean                        -2.72705     0.00668    -2.71286    -2.73626
log_probs/std                         0.25379      0.01075    0.26947     0.23301
log_probs/max                         -2.03648     0.03692    -1.98766    -2.08672
log_probs/min                         -5.21273     0.58763    -4.40216    -6.43272
mean/mean                             -0.00578     0.00068    -0.00458    -0.00662
mean/std                              0.04571      0.00013    0.04600     0.04553
mean/max                              0.07167      0.00083    0.07282     0.07035
mean/min                              -0.11285     0.00302    -0.10827    -0.11740
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 6, 1, 5, 4, 8, 7, 0, 3, 9]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8308141231536865 4.38690185546875e-05
train_time 1.8309297561645508
snapshot at best
2023-09-06 13:25:26,414 MainThread INFO: EPOCH:42
2023-09-06 13:25:26,414 MainThread INFO: Time Consumed:2.7508087158203125s
2023-09-06 13:25:26,414 MainThread INFO: Total Frames:64500s
 22%|██▏       | 43/200 [01:48<07:58,  3.04s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2088.84375
Train_Epoch_Reward                    12125.85867
Running_Training_Average_Rewards      1929.08744
Explore_Time                          0.00364
Train___Time                          1.83093
Eval____Time                          0.00469
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.46045
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.68974
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.22227
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.23700
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.41399
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -24.48595
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.20954
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 21872.30555
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.52966
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.35933
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           8.78868      0.46843    9.50053     8.05066
alpha_0                               0.87996      0.00076    0.88114     0.87877
alpha_1                               0.88001      0.00076    0.88120     0.87883
alpha_2                               0.88003      0.00076    0.88122     0.87885
alpha_3                               0.87999      0.00076    0.88118     0.87880
alpha_4                               0.87998      0.00076    0.88117     0.87880
alpha_5                               0.88002      0.00076    0.88121     0.87883
alpha_6                               0.88002      0.00076    0.88121     0.87884
alpha_7                               0.88002      0.00076    0.88121     0.87883
alpha_8                               0.88004      0.00076    0.88123     0.87886
alpha_9                               0.87996      0.00076    0.88115     0.87877
Alpha_loss                            -0.85764     0.00583    -0.84892    -0.86704
Training/policy_loss                  -5.58153     0.03369    -5.52380    -5.63777
Training/qf1_loss                     1244.20323   124.88425  1462.88171  1091.37952
Training/qf2_loss                     1239.55641   124.54858  1458.12769  1086.83337
Training/pf_norm                      0.12501      0.02395    0.16419     0.07923
Training/qf1_norm                     158.48270    8.62495    172.34258   144.44463
Training/qf2_norm                     159.24844    8.55204    172.89030   145.85324
log_std/mean                          -0.14233     0.00010    -0.14211    -0.14246
log_std/std                           0.00608      0.00007    0.00617     0.00594
log_std/max                           -0.12831     0.00048    -0.12770    -0.12897
log_std/min                           -0.15741     0.00049    -0.15664    -0.15832
log_probs/mean                        -2.72511     0.00303    -2.72026    -2.72811
log_probs/std                         0.25014      0.01489    0.28213     0.22828
log_probs/max                         -2.01691     0.06400    -1.92363    -2.11768
log_probs/min                         -4.81181     0.42323    -4.22479    -5.79020
mean/mean                             -0.00734     0.00031    -0.00678    -0.00777
mean/std                              0.04683      0.00031    0.04711     0.04616
mean/max                              0.07090      0.00042    0.07168     0.07038
mean/min                              -0.12099     0.00219    -0.11704    -0.12377
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 0, 7, 1, 5, 2, 6, 9, 4, 8]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.9687578678131104 2.2649765014648438e-05
train_time 1.9688465595245361
snapshot at best
2023-09-06 13:25:29,820 MainThread INFO: EPOCH:43
2023-09-06 13:25:29,820 MainThread INFO: Time Consumed:2.8557093143463135s
2023-09-06 13:25:29,820 MainThread INFO: Total Frames:66000s
 22%|██▏       | 44/200 [01:52<08:12,  3.16s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2173.32629
Train_Epoch_Reward                    16059.39647
Running_Training_Average_Rewards      1866.83087
Explore_Time                          0.00442
Train___Time                          1.96885
Eval____Time                          0.01046
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.71297
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.43057
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.27761
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.90731
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.59309
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.88118
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.85546
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 22744.55813
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.34894
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.91668
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.79238      0.74169    11.28152    8.81341
alpha_0                               0.87732      0.00075    0.87851     0.87614
alpha_1                               0.87738      0.00076    0.87856     0.87620
alpha_2                               0.87740      0.00076    0.87858     0.87622
alpha_3                               0.87736      0.00076    0.87854     0.87617
alpha_4                               0.87735      0.00076    0.87853     0.87616
alpha_5                               0.87739      0.00076    0.87857     0.87620
alpha_6                               0.87739      0.00076    0.87857     0.87620
alpha_7                               0.87739      0.00075    0.87857     0.87621
alpha_8                               0.87741      0.00076    0.87859     0.87623
alpha_9                               0.87732      0.00076    0.87850     0.87613
Alpha_loss                            -0.87812     0.00628    -0.86859    -0.88864
Training/policy_loss                  -5.69453     0.03515    -5.63571    -5.75117
Training/qf1_loss                     1754.72865   484.44977  2744.77124  1134.76404
Training/qf2_loss                     1749.88928   483.87026  2738.46924  1130.50134
Training/pf_norm                      0.12245      0.02306    0.16192     0.09302
Training/qf1_norm                     184.52590    14.88746   213.50893   164.67683
Training/qf2_norm                     184.63150    15.40370   215.11098   164.47830
log_std/mean                          -0.14124     0.00052    -0.14063    -0.14200
log_std/std                           0.00573      0.00005    0.00585     0.00566
log_std/max                           -0.12764     0.00113    -0.12618    -0.12931
log_std/min                           -0.15995     0.00083    -0.15821    -0.16090
log_probs/mean                        -2.72747     0.00607    -2.71803    -2.73838
log_probs/std                         0.25589      0.01740    0.29051     0.23444
log_probs/max                         -1.99509     0.05886    -1.89349    -2.08384
log_probs/min                         -4.96618     0.57688    -4.09454    -5.94229
mean/mean                             -0.00863     0.00052    -0.00789    -0.00950
mean/std                              0.04653      0.00031    0.04702     0.04612
mean/max                              0.07136      0.00039    0.07198     0.07069
mean/min                              -0.12638     0.00154    -0.12376    -0.12900
------------------------------------  -----------  ---------  ----------  ----------
sample: [7, 2, 4, 5, 9, 3, 0, 1, 8, 6]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.761202335357666 2.002716064453125e-05
train_time 1.7612886428833008
snapshot at best
2023-09-06 13:25:33,097 MainThread INFO: EPOCH:44
2023-09-06 13:25:33,098 MainThread INFO: Time Consumed:2.5925049781799316s
2023-09-06 13:25:33,098 MainThread INFO: Total Frames:67500s
 22%|██▎       | 45/200 [01:55<08:14,  3.19s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2229.60928
Train_Epoch_Reward                    20707.60633
Running_Training_Average_Rewards      1629.76205
Explore_Time                          0.00414
Train___Time                          1.76129
Eval____Time                          0.00550
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.16527
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.14086
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.22690
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.57816
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.39474
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.02102
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.55306
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 23080.71996
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.06636
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.62709
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.32662      0.79911    10.85177    8.36411
alpha_0                               0.87470      0.00075    0.87588     0.87352
alpha_1                               0.87475      0.00075    0.87593     0.87357
alpha_2                               0.87477      0.00075    0.87595     0.87359
alpha_3                               0.87472      0.00075    0.87591     0.87354
alpha_4                               0.87472      0.00075    0.87590     0.87354
alpha_5                               0.87476      0.00075    0.87594     0.87358
alpha_6                               0.87476      0.00075    0.87594     0.87358
alpha_7                               0.87476      0.00075    0.87594     0.87358
alpha_8                               0.87478      0.00075    0.87596     0.87360
alpha_9                               0.87469      0.00075    0.87587     0.87351
Alpha_loss                            -0.89863     0.00506    -0.89045    -0.90756
Training/policy_loss                  -5.80648     0.03169    -5.75716    -5.85664
Training/qf1_loss                     1391.80048   385.36302  2130.68433  1007.04828
Training/qf2_loss                     1387.05362   385.17670  2125.75122  1002.00275
Training/pf_norm                      0.12259      0.02827    0.19007     0.08291
Training/qf1_norm                     180.69841    17.24790   213.89159   163.81555
Training/qf2_norm                     180.80331    16.89917   213.10431   165.01979
log_std/mean                          -0.14012     0.00030    -0.13969    -0.14058
log_std/std                           0.00595      0.00008    0.00606     0.00580
log_std/max                           -0.12436     0.00087    -0.12327    -0.12590
log_std/min                           -0.16044     0.00063    -0.15954    -0.16132
log_probs/mean                        -2.72997     0.00712    -2.72072    -2.74250
log_probs/std                         0.25365      0.01096    0.27598     0.23626
log_probs/max                         -1.98995     0.08658    -1.80594    -2.09223
log_probs/min                         -4.83161     0.42058    -4.23063    -5.51111
mean/mean                             -0.01096     0.00066    -0.00980    -0.01175
mean/std                              0.04753      0.00086    0.04901     0.04642
mean/max                              0.07512      0.00234    0.07934     0.07218
mean/min                              -0.13419     0.00405    -0.12824    -0.13999
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 3, 4, 7, 0, 8, 9, 6, 1, 2]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.8634240627288818 1.9073486328125e-05
train_time 1.863511562347412
2023-09-06 13:25:35,504 MainThread INFO: EPOCH:45
2023-09-06 13:25:35,505 MainThread INFO: Time Consumed:1.8737859725952148s
2023-09-06 13:25:35,505 MainThread INFO: Total Frames:69000s
 23%|██▎       | 46/200 [01:58<07:35,  2.96s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               2239.20406
Train_Epoch_Reward                    21238.16532
Running_Training_Average_Rewards      1933.50560
Explore_Time                          0.00443
Train___Time                          1.86351
Eval____Time                          0.00509
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.02790
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.08247
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.69843
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.78989
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.75930
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.86469
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.21110
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 22152.98016
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.05125
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.95416
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.09807      0.72139    10.29258    8.03334
alpha_0                               0.87208      0.00075    0.87326     0.87090
alpha_1                               0.87213      0.00075    0.87331     0.87095
alpha_2                               0.87215      0.00075    0.87333     0.87097
alpha_3                               0.87210      0.00075    0.87328     0.87092
alpha_4                               0.87209      0.00075    0.87327     0.87092
alpha_5                               0.87214      0.00075    0.87331     0.87096
alpha_6                               0.87214      0.00075    0.87331     0.87096
alpha_7                               0.87215      0.00075    0.87332     0.87097
alpha_8                               0.87216      0.00075    0.87334     0.87099
alpha_9                               0.87207      0.00075    0.87324     0.87089
Alpha_loss                            -0.91823     0.00512    -0.91083    -0.92576
Training/policy_loss                  -5.91770     0.02781    -5.88084    -5.96081
Training/qf1_loss                     1395.25266   280.45941  1755.46582  996.56635
Training/qf2_loss                     1390.50585   280.04820  1750.39453  992.27472
Training/pf_norm                      0.13378      0.01243    0.15518     0.11714
Training/qf1_norm                     182.36652    14.80802   206.18631   158.47984
Training/qf2_norm                     182.33574    14.78231   206.22119   158.72063
log_std/mean                          -0.13874     0.00054    -0.13807    -0.13967
log_std/std                           0.00625      0.00014    0.00651     0.00609
log_std/max                           -0.12298     0.00034    -0.12232    -0.12355
log_std/min                           -0.16034     0.00070    -0.15901    -0.16178
log_probs/mean                        -2.72562     0.00724    -2.71431    -2.73802
log_probs/std                         0.26746      0.01367    0.28927     0.25037
log_probs/max                         -1.95681     0.08502    -1.82074    -2.10568
log_probs/min                         -5.32122     0.45163    -4.43796    -6.05220
mean/mean                             -0.01174     0.00004    -0.01168    -0.01183
mean/std                              0.05143      0.00125    0.05331     0.04948
mean/max                              0.08655      0.00364    0.09226     0.08054
mean/min                              -0.14766     0.00417    -0.14096    -0.15453
------------------------------------  -----------  ---------  ----------  ---------
sample: [9, 3, 5, 4, 6, 0, 1, 7, 2, 8]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.2790913581848145 2.1219253540039062e-05
train_time 3.2791695594787598
2023-09-06 13:25:38,916 MainThread INFO: EPOCH:46
2023-09-06 13:25:38,917 MainThread INFO: Time Consumed:3.293546199798584s
2023-09-06 13:25:38,917 MainThread INFO: Total Frames:70500s
 24%|██▎       | 47/200 [02:01<07:53,  3.09s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2181.46345
Train_Epoch_Reward                    13037.66505
Running_Training_Average_Rewards      1832.78122
Explore_Time                          0.00860
Train___Time                          3.27917
Eval____Time                          0.00483
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.74795
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.38574
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.22362
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.22995
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -25.88594
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -29.36071
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.07560
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 21014.07195
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.47112
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.27534
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.30632      0.50461    10.20782    8.63224
alpha_0                               0.86947      0.00075    0.87064     0.86830
alpha_1                               0.86952      0.00075    0.87069     0.86835
alpha_2                               0.86954      0.00075    0.87071     0.86837
alpha_3                               0.86949      0.00075    0.87066     0.86831
alpha_4                               0.86948      0.00075    0.87065     0.86830
alpha_5                               0.86952      0.00075    0.87070     0.86835
alpha_6                               0.86952      0.00075    0.87070     0.86835
alpha_7                               0.86954      0.00075    0.87071     0.86837
alpha_8                               0.86955      0.00075    0.87073     0.86838
alpha_9                               0.86945      0.00075    0.87063     0.86828
Alpha_loss                            -0.93832     0.00570    -0.93011    -0.94624
Training/policy_loss                  -6.02943     0.03238    -5.98109    -6.07163
Training/qf1_loss                     1414.37181   168.54550  1727.26355  1230.13977
Training/qf2_loss                     1409.54790   168.34298  1721.28845  1225.35242
Training/pf_norm                      0.12872      0.02030    0.15383     0.08330
Training/qf1_norm                     193.22523    11.86811   213.04219   176.11893
Training/qf2_norm                     192.87798    11.35714   210.55911   176.43443
log_std/mean                          -0.13956     0.00062    -0.13853    -0.14037
log_std/std                           0.00730      0.00050    0.00810     0.00659
log_std/max                           -0.12402     0.00049    -0.12324    -0.12476
log_std/min                           -0.16483     0.00245    -0.16074    -0.16788
log_probs/mean                        -2.72499     0.01012    -2.70679    -2.74547
log_probs/std                         0.26650      0.01452    0.28843     0.24019
log_probs/max                         -1.88121     0.09556    -1.72783    -2.00605
log_probs/min                         -5.13594     0.60862    -4.34551    -6.08420
mean/mean                             -0.01266     0.00049    -0.01194    -0.01354
mean/std                              0.05493      0.00082    0.05616     0.05363
mean/max                              0.09630      0.00248    0.09986     0.09229
mean/min                              -0.15941     0.00345    -0.15366    -0.16400
------------------------------------  -----------  ---------  ----------  ----------
sample: [8, 5, 1, 4, 7, 2, 3, 0, 9, 6]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.056828022003174 2.2411346435546875e-05
train_time 3.056938886642456
2023-09-06 13:25:42,158 MainThread INFO: EPOCH:47
2023-09-06 13:25:42,158 MainThread INFO: Time Consumed:3.0918614864349365s
2023-09-06 13:25:42,158 MainThread INFO: Total Frames:72000s
 24%|██▍       | 48/200 [02:04<07:56,  3.14s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2097.63605
Train_Epoch_Reward                    12154.70040
Running_Training_Average_Rewards      1547.68436
Explore_Time                          0.03008
Train___Time                          3.05694
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.89937
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.49569
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.20059
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.42792
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.04181
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -30.61330
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.29746
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20576.22003
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.69341
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.42595
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.70627      0.90625    11.29407    8.77985
alpha_0                               0.86687      0.00075    0.86804     0.86571
alpha_1                               0.86692      0.00075    0.86809     0.86575
alpha_2                               0.86694      0.00075    0.86811     0.86577
alpha_3                               0.86688      0.00075    0.86805     0.86571
alpha_4                               0.86687      0.00075    0.86804     0.86570
alpha_5                               0.86692      0.00075    0.86809     0.86575
alpha_6                               0.86692      0.00075    0.86809     0.86575
alpha_7                               0.86694      0.00074    0.86811     0.86577
alpha_8                               0.86695      0.00075    0.86812     0.86578
alpha_9                               0.86684      0.00075    0.86802     0.86567
Alpha_loss                            -0.95796     0.00581    -0.94733    -0.96606
Training/policy_loss                  -6.14255     0.03178    -6.08355    -6.18855
Training/qf1_loss                     1540.11635   461.78913  2543.31812  1093.68396
Training/qf2_loss                     1535.17433   461.39405  2538.00513  1089.70398
Training/pf_norm                      0.13552      0.01641    0.15877     0.11280
Training/qf1_norm                     207.58228    20.45961   246.43327   186.74852
Training/qf2_norm                     206.97610    20.35992   244.91165   186.53389
log_std/mean                          -0.14067     0.00016    -0.14044    -0.14089
log_std/std                           0.00870      0.00024    0.00906     0.00834
log_std/max                           -0.12183     0.00137    -0.11942    -0.12408
log_std/min                           -0.16911     0.00059    -0.16824    -0.17024
log_probs/mean                        -2.72130     0.00629    -2.71018    -2.73106
log_probs/std                         0.26802      0.01191    0.29281     0.24893
log_probs/max                         -1.88298     0.06070    -1.76874    -1.97145
log_probs/min                         -5.13115     0.68265    -4.28289    -6.68419
mean/mean                             -0.01488     0.00056    -0.01382    -0.01545
mean/std                              0.05703      0.00035    0.05760     0.05646
mean/max                              0.10310      0.00135    0.10543     0.10127
mean/min                              -0.17096     0.00243    -0.16752    -0.17457
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 1, 5, 8, 0, 3, 7, 6, 4, 9]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.2514240741729736 1.8835067749023438e-05
train_time 3.2515041828155518
2023-09-06 13:25:45,596 MainThread INFO: EPOCH:48
2023-09-06 13:25:45,597 MainThread INFO: Time Consumed:3.272918462753296s
2023-09-06 13:25:45,597 MainThread INFO: Total Frames:73500s
 24%|██▍       | 49/200 [02:08<08:07,  3.23s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               2001.19144
Train_Epoch_Reward                    19662.10180
Running_Training_Average_Rewards      1495.14891
Explore_Time                          0.01473
Train___Time                          3.25150
Eval____Time                          0.00592
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.72016
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.64625
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.29906
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.70980
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -28.16806
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -32.12819
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.12046
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19281.77360
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.94128
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.83778
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.26124      0.77310    10.57226    8.12568
alpha_0                               0.86428      0.00074    0.86545     0.86312
alpha_1                               0.86432      0.00074    0.86549     0.86315
alpha_2                               0.86434      0.00074    0.86551     0.86317
alpha_3                               0.86428      0.00074    0.86545     0.86312
alpha_4                               0.86427      0.00075    0.86544     0.86310
alpha_5                               0.86433      0.00074    0.86549     0.86316
alpha_6                               0.86432      0.00074    0.86549     0.86316
alpha_7                               0.86435      0.00074    0.86551     0.86319
alpha_8                               0.86435      0.00074    0.86552     0.86319
alpha_9                               0.86424      0.00075    0.86541     0.86307
Alpha_loss                            -0.97840     0.00549    -0.96973    -0.98781
Training/policy_loss                  -6.25387     0.02869    -6.21039    -6.30736
Training/qf1_loss                     1359.16145   300.75605  1790.66919  901.81116
Training/qf2_loss                     1354.40817   300.42731  1785.68323  897.41571
Training/pf_norm                      0.12974      0.01692    0.15518     0.09761
Training/qf1_norm                     204.81816    19.21715   238.49254   178.43246
Training/qf2_norm                     203.91544    19.19394   238.26472   178.02832
log_std/mean                          -0.14165     0.00067    -0.14068    -0.14255
log_std/std                           0.00971      0.00030    0.01008     0.00916
log_std/max                           -0.11818     0.00057    -0.11742    -0.11913
log_std/min                           -0.17011     0.00161    -0.16826    -0.17282
log_probs/mean                        -2.72329     0.00413    -2.71700    -2.73135
log_probs/std                         0.27232      0.01488    0.29986     0.25384
log_probs/max                         -1.88570     0.07024    -1.74599    -1.99072
log_probs/min                         -4.88582     0.44484    -4.19358    -5.56028
mean/mean                             -0.01676     0.00089    -0.01542    -0.01808
mean/std                              0.05973      0.00131    0.06193     0.05791
mean/max                              0.10923      0.00271    0.11402     0.10625
mean/min                              -0.18528     0.00628    -0.17592    -0.19612
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 8, 5, 9, 4, 0, 3, 1, 7, 2]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.043800115585327 1.9073486328125e-05
train_time 3.0438666343688965
2023-09-06 13:25:48,804 MainThread INFO: EPOCH:49
2023-09-06 13:25:48,804 MainThread INFO: Time Consumed:3.0609147548675537s
2023-09-06 13:25:48,804 MainThread INFO: Total Frames:75000s
 25%|██▌       | 50/200 [02:11<08:02,  3.22s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1916.64745
Train_Epoch_Reward                    15320.54571
Running_Training_Average_Rewards      1571.24493
Explore_Time                          0.01169
Train___Time                          3.04387
Eval____Time                          0.00484
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.61931
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.74013
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.41031
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.96695
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -28.77712
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -32.68490
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.20548
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18494.88804
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.13906
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.24845
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.07998      0.50495    10.09802    8.44544
alpha_0                               0.86170      0.00074    0.86286     0.86054
alpha_1                               0.86173      0.00074    0.86289     0.86057
alpha_2                               0.86175      0.00074    0.86292     0.86059
alpha_3                               0.86169      0.00074    0.86286     0.86053
alpha_4                               0.86168      0.00074    0.86285     0.86052
alpha_5                               0.86174      0.00074    0.86290     0.86058
alpha_6                               0.86174      0.00074    0.86290     0.86058
alpha_7                               0.86177      0.00074    0.86293     0.86061
alpha_8                               0.86177      0.00074    0.86293     0.86061
alpha_9                               0.86165      0.00074    0.86281     0.86048
Alpha_loss                            -0.99877     0.00544    -0.99101    -1.00774
Training/policy_loss                  -6.37321     0.03162    -6.33030    -6.43062
Training/qf1_loss                     1442.01570   361.80946  2297.41504  1032.28223
Training/qf2_loss                     1436.99174   361.95112  2293.16626  1027.66370
Training/pf_norm                      0.12127      0.01962    0.14718     0.09159
Training/qf1_norm                     206.10944    12.85838   230.89629   192.65451
Training/qf2_norm                     205.63820    12.19286   228.06725   192.21509
log_std/mean                          -0.14320     0.00039    -0.14260    -0.14392
log_std/std                           0.01013      0.00005    0.01023     0.01007
log_std/max                           -0.11758     0.00047    -0.11699    -0.11869
log_std/min                           -0.17340     0.00106    -0.17144    -0.17466
log_probs/mean                        -2.72471     0.00539    -2.71806    -2.73364
log_probs/std                         0.28047      0.01141    0.30353     0.26699
log_probs/max                         -1.80924     0.09506    -1.66390    -2.00384
log_probs/min                         -5.15213     0.36938    -4.40121    -5.69349
mean/mean                             -0.01909     0.00049    -0.01829    -0.01993
mean/std                              0.06503      0.00173    0.06787     0.06249
mean/max                              0.11960      0.00320    0.12504     0.11478
mean/min                              -0.20666     0.00678    -0.19574    -0.21585
------------------------------------  -----------  ---------  ----------  ----------
sample: [1, 0, 6, 4, 5, 8, 2, 7, 3, 9]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 1.9005041122436523 2.0265579223632812e-05
train_time 1.9005839824676514
2023-09-06 13:25:52,013 MainThread INFO: EPOCH:50
2023-09-06 13:25:52,013 MainThread INFO: Time Consumed:1.9110925197601318s
2023-09-06 13:25:52,013 MainThread INFO: Total Frames:76500s
 26%|██▌       | 51/200 [02:14<08:00,  3.22s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1793.22925
Train_Epoch_Reward                    15529.92033
Running_Training_Average_Rewards      1683.75226
Explore_Time                          0.00329
Train___Time                          1.90058
Eval____Time                          0.00659
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.43076
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.31990
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.15334
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.46943
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -29.74743
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -34.85892
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.57149
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16894.47633
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.78844
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.55786
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.56484      0.29299    10.08649    9.13105
alpha_0                               0.85913      0.00074    0.86029     0.85798
alpha_1                               0.85915      0.00074    0.86031     0.85799
alpha_2                               0.85917      0.00074    0.86033     0.85801
alpha_3                               0.85911      0.00074    0.86027     0.85795
alpha_4                               0.85910      0.00074    0.86026     0.85794
alpha_5                               0.85916      0.00074    0.86032     0.85800
alpha_6                               0.85916      0.00074    0.86032     0.85800
alpha_7                               0.85920      0.00074    0.86036     0.85804
alpha_8                               0.85919      0.00074    0.86035     0.85803
alpha_9                               0.85907      0.00074    0.86023     0.85791
Alpha_loss                            -1.01722     0.00568    -1.00801    -1.02437
Training/policy_loss                  -6.48119     0.03226    -6.42912    -6.52224
Training/qf1_loss                     1477.42078   193.65912  1802.13318  1222.00977
Training/qf2_loss                     1472.49990   193.32181  1795.88367  1217.13489
Training/pf_norm                      0.12366      0.01811    0.15542     0.09258
Training/qf1_norm                     225.37747    8.26731    242.12381   216.80060
Training/qf2_norm                     224.06890    7.55611    238.97523   215.96181
log_std/mean                          -0.14398     0.00022    -0.14364    -0.14425
log_std/std                           0.01023      0.00004    0.01030     0.01017
log_std/max                           -0.11868     0.00040    -0.11804    -0.11927
log_std/min                           -0.17557     0.00068    -0.17400    -0.17642
log_probs/mean                        -2.71340     0.00942    -2.69990    -2.72737
log_probs/std                         0.27888      0.00846    0.29553     0.26749
log_probs/max                         -1.78373     0.12074    -1.61575    -1.97964
log_probs/min                         -4.84044     0.39569    -4.41454    -5.76713
mean/mean                             -0.02059     0.00015    -0.02021    -0.02075
mean/std                              0.07096      0.00139    0.07288     0.06849
mean/max                              0.13060      0.00321    0.13555     0.12487
mean/min                              -0.22740     0.00422    -0.21796    -0.23350
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 2, 6, 7, 9, 5, 0, 1, 4, 8]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.4107165336608887 1.9311904907226562e-05
train_time 3.4108054637908936
2023-09-06 13:25:55,606 MainThread INFO: EPOCH:51
2023-09-06 13:25:55,607 MainThread INFO: Time Consumed:3.4221444129943848s
2023-09-06 13:25:55,608 MainThread INFO: Total Frames:78000s
 26%|██▌       | 52/200 [02:18<08:12,  3.33s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1670.42253
Train_Epoch_Reward                    2380.99516
Running_Training_Average_Rewards      1107.71537
Explore_Time                          0.00639
Train___Time                          3.41081
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.48002
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.91681
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.00258
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.90062
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -30.80879
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -36.94371
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.14605
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15606.37527
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.42445
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.75129
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.16590     0.52631    11.06272    9.24332
alpha_0                               0.85657      0.00073    0.85772     0.85542
alpha_1                               0.85658      0.00074    0.85773     0.85542
alpha_2                               0.85660      0.00074    0.85775     0.85544
alpha_3                               0.85654      0.00074    0.85769     0.85538
alpha_4                               0.85652      0.00074    0.85768     0.85537
alpha_5                               0.85659      0.00074    0.85775     0.85544
alpha_6                               0.85659      0.00074    0.85774     0.85543
alpha_7                               0.85663      0.00074    0.85779     0.85548
alpha_8                               0.85662      0.00074    0.85777     0.85547
alpha_9                               0.85649      0.00074    0.85765     0.85534
Alpha_loss                            -1.03785     0.00572    -1.02996    -1.04640
Training/policy_loss                  -6.60041     0.03448    -6.55138    -6.65752
Training/qf1_loss                     1735.11971   293.89823  2314.30762  1258.96509
Training/qf2_loss                     1730.17057   293.78788  2309.19995  1254.43933
Training/pf_norm                      0.14725      0.02152    0.18889     0.11390
Training/qf1_norm                     247.37567    13.01554   267.15594   223.68047
Training/qf2_norm                     245.32854    13.04252   264.61731   220.54742
log_std/mean                          -0.14361     0.00007    -0.14352    -0.14374
log_std/std                           0.01011      0.00007    0.01021     0.01003
log_std/max                           -0.12157     0.00167    -0.11955    -0.12435
log_std/min                           -0.17589     0.00052    -0.17502    -0.17668
log_probs/mean                        -2.71674     0.00794    -2.70651    -2.73268
log_probs/std                         0.28903      0.00856    0.29758     0.27233
log_probs/max                         -1.78915     0.07793    -1.67319    -1.90056
log_probs/min                         -5.08100     0.60210    -4.29455    -6.46340
mean/mean                             -0.02047     0.00010    -0.02030    -0.02062
mean/std                              0.07497      0.00099    0.07634     0.07326
mean/max                              0.14034      0.00240    0.14344     0.13654
mean/min                              -0.24302     0.00491    -0.23495    -0.24985
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 2, 5, 8, 4, 7, 6, 1, 3, 0]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.1445183753967285 5.1975250244140625e-05
train_time 3.1446282863616943
2023-09-06 13:25:58,921 MainThread INFO: EPOCH:52
2023-09-06 13:25:58,922 MainThread INFO: Time Consumed:3.1531097888946533s
2023-09-06 13:25:58,922 MainThread INFO: Total Frames:79500s
 26%|██▋       | 53/200 [02:21<08:09,  3.33s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1553.87777
Train_Epoch_Reward                    45915.83298
Running_Training_Average_Rewards      2127.55828
Explore_Time                          0.00402
Train___Time                          3.14463
Eval____Time                          0.00344
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.71596
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.03690
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.20732
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.79864
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -31.63088
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -38.99447
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.36841
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15008.70962
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.50780
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.69592
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.50281      0.59668    10.28968    8.44384
alpha_0                               0.85402      0.00073    0.85517     0.85287
alpha_1                               0.85401      0.00073    0.85516     0.85286
alpha_2                               0.85403      0.00074    0.85519     0.85288
alpha_3                               0.85397      0.00074    0.85512     0.85282
alpha_4                               0.85396      0.00074    0.85511     0.85280
alpha_5                               0.85403      0.00074    0.85518     0.85287
alpha_6                               0.85402      0.00074    0.85518     0.85287
alpha_7                               0.85407      0.00073    0.85522     0.85293
alpha_8                               0.85406      0.00073    0.85521     0.85291
alpha_9                               0.85393      0.00074    0.85508     0.85278
Alpha_loss                            -1.05770     0.00477    -1.05060    -1.06603
Training/policy_loss                  -6.72200     0.02962    -6.67442    -6.76970
Training/qf1_loss                     1400.58636   238.56213  1907.64734  1075.29736
Training/qf2_loss                     1396.04243   238.16772  1901.83679  1071.34570
Training/pf_norm                      0.13644      0.02731    0.18677     0.08527
Training/qf1_norm                     237.54117    15.14561   259.15387   208.97073
Training/qf2_norm                     235.13485    15.20670   256.88214   206.80949
log_std/mean                          -0.14269     0.00045    -0.14221    -0.14339
log_std/std                           0.01026      0.00019    0.01057     0.01002
log_std/max                           -0.12351     0.00060    -0.12259    -0.12429
log_std/min                           -0.17471     0.00056    -0.17394    -0.17573
log_probs/mean                        -2.71504     0.00804    -2.70221    -2.72755
log_probs/std                         0.29612      0.01244    0.31369     0.27493
log_probs/max                         -1.69397     0.08840    -1.51380    -1.82414
log_probs/min                         -5.08636     0.55201    -3.98393    -5.90876
mean/mean                             -0.01947     0.00038    -0.01900    -0.02015
mean/std                              0.07738      0.00058    0.07827     0.07640
mean/max                              0.14918      0.00285    0.15316     0.14377
mean/min                              -0.25771     0.00459    -0.25055    -0.26585
------------------------------------  -----------  ---------  ----------  ----------
sample: [2, 5, 7, 8, 1, 4, 9, 3, 0, 6]
replay_buffer._size: [8250 8250 8250 8250 8250 8250 8250 8250 8250 8250]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.367814540863037 1.8358230590820312e-05
train_time 3.3678853511810303
2023-09-06 13:26:02,476 MainThread INFO: EPOCH:53
2023-09-06 13:26:02,476 MainThread INFO: Time Consumed:3.383661985397339s
2023-09-06 13:26:02,476 MainThread INFO: Total Frames:81000s
 27%|██▋       | 54/200 [02:25<08:16,  3.40s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1476.68865
Train_Epoch_Reward                    21213.96285
Running_Training_Average_Rewards      2317.02637
Explore_Time                          0.00975
Train___Time                          3.36789
Eval____Time                          0.00472
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.13796
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.84661
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.62471
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.39842
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.19014
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.12026
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.62635
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14583.87347
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.39260
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.63109
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.16546     0.69416    11.19971    8.89513
alpha_0                               0.85148      0.00073    0.85262     0.85034
alpha_1                               0.85146      0.00073    0.85261     0.85031
alpha_2                               0.85148      0.00073    0.85263     0.85033
alpha_3                               0.85142      0.00073    0.85256     0.85027
alpha_4                               0.85140      0.00073    0.85255     0.85025
alpha_5                               0.85147      0.00073    0.85262     0.85032
alpha_6                               0.85147      0.00073    0.85262     0.85032
alpha_7                               0.85153      0.00073    0.85267     0.85038
alpha_8                               0.85151      0.00073    0.85265     0.85036
alpha_9                               0.85137      0.00073    0.85252     0.85022
Alpha_loss                            -1.07827     0.00625    -1.06724    -1.08779
Training/policy_loss                  -6.84436     0.03644    -6.78564    -6.89966
Training/qf1_loss                     1722.19233   368.84055  2299.32495  1161.50586
Training/qf2_loss                     1717.53756   368.43238  2292.62988  1155.81055
Training/pf_norm                      0.13542      0.02496    0.17526     0.09692
Training/qf1_norm                     262.47425    19.84185   290.75854   223.88519
Training/qf2_norm                     259.41887    19.60970   287.07602   223.48555
log_std/mean                          -0.14211     0.00012    -0.14190    -0.14228
log_std/std                           0.01105      0.00023    0.01137     0.01069
log_std/max                           -0.12215     0.00054    -0.12146    -0.12336
log_std/min                           -0.17767     0.00147    -0.17540    -0.18004
log_probs/mean                        -2.71789     0.00628    -2.70547    -2.72859
log_probs/std                         0.30705      0.01251    0.32807     0.28904
log_probs/max                         -1.67506     0.10982    -1.49012    -1.84096
log_probs/min                         -5.45914     1.14647    -4.46517    -8.23493
mean/mean                             -0.02019     0.00092    -0.01909    -0.02169
mean/std                              0.07944      0.00074    0.08073     0.07847
mean/max                              0.15659      0.00134    0.15882     0.15372
mean/min                              -0.27650     0.00714    -0.26575    -0.28856
------------------------------------  -----------  ---------  ----------  ----------
sample: [0, 4, 2, 3, 9, 1, 5, 7, 6, 8]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.3869097232818604 1.7404556274414062e-05
train_time 3.3869874477386475
2023-09-06 13:26:06,027 MainThread INFO: EPOCH:54
2023-09-06 13:26:06,027 MainThread INFO: Time Consumed:3.405829429626465s
2023-09-06 13:26:06,027 MainThread INFO: Total Frames:82500s
 28%|██▊       | 55/200 [02:28<08:17,  3.43s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1413.45412
Train_Epoch_Reward                    14484.54136
Running_Training_Average_Rewards      2720.47791
Explore_Time                          0.01505
Train___Time                          3.38699
Eval____Time                          0.00336
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.28308
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.57485
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.90465
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.53218
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.35126
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -39.84808
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.09117
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13713.89013
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.34753
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.99249
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.13924     0.56786    10.97258    9.24729
alpha_0                               0.84894      0.00073    0.85008     0.84781
alpha_1                               0.84891      0.00073    0.85005     0.84776
alpha_2                               0.84893      0.00073    0.85008     0.84779
alpha_3                               0.84887      0.00073    0.85001     0.84772
alpha_4                               0.84884      0.00073    0.84999     0.84770
alpha_5                               0.84892      0.00073    0.85007     0.84777
alpha_6                               0.84892      0.00073    0.85006     0.84777
alpha_7                               0.84899      0.00073    0.85013     0.84785
alpha_8                               0.84896      0.00073    0.85010     0.84782
alpha_9                               0.84882      0.00073    0.84997     0.84767
Alpha_loss                            -1.09863     0.00602    -1.08911    -1.10879
Training/policy_loss                  -6.96673     0.03579    -6.90391    -7.01838
Training/qf1_loss                     1616.91768   242.69581  2085.29419  1261.21130
Training/qf2_loss                     1611.72299   242.55210  2079.46338  1256.21216
Training/pf_norm                      0.14468      0.03313    0.19963     0.08862
Training/qf1_norm                     269.34859    16.72386   293.65494   243.92050
Training/qf2_norm                     266.91304    16.30125   290.05685   242.37584
log_std/mean                          -0.14375     0.00093    -0.14246    -0.14538
log_std/std                           0.01202      0.00045    0.01281     0.01141
log_std/max                           -0.12376     0.00081    -0.12224    -0.12503
log_std/min                           -0.18351     0.00239    -0.17929    -0.18773
log_probs/mean                        -2.71929     0.00867    -2.70571    -2.73826
log_probs/std                         0.31341      0.01504    0.34999     0.29276
log_probs/max                         -1.65526     0.07218    -1.51117    -1.76202
log_probs/min                         -5.14935     0.68324    -4.53045    -6.96062
mean/mean                             -0.02366     0.00097    -0.02205    -0.02518
mean/std                              0.08397      0.00201    0.08747     0.08113
mean/max                              0.16482      0.00355    0.17106     0.15939
mean/min                              -0.30552     0.01065    -0.28744    -0.32344
------------------------------------  -----------  ---------  ----------  ----------
sample: [5, 2, 1, 4, 6, 3, 0, 7, 9, 8]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.219766139984131 3.0040740966796875e-05
train_time 3.2198421955108643
2023-09-06 13:26:09,422 MainThread INFO: EPOCH:55
2023-09-06 13:26:09,422 MainThread INFO: Time Consumed:3.226724863052368s
2023-09-06 13:26:09,422 MainThread INFO: Total Frames:84000s
 28%|██▊       | 56/200 [02:31<08:14,  3.43s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1312.88654
Train_Epoch_Reward                    8942.93858
Running_Training_Average_Rewards      1488.04809
Explore_Time                          0.00334
Train___Time                          3.21984
Eval____Time                          0.00302
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.74768
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.86169
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.98097
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.19075
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.74111
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.82327
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.24572
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11999.04359
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.88756
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.83876
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.98361      0.78630    10.93339    8.49792
alpha_0                               0.84642      0.00072    0.84755     0.84529
alpha_1                               0.84637      0.00073    0.84751     0.84523
alpha_2                               0.84639      0.00073    0.84753     0.84525
alpha_3                               0.84633      0.00073    0.84747     0.84518
alpha_4                               0.84630      0.00073    0.84744     0.84516
alpha_5                               0.84638      0.00073    0.84752     0.84524
alpha_6                               0.84637      0.00073    0.84752     0.84523
alpha_7                               0.84645      0.00073    0.84759     0.84532
alpha_8                               0.84642      0.00073    0.84756     0.84528
alpha_9                               0.84627      0.00073    0.84742     0.84513
Alpha_loss                            -1.11712     0.00557    -1.10887    -1.12426
Training/policy_loss                  -7.09518     0.03892    -7.04233    -7.15633
Training/qf1_loss                     1583.94821   260.94529  1914.50903  1086.22363
Training/qf2_loss                     1579.03107   261.03698  1909.93713  1081.70459
Training/pf_norm                      0.13983      0.01634    0.17528     0.12004
Training/qf1_norm                     272.17344    23.95491   299.42191   227.51645
Training/qf2_norm                     269.19374    22.81792   295.41589   225.64075
log_std/mean                          -0.14686     0.00063    -0.14582    -0.14770
log_std/std                           0.01359      0.00039    0.01407     0.01294
log_std/max                           -0.12495     0.00051    -0.12419    -0.12566
log_std/min                           -0.19199     0.00203    -0.18865    -0.19418
log_probs/mean                        -2.70946     0.00761    -2.69814    -2.72141
log_probs/std                         0.32351      0.01185    0.34042     0.30310
log_probs/max                         -1.53045     0.08054    -1.40053    -1.65120
log_probs/min                         -5.16341     0.76217    -4.06914    -6.43521
mean/mean                             -0.02703     0.00111    -0.02553    -0.02891
mean/std                              0.09227      0.00231    0.09565     0.08840
mean/max                              0.18315      0.00513    0.19102     0.17433
mean/min                              -0.34554     0.01207    -0.32666    -0.36324
------------------------------------  -----------  ---------  ----------  ----------
sample: [3, 0, 2, 1, 6, 8, 5, 7, 9, 4]
replay_buffer._size: [8700 8700 8700 8700 8700 8700 8700 8700 8700 8700]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 2.111873149871826 2.5510787963867188e-05
train_time 2.111959218978882
2023-09-06 13:26:13,091 MainThread INFO: EPOCH:56
2023-09-06 13:26:13,093 MainThread INFO: Time Consumed:2.1191296577453613s
2023-09-06 13:26:13,093 MainThread INFO: Total Frames:85500s
 28%|██▊       | 57/200 [02:35<08:19,  3.50s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               1163.48540
Train_Epoch_Reward                    29828.58394
Running_Training_Average_Rewards      1775.20213
Explore_Time                          0.00346
Train___Time                          2.11196
Eval____Time                          0.00319
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.84412
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.61222
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.73782
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.18290
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.32584
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -42.93544
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.88435
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10113.94240
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -33.86291
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -26.68571
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           10.45847     0.73983    12.09816    9.46984
alpha_0                               0.84391      0.00072    0.84504     0.84279
alpha_1                               0.84384      0.00073    0.84497     0.84270
alpha_2                               0.84386      0.00073    0.84500     0.84272
alpha_3                               0.84379      0.00073    0.84493     0.84265
alpha_4                               0.84376      0.00073    0.84490     0.84263
alpha_5                               0.84384      0.00073    0.84498     0.84271
alpha_6                               0.84384      0.00073    0.84498     0.84270
alpha_7                               0.84393      0.00073    0.84506     0.84279
alpha_8                               0.84389      0.00073    0.84503     0.84275
alpha_9                               0.84374      0.00073    0.84488     0.84260
Alpha_loss                            -1.13624     0.00488    -1.12876    -1.14399
Training/policy_loss                  -7.22436     0.03567    -7.15943    -7.27280
Training/qf1_loss                     1843.13885   417.85280  2895.63159  1336.36877
Training/qf2_loss                     1838.57775   418.00320  2891.06226  1330.91382
Training/pf_norm                      0.14539      0.01807    0.17935     0.11237
Training/qf1_norm                     294.43450    22.61268   346.10638   266.96399
Training/qf2_norm                     290.40787    21.83473   340.88028   264.68100
log_std/mean                          -0.14750     0.00009    -0.14735    -0.14770
log_std/std                           0.01417      0.00005    0.01426     0.01409
log_std/max                           -0.12453     0.00054    -0.12399    -0.12548
log_std/min                           -0.19404     0.00137    -0.19177    -0.19594
log_probs/mean                        -2.70378     0.00853    -2.68945    -2.71814
log_probs/std                         0.33215      0.01186    0.34963     0.31316
log_probs/max                         -1.48346     0.06124    -1.39171    -1.57942
log_probs/min                         -5.08205     0.58251    -4.37458    -6.51747
mean/mean                             -0.03125     0.00125    -0.02938    -0.03327
mean/std                              0.09879      0.00151    0.10073     0.09624
mean/max                              0.19548      0.00329    0.19945     0.19019
mean/min                              -0.37884     0.00865    -0.36415    -0.38868
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 3, 1, 0, 2, 5, 7, 4, 8]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.4553253650665283 1.9073486328125e-05
train_time 3.4553887844085693
2023-09-06 13:26:16,721 MainThread INFO: EPOCH:57
2023-09-06 13:26:16,728 MainThread INFO: Time Consumed:3.472921848297119s
2023-09-06 13:26:16,728 MainThread INFO: Total Frames:87000s
 29%|██▉       | 58/200 [02:39<08:23,  3.55s/it]------------------------------------  -----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               993.40115
Train_Epoch_Reward                    26877.10285
Running_Training_Average_Rewards      2188.28751
Explore_Time                          0.01365
Train___Time                          3.45539
Eval____Time                          0.00334
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.20993
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -50.64334
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.33785
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.24495
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.83892
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -45.64277
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.19413
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8633.82470
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.71462
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.56077
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           9.94976      0.66965    11.37136    9.03148
alpha_0                               0.84142      0.00071    0.84254     0.84031
alpha_1                               0.84132      0.00072    0.84245     0.84018
alpha_2                               0.84134      0.00072    0.84247     0.84020
alpha_3                               0.84126      0.00072    0.84240     0.84013
alpha_4                               0.84124      0.00072    0.84238     0.84011
alpha_5                               0.84132      0.00072    0.84245     0.84019
alpha_6                               0.84131      0.00072    0.84245     0.84018
alpha_7                               0.84141      0.00072    0.84254     0.84028
alpha_8                               0.84137      0.00072    0.84250     0.84024
alpha_9                               0.84121      0.00073    0.84234     0.84007
Alpha_loss                            -1.15598     0.00690    -1.14390    -1.16589
Training/policy_loss                  -7.35517     0.04174    -7.28859    -7.42165
Training/qf1_loss                     1605.27457   272.99626  2066.63818  1278.03613
Training/qf2_loss                     1600.32673   272.91248  2059.71997  1272.12964
Training/pf_norm                      0.15027      0.03086    0.21227     0.08801
Training/qf1_norm                     285.88619    19.94286   324.53168   257.85281
Training/qf2_norm                     282.54137    19.82612   322.45163   253.42024
log_std/mean                          -0.14812     0.00024    -0.14761    -0.14840
log_std/std                           0.01434      0.00010    0.01452     0.01419
log_std/max                           -0.12648     0.00099    -0.12461    -0.12802
log_std/min                           -0.19693     0.00128    -0.19453    -0.19954
log_probs/mean                        -2.70185     0.00810    -2.68402    -2.71304
log_probs/std                         0.33928      0.01383    0.36723     0.31743
log_probs/max                         -1.50003     0.07924    -1.38801    -1.61914
log_probs/min                         -5.21242     0.44921    -4.50073    -6.01338
mean/mean                             -0.03407     0.00021    -0.03352    -0.03428
mean/std                              0.10283      0.00148    0.10570     0.10113
mean/max                              0.20357      0.00425    0.21215     0.19764
mean/min                              -0.40420     0.00785    -0.39112    -0.41813
------------------------------------  -----------  ---------  ----------  ----------
sample: [9, 6, 8, 7, 4, 3, 0, 5, 1, 2]
replay_buffer._size: [9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
obs.device cuda:0
policy_device_masks.device cuda:0
diff1,diff2 3.645139217376709 1.8358230590820312e-05
train_time 3.6452176570892334
2023-09-06 13:26:20,536 MainThread INFO: EPOCH:58
2023-09-06 13:26:20,536 MainThread INFO: Time Consumed:3.6546642780303955s
2023-09-06 13:26:20,536 MainThread INFO: Total Frames:88500s
 30%|██▉       | 59/200 [02:43<08:30,  3.62s/it] 30%|██▉       | 59/200 [02:45<06:35,  2.81s/it]
------------------------------------  ----------  ---------  ----------  ----------
Name                                  Value
Running_Average_Rewards               848.97502
Train_Epoch_Reward                    8621.36751
Running_Training_Average_Rewards      2177.56848
Explore_Time                          0.00371
Train___Time                          3.64522
Eval____Time                          0.00525
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.31320
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.46741
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.13624
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.27846
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.25359
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -47.73667
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.03747
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7689.46767
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.55442
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -28.74805
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           9.80410     0.61302    10.54976    8.74324
alpha_0                               0.83895     0.00071    0.84006     0.83784
alpha_1                               0.83880     0.00072    0.83993     0.83767
alpha_2                               0.83882     0.00072    0.83995     0.83770
alpha_3                               0.83874     0.00072    0.83988     0.83761
alpha_4                               0.83873     0.00072    0.83986     0.83759
alpha_5                               0.83880     0.00072    0.83993     0.83768
alpha_6                               0.83879     0.00072    0.83992     0.83766
alpha_7                               0.83890     0.00072    0.84003     0.83778
alpha_8                               0.83886     0.00072    0.83998     0.83773
alpha_9                               0.83869     0.00072    0.83982     0.83756
Alpha_loss                            -1.17511    0.00635    -1.16588    -1.18564
Training/policy_loss                  -7.48849    0.03809    -7.43271    -7.54279
Training/qf1_loss                     1636.02610  369.64898  2338.68042  1213.97095
Training/qf2_loss                     1630.97528  369.15586  2332.61841  1208.11914
Training/pf_norm                      0.16230     0.02469    0.19446     0.11897
Training/qf1_norm                     288.59194   20.84365   317.82547   252.77136
Training/qf2_norm                     285.29771   20.62016   314.98920   251.87347
log_std/mean                          -0.14804    0.00018    -0.14777    -0.14831
log_std/std                           0.01499     0.00036    0.01562     0.01449
log_std/max                           -0.12519    0.00101    -0.12370    -0.12728
log_std/min                           -0.20608    0.00387    -0.19918    -0.21205
log_probs/mean                        -2.69670    0.00986    -2.68375    -2.71671
log_probs/std                         0.35126     0.00959    0.37248     0.33815
log_probs/max                         -1.38384    0.08011    -1.27100    -1.54423
log_probs/min                         -5.07663    0.49182    -4.41352    -6.11729
mean/mean                             -0.03538    0.00060    -0.03441    -0.03652
mean/std                              0.11048     0.00257    0.11447     0.10652
mean/max                              0.22374     0.00627    0.23259     0.21243
mean/min                              -0.44466    0.01338    -0.42378    -0.46545
------------------------------------  ----------  ---------  ----------  ----------
sample: [5, 1, 4, 0, 6, 2, 8, 9, 3, 7]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
obs.device cuda:0
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 149, in _serve
    send(conn, destination_pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 50, in send
    reduction.send_handle(conn, new_fd, pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 184, in send_handle
    sendfds(s, [handle])
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 149, in sendfds
    sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)])
BrokenPipeError: [Errno 32] Broken pipe
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 38, in __init__
    def __init__(self, *args):
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-18:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 310, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 305, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 410, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer, epoch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 304, in update_per_epoch
    info = self.update(batch, task_sample_index, task_scheduler, mask_buffer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 123, in update
    q2_device_masks = self.concat_mask_tensors(task_scheduler.task_sample_num,
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 47, in concat_mask_tensors
    single_mask = [each.expand(task_batch_size, -1).to(device) for each in specific_mask_buffer[i]]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 189, in recv_handle
    return recvfds(s, 1)[0]
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 157, in recvfds
    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-20:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 330, in _bootstrap
    sys.stderr.write('Process %s:\n' % self.name)
KeyboardInterrupt
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
