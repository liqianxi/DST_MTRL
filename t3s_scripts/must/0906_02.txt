W&B disabled.
2023-09-06 12:22:48,708 MainThread INFO: Experiment Name:testing_must_mtsac
2023-09-06 12:22:48,708 MainThread INFO: {
  "env_name": "mt10",
  "env": {
    "reward_scale": 1,
    "obs_norm": false
  },
  "meta_env": {
    "obs_type": "with_goal_and_id"
  },
  "replay_buffer": {
    "size": 1000000.0
  },
  "net": {
    "hidden_shapes": [
      400,
      400,
      400
    ]
  },
  "task_embedding": {
    "em_hidden_shapes": [
      256,
      256
    ]
  },
  "traj_encoder": {
    "hidden_shapes": [
      256,
      256
    ],
    "latent_size": 64
  },
  "sparse_training": {
    "pruning_ratio": 0.4
  },
  "general_setting": {
    "discount": 0.99,
    "pretrain_epochs": 0,
    "num_epochs": 200,
    "epoch_frames": 150,
    "max_episode_frames": 150,
    "success_traj_update_only": 1,
    "batch_size": 1280,
    "min_pool": 10000,
    "target_hard_update_period": 1000,
    "use_soft_update": true,
    "tau": 0.005,
    "opt_times": 50,
    "mask_update_interval": 3,
    "update_end_epoch": 20,
    "eval_episodes": 1
  },
  "sac": {
    "plr": 0.0003,
    "qlr": 0.0003,
    "reparameterization": true,
    "automatic_entropy_tuning": true,
    "policy_std_reg_weight": 0,
    "policy_mean_reg_weight": 0
  }
}
finish policy net init
mask generator finish initialization
/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Could not seed environment <MTEnv instance>[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
2023-09-06 12:24:10,089 MainThread INFO: Finished Pretrain
  0%|          | 0/200 [00:00<?, ?it/s]sample: [6, 5, 0, 3, 9, 8, 4, 2, 1, 7]
replay_buffer._size: [300 300 300 300 300 300 300 300 300 300]
diff1,diff2 6.931652784347534 0.00020051002502441406
train_time 6.931949615478516
snapshot at best
2023-09-06 12:24:19,229 MainThread INFO: EPOCH:0
2023-09-06 12:24:19,230 MainThread INFO: Time Consumed:9.04951524734497s
2023-09-06 12:24:19,230 MainThread INFO: Total Frames:1500s
/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py:374: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  value = torch.sum((self.mask_buffer["Policy"][each_task][0] == 0).nonzero().squeeze()).item()
  0%|          | 1/200 [00:10<34:16, 10.34s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               343.03018
Train_Epoch_Reward                    3680.63417
Running_Training_Average_Rewards      368.06342
Explore_Time                          0.01053
Train___Time                          6.93195
Eval____Time                          1.59474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.55176
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.42746
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.76723
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.59015
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.21582
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -29.57356
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.05872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3716.49324
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.59702
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.40969
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.92848     0.40472   4.65764    2.84253
alpha_0                               0.99238     0.00430   0.99970    0.98510
alpha_1                               0.99238     0.00430   0.99970    0.98510
alpha_2                               0.99239     0.00430   0.99970    0.98510
alpha_3                               0.99238     0.00430   0.99970    0.98510
alpha_4                               0.99238     0.00430   0.99970    0.98510
alpha_5                               0.99238     0.00430   0.99970    0.98509
alpha_6                               0.99238     0.00430   0.99970    0.98509
alpha_7                               0.99239     0.00430   0.99970    0.98511
alpha_8                               0.99238     0.00430   0.99970    0.98511
alpha_9                               0.99238     0.00430   0.99970    0.98510
Alpha_loss                            -0.04951    0.02917   -0.00000   -0.09898
Training/policy_loss                  -4.14281    1.47082   -2.67676   -7.30614
Training/qf1_loss                     260.84447   34.58921  338.72339  184.06696
Training/qf2_loss                     260.36094   34.52060  338.50568  184.02640
Training/pf_norm                      0.31155     0.13328   0.74505    0.17131
Training/qf1_norm                     96.35522    64.07470  237.91557  18.93308
Training/qf2_norm                     96.40998    61.71249  232.13609  19.66670
log_std/mean                          -0.11794    0.04206   0.00086    -0.17202
log_std/std                           0.00603     0.00192   0.00862    0.00295
log_std/max                           -0.10488    0.04143   0.00940    -0.16433
log_std/min                           -0.12979    0.04498   -0.00373   -0.18044
log_probs/mean                        -2.72797    0.01285   -2.67662   -2.74416
log_probs/std                         0.26573     0.05451   0.45077    0.19802
log_probs/max                         -2.02259    0.23250   -1.28101   -2.31891
log_probs/min                         -4.99855    0.75682   -3.80634   -7.55807
mean/mean                             -0.00587    0.01067   0.00226    -0.04024
mean/std                              0.01642     0.00830   0.04319    0.00342
mean/max                              0.03128     0.01170   0.05905    0.00396
mean/min                              -0.03310    0.01889   -0.00917   -0.09231
------------------------------------  ----------  --------  ---------  ---------
snapshot at 0
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [6, 1, 5, 2, 8, 7, 0, 9, 3, 4]
replay_buffer._size: [450 450 450 450 450 450 450 450 450 450]
diff1,diff2 4.899250030517578 0.00010013580322265625
train_time 4.8994221687316895
snapshot at best
2023-09-06 12:24:26,000 MainThread INFO: EPOCH:1
2023-09-06 12:24:26,000 MainThread INFO: Time Consumed:5.524352788925171s
2023-09-06 12:24:26,000 MainThread INFO: Total Frames:3000s
  1%|          | 2/200 [00:15<25:00,  7.58s/it]------------------------------------  ----------  --------  ---------  ---------
Name                                  Value
Running_Average_Rewards               343.13622
Train_Epoch_Reward                    5281.02364
Running_Training_Average_Rewards      448.08289
Explore_Time                          0.00465
Train___Time                          4.89942
Eval____Time                          0.00547
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.43094
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.42746
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.76723
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.59015
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.21582
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -29.57356
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.05872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3716.49324
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.59702
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.40969
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           3.29581     0.28180   4.41861    2.76521
alpha_0                               0.97795     0.00387   0.98481    0.97158
alpha_1                               0.97763     0.00420   0.98481    0.97052
alpha_2                               0.97763     0.00421   0.98481    0.97051
alpha_3                               0.97763     0.00420   0.98481    0.97052
alpha_4                               0.97763     0.00420   0.98480    0.97052
alpha_5                               0.97761     0.00422   0.98480    0.97047
alpha_6                               0.97762     0.00421   0.98480    0.97050
alpha_7                               0.97763     0.00421   0.98481    0.97051
alpha_8                               0.97764     0.00421   0.98481    0.97051
alpha_9                               0.97763     0.00421   0.98481    0.97049
Alpha_loss                            -0.14671    0.02717   -0.10095   -0.19449
Training/policy_loss                  -9.84127    1.32118   -7.43402   -11.91797
Training/qf1_loss                     111.74114   34.30136  248.02318  69.50995
Training/qf2_loss                     112.75820   33.77877  247.26585  69.97109
Training/pf_norm                      0.39167     0.11533   0.75173    0.22698
Training/qf1_norm                     113.15027   71.84611  262.28183  7.42304
Training/qf2_norm                     108.07394   68.13995  255.62251  7.31145
log_std/mean                          -0.14387    0.01183   -0.11803   -0.16190
log_std/std                           0.03815     0.01843   0.06247    0.00863
log_std/max                           -0.11017    0.01429   -0.07824   -0.12570
log_std/min                           -0.30104    0.08643   -0.15933   -0.39338
log_probs/mean                        -2.58693    0.09516   -2.40089   -2.72902
log_probs/std                         0.59559     0.20269   0.95100    0.26532
log_probs/max                         0.33953     1.47910   2.52864    -1.96150
log_probs/min                         -5.49431    0.81684   -4.01061   -7.95351
mean/mean                             -0.11722    0.03856   -0.04326   -0.18423
mean/std                              0.17782     0.07528   0.28536    0.04722
mean/max                              0.32826     0.18800   0.58702    0.06408
mean/min                              -0.64804    0.34749   -0.09777   -0.99565
------------------------------------  ----------  --------  ---------  ---------
sample: [8, 9, 1, 7, 3, 4, 0, 5, 2, 6]
replay_buffer._size: [600 600 600 600 600 600 600 600 600 600]
diff1,diff2 5.209552526473999 0.00021958351135253906
train_time 5.209882974624634
snapshot at best
2023-09-06 12:24:31,898 MainThread INFO: EPOCH:2
2023-09-06 12:24:31,898 MainThread INFO: Time Consumed:5.783339023590088s
2023-09-06 12:24:31,898 MainThread INFO: Total Frames:4500s
  2%|â–         | 3/200 [00:21<22:20,  6.80s/it]------------------------------------  ----------  --------  ---------  --------
Name                                  Value
Running_Average_Rewards               343.43344
Train_Epoch_Reward                    9288.96770
Running_Training_Average_Rewards      608.35418
Explore_Time                          0.00463
Train___Time                          5.20988
Eval____Time                          0.00506
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.57484
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.42746
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -11.76723
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.59015
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -23.21582
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -29.57356
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.05872
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 3716.49324
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.59702
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.40969
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std       Max        Min
Reward_Mean                           2.73431     0.26357   3.49756    2.22680
alpha_0                               0.96456     0.00411   0.97132    0.95741
alpha_1                               0.96313     0.00418   0.97023    0.95605
alpha_2                               0.96312     0.00418   0.97022    0.95604
alpha_3                               0.96313     0.00418   0.97023    0.95605
alpha_4                               0.96314     0.00418   0.97023    0.95605
alpha_5                               0.96309     0.00418   0.97018    0.95601
alpha_6                               0.96310     0.00418   0.97021    0.95602
alpha_7                               0.96314     0.00417   0.97022    0.95606
alpha_8                               0.96313     0.00418   0.97022    0.95605
alpha_9                               0.96310     0.00418   0.97020    0.95602
Alpha_loss                            -0.24826    0.03040   -0.19701   -0.29851
Training/policy_loss                  -8.28179    0.46016   -7.67361   -9.09639
Training/qf1_loss                     87.20441    6.69510   103.14056  76.65633
Training/qf2_loss                     87.23171    6.67034   102.78533  76.60156
Training/pf_norm                      0.29051     0.05213   0.45149    0.18769
Training/qf1_norm                     48.65227    34.18430  168.47527  7.98447
Training/qf2_norm                     46.40774    31.48209  152.09685  6.57933
log_std/mean                          -0.14008    0.01152   -0.12829   -0.16738
log_std/std                           0.02059     0.01021   0.04253    0.00738
log_std/max                           -0.10621    0.01344   -0.08776   -0.12846
log_std/min                           -0.21691    0.07705   -0.15670   -0.38108
log_probs/mean                        -2.67841    0.04944   -2.56922   -2.73023
log_probs/std                         0.39847     0.12535   0.64752    0.26020
log_probs/max                         -0.60742    0.83564   1.04145    -1.84907
log_probs/min                         -5.11960    0.85836   -4.01414   -9.80138
mean/mean                             -0.04498    0.05137   0.03896    -0.12330
mean/std                              0.11422     0.04521   0.19509    0.06625
mean/max                              0.10823     0.07621   0.29739    0.03055
mean/min                              -0.51335    0.26904   -0.21379   -0.95366
------------------------------------  ----------  --------  ---------  --------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [3, 2, 1, 7, 9, 0, 8, 4, 5, 6]
replay_buffer._size: [750 750 750 750 750 750 750 750 750 750]
diff1,diff2 5.247280120849609 6.794929504394531e-05
train_time 5.249736070632935
2023-09-06 12:24:39,266 MainThread INFO: EPOCH:3
2023-09-06 12:24:39,267 MainThread INFO: Time Consumed:5.260721445083618s
2023-09-06 12:24:39,267 MainThread INFO: Total Frames:6000s
  2%|â–         | 4/200 [00:29<22:57,  7.03s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               230.25770
Train_Epoch_Reward                    1449.47784
Running_Training_Average_Rewards      533.98231
Explore_Time                          0.00498
Train___Time                          5.24974
Eval____Time                          0.00433
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.48357
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.95792
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -9.77711
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.99789
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -41.59678
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -61.69673
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.22861
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 417.44867
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.73409
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.94646
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.98760     0.63563    6.70732    2.80364
alpha_0                               0.95051     0.00356    0.95710    0.94518
alpha_1                               0.94876     0.00411    0.95576    0.94181
alpha_2                               0.94877     0.00409    0.95576    0.94186
alpha_3                               0.94877     0.00410    0.95576    0.94183
alpha_4                               0.94878     0.00409    0.95577    0.94188
alpha_5                               0.94875     0.00409    0.95573    0.94185
alpha_6                               0.94876     0.00409    0.95573    0.94185
alpha_7                               0.94879     0.00410    0.95577    0.94186
alpha_8                               0.94877     0.00410    0.95576    0.94182
alpha_9                               0.94876     0.00409    0.95574    0.94186
Alpha_loss                            -0.33723    0.01965    -0.30100   -0.37296
Training/policy_loss                  -11.50364   1.61452    -9.03186   -13.82872
Training/qf1_loss                     447.98203   112.67668  827.53741  75.94290
Training/qf2_loss                     449.12376   112.92614  829.99707  76.07384
Training/pf_norm                      0.41505     0.11762    0.81527    0.27331
Training/qf1_norm                     260.41539   186.13593  797.76044  21.22432
Training/qf2_norm                     257.54987   182.94459  787.05872  19.74404
log_std/mean                          -0.15804    0.01436    -0.13796   -0.18607
log_std/std                           0.04860     0.02451    0.08881    0.00629
log_std/max                           -0.11914    0.01104    -0.10473   -0.13803
log_std/min                           -0.35557    0.11058    -0.15963   -0.50903
log_probs/mean                        -2.47610    0.16326    -2.15462   -2.71674
log_probs/std                         0.87863     0.36512    1.57588    0.32529
log_probs/max                         2.23407     2.03739    5.05743    -1.74053
log_probs/min                         -5.79896    1.02433    -4.49437   -8.77324
mean/mean                             0.12004     0.04480    0.17633    0.04168
mean/std                              0.25906     0.09155    0.38671    0.08963
mean/max                              0.92598     0.39660    1.37772    0.21708
mean/min                              -0.79006    0.23670    -0.32111   -1.18998
------------------------------------  ----------  ---------  ---------  ---------
sample: [6, 5, 4, 7, 0, 1, 8, 2, 9, 3]
replay_buffer._size: [900 900 900 900 900 900 900 900 900 900]
diff1,diff2 5.186906576156616 7.62939453125e-05
train_time 5.187469482421875
snapshot at best
2023-09-06 12:24:45,529 MainThread INFO: EPOCH:4
2023-09-06 12:24:45,530 MainThread INFO: Time Consumed:6.091018199920654s
2023-09-06 12:24:45,530 MainThread INFO: Total Frames:7500s
  2%|â–Ž         | 5/200 [00:35<21:57,  6.76s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               445.07921
Train_Epoch_Reward                    585.62981
Running_Training_Average_Rewards      377.46918
Explore_Time                          0.01601
Train___Time                          5.18747
Eval____Time                          0.00502
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -36.04975
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.14059
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -33.26890
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.92143
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.45765
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -32.16166
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.48125
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10158.69874
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.31651
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.83304
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.25510      0.73817    6.66801     3.57280
alpha_0                               0.94256      0.00114    0.94502     0.94105
alpha_1                               0.93471      0.00400    0.94153     0.92793
alpha_2                               0.93479      0.00398    0.94158     0.92804
alpha_3                               0.93472      0.00401    0.94155     0.92793
alpha_4                               0.93481      0.00398    0.94160     0.92807
alpha_5                               0.93482      0.00396    0.94157     0.92811
alpha_6                               0.93479      0.00398    0.94157     0.92805
alpha_7                               0.93478      0.00399    0.94158     0.92801
alpha_8                               0.93472      0.00400    0.94154     0.92795
alpha_9                               0.93480      0.00398    0.94158     0.92806
Alpha_loss                            -0.40497     0.02262    -0.37221    -0.45467
Training/policy_loss                  -12.60464    0.80380    -10.43716   -13.56955
Training/qf1_loss                     625.95903    148.94164  1033.95410  342.67642
Training/qf2_loss                     626.28900    149.30397  1034.73010  341.86240
Training/pf_norm                      0.64573      0.17090    1.04410     0.32018
Training/qf1_norm                     281.64429    182.90041  646.99548   30.78269
Training/qf2_norm                     274.83590    177.25597  627.46039   30.91566
log_std/mean                          -0.18584     0.00540    -0.17233    -0.19750
log_std/std                           0.10630      0.01100    0.12407     0.08460
log_std/max                           -0.12343     0.00499    -0.10694    -0.13398
log_std/min                           -0.56447     0.03786    -0.48724    -0.62968
log_probs/mean                        -2.04502     0.08945    -1.91819    -2.31420
log_probs/std                         1.85423      0.18703    2.11765     1.34399
log_probs/max                         6.58362      0.68687    7.61991     4.33006
log_probs/min                         -6.14106     1.16178    -4.59689    -9.32711
mean/mean                             0.19991      0.01301    0.21906     0.16194
mean/std                              0.45580      0.03192    0.49408     0.35884
mean/max                              1.59276      0.09418    1.73495     1.29842
mean/min                              -1.38505     0.09506    -1.11722    -1.50988
------------------------------------  -----------  ---------  ----------  ---------
sample: [6, 7, 1, 9, 8, 4, 3, 0, 5, 2]
replay_buffer._size: [1050 1050 1050 1050 1050 1050 1050 1050 1050 1050]
diff1,diff2 4.792577266693115 6.699562072753906e-05
train_time 4.792711973190308
2023-09-06 12:24:50,449 MainThread INFO: EPOCH:5
2023-09-06 12:24:50,449 MainThread INFO: Time Consumed:4.801858425140381s
2023-09-06 12:24:50,449 MainThread INFO: Total Frames:9000s
  3%|â–Ž         | 6/200 [00:40<19:48,  6.13s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               551.96080
Train_Epoch_Reward                    26053.66409
Running_Training_Average_Rewards      936.29239
Explore_Time                          0.00493
Train___Time                          4.79271
Eval____Time                          0.00351
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.71507
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.30792
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -52.91989
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.76540
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.05755
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.50216
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -51.60611
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7083.08000
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.19520
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.28415
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.26402      0.73397    6.95713     3.80134
alpha_0                               0.93942      0.00113    0.94100     0.93727
alpha_1                               0.92087      0.00399    0.92765     0.91410
alpha_2                               0.92101      0.00398    0.92777     0.91426
alpha_3                               0.92089      0.00399    0.92766     0.91413
alpha_4                               0.92104      0.00398    0.92780     0.91428
alpha_5                               0.92108      0.00398    0.92784     0.91432
alpha_6                               0.92101      0.00399    0.92777     0.91424
alpha_7                               0.92097      0.00399    0.92774     0.91421
alpha_8                               0.92091      0.00398    0.92767     0.91415
alpha_9                               0.92105      0.00397    0.92778     0.91430
Alpha_loss                            -0.50248     0.02952    -0.45378    -0.54852
Training/policy_loss                  -13.34328    0.64799    -12.26428   -14.16821
Training/qf1_loss                     749.81488    194.35646  1259.96765  398.30515
Training/qf2_loss                     749.42633    194.53950  1260.38660  398.11148
Training/pf_norm                      0.58587      0.15561    0.94283     0.28897
Training/qf1_norm                     255.66952    169.15553  764.08899   26.60895
Training/qf2_norm                     248.77045    164.98899  741.98291   21.35133
log_std/mean                          -0.17095     0.00953    -0.15413    -0.18790
log_std/std                           0.10407      0.00694    0.11996     0.09179
log_std/max                           -0.10933     0.01646    -0.08378    -0.13520
log_std/min                           -0.56681     0.02088    -0.52121    -0.59937
log_probs/mean                        -2.16102     0.06950    -1.99575    -2.28430
log_probs/std                         1.74080      0.14093    2.16370     1.51564
log_probs/max                         6.24082      0.48510    7.59212     5.40691
log_probs/min                         -5.46529     1.17447    -4.01131    -9.47564
mean/mean                             0.14034      0.03019    0.18809     0.09674
mean/std                              0.42882      0.01747    0.47183     0.40359
mean/max                              1.64835      0.04480    1.71920     1.57396
mean/min                              -1.29338     0.06625    -1.21015    -1.45140
------------------------------------  -----------  ---------  ----------  ---------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [4, 3, 1, 5, 9, 8, 6, 2, 7, 0]
replay_buffer._size: [1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]
diff1,diff2 4.728179454803467 6.914138793945312e-05
train_time 4.729734182357788
2023-09-06 12:24:58,507 MainThread INFO: EPOCH:6
2023-09-06 12:24:58,507 MainThread INFO: Time Consumed:4.738974332809448s
2023-09-06 12:24:58,507 MainThread INFO: Total Frames:10500s
  4%|â–Ž         | 7/200 [00:48<21:44,  6.76s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               781.26819
Train_Epoch_Reward                    8997.50767
Running_Training_Average_Rewards      1187.89339
Explore_Time                          0.00361
Train___Time                          4.72973
Eval____Time                          0.00491
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.17944
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.24494
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -50.78443
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.29999
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.20172
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.90882
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -50.51746
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7355.65407
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.54688
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.71910
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.15203     0.81619    7.25924     3.52930
alpha_0                               0.93471     0.00155    0.93717     0.93169
alpha_1                               0.90712     0.00394    0.91382     0.90045
alpha_2                               0.90728     0.00394    0.91399     0.90060
alpha_3                               0.90715     0.00394    0.91385     0.90047
alpha_4                               0.90731     0.00394    0.91401     0.90064
alpha_5                               0.90735     0.00393    0.91405     0.90069
alpha_6                               0.90725     0.00395    0.91397     0.90057
alpha_7                               0.90723     0.00394    0.91393     0.90055
alpha_8                               0.90718     0.00394    0.91388     0.90051
alpha_9                               0.90732     0.00394    0.91403     0.90065
Alpha_loss                            -0.59841    0.03026    -0.54744    -0.65217
Training/policy_loss                  -14.19679   0.26465    -13.70743   -14.64636
Training/qf1_loss                     749.75587   237.00596  1355.76428  395.75018
Training/qf2_loss                     749.35525   236.95846  1355.62976  395.59360
Training/pf_norm                      0.55259     0.14035    1.02303     0.38209
Training/qf1_norm                     304.27670   235.57228  882.49597   32.40369
Training/qf2_norm                     296.78350   229.15722  861.82635   32.97839
log_std/mean                          -0.17077    0.00860    -0.15512    -0.18269
log_std/std                           0.09670     0.00494    0.10424     0.08367
log_std/max                           -0.12236    0.00738    -0.11256    -0.13849
log_std/min                           -0.56032    0.02704    -0.52570    -0.63157
log_probs/mean                        -2.22595    0.06074    -2.11891    -2.35111
log_probs/std                         1.59067     0.16747    1.87140     1.26931
log_probs/max                         5.51366     0.77265    6.77562     3.63562
log_probs/min                         -6.01024    1.51354    -4.01394    -11.23084
mean/mean                             0.05708     0.03135    0.09400     -0.00728
mean/std                              0.41925     0.02117    0.45724     0.37722
mean/max                              1.68141     0.05801    1.78718     1.57157
mean/min                              -1.28581    0.06602    -1.14625    -1.43343
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 7, 3, 1, 8, 5, 9, 4, 2, 6]
replay_buffer._size: [1350 1350 1350 1350 1350 1350 1350 1350 1350 1350]
diff1,diff2 5.230168581008911 5.030632019042969e-05
train_time 5.230286598205566
2023-09-06 12:25:03,965 MainThread INFO: EPOCH:7
2023-09-06 12:25:03,965 MainThread INFO: Time Consumed:5.2394349575042725s
2023-09-06 12:25:03,965 MainThread INFO: Total Frames:12000s
  4%|â–         | 8/200 [00:53<20:19,  6.35s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               644.47211
Train_Epoch_Reward                    8526.76266
Running_Training_Average_Rewards      1452.59781
Explore_Time                          0.00458
Train___Time                          5.23029
Eval____Time                          0.00384
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.34710
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.95175
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -40.49723
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.28560
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.23151
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -59.25380
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.87428
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6207.08654
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.31581
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.14390
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.56122     0.76169    6.21300     3.22861
alpha_0                               0.92668     0.00308    0.93153     0.92113
alpha_1                               0.89359     0.00387    0.90018     0.88705
alpha_2                               0.89371     0.00389    0.90033     0.88713
alpha_3                               0.89360     0.00388    0.90020     0.88704
alpha_4                               0.89377     0.00388    0.90037     0.88719
alpha_5                               0.89382     0.00388    0.90042     0.88725
alpha_6                               0.89368     0.00389    0.90030     0.88709
alpha_7                               0.89368     0.00387    0.90028     0.88712
alpha_8                               0.89365     0.00387    0.90024     0.88709
alpha_9                               0.89377     0.00388    0.90038     0.88719
Alpha_loss                            -0.70255    0.02993    -0.65003    -0.75292
Training/policy_loss                  -14.53849   0.70587    -13.36224   -15.74505
Training/qf1_loss                     675.32178   211.94898  1281.05493  353.85324
Training/qf2_loss                     674.97505   211.81374  1280.19263  353.51285
Training/pf_norm                      0.39158     0.07563    0.57618     0.25713
Training/qf1_norm                     304.47904   195.67647  773.27539   35.33042
Training/qf2_norm                     297.14830   190.74436  753.71185   36.50181
log_std/mean                          -0.16601    0.00591    -0.15908    -0.17979
log_std/std                           0.07783     0.00755    0.09231     0.06727
log_std/max                           -0.11907    0.00598    -0.10948    -0.13015
log_std/min                           -0.55673    0.03728    -0.51255    -0.63439
log_probs/mean                        -2.38233    0.04245    -2.29280    -2.45399
log_probs/std                         1.15051     0.11028    1.38078     0.96543
log_probs/max                         3.65778     0.41322    4.48566     2.88843
log_probs/min                         -6.11457    1.43152    -4.38637    -10.55616
mean/mean                             -0.02857    0.01277    -0.00927    -0.04456
mean/std                              0.35140     0.01917    0.38558     0.32405
mean/max                              1.52919     0.06908    1.65858     1.42501
mean/min                              -0.98364    0.09273    -0.78033    -1.13851
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 6, 7, 8, 3, 5, 2, 9, 4, 0]
replay_buffer._size: [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]
diff1,diff2 5.448954343795776 3.8623809814453125e-05
train_time 5.449073314666748
2023-09-06 12:25:09,580 MainThread INFO: EPOCH:8
2023-09-06 12:25:09,580 MainThread INFO: Time Consumed:5.465929269790649s
2023-09-06 12:25:09,580 MainThread INFO: Total Frames:13500s
  4%|â–         | 9/200 [00:59<19:27,  6.11s/it]------------------------------------  ----------  ---------  ---------  ---------
Name                                  Value
Running_Average_Rewards               474.99177
Train_Epoch_Reward                    4733.57694
Running_Training_Average_Rewards      741.92824
Explore_Time                          0.01173
Train___Time                          5.44907
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.08539
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.78070
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -22.91416
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.12280
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.46379
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -30.75981
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.75970
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1930.86273
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -41.97099
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.68901
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max        Min
Reward_Mean                           4.30823     0.64369    6.02147    3.05384
alpha_0                               0.91374     0.00437    0.92087    0.90617
alpha_1                               0.88034     0.00379    0.88679    0.87392
alpha_2                               0.88037     0.00382    0.88686    0.87391
alpha_3                               0.88030     0.00380    0.88677    0.87387
alpha_4                               0.88043     0.00381    0.88692    0.87397
alpha_5                               0.88048     0.00382    0.88698    0.87401
alpha_6                               0.88033     0.00382    0.88682    0.87387
alpha_7                               0.88038     0.00381    0.88686    0.87394
alpha_8                               0.88035     0.00381    0.88682    0.87390
alpha_9                               0.88042     0.00382    0.88693    0.87396
Alpha_loss                            -0.80848    0.02895    -0.75877   -0.85322
Training/policy_loss                  -15.31804   0.63858    -14.24130  -16.36806
Training/qf1_loss                     619.15700   156.16397  982.56897  246.80269
Training/qf2_loss                     618.67089   155.96504  981.34833  246.21190
Training/pf_norm                      0.47046     0.08069    0.61140    0.30656
Training/qf1_norm                     244.48166   165.81242  683.15253  28.09089
Training/qf2_norm                     239.36586   160.81599  653.26660  27.09805
log_std/mean                          -0.15864    0.00912    -0.13785   -0.17033
log_std/std                           0.05738     0.00205    0.06414    0.05369
log_std/max                           -0.10854    0.01290    -0.08305   -0.12564
log_std/min                           -0.49226    0.01349    -0.46019   -0.53457
log_probs/mean                        -2.50768    0.02901    -2.45297   -2.56580
log_probs/std                         0.77794     0.05527    0.91977    0.66610
log_probs/max                         1.57625     0.47698    2.82667    0.76469
log_probs/min                         -5.98116    0.77810    -4.61895   -8.26188
mean/mean                             -0.03823    0.01306    -0.02076   -0.06276
mean/std                              0.28138     0.01450    0.31558    0.25968
mean/max                              1.28999     0.06202    1.46157    1.21008
mean/min                              -0.63834    0.09854    -0.43088   -0.75451
------------------------------------  ----------  ---------  ---------  ---------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [4, 3, 8, 9, 0, 6, 5, 7, 2, 1]
replay_buffer._size: [1650 1650 1650 1650 1650 1650 1650 1650 1650 1650]
diff1,diff2 4.9678544998168945 5.030632019042969e-05
train_time 4.96934700012207
2023-09-06 12:25:18,687 MainThread INFO: EPOCH:9
2023-09-06 12:25:18,688 MainThread INFO: Time Consumed:4.979623556137085s
2023-09-06 12:25:18,688 MainThread INFO: Total Frames:15000s
  5%|â–Œ         | 10/200 [01:08<22:17,  7.04s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               270.14323
Train_Epoch_Reward                    2460.42480
Running_Training_Average_Rewards      524.02548
Explore_Time                          0.00488
Train___Time                          4.96935
Eval____Time                          0.00476
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.70608
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.65385
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.07012
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.16259
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -39.75598
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.29512
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.53044
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 1116.84387
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.29268
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.58211
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.71821     0.76073    6.99292     3.50362
alpha_0                               0.89889     0.00394    0.90586     0.89248
alpha_1                               0.86731     0.00373    0.87366     0.86099
alpha_2                               0.86729     0.00374    0.87365     0.86095
alpha_3                               0.86725     0.00374    0.87361     0.86091
alpha_4                               0.86732     0.00375    0.87370     0.86096
alpha_5                               0.86735     0.00376    0.87374     0.86099
alpha_6                               0.86724     0.00374    0.87361     0.86089
alpha_7                               0.86730     0.00375    0.87367     0.86095
alpha_8                               0.86728     0.00374    0.87364     0.86094
alpha_9                               0.86732     0.00375    0.87369     0.86097
Alpha_loss                            -0.89793    0.02596    -0.85430    -0.93838
Training/policy_loss                  -16.82082   0.57547    -15.91232   -18.03917
Training/qf1_loss                     682.98299   184.02134  1101.88611  420.50958
Training/qf2_loss                     682.35428   183.83568  1100.76917  420.55588
Training/pf_norm                      0.45204     0.12633    0.94855     0.22767
Training/qf1_norm                     312.80911   217.82284  994.24298   24.33917
Training/qf2_norm                     304.52780   211.27299  963.91473   24.13494
log_std/mean                          -0.15486    0.00553    -0.14586    -0.16890
log_std/std                           0.06548     0.00664    0.08187     0.05749
log_std/max                           -0.10969    0.00573    -0.09894    -0.12141
log_std/min                           -0.45622    0.04625    -0.39248    -0.56703
log_probs/mean                        -2.42963    0.03539    -2.34926    -2.49924
log_probs/std                         0.98240     0.09916    1.21620     0.80556
log_probs/max                         2.82244     0.60067    4.13881     1.72228
log_probs/min                         -5.75116    0.80896    -4.42687    -8.29532
mean/mean                             0.02185     0.03481    0.06515     -0.02258
mean/std                              0.32722     0.01498    0.35621     0.29943
mean/max                              1.25847     0.11453    1.52383     1.11683
mean/min                              -0.65483    0.09657    -0.39763    -0.75413
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 7, 5, 0, 8, 1, 6, 4, 9, 3]
replay_buffer._size: [1800 1800 1800 1800 1800 1800 1800 1800 1800 1800]
diff1,diff2 5.291764497756958 3.719329833984375e-05
train_time 5.291878700256348
2023-09-06 12:25:24,162 MainThread INFO: EPOCH:10
2023-09-06 12:25:24,163 MainThread INFO: Time Consumed:5.320505619049072s
2023-09-06 12:25:24,163 MainThread INFO: Total Frames:16500s
  6%|â–Œ         | 11/200 [01:14<20:41,  6.57s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               381.27369
Train_Epoch_Reward                    1387.64989
Running_Training_Average_Rewards      286.05505
Explore_Time                          0.02363
Train___Time                          5.29188
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.57640
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.22029
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.78695
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.73985
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -43.29368
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.49773
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.51017
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9407.41460
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -22.92036
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.76977
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           4.57855     0.66272    6.07914     3.16706
alpha_0                               0.88646     0.00345    0.89224     0.88048
alpha_1                               0.85443     0.00371    0.86073     0.84814
alpha_2                               0.85439     0.00371    0.86069     0.84810
alpha_3                               0.85435     0.00371    0.86065     0.84807
alpha_4                               0.85438     0.00372    0.86070     0.84808
alpha_5                               0.85441     0.00371    0.86073     0.84814
alpha_6                               0.85433     0.00370    0.86063     0.84806
alpha_7                               0.85438     0.00371    0.86069     0.84810
alpha_8                               0.85436     0.00371    0.86068     0.84807
alpha_9                               0.85439     0.00371    0.86071     0.84810
Alpha_loss                            -0.99626    0.03142    -0.94034    -1.05137
Training/policy_loss                  -17.94176   0.50274    -17.02766   -18.62353
Training/qf1_loss                     664.94588   186.72055  1191.68091  281.92233
Training/qf2_loss                     664.44721   186.49688  1191.22485  282.00180
Training/pf_norm                      0.43909     0.10804    0.72013     0.26123
Training/qf1_norm                     296.95327   204.18105  809.15466   22.17089
Training/qf2_norm                     289.11912   198.04257  784.95636   22.85526
log_std/mean                          -0.15868    0.00515    -0.15256    -0.16911
log_std/std                           0.06996     0.00408    0.08044     0.06457
log_std/max                           -0.12136    0.00412    -0.11229    -0.12783
log_std/min                           -0.51935    0.02204    -0.46213    -0.55475
log_probs/mean                        -2.43685    0.03403    -2.34784    -2.50754
log_probs/std                         1.01759     0.07022    1.21924     0.85518
log_probs/max                         3.08471     0.45008    4.37426     2.25274
log_probs/min                         -5.92220    0.86353    -4.81850    -8.51850
mean/mean                             0.03354     0.02527    0.06402     -0.01803
mean/std                              0.32325     0.01280    0.35465     0.30429
mean/max                              1.46117     0.03698    1.52663     1.39905
mean/min                              -0.62863    0.07441    -0.46439    -0.71812
------------------------------------  ----------  ---------  ----------  ---------
sample: [5, 0, 3, 4, 6, 7, 9, 1, 2, 8]
replay_buffer._size: [1950 1950 1950 1950 1950 1950 1950 1950 1950 1950]
diff1,diff2 5.601124286651611 7.05718994140625e-05
train_time 5.601274251937866
2023-09-06 12:25:29,932 MainThread INFO: EPOCH:11
2023-09-06 12:25:29,933 MainThread INFO: Time Consumed:5.616426467895508s
2023-09-06 12:25:29,933 MainThread INFO: Total Frames:18000s
  6%|â–Œ         | 12/200 [01:19<19:47,  6.32s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               397.78473
Train_Epoch_Reward                    11360.27210
Running_Training_Average_Rewards      506.94489
Explore_Time                          0.01086
Train___Time                          5.60127
Eval____Time                          0.00372
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.04400
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.59351
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.17471
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.66688
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.70721
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.80908
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.99322
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 2353.08166
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -20.81514
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.63026
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.10645      0.82649    6.78907     3.14790
alpha_0                               0.87423      0.00331    0.88022     0.86924
alpha_1                               0.84166      0.00366    0.84789     0.83547
alpha_2                               0.84161      0.00367    0.84785     0.83540
alpha_3                               0.84160      0.00365    0.84782     0.83541
alpha_4                               0.84160      0.00366    0.84783     0.83540
alpha_5                               0.84166      0.00366    0.84788     0.83546
alpha_6                               0.84157      0.00366    0.84780     0.83538
alpha_7                               0.84162      0.00365    0.84784     0.83543
alpha_8                               0.84158      0.00366    0.84781     0.83538
alpha_9                               0.84161      0.00366    0.84784     0.83541
Alpha_loss                            -1.08501     0.01698    -1.04893    -1.11494
Training/policy_loss                  -20.13630    0.74975    -18.27818   -21.33213
Training/qf1_loss                     1047.03471   391.12933  2184.28784  438.44962
Training/qf2_loss                     1046.10026   391.00465  2183.91089  438.14288
Training/pf_norm                      0.48949      0.17237    1.05803     0.27566
Training/qf1_norm                     424.44334    300.27725  1093.80444  52.40839
Training/qf2_norm                     412.68076    290.55827  1067.23511  51.76028
log_std/mean                          -0.15908     0.00751    -0.15073    -0.17522
log_std/std                           0.07901      0.01337    0.10344     0.05770
log_std/max                           -0.11325     0.00513    -0.10535    -0.12445
log_std/min                           -0.55843     0.04242    -0.48003    -0.62227
log_probs/mean                        -2.38067     0.08994    -2.19264    -2.51643
log_probs/std                         1.19670      0.25409    1.67118     0.83045
log_probs/max                         3.99610      1.24783    6.17000     2.11285
log_probs/min                         -6.17849     1.25417    -4.12381    -10.59800
mean/mean                             -0.02709     0.00895    -0.01465    -0.04320
mean/std                              0.35366      0.04632    0.43333     0.29048
mean/max                              1.62485      0.14269    1.86251     1.37169
mean/min                              -0.94995     0.21268    -0.52357    -1.36118
------------------------------------  -----------  ---------  ----------  ---------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [5, 4, 3, 2, 6, 9, 7, 8, 0, 1]
replay_buffer._size: [2100 2100 2100 2100 2100 2100 2100 2100 2100 2100]
diff1,diff2 5.001540899276733 6.580352783203125e-05
train_time 5.003169775009155
snapshot at best
2023-09-06 12:25:39,852 MainThread INFO: EPOCH:12
2023-09-06 12:25:39,853 MainThread INFO: Time Consumed:5.899093151092529s
2023-09-06 12:25:39,853 MainThread INFO: Total Frames:19500s
  6%|â–‹         | 13/200 [01:29<23:06,  7.41s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               799.56688
Train_Epoch_Reward                    2384.50091
Running_Training_Average_Rewards      504.41410
Explore_Time                          0.00397
Train___Time                          5.00317
Eval____Time                          0.00402
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.08417
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -52.28154
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.56235
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.01435
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -34.12508
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -52.66240
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.92186
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13144.92166
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.06835
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -24.94230
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.25899      0.77097    6.95797     3.20883
alpha_0                               0.86632      0.00151    0.86909     0.86392
alpha_1                               0.82909      0.00360    0.83521     0.82300
alpha_2                               0.82903      0.00360    0.83515     0.82293
alpha_3                               0.82905      0.00359    0.83516     0.82296
alpha_4                               0.82902      0.00360    0.83515     0.82291
alpha_5                               0.82913      0.00357    0.83521     0.82306
alpha_6                               0.82903      0.00358    0.83513     0.82295
alpha_7                               0.82904      0.00360    0.83517     0.82294
alpha_8                               0.82901      0.00360    0.83513     0.82291
alpha_9                               0.82904      0.00360    0.83516     0.82294
Alpha_loss                            -1.14972     0.02724    -1.10256    -1.19369
Training/policy_loss                  -22.55056    0.99773    -20.67220   -23.98126
Training/qf1_loss                     1115.38898   334.57595  1889.58813  481.24875
Training/qf2_loss                     1114.26566   334.73910  1888.65784  480.51465
Training/pf_norm                      0.52385      0.18644    1.27706     0.26244
Training/qf1_norm                     431.08341    306.60701  1528.92004  74.88697
Training/qf2_norm                     418.67688    293.71601  1464.85498  75.13619
log_std/mean                          -0.16672     0.00971    -0.15222    -0.18455
log_std/std                           0.10480      0.00680    0.11429     0.08944
log_std/max                           -0.10158     0.01454    -0.08289    -0.12710
log_std/min                           -0.60798     0.02426    -0.55438    -0.65476
log_probs/mean                        -2.17792     0.03831    -2.09544    -2.27863
log_probs/std                         1.72103      0.09043    1.94235     1.45216
log_probs/max                         6.10820      0.30715    6.69363     5.14915
log_probs/min                         -5.70630     1.43664    -4.12153    -11.03019
mean/mean                             0.01099      0.00846    0.02278     -0.00622
mean/std                              0.45031      0.01130    0.47092     0.43033
mean/max                              1.88596      0.07944    2.03707     1.70961
mean/min                              -1.50547     0.07882    -1.35894    -1.63089
------------------------------------  -----------  ---------  ----------  ---------
sample: [8, 6, 7, 4, 2, 5, 1, 0, 3, 9]
replay_buffer._size: [2250 2250 2250 2250 2250 2250 2250 2250 2250 2250]
diff1,diff2 4.818902254104614 6.67572021484375e-05
train_time 4.819067478179932
2023-09-06 12:25:44,804 MainThread INFO: EPOCH:13
2023-09-06 12:25:44,804 MainThread INFO: Time Consumed:4.828780889511108s
2023-09-06 12:25:44,804 MainThread INFO: Total Frames:21000s
  7%|â–‹         | 14/200 [01:34<20:39,  6.67s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               835.85483
Train_Epoch_Reward                    21154.28232
Running_Training_Average_Rewards      1163.30184
Explore_Time                          0.00451
Train___Time                          4.81907
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -29.13670
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.52884
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -41.01190
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.51101
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.78041
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.18857
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.96246
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10481.69279
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.45342
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.38159
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.47112      1.00511    7.27922     3.53969
alpha_0                               0.86241      0.00063    0.86384     0.86178
alpha_1                               0.81671      0.00355    0.82275     0.81071
alpha_2                               0.81664      0.00355    0.82268     0.81063
alpha_3                               0.81668      0.00354    0.82271     0.81070
alpha_4                               0.81662      0.00355    0.82266     0.81062
alpha_5                               0.81677      0.00355    0.82281     0.81077
alpha_6                               0.81667      0.00355    0.82270     0.81066
alpha_7                               0.81666      0.00355    0.82270     0.81065
alpha_8                               0.81662      0.00355    0.82266     0.81061
alpha_9                               0.81665      0.00355    0.82269     0.81064
Alpha_loss                            -1.22508     0.01661    -1.19257    -1.25923
Training/policy_loss                  -24.57691    0.86828    -22.89019   -26.01334
Training/qf1_loss                     1268.40424   482.47487  2483.48560  583.04865
Training/qf2_loss                     1266.73148   481.92796  2480.16968  582.01923
Training/pf_norm                      0.57014      0.19115    1.29934     0.28785
Training/qf1_norm                     610.20891    377.84944  1380.28296  68.45245
Training/qf2_norm                     592.71184    365.68370  1346.15808  71.38204
log_std/mean                          -0.17535     0.00875    -0.15980    -0.18879
log_std/std                           0.11124      0.00818    0.12706     0.09599
log_std/max                           -0.12096     0.01153    -0.09694    -0.13810
log_std/min                           -0.61722     0.02644    -0.56626    -0.65997
log_probs/mean                        -2.06792     0.07662    -1.93220    -2.21385
log_probs/std                         2.04986      0.19624    2.39459     1.68629
log_probs/max                         7.31108      0.77259    8.70434     5.80681
log_probs/min                         -5.15357     0.69510    -4.25515    -7.85399
mean/mean                             -0.02200     0.00850    -0.00627    -0.03401
mean/std                              0.49817      0.02946    0.54903     0.44439
mean/max                              2.03311      0.05581    2.13161     1.92405
mean/min                              -1.77433     0.09844    -1.57789    -1.95555
------------------------------------  -----------  ---------  ----------  ---------
sample: [1, 9, 4, 6, 8, 7, 5, 0, 3, 2]
replay_buffer._size: [2400 2400 2400 2400 2400 2400 2400 2400 2400 2400]
diff1,diff2 5.433767080307007 3.695487976074219e-05
train_time 5.433877468109131
2023-09-06 12:25:50,391 MainThread INFO: EPOCH:14
2023-09-06 12:25:50,392 MainThread INFO: Time Consumed:5.443774938583374s
2023-09-06 12:25:50,392 MainThread INFO: Total Frames:22500s
  8%|â–Š         | 15/200 [01:40<19:34,  6.35s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1166.23195
Train_Epoch_Reward                    10275.05298
Running_Training_Average_Rewards      1127.12787
Explore_Time                          0.00521
Train___Time                          5.43388
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.74241
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.63717
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -25.36307
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -16.75170
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -29.14701
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -50.96127
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.87654
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12240.19323
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.90825
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -18.84454
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.56117      0.94557    7.50376     3.72704
alpha_0                               0.86304      0.00078    0.86453     0.86190
alpha_1                               0.80452      0.00349    0.81046     0.79861
alpha_2                               0.80445      0.00349    0.81039     0.79854
alpha_3                               0.80453      0.00349    0.81045     0.79861
alpha_4                               0.80444      0.00349    0.81038     0.79853
alpha_5                               0.80464      0.00347    0.81053     0.79874
alpha_6                               0.80449      0.00349    0.81042     0.79858
alpha_7                               0.80446      0.00349    0.81040     0.79854
alpha_8                               0.80443      0.00349    0.81037     0.79851
alpha_9                               0.80445      0.00349    0.81039     0.79853
Alpha_loss                            -1.29614     0.02847    -1.24560    -1.34252
Training/policy_loss                  -26.98032    0.57894    -25.94188   -28.63972
Training/qf1_loss                     1300.47186   415.95620  2237.01758  552.79108
Training/qf2_loss                     1298.24237   415.46574  2233.76611  551.43353
Training/pf_norm                      0.67337      0.20738    1.18292     0.37147
Training/qf1_norm                     567.22814    365.58850  1556.95227  78.61597
Training/qf2_norm                     551.29509    353.01491  1511.10767  80.35777
log_std/mean                          -0.17435     0.00949    -0.15792    -0.19009
log_std/std                           0.12536      0.00843    0.14462     0.11060
log_std/max                           -0.11026     0.01757    -0.08203    -0.13143
log_std/min                           -0.64139     0.02954    -0.57914    -0.70682
log_probs/mean                        -1.93515     0.04459    -1.85089    -2.02418
log_probs/std                         2.43207      0.10904    2.66950     2.22197
log_probs/max                         8.74250      0.37227    9.55050     7.80828
log_probs/min                         -5.13781     0.85657    -4.06247    -8.97204
mean/mean                             -0.01643     0.01807    0.00910     -0.04322
mean/std                              0.55072      0.01298    0.57407     0.52499
mean/max                              2.11288      0.04959    2.20010     1.99740
mean/min                              -1.96253     0.07069    -1.82009    -2.06712
------------------------------------  -----------  ---------  ----------  ---------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [5, 4, 8, 3, 1, 2, 9, 6, 0, 7]
replay_buffer._size: [2550 2550 2550 2550 2550 2550 2550 2550 2550 2550]
diff1,diff2 4.980623006820679 3.9577484130859375e-05
train_time 4.98218846321106
2023-09-06 12:25:59,667 MainThread INFO: EPOCH:15
2023-09-06 12:25:59,667 MainThread INFO: Time Consumed:4.992427349090576s
2023-09-06 12:25:59,667 MainThread INFO: Total Frames:24000s
  8%|â–Š         | 16/200 [01:49<22:09,  7.22s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               1021.31014
Train_Epoch_Reward                    13189.82379
Running_Training_Average_Rewards      1487.30530
Explore_Time                          0.00396
Train___Time                          4.98219
Eval____Time                          0.00537
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.49825
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -51.16676
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.39950
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.42173
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.01593
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -34.00586
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.79512
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8806.44824
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -36.27808
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.26180
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.64559      0.94123    7.60269     3.64012
alpha_0                               0.86753      0.00189    0.87083     0.86461
alpha_1                               0.79250      0.00345    0.79837     0.78666
alpha_2                               0.79243      0.00344    0.79830     0.78661
alpha_3                               0.79251      0.00344    0.79837     0.78669
alpha_4                               0.79243      0.00344    0.79829     0.78660
alpha_5                               0.79267      0.00342    0.79850     0.78689
alpha_6                               0.79247      0.00345    0.79834     0.78664
alpha_7                               0.79243      0.00344    0.79829     0.78660
alpha_8                               0.79241      0.00344    0.79827     0.78658
alpha_9                               0.79243      0.00344    0.79829     0.78660
Alpha_loss                            -1.37424     0.02563    -1.33306    -1.42358
Training/policy_loss                  -29.37955    0.75256    -27.97423   -30.52836
Training/qf1_loss                     1432.25440   421.15933  2488.98608  502.03146
Training/qf2_loss                     1429.48276   420.50704  2483.47705  500.21964
Training/pf_norm                      0.70682      0.17738    1.23439     0.41890
Training/qf1_norm                     655.22184    484.58125  2272.15576  95.69162
Training/qf2_norm                     638.07916    465.90819  2208.49829  87.33618
log_std/mean                          -0.17598     0.00813    -0.14985    -0.18561
log_std/std                           0.14311      0.00549    0.15151     0.12814
log_std/max                           -0.10491     0.01236    -0.07411    -0.12553
log_std/min                           -0.69488     0.03169    -0.63456    -0.77411
log_probs/mean                        -1.84109     0.03764    -1.76359    -1.93428
log_probs/std                         2.71775      0.09831    2.93136     2.47790
log_probs/max                         9.72039      0.32114    10.37974    8.88380
log_probs/min                         -4.99501     0.67016    -4.08102    -7.51979
mean/mean                             0.02250      0.01306    0.03953     -0.01312
mean/std                              0.58541      0.00946    0.60262     0.56811
mean/max                              2.18285      0.04641    2.27685     2.09052
mean/min                              -2.09785     0.03191    -2.04374    -2.16670
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 3, 5, 1, 6, 4, 9, 7, 8, 0]
replay_buffer._size: [2700 2700 2700 2700 2700 2700 2700 2700 2700 2700]
diff1,diff2 5.332718133926392 5.054473876953125e-05
train_time 5.332852125167847
2023-09-06 12:26:05,216 MainThread INFO: EPOCH:16
2023-09-06 12:26:05,218 MainThread INFO: Time Consumed:5.356963396072388s
2023-09-06 12:26:05,218 MainThread INFO: Total Frames:25500s
  8%|â–Š         | 17/200 [01:55<20:30,  6.72s/it]------------------------------------  -----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               956.96250
Train_Epoch_Reward                    10559.89047
Running_Training_Average_Rewards      1134.15891
Explore_Time                          0.01934
Train___Time                          5.33285
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.68199
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -53.53976
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.38486
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -34.02566
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.44531
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.78993
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.56014
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8573.71199
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -37.35748
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.61820
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std        Max         Min
Reward_Mean                           5.54461      0.94795    7.53789     3.71370
alpha_0                               0.87363      0.00140    0.87575     0.87097
alpha_1                               0.78065      0.00339    0.78643     0.77493
alpha_2                               0.78060      0.00338    0.78637     0.77488
alpha_3                               0.78069      0.00339    0.78646     0.77496
alpha_4                               0.78061      0.00338    0.78637     0.77490
alpha_5                               0.78092      0.00335    0.78665     0.77526
alpha_6                               0.78063      0.00338    0.78640     0.77491
alpha_7                               0.78061      0.00337    0.78636     0.77492
alpha_8                               0.78058      0.00338    0.78634     0.77485
alpha_9                               0.78062      0.00337    0.78637     0.77492
Alpha_loss                            -1.47015     0.02526    -1.42547    -1.52379
Training/policy_loss                  -31.07469    0.65189    -29.90698   -32.30001
Training/qf1_loss                     1303.44840   414.24982  2231.77905  400.70370
Training/qf2_loss                     1301.07722   413.41260  2227.58228  400.48871
Training/pf_norm                      0.78144      0.22962    1.44312     0.43431
Training/qf1_norm                     635.30170    393.63634  1503.60681  107.29154
Training/qf2_norm                     620.29502    381.57005  1450.05212  107.81326
log_std/mean                          -0.15723     0.02302    -0.13256    -0.19754
log_std/std                           0.13472      0.00816    0.14695     0.11874
log_std/max                           -0.07688     0.02180    -0.03349    -0.10510
log_std/min                           -0.66324     0.02572    -0.62675    -0.72469
log_probs/mean                        -1.89081     0.03607    -1.80731    -1.95942
log_probs/std                         2.49225      0.11060    2.70252     2.25709
log_probs/max                         8.72787      0.54301    9.65642     7.38118
log_probs/min                         -5.21866     1.57723    -3.83180    -13.65468
mean/mean                             0.06170      0.01931    0.08457     0.02314
mean/std                              0.56590      0.01139    0.59510     0.53888
mean/max                              2.16072      0.04758    2.26957     2.07106
mean/min                              -2.11855     0.06403    -2.02043    -2.28282
------------------------------------  -----------  ---------  ----------  ---------
sample: [2, 0, 7, 3, 8, 6, 5, 4, 9, 1]
replay_buffer._size: [2850 2850 2850 2850 2850 2850 2850 2850 2850 2850]
diff1,diff2 5.785383939743042 4.1961669921875e-05
train_time 5.785513401031494
2023-09-06 12:26:11,186 MainThread INFO: EPOCH:17
2023-09-06 12:26:11,186 MainThread INFO: Time Consumed:5.79739236831665s
2023-09-06 12:26:11,186 MainThread INFO: Total Frames:27000s
  9%|â–‰         | 18/200 [02:01<19:41,  6.49s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               823.12037
Train_Epoch_Reward                    8453.15597
Running_Training_Average_Rewards      1073.42901
Explore_Time                          0.00706
Train___Time                          5.78551
Eval____Time                          0.00415
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.99054
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.66456
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.50560
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.43658
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.71007
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -26.76819
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.62826
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8219.59291
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.42585
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.76609
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.47757     0.97874    7.33806     3.16928
alpha_0                               0.87794     0.00142    0.88069     0.87583
alpha_1                               0.76902     0.00334    0.77470     0.76336
alpha_2                               0.76898     0.00334    0.77465     0.76333
alpha_3                               0.76905     0.00334    0.77472     0.76340
alpha_4                               0.76900     0.00333    0.77467     0.76335
alpha_5                               0.76937     0.00334    0.77503     0.76371
alpha_6                               0.76901     0.00333    0.77468     0.76336
alpha_7                               0.76902     0.00334    0.77469     0.76336
alpha_8                               0.76895     0.00334    0.77462     0.76330
alpha_9                               0.76904     0.00333    0.77469     0.76340
Alpha_loss                            -1.56261    0.02219    -1.52327    -1.59828
Training/policy_loss                  -33.78228   1.30675    -31.53903   -37.23400
Training/qf1_loss                     1310.07280  402.87699  2116.58838  471.00000
Training/qf2_loss                     1307.62908  402.35742  2112.85791  469.19113
Training/pf_norm                      1.08155     0.44048    2.01457     0.39101
Training/qf1_norm                     704.97603   494.97530  2282.31641  125.18060
Training/qf2_norm                     689.53644   481.26211  2236.54883  128.83260
log_std/mean                          -0.13906    0.00834    -0.12668    -0.15863
log_std/std                           0.13830     0.00452    0.14470     0.12642
log_std/max                           -0.05507    0.01550    -0.01807    -0.07825
log_std/min                           -0.66338    0.02351    -0.62946    -0.71014
log_probs/mean                        -1.88323    0.06120    -1.71319    -2.00684
log_probs/std                         2.56376     0.16364    2.94725     2.19436
log_probs/max                         8.66307     0.72169    10.60523    7.42401
log_probs/min                         -4.89132    0.72164    -3.79872    -7.64876
mean/mean                             0.06556     0.00844    0.07695     0.04724
mean/std                              0.57850     0.02465    0.64653     0.52914
mean/max                              2.25510     0.07864    2.43880     2.09635
mean/min                              -2.25697    0.08771    -2.02990    -2.40532
------------------------------------  ----------  ---------  ----------  ---------
start to update mask
{0: deque([0.0, 0.0, 0.0], maxlen=3), 1: deque([0.0, 0.0, 0.0], maxlen=3), 2: deque([0.0, 0.0, 0.0], maxlen=3), 3: deque([0.0, 0.0, 0.0], maxlen=3), 4: deque([0.0, 0.0, 0.0], maxlen=3), 5: deque([0.0, 0.0, 0.0], maxlen=3), 6: deque([0.0, 0.0, 0.0], maxlen=3), 7: deque([0.0, 0.0, 0.0], maxlen=3), 8: deque([0.0, 0.0, 0.0], maxlen=3), 9: deque([0.0, 0.0, 0.0], maxlen=3)}
sample: [5, 0, 7, 4, 1, 6, 9, 2, 3, 8]
replay_buffer._size: [3000 3000 3000 3000 3000 3000 3000 3000 3000 3000]
diff1,diff2 4.924085855484009 1.7642974853515625e-05
train_time 4.925774097442627
2023-09-06 12:26:20,182 MainThread INFO: EPOCH:18
2023-09-06 12:26:20,182 MainThread INFO: Time Consumed:4.935243129730225s
2023-09-06 12:26:20,182 MainThread INFO: Total Frames:28500s
 10%|â–‰         | 19/200 [02:10<21:50,  7.24s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               789.62293
Train_Epoch_Reward                    8778.27509
Running_Training_Average_Rewards      926.37738
Explore_Time                          0.00416
Train___Time                          4.92577
Eval____Time                          0.00467
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.71665
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.53566
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.01055
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.39219
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.89831
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -38.07736
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.03631
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7826.18487
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -41.89559
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.94017
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.34842     0.94693    7.99798     3.64040
alpha_0                               0.88574     0.00287    0.89064     0.88086
alpha_1                               0.75756     0.00327    0.76313     0.75202
alpha_2                               0.75757     0.00325    0.76310     0.75207
alpha_3                               0.75763     0.00326    0.76318     0.75211
alpha_4                               0.75759     0.00325    0.76313     0.75210
alpha_5                               0.75796     0.00325    0.76349     0.75246
alpha_6                               0.75758     0.00327    0.76313     0.75204
alpha_7                               0.75758     0.00327    0.76313     0.75204
alpha_8                               0.75751     0.00327    0.76307     0.75198
alpha_9                               0.75763     0.00325    0.76317     0.75213
Alpha_loss                            -1.62175    0.03147    -1.56088    -1.66349
Training/policy_loss                  -36.59647   1.50944    -33.74267   -39.61163
Training/qf1_loss                     1176.35686  403.18576  2258.76245  369.31430
Training/qf2_loss                     1174.30297  402.39759  2256.48022  369.00031
Training/pf_norm                      1.53846     0.42598    2.46140     0.53619
Training/qf1_norm                     699.53560   488.35701  2585.56128  176.54063
Training/qf2_norm                     687.50583   473.77051  2536.75073  178.96838
log_std/mean                          -0.11641    0.02133    -0.10042    -0.16702
log_std/std                           0.16122     0.00794    0.17460     0.14076
log_std/max                           0.00485     0.03229    0.07225     -0.05852
log_std/min                           -0.68087    0.01754    -0.65754    -0.71740
log_probs/mean                        -1.69711    0.07346    -1.52840    -1.84988
log_probs/std                         2.93104     0.16406    3.35962     2.62650
log_probs/max                         10.30027    0.68244    11.85679    9.28137
log_probs/min                         -5.08085    0.93261    -4.05742    -9.46658
mean/mean                             0.09636     0.04176    0.18463     0.04791
mean/std                              0.63414     0.02405    0.67723     0.59776
mean/max                              2.25566     0.08078    2.42690     2.14884
mean/min                              -2.38379    0.05917    -2.31783    -2.55116
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 0, 7, 5, 4, 9, 6, 8, 2, 1]
replay_buffer._size: [3157 3157 3154 3158 3155 3155 3157 3155 3156 3154]
diff1,diff2 5.324087858200073 6.747245788574219e-05
train_time 5.324237823486328
2023-09-06 12:26:25,830 MainThread INFO: EPOCH:19
2023-09-06 12:26:25,831 MainThread INFO: Time Consumed:5.4660258293151855s
2023-09-06 12:26:25,831 MainThread INFO: Total Frames:30000s
 10%|â–ˆ         | 20/200 [02:15<20:23,  6.80s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               745.77240
Train_Epoch_Reward                    8133.88190
Running_Training_Average_Rewards      845.51043
Explore_Time                          0.13618
Train___Time                          5.32424
Eval____Time                          0.00498
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.76907
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -61.67478
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -56.13864
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.91990
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.09789
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.99412
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.67369
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7416.00071
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.78126
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.15867
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.50394     1.07874    8.51268     3.70382
alpha_0                               0.89872     0.00489    0.90715     0.89089
alpha_1                               0.74639     0.00317    0.75180     0.74101
alpha_2                               0.74655     0.00309    0.75185     0.74129
alpha_3                               0.74647     0.00317    0.75189     0.74108
alpha_4                               0.74652     0.00313    0.75187     0.74119
alpha_5                               0.74686     0.00315    0.75224     0.74150
alpha_6                               0.74637     0.00319    0.75182     0.74097
alpha_7                               0.74638     0.00319    0.75182     0.74098
alpha_8                               0.74635     0.00317    0.75176     0.74098
alpha_9                               0.74653     0.00316    0.75191     0.74115
Alpha_loss                            -1.67290    0.04426    -1.62274    -1.75303
Training/policy_loss                  -40.62501   2.17226    -36.56454   -44.42477
Training/qf1_loss                     1246.93527  454.57098  2547.46069  568.55457
Training/qf2_loss                     1244.96624  453.37684  2541.70166  568.78088
Training/pf_norm                      0.93780     0.26069    1.62815     0.45560
Training/qf1_norm                     994.36032   606.17288  2820.77148  283.92853
Training/qf2_norm                     980.56576   597.66903  2741.18384  287.18161
log_std/mean                          -0.09753    0.01693    -0.07184    -0.12223
log_std/std                           0.17826     0.00513    0.18687     0.16926
log_std/max                           0.04663     0.01286    0.07123     0.02471
log_std/min                           -0.67433    0.02470    -0.63262    -0.72146
log_probs/mean                        -1.44844    0.10385    -1.24737    -1.60652
log_probs/std                         3.43173     0.12875    3.70266     3.13463
log_probs/max                         12.17237    0.43525    12.95035    10.99883
log_probs/min                         -5.11369    0.67389    -3.73561    -6.91173
mean/mean                             0.17259     0.06263    0.24151     0.08486
mean/std                              0.69504     0.02254    0.73689     0.65324
mean/max                              2.32815     0.03588    2.39352     2.26142
mean/min                              -2.49130    0.06352    -2.38619    -2.67610
------------------------------------  ----------  ---------  ----------  ---------
sample: [4, 9, 7, 8, 0, 3, 5, 6, 2, 1]
replay_buffer._size: [3300 3300 3300 3300 3300 3300 3300 3300 3300 3300]
diff1,diff2 5.334408521652222 2.9802322387695312e-05
train_time 5.334517478942871
2023-09-06 12:26:31,432 MainThread INFO: EPOCH:20
2023-09-06 12:26:31,433 MainThread INFO: Time Consumed:5.3474907875061035s
2023-09-06 12:26:31,433 MainThread INFO: Total Frames:31500s
 10%|â–ˆ         | 21/200 [02:21<19:06,  6.41s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               706.06129
Train_Epoch_Reward                    7285.33304
Running_Training_Average_Rewards      806.58300
Explore_Time                          0.00486
Train___Time                          5.33452
Eval____Time                          0.00747
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.43095
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -55.58913
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.13236
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.78853
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -39.88576
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -58.70116
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.28409
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7198.29905
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.70405
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.41926
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.45669     1.12666    8.96492     2.94855
alpha_0                               0.91554     0.00443    0.92273     0.90751
alpha_1                               0.73538     0.00318    0.74079     0.73000
alpha_2                               0.73572     0.00314    0.74107     0.73040
alpha_3                               0.73548     0.00316    0.74086     0.73013
alpha_4                               0.73558     0.00317    0.74097     0.73022
alpha_5                               0.73586     0.00319    0.74128     0.73045
alpha_6                               0.73534     0.00318    0.74075     0.72996
alpha_7                               0.73535     0.00318    0.74076     0.72996
alpha_8                               0.73535     0.00318    0.74076     0.72997
alpha_9                               0.73551     0.00318    0.74093     0.73012
Alpha_loss                            -1.80354    0.02843    -1.74279    -1.85104
Training/policy_loss                  -43.32149   1.84231    -40.04437   -47.19158
Training/qf1_loss                     1134.76537  425.26783  2511.06982  344.63580
Training/qf2_loss                     1133.32600  424.97383  2506.61182  345.07919
Training/pf_norm                      1.61760     0.58574    2.88184     0.85785
Training/qf1_norm                     908.32085   620.58511  3352.75415  197.19379
Training/qf2_norm                     897.24589   607.30820  3308.22925  206.69310
log_std/mean                          -0.05598    0.01384    -0.03798    -0.07918
log_std/std                           0.18793     0.00628    0.19696     0.17553
log_std/max                           0.13137     0.05285    0.23246     0.05829
log_std/min                           -0.71708    0.02946    -0.66718    -0.76117
log_probs/mean                        -1.60840    0.05553    -1.45321    -1.72441
log_probs/std                         3.24830     0.17623    3.70445     2.95399
log_probs/max                         11.51062    0.56314    12.84724    10.42811
log_probs/min                         -4.31579    0.49387    -3.62619    -5.89154
mean/mean                             0.06775     0.02936    0.10428     0.02417
mean/std                              0.66495     0.01515    0.70183     0.64425
mean/max                              2.36686     0.04773    2.47239     2.27396
mean/min                              -2.51100    0.05941    -2.40869    -2.63771
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 6, 9, 4, 2, 3, 0, 8, 5, 7]
replay_buffer._size: [3450 3450 3450 3450 3450 3450 3450 3450 3450 3450]
diff1,diff2 5.897867202758789 1.8358230590820312e-05
train_time 5.897947788238525
2023-09-06 12:26:37,486 MainThread INFO: EPOCH:21
2023-09-06 12:26:37,486 MainThread INFO: Time Consumed:5.9085211753845215s
2023-09-06 12:26:37,486 MainThread INFO: Total Frames:33000s
 11%|â–ˆ         | 22/200 [02:27<18:42,  6.31s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               683.24172
Train_Epoch_Reward                    6748.03507
Running_Training_Average_Rewards      738.90833
Explore_Time                          0.00606
Train___Time                          5.89795
Eval____Time                          0.00395
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.58258
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.03222
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -31.32034
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.32909
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -26.68492
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.83526
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.32268
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7165.17698
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -37.52358
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.45134
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.51381     1.10458    8.07901     2.92839
alpha_0                               0.93094     0.00507    0.94026     0.92301
alpha_1                               0.72449     0.00311    0.72978     0.71923
alpha_2                               0.72498     0.00305    0.73019     0.71981
alpha_3                               0.72463     0.00310    0.72991     0.71938
alpha_4                               0.72476     0.00308    0.73001     0.71954
alpha_5                               0.72489     0.00313    0.73023     0.71959
alpha_6                               0.72442     0.00312    0.72974     0.71913
alpha_7                               0.72443     0.00312    0.72974     0.71915
alpha_8                               0.72443     0.00312    0.72975     0.71914
alpha_9                               0.72459     0.00311    0.72990     0.71932
Alpha_loss                            -1.87829    0.02459    -1.83873    -1.94026
Training/policy_loss                  -46.66471   2.10670    -41.92646   -50.69471
Training/qf1_loss                     1225.48588  409.90786  2168.55029  567.55957
Training/qf2_loss                     1226.16911  409.95769  2170.16577  567.66895
Training/pf_norm                      1.54967     0.68990    2.82612     0.68024
Training/qf1_norm                     1180.96275  793.23512  3602.74268  216.14600
Training/qf2_norm                     1165.87631  785.08614  3597.68262  249.18399
log_std/mean                          -0.04333    0.00153    -0.04028    -0.04702
log_std/std                           0.19528     0.01014    0.20838     0.17847
log_std/max                           0.17197     0.01115    0.19243     0.14614
log_std/min                           -0.68887    0.03239    -0.63528    -0.78996
log_probs/mean                        -1.46822    0.08616    -1.32419    -1.61331
log_probs/std                         3.52747     0.24339    3.97699     3.11824
log_probs/max                         12.28518    1.00213    13.71811    10.66718
log_probs/min                         -4.48955    0.46769    -3.87761    -6.06919
mean/mean                             0.07416     0.01453    0.09364     0.05073
mean/std                              0.71291     0.02153    0.74880     0.67565
mean/max                              2.49098     0.06316    2.58825     2.38597
mean/min                              -2.63149    0.03341    -2.55418    -2.68490
------------------------------------  ----------  ---------  ----------  ---------
sample: [2, 0, 5, 1, 8, 9, 6, 7, 4, 3]
replay_buffer._size: [3600 3600 3600 3600 3600 3600 3600 3600 3600 3600]
diff1,diff2 5.766799449920654 6.031990051269531e-05
train_time 5.7669453620910645
2023-09-06 12:26:43,482 MainThread INFO: EPOCH:22
2023-09-06 12:26:43,483 MainThread INFO: Time Consumed:5.776289939880371s
2023-09-06 12:26:43,483 MainThread INFO: Total Frames:34500s
 12%|â–ˆâ–        | 23/200 [02:33<18:19,  6.21s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               672.62928
Train_Epoch_Reward                    6963.13413
Running_Training_Average_Rewards      699.88341
Explore_Time                          0.00486
Train___Time                          5.76695
Eval____Time                          0.00398
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.64779
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.80432
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -27.14651
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.33117
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -28.97021
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.49487
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.01996
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7041.76642
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.73854
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.19336
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.27503     1.17310    8.23473     3.13723
alpha_0                               0.95039     0.00540    0.95901     0.94068
alpha_1                               0.71378     0.00308    0.71902     0.70857
alpha_2                               0.71439     0.00307    0.71960     0.70919
alpha_3                               0.71392     0.00308    0.71917     0.70871
alpha_4                               0.71410     0.00308    0.71932     0.70888
alpha_5                               0.71415     0.00306    0.71938     0.70897
alpha_6                               0.71368     0.00307    0.71892     0.70850
alpha_7                               0.71370     0.00308    0.71893     0.70849
alpha_8                               0.71369     0.00308    0.71893     0.70848
alpha_9                               0.71387     0.00307    0.71911     0.70867
Alpha_loss                            -1.98451    0.02920    -1.92886    -2.03624
Training/policy_loss                  -49.22819   1.40945    -46.16256   -52.77969
Training/qf1_loss                     1073.68324  440.36141  2702.61255  494.97247
Training/qf2_loss                     1076.22953  441.30664  2709.63672  495.69345
Training/pf_norm                      1.53373     0.49586    2.41958     0.73942
Training/qf1_norm                     1196.69751  769.59569  3889.73877  277.19968
Training/qf2_norm                     1185.29666  754.81408  3863.09302  302.66077
log_std/mean                          -0.03113    0.01101    -0.01550    -0.04686
log_std/std                           0.19617     0.00785    0.20706     0.18122
log_std/max                           0.15127     0.02455    0.19770     0.10525
log_std/min                           -0.70823    0.03607    -0.64363    -0.80024
log_probs/mean                        -1.50482    0.06904    -1.35957    -1.63919
log_probs/std                         3.48898     0.21476    3.94368     3.12111
log_probs/max                         12.36715    0.80150    13.97344    10.72792
log_probs/min                         -4.30185    0.43610    -3.71132    -5.54234
mean/mean                             0.05865     0.01308    0.07847     0.04262
mean/std                              0.70160     0.02192    0.75390     0.67010
mean/max                              2.48241     0.07794    2.66198     2.37711
mean/min                              -2.67876    0.06318    -2.55057    -2.78641
------------------------------------  ----------  ---------  ----------  ---------
sample: [0, 1, 6, 8, 3, 9, 7, 4, 5, 2]
replay_buffer._size: [3750 3750 3750 3750 3750 3750 3750 3750 3750 3750]
diff1,diff2 5.795227289199829 3.4332275390625e-05
train_time 5.795325040817261
2023-09-06 12:26:49,441 MainThread INFO: EPOCH:23
2023-09-06 12:26:49,442 MainThread INFO: Time Consumed:5.805706977844238s
2023-09-06 12:26:49,442 MainThread INFO: Total Frames:36000s
 12%|â–ˆâ–        | 24/200 [02:39<17:59,  6.14s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               670.11712
Train_Epoch_Reward                    6050.46190
Running_Training_Average_Rewards      658.72104
Explore_Time                          0.00529
Train___Time                          5.79533
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.62308
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.54178
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -27.40561
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.47341
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.02234
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.09353
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.39140
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7054.86946
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.53520
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.78413
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.32008     1.26726    10.81544    2.75489
alpha_0                               0.96878     0.00582    0.97863     0.95935
alpha_1                               0.70321     0.00302    0.70836     0.69810
alpha_2                               0.70391     0.00296    0.70898     0.69892
alpha_3                               0.70335     0.00302    0.70850     0.69825
alpha_4                               0.70356     0.00299    0.70867     0.69851
alpha_5                               0.70363     0.00301    0.70876     0.69855
alpha_6                               0.70315     0.00301    0.70828     0.69805
alpha_7                               0.70315     0.00301    0.70828     0.69806
alpha_8                               0.70312     0.00303    0.70827     0.69800
alpha_9                               0.70331     0.00302    0.70845     0.69821
Alpha_loss                            -2.06110    0.02211    -2.03179    -2.11387
Training/policy_loss                  -52.52745   1.90520    -48.73397   -58.31922
Training/qf1_loss                     1068.80409  440.82520  2559.15674  431.53329
Training/qf2_loss                     1072.95689  440.94119  2567.89453  434.45538
Training/pf_norm                      1.81778     0.51563    2.62881     0.61032
Training/qf1_norm                     1429.21380  960.28636  5636.96777  388.50305
Training/qf2_norm                     1422.26491  947.77086  5569.52588  374.39606
log_std/mean                          -0.00883    0.00875    0.00417     -0.02248
log_std/std                           0.21707     0.00996    0.23226     0.19999
log_std/max                           0.28169     0.04310    0.34448     0.20267
log_std/min                           -0.70015    0.02506    -0.64516    -0.74629
log_probs/mean                        -1.39583    0.07620    -1.25163    -1.53653
log_probs/std                         3.64778     0.16845    4.04554     3.30373
log_probs/max                         12.94640    0.55360    13.86902    11.60145
log_probs/min                         -4.28485    0.33990    -3.84524    -5.38431
mean/mean                             0.07260     0.01586    0.09733     0.05635
mean/std                              0.72197     0.01740    0.75565     0.69027
mean/max                              2.56495     0.07531    2.69762     2.43128
mean/min                              -2.70360    0.04562    -2.60685    -2.78577
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 1, 6, 8, 2, 0, 4, 5, 7, 9]
replay_buffer._size: [3900 3900 3900 3900 3900 3900 3900 3900 3900 3900]
diff1,diff2 5.67977499961853 1.8835067749023438e-05
train_time 5.679889917373657
2023-09-06 12:26:55,284 MainThread INFO: EPOCH:24
2023-09-06 12:26:55,285 MainThread INFO: Time Consumed:5.692385196685791s
2023-09-06 12:26:55,285 MainThread INFO: Total Frames:37500s
 12%|â–ˆâ–Ž        | 25/200 [02:45<17:37,  6.04s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               670.68780
Train_Epoch_Reward                    6881.25176
Running_Training_Average_Rewards      663.16159
Explore_Time                          0.00679
Train___Time                          5.67989
Eval____Time                          0.00458
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.00750
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.79503
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.79260
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.25069
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.32351
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -30.88142
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.35602
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7067.31223
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.23293
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -30.45713
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.30638     0.96622    7.78841     3.37926
alpha_0                               0.98808     0.00540    0.99734     0.97901
alpha_1                               0.69287     0.00294    0.69789     0.68790
alpha_2                               0.69378     0.00288    0.69871     0.68891
alpha_3                               0.69298     0.00297    0.69804     0.68795
alpha_4                               0.69332     0.00292    0.69830     0.68838
alpha_5                               0.69332     0.00295    0.69834     0.68834
alpha_6                               0.69283     0.00295    0.69785     0.68784
alpha_7                               0.69285     0.00293    0.69785     0.68788
alpha_8                               0.69275     0.00296    0.69779     0.68775
alpha_9                               0.69297     0.00295    0.69801     0.68797
Alpha_loss                            -2.14025    0.02288    -2.10185    -2.18464
Training/policy_loss                  -55.70979   2.66037    -49.80210   -61.40039
Training/qf1_loss                     1029.50100  298.23713  2051.72314  461.59390
Training/qf2_loss                     1036.91902  298.69226  2055.88208  463.82706
Training/pf_norm                      2.66763     0.89655    4.50145     0.81378
Training/qf1_norm                     1438.53052  807.07376  3156.17090  368.19315
Training/qf2_norm                     1454.23498  792.66549  3081.47900  354.74075
log_std/mean                          0.02362     0.01260    0.03887     -0.00556
log_std/std                           0.22190     0.00563    0.23340     0.21511
log_std/max                           0.33195     0.04527    0.40966     0.23011
log_std/min                           -0.69833    0.02564    -0.65779    -0.75244
log_probs/mean                        -1.37285    0.06487    -1.23643    -1.48537
log_probs/std                         3.56208     0.10187    3.77331     3.37366
log_probs/max                         12.95860    0.44708    13.99805    12.08615
log_probs/min                         -4.43024    0.38540    -4.02422    -5.75963
mean/mean                             0.12364     0.01856    0.15574     0.09837
mean/std                              0.72073     0.01572    0.74521     0.69378
mean/max                              2.59521     0.06726    2.72599     2.50958
mean/min                              -2.79964    0.05357    -2.72117    -2.88684
------------------------------------  ----------  ---------  ----------  ---------
sample: [1, 3, 0, 4, 9, 5, 7, 6, 8, 2]
replay_buffer._size: [4050 4050 4050 4050 4050 4050 4050 4050 4050 4050]
diff1,diff2 6.180254220962524 7.43865966796875e-05
train_time 6.18043327331543
2023-09-06 12:27:01,636 MainThread INFO: EPOCH:25
2023-09-06 12:27:01,637 MainThread INFO: Time Consumed:6.190561771392822s
2023-09-06 12:27:01,637 MainThread INFO: Total Frames:39000s
 13%|â–ˆâ–Ž        | 26/200 [02:51<17:47,  6.14s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               671.26054
Train_Epoch_Reward                    6832.08791
Running_Training_Average_Rewards      658.79339
Explore_Time                          0.00500
Train___Time                          6.18043
Eval____Time                          0.00434
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.29941
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.51360
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.65940
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -33.97859
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -40.45937
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.86378
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.91290
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7023.77222
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -35.71703
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.76631
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.43007     1.06507    8.96359     3.17461
alpha_0                               1.00705     0.00565    1.01718     0.99772
alpha_1                               0.68278     0.00288    0.68770     0.67792
alpha_2                               0.68397     0.00278    0.68872     0.67935
alpha_3                               0.68279     0.00291    0.68775     0.67787
alpha_4                               0.68332     0.00284    0.68818     0.67856
alpha_5                               0.68327     0.00286    0.68814     0.67845
alpha_6                               0.68272     0.00289    0.68764     0.67784
alpha_7                               0.68279     0.00286    0.68768     0.67797
alpha_8                               0.68258     0.00291    0.68754     0.67766
alpha_9                               0.68282     0.00290    0.68777     0.67794
Alpha_loss                            -2.19740    0.01975    -2.15873    -2.23574
Training/policy_loss                  -58.82957   2.55800    -54.02378   -66.08167
Training/qf1_loss                     1053.24764  339.36052  2258.96655  417.49463
Training/qf2_loss                     1060.87066  339.63666  2267.81616  425.68057
Training/pf_norm                      1.74763     0.88444    3.82338     0.63635
Training/qf1_norm                     1532.32543  944.50269  5603.70557  308.49286
Training/qf2_norm                     1516.12999  943.34391  5577.45215  313.71408
log_std/mean                          0.04910     0.01345    0.07187     0.02002
log_std/std                           0.23740     0.01456    0.26440     0.21715
log_std/max                           0.42266     0.05792    0.53647     0.33227
log_std/min                           -0.68292    0.01849    -0.65229    -0.72541
log_probs/mean                        -1.22237    0.15563    -0.89904    -1.40790
log_probs/std                         3.71629     0.20771    4.12946     3.35404
log_probs/max                         13.13900    0.82035    14.40907    11.86427
log_probs/min                         -4.63594    0.38501    -4.13745    -5.58919
mean/mean                             0.09743     0.00848    0.10941     0.08555
mean/std                              0.76384     0.03639    0.83947     0.71731
mean/max                              2.73645     0.05579    2.84826     2.63630
mean/min                              -2.88735    0.06597    -2.76341    -3.00848
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 6, 0, 5, 2, 1, 4, 9, 3, 8]
replay_buffer._size: [4200 4200 4200 4200 4200 4200 4200 4200 4200 4200]
diff1,diff2 5.689875602722168 8.344650268554688e-05
train_time 5.69002366065979
2023-09-06 12:27:07,537 MainThread INFO: EPOCH:26
2023-09-06 12:27:07,537 MainThread INFO: Time Consumed:5.700692892074585s
2023-09-06 12:27:07,537 MainThread INFO: Total Frames:40500s
 14%|â–ˆâ–Ž        | 27/200 [02:57<17:34,  6.10s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               670.00750
Train_Epoch_Reward                    6640.07826
Running_Training_Average_Rewards      678.44726
Explore_Time                          0.00383
Train___Time                          5.69002
Eval____Time                          0.00583
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.52344
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.61364
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.73374
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.80811
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -45.86479
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -86.61820
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.23793
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7064.44561
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.13868
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.49920
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.17715     1.13164     8.34544     2.58608
alpha_0                               1.02945     0.00693     1.04100     1.01764
alpha_1                               0.67304     0.00275     0.67773     0.66843
alpha_2                               0.67720     0.00072     0.67918     0.67661
alpha_3                               0.67282     0.00284     0.67767     0.66807
alpha_4                               0.67389     0.00257     0.67837     0.66993
alpha_5                               0.67390     0.00241     0.67826     0.67069
alpha_6                               0.67286     0.00279     0.67764     0.66825
alpha_7                               0.67314     0.00271     0.67777     0.66876
alpha_8                               0.67264     0.00283     0.67746     0.66787
alpha_9                               0.67297     0.00282     0.67775     0.66822
Alpha_loss                            -1.87965    0.24266     -1.31426    -2.15431
Training/policy_loss                  -61.31623   2.42403     -56.50727   -66.52891
Training/qf1_loss                     969.94380   399.62290   2095.22900  403.80060
Training/qf2_loss                     976.57448   400.96766   2098.88599  411.05313
Training/pf_norm                      1.38558     0.29082     2.03583     0.82911
Training/qf1_norm                     1621.12975  1008.89234  4180.49512  403.05872
Training/qf2_norm                     1597.37088  992.85350   4174.53223  498.18301
log_std/mean                          -0.02946    0.05772     0.04028     -0.16621
log_std/std                           0.26744     0.02470     0.30455     0.21471
log_std/max                           0.35652     0.08109     0.48855     0.24238
log_std/min                           -0.77369    0.14830     -0.62383    -1.09196
log_probs/mean                        -0.07846    0.64324     1.39902     -0.85325
log_probs/std                         4.30530     0.15425     4.59934     3.93602
log_probs/max                         14.18832    0.44125     15.09360    13.48859
log_probs/min                         -6.15126    1.26562     -4.09623    -9.99367
mean/mean                             0.12436     0.06385     0.24677     0.03931
mean/std                              1.02852     0.12335     1.29601     0.85520
mean/max                              2.72046     0.05277     2.83689     2.59795
mean/min                              -2.85746    0.06243     -2.69342    -2.98540
------------------------------------  ----------  ----------  ----------  ---------
sample: [1, 8, 2, 6, 9, 7, 4, 0, 5, 3]
replay_buffer._size: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350]
diff1,diff2 5.782654047012329 7.152557373046875e-05
train_time 5.7827959060668945
2023-09-06 12:27:13,613 MainThread INFO: EPOCH:27
2023-09-06 12:27:13,613 MainThread INFO: Time Consumed:5.80117654800415s
2023-09-06 12:27:13,613 MainThread INFO: Total Frames:42000s
 14%|â–ˆâ–        | 28/200 [03:03<17:22,  6.06s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               659.51830
Train_Epoch_Reward                    6734.83822
Running_Training_Average_Rewards      673.56681
Explore_Time                          0.01293
Train___Time                          5.78280
Eval____Time                          0.00477
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -37.60727
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -56.33823
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -67.99104
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.34785
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.05770
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -112.08696
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -62.36059
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7024.05406
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.91985
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.80540
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.10449     0.95266    6.96960     3.22876
alpha_0                               1.05344     0.00732    1.06595     1.04145
alpha_1                               0.66424     0.00220    0.66825     0.66093
alpha_2                               0.67619     0.00036    0.67660     0.67548
alpha_3                               0.66410     0.00211    0.66789     0.66070
alpha_4                               0.66852     0.00079    0.66984     0.66713
alpha_5                               0.66933     0.00084    0.67066     0.66798
alpha_6                               0.66604     0.00094    0.66809     0.66454
alpha_7                               0.66729     0.00070    0.66864     0.66608
alpha_8                               0.66318     0.00261    0.66768     0.65888
alpha_9                               0.66426     0.00197    0.66803     0.66139
Alpha_loss                            -1.06511    0.24819    -0.51789    -1.56686
Training/policy_loss                  -64.77888   2.28469    -59.91410   -71.36404
Training/qf1_loss                     939.79484   303.13486  1748.29065  450.54990
Training/qf2_loss                     946.49518   301.95564  1743.50378  461.29736
Training/pf_norm                      2.74404     0.99843    5.34801     1.47993
Training/qf1_norm                     1558.97118  973.55848  4563.75439  365.68088
Training/qf2_norm                     1563.12380  962.17241  4387.55811  354.57401
log_std/mean                          -0.23844    0.04514    -0.16052    -0.34775
log_std/std                           0.25366     0.01571    0.28949     0.21851
log_std/max                           0.23864     0.03089    0.28468     0.18174
log_std/min                           -1.15963    0.12139    -0.75740    -1.35953
log_probs/mean                        2.17114     0.64431    3.58094     0.90816
log_probs/std                         4.53950     0.16032    4.84978     4.12374
log_probs/max                         15.05790    0.98054    19.30768    13.34270
log_probs/min                         -7.17516    1.04566    -5.43690    -9.88791
mean/mean                             0.16902     0.04168    0.24507     0.10505
mean/std                              1.42386     0.09565    1.61869     1.22670
mean/max                              3.05211     0.24031    3.55273     2.73435
mean/min                              -3.17205    0.28112    -2.77984    -3.74860
------------------------------------  ----------  ---------  ----------  ---------
sample: [3, 1, 8, 5, 2, 0, 7, 6, 9, 4]
replay_buffer._size: [4500 4500 4500 4500 4500 4500 4500 4500 4500 4500]
diff1,diff2 5.818598508834839 7.271766662597656e-05
train_time 5.818758964538574
2023-09-06 12:27:19,679 MainThread INFO: EPOCH:28
2023-09-06 12:27:19,679 MainThread INFO: Time Consumed:5.832631349563599s
2023-09-06 12:27:19,679 MainThread INFO: Total Frames:43500s
 14%|â–ˆâ–        | 29/200 [03:09<17:16,  6.06s/it]------------------------------------  ----------  ---------  ----------  ---------
Name                                  Value
Running_Average_Rewards               651.12229
Train_Epoch_Reward                    6634.16886
Running_Training_Average_Rewards      666.96951
Explore_Time                          0.00865
Train___Time                          5.81876
Eval____Time                          0.00411
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.55381
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -65.58759
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -83.20312
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -68.05683
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -89.89467
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -113.25802
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -68.78296
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7031.29111
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.59718
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -27.63519
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std        Max         Min
Reward_Mean                           5.13271     0.86321    7.86972     3.48653
alpha_0                               1.07840     0.00679    1.08941     1.06646
alpha_1                               0.65839     0.00147    0.66084     0.65585
alpha_2                               0.67497     0.00028    0.67546     0.67451
alpha_3                               0.65808     0.00159    0.66061     0.65528
alpha_4                               0.66578     0.00078    0.66708     0.66447
alpha_5                               0.66684     0.00065    0.66794     0.66574
alpha_6                               0.66308     0.00085    0.66448     0.66165
alpha_7                               0.66481     0.00076    0.66604     0.66355
alpha_8                               0.65679     0.00107    0.65875     0.65508
alpha_9                               0.65945     0.00111    0.66132     0.65751
Alpha_loss                            -0.81362    0.19099    -0.50420    -1.26389
Training/policy_loss                  -68.14343   2.49068    -63.46285   -73.20083
Training/qf1_loss                     885.33951   335.39003  2361.68750  435.59854
Training/qf2_loss                     892.84483   335.75727  2364.86621  441.02319
Training/pf_norm                      3.00594     1.31078    5.26413     1.01752
Training/qf1_norm                     1669.55964  957.79336  4119.49463  524.66718
Training/qf2_norm                     1684.00205  958.66783  4122.38281  402.66049
log_std/mean                          -0.29105    0.03397    -0.22624    -0.35021
log_std/std                           0.24439     0.01540    0.27139     0.20963
log_std/max                           0.14661     0.02173    0.17616     0.10397
log_std/min                           -1.06124    0.11902    -0.79138    -1.25978
log_probs/mean                        2.77794     0.47203    3.50167     1.65907
log_probs/std                         4.53811     0.14314    4.88854     4.26201
log_probs/max                         15.02451    1.17180    17.94823    12.96890
log_probs/min                         -6.62344    1.02518    -4.73931    -9.51229
mean/mean                             0.17265     0.04130    0.25988     0.12485
mean/std                              1.50608     0.06754    1.62140     1.34302
mean/max                              3.21400     0.18589    3.62523     2.77225
mean/min                              -3.39505    0.20601    -2.93355    -3.86308
------------------------------------  ----------  ---------  ----------  ---------
sample: [7, 5, 8, 4, 3, 1, 2, 0, 6, 9]
replay_buffer._size: [4650 4650 4650 4650 4650 4650 4650 4650 4650 4650]
diff1,diff2 6.081747055053711 6.961822509765625e-05
train_time 6.081890344619751
2023-09-06 12:27:25,949 MainThread INFO: EPOCH:29
2023-09-06 12:27:25,950 MainThread INFO: Time Consumed:6.093727111816406s
2023-09-06 12:27:25,950 MainThread INFO: Total Frames:45000s
 15%|â–ˆâ–Œ        | 30/200 [03:15<17:21,  6.12s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               646.82746
Train_Epoch_Reward                    6437.50452
Running_Training_Average_Rewards      660.21705
Explore_Time                          0.00473
Train___Time                          6.08189
Eval____Time                          0.00633
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.81036
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -54.43864
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -68.05137
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.66073
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -70.70528
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.91477
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -56.97773
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7021.03086
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -43.43401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.47496
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.05367     1.07480     7.87522     2.69311
alpha_0                               1.09964     0.00576     1.10937     1.08982
alpha_1                               0.65327     0.00147     0.65576     0.65074
alpha_2                               0.67395     0.00032     0.67449     0.67330
alpha_3                               0.65275     0.00135     0.65517     0.65037
alpha_4                               0.66322     0.00071     0.66441     0.66187
alpha_5                               0.66472     0.00057     0.66570     0.66373
alpha_6                               0.66034     0.00075     0.66160     0.65895
alpha_7                               0.66241     0.00066     0.66351     0.66121
alpha_8                               0.65354     0.00090     0.65503     0.65199
alpha_9                               0.65591     0.00087     0.65743     0.65435
Alpha_loss                            -0.77777    0.12654     -0.49711    -1.03279
Training/policy_loss                  -71.09992   2.79080     -65.63772   -77.19588
Training/qf1_loss                     890.74931   337.00846   1865.89734  421.29272
Training/qf2_loss                     894.26481   338.93536   1874.33679  425.46823
Training/pf_norm                      2.73861     0.63236     4.70220     1.72532
Training/qf1_norm                     1873.35868  1091.21335  4836.45996  525.02069
Training/qf2_norm                     1853.76074  1092.38399  4915.65283  503.52002
log_std/mean                          -0.28125    0.03174     -0.22644    -0.34033
log_std/std                           0.26679     0.01183     0.28164     0.24003
log_std/max                           0.21755     0.05604     0.29169     0.09553
log_std/min                           -0.92030    0.07682     -0.77034    -1.05060
log_probs/mean                        2.82279     0.30683     3.50200     2.18322
log_probs/std                         4.54102     0.11480     4.75741     4.34767
log_probs/max                         13.85304    0.96724     15.97139    12.26389
log_probs/min                         -6.98839    1.48764     -4.89616    -12.60730
mean/mean                             0.21560     0.01969     0.25877     0.18219
mean/std                              1.51226     0.04457     1.60892     1.41664
mean/max                              3.03097     0.11201     3.27115     2.78929
mean/min                              -3.21541    0.12985     -2.96958    -3.45455
------------------------------------  ----------  ----------  ----------  ---------
sample: [0, 2, 8, 6, 5, 7, 9, 3, 1, 4]
replay_buffer._size: [4800 4800 4800 4800 4800 4800 4800 4800 4800 4801]
diff1,diff2 5.906447410583496 3.62396240234375e-05
train_time 5.906565189361572
2023-09-06 12:27:32,050 MainThread INFO: EPOCH:30
2023-09-06 12:27:32,051 MainThread INFO: Time Consumed:5.9334259033203125s
2023-09-06 12:27:32,051 MainThread INFO: Total Frames:46500s
 16%|â–ˆâ–Œ        | 31/200 [03:22<17:15,  6.13s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               653.30690
Train_Epoch_Reward                    6669.53058
Running_Training_Average_Rewards      658.04013
Explore_Time                          0.02244
Train___Time                          5.90657
Eval____Time                          0.00370
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.63938
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.92208
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.61209
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.71469
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.89658
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.70959
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -43.91574
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7041.36626
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -38.15759
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -15.87625
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.29143     1.05448     7.64232     2.82101
alpha_0                               1.11959     0.00585     1.12953     1.10976
alpha_1                               0.64819     0.00139     0.65063     0.64585
alpha_2                               0.67262     0.00034     0.67327     0.67201
alpha_3                               0.64801     0.00109     0.65025     0.64632
alpha_4                               0.66058     0.00054     0.66180     0.65978
alpha_5                               0.66278     0.00052     0.66369     0.66188
alpha_6                               0.65782     0.00057     0.65889     0.65685
alpha_7                               0.66008     0.00058     0.66116     0.65913
alpha_8                               0.65045     0.00083     0.65192     0.64902
alpha_9                               0.65281     0.00079     0.65427     0.65153
Alpha_loss                            -0.63681    0.24604     -0.14799    -0.99530
Training/policy_loss                  -74.40977   2.93093     -67.57992   -80.36889
Training/qf1_loss                     904.54508   321.63092   1741.73853  395.63193
Training/qf2_loss                     908.07710   319.95378   1762.42151  406.18774
Training/pf_norm                      3.68845     1.15220     5.83128     1.67880
Training/qf1_norm                     2089.68632  1340.23495  5002.51270  444.00916
Training/qf2_norm                     2127.99003  1388.80000  5189.92773  587.09003
log_std/mean                          -0.30800    0.03471     -0.24775    -0.37827
log_std/std                           0.25865     0.01203     0.27761     0.23130
log_std/max                           0.09253     0.02092     0.13499     0.07398
log_std/min                           -0.84423    0.06126     -0.70756    -0.95831
log_probs/mean                        3.21696     0.59405     4.40772     2.34808
log_probs/std                         4.63692     0.13462     4.91027     4.38681
log_probs/max                         13.68801    0.75507     15.84864    12.59748
log_probs/min                         -6.65948    1.41067     -4.56464    -12.76804
mean/mean                             0.21918     0.02945     0.28548     0.17704
mean/std                              1.57230     0.08065     1.71868     1.45427
mean/max                              3.05355     0.08547     3.27141     2.89339
mean/min                              -3.18901    0.12467     -2.96969    -3.46054
------------------------------------  ----------  ----------  ----------  ---------
sample: [6, 4, 1, 3, 9, 5, 8, 0, 7, 2]
replay_buffer._size: [4950 4950 4950 4950 4950 4950 4950 4950 4950 4950]
diff1,diff2 5.757395505905151 7.152557373046875e-05
train_time 5.757555723190308
2023-09-06 12:27:38,008 MainThread INFO: EPOCH:31
2023-09-06 12:27:38,008 MainThread INFO: Time Consumed:5.7706522941589355s
2023-09-06 12:27:38,008 MainThread INFO: Total Frames:48000s
 16%|â–ˆâ–Œ        | 32/200 [03:27<16:59,  6.07s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               665.33782
Train_Epoch_Reward                    6946.48180
Running_Training_Average_Rewards      668.45056
Explore_Time                          0.00532
Train___Time                          5.75756
Eval____Time                          0.00723
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.81974
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.11379
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.76303
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.91838
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.31625
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -34.22556
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.83388
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7041.30596
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.85626
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -11.80987
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           4.95535     1.02713     8.21908     3.10139
alpha_0                               1.14184     0.00744     1.15477     1.12994
alpha_1                               0.64365     0.00133     0.64577     0.64139
alpha_2                               0.67133     0.00046     0.67199     0.67059
alpha_3                               0.64410     0.00153     0.64626     0.64129
alpha_4                               0.65874     0.00078     0.65976     0.65732
alpha_5                               0.66099     0.00057     0.66185     0.65999
alpha_6                               0.65541     0.00092     0.65682     0.65391
alpha_7                               0.65808     0.00063     0.65909     0.65706
alpha_8                               0.64726     0.00109     0.64897     0.64551
alpha_9                               0.65007     0.00093     0.65148     0.64849
Alpha_loss                            -0.82171    0.25636     -0.29983    -1.32596
Training/policy_loss                  -77.38444   2.90416     -70.53611   -83.32472
Training/qf1_loss                     807.90710   354.09709   2016.33435  354.92673
Training/qf2_loss                     806.76344   352.99639   2010.59656  354.21283
Training/pf_norm                      3.75932     1.02302     5.76841     1.73471
Training/qf1_norm                     2334.65635  1545.86838  6614.36133  479.27634
Training/qf2_norm                     2274.75966  1466.12740  6492.74951  462.07822
log_std/mean                          -0.28566    0.02738     -0.23720    -0.33187
log_std/std                           0.26272     0.00962     0.28394     0.24545
log_std/max                           0.11257     0.01651     0.13944     0.08230
log_std/min                           -0.79885    0.05491     -0.68757    -0.91288
log_probs/mean                        3.05269     0.54558     4.10356     1.99151
log_probs/std                         5.14322     0.17233     5.43211     4.79923
log_probs/max                         15.45571    0.58586     16.73678    14.39326
log_probs/min                         -6.10793    1.24300     -4.32884    -9.75827
mean/mean                             0.13532     0.03244     0.19528     0.07164
mean/std                              1.56495     0.07299     1.69544     1.42658
mean/max                              2.98730     0.04920     3.06957     2.83411
mean/min                              -3.14353    0.05863     -2.97394    -3.27266
------------------------------------  ----------  ----------  ----------  ---------
sample: [6, 8, 4, 3, 1, 2, 9, 5, 7, 0]
replay_buffer._size: [5100 5100 5100 5100 5100 5100 5100 5100 5100 5100]
diff1,diff2 5.979255676269531 1.8358230590820312e-05
train_time 5.979334115982056
2023-09-06 12:27:44,188 MainThread INFO: EPOCH:32
2023-09-06 12:27:44,188 MainThread INFO: Time Consumed:5.997443914413452s
2023-09-06 12:27:44,188 MainThread INFO: Total Frames:49500s
 16%|â–ˆâ–‹        | 33/200 [03:34<16:58,  6.10s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               672.85366
Train_Epoch_Reward                    6872.71084
Running_Training_Average_Rewards      682.95744
Explore_Time                          0.01375
Train___Time                          5.97933
Eval____Time                          0.00369
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.12827
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.71013
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -42.70601
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.42494
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -24.99096
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -33.07995
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -34.91535
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7049.26881
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.19501
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -13.07985
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           4.92955     0.99144     7.33711     2.82191
alpha_0                               1.16656     0.00634     1.17702     1.15527
alpha_1                               0.63893     0.00151     0.64131     0.63636
alpha_2                               0.66956     0.00072     0.67056     0.66825
alpha_3                               0.63908     0.00131     0.64119     0.63662
alpha_4                               0.65585     0.00094     0.65726     0.65418
alpha_5                               0.65887     0.00070     0.65994     0.65761
alpha_6                               0.65238     0.00099     0.65385     0.65064
alpha_7                               0.65584     0.00078     0.65702     0.65450
alpha_8                               0.64367     0.00116     0.64545     0.64168
alpha_9                               0.64672     0.00110     0.64843     0.64492
Alpha_loss                            -0.86493    0.21721     -0.44453    -1.19054
Training/policy_loss                  -79.93594   3.26724     -73.60037   -88.22272
Training/qf1_loss                     773.61750   269.24107   1781.10437  308.90103
Training/qf2_loss                     770.69264   266.53845   1760.04065  306.15366
Training/pf_norm                      3.07446     1.23285     5.93078     1.33786
Training/qf1_norm                     1733.37025  1073.76012  4569.39355  444.10336
Training/qf2_norm                     1830.08694  998.66671   4022.01709  532.96368
log_std/mean                          -0.26509    0.02238     -0.22472    -0.30090
log_std/std                           0.28427     0.01662     0.31310     0.25851
log_std/max                           0.14834     0.03218     0.23070     0.11713
log_std/min                           -0.79385    0.03936     -0.70914    -0.86079
log_probs/mean                        2.83250     0.56426     3.86055     1.94238
log_probs/std                         5.07214     0.14619     5.32369     4.78737
log_probs/max                         14.38840    0.69649     15.66819    12.83045
log_probs/min                         -6.29596    1.60147     -4.06094    -11.74940
mean/mean                             0.15210     0.03396     0.21639     0.10543
mean/std                              1.53491     0.07938     1.68725     1.41325
mean/max                              2.96951     0.08901     3.15679     2.82210
mean/min                              -3.12316    0.09613     -2.95279    -3.30364
------------------------------------  ----------  ----------  ----------  ---------
sample: [7, 8, 0, 4, 3, 5, 2, 9, 6, 1]
replay_buffer._size: [5250 5250 5250 5250 5250 5250 5250 5250 5250 5250]
diff1,diff2 5.888683319091797 6.651878356933594e-05
train_time 5.888817310333252
2023-09-06 12:27:50,254 MainThread INFO: EPOCH:33
2023-09-06 12:27:50,254 MainThread INFO: Time Consumed:5.897135972976685s
2023-09-06 12:27:50,254 MainThread INFO: Total Frames:51000s
 17%|â–ˆâ–‹        | 34/200 [03:40<16:51,  6.09s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               675.09676
Train_Epoch_Reward                    6837.68176
Running_Training_Average_Rewards      688.56248
Explore_Time                          0.00376
Train___Time                          5.88882
Eval____Time                          0.00385
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.68725
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.68911
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -41.52148
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.72144
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.35644
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -27.05904
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.06271
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7035.48280
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.09749
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -11.07263
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           4.97490     1.17347     8.77085     3.24046
alpha_0                               1.18747     0.00571     1.19743     1.17746
alpha_1                               0.63298     0.00205     0.63627     0.62964
alpha_2                               0.66613     0.00137     0.66822     0.66399
alpha_3                               0.63369     0.00172     0.63653     0.63096
alpha_4                               0.65214     0.00117     0.65413     0.65035
alpha_5                               0.65576     0.00123     0.65757     0.65376
alpha_6                               0.64863     0.00124     0.65059     0.64670
alpha_7                               0.65216     0.00156     0.65447     0.64976
alpha_8                               0.63904     0.00165     0.64161     0.63638
alpha_9                               0.64253     0.00149     0.64486     0.64016
Alpha_loss                            -1.26984    0.42115     -0.74049    -2.00248
Training/policy_loss                  -80.63172   4.03582     -71.37033   -90.94389
Training/qf1_loss                     796.51167   275.20544   1549.82654  340.00638
Training/qf2_loss                     788.40721   273.76256   1540.37500  329.85580
Training/pf_norm                      3.31302     1.02310     6.71200     1.69752
Training/qf1_norm                     2234.06878  1256.98208  6465.85791  461.29648
Training/qf2_norm                     2211.64462  1238.77025  6254.53467  471.42911
log_std/mean                          -0.19990    0.05010     -0.11369    -0.27324
log_std/std                           0.26065     0.01486     0.28572     0.22749
log_std/max                           0.17587     0.02195     0.22217     0.13464
log_std/min                           -0.73840    0.03099     -0.66160    -0.79774
log_probs/mean                        1.89458     1.07270     3.26002     0.06777
log_probs/std                         4.95878     0.18452     5.20538     4.45456
log_probs/max                         14.01409    0.89596     15.99290    12.24690
log_probs/min                         -5.74011    0.96581     -3.82707    -8.07586
mean/mean                             0.11666     0.06895     0.19764     -0.01569
mean/std                              1.40297     0.16640     1.61069     1.10117
mean/max                              3.07453     0.11194     3.28609     2.83979
mean/min                              -3.21477    0.14603     -2.90495    -3.49927
------------------------------------  ----------  ----------  ----------  ---------
sample: [9, 2, 7, 1, 0, 6, 8, 3, 4, 5]
replay_buffer._size: [5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]
diff1,diff2 6.424731254577637 3.0994415283203125e-05
train_time 6.424837589263916
2023-09-06 12:27:56,836 MainThread INFO: EPOCH:34
2023-09-06 12:27:56,837 MainThread INFO: Time Consumed:6.432783126831055s
2023-09-06 12:27:56,837 MainThread INFO: Total Frames:52500s
 18%|â–ˆâ–Š        | 35/200 [03:46<17:09,  6.24s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               674.59326
Train_Epoch_Reward                    6708.27794
Running_Training_Average_Rewards      680.62235
Explore_Time                          0.00357
Train___Time                          6.42484
Eval____Time                          0.00369
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.73943
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.87775
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.56655
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.07394
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -22.18375
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.04895
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.22904
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7024.04043
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.04803
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -11.72882
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.22678     0.91279     7.70303     3.46924
alpha_0                               1.20855     0.00647     1.21939     1.19785
alpha_1                               0.62624     0.00191     0.62950     0.62282
alpha_2                               0.66097     0.00166     0.66388     0.65820
alpha_3                               0.62750     0.00199     0.63084     0.62408
alpha_4                               0.64777     0.00156     0.65027     0.64496
alpha_5                               0.65088     0.00174     0.65367     0.64767
alpha_6                               0.64413     0.00143     0.64660     0.64167
alpha_7                               0.64665     0.00178     0.64965     0.64345
alpha_8                               0.63322     0.00176     0.63626     0.63002
alpha_9                               0.63717     0.00167     0.64004     0.63436
Alpha_loss                            -1.50320    0.42012     -0.79328    -2.12422
Training/policy_loss                  -85.78070   4.15500     -79.11515   -96.16464
Training/qf1_loss                     794.36186   277.11222   1484.34998  462.87628
Training/qf2_loss                     783.07611   275.18214   1467.33850  458.30469
Training/pf_norm                      3.59291     1.20111     6.94650     1.55024
Training/qf1_norm                     1934.96191  1133.30520  5425.28076  357.10367
Training/qf2_norm                     1991.75738  1051.02807  5001.02734  387.17566
log_std/mean                          -0.16469    0.04759     -0.09551    -0.23573
log_std/std                           0.26375     0.01746     0.29219     0.23189
log_std/max                           0.19898     0.01388     0.22236     0.17478
log_std/min                           -0.75485    0.03254     -0.69068    -0.82392
log_probs/mean                        1.51282     1.00803     3.08292     0.07129
log_probs/std                         5.15820     0.22368     5.52469     4.71741
log_probs/max                         14.86138    0.76255     16.51367    13.55100
log_probs/min                         -5.50142    1.30747     -3.93852    -11.10766
mean/mean                             0.11853     0.05611     0.20880     0.02675
mean/std                              1.35563     0.15870     1.59526     1.11519
mean/max                              3.17694     0.10803     3.41753     3.02315
mean/min                              -3.30195    0.10676     -3.12811    -3.55772
------------------------------------  ----------  ----------  ----------  ---------
sample: [5, 8, 3, 0, 7, 6, 1, 2, 4, 9]
replay_buffer._size: [5550 5550 5550 5550 5550 5550 5550 5550 5550 5550]
diff1,diff2 6.043086767196655 1.7642974853515625e-05
train_time 6.043165683746338
2023-09-06 12:28:03,048 MainThread INFO: EPOCH:35
2023-09-06 12:28:03,048 MainThread INFO: Time Consumed:6.0518083572387695s
2023-09-06 12:28:03,048 MainThread INFO: Total Frames:54000s
 18%|â–ˆâ–Š        | 36/200 [03:53<17:02,  6.23s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               677.16558
Train_Epoch_Reward                    7357.28243
Running_Training_Average_Rewards      696.77474
Explore_Time                          0.00378
Train___Time                          6.04317
Eval____Time                          0.00417
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.81223
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.14616
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -30.44747
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.13795
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.48053
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.71103
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.60950
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7067.07253
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.55830
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -17.96141
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.20239     1.09787     8.84184     2.88172
alpha_0                               1.23087     0.00643     1.24139     1.21984
alpha_1                               0.61927     0.00195     0.62268     0.61597
alpha_2                               0.65551     0.00153     0.65811     0.65293
alpha_3                               0.62028     0.00219     0.62394     0.61658
alpha_4                               0.64163     0.00200     0.64486     0.63829
alpha_5                               0.64468     0.00168     0.64755     0.64178
alpha_6                               0.63927     0.00136     0.64159     0.63700
alpha_7                               0.63949     0.00235     0.64332     0.63540
alpha_8                               0.62635     0.00205     0.62989     0.62305
alpha_9                               0.63148     0.00172     0.63428     0.62869
Alpha_loss                            -1.61851    0.20266     -1.23412    -1.95753
Training/policy_loss                  -86.60742   4.18299     -79.18572   -96.36295
Training/qf1_loss                     781.13471   261.97861   1421.34619  293.30746
Training/qf2_loss                     766.25444   261.48976   1405.23669  280.27292
Training/pf_norm                      3.23775     1.01972     6.43864     1.71646
Training/qf1_norm                     3150.53285  1488.11518  6646.15332  603.17242
Training/qf2_norm                     2988.81040  1580.51240  7832.41553  708.37537
log_std/mean                          -0.14853    0.02177     -0.12086    -0.20076
log_std/std                           0.26822     0.01247     0.28776     0.24186
log_std/max                           0.21279     0.01122     0.23265     0.19605
log_std/min                           -0.76468    0.04169     -0.67136    -0.83827
log_probs/mean                        1.32558     0.45622     2.14460     0.58577
log_probs/std                         5.23271     0.17934     5.59071     4.93711
log_probs/max                         14.76822    0.77816     16.54691    13.05596
log_probs/min                         -5.87174    1.22965     -4.11561    -11.22395
mean/mean                             0.11001     0.02331     0.15461     0.07148
mean/std                              1.33292     0.07385     1.45822     1.20185
mean/max                              3.12712     0.09595     3.33432     2.91557
mean/min                              -3.28448    0.09115     -3.03793    -3.43460
------------------------------------  ----------  ----------  ----------  ---------
sample: [4, 0, 1, 9, 2, 8, 5, 6, 7, 3]
replay_buffer._size: [5700 5700 5700 5700 5700 5700 5700 5700 5700 5700]
diff1,diff2 6.337893962860107 5.340576171875e-05
train_time 6.338017702102661
2023-09-06 12:28:09,546 MainThread INFO: EPOCH:36
2023-09-06 12:28:09,546 MainThread INFO: Time Consumed:6.34810471534729s
2023-09-06 12:28:09,546 MainThread INFO: Total Frames:55500s
 18%|â–ˆâ–Š        | 37/200 [03:59<17:08,  6.31s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               678.56270
Train_Epoch_Reward                    6923.25403
Running_Training_Average_Rewards      699.62715
Explore_Time                          0.00508
Train___Time                          6.33802
Eval____Time                          0.00443
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -40.50527
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.49083
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -36.67237
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.55278
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.38026
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.97270
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.07665
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7037.31358
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.46991
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.06382
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           4.95256     0.82534     7.14040     3.46946
alpha_0                               1.25145     0.00545     1.26102     1.24179
alpha_1                               0.61272     0.00189     0.61585     0.60957
alpha_2                               0.64931     0.00231     0.65283     0.64534
alpha_3                               0.61290     0.00210     0.61644     0.60937
alpha_4                               0.63484     0.00213     0.63818     0.63117
alpha_5                               0.63790     0.00241     0.64165     0.63373
alpha_6                               0.63383     0.00190     0.63690     0.63084
alpha_7                               0.63086     0.00252     0.63523     0.62682
alpha_8                               0.61970     0.00208     0.62294     0.61612
alpha_9                               0.62566     0.00189     0.62860     0.62252
Alpha_loss                            -1.86082    0.34179     -1.25111    -2.35444
Training/policy_loss                  -88.01218   4.41354     -79.26845   -97.38145
Training/qf1_loss                     737.22427   258.39190   1433.46423  268.81259
Training/qf2_loss                     720.04665   252.82415   1382.18152  264.78293
Training/pf_norm                      5.17790     1.86508     9.69634     2.24038
Training/qf1_norm                     2384.23557  1391.06499  8368.14062  621.35010
Training/qf2_norm                     2263.53815  1367.80991  8094.23975  537.90698
log_std/mean                          -0.10723    0.04232     -0.04270    -0.18464
log_std/std                           0.25729     0.02796     0.30752     0.21478
log_std/max                           0.29687     0.08531     0.43325     0.19504
log_std/min                           -0.70984    0.04367     -0.63036    -0.79644
log_probs/mean                        0.80273     0.89046     2.32942     -0.43407
log_probs/std                         4.93370     0.48092     5.68032     4.13499
log_probs/max                         15.11729    1.43074     18.24734    12.83023
log_probs/min                         -5.54572    1.02227     -4.13109    -8.97983
mean/mean                             0.11169     0.03897     0.18174     0.04976
mean/std                              1.23177     0.16437     1.48520     0.99782
mean/max                              3.17862     0.20266     3.55243     2.84772
mean/min                              -3.32647    0.20766     -2.98340    -3.73294
------------------------------------  ----------  ----------  ----------  ---------
sample: [1, 3, 2, 4, 6, 8, 0, 9, 5, 7]
replay_buffer._size: [5850 5850 5850 5850 5850 5850 5850 5850 5850 5850]
diff1,diff2 6.292261600494385 3.62396240234375e-05
train_time 6.2926695346832275
2023-09-06 12:28:16,051 MainThread INFO: EPOCH:37
2023-09-06 12:28:16,051 MainThread INFO: Time Consumed:6.304178714752197s
2023-09-06 12:28:16,051 MainThread INFO: Total Frames:57000s
 19%|â–ˆâ–‰        | 38/200 [04:06<17:12,  6.37s/it]------------------------------------  ----------  ----------  ----------  ---------
Name                                  Value
Running_Average_Rewards               679.07280
Train_Epoch_Reward                    6813.93058
Running_Training_Average_Rewards      703.14890
Explore_Time                          0.00666
Train___Time                          6.29267
Eval____Time                          0.00409
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.89882
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.26828
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -34.80502
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.46463
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.59796
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -26.40363
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.96155
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7022.01349
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.85129
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -12.91539
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.06358     1.03642     7.12577     2.44948
alpha_0                               1.26856     0.00380     1.27334     1.26142
alpha_1                               0.60610     0.00195     0.60943     0.60271
alpha_2                               0.64129     0.00220     0.64517     0.63752
alpha_3                               0.60534     0.00225     0.60922     0.60158
alpha_4                               0.62711     0.00224     0.63101     0.62317
alpha_5                               0.62922     0.00243     0.63354     0.62501
alpha_6                               0.62739     0.00191     0.63070     0.62407
alpha_7                               0.62240     0.00244     0.62665     0.61830
alpha_8                               0.61262     0.00185     0.61596     0.60950
alpha_9                               0.61861     0.00218     0.62237     0.61484
Alpha_loss                            -1.89213    0.22158     -1.49472    -2.32414
Training/policy_loss                  -90.55352   3.66208     -78.90539   -98.45860
Training/qf1_loss                     737.40409   294.76218   1621.63855  313.26837
Training/qf2_loss                     718.14106   289.35248   1586.15344  309.56418
Training/pf_norm                      3.79790     1.67344     8.84564     1.71178
Training/qf1_norm                     2609.04339  1543.20952  6176.88623  483.38596
Training/qf2_norm                     2493.83859  1503.97557  6095.16748  433.42734
log_std/mean                          -0.08098    0.02879     -0.03681    -0.13562
log_std/std                           0.24675     0.01891     0.28337     0.21258
log_std/max                           0.25368     0.01524     0.30023     0.22645
log_std/min                           -0.78246    0.04609     -0.68788    -0.87720
log_probs/mean                        0.37448     0.61906     1.60109     -0.58500
log_probs/std                         4.63455     0.31803     5.19620     3.94175
log_probs/max                         14.92568    1.59440     19.13931    12.54706
log_probs/min                         -5.55359    1.12087     -3.95706    -9.13540
mean/mean                             0.11513     0.03299     0.16604     0.04708
mean/std                              1.15280     0.11732     1.37648     0.95975
mean/max                              3.38057     0.26725     3.81514     2.89925
mean/min                              -3.54195    0.27251     -3.12521    -4.07808
------------------------------------  ----------  ----------  ----------  ---------
sample: [3, 4, 9, 2, 8, 7, 0, 6, 1, 5]
replay_buffer._size: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]
diff1,diff2 6.004291296005249 3.147125244140625e-05
train_time 6.00440526008606
2023-09-06 12:28:22,331 MainThread INFO: EPOCH:38
2023-09-06 12:28:22,332 MainThread INFO: Time Consumed:6.070670127868652s
2023-09-06 12:28:22,332 MainThread INFO: Total Frames:58500s
 20%|â–ˆâ–‰        | 39/200 [04:12<17:01,  6.35s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               678.65369
Train_Epoch_Reward                    6748.09904
Running_Training_Average_Rewards      682.84279
Explore_Time                          0.05653
Train___Time                          6.00441
Eval____Time                          0.00882
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.56264
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.64802
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.25809
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -20.42330
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.01893
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.06269
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.72540
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7064.42375
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.33363
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.75624
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.12951     1.00308     7.80605     3.33936
alpha_0                               1.26989     0.00184     1.27328     1.26787
alpha_1                               0.59840     0.00254     0.60256     0.59403
alpha_2                               0.63275     0.00296     0.63736     0.62747
alpha_3                               0.59742     0.00245     0.60144     0.59319
alpha_4                               0.61807     0.00305     0.62300     0.61277
alpha_5                               0.61969     0.00312     0.62482     0.61430
alpha_6                               0.61958     0.00277     0.62393     0.61466
alpha_7                               0.61346     0.00286     0.61813     0.60851
alpha_8                               0.60529     0.00253     0.60936     0.60088
alpha_9                               0.61015     0.00278     0.61468     0.60534
Alpha_loss                            -2.46103    0.20193     -1.96205    -2.73278
Training/policy_loss                  -97.12721   4.75327     -88.20814   -104.76257
Training/qf1_loss                     684.09506   261.48400   1380.53674  315.31989
Training/qf2_loss                     667.16937   258.27347   1351.24902  304.69635
Training/pf_norm                      6.76106     2.36427     11.35675    2.93388
Training/qf1_norm                     2138.99974  1116.71308  5885.31201  869.27374
Training/qf2_norm                     2207.86486  1127.64320  5074.22070  446.58054
log_std/mean                          -0.00533    0.02331     0.03078     -0.06826
log_std/std                           0.21030     0.02550     0.27381     0.17349
log_std/max                           0.43542     0.18890     0.75041     0.22354
log_std/min                           -1.37728    0.48446     -0.69464    -2.29692
log_probs/mean                        -1.13483    0.24483     -0.45765    -1.52732
log_probs/std                         4.03761     0.45008     5.08108     3.24662
log_probs/max                         28.54335    8.80296     40.72686    13.39366
log_probs/min                         -5.46213    0.79801     -4.26267    -8.52958
mean/mean                             0.01221     0.04282     0.10767     -0.05669
mean/std                              0.84061     0.06823     0.99614     0.71298
mean/max                              5.68204     1.25062     7.27474     3.46118
mean/min                              -5.96074    1.47768     -3.44594    -7.85951
------------------------------------  ----------  ----------  ----------  ----------
sample: [6, 5, 4, 7, 2, 1, 3, 0, 9, 8]
replay_buffer._size: [6150 6150 6150 6150 6150 6150 6150 6150 6150 6150]
diff1,diff2 6.261019945144653 1.9311904907226562e-05
train_time 6.261109828948975
2023-09-06 12:28:28,808 MainThread INFO: EPOCH:39
2023-09-06 12:28:28,808 MainThread INFO: Time Consumed:6.276791334152222s
2023-09-06 12:28:28,808 MainThread INFO: Total Frames:60000s
 20%|â–ˆâ–ˆ        | 40/200 [04:18<17:01,  6.39s/it]------------------------------------  ----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               694.82452
Train_Epoch_Reward                    6813.52866
Running_Training_Average_Rewards      679.18528
Explore_Time                          0.01115
Train___Time                          6.26111
Eval____Time                          0.00396
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.28138
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.02241
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -34.45101
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.86564
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.57533
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -28.70842
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.24506
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7526.34554
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.84150
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -14.10078
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max         Min
Reward_Mean                           5.48317     1.01763     7.73782     3.24926
alpha_0                               1.27696     0.00461     1.28477     1.26901
alpha_1                               0.58947     0.00260     0.59385     0.58512
alpha_2                               0.62171     0.00322     0.62724     0.61640
alpha_3                               0.58858     0.00264     0.59301     0.58411
alpha_4                               0.60714     0.00318     0.61255     0.60177
alpha_5                               0.60859     0.00323     0.61408     0.60316
alpha_6                               0.60921     0.00312     0.61444     0.60392
alpha_7                               0.60331     0.00293     0.60830     0.59838
alpha_8                               0.59609     0.00276     0.60069     0.59142
alpha_9                               0.60018     0.00294     0.60514     0.59524
Alpha_loss                            -2.79013    0.07688     -2.61824    -2.94229
Training/policy_loss                  -105.57775  4.23800     -97.32668   -116.62762
Training/qf1_loss                     562.44895   214.38229   1208.66907  231.61975
Training/qf2_loss                     547.96317   212.74058   1188.28711  225.17278
Training/pf_norm                      5.63753     3.00932     16.02173    1.92273
Training/qf1_norm                     2486.61482  1220.94745  6003.97412  729.02808
Training/qf2_norm                     2516.82665  1120.03140  5480.38867  812.71143
log_std/mean                          -0.04951    0.01851     -0.01907    -0.08094
log_std/std                           0.24631     0.01424     0.28378     0.22728
log_std/max                           0.48157     0.13126     0.72370     0.32245
log_std/min                           -1.59544    0.28576     -1.07690    -2.27618
log_probs/mean                        -0.83914    0.24598     -0.38528    -1.23442
log_probs/std                         4.49004     0.44116     5.27154     3.70236
log_probs/max                         33.62618    4.84320     39.76124    17.67695
log_probs/min                         -5.21381    1.00565     -3.88840    -8.77461
mean/mean                             -0.01892    0.01614     0.01527     -0.04905
mean/std                              0.92191     0.07625     1.05738     0.79294
mean/max                              6.58484     0.71606     7.55249     4.11781
mean/min                              -6.96843    0.76118     -4.33421    -7.97265
------------------------------------  ----------  ----------  ----------  ----------
sample: [2, 1, 3, 4, 7, 8, 0, 5, 9, 6]
replay_buffer._size: [6300 6300 6300 6300 6300 6300 6300 6300 6300 6300]
diff1,diff2 6.0961594581604 1.811981201171875e-05
train_time 6.09624171257019
snapshot at best
2023-09-06 12:28:36,165 MainThread INFO: EPOCH:40
2023-09-06 12:28:36,166 MainThread INFO: Time Consumed:7.179511547088623s
2023-09-06 12:28:36,166 MainThread INFO: Total Frames:61500s
 20%|â–ˆâ–ˆ        | 41/200 [04:26<17:40,  6.67s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1343.51043
Train_Epoch_Reward                    8515.71152
Running_Training_Average_Rewards      735.91131
Explore_Time                          0.00510
Train___Time                          6.09624
Eval____Time                          0.00497
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.71771
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.35129
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.37183
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.90721
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.43011
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.73323
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.31979
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 26474.17019
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.49747
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.41756
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           6.44664      1.49065     9.59864      3.11115
alpha_0                               1.29339      0.00520     1.30317      1.28513
alpha_1                               0.58059      0.00263     0.58495      0.57605
alpha_2                               0.61087      0.00320     0.61620      0.60541
alpha_3                               0.57944      0.00266     0.58392      0.57491
alpha_4                               0.59624      0.00313     0.60156      0.59094
alpha_5                               0.59762      0.00315     0.60294      0.59226
alpha_6                               0.59859      0.00305     0.60372      0.59334
alpha_7                               0.59337      0.00285     0.59818      0.58850
alpha_8                               0.58660      0.00278     0.59124      0.58184
alpha_9                               0.59013      0.00293     0.59505      0.58515
Alpha_loss                            -2.98875     0.11343     -2.75846     -3.12994
Training/policy_loss                  -113.49319   5.31254     -99.84412    -122.40331
Training/qf1_loss                     889.05423    406.05762   1960.10535   306.09192
Training/qf2_loss                     864.78234    396.73097   1919.23950   294.63855
Training/pf_norm                      5.18175      3.13665     14.75356     1.74895
Training/qf1_norm                     3290.51931   2243.10122  10514.07715  803.53522
Training/qf2_norm                     3182.03764   2201.95698  10443.70996  722.07770
log_std/mean                          -0.06055     0.01656     -0.03259     -0.08275
log_std/std                           0.22046      0.01072     0.24336      0.20543
log_std/max                           0.24332      0.07706     0.38785      0.17491
log_std/min                           -1.15859     0.18313     -0.73294     -1.38765
log_probs/mean                        -0.97272     0.11633     -0.68240     -1.15471
log_probs/std                         4.26092      0.29230     4.85869      3.66849
log_probs/max                         29.43643     4.73345     35.18655     16.68345
log_probs/min                         -4.72150     0.61307     -3.82869     -6.72943
mean/mean                             -0.08559     0.03850     -0.01976     -0.13755
mean/std                              0.87228      0.03437     0.93768      0.79303
mean/max                              6.00921      0.74192     6.85021      3.73045
mean/min                              -6.30773     0.80850     -3.84194     -7.23025
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 5, 2, 1, 0, 9, 4, 7, 6]
replay_buffer._size: [6450 6450 6450 6450 6450 6450 6450 6450 6450 6450]
diff1,diff2 5.456637859344482 4.8160552978515625e-05
train_time 5.456777811050415
snapshot at best
2023-09-06 12:28:42,615 MainThread INFO: EPOCH:41
2023-09-06 12:28:42,615 MainThread INFO: Time Consumed:6.344147205352783s
2023-09-06 12:28:42,615 MainThread INFO: Total Frames:63000s
 21%|â–ˆâ–ˆ        | 42/200 [04:32<17:24,  6.61s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               3121.29602
Train_Epoch_Reward                    32006.27934
Running_Training_Average_Rewards      1577.85065
Explore_Time                          0.00394
Train___Time                          5.45678
Eval____Time                          0.00422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.30382
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.43509
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.50734
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -18.19526
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -17.79468
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -23.32615
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.87186
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 60387.73830
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.82179
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -19.27975
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max         Min
Reward_Mean                           6.83365      1.09664     8.75888     3.70957
alpha_0                               1.31526      0.00679     1.32668     1.30364
alpha_1                               0.57132      0.00264     0.57586     0.56690
alpha_2                               0.59987      0.00311     0.60519     0.59465
alpha_3                               0.57025      0.00261     0.57473     0.56584
alpha_4                               0.58559      0.00300     0.59073     0.58053
alpha_5                               0.58684      0.00304     0.59205     0.58171
alpha_6                               0.58792      0.00304     0.59313     0.58281
alpha_7                               0.58346      0.00285     0.58831     0.57864
alpha_8                               0.57704      0.00269     0.58165     0.57252
alpha_9                               0.58004      0.00286     0.58495     0.57525
Alpha_loss                            -3.10603     0.04113     -2.97805    -3.17834
Training/policy_loss                  -123.74654   3.63833     -113.86092  -132.56493
Training/qf1_loss                     994.91715    336.51289   2043.36804  535.22839
Training/qf2_loss                     970.21755    330.36719   1983.39771  527.43335
Training/pf_norm                      7.64725      4.25156     18.36902    1.56430
Training/qf1_norm                     2809.21467   1378.26244  7554.54346  738.66876
Training/qf2_norm                     2694.96304   1375.84976  7535.30811  1004.95795
log_std/mean                          -0.07446     0.00901     -0.05985    -0.09727
log_std/std                           0.23665      0.00458     0.24813     0.22667
log_std/max                           0.19858      0.01100     0.21828     0.17512
log_std/min                           -1.28387     0.11569     -0.91503    -1.50952
log_probs/mean                        -0.85655     0.09578     -0.61119    -1.08366
log_probs/std                         4.52401      0.16763     4.97600     4.22025
log_probs/max                         31.37008     4.17681     39.44152    19.43454
log_probs/min                         -5.18491     1.24868     -3.85261    -10.40257
mean/mean                             -0.09014     0.00936     -0.07089    -0.11489
mean/std                              0.89806      0.02502     0.95829     0.83592
mean/max                              6.26424      0.63082     7.53176     4.37327
mean/min                              -6.74062     0.65912     -4.69216    -8.07608
------------------------------------  -----------  ----------  ----------  ----------
sample: [1, 7, 8, 2, 6, 4, 3, 0, 9, 5]
replay_buffer._size: [6600 6600 6600 6600 6600 6600 6600 6600 6600 6600]
diff1,diff2 5.321828365325928 1.9073486328125e-05
train_time 5.321892976760864
2023-09-06 12:28:48,094 MainThread INFO: EPOCH:42
2023-09-06 12:28:48,095 MainThread INFO: Time Consumed:5.333359479904175s
2023-09-06 12:28:48,095 MainThread INFO: Total Frames:64500s
 22%|â–ˆâ–ˆâ–       | 43/200 [04:38<16:25,  6.27s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               3797.23996
Train_Epoch_Reward                    82325.41269
Running_Training_Average_Rewards      4094.91345
Explore_Time                          0.00523
Train___Time                          5.32189
Eval____Time                          0.00524
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.63754
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.00732
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.02060
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.94246
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -20.59509
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -30.76366
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.46629
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 27824.62565
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.91694
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.70339
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.04953      1.28234     9.76912     4.38609
alpha_0                               1.33898      0.00712     1.35082     1.32712
alpha_1                               0.56240      0.00250     0.56672     0.55839
alpha_2                               0.58932      0.00296     0.59444     0.58447
alpha_3                               0.56126      0.00258     0.56566     0.55694
alpha_4                               0.57532      0.00293     0.58032     0.57039
alpha_5                               0.57652      0.00286     0.58151     0.57187
alpha_6                               0.57756      0.00293     0.58260     0.57273
alpha_7                               0.57371      0.00277     0.57844     0.56911
alpha_8                               0.56784      0.00261     0.57234     0.56359
alpha_9                               0.57037      0.00272     0.57505     0.56596
Alpha_loss                            -3.09185     0.18791     -2.68756    -3.35249
Training/policy_loss                  -130.58076   3.53332     -122.43439  -141.21428
Training/qf1_loss                     1028.00366   456.65466   2532.78296  289.45245
Training/qf2_loss                     1000.20859   449.75296   2474.85962  273.09738
Training/pf_norm                      8.80129      6.60982     28.15060    2.32085
Training/qf1_norm                     3593.36474   2075.51147  9665.05371  1024.54700
Training/qf2_norm                     3432.51174   2015.42038  9246.45020  882.85205
log_std/mean                          -0.10799     0.01825     -0.06606    -0.13948
log_std/std                           0.24100      0.00979     0.25724     0.22236
log_std/max                           0.18200      0.00559     0.19551     0.16700
log_std/min                           -1.40620     0.24880     -0.80375    -1.82434
log_probs/mean                        -0.60766     0.35217     0.20137     -1.12419
log_probs/std                         4.75100      0.29885     5.23633     4.17807
log_probs/max                         32.83990     6.27288     41.64531    14.20616
log_probs/min                         -5.13292     0.96570     -3.87549    -8.44864
mean/mean                             -0.06290     0.03334     0.00385     -0.10650
mean/std                              0.96193      0.07812     1.11569     0.81673
mean/max                              6.49792      1.03263     8.06714     3.64045
mean/min                              -7.04631     1.12951     -3.89884    -8.75746
------------------------------------  -----------  ----------  ----------  ----------
sample: [3, 0, 4, 9, 8, 7, 2, 6, 1, 5]
replay_buffer._size: [6750 6750 6750 6750 6750 6750 6750 6750 6750 6750]
diff1,diff2 6.420212745666504 3.075599670410156e-05
train_time 6.42034125328064
2023-09-06 12:28:54,872 MainThread INFO: EPOCH:43
2023-09-06 12:28:54,872 MainThread INFO: Time Consumed:6.432816028594971s
2023-09-06 12:28:54,872 MainThread INFO: Total Frames:66000s
 22%|â–ˆâ–ˆâ–       | 44/200 [04:44<16:41,  6.42s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               3584.75049
Train_Epoch_Reward                    36110.28963
Running_Training_Average_Rewards      5014.73272
Explore_Time                          0.00684
Train___Time                          6.42034
Eval____Time                          0.00489
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.44307
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.77590
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.19472
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.59143
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -14.66602
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.81153
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.32478
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20101.40693
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.25145
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -25.60817
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.33238      1.29698     10.87080    4.20347
alpha_0                               1.36250      0.00666     1.37419     1.35130
alpha_1                               0.55431      0.00241     0.55825     0.55015
alpha_2                               0.58003      0.00255     0.58430     0.57563
alpha_3                               0.55265      0.00242     0.55677     0.54857
alpha_4                               0.56538      0.00284     0.57020     0.56057
alpha_5                               0.56723      0.00269     0.57170     0.56264
alpha_6                               0.56805      0.00266     0.57255     0.56354
alpha_7                               0.56450      0.00263     0.56893     0.56001
alpha_8                               0.55941      0.00242     0.56343     0.55526
alpha_9                               0.56143      0.00266     0.56580     0.55686
Alpha_loss                            -3.16300     0.10446     -2.89357    -3.32387
Training/policy_loss                  -135.30902   4.55344     -124.75451  -144.96666
Training/qf1_loss                     1066.60696   428.56544   2254.13818  497.93332
Training/qf2_loss                     1037.50674   422.52586   2195.84961  482.34030
Training/pf_norm                      7.78780      5.77492     21.93402    1.58810
Training/qf1_norm                     3499.94188   1955.33989  9019.11914  946.38226
Training/qf2_norm                     3336.77878   1905.52350  8402.69434  804.23242
log_std/mean                          -0.09031     0.01197     -0.07234    -0.11734
log_std/std                           0.24914      0.00794     0.26106     0.23239
log_std/max                           0.21090      0.01326     0.23307     0.18435
log_std/min                           -1.24044     0.19131     -0.82879    -1.56379
log_probs/mean                        -0.60632     0.13996     -0.22793    -0.90520
log_probs/std                         4.66819      0.23529     5.17021     4.19704
log_probs/max                         29.96440     5.09653     38.54387    17.16075
log_probs/min                         -5.21332     0.98619     -3.95670    -7.90213
mean/mean                             -0.06171     0.01594     -0.02665    -0.09020
mean/std                              0.95901      0.03414     1.05616     0.87997
mean/max                              5.87081      0.76935     7.01750     3.85583
mean/min                              -6.38392     0.85667     -4.17298    -7.68459
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 8, 2, 6, 5, 0, 9, 1, 7, 3]
replay_buffer._size: [6900 6900 6900 6900 6900 6900 6900 6900 6900 6900]
diff1,diff2 6.405756711959839 2.86102294921875e-05
train_time 6.405859470367432
2023-09-06 12:29:01,426 MainThread INFO: EPOCH:44
2023-09-06 12:29:01,426 MainThread INFO: Time Consumed:6.418791055679321s
2023-09-06 12:29:01,426 MainThread INFO: Total Frames:67500s
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [04:51<16:40,  6.46s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2391.69252
Train_Epoch_Reward                    19363.94755
Running_Training_Average_Rewards      4593.32166
Explore_Time                          0.00573
Train___Time                          6.40586
Eval____Time                          0.00515
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.61793
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.59960
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.60852
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.78754
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.81799
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -21.77842
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.28531
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 24610.40294
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.32074
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -22.12351
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.32627      1.27159     9.67717     3.90309
alpha_0                               1.38553      0.00631     1.39606     1.37467
alpha_1                               0.54576      0.00251     0.54998     0.54142
alpha_2                               0.57110      0.00259     0.57544     0.56653
alpha_3                               0.54439      0.00239     0.54840     0.54029
alpha_4                               0.55565      0.00277     0.56038     0.55095
alpha_5                               0.55796      0.00266     0.56245     0.55337
alpha_6                               0.55891      0.00266     0.56335     0.55429
alpha_7                               0.55543      0.00259     0.55983     0.55098
alpha_8                               0.55103      0.00244     0.55509     0.54672
alpha_9                               0.55210      0.00269     0.55667     0.54751
Alpha_loss                            -3.32348     0.17115     -2.97758    -3.52851
Training/policy_loss                  -140.84774   4.26448     -126.93829  -149.28673
Training/qf1_loss                     1132.65831   413.90459   2302.34888  395.78674
Training/qf2_loss                     1102.34582   407.87861   2258.82788  392.13416
Training/pf_norm                      6.59969      5.38398     34.30242    2.15607
Training/qf1_norm                     3624.38182   1905.81532  9136.03809  1082.22864
Training/qf2_norm                     3454.18384   1816.80675  9208.03906  1033.97827
log_std/mean                          -0.11134     0.02667     -0.07099    -0.15125
log_std/std                           0.23007      0.00517     0.23857     0.21746
log_std/max                           0.20824      0.02621     0.25394     0.17421
log_std/min                           -0.92505     0.07160     -0.72810    -1.03468
log_probs/mean                        -0.82010     0.27567     -0.28397    -1.20391
log_probs/std                         4.27744      0.24113     4.76682     3.86934
log_probs/max                         21.09724     3.15692     27.59769    13.71118
log_probs/min                         -5.16730     1.01770     -3.99869    -9.07163
mean/mean                             -0.05939     0.03465     -0.00026    -0.11505
mean/std                              0.89205      0.07138     1.00787     0.79302
mean/max                              4.53898      0.43395     5.31331     3.30596
mean/min                              -4.83267     0.46268     -3.47312    -5.70130
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 9, 2, 1, 6, 7, 4, 3, 8, 0]
replay_buffer._size: [7050 7050 7050 7050 7050 7050 7050 7050 7050 7050]
diff1,diff2 6.353496789932251 1.811981201171875e-05
train_time 6.353589296340942
2023-09-06 12:29:07,995 MainThread INFO: EPOCH:45
2023-09-06 12:29:07,995 MainThread INFO: Time Consumed:6.373295783996582s
2023-09-06 12:29:07,995 MainThread INFO: Total Frames:69000s
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [04:57<16:40,  6.50s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2497.16286
Train_Epoch_Reward                    25596.87837
Running_Training_Average_Rewards      2702.37052
Explore_Time                          0.01459
Train___Time                          6.35359
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.59472
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.29659
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.21584
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.43079
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -13.24620
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -19.45281
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.57791
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 30952.40268
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.36994
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -23.53538
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.95916      1.28280     11.28216    5.03521
alpha_0                               1.40649      0.00591     1.41655     1.39646
alpha_1                               0.53691      0.00250     0.54124     0.53274
alpha_2                               0.56158      0.00279     0.56634     0.55685
alpha_3                               0.53607      0.00236     0.54012     0.53210
alpha_4                               0.54618      0.00268     0.55076     0.54163
alpha_5                               0.54863      0.00267     0.55318     0.54410
alpha_6                               0.54945      0.00271     0.55410     0.54490
alpha_7                               0.54638      0.00258     0.55080     0.54204
alpha_8                               0.54212      0.00258     0.54653     0.53775
alpha_9                               0.54275      0.00267     0.54732     0.53826
Alpha_loss                            -3.45019     0.04537     -3.35951    -3.53986
Training/policy_loss                  -147.43827   3.92576     -139.01015  -155.46878
Training/qf1_loss                     1367.30547   465.64904   2444.02222  399.78146
Training/qf2_loss                     1332.68467   456.93676   2354.56421  383.85727
Training/pf_norm                      8.87340      6.46221     33.67464    1.82427
Training/qf1_norm                     3688.50772   2265.26810  9785.94141  1139.52344
Training/qf2_norm                     3471.83902   2155.49484  9898.03027  991.54175
log_std/mean                          -0.11740     0.01166     -0.10201    -0.13934
log_std/std                           0.22722      0.00399     0.23565     0.21907
log_std/max                           0.20480      0.01091     0.21815     0.18574
log_std/min                           -0.88098     0.08645     -0.75358    -1.02090
log_probs/mean                        -0.90932     0.08673     -0.65788    -1.03933
log_probs/std                         4.22232      0.16751     4.68324     3.93049
log_probs/max                         19.01470     3.56035     26.93008    13.04477
log_probs/min                         -5.26644     0.84760     -4.06521    -7.09757
mean/mean                             -0.03637     0.00787     -0.01806    -0.05179
mean/std                              0.87828      0.02477     0.94185     0.84424
mean/max                              4.16059      0.52404     5.08492     2.91421
mean/min                              -4.52907     0.57174     -3.20026    -5.53117
------------------------------------  -----------  ----------  ----------  ----------
sample: [5, 6, 1, 4, 3, 7, 0, 9, 8, 2]
replay_buffer._size: [7200 7200 7200 7200 7200 7200 7200 7200 7200 7200]
diff1,diff2 6.457826137542725 1.8596649169921875e-05
train_time 6.457909345626831
2023-09-06 12:29:14,661 MainThread INFO: EPOCH:46
2023-09-06 12:29:14,662 MainThread INFO: Time Consumed:6.484044075012207s
2023-09-06 12:29:14,662 MainThread INFO: Total Frames:70500s
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [05:04<16:42,  6.55s/it]------------------------------------  -----------  ----------  ----------  ----------
Name                                  Value
Running_Average_Rewards               2586.59869
Train_Epoch_Reward                    27846.86165
Running_Training_Average_Rewards      2426.92292
Explore_Time                          0.01992
Train___Time                          6.45791
Eval____Time                          0.00568
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.01871
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.52094
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.88277
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.32250
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.47053
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -30.97860
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.63074
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 22790.43831
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.77938
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.01924
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max         Min
Reward_Mean                           7.84061      1.33396     11.21230    4.84932
alpha_0                               1.42689      0.00581     1.43652     1.41695
alpha_1                               0.52835      0.00250     0.53258     0.52414
alpha_2                               0.55199      0.00272     0.55666     0.54740
alpha_3                               0.52797      0.00235     0.53194     0.52396
alpha_4                               0.53695      0.00264     0.54145     0.53250
alpha_5                               0.53942      0.00263     0.54392     0.53496
alpha_6                               0.54025      0.00263     0.54472     0.53579
alpha_7                               0.53754      0.00254     0.54186     0.53323
alpha_8                               0.53323      0.00253     0.53757     0.52896
alpha_9                               0.53362      0.00262     0.53808     0.52919
Alpha_loss                            -3.59082     0.06785     -3.46891    -3.72997
Training/policy_loss                  -151.78550   4.18071     -138.60616  -159.92664
Training/qf1_loss                     1229.09185   403.47373   2552.94775  412.16855
Training/qf2_loss                     1194.02833   395.79106   2477.95312  396.57516
Training/pf_norm                      9.38466      7.25042     38.94026    1.37533
Training/qf1_norm                     3756.31446   1994.93074  9972.98145  1167.58997
Training/qf2_norm                     3688.72577   1878.85460  9391.39258  1268.82019
log_std/mean                          -0.11754     0.00706     -0.10169    -0.12915
log_std/std                           0.22099      0.00458     0.22909     0.21029
log_std/max                           0.20722      0.01316     0.23108     0.18788
log_std/min                           -0.80453     0.02008     -0.75939    -0.84285
log_probs/mean                        -1.01915     0.08288     -0.83987    -1.18814
log_probs/std                         4.04294      0.12218     4.31472     3.79254
log_probs/max                         15.55176     2.24056     20.60194    12.75585
log_probs/min                         -5.12074     0.73334     -3.97554    -8.02263
mean/mean                             -0.03544     0.01649     -0.00519    -0.07053
mean/std                              0.84440      0.02078     0.88716     0.79839
mean/max                              3.63330      0.34899     4.37691     2.89484
mean/min                              -3.89990     0.38225     -3.09037    -4.71923
------------------------------------  -----------  ----------  ----------  ----------
sample: [4, 0, 3, 2, 5, 8, 9, 1, 6, 7]
replay_buffer._size: [7350 7350 7350 7350 7350 7350 7350 7350 7350 7350]
diff1,diff2 6.465594053268433 1.8596649169921875e-05
train_time 6.46568751335144
2023-09-06 12:29:21,312 MainThread INFO: EPOCH:47
2023-09-06 12:29:21,312 MainThread INFO: Time Consumed:6.482539415359497s
2023-09-06 12:29:21,312 MainThread INFO: Total Frames:72000s
 24%|â–ˆâ–ˆâ–       | 48/200 [05:11<16:39,  6.57s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2559.16515
Train_Epoch_Reward                    26574.73209
Running_Training_Average_Rewards      2667.28240
Explore_Time                          0.00907
Train___Time                          6.46569
Eval____Time                          0.00686
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.88736
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.45347
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.09319
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.56360
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -12.39906
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -20.42791
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.66982
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 23775.38980
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.52618
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.91200
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.21519      1.48576     12.36926     5.20801
alpha_0                               1.44657      0.00570     1.45623      1.43691
alpha_1                               0.51978      0.00247     0.52397      0.51562
alpha_2                               0.54260      0.00273     0.54722      0.53798
alpha_3                               0.51969      0.00242     0.52379      0.51558
alpha_4                               0.52791      0.00258     0.53232      0.52354
alpha_5                               0.53033      0.00261     0.53477      0.52591
alpha_6                               0.53111      0.00266     0.53561      0.52660
alpha_7                               0.52872      0.00254     0.53305      0.52443
alpha_8                               0.52448      0.00254     0.52879      0.52016
alpha_9                               0.52457      0.00261     0.52901      0.52013
Alpha_loss                            -3.76767     0.05411     -3.66678     -3.87828
Training/policy_loss                  -157.12869   4.05794     -148.85258   -168.16451
Training/qf1_loss                     1438.41046   491.44877   2776.71680   574.31830
Training/qf2_loss                     1396.98023   479.79150   2679.90015   547.54688
Training/pf_norm                      8.33200      5.58419     26.51976     2.28375
Training/qf1_norm                     4598.58874   2943.96772  12102.28516  1425.85974
Training/qf2_norm                     4397.44080   2586.46120  10958.22852  1307.25342
log_std/mean                          -0.10917     0.01296     -0.08662     -0.13577
log_std/std                           0.22844      0.00503     0.24097      0.21656
log_std/max                           0.22680      0.01098     0.24907      0.21264
log_std/min                           -0.91628     0.04269     -0.83559     -0.98237
log_probs/mean                        -1.15428     0.06907     -1.03011     -1.34306
log_probs/std                         3.90294      0.14391     4.14347      3.57359
log_probs/max                         14.53892     1.64365     18.19885     12.19645
log_probs/min                         -5.06380     0.72555     -3.92175     -6.81931
mean/mean                             -0.09021     0.01341     -0.04950     -0.10789
mean/std                              0.80579      0.02146     0.84370      0.76019
mean/max                              3.40282      0.35880     3.95412      2.69838
mean/min                              -3.68298     0.38217     -2.95483     -4.27528
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 2, 5, 6, 4, 1, 8, 0, 7, 3]
replay_buffer._size: [7500 7500 7500 7500 7500 7500 7500 7500 7500 7500]
diff1,diff2 6.445973634719849 1.8358230590820312e-05
train_time 6.4460625648498535
2023-09-06 12:29:27,996 MainThread INFO: EPOCH:48
2023-09-06 12:29:27,996 MainThread INFO: Time Consumed:6.471027612686157s
2023-09-06 12:29:27,996 MainThread INFO: Total Frames:73500s
 24%|â–ˆâ–ˆâ–       | 49/200 [05:18<16:38,  6.61s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2450.33174
Train_Epoch_Reward                    22241.83425
Running_Training_Average_Rewards      2555.44760
Explore_Time                          0.02036
Train___Time                          6.44606
Eval____Time                          0.00407
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.29038
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.98227
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.39637
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.32154
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -10.28184
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -2.53824
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.68486
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 27684.52546
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.42582
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -29.92406
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.47720      1.30340     12.25385     6.03381
alpha_0                               1.46624      0.00559     1.47562      1.45663
alpha_1                               0.51130      0.00246     0.51545      0.50713
alpha_2                               0.53324      0.00267     0.53779      0.52873
alpha_3                               0.51136      0.00238     0.51541      0.50734
alpha_4                               0.51908      0.00252     0.52337      0.51484
alpha_5                               0.52132      0.00260     0.52573      0.51690
alpha_6                               0.52197      0.00261     0.52642      0.51756
alpha_7                               0.52001      0.00249     0.52425      0.51580
alpha_8                               0.51569      0.00253     0.51999      0.51140
alpha_9                               0.51558      0.00257     0.51995      0.51123
Alpha_loss                            -3.88688     0.05159     -3.78440     -3.99712
Training/policy_loss                  -163.59301   3.13682     -156.53569   -170.31783
Training/qf1_loss                     1557.95641   408.32161   2581.55786   782.72180
Training/qf2_loss                     1509.96492   407.57582   2521.82812   758.19745
Training/pf_norm                      5.66146      3.56506     18.04559     1.63827
Training/qf1_norm                     4443.66381   2134.14017  11857.01660  1602.52112
Training/qf2_norm                     3963.42123   2268.89309  11782.97070  765.69623
log_std/mean                          -0.11762     0.00992     -0.09840     -0.13723
log_std/std                           0.21043      0.00697     0.22827      0.20006
log_std/max                           0.22622      0.01273     0.25342      0.20781
log_std/min                           -0.88575     0.05375     -0.74286     -0.96059
log_probs/mean                        -1.21899     0.08309     -1.07962     -1.38377
log_probs/std                         3.77852      0.16326     4.04321      3.40370
log_probs/max                         13.56366     1.03261     16.40976     11.77085
log_probs/min                         -5.16372     0.72376     -4.06549     -7.61960
mean/mean                             -0.06176     0.02263     -0.02743     -0.10490
mean/std                              0.79605      0.02681     0.84668      0.73140
mean/max                              3.24928      0.22430     3.84397      2.85147
mean/min                              -3.46541     0.25255     -2.99502     -4.13451
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 4, 1, 5, 6, 3, 7, 8, 2, 9]
replay_buffer._size: [7650 7650 7650 7650 7650 7650 7650 7650 7650 7650]
diff1,diff2 6.34815526008606 1.9311904907226562e-05
train_time 6.3482506275177
2023-09-06 12:29:34,517 MainThread INFO: EPOCH:49
2023-09-06 12:29:34,517 MainThread INFO: Time Consumed:6.359063625335693s
2023-09-06 12:29:34,517 MainThread INFO: Total Frames:75000s
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [05:24<16:27,  6.58s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2318.06100
Train_Epoch_Reward                    25851.91970
Running_Training_Average_Rewards      2488.94953
Explore_Time                          0.00489
Train___Time                          6.34825
Eval____Time                          0.00502
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.47092
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.21149
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.55029
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.63406
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -11.17123
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -10.31220
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.21690
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18789.30064
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.35049
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -31.69032
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.35814      1.42739     11.40424     5.66980
alpha_0                               1.48572      0.00577     1.49575      1.47600
alpha_1                               0.50289      0.00239     0.50696      0.49883
alpha_2                               0.52412      0.00261     0.52855      0.51969
alpha_3                               0.50318      0.00235     0.50717      0.49920
alpha_4                               0.51051      0.00244     0.51467      0.50637
alpha_5                               0.51237      0.00255     0.51672      0.50806
alpha_6                               0.51304      0.00255     0.51738      0.50872
alpha_7                               0.51148      0.00243     0.51563      0.50734
alpha_8                               0.50706      0.00243     0.51123      0.50293
alpha_9                               0.50678      0.00251     0.51106      0.50254
Alpha_loss                            -4.00580     0.07225     -3.88361     -4.14102
Training/policy_loss                  -167.34020   4.29824     -157.99629   -178.95561
Training/qf1_loss                     1540.71169   554.09780   3489.19312   713.74115
Training/qf2_loss                     1501.57829   541.82098   3387.02905   695.45782
Training/pf_norm                      4.90785      2.93654     19.35648     1.87339
Training/qf1_norm                     5589.09612   3536.13237  15932.00879  1049.34460
Training/qf2_norm                     5697.16306   3699.41358  15242.63379  944.38165
log_std/mean                          -0.11107     0.00702     -0.09857     -0.12853
log_std/std                           0.19967      0.00906     0.21532      0.18437
log_std/max                           0.23256      0.00934     0.25103      0.21874
log_std/min                           -0.79582     0.06727     -0.66661     -0.94049
log_probs/mean                        -1.21095     0.06831     -1.07611     -1.39783
log_probs/std                         3.80092      0.12863     4.07232      3.51845
log_probs/max                         13.69434     0.92513     16.37910     12.31815
log_probs/min                         -5.03132     0.68316     -3.88012     -7.15423
mean/mean                             -0.04391     0.05355     0.03449      -0.14772
mean/std                              0.79935      0.02376     0.85170      0.72942
mean/max                              3.18205      0.18898     3.60517      2.86029
mean/min                              -3.40130     0.22990     -3.06059     -3.90917
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 1, 5, 6, 8, 7, 0, 3, 4, 9]
replay_buffer._size: [7800 7800 7800 7800 7800 7800 7800 7800 7800 7800]
diff1,diff2 6.732863664627075 6.0558319091796875e-05
train_time 6.733000993728638
2023-09-06 12:29:41,482 MainThread INFO: EPOCH:50
2023-09-06 12:29:41,483 MainThread INFO: Time Consumed:6.74980902671814s
2023-09-06 12:29:41,483 MainThread INFO: Total Frames:76500s
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [05:31<16:36,  6.69s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2156.47242
Train_Epoch_Reward                    19889.84052
Running_Training_Average_Rewards      2266.11982
Explore_Time                          0.01095
Train___Time                          6.73300
Eval____Time                          0.00519
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.15216
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -49.65914
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.62322
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.35647
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -15.99254
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            88.58112
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  359.96727
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18469.24390
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -31.02637
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.18264
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.66033      1.42732     12.45725     5.54262
alpha_0                               1.50558      0.00539     1.51486      1.49617
alpha_1                               0.49467      0.00233     0.49866      0.49071
alpha_2                               0.51514      0.00254     0.51951      0.51084
alpha_3                               0.49515      0.00227     0.49904      0.49132
alpha_4                               0.50208      0.00242     0.50620      0.49799
alpha_5                               0.50363      0.00250     0.50788      0.49940
alpha_6                               0.50430      0.00250     0.50855      0.50007
alpha_7                               0.50306      0.00239     0.50717      0.49902
alpha_8                               0.49860      0.00245     0.50276      0.49445
alpha_9                               0.49822      0.00244     0.50237      0.49410
Alpha_loss                            -4.09632     0.05480     -3.98712     -4.20623
Training/policy_loss                  -172.55722   4.23817     -164.17839   -182.78064
Training/qf1_loss                     1604.63116   518.58944   2770.04541   629.00726
Training/qf2_loss                     1551.54923   502.00013   2632.14551   617.72736
Training/pf_norm                      5.64138      3.36482     18.44321     2.43048
Training/qf1_norm                     5541.93484   3080.72290  13799.39746  802.34143
Training/qf2_norm                     5230.14297   2857.44616  12652.02637  1328.16980
log_std/mean                          -0.11980     0.00499     -0.11222     -0.13013
log_std/std                           0.20754      0.00705     0.22013      0.19658
log_std/max                           0.21883      0.04964     0.36427      0.17206
log_std/min                           -0.97380     0.04584     -0.87484     -1.04348
log_probs/mean                        -1.26374     0.06009     -1.10491     -1.42618
log_probs/std                         3.67460      0.10689     3.87839      3.44405
log_probs/max                         12.75969     0.51133     14.14217     11.77055
log_probs/min                         -5.20485     0.75270     -4.12973     -7.60640
mean/mean                             -0.12058     0.02703     -0.07475     -0.16203
mean/std                              0.77165      0.02170     0.83842      0.72973
mean/max                              2.98216      0.13490     3.31191      2.73423
mean/min                              -3.17271     0.15245     -2.91638     -3.55112
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 2, 6, 1, 5, 7, 8, 9, 0]
replay_buffer._size: [7950 7950 7950 7950 7950 7950 7950 7950 7950 7950]
diff1,diff2 6.642232894897461 1.9550323486328125e-05
train_time 6.6423234939575195
2023-09-06 12:29:48,332 MainThread INFO: EPOCH:51
2023-09-06 12:29:48,332 MainThread INFO: Time Consumed:6.653866529464722s
2023-09-06 12:29:48,332 MainThread INFO: Total Frames:78000s
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [05:38<16:37,  6.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1832.77482
Train_Epoch_Reward                    20552.42710
Running_Training_Average_Rewards      2209.80624
Explore_Time                          0.00446
Train___Time                          6.64232
Eval____Time                          0.00650
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.31388
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.31957
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.46381
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.10754
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -10.32330
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -25.55333
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  449.74747
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17541.66191
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.39705
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.17881
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.37744      1.18795     11.32117     5.92345
alpha_0                               1.52494      0.00568     1.53443      1.51526
alpha_1                               0.48659      0.00232     0.49055      0.48268
alpha_2                               0.50645      0.00245     0.51066      0.50235
alpha_3                               0.48736      0.00223     0.49117      0.48358
alpha_4                               0.49377      0.00238     0.49783      0.48974
alpha_5                               0.49510      0.00242     0.49923      0.49100
alpha_6                               0.49576      0.00241     0.49990      0.49170
alpha_7                               0.49484      0.00236     0.49886      0.49084
alpha_8                               0.49021      0.00240     0.49429      0.48614
alpha_9                               0.48991      0.00236     0.49394      0.48591
Alpha_loss                            -4.20240     0.06303     -4.08064     -4.34858
Training/policy_loss                  -175.06372   4.05658     -163.72488   -183.75604
Training/qf1_loss                     1630.96908   392.14095   2544.84448   893.59320
Training/qf2_loss                     1580.83813   384.30578   2492.55835   846.26428
Training/pf_norm                      4.84309      2.42748     15.39132     1.52063
Training/qf1_norm                     4142.24789   2571.79771  12460.62305  1102.68518
Training/qf2_norm                     4105.69705   2554.50200  11625.98633  926.86218
log_std/mean                          -0.12930     0.00462     -0.12173     -0.13841
log_std/std                           0.20512      0.01039     0.22109      0.19054
log_std/max                           0.30959      0.08517     0.44867      0.21957
log_std/min                           -0.95621     0.10599     -0.78406     -1.12127
log_probs/mean                        -1.26945     0.08161     -1.04543     -1.45526
log_probs/std                         3.65757      0.16122     3.98971      3.39754
log_probs/max                         13.13198     0.91100     15.18416     11.49431
log_probs/min                         -5.39409     0.73621     -4.34928     -7.98899
mean/mean                             -0.12301     0.03178     -0.07467     -0.17335
mean/std                              0.77170      0.02460     0.84128      0.72927
mean/max                              2.98353      0.13834     3.25797      2.70932
mean/min                              -3.23250     0.16861     -2.86909     -3.56293
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 6, 2, 5, 4, 3, 7, 1, 9]
replay_buffer._size: [8100 8100 8100 8100 8100 8100 8100 8100 8100 8100]
diff1,diff2 6.4684460163116455 3.3855438232421875e-05
train_time 6.468555212020874
2023-09-06 12:29:54,962 MainThread INFO: EPOCH:52
2023-09-06 12:29:54,962 MainThread INFO: Time Consumed:6.4811623096466064s
2023-09-06 12:29:54,962 MainThread INFO: Total Frames:79500s
 26%|â–ˆâ–ˆâ–‹       | 53/200 [05:44<16:27,  6.72s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1533.06295
Train_Epoch_Reward                    18170.45674
Running_Training_Average_Rewards      1953.75748
Explore_Time                          0.00603
Train___Time                          6.46856
Eval____Time                          0.00604
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.61068
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.82049
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.33273
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.58234
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -7.67242
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -7.75147
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  931.98471
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8852.73367
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.89060
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.72111
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.30095      1.44127     10.63879     4.42954
alpha_0                               1.54467      0.00586     1.55473      1.53481
alpha_1                               0.47861      0.00230     0.48253      0.47471
alpha_2                               0.49802      0.00244     0.50218      0.49391
alpha_3                               0.47960      0.00224     0.48342      0.47581
alpha_4                               0.48559      0.00233     0.48958      0.48164
alpha_5                               0.48678      0.00237     0.49083      0.48277
alpha_6                               0.48749      0.00237     0.49153      0.48349
alpha_7                               0.48669      0.00234     0.49068      0.48272
alpha_8                               0.48195      0.00236     0.48598      0.47795
alpha_9                               0.48176      0.00234     0.48575      0.47780
Alpha_loss                            -4.36542     0.06327     -4.20765     -4.47929
Training/policy_loss                  -179.96600   4.20599     -170.04291   -188.29561
Training/qf1_loss                     1717.57852   549.17112   2813.78931   661.40997
Training/qf2_loss                     1656.72635   540.66837   2726.34106   597.26434
Training/pf_norm                      4.38491      2.15921     12.56362     1.76772
Training/qf1_norm                     4723.42219   2939.75951  12497.68066  1274.35339
Training/qf2_norm                     4381.49156   2704.70773  11839.47266  1054.87830
log_std/mean                          -0.12162     0.00880     -0.10860     -0.13576
log_std/std                           0.19531      0.00560     0.20617      0.18221
log_std/max                           0.19345      0.02176     0.25578      0.15027
log_std/min                           -0.90042     0.04813     -0.79577     -0.97403
log_probs/mean                        -1.33000     0.07724     -1.12231     -1.50738
log_probs/std                         3.63607      0.13785     3.99334      3.33559
log_probs/max                         13.42238     0.65278     14.88542     12.35018
log_probs/min                         -5.17534     0.84622     -3.98162     -8.71215
mean/mean                             -0.12813     0.02294     -0.08223     -0.16854
mean/std                              0.75459      0.02720     0.83119      0.70091
mean/max                              2.86894      0.11079     3.13269      2.64509
mean/min                              -3.28546     0.17339     -2.90991     -3.60657
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 1, 3, 4, 7, 9, 2, 5, 8, 6]
replay_buffer._size: [8254 8254 8254 8255 8254 8255 8255 8254 8254 8254]
diff1,diff2 6.511976957321167 3.123283386230469e-05
train_time 6.512086391448975
2023-09-06 12:30:01,792 MainThread INFO: EPOCH:53
2023-09-06 12:30:01,792 MainThread INFO: Time Consumed:6.637165069580078s
2023-09-06 12:30:01,792 MainThread INFO: Total Frames:81000s
 27%|â–ˆâ–ˆâ–‹       | 54/200 [05:51<16:25,  6.75s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1087.63167
Train_Epoch_Reward                    10579.20358
Running_Training_Average_Rewards      1643.40291
Explore_Time                          0.12071
Train___Time                          6.51209
Eval____Time                          0.00386
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.81552
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.93675
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.60060
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.46731
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -8.77713
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -7.81841
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  669.04262
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4877.26884
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.14738
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.88686
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.03070      1.33777     11.06587     4.82025
alpha_0                               1.56520      0.00610     1.57525      1.55512
alpha_1                               0.47063      0.00231     0.47455      0.46672
alpha_2                               0.48975      0.00238     0.49375      0.48567
alpha_3                               0.47194      0.00220     0.47566      0.46815
alpha_4                               0.47759      0.00229     0.48148      0.47370
alpha_5                               0.47864      0.00233     0.48261      0.47470
alpha_6                               0.47937      0.00234     0.48333      0.47539
alpha_7                               0.47853      0.00236     0.48255      0.47453
alpha_8                               0.47381      0.00233     0.47779      0.46986
alpha_9                               0.47370      0.00231     0.47764      0.46979
Alpha_loss                            -4.51975     0.07882     -4.35346     -4.63413
Training/policy_loss                  -183.23047   4.37080     -175.57764   -196.00085
Training/qf1_loss                     1680.32166   587.02891   2928.99902   597.55048
Training/qf2_loss                     1609.27589   567.42776   2778.36865   552.20312
Training/pf_norm                      4.54979      2.38029     13.44325     1.13425
Training/qf1_norm                     5923.24912   3714.33048  16472.05664  1323.25928
Training/qf2_norm                     5911.85579   3567.24676  16148.99805  1470.21667
log_std/mean                          -0.13532     0.00817     -0.12331     -0.14933
log_std/std                           0.19192      0.00816     0.20351      0.17512
log_std/max                           0.16012      0.01413     0.19142      0.13118
log_std/min                           -0.80919     0.03273     -0.74433     -0.87505
log_probs/mean                        -1.42237     0.11904     -1.14274     -1.67551
log_probs/std                         3.51414      0.21243     3.86916      3.01502
log_probs/max                         12.81818     0.85378     14.11230     10.55872
log_probs/min                         -5.13467     0.78198     -4.16577     -9.12363
mean/mean                             -0.11973     0.04446     -0.04659     -0.18749
mean/std                              0.71911      0.03731     0.79517      0.64933
mean/max                              2.86699      0.13890     3.12993      2.57399
mean/min                              -3.03868     0.17665     -2.60086     -3.36896
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 1, 4, 5, 7, 2, 3, 0, 9, 6]
replay_buffer._size: [8400 8400 8400 8400 8400 8400 8400 8400 8400 8400]
diff1,diff2 6.962164640426636 7.677078247070312e-05
train_time 6.962321758270264
2023-09-06 12:30:08,934 MainThread INFO: EPOCH:54
2023-09-06 12:30:08,934 MainThread INFO: Time Consumed:6.974629163742065s
2023-09-06 12:30:08,935 MainThread INFO: Total Frames:82500s
 28%|â–ˆâ–ˆâ–Š       | 55/200 [05:58<16:35,  6.87s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               787.60677
Train_Epoch_Reward                    6173.02541
Running_Training_Average_Rewards      1164.08952
Explore_Time                          0.00697
Train___Time                          6.96232
Eval____Time                          0.00474
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.57061
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.08227
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.56827
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.52442
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.48351
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -40.36908
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  4748.33790
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4264.41332
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.61266
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.53520
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           8.25077     1.35463     12.18868     5.73661
alpha_0                               1.58438     0.00512     1.59308      1.57562
alpha_1                               0.46271     0.00226     0.46656      0.45889
alpha_2                               0.48147     0.00236     0.48551      0.47753
alpha_3                               0.46416     0.00223     0.46799      0.46041
alpha_4                               0.46971     0.00223     0.47354      0.46596
alpha_5                               0.47065     0.00228     0.47454      0.46678
alpha_6                               0.47127     0.00232     0.47523      0.46736
alpha_7                               0.47042     0.00231     0.47437      0.46652
alpha_8                               0.46583     0.00227     0.46970      0.46200
alpha_9                               0.46576     0.00227     0.46963      0.46193
Alpha_loss                            -4.60430    0.03020     -4.51234     -4.65868
Training/policy_loss                  -186.58486  4.63229     -173.43912   -196.90311
Training/qf1_loss                     1664.11971  477.14657   3196.25903   757.47845
Training/qf2_loss                     1584.27617  460.13386   3075.64136   716.13409
Training/pf_norm                      6.01695     3.61761     17.93465     2.12110
Training/qf1_norm                     4994.52090  3540.84149  17448.17969  1509.24084
Training/qf2_norm                     4767.21168  3485.92509  16609.33398  1216.84924
log_std/mean                          -0.11836    0.00837     -0.10661     -0.13970
log_std/std                           0.18257     0.00314     0.19005      0.17715
log_std/max                           0.16416     0.02237     0.20879      0.13246
log_std/min                           -0.75953    0.03418     -0.69224     -0.82585
log_probs/mean                        -1.49509    0.05431     -1.39174     -1.59545
log_probs/std                         3.37160     0.09272     3.55683      3.12908
log_probs/max                         13.53363    1.92785     18.78162     11.45627
log_probs/min                         -5.44033    1.03238     -4.04443     -9.64023
mean/mean                             -0.07516    0.02562     -0.02677     -0.11319
mean/std                              0.71169     0.01702     0.74746      0.67713
mean/max                              3.48644     0.38062     4.12245      2.76573
mean/min                              -3.58912    0.42340     -2.82064     -4.32589
------------------------------------  ----------  ----------  -----------  ----------
sample: [9, 5, 7, 3, 8, 1, 6, 2, 4, 0]
replay_buffer._size: [8550 8550 8550 8550 8550 8550 8550 8550 8550 8550]
diff1,diff2 6.670288562774658 6.532669067382812e-05
train_time 6.670432806015015
2023-09-06 12:30:15,808 MainThread INFO: EPOCH:55
2023-09-06 12:30:15,808 MainThread INFO: Time Consumed:6.680830717086792s
2023-09-06 12:30:15,808 MainThread INFO: Total Frames:84000s
 28%|â–ˆâ–ˆâ–Š       | 56/200 [06:05<16:27,  6.86s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               629.55335
Train_Epoch_Reward                    4021.20741
Running_Training_Average_Rewards      692.44788
Explore_Time                          0.00485
Train___Time                          6.67043
Eval____Time                          0.00441
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.35462
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.29169
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.93570
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -34.17564
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -29.50985
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -33.16785
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  219.00790
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4883.81172
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.00401
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.64655
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           8.14873     1.37184     13.62617     6.19535
alpha_0                               1.60293     0.00583     1.61315      1.59343
alpha_1                               0.45502     0.00218     0.45873      0.45133
alpha_2                               0.47355     0.00225     0.47737      0.46970
alpha_3                               0.45664     0.00213     0.46026      0.45301
alpha_4                               0.46216     0.00214     0.46581      0.45853
alpha_5                               0.46280     0.00224     0.46662      0.45902
alpha_6                               0.46342     0.00222     0.46720      0.45966
alpha_7                               0.46254     0.00224     0.46636      0.45875
alpha_8                               0.45809     0.00220     0.46185      0.45436
alpha_9                               0.45801     0.00221     0.46177      0.45427
Alpha_loss                            -4.69814    0.08976     -4.56946     -4.87813
Training/policy_loss                  -190.55390  5.69988     -177.01901   -207.27628
Training/qf1_loss                     1643.02213  493.75497   3568.13330   789.75128
Training/qf2_loss                     1553.81006  474.58088   3420.66284   743.02600
Training/pf_norm                      5.53615     3.40326     17.57612     1.33249
Training/qf1_norm                     4762.40290  3433.98961  18504.90430  965.44287
Training/qf2_norm                     4598.67150  2966.27303  16262.17285  1422.30139
log_std/mean                          -0.13529    0.01251     -0.11938     -0.15642
log_std/std                           0.18447     0.00554     0.19337      0.17141
log_std/max                           0.14327     0.01205     0.16174      0.10132
log_std/min                           -0.77338    0.04024     -0.69611     -0.83793
log_probs/mean                        -1.39999    0.06941     -1.25197     -1.56185
log_probs/std                         3.58424     0.16387     3.92621      3.24915
log_probs/max                         16.03275    2.21430     20.65971     11.61659
log_probs/min                         -5.14946    0.90516     -3.94666     -8.93169
mean/mean                             -0.08226    0.01141     -0.06174     -0.10351
mean/std                              0.74140     0.02649     0.79830      0.69472
mean/max                              3.47255     0.40354     4.16389      2.72470
mean/min                              -3.72751    0.43549     -2.98076     -4.43604
------------------------------------  ----------  ----------  -----------  ----------
sample: [4, 3, 1, 9, 8, 0, 7, 5, 6, 2]
replay_buffer._size: [8706 8706 8705 8717 8707 8713 8707 8707 8704 8706]
diff1,diff2 6.541654825210571 7.128715515136719e-05
train_time 6.541819334030151
2023-09-06 12:30:22,647 MainThread INFO: EPOCH:56
2023-09-06 12:30:22,647 MainThread INFO: Time Consumed:6.660092830657959s
2023-09-06 12:30:22,647 MainThread INFO: Total Frames:85500s
 28%|â–ˆâ–ˆâ–Š       | 57/200 [06:12<16:19,  6.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1054.42581
Train_Epoch_Reward                    5194.54871
Running_Training_Average_Rewards      512.95938
Explore_Time                          0.11268
Train___Time                          6.54182
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.60581
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.67459
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.95886
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.15785
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.60987
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -8.68626
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.02449
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18315.69781
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.30991
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.63483
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.55999      1.40237     12.54652     5.69101
alpha_0                               1.62361      0.00581     1.63323      1.61357
alpha_1                               0.44754      0.00214     0.45118      0.44392
alpha_2                               0.46562      0.00231     0.46954      0.46172
alpha_3                               0.44920      0.00215     0.45286      0.44559
alpha_4                               0.45469      0.00216     0.45838      0.45104
alpha_5                               0.45515      0.00218     0.45886      0.45145
alpha_6                               0.45573      0.00222     0.45950      0.45198
alpha_7                               0.45483      0.00221     0.45860      0.45109
alpha_8                               0.45050      0.00218     0.45420      0.44683
alpha_9                               0.45042      0.00217     0.45412      0.44674
Alpha_loss                            -4.85448     0.03583     -4.78068     -4.92591
Training/policy_loss                  -195.42937   4.95977     -186.12325   -205.67268
Training/qf1_loss                     1714.77384   503.40244   3444.65234   792.98450
Training/qf2_loss                     1614.81842   484.88519   3282.88794   719.42969
Training/pf_norm                      7.60708      4.97295     23.19369     1.74492
Training/qf1_norm                     5328.21629   3307.83328  14914.27734  1478.60437
Training/qf2_norm                     5290.62179   2889.86724  13730.41504  1431.16602
log_std/mean                          -0.14129     0.00712     -0.13187     -0.15651
log_std/std                           0.18058      0.00545     0.19141      0.17104
log_std/max                           0.13601      0.01491     0.15946      0.10501
log_std/min                           -0.81477     0.06090     -0.70995     -0.90941
log_probs/mean                        -1.51399     0.04711     -1.43072     -1.62631
log_probs/std                         3.42426      0.12009     3.71572      3.16135
log_probs/max                         14.74127     2.04162     19.98531     11.84198
log_probs/min                         -5.18033     0.83718     -4.00024     -8.39692
mean/mean                             -0.07619     0.01469     -0.04642     -0.09991
mean/std                              0.70451      0.01408     0.72872      0.67264
mean/max                              3.14887      0.23069     3.66115      2.74800
mean/min                              -3.28839     0.22370     -2.90166     -3.79557
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 4, 7, 0, 6, 2, 5, 9, 3]
replay_buffer._size: [8850 8850 8850 8850 8850 8850 8850 8850 8850 8850]
diff1,diff2 6.596882581710815 7.224082946777344e-05
train_time 6.597045660018921
2023-09-06 12:30:29,517 MainThread INFO: EPOCH:57
2023-09-06 12:30:29,517 MainThread INFO: Time Consumed:6.625871181488037s
2023-09-06 12:30:29,517 MainThread INFO: Total Frames:87000s
 29%|â–ˆâ–ˆâ–‰       | 58/200 [06:19<16:15,  6.87s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1498.07192
Train_Epoch_Reward                    21016.82984
Running_Training_Average_Rewards      1007.75287
Explore_Time                          0.02307
Train___Time                          6.59705
Eval____Time                          0.00506
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.59476
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.90371
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.23615
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.57039
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -21.64197
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -8.03199
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.38488
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 22305.98980
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.70345
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.53397
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.36268      1.32361     11.94389     5.12044
alpha_0                               1.64368      0.00610     1.65433      1.63362
alpha_1                               0.44022      0.00209     0.44378      0.43669
alpha_2                               0.45777      0.00222     0.46156      0.45400
alpha_3                               0.44196      0.00205     0.44544      0.43846
alpha_4                               0.44738      0.00206     0.45089      0.44389
alpha_5                               0.44766      0.00213     0.45130      0.44405
alpha_6                               0.44814      0.00216     0.45182      0.44449
alpha_7                               0.44726      0.00215     0.45094      0.44362
alpha_8                               0.44312      0.00208     0.44668      0.43959
alpha_9                               0.44298      0.00212     0.44659      0.43940
Alpha_loss                            -4.92703     0.06751     -4.80213     -5.02257
Training/policy_loss                  -199.33889   5.44020     -186.63094   -210.52452
Training/qf1_loss                     1711.87433   445.73529   2913.23999   1041.52783
Training/qf2_loss                     1606.58311   425.66345   2699.25586   971.77814
Training/pf_norm                      8.01106      5.16498     33.71683     2.12481
Training/qf1_norm                     6061.54173   2951.49905  13884.85938  1298.95398
Training/qf2_norm                     5608.07769   2919.45150  12934.22363  1079.64990
log_std/mean                          -0.14232     0.00325     -0.13472     -0.14810
log_std/std                           0.18980      0.00434     0.20050      0.18084
log_std/max                           0.13848      0.00641     0.15044      0.12360
log_std/min                           -0.88956     0.05950     -0.76482     -0.98957
log_probs/mean                        -1.42779     0.06096     -1.28779     -1.58132
log_probs/std                         3.54329      0.13616     3.85768      3.30898
log_probs/max                         14.32750     1.84604     18.37232     11.56288
log_probs/min                         -5.11614     0.71723     -4.11490     -7.54211
mean/mean                             -0.10173     0.01516     -0.06622     -0.12493
mean/std                              0.72553      0.01889     0.76410      0.68672
mean/max                              3.03880      0.22512     3.46028      2.65573
mean/min                              -3.26119     0.24843     -2.83942     -3.66696
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 2, 3, 1, 7, 4, 5, 9, 6, 0]
replay_buffer._size: [9003 9004 9004 9004 9005 9005 9004 9005 9006 9006]
diff1,diff2 6.403713226318359 1.8358230590820312e-05
train_time 6.403796434402466
2023-09-06 12:30:36,327 MainThread INFO: EPOCH:58
2023-09-06 12:30:36,327 MainThread INFO: Time Consumed:6.5374915599823s
2023-09-06 12:30:36,327 MainThread INFO: Total Frames:88500s
 30%|â–ˆâ–ˆâ–‰       | 59/200 [06:26<16:05,  6.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2642.23570
Train_Epoch_Reward                    26435.45461
Running_Training_Average_Rewards      1754.89444
Explore_Time                          0.12806
Train___Time                          6.40380
Eval____Time                          0.00457
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.25561
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.06758
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.05523
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.44810
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -16.87585
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            1.05132
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.06224
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 39385.27028
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.90693
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.00281
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.72983      1.56048     12.52217     5.96545
alpha_0                               1.66505      0.00596     1.67543      1.65477
alpha_1                               0.43305      0.00204     0.43654      0.42960
alpha_2                               0.45017      0.00212     0.45385      0.44665
alpha_3                               0.43492      0.00197     0.43832      0.43163
alpha_4                               0.44032      0.00199     0.44374      0.43700
alpha_5                               0.44035      0.00208     0.44390      0.43686
alpha_6                               0.44077      0.00209     0.44434      0.43726
alpha_7                               0.43989      0.00210     0.44347      0.43636
alpha_8                               0.43598      0.00201     0.43944      0.43260
alpha_9                               0.43574      0.00206     0.43925      0.43227
Alpha_loss                            -4.93144     0.06650     -4.76858     -5.07161
Training/policy_loss                  -204.35125   5.44799     -194.86348   -222.27657
Training/qf1_loss                     1852.63369   536.35746   3458.17969   832.12268
Training/qf2_loss                     1728.92644   507.74070   3262.98926   752.42999
Training/pf_norm                      6.74172      4.89538     29.51647     2.12983
Training/qf1_norm                     6307.80713   3388.32380  18416.92969  1347.29675
Training/qf2_norm                     5971.60103   3026.88103  17585.82812  1409.42773
log_std/mean                          -0.13768     0.00489     -0.12911     -0.14688
log_std/std                           0.19153      0.00613     0.20182      0.18010
log_std/max                           0.13621      0.00303     0.14140      0.12683
log_std/min                           -0.87424     0.02316     -0.80424     -0.91198
log_probs/mean                        -1.34059     0.13810     -1.06368     -1.57026
log_probs/std                         3.58434      0.22070     4.01187      3.19448
log_probs/max                         13.10862     0.96815     15.25644     10.99209
log_probs/min                         -5.20371     0.82117     -4.10749     -7.53412
mean/mean                             -0.11238     0.00804     -0.09440     -0.12809
mean/std                              0.74872      0.04434     0.82725      0.67158
mean/max                              2.88007      0.11130     3.08733      2.63882
mean/min                              -3.24215     0.17651     -2.94987     -3.58949
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 0, 6, 1, 8, 4, 2, 7, 5]
replay_buffer._size: [9150 9150 9150 9150 9150 9150 9150 9150 9150 9150]
diff1,diff2 6.668198108673096 7.128715515136719e-05
train_time 6.668350696563721
2023-09-06 12:30:43,183 MainThread INFO: EPOCH:59
2023-09-06 12:30:43,183 MainThread INFO: Time Consumed:6.693996429443359s
2023-09-06 12:30:43,184 MainThread INFO: Total Frames:90000s
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [06:33<15:59,  6.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2884.67987
Train_Epoch_Reward                    41766.00800
Running_Training_Average_Rewards      2973.94308
Explore_Time                          0.02053
Train___Time                          6.66835
Eval____Time                          0.00425
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.35069
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.24683
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.09558
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.80265
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -30.66328
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -6.65189
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.03329
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 25592.79919
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.55193
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.04286
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.64950      1.65521     12.43214     5.69780
alpha_0                               1.68654      0.00636     1.69777      1.67588
alpha_1                               0.42606      0.00199     0.42946      0.42271
alpha_2                               0.44313      0.00199     0.44651      0.43979
alpha_3                               0.42817      0.00196     0.43149      0.42488
alpha_4                               0.43370      0.00185     0.43687      0.43062
alpha_5                               0.43329      0.00200     0.43672      0.42992
alpha_6                               0.43363      0.00205     0.43712      0.43017
alpha_7                               0.43284      0.00197     0.43622      0.42952
alpha_8                               0.42914      0.00195     0.43247      0.42586
alpha_9                               0.42869      0.00202     0.43213      0.42527
Alpha_loss                            -4.97079     0.10179     -4.74130     -5.18982
Training/policy_loss                  -208.87589   4.80518     -198.93555   -219.70850
Training/qf1_loss                     1712.46498   602.01189   3157.92554   944.06946
Training/qf2_loss                     1584.65504   572.66249   2973.92163   853.37024
Training/pf_norm                      8.13840      5.10729     24.72027     1.97442
Training/qf1_norm                     6391.63681   4265.35780  20349.38672  1613.29382
Training/qf2_norm                     5959.62539   3793.50929  18779.11523  1629.97290
log_std/mean                          -0.13143     0.00426     -0.12374     -0.14192
log_std/std                           0.19258      0.00521     0.20636      0.18169
log_std/max                           0.13918      0.00683     0.15061      0.12364
log_std/min                           -0.84144     0.05630     -0.69207     -0.94643
log_probs/mean                        -1.23257     0.13540     -0.89733     -1.48703
log_probs/std                         3.73325      0.19795     4.24522      3.29972
log_probs/max                         13.99007     1.43131     17.75853     11.98959
log_probs/min                         -5.26450     0.94902     -4.06710     -7.99069
mean/mean                             -0.09018     0.01551     -0.05729     -0.11979
mean/std                              0.78134      0.04247     0.88272      0.70809
mean/max                              2.99682      0.17974     3.36089      2.60516
mean/min                              -3.29360     0.23934     -2.77203     -3.71457
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 4, 7, 6, 0, 5, 2, 3, 9]
replay_buffer._size: [9300 9300 9300 9300 9300 9300 9300 9300 9300 9300]
diff1,diff2 6.799957275390625 1.9311904907226562e-05
train_time 6.800050258636475
2023-09-06 12:30:50,151 MainThread INFO: EPOCH:60
2023-09-06 12:30:50,151 MainThread INFO: Time Consumed:6.809943914413452s
2023-09-06 12:30:50,151 MainThread INFO: Total Frames:91500s
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [06:40<15:57,  6.89s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2817.26143
Train_Epoch_Reward                    31519.15349
Running_Training_Average_Rewards      3324.02054
Explore_Time                          0.00441
Train___Time                          6.80005
Eval____Time                          0.00478
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.96921
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -44.27536
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -16.35107
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.77487
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -9.36494
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -15.55730
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.82455
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20264.52507
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.25012
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.32214
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.08879      1.48561     12.55508     6.29880
alpha_0                               1.70957      0.00644     1.71998      1.69825
alpha_1                               0.41923      0.00197     0.42257      0.41589
alpha_2                               0.43617      0.00207     0.43965      0.43266
alpha_3                               0.42143      0.00197     0.42475      0.41809
alpha_4                               0.42728      0.00192     0.43049      0.42401
alpha_5                               0.42640      0.00199     0.42978      0.42303
alpha_6                               0.42659      0.00203     0.43003      0.42315
alpha_7                               0.42599      0.00200     0.42939      0.42259
alpha_8                               0.42238      0.00199     0.42573      0.41900
alpha_9                               0.42176      0.00198     0.42513      0.41841
Alpha_loss                            -5.21499     0.04408     -5.04039     -5.27997
Training/policy_loss                  -212.97922   4.58805     -204.31042   -222.84969
Training/qf1_loss                     1860.18059   479.29849   3074.92163   948.52753
Training/qf2_loss                     1711.19666   443.24753   2855.43384   858.31293
Training/pf_norm                      4.74628      3.00843     16.22816     1.50259
Training/qf1_norm                     5738.14792   3028.65588  13468.38770  1268.29480
Training/qf2_norm                     5345.95924   3317.59716  14117.36035  1107.62561
log_std/mean                          -0.12406     0.01175     -0.10682     -0.14042
log_std/std                           0.18927      0.00320     0.19731      0.18422
log_std/max                           0.15842      0.01381     0.18285      0.13943
log_std/min                           -0.89184     0.08527     -0.70977     -1.09398
log_probs/mean                        -1.46235     0.06206     -1.33387     -1.55553
log_probs/std                         3.41651      0.13145     3.69400      3.23546
log_probs/max                         12.43592     0.66471     14.20123     11.26957
log_probs/min                         -4.92770     0.65031     -4.05883     -7.27909
mean/mean                             -0.14005     0.01539     -0.11205     -0.16598
mean/std                              0.70328      0.01910     0.74828      0.67469
mean/max                              2.75900      0.08509     2.88001      2.56210
mean/min                              -3.13339     0.15164     -2.80926     -3.50749
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 0, 4, 2, 6, 7, 8, 5, 1, 3]
replay_buffer._size: [9450 9450 9450 9450 9450 9450 9450 9450 9450 9450]
diff1,diff2 6.938841819763184 8.487701416015625e-05
train_time 6.9390411376953125
2023-09-06 12:30:57,273 MainThread INFO: EPOCH:61
2023-09-06 12:30:57,274 MainThread INFO: Time Consumed:6.949495553970337s
2023-09-06 12:30:57,274 MainThread INFO: Total Frames:93000s
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [06:47<15:58,  6.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2401.20284
Train_Epoch_Reward                    22440.69078
Running_Training_Average_Rewards      3190.86174
Explore_Time                          0.00442
Train___Time                          6.93904
Eval____Time                          0.00543
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.47235
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -43.93083
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.15441
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.16561
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -10.33775
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -4.47978
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.04003
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 26901.82822
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.99607
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.36185
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.68193      1.51625     12.03490     4.76549
alpha_0                               1.73018      0.00600     1.74080      1.72039
alpha_1                               0.41246      0.00193     0.41576      0.40919
alpha_2                               0.42905      0.00203     0.43252      0.42561
alpha_3                               0.41471      0.00191     0.41796      0.41147
alpha_4                               0.42068      0.00189     0.42388      0.41746
alpha_5                               0.41955      0.00196     0.42290      0.41624
alpha_6                               0.41962      0.00199     0.42301      0.41626
alpha_7                               0.41908      0.00198     0.42245      0.41573
alpha_8                               0.41551      0.00196     0.41886      0.41220
alpha_9                               0.41498      0.00193     0.41828      0.41172
Alpha_loss                            -5.29703     0.04782     -5.15708     -5.38130
Training/policy_loss                  -215.53627   5.21861     -202.57890   -228.29305
Training/qf1_loss                     1713.54328   442.82451   3276.93555   838.50830
Training/qf2_loss                     1556.09023   409.79709   2927.65015   720.25092
Training/pf_norm                      5.93048      2.35315     14.38078     2.21867
Training/qf1_norm                     6444.04412   3727.79889  25641.08203  1425.83813
Training/qf2_norm                     5879.82867   3405.58598  21107.10156  1255.41760
log_std/mean                          -0.11955     0.00618     -0.10906     -0.12999
log_std/std                           0.19305      0.00751     0.20754      0.18205
log_std/max                           0.27197      0.11256     0.47765      0.15732
log_std/min                           -0.93587     0.06597     -0.81775     -1.04150
log_probs/mean                        -1.45905     0.05817     -1.36217     -1.59093
log_probs/std                         3.39313      0.10552     3.57591      3.13465
log_probs/max                         12.94010     0.64764     14.55634     11.83969
log_probs/min                         -5.04602     0.77296     -3.99105     -7.70886
mean/mean                             -0.15181     0.01410     -0.12425     -0.17851
mean/std                              0.70770      0.01524     0.73409      0.67483
mean/max                              2.79325      0.07597     2.91761      2.62264
mean/min                              -3.24793     0.13403     -3.03280     -3.47792
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 2, 7, 9, 5, 1, 0, 4, 6]
replay_buffer._size: [9600 9600 9600 9600 9600 9600 9600 9600 9600 9600]
diff1,diff2 6.842398643493652 1.8358230590820312e-05
train_time 6.8424811363220215
2023-09-06 12:31:04,323 MainThread INFO: EPOCH:62
2023-09-06 12:31:04,323 MainThread INFO: Time Consumed:6.8610007762908936s
2023-09-06 12:31:04,323 MainThread INFO: Total Frames:94500s
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [06:54<15:55,  6.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2097.72939
Train_Epoch_Reward                    26977.31468
Running_Training_Average_Rewards      2697.90530
Explore_Time                          0.01350
Train___Time                          6.84248
Eval____Time                          0.00429
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.98268
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.64656
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.33539
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.41733
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.27094
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -4.81994
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  142.30462
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16333.98647
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -30.99523
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.66627
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.48926      1.79879     14.06977     6.24114
alpha_0                               1.75272      0.00692     1.76472      1.74124
alpha_1                               0.40586      0.00188     0.40906      0.40267
alpha_2                               0.42208      0.00200     0.42548      0.41869
alpha_3                               0.40818      0.00187     0.41134      0.40499
alpha_4                               0.41426      0.00180     0.41733      0.41120
alpha_5                               0.41286      0.00191     0.41611      0.40962
alpha_6                               0.41285      0.00193     0.41613      0.40958
alpha_7                               0.41230      0.00194     0.41560      0.40902
alpha_8                               0.40882      0.00191     0.41206      0.40559
alpha_9                               0.40837      0.00189     0.41159      0.40518
Alpha_loss                            -5.40271     0.09038     -5.13898     -5.56769
Training/policy_loss                  -220.88539   4.80296     -212.46008   -231.13069
Training/qf1_loss                     2073.31294   534.96834   3469.49146   1146.21912
Training/qf2_loss                     1899.53444   492.90625   3161.24536   1053.96484
Training/pf_norm                      6.51991      3.41475     19.70760     2.01788
Training/qf1_norm                     6726.53398   4427.56239  23325.51758  1176.30005
Training/qf2_norm                     7925.27316   5023.27146  24349.77148  1064.61450
log_std/mean                          -0.12446     0.00601     -0.11500     -0.13909
log_std/std                           0.19161      0.00517     0.20263      0.18282
log_std/max                           0.15334      0.01278     0.19463      0.13525
log_std/min                           -0.87082     0.05857     -0.75312     -0.98173
log_probs/mean                        -1.37699     0.05384     -1.27344     -1.51797
log_probs/std                         3.57849      0.11180     3.80265      3.31531
log_probs/max                         13.64456     0.86616     15.50836     12.24266
log_probs/min                         -5.21775     0.74874     -4.21751     -8.80797
mean/mean                             -0.15097     0.01842     -0.12013     -0.19170
mean/std                              0.73575      0.01448     0.78010      0.70708
mean/max                              2.86550      0.13198     3.09475      2.52795
mean/min                              -3.05346     0.07440     -2.93492     -3.22591
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 7, 1, 6, 9, 0, 5, 3, 4, 2]
replay_buffer._size: [9750 9750 9750 9750 9750 9750 9750 9750 9750 9750]
diff1,diff2 6.712146520614624 1.8835067749023438e-05
train_time 6.712231397628784
2023-09-06 12:31:11,447 MainThread INFO: EPOCH:63
2023-09-06 12:31:11,447 MainThread INFO: Time Consumed:6.729787349700928s
2023-09-06 12:31:11,447 MainThread INFO: Total Frames:96000s
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [07:01<15:56,  7.03s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1570.20174
Train_Epoch_Reward                    15539.98104
Running_Training_Average_Rewards      2165.26622
Explore_Time                          0.01181
Train___Time                          6.71223
Eval____Time                          0.00516
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.70100
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -40.90005
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.50700
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -23.89685
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -19.82253
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            83.33809
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.76278
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4359.42362
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.46902
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.69645
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.73534      1.25323     11.02332     6.17626
alpha_0                               1.77667      0.00642     1.78740      1.76526
alpha_1                               0.39939      0.00185     0.40255      0.39626
alpha_2                               0.41519      0.00197     0.41855      0.41185
alpha_3                               0.40167      0.00187     0.40486      0.39850
alpha_4                               0.40789      0.00189     0.41107      0.40468
alpha_5                               0.40629      0.00188     0.40949      0.40311
alpha_6                               0.40620      0.00191     0.40944      0.40297
alpha_7                               0.40564      0.00190     0.40888      0.40242
alpha_8                               0.40225      0.00188     0.40546      0.39907
alpha_9                               0.40189      0.00186     0.40505      0.39874
Alpha_loss                            -5.53668     0.04499     -5.43582     -5.60235
Training/policy_loss                  -223.93531   6.41916     -204.60014   -237.69072
Training/qf1_loss                     1715.60500   404.69845   2883.83203   1009.51251
Training/qf2_loss                     1542.69046   381.76211   2598.49951   877.02240
Training/pf_norm                      7.19518      4.93250     29.96305     1.70187
Training/qf1_norm                     6848.40539   3884.63887  21007.77539  1377.91504
Training/qf2_norm                     6826.19728   3506.10153  18373.93555  1843.03406
log_std/mean                          -0.12603     0.00572     -0.11677     -0.13688
log_std/std                           0.18754      0.00373     0.19909      0.17986
log_std/max                           0.22092      0.03929     0.26950      0.14916
log_std/min                           -0.82806     0.06763     -0.70270     -0.96791
log_probs/mean                        -1.51210     0.06104     -1.33248     -1.66857
log_probs/std                         3.33699      0.12655     3.66476      3.03275
log_probs/max                         13.47020     1.27671     16.38398     11.87278
log_probs/min                         -5.35502     0.71509     -4.32939     -7.65737
mean/mean                             -0.14416     0.01982     -0.11117     -0.18952
mean/std                              0.68821      0.01290     0.72670      0.66023
mean/max                              2.84838      0.23083     3.38345      2.49666
mean/min                              -3.26619     0.29034     -2.91414     -3.93332
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 6, 1, 5, 0, 7, 8, 4, 2, 3]
replay_buffer._size: [9900 9900 9900 9900 9900 9900 9900 9900 9900 9900]
diff1,diff2 6.988667249679565 6.67572021484375e-05
train_time 6.988826751708984
2023-09-06 12:31:18,631 MainThread INFO: EPOCH:64
2023-09-06 12:31:18,631 MainThread INFO: Time Consumed:6.998430967330933s
2023-09-06 12:31:18,631 MainThread INFO: Total Frames:97500s
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [07:08<15:55,  7.07s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               828.12749
Train_Epoch_Reward                    4658.65012
Running_Training_Average_Rewards      1572.53153
Explore_Time                          0.00519
Train___Time                          6.98883
Eval____Time                          0.00381
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.55634
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.80347
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.42465
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.93834
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.37696
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -54.28415
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.56983
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4727.16640
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.36155
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.18922
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           9.23914     1.34179     11.93167     6.03746
alpha_0                               1.79888     0.00657     1.81022      1.78784
alpha_1                               0.39306     0.00180     0.39613      0.39000
alpha_2                               0.40845     0.00192     0.41171      0.40520
alpha_3                               0.39524     0.00184     0.39837      0.39214
alpha_4                               0.40140     0.00185     0.40455      0.39826
alpha_5                               0.39985     0.00184     0.40299      0.39673
alpha_6                               0.39967     0.00186     0.40284      0.39651
alpha_7                               0.39912     0.00186     0.40229      0.39598
alpha_8                               0.39583     0.00183     0.39894      0.39273
alpha_9                               0.39551     0.00182     0.39861      0.39243
Alpha_loss                            -5.62484    0.04945     -5.51360     -5.73761
Training/policy_loss                  -228.95472  4.50699     -219.22281   -237.84109
Training/qf1_loss                     1929.57200  408.66270   2640.14307   1119.06726
Training/qf2_loss                     1711.95558  372.96008   2354.28589   951.62823
Training/pf_norm                      5.62384     4.43999     27.10027     1.50184
Training/qf1_norm                     8982.86857  5288.24344  27409.68555  1749.47266
Training/qf2_norm                     7112.53144  4240.21302  20538.97656  1842.82654
log_std/mean                          -0.13432    0.00684     -0.12561     -0.14715
log_std/std                           0.19135     0.00581     0.20180      0.18322
log_std/max                           0.28900     0.02669     0.32955      0.22716
log_std/min                           -0.78387    0.05117     -0.70552     -0.87340
log_probs/mean                        -1.46866    0.05616     -1.33036     -1.58133
log_probs/std                         3.39887     0.14344     3.66261      3.12661
log_probs/max                         12.98813    0.79191     14.75981     11.46501
log_probs/min                         -5.42621    1.22169     -4.24187     -12.62916
mean/mean                             -0.13151    0.01462     -0.11064     -0.16100
mean/std                              0.70448     0.01674     0.73758      0.67211
mean/max                              2.90268     0.18143     3.26327      2.56981
mean/min                              -3.19301    0.15190     -2.95246     -3.45398
------------------------------------  ----------  ----------  -----------  ----------
sample: [2, 3, 1, 4, 5, 0, 7, 6, 8, 9]
replay_buffer._size: [10050 10050 10050 10050 10050 10050 10050 10058 10050 10050]
diff1,diff2 7.107160806655884 3.1948089599609375e-05
train_time 7.1072728633880615
2023-09-06 12:31:25,973 MainThread INFO: EPOCH:65
2023-09-06 12:31:25,973 MainThread INFO: Time Consumed:7.154009819030762s
2023-09-06 12:31:25,973 MainThread INFO: Total Frames:99000s
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [07:15<15:58,  7.15s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               501.51556
Train_Epoch_Reward                    5188.06607
Running_Training_Average_Rewards      846.22324
Explore_Time                          0.04058
Train___Time                          7.10727
Eval____Time                          0.00542
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.18071
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.13025
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.83391
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.30867
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.99356
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -51.59494
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.11243
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6743.70715
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.91192
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.84195
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           9.01905     1.40883     12.05907     5.93763
alpha_0                               1.82238     0.00681     1.83390      1.81072
alpha_1                               0.38689     0.00175     0.38988      0.38392
alpha_2                               0.40189     0.00186     0.40507      0.39876
alpha_3                               0.38899     0.00177     0.39201      0.38601
alpha_4                               0.39505     0.00181     0.39813      0.39199
alpha_5                               0.39353     0.00180     0.39660      0.39048
alpha_6                               0.39328     0.00182     0.39639      0.39020
alpha_7                               0.39277     0.00181     0.39585      0.38971
alpha_8                               0.38956     0.00179     0.39261      0.38654
alpha_9                               0.38928     0.00177     0.39230      0.38627
Alpha_loss                            -5.67273    0.03412     -5.59353     -5.74454
Training/policy_loss                  -232.62606  4.51991     -223.49239   -241.83366
Training/qf1_loss                     1828.03071  529.50995   2958.04663   740.19391
Training/qf2_loss                     1615.24382  491.20011   2644.09839   636.30969
Training/pf_norm                      7.04247     5.12475     21.47813     1.65753
Training/qf1_norm                     6321.39332  3395.91458  15488.02441  1418.03296
Training/qf2_norm                     5767.16148  3096.73492  16088.80566  1789.66455
log_std/mean                          -0.14157    0.00507     -0.13129     -0.15076
log_std/std                           0.20081     0.00378     0.20712      0.19264
log_std/max                           0.34166     0.02880     0.40099      0.27554
log_std/min                           -0.74720    0.02929     -0.68668     -0.80955
log_probs/mean                        -1.42450    0.04757     -1.32683     -1.55090
log_probs/std                         3.35906     0.08784     3.53992      3.14276
log_probs/max                         12.53827    0.55306     14.21649     11.79953
log_probs/min                         -5.47148    0.68746     -4.28056     -7.04933
mean/mean                             -0.14427    0.00767     -0.12855     -0.15605
mean/std                              0.70893     0.01271     0.74172      0.67924
mean/max                              2.90489     0.13467     3.16044      2.55107
mean/min                              -3.06353    0.12602     -2.85814     -3.33196
------------------------------------  ----------  ----------  -----------  ----------
sample: [0, 1, 4, 9, 8, 5, 6, 3, 7, 2]
replay_buffer._size: [10200 10200 10200 10200 10200 10200 10200 10200 10200 10200]
diff1,diff2 7.121426582336426 1.9073486328125e-05
train_time 7.1215057373046875
2023-09-06 12:31:33,309 MainThread INFO: EPOCH:66
2023-09-06 12:31:33,310 MainThread INFO: Time Consumed:7.132980823516846s
2023-09-06 12:31:33,310 MainThread INFO: Total Frames:100500s
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [07:23<16:01,  7.23s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               646.33035
Train_Epoch_Reward                    9442.12227
Running_Training_Average_Rewards      642.96128
Explore_Time                          0.00561
Train___Time                          7.12151
Eval____Time                          0.00443
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.30798
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.15579
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.51015
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.34461
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.77767
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.69022
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.40036
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8871.18245
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.65074
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.89525
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           9.00840     1.54007     13.46900     6.06785
alpha_0                               1.84557     0.00653     1.85650      1.83437
alpha_1                               0.38087     0.00172     0.38380      0.37799
alpha_2                               0.39558     0.00179     0.39863      0.39259
alpha_3                               0.38296     0.00172     0.38589      0.38009
alpha_4                               0.38886     0.00177     0.39187      0.38585
alpha_5                               0.38735     0.00177     0.39036      0.38436
alpha_6                               0.38704     0.00178     0.39007      0.38406
alpha_7                               0.38656     0.00178     0.38958      0.38354
alpha_8                               0.38344     0.00175     0.38642      0.38048
alpha_9                               0.38318     0.00174     0.38615      0.38023
Alpha_loss                            -5.71372    0.05709     -5.59938     -5.82442
Training/policy_loss                  -234.16140  5.35635     -221.97314   -245.48003
Training/qf1_loss                     1876.02946  433.77024   2775.39062   970.83685
Training/qf2_loss                     1621.30340  388.22747   2470.72632   819.91064
Training/pf_norm                      7.16613     4.42971     19.05709     1.96678
Training/qf1_norm                     9132.20509  5720.64622  25538.14062  1526.84326
Training/qf2_norm                     5868.32956  3957.04365  16885.70312  1337.34009
log_std/mean                          -0.13520    0.00847     -0.12174     -0.15138
log_std/std                           0.19737     0.00298     0.20303      0.19116
log_std/max                           0.30875     0.02196     0.35518      0.27017
log_std/min                           -0.80758    0.06276     -0.72101     -0.97154
log_probs/mean                        -1.40624    0.06953     -1.19130     -1.51218
log_probs/std                         3.37212     0.12612     3.71000      3.17586
log_probs/max                         12.80890    1.06305     15.46245     11.45830
log_probs/min                         -5.38057    0.66737     -4.26347     -7.92105
mean/mean                             -0.12300    0.01349     -0.10071     -0.15151
mean/std                              0.71901     0.02309     0.77677      0.68471
mean/max                              2.95349     0.14448     3.30867      2.64369
mean/min                              -3.14983    0.21138     -2.83052     -3.63280
------------------------------------  ----------  ----------  -----------  ----------
sample: [5, 8, 7, 4, 9, 3, 1, 2, 6, 0]
replay_buffer._size: [10354 10354 10354 10355 10355 10357 10354 10354 10356 10354]
diff1,diff2 7.065034866333008 5.0067901611328125e-05
train_time 7.065159797668457
2023-09-06 12:31:40,696 MainThread INFO: EPOCH:67
2023-09-06 12:31:40,696 MainThread INFO: Time Consumed:7.192567348480225s
2023-09-06 12:31:40,696 MainThread INFO: Total Frames:102000s
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [07:30<15:58,  7.26s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               804.85768
Train_Epoch_Reward                    10957.54213
Running_Training_Average_Rewards      852.92435
Explore_Time                          0.12269
Train___Time                          7.06516
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.12725
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.66402
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -12.63256
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.57440
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -39.11421
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.09851
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.13251
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9489.02876
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.90183
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.30150
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.82100      1.25126     11.57103     6.42004
alpha_0                               1.86750      0.00621     1.87803      1.85695
alpha_1                               0.37511      0.00163     0.37788      0.37235
alpha_2                               0.38968      0.00163     0.39247      0.38699
alpha_3                               0.37718      0.00165     0.37998      0.37441
alpha_4                               0.38277      0.00173     0.38572      0.37985
alpha_5                               0.38127      0.00175     0.38424      0.37831
alpha_6                               0.38104      0.00172     0.38394      0.37814
alpha_7                               0.38045      0.00174     0.38342      0.37749
alpha_8                               0.37743      0.00172     0.38036      0.37453
alpha_9                               0.37722      0.00170     0.38011      0.37435
Alpha_loss                            -5.68678     0.07916     -5.51038     -5.85016
Training/policy_loss                  -239.16589   4.79221     -229.18773   -252.61523
Training/qf1_loss                     1872.87171   496.39743   3696.84546   850.47015
Training/qf2_loss                     1632.91545   450.18482   3268.13257   722.07593
Training/pf_norm                      8.52894      5.88560     29.76599     1.80106
Training/qf1_norm                     6657.08062   3478.07785  14968.06543  2093.36523
Training/qf2_norm                     6151.46832   3479.97902  16743.80078  1930.31250
log_std/mean                          -0.14276     0.00606     -0.12757     -0.15334
log_std/std                           0.19411      0.00444     0.20622      0.18780
log_std/max                           0.27996      0.01377     0.31194      0.24700
log_std/min                           -0.75547     0.02902     -0.70821     -0.81918
log_probs/mean                        -1.31551     0.10450     -1.07090     -1.48241
log_probs/std                         3.45476      0.16836     3.89799      3.22650
log_probs/max                         12.38502     0.58615     13.80762     11.48730
log_probs/min                         -5.47477     0.90187     -4.41037     -9.78970
mean/mean                             -0.09866     0.00944     -0.08325     -0.11960
mean/std                              0.75307      0.03485     0.85425      0.69911
mean/max                              3.01473      0.09232     3.21746      2.85404
mean/min                              -3.09912     0.09624     -2.93272     -3.33441
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 7, 8, 3, 1, 0, 6, 9, 5]
replay_buffer._size: [10500 10500 10500 10500 10500 10500 10500 10500 10500 10500]
diff1,diff2 7.006207227706909 1.8835067749023438e-05
train_time 7.006288051605225
2023-09-06 12:31:47,893 MainThread INFO: EPOCH:68
2023-09-06 12:31:47,893 MainThread INFO: Time Consumed:7.015299081802368s
2023-09-06 12:31:47,893 MainThread INFO: Total Frames:103500s
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [07:37<15:47,  7.23s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               911.95539
Train_Epoch_Reward                    10719.41551
Running_Training_Average_Rewards      1037.30266
Explore_Time                          0.00439
Train___Time                          7.00629
Eval____Time                          0.00400
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.31907
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -37.31686
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -13.06613
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.86802
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.74761
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.94114
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.91412
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9964.78771
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.12133
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.76347
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.79702      1.29377     11.13715     5.19685
alpha_0                               1.89011      0.00683     1.90195      1.87849
alpha_1                               0.36947      0.00164     0.37224      0.36669
alpha_2                               0.38444      0.00151     0.38689      0.38180
alpha_3                               0.37160      0.00161     0.37430      0.36883
alpha_4                               0.37686      0.00170     0.37973      0.37398
alpha_5                               0.37527      0.00171     0.37819      0.37237
alpha_6                               0.37519      0.00169     0.37803      0.37230
alpha_7                               0.37446      0.00171     0.37737      0.37156
alpha_8                               0.37153      0.00170     0.37441      0.36866
alpha_9                               0.37142      0.00166     0.37424      0.36861
Alpha_loss                            -5.82868     0.11436     -5.58387     -5.99021
Training/policy_loss                  -242.76242   5.61254     -232.28755   -251.06578
Training/qf1_loss                     1689.55847   405.57466   2754.11792   905.30273
Training/qf2_loss                     1447.50210   365.03194   2440.23730   737.43958
Training/pf_norm                      8.45371      5.18675     24.16883     2.14907
Training/qf1_norm                     6854.85428   4368.46029  21668.05664  1592.20691
Training/qf2_norm                     6520.87982   4109.10660  19673.87695  1662.85864
log_std/mean                          -0.13762     0.00840     -0.12706     -0.15524
log_std/std                           0.20044      0.00409     0.21124      0.19514
log_std/max                           0.26294      0.04906     0.34222      0.19591
log_std/min                           -0.79895     0.05646     -0.71618     -0.95081
log_probs/mean                        -1.29992     0.11800     -1.03009     -1.51630
log_probs/std                         3.51469      0.19039     3.92873      3.18498
log_probs/max                         12.74156     0.91794     15.22221     11.42170
log_probs/min                         -5.37850     0.82324     -4.27995     -9.28900
mean/mean                             -0.11871     0.01272     -0.09460     -0.13960
mean/std                              0.75825      0.04098     0.85336      0.69235
mean/max                              2.87512      0.17916     3.19602      2.56747
mean/min                              -3.20873     0.16407     -3.00066     -3.57641
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 5, 0, 2, 9, 3, 6, 7, 8, 4]
replay_buffer._size: [10650 10650 10650 10650 10650 10650 10650 10650 10650 10650]
diff1,diff2 7.002473592758179 3.361701965332031e-05
train_time 7.002573251724243
2023-09-06 12:31:55,078 MainThread INFO: EPOCH:69
2023-09-06 12:31:55,078 MainThread INFO: Time Consumed:7.0199456214904785s
2023-09-06 12:31:55,078 MainThread INFO: Total Frames:105000s
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [07:45<15:41,  7.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1206.42434
Train_Epoch_Reward                    11702.22681
Running_Training_Average_Rewards      1112.63948
Explore_Time                          0.01214
Train___Time                          7.00257
Eval____Time                          0.00438
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.71632
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.54914
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.06870
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.72866
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.12378
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.04573
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.46105
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17693.92577
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.57250
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.14171
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.19559      1.53599     12.24014     6.15709
alpha_0                               1.91475      0.00725     1.92709      1.90247
alpha_1                               0.36389      0.00158     0.36658      0.36123
alpha_2                               0.37900      0.00160     0.38169      0.37629
alpha_3                               0.36599      0.00160     0.36872      0.36329
alpha_4                               0.37105      0.00166     0.37386      0.36824
alpha_5                               0.36941      0.00167     0.37226      0.36659
alpha_6                               0.36931      0.00169     0.37218      0.36644
alpha_7                               0.36859      0.00168     0.37144      0.36574
alpha_8                               0.36570      0.00167     0.36854      0.36289
alpha_9                               0.36573      0.00162     0.36849      0.36299
Alpha_loss                            -5.91971     0.07530     -5.74029     -6.06377
Training/policy_loss                  -247.19808   5.21042     -233.88701   -261.61911
Training/qf1_loss                     1921.92031   581.40712   3437.94141   928.16937
Training/qf2_loss                     1634.92091   519.69606   2927.93237   750.42603
Training/pf_norm                      7.59941      4.21372     19.59892     2.32036
Training/qf1_norm                     7374.09055   4818.61679  24183.90625  1705.75317
Training/qf2_norm                     6727.24867   4451.20700  22487.30469  1055.84546
log_std/mean                          -0.13351     0.01094     -0.12029     -0.15525
log_std/std                           0.20547      0.00792     0.22044      0.19105
log_std/max                           0.36219      0.02500     0.40511      0.32781
log_std/min                           -0.82637     0.06963     -0.69691     -1.00420
log_probs/mean                        -1.29881     0.08197     -1.15396     -1.50375
log_probs/std                         3.47646      0.20445     3.83233      3.06128
log_probs/max                         13.12921     1.23220     16.25475     11.26720
log_probs/min                         -5.28012     0.65459     -4.19296     -7.75472
mean/mean                             -0.11577     0.01259     -0.09480     -0.13508
mean/std                              0.75423      0.02672     0.80642      0.69727
mean/max                              2.91920      0.13413     3.21797      2.64293
mean/min                              -3.11561     0.14486     -2.88090     -3.44007
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 5, 2, 4, 1, 0, 8, 9, 6, 7]
replay_buffer._size: [10800 10800 10800 10800 10800 10800 10800 10800 10800 10800]
diff1,diff2 7.028819561004639 2.8848648071289062e-05
train_time 7.028949022293091
2023-09-06 12:32:02,317 MainThread INFO: EPOCH:70
2023-09-06 12:32:02,318 MainThread INFO: Time Consumed:7.041344881057739s
2023-09-06 12:32:02,318 MainThread INFO: Total Frames:106500s
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [07:52<15:31,  7.22s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1249.85485
Train_Epoch_Reward                    20920.96891
Running_Training_Average_Rewards      1444.75371
Explore_Time                          0.00717
Train___Time                          7.02895
Eval____Time                          0.00471
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.61155
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.63186
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.80190
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.66502
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.91160
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.76945
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.29454
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10781.31254
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.17548
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.05390
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.97729      1.39533     12.13067     5.99398
alpha_0                               1.93993      0.00724     1.95234      1.92759
alpha_1                               0.35847      0.00156     0.36112      0.35582
alpha_2                               0.37358      0.00150     0.37618      0.37104
alpha_3                               0.36053      0.00155     0.36318      0.35788
alpha_4                               0.36541      0.00157     0.36813      0.36277
alpha_5                               0.36367      0.00165     0.36647      0.36088
alpha_6                               0.36352      0.00165     0.36633      0.36073
alpha_7                               0.36282      0.00165     0.36563      0.36003
alpha_8                               0.36002      0.00162     0.36278      0.35726
alpha_9                               0.36020      0.00157     0.36288      0.35754
Alpha_loss                            -5.96912     0.12562     -5.67235     -6.19172
Training/policy_loss                  -249.54922   7.02176     -231.74409   -263.22623
Training/qf1_loss                     1938.43053   572.36750   4336.30420   793.42499
Training/qf2_loss                     1626.19116   497.94271   3758.18164   664.47797
Training/pf_norm                      8.21047      6.33152     30.63428     2.27424
Training/qf1_norm                     6523.65025   3832.30169  19126.98438  2265.74023
Training/qf2_norm                     6263.25795   3425.23606  16748.85742  2094.39355
log_std/mean                          -0.12596     0.00333     -0.11983     -0.13273
log_std/std                           0.20830      0.00375     0.21599      0.20106
log_std/max                           0.38509      0.04481     0.43934      0.31717
log_std/min                           -0.79187     0.04933     -0.71031     -0.89625
log_probs/mean                        -1.26146     0.09245     -0.99275     -1.39315
log_probs/std                         3.51621      0.10093     3.74785      3.32253
log_probs/max                         12.74234     0.67673     14.69646     11.44028
log_probs/min                         -5.44000     0.77093     -4.38462     -7.78129
mean/mean                             -0.10641     0.02319     -0.06504     -0.14124
mean/std                              0.76630      0.02887     0.84470      0.72688
mean/max                              2.87376      0.06903     3.02197      2.69863
mean/min                              -3.11015     0.06480     -3.01723     -3.26963
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 2, 5, 7, 9, 3, 1, 4, 0, 8]
replay_buffer._size: [10950 10950 10950 10950 10950 10950 10950 10950 10950 10950]
diff1,diff2 7.063141822814941 1.7642974853515625e-05
train_time 7.063228607177734
2023-09-06 12:32:09,715 MainThread INFO: EPOCH:71
2023-09-06 12:32:09,716 MainThread INFO: Time Consumed:7.207638263702393s
2023-09-06 12:32:09,716 MainThread INFO: Total Frames:108000s
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [07:59<15:30,  7.27s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1221.95526
Train_Epoch_Reward                    10113.69177
Running_Training_Average_Rewards      1424.56292
Explore_Time                          0.13988
Train___Time                          7.06323
Eval____Time                          0.00378
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.78127
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.72610
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -14.35428
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.36625
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.05464
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.53187
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.78245
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9130.21050
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.16498
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.70628
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.23024      1.40190     12.68542     6.30576
alpha_0                               1.96515      0.00724     1.97763      1.95285
alpha_1                               0.35305      0.00156     0.35571      0.35041
alpha_2                               0.36840      0.00145     0.37093      0.36598
alpha_3                               0.35516      0.00152     0.35777      0.35259
alpha_4                               0.36007      0.00152     0.36267      0.35749
alpha_5                               0.35800      0.00162     0.36076      0.35526
alpha_6                               0.35785      0.00162     0.36062      0.35511
alpha_7                               0.35715      0.00162     0.35991      0.35440
alpha_8                               0.35441      0.00160     0.35715      0.35170
alpha_9                               0.35476      0.00157     0.35743      0.35210
Alpha_loss                            -6.04181     0.10382     -5.78453     -6.23716
Training/policy_loss                  -254.60102   6.06352     -238.84341   -269.09775
Training/qf1_loss                     1987.65613   559.92121   3263.29858   1019.79553
Training/qf2_loss                     1630.09417   491.18228   2789.23169   792.54016
Training/pf_norm                      5.67210      2.85492     15.96433     1.80568
Training/qf1_norm                     6728.74279   3552.43469  17766.47266  1427.06177
Training/qf2_norm                     5621.07566   2883.54259  14065.15625  1317.51001
log_std/mean                          -0.12480     0.00447     -0.11632     -0.13336
log_std/std                           0.20967      0.00308     0.21769      0.20527
log_std/max                           0.37149      0.02321     0.41423      0.31228
log_std/min                           -0.79440     0.03551     -0.70839     -0.87762
log_probs/mean                        -1.24749     0.06940     -1.06499     -1.37188
log_probs/std                         3.51569      0.10491     3.77550      3.32712
log_probs/max                         12.92565     0.74826     14.28398     11.07738
log_probs/min                         -5.49922     0.62596     -4.33482     -8.25819
mean/mean                             -0.09887     0.00933     -0.08019     -0.11666
mean/std                              0.77467      0.02403     0.83852      0.73104
mean/max                              2.85047      0.10010     3.08552      2.63933
mean/min                              -3.04113     0.09159     -2.88016     -3.26303
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 4, 1, 6, 2, 0, 7, 8, 9, 5]
replay_buffer._size: [11100 11100 11100 11100 11100 11100 11100 11100 11100 11100]
diff1,diff2 7.135693311691284 1.811981201171875e-05
train_time 7.135804891586304
2023-09-06 12:32:17,064 MainThread INFO: EPOCH:72
2023-09-06 12:32:17,065 MainThread INFO: Time Consumed:7.1439666748046875s
2023-09-06 12:32:17,065 MainThread INFO: Total Frames:109500s
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [08:07<15:27,  7.30s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1038.15672
Train_Epoch_Reward                    12376.25763
Running_Training_Average_Rewards      1447.03061
Explore_Time                          0.00375
Train___Time                          7.13580
Eval____Time                          0.00377
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.91671
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.90308
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.24336
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.27815
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.38423
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.92583
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.24948
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12187.50714
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.44522
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.59910
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.68423      1.18441     11.41771     6.33459
alpha_0                               1.99080      0.00717     2.00325      1.97819
alpha_1                               0.34769      0.00153     0.35030      0.34508
alpha_2                               0.36370      0.00130     0.36588      0.36141
alpha_3                               0.34991      0.00151     0.35248      0.34733
alpha_4                               0.35480      0.00152     0.35738      0.35218
alpha_5                               0.35245      0.00158     0.35515      0.34977
alpha_6                               0.35232      0.00157     0.35500      0.34966
alpha_7                               0.35157      0.00160     0.35429      0.34886
alpha_8                               0.34892      0.00156     0.35159      0.34627
alpha_9                               0.34936      0.00154     0.35199      0.34674
Alpha_loss                            -6.08836     0.15055     -5.79660     -6.35495
Training/policy_loss                  -257.36946   5.63490     -246.16521   -269.25601
Training/qf1_loss                     1721.61022   422.46455   2648.96289   680.01721
Training/qf2_loss                     1380.47483   352.56218   2101.19507   543.40521
Training/pf_norm                      8.65947      5.89159     24.78680     1.91395
Training/qf1_norm                     6895.88691   3999.45186  17183.48828  1890.64258
Training/qf2_norm                     6350.13301   3945.92429  16219.97070  1410.74182
log_std/mean                          -0.12099     0.00601     -0.10912     -0.13134
log_std/std                           0.20715      0.00470     0.21537      0.19974
log_std/max                           0.33424      0.02644     0.39575      0.25264
log_std/min                           -0.86063     0.05925     -0.72445     -0.94627
log_probs/mean                        -1.22020     0.09963     -1.00667     -1.36094
log_probs/std                         3.50189      0.17112     3.86666      3.12889
log_probs/max                         13.23284     0.84255     15.13719     10.95971
log_probs/min                         -5.69766     0.83280     -4.42479     -8.10002
mean/mean                             -0.03256     0.04965     0.04242      -0.09944
mean/std                              0.78305      0.02828     0.84330      0.73345
mean/max                              2.74094      0.10190     2.97246      2.52521
mean/min                              -3.16032     0.09419     -2.99982     -3.34509
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 3, 1, 0, 9, 2, 6, 8, 7, 5]
replay_buffer._size: [11250 11250 11250 11250 11250 11250 11250 11250 11250 11250]
diff1,diff2 7.303696870803833 4.9591064453125e-05
train_time 7.303833723068237
2023-09-06 12:32:24,583 MainThread INFO: EPOCH:73
2023-09-06 12:32:24,584 MainThread INFO: Time Consumed:7.320685625076294s
2023-09-06 12:32:24,584 MainThread INFO: Total Frames:111000s
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [08:14<15:28,  7.37s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               835.24421
Train_Epoch_Reward                    10976.83317
Running_Training_Average_Rewards      1115.55942
Explore_Time                          0.01271
Train___Time                          7.30383
Eval____Time                          0.00363
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.62404
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.07611
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -15.29490
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.34978
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.72100
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.88805
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.04016
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4694.34223
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.95974
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.36639
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.57525      1.24951     11.58810     5.62983
alpha_0                               2.01675      0.00750     2.02886      2.00378
alpha_1                               0.34238      0.00152     0.34498      0.33979
alpha_2                               0.35887      0.00147     0.36131      0.35641
alpha_3                               0.34461      0.00154     0.34722      0.34199
alpha_4                               0.34939      0.00158     0.35207      0.34671
alpha_5                               0.34700      0.00156     0.34966      0.34435
alpha_6                               0.34693      0.00154     0.34955      0.34434
alpha_7                               0.34608      0.00157     0.34875      0.34343
alpha_8                               0.34352      0.00155     0.34616      0.34089
alpha_9                               0.34405      0.00153     0.34664      0.34145
Alpha_loss                            -6.27846     0.08253     -6.06582     -6.39483
Training/policy_loss                  -258.22628   5.28267     -246.51134   -272.10794
Training/qf1_loss                     1673.54427   393.31447   2576.51685   784.15869
Training/qf2_loss                     1332.13971   324.32868   2156.42358   600.43225
Training/pf_norm                      7.19806      4.64156     23.59546     2.57686
Training/qf1_norm                     6793.35516   3442.46028  16501.40820  2614.62842
Training/qf2_norm                     6110.47130   2808.47801  12178.33008  2049.25781
log_std/mean                          -0.11713     0.01140     -0.10043     -0.13484
log_std/std                           0.20920      0.00423     0.21722      0.19860
log_std/max                           0.43973      0.11801     0.62596      0.26551
log_std/min                           -0.82258     0.07980     -0.71728     -1.05696
log_probs/mean                        -1.33752     0.09354     -1.10924     -1.52332
log_probs/std                         3.37437      0.15567     3.82871      3.09291
log_probs/max                         12.76719     0.72456     14.31300     11.52279
log_probs/min                         -5.45757     0.43051     -4.75897     -6.36911
mean/mean                             -0.07578     0.01660     -0.04998     -0.10459
mean/std                              0.74545      0.02873     0.81034      0.69917
mean/max                              2.73407      0.10595     3.05625      2.57104
mean/min                              -2.99314     0.10596     -2.84682     -3.38914
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 5, 1, 8, 7, 2, 0, 6, 9, 4]
replay_buffer._size: [11400 11400 11400 11400 11400 11400 11400 11400 11400 11400]
diff1,diff2 7.173608064651489 4.673004150390625e-05
train_time 7.173731803894043
2023-09-06 12:32:31,950 MainThread INFO: EPOCH:74
2023-09-06 12:32:31,950 MainThread INFO: Time Consumed:7.184314012527466s
2023-09-06 12:32:31,951 MainThread INFO: Total Frames:112500s
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [08:21<15:20,  7.37s/it]------------------------------------  ----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               683.86383
Train_Epoch_Reward                    6443.08801
Running_Training_Average_Rewards      993.20596
Explore_Time                          0.00558
Train___Time                          7.17373
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.00096
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.51877
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -19.50458
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.59847
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.58536
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.03720
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.15915
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4580.16827
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.49307
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.93971
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean        Std         Max          Min
Reward_Mean                           8.68235     1.24411     11.17011     5.06100
alpha_0                               2.04168     0.00728     2.05394      2.02934
alpha_1                               0.33710     0.00152     0.33968      0.33453
alpha_2                               0.35397     0.00144     0.35632      0.35147
alpha_3                               0.33927     0.00154     0.34188      0.33666
alpha_4                               0.34395     0.00156     0.34661      0.34130
alpha_5                               0.34161     0.00155     0.34424      0.33899
alpha_6                               0.34169     0.00152     0.34424      0.33911
alpha_7                               0.34069     0.00155     0.34332      0.33806
alpha_8                               0.33818     0.00153     0.34078      0.33559
alpha_9                               0.33877     0.00152     0.34135      0.33620
Alpha_loss                            -6.44568    0.08782     -6.22134     -6.61162
Training/policy_loss                  -261.07726  5.67953     -249.04185   -272.18607
Training/qf1_loss                     1863.62958  513.80550   3306.20557   1000.78363
Training/qf2_loss                     1446.60958  429.48205   2712.06445   812.05414
Training/pf_norm                      8.43267     5.73681     28.80548     2.09831
Training/qf1_norm                     8521.24859  5636.38067  24295.25000  1749.76123
Training/qf2_norm                     6850.89051  4299.88104  18220.98242  1101.55200
log_std/mean                          -0.11065    0.00319     -0.10519     -0.11763
log_std/std                           0.20998     0.00506     0.21974      0.19952
log_std/max                           0.52217     0.05062     0.62583      0.45182
log_std/min                           -0.86847    0.08831     -0.69230     -1.06448
log_probs/mean                        -1.41203    0.08904     -1.15087     -1.54800
log_probs/std                         3.33479     0.17153     3.75687      3.02248
log_probs/max                         13.18006    1.07216     16.47092     10.79181
log_probs/min                         -5.29984    0.59557     -4.31354     -7.45114
mean/mean                             -0.05147    0.00505     -0.04054     -0.06249
mean/std                              0.72668     0.02649     0.80785      0.68454
mean/max                              2.82367     0.14732     3.14098      2.60925
mean/min                              -3.09332    0.14731     -2.84801     -3.41207
------------------------------------  ----------  ----------  -----------  ----------
sample: [0, 1, 5, 8, 4, 7, 2, 6, 3, 9]
replay_buffer._size: [11550 11550 11550 11550 11550 11550 11550 11550 11550 11550]
diff1,diff2 6.909639596939087 1.7642974853515625e-05
train_time 6.909726619720459
2023-09-06 12:32:39,126 MainThread INFO: EPOCH:75
2023-09-06 12:32:39,126 MainThread INFO: Time Consumed:6.99531364440918s
2023-09-06 12:32:39,126 MainThread INFO: Total Frames:114000s
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [08:29<15:06,  7.31s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               708.00884
Train_Epoch_Reward                    5050.65131
Running_Training_Average_Rewards      749.01908
Explore_Time                          0.08154
Train___Time                          6.90973
Eval____Time                          0.00350
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -39.88702
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.93433
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.32559
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.00602
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.02299
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.22635
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.83882
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12882.98255
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.93906
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.89023
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.53097      1.59358     11.49012     5.11204
alpha_0                               2.06772      0.00776     2.08056      2.05445
alpha_1                               0.33192      0.00147     0.33443      0.32944
alpha_2                               0.34880      0.00151     0.35136      0.34624
alpha_3                               0.33398      0.00150     0.33655      0.33144
alpha_4                               0.33859      0.00152     0.34119      0.33602
alpha_5                               0.33630      0.00152     0.33889      0.33374
alpha_6                               0.33646      0.00149     0.33900      0.33394
alpha_7                               0.33537      0.00152     0.33796      0.33281
alpha_8                               0.33294      0.00150     0.33549      0.33040
alpha_9                               0.33355      0.00149     0.33609      0.33104
Alpha_loss                            -6.52546     0.04253     -6.41715     -6.61626
Training/policy_loss                  -263.55233   6.52598     -249.83946   -276.59619
Training/qf1_loss                     1869.60144   505.85061   2826.88159   1017.60590
Training/qf2_loss                     1463.94324   410.20508   2168.91699   781.19989
Training/pf_norm                      7.75708      5.23138     26.01107     1.63687
Training/qf1_norm                     8740.04853   5457.59644  23415.50195  1793.35266
Training/qf2_norm                     8830.81359   4940.62368  20175.34961  1962.77515
log_std/mean                          -0.12433     0.00610     -0.11306     -0.13535
log_std/std                           0.21423      0.00424     0.22281      0.20791
log_std/max                           0.42945      0.02467     0.47034      0.39488
log_std/min                           -0.83365     0.05475     -0.73837     -0.94772
log_probs/mean                        -1.38507     0.05169     -1.27423     -1.48628
log_probs/std                         3.30780      0.13168     3.60975      3.05061
log_probs/max                         12.94727     0.81873     14.61173     11.30964
log_probs/min                         -5.72930     0.83322     -4.53912     -8.21931
mean/mean                             -0.04945     0.00764     -0.03447     -0.06681
mean/std                              0.73292      0.01373     0.76291      0.70327
mean/max                              2.77274      0.07462     2.92727      2.61851
mean/min                              -3.03647     0.07341     -2.92146     -3.19451
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 2, 1, 7, 6, 4, 0, 9, 5]
replay_buffer._size: [11700 11700 11700 11700 11700 11700 11700 11700 11700 11700]
diff1,diff2 7.404666900634766 1.811981201171875e-05
train_time 7.404965400695801
2023-09-06 12:32:46,719 MainThread INFO: EPOCH:76
2023-09-06 12:32:46,719 MainThread INFO: Time Consumed:7.413866996765137s
2023-09-06 12:32:46,719 MainThread INFO: Total Frames:115500s
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [08:36<15:09,  7.40s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1116.25279
Train_Epoch_Reward                    9057.26372
Running_Training_Average_Rewards      685.03343
Explore_Time                          0.00398
Train___Time                          7.40497
Eval____Time                          0.00442
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.52933
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.89478
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.29885
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.94445
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -33.20778
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.05228
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.21819
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16947.44585
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.63678
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.32270
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.74866      1.50080     11.63272     5.63522
alpha_0                               2.09317      0.00688     2.10472      2.08105
alpha_1                               0.32695      0.00141     0.32935      0.32456
alpha_2                               0.34362      0.00148     0.34614      0.34112
alpha_3                               0.32882      0.00148     0.33134      0.32633
alpha_4                               0.33339      0.00148     0.33591      0.33088
alpha_5                               0.33111      0.00148     0.33364      0.32860
alpha_6                               0.33132      0.00147     0.33383      0.32883
alpha_7                               0.33020      0.00148     0.33271      0.32770
alpha_8                               0.32780      0.00147     0.33030      0.32530
alpha_9                               0.32845      0.00146     0.33094      0.32598
Alpha_loss                            -6.55379     0.04053     -6.47638     -6.64684
Training/policy_loss                  -267.40813   6.39494     -251.13408   -281.87170
Training/qf1_loss                     1825.12958   511.59952   3491.12939   906.56897
Training/qf2_loss                     1379.30304   436.06111   2853.93848   676.26648
Training/pf_norm                      10.20980     5.94411     26.77008     3.10842
Training/qf1_norm                     8501.21750   5377.70367  26225.95703  2222.80615
Training/qf2_norm                     7440.89578   5229.90772  25385.83984  1819.92847
log_std/mean                          -0.14459     0.00575     -0.13712     -0.15631
log_std/std                           0.22557      0.00740     0.24077      0.21358
log_std/max                           0.55544      0.04109     0.59835      0.42520
log_std/min                           -0.94524     0.07235     -0.82917     -1.09096
log_probs/mean                        -1.39344     0.08119     -1.26855     -1.56351
log_probs/std                         3.15104      0.14532     3.40151      2.85016
log_probs/max                         12.57988     0.81502     14.51344     10.44896
log_probs/min                         -5.99782     0.67699     -4.96602     -8.75095
mean/mean                             -0.05871     0.00863     -0.04365     -0.07491
mean/std                              0.72006      0.02175     0.75269      0.68091
mean/max                              2.71279      0.07464     2.85635      2.53614
mean/min                              -3.08491     0.10188     -2.91696     -3.24306
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 0, 5, 3, 6, 2, 7, 1, 4, 9]
replay_buffer._size: [11850 11850 11850 11850 11850 11850 11850 11850 11850 11850]
diff1,diff2 7.166165828704834 1.811981201171875e-05
train_time 7.166245698928833
2023-09-06 12:32:54,093 MainThread INFO: EPOCH:77
2023-09-06 12:32:54,093 MainThread INFO: Time Consumed:7.17883825302124s
2023-09-06 12:32:54,093 MainThread INFO: Total Frames:117000s
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [08:44<15:00,  7.38s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1519.63080
Train_Epoch_Reward                    16313.51559
Running_Training_Average_Rewards      1014.04769
Explore_Time                          0.00611
Train___Time                          7.16625
Eval____Time                          0.00597
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.42479
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.03933
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -18.33245
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.91304
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -39.71498
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.90782
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.98596
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16707.45483
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.56724
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.89797
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.84404      1.68932     12.57148     5.60352
alpha_0                               2.11708      0.00693     2.12879      2.10521
alpha_1                               0.32206      0.00142     0.32447      0.31966
alpha_2                               0.33850      0.00148     0.34102      0.33600
alpha_3                               0.32376      0.00146     0.32623      0.32130
alpha_4                               0.32828      0.00147     0.33078      0.32580
alpha_5                               0.32602      0.00146     0.32850      0.32356
alpha_6                               0.32626      0.00145     0.32873      0.32381
alpha_7                               0.32512      0.00145     0.32760      0.32267
alpha_8                               0.32273      0.00145     0.32520      0.32029
alpha_9                               0.32343      0.00144     0.32588      0.32099
Alpha_loss                            -6.67435     0.04365     -6.57447     -6.77570
Training/policy_loss                  -271.20671   7.34607     -254.31441   -288.06549
Training/qf1_loss                     1966.28493   535.88126   3876.63135   871.21698
Training/qf2_loss                     1470.58322   430.71438   2950.77271   622.49609
Training/pf_norm                      9.04120      5.85192     26.78897     2.11162
Training/qf1_norm                     8221.44662   4390.58584  18825.65820  2356.05273
Training/qf2_norm                     7094.92048   3447.32357  18017.42578  2465.56128
log_std/mean                          -0.12771     0.01267     -0.10942     -0.15066
log_std/std                           0.22094      0.00370     0.22961      0.21564
log_std/max                           0.66989      0.03825     0.71402      0.57995
log_std/min                           -0.97408     0.08980     -0.79188     -1.14003
log_probs/mean                        -1.42984     0.05243     -1.32155     -1.53829
log_probs/std                         3.13495      0.10191     3.38736      2.95339
log_probs/max                         13.13503     1.12734     15.71573     11.34748
log_probs/min                         -5.82782     0.71902     -4.73903     -7.91625
mean/mean                             -0.08056     0.01323     -0.05848     -0.10188
mean/std                              0.70668      0.01522     0.74072      0.68757
mean/max                              2.66044      0.08257     2.84862      2.50147
mean/min                              -3.10074     0.07752     -2.91540     -3.32985
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 2, 5, 9, 4, 6, 1, 3, 7]
replay_buffer._size: [12000 12000 12000 12000 12000 12000 12000 12000 12000 12000]
diff1,diff2 7.307450771331787 4.744529724121094e-05
train_time 7.3075714111328125
2023-09-06 12:33:01,585 MainThread INFO: EPOCH:78
2023-09-06 12:33:01,585 MainThread INFO: Time Consumed:7.329899072647095s
2023-09-06 12:33:01,586 MainThread INFO: Total Frames:118500s
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [08:51<14:58,  7.42s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1563.64499
Train_Epoch_Reward                    19524.94286
Running_Training_Average_Rewards      1496.52407
Explore_Time                          0.01726
Train___Time                          7.30757
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -46.03064
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.16855
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.13739
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.64121
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -38.97057
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.43776
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.31540
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14236.88444
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.01770
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.82757
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.02133      1.52079     13.77392     5.64332
alpha_0                               2.14245      0.00796     2.15653      2.12930
alpha_1                               0.31721      0.00138     0.31956      0.31487
alpha_2                               0.33346      0.00144     0.33590      0.33101
alpha_3                               0.31878      0.00142     0.32120      0.31638
alpha_4                               0.32328      0.00143     0.32570      0.32085
alpha_5                               0.32103      0.00143     0.32346      0.31861
alpha_6                               0.32131      0.00142     0.32371      0.31891
alpha_7                               0.32016      0.00141     0.32257      0.31777
alpha_8                               0.31780      0.00141     0.32019      0.31542
alpha_9                               0.31849      0.00141     0.32089      0.31609
Alpha_loss                            -6.75909     0.07130     -6.62359     -6.88421
Training/policy_loss                  -273.75137   8.01496     -252.82738   -289.36874
Training/qf1_loss                     2008.25018   492.44522   3133.61279   1147.70105
Training/qf2_loss                     1512.63274   401.34187   2382.90625   804.91553
Training/pf_norm                      6.78323      5.32191     36.85006     2.02643
Training/qf1_norm                     10355.38013  5660.49201  23320.29492  2725.96460
Training/qf2_norm                     10798.22276  6813.03844  24514.04102  2196.70264
log_std/mean                          -0.13521     0.01572     -0.10979     -0.15961
log_std/std                           0.23592      0.00890     0.24912      0.21804
log_std/max                           0.71677      0.14382     0.91583      0.48991
log_std/min                           -0.85968     0.04925     -0.76538     -0.99060
log_probs/mean                        -1.33581     0.04494     -1.23709     -1.43067
log_probs/std                         3.27544      0.10865     3.51882      3.08494
log_probs/max                         14.65168     1.36068     17.54266     11.96433
log_probs/min                         -6.12078     0.75405     -4.82085     -8.22967
mean/mean                             -0.05512     0.03352     -0.01593     -0.11173
mean/std                              0.73600      0.01082     0.75824      0.71631
mean/max                              2.77593      0.20807     3.07806      2.45548
mean/min                              -3.10699     0.11231     -2.94975     -3.34533
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 0, 3, 4, 6, 8, 1, 2, 7, 5]
replay_buffer._size: [12150 12150 12150 12150 12150 12150 12150 12150 12150 12150]
diff1,diff2 7.25940465927124 2.9802322387695312e-05
train_time 7.259501934051514
2023-09-06 12:33:09,027 MainThread INFO: EPOCH:79
2023-09-06 12:33:09,027 MainThread INFO: Time Consumed:7.268560886383057s
2023-09-06 12:33:09,027 MainThread INFO: Total Frames:120000s
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [08:58<14:50,  7.42s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1159.82182
Train_Epoch_Reward                    13280.30632
Running_Training_Average_Rewards      1637.29216
Explore_Time                          0.00489
Train___Time                          7.25950
Eval____Time                          0.00354
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -42.91733
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.98365
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.57221
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.92664
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -39.39471
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.29341
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.87058
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4835.43383
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.50276
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -33.32692
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.62000      1.25875     11.21661     5.44857
alpha_0                               2.17140      0.00831     2.18581      2.15716
alpha_1                               0.31249      0.00136     0.31477      0.31016
alpha_2                               0.32853      0.00142     0.33091      0.32610
alpha_3                               0.31391      0.00140     0.31628      0.31153
alpha_4                               0.31838      0.00140     0.32076      0.31599
alpha_5                               0.31612      0.00141     0.31851      0.31373
alpha_6                               0.31647      0.00138     0.31881      0.31411
alpha_7                               0.31531      0.00140     0.31767      0.31293
alpha_8                               0.31298      0.00138     0.31532      0.31064
alpha_9                               0.31363      0.00139     0.31600      0.31126
Alpha_loss                            -6.86775     0.14803     -6.54826     -7.06290
Training/policy_loss                  -274.79612   5.88287     -261.11533   -285.20343
Training/qf1_loss                     1835.21759   505.44213   3369.80640   1071.09729
Training/qf2_loss                     1319.05432   397.52808   2595.46167   616.98779
Training/pf_norm                      5.63664      3.20843     14.66412     1.81055
Training/qf1_norm                     9554.99761   4775.03228  20491.53320  3087.03906
Training/qf2_norm                     6477.14667   3434.22247  18936.01953  1852.31555
log_std/mean                          -0.12845     0.01607     -0.10928     -0.15907
log_std/std                           0.23586      0.01545     0.26488      0.21483
log_std/max                           0.84021      0.03512     0.87846      0.75590
log_std/min                           -0.87549     0.07587     -0.74856     -0.99817
log_probs/mean                        -1.34047     0.10835     -1.11120     -1.50287
log_probs/std                         3.27665      0.13671     3.61676      3.09740
log_probs/max                         14.26706     1.31647     18.09446     12.32068
log_probs/min                         -6.02924     0.68318     -4.98550     -7.49806
mean/mean                             -0.01166     0.02273     0.02799      -0.04751
mean/std                              0.73627      0.02295     0.77493      0.69734
mean/max                              2.76636      0.09441     3.00890      2.64823
mean/min                              -3.07638     0.11700     -2.89062     -3.36104
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 3, 4, 5, 2, 0, 7, 1, 8, 6]
replay_buffer._size: [12300 12300 12300 12300 12300 12300 12300 12300 12300 12300]
diff1,diff2 7.502942323684692 2.956390380859375e-05
train_time 7.503023862838745
2023-09-06 12:33:16,728 MainThread INFO: EPOCH:80
2023-09-06 12:33:16,729 MainThread INFO: Time Consumed:7.518591642379761s
2023-09-06 12:33:16,729 MainThread INFO: Total Frames:121500s
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [09:06<14:53,  7.51s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1075.63220
Train_Epoch_Reward                    6811.98217
Running_Training_Average_Rewards      1320.57438
Explore_Time                          0.01077
Train___Time                          7.50302
Eval____Time                          0.00429
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -47.65109
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.09455
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.46937
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -25.32518
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -45.61080
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.38679
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.20654
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14180.74208
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.34298
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.67213
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.74739      1.48460     11.83483     5.32484
alpha_0                               2.20177      0.00893     2.21701      2.18648
alpha_1                               0.30780      0.00132     0.31007      0.30557
alpha_2                               0.32358      0.00142     0.32600      0.32118
alpha_3                               0.30908      0.00138     0.31143      0.30675
alpha_4                               0.31352      0.00139     0.31589      0.31118
alpha_5                               0.31127      0.00139     0.31364      0.30893
alpha_6                               0.31168      0.00137     0.31402      0.30936
alpha_7                               0.31049      0.00138     0.31284      0.30816
alpha_8                               0.30822      0.00136     0.31054      0.30591
alpha_9                               0.30883      0.00137     0.31117      0.30651
Alpha_loss                            -6.95565     0.04216     -6.86414     -7.03011
Training/policy_loss                  -277.99520   6.10701     -264.12350   -293.00949
Training/qf1_loss                     2011.99691   479.19282   2987.22437   814.52979
Training/qf2_loss                     1431.92578   367.66598   2125.32007   619.90833
Training/pf_norm                      7.54657      4.54622     23.48672     2.16210
Training/qf1_norm                     10262.49429  4770.75513  23996.99414  3247.97437
Training/qf2_norm                     9004.75148   5000.23167  22907.00195  2147.37256
log_std/mean                          -0.14351     0.00744     -0.12780     -0.15553
log_std/std                           0.23883      0.01013     0.26275      0.22822
log_std/max                           0.64134      0.14897     0.93629      0.44272
log_std/min                           -0.89751     0.02938     -0.84099     -0.94876
log_probs/mean                        -1.32309     0.06285     -1.17994     -1.42390
log_probs/std                         3.30007      0.09013     3.48004      3.10515
log_probs/max                         14.35261     1.06279     17.39345     12.54198
log_probs/min                         -6.19953     1.00597     -4.72371     -10.02010
mean/mean                             -0.00811     0.02413     0.03127      -0.05080
mean/std                              0.74240      0.01249     0.76858      0.72144
mean/max                              2.74388      0.07730     2.92611      2.61554
mean/min                              -3.14019     0.12243     -2.90997     -3.37114
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 4, 3, 5, 2, 9, 0, 6, 1, 7]
replay_buffer._size: [12450 12450 12450 12450 12450 12450 12450 12450 12450 12450]
diff1,diff2 7.269534349441528 1.7642974853515625e-05
train_time 7.269612550735474
2023-09-06 12:33:24,225 MainThread INFO: EPOCH:81
2023-09-06 12:33:24,225 MainThread INFO: Time Consumed:7.277102947235107s
2023-09-06 12:33:24,225 MainThread INFO: Total Frames:123000s
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [09:14<14:44,  7.50s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1144.93490
Train_Epoch_Reward                    12046.77109
Running_Training_Average_Rewards      1071.30199
Explore_Time                          0.00361
Train___Time                          7.26961
Eval____Time                          0.00324
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -56.34899
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.26121
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.06273
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -27.61435
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -40.84555
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.39110
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.63071
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 16327.95568
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.06857
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.31388
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.57487      1.28156     11.55592     6.42350
alpha_0                               2.23309      0.00923     2.24915      2.21765
alpha_1                               0.30330      0.00129     0.30548      0.30111
alpha_2                               0.31870      0.00142     0.32109      0.31628
alpha_3                               0.30438      0.00134     0.30665      0.30210
alpha_4                               0.30880      0.00134     0.31109      0.30656
alpha_5                               0.30653      0.00135     0.30883      0.30425
alpha_6                               0.30702      0.00131     0.30927      0.30480
alpha_7                               0.30577      0.00135     0.30807      0.30349
alpha_8                               0.30359      0.00131     0.30582      0.30137
alpha_9                               0.30414      0.00134     0.30642      0.30187
Alpha_loss                            -6.99752     0.06822     -6.78921     -7.13258
Training/policy_loss                  -281.14310   6.99133     -265.17551   -299.51114
Training/qf1_loss                     1896.75996   458.18052   2923.94214   951.54315
Training/qf2_loss                     1338.31256   351.52125   2186.40796   684.11548
Training/pf_norm                      6.92583      4.00441     18.37585     2.07747
Training/qf1_norm                     9249.98502   4732.55476  19624.53320  2562.93408
Training/qf2_norm                     8006.52101   4253.84941  17163.41016  1688.88318
log_std/mean                          -0.15090     0.01140     -0.13422     -0.17363
log_std/std                           0.23710      0.00979     0.26017      0.22091
log_std/max                           0.59743      0.21920     0.93845      0.30742
log_std/min                           -0.87162     0.03054     -0.82905     -0.94146
log_probs/mean                        -1.25513     0.05520     -1.15418     -1.41747
log_probs/std                         3.37357      0.14246     3.68961      2.96232
log_probs/max                         14.86635     0.81142     16.76188     13.23306
log_probs/min                         -6.08444     0.65207     -4.91811     -8.01349
mean/mean                             0.04213      0.00871     0.07870      0.02346
mean/std                              0.76065      0.01442     0.79019      0.72098
mean/max                              2.83041      0.06967     2.96506      2.69727
mean/min                              -3.15655     0.08108     -3.00048     -3.35916
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 0, 5, 6, 9, 3, 8, 1, 2, 4]
replay_buffer._size: [12600 12600 12600 12600 12600 12600 12600 12600 12600 12600]
diff1,diff2 7.302933692932129 1.8596649169921875e-05
train_time 7.3030102252960205
2023-09-06 12:33:31,708 MainThread INFO: EPOCH:82
2023-09-06 12:33:31,708 MainThread INFO: Time Consumed:7.314683675765991s
2023-09-06 12:33:31,709 MainThread INFO: Total Frames:124500s
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [09:21<14:38,  7.51s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1200.42418
Train_Epoch_Reward                    18598.05027
Running_Training_Average_Rewards      1248.56012
Explore_Time                          0.00487
Train___Time                          7.30301
Eval____Time                          0.00618
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.13468
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.37172
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -20.99989
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.94943
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -42.47953
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.73068
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.79347
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6520.00139
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.83115
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.38662
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.13653      1.49862     12.25526     5.63129
alpha_0                               2.26649      0.00988     2.28283      2.24984
alpha_1                               0.29888      0.00126     0.30102      0.29674
alpha_2                               0.31388      0.00135     0.31619      0.31160
alpha_3                               0.29980      0.00129     0.30201      0.29762
alpha_4                               0.30427      0.00129     0.30647      0.30209
alpha_5                               0.30190      0.00133     0.30416      0.29965
alpha_6                               0.30257      0.00125     0.30471      0.30045
alpha_7                               0.30113      0.00133     0.30339      0.29888
alpha_8                               0.29913      0.00126     0.30128      0.29698
alpha_9                               0.29955      0.00131     0.30177      0.29733
Alpha_loss                            -6.96780     0.06836     -6.86112     -7.15926
Training/policy_loss                  -285.23390   6.56520     -271.10849   -300.48862
Training/qf1_loss                     2021.74036   534.84478   3527.43604   1072.34204
Training/qf2_loss                     1393.87655   416.95784   2648.30298   638.83716
Training/pf_norm                      11.97690     8.50497     38.83234     3.43491
Training/qf1_norm                     10040.67855  5944.11743  29509.03711  3664.05176
Training/qf2_norm                     8310.49955   4212.51388  19676.90430  1198.59277
log_std/mean                          -0.17043     0.00641     -0.15954     -0.17923
log_std/std                           0.24309      0.01221     0.26448      0.22393
log_std/max                           0.33105      0.02555     0.38360      0.27352
log_std/min                           -0.92755     0.04710     -0.83879     -1.00288
log_probs/mean                        -1.16120     0.08964     -0.96447     -1.30316
log_probs/std                         3.37002      0.15438     3.70255      3.04562
log_probs/max                         14.34368     1.16352     18.43770     11.71352
log_probs/min                         -6.65404     0.75373     -5.27570     -8.34032
mean/mean                             0.07659      0.02657     0.11985      0.03667
mean/std                              0.77487      0.02130     0.81467      0.74084
mean/max                              2.77642      0.08069     2.90438      2.58660
mean/min                              -3.18393     0.14307     -2.94922     -3.53280
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 0, 4, 5, 6, 3, 8, 9, 1, 2]
replay_buffer._size: [12750 12750 12750 12750 12750 12750 12750 12750 12750 12750]
diff1,diff2 7.610579967498779 4.792213439941406e-05
train_time 7.610735654830933
2023-09-06 12:33:39,557 MainThread INFO: EPOCH:83
2023-09-06 12:33:39,557 MainThread INFO: Time Consumed:7.620252847671509s
2023-09-06 12:33:39,557 MainThread INFO: Total Frames:126000s
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [09:29<14:42,  7.61s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1324.46433
Train_Epoch_Reward                    10013.45502
Running_Training_Average_Rewards      1355.27588
Explore_Time                          0.00523
Train___Time                          7.61074
Eval____Time                          0.00360
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.70794
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -23.41662
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.44278
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -21.89255
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -35.07672
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.63641
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.39106
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17869.49554
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -22.24129
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.50298
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.86899      1.44862     12.09949     5.99286
alpha_0                               2.30080      0.01009     2.31703      2.28343
alpha_1                               0.29453      0.00126     0.29665      0.29238
alpha_2                               0.30932      0.00128     0.31151      0.30715
alpha_3                               0.29540      0.00126     0.29753      0.29325
alpha_4                               0.29980      0.00131     0.30200      0.29758
alpha_5                               0.29733      0.00131     0.29956      0.29511
alpha_6                               0.29825      0.00125     0.30036      0.29612
alpha_7                               0.29658      0.00130     0.29879      0.29437
alpha_8                               0.29473      0.00128     0.29689      0.29256
alpha_9                               0.29506      0.00128     0.29724      0.29289
Alpha_loss                            -7.10263     0.08167     -6.90049     -7.23854
Training/policy_loss                  -287.39582   7.98298     -271.25607   -306.42972
Training/qf1_loss                     2028.27922   503.48580   3379.83374   1280.59705
Training/qf2_loss                     1350.40358   370.75961   2384.43140   780.45111
Training/pf_norm                      9.43315      4.90701     21.93568     2.03376
Training/qf1_norm                     9475.83859   5245.22086  26459.86523  2178.58740
Training/qf2_norm                     7226.41363   4237.11662  22777.64648  2106.32788
log_std/mean                          -0.14741     0.01097     -0.12928     -0.16709
log_std/std                           0.23718      0.01758     0.27037      0.21444
log_std/max                           0.36855      0.02175     0.41106      0.32075
log_std/min                           -0.87466     0.09877     -0.74949     -1.09468
log_probs/mean                        -1.17701     0.13877     -0.82208     -1.35724
log_probs/std                         3.42612      0.27523     4.06503      2.99314
log_probs/max                         14.94539     1.80111     19.98272     12.26837
log_probs/min                         -6.30421     0.80201     -5.20080     -8.90431
mean/mean                             0.07716      0.03649     0.13848      0.02152
mean/std                              0.77969      0.03790     0.86793      0.72025
mean/max                              2.87219      0.23201     3.36540      2.58066
mean/min                              -3.25425     0.22386     -2.87711     -3.66721
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 6, 9, 8, 5, 7, 2, 0, 4]
replay_buffer._size: [12900 12900 12900 12900 12900 12900 12900 12900 12900 12900]
diff1,diff2 7.631303310394287 2.9325485229492188e-05
train_time 7.6314239501953125
2023-09-06 12:33:47,400 MainThread INFO: EPOCH:84
2023-09-06 12:33:47,401 MainThread INFO: Time Consumed:7.643656253814697s
2023-09-06 12:33:47,401 MainThread INFO: Total Frames:127500s
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [09:37<14:41,  7.67s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               930.09131
Train_Epoch_Reward                    19474.92135
Running_Training_Average_Rewards      1602.88089
Explore_Time                          0.00762
Train___Time                          7.63142
Eval____Time                          0.00334
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -49.74652
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -25.05646
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -21.52226
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -26.76118
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -44.09427
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -84.10340
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -22.10947
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 4498.62424
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -22.84602
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.15664
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.72743      1.34607     12.43015     6.66217
alpha_0                               2.33247      0.00896     2.34861      2.31764
alpha_1                               0.29019      0.00123     0.29229      0.28811
alpha_2                               0.30495      0.00123     0.30706      0.30288
alpha_3                               0.29107      0.00122     0.29316      0.28901
alpha_4                               0.29531      0.00128     0.29749      0.29316
alpha_5                               0.29283      0.00128     0.29502      0.29067
alpha_6                               0.29395      0.00121     0.29603      0.29191
alpha_7                               0.29211      0.00128     0.29428      0.28995
alpha_8                               0.29032      0.00126     0.29247      0.28819
alpha_9                               0.29065      0.00126     0.29280      0.28851
Alpha_loss                            -7.06123     0.07890     -6.82902     -7.22260
Training/policy_loss                  -289.39958   6.68697     -276.49118   -306.08130
Training/qf1_loss                     1992.24137   513.93259   3447.91577   931.05743
Training/qf2_loss                     1329.23906   376.48483   2447.30176   591.13135
Training/pf_norm                      10.72198     8.13213     45.75123     3.61996
Training/qf1_norm                     9761.91503   5486.73619  23459.00000  1659.66309
Training/qf2_norm                     10300.32481  6191.73241  29977.46094  1284.38367
log_std/mean                          -0.16990     0.01632     -0.15085     -0.20113
log_std/std                           0.24326      0.00875     0.27305      0.23430
log_std/max                           0.31149      0.01695     0.34442      0.27925
log_std/min                           -0.90703     0.04435     -0.84625     -1.00827
log_probs/mean                        -1.11957     0.10875     -0.82593     -1.30818
log_probs/std                         3.32268      0.18380     3.79901      2.89186
log_probs/max                         15.02944     1.86510     20.56372     11.53833
log_probs/min                         -6.68973     0.80918     -5.32646     -9.03572
mean/mean                             0.06539      0.03361     0.15460      0.01866
mean/std                              0.78820      0.02338     0.83584      0.75427
mean/max                              2.88391      0.18049     3.22786      2.60039
mean/min                              -3.29182     0.16412     -2.99744     -3.59966
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 2, 3, 9, 1, 0, 7, 8, 4, 6]
replay_buffer._size: [13050 13050 13050 13050 13050 13050 13050 13050 13050 13050]
diff1,diff2 7.626421928405762 1.7881393432617188e-05
train_time 7.626502990722656
2023-09-06 12:33:55,306 MainThread INFO: EPOCH:85
2023-09-06 12:33:55,306 MainThread INFO: Time Consumed:7.63704514503479s
2023-09-06 12:33:55,306 MainThread INFO: Total Frames:129000s
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [09:45<14:43,  7.75s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1076.98327
Train_Epoch_Reward                    5963.48540
Running_Training_Average_Rewards      1181.72873
Explore_Time                          0.00674
Train___Time                          7.62650
Eval____Time                          0.00330
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.34684
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -24.30279
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.68485
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.52791
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.96988
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -79.31825
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.36422
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10897.98907
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.47907
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -34.91222
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.96535      1.37390     12.70714     5.87763
alpha_0                               2.36669      0.01013     2.38381      2.34933
alpha_1                               0.28603      0.00119     0.28803      0.28398
alpha_2                               0.30095      0.00111     0.30280      0.29903
alpha_3                               0.28699      0.00116     0.28893      0.28500
alpha_4                               0.29099      0.00123     0.29307      0.28888
alpha_5                               0.28844      0.00126     0.29058      0.28630
alpha_6                               0.28987      0.00117     0.29183      0.28785
alpha_7                               0.28776      0.00124     0.28986      0.28564
alpha_8                               0.28606      0.00121     0.28811      0.28398
alpha_9                               0.28634      0.00123     0.28843      0.28424
Alpha_loss                            -7.04460     0.23999     -6.64090     -7.42604
Training/policy_loss                  -292.51962   8.30078     -271.81589   -311.21262
Training/qf1_loss                     2032.77902   513.94473   3166.99683   1014.85663
Training/qf2_loss                     1346.92766   379.15127   2237.99390   629.70209
Training/pf_norm                      10.29444     6.73453     35.05788     2.90138
Training/qf1_norm                     11103.26936  6386.89244  28194.31836  2338.98950
Training/qf2_norm                     10739.97479  6076.06861  27355.88672  2351.34277
log_std/mean                          -0.16950     0.01098     -0.15411     -0.18866
log_std/std                           0.24367      0.02213     0.28375      0.21431
log_std/max                           0.35125      0.05201     0.49087      0.27905
log_std/min                           -0.89578     0.06591     -0.78603     -1.02009
log_probs/mean                        -0.99347     0.19587     -0.56239     -1.26759
log_probs/std                         3.39478      0.14580     3.72882      3.09225
log_probs/max                         14.67220     1.23461     17.38987     12.96829
log_probs/min                         -6.69128     0.92720     -5.18234     -9.11149
mean/mean                             0.10338      0.06474     0.20929      0.03026
mean/std                              0.81161      0.03258     0.88647      0.76564
mean/max                              2.75905      0.08947     2.93572      2.63983
mean/min                              -3.20235     0.09393     -2.96923     -3.36504
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 9, 7, 5, 0, 1, 8, 3, 4, 6]
replay_buffer._size: [13200 13200 13200 13200 13200 13200 13200 13200 13200 13200]
diff1,diff2 7.501786231994629 2.8848648071289062e-05
train_time 7.501891613006592
2023-09-06 12:34:03,043 MainThread INFO: EPOCH:86
2023-09-06 12:34:03,044 MainThread INFO: Time Consumed:7.512120962142944s
2023-09-06 12:34:03,044 MainThread INFO: Total Frames:130500s
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [09:53<14:34,  7.74s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               768.94786
Train_Epoch_Reward                    14379.09038
Running_Training_Average_Rewards      1327.24990
Explore_Time                          0.00538
Train___Time                          7.50189
Eval____Time                          0.00430
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.52124
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -23.74512
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.32498
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.85006
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.02714
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -83.52492
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -23.01675
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8690.83821
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.39621
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.30709
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.89235      1.30365     12.13673     5.75574
alpha_0                               2.40279      0.01120     2.42254      2.38452
alpha_1                               0.28187      0.00119     0.28390      0.27986
alpha_2                               0.29714      0.00105     0.29895      0.29541
alpha_3                               0.28297      0.00113     0.28492      0.28107
alpha_4                               0.28671      0.00122     0.28880      0.28464
alpha_5                               0.28410      0.00124     0.28622      0.28200
alpha_6                               0.28575      0.00118     0.28776      0.28376
alpha_7                               0.28348      0.00122     0.28555      0.28142
alpha_8                               0.28182      0.00122     0.28390      0.27975
alpha_9                               0.28207      0.00122     0.28415      0.28000
Alpha_loss                            -7.11596     0.09200     -6.90914     -7.40156
Training/policy_loss                  -294.37643   5.79857     -280.31070   -307.06113
Training/qf1_loss                     1983.74782   480.48264   2971.76440   1010.58466
Training/qf2_loss                     1267.83121   332.28030   2147.58252   603.32892
Training/pf_norm                      5.90349      2.89729     16.52593     2.68521
Training/qf1_norm                     9429.01890   5730.95476  25916.41992  2399.17065
Training/qf2_norm                     7313.32870   4774.36576  24073.87109  2364.61597
log_std/mean                          -0.21276     0.01657     -0.18787     -0.23474
log_std/std                           0.25495      0.00862     0.27262      0.23683
log_std/max                           0.46175      0.08997     0.64299      0.30493
log_std/min                           -0.91591     0.03837     -0.83797     -0.98032
log_probs/mean                        -0.90129     0.12119     -0.60122     -1.13403
log_probs/std                         3.54989      0.20766     4.12184      3.24314
log_probs/max                         15.54564     1.49198     18.71304     13.39194
log_probs/min                         -6.79681     0.89001     -5.11277     -9.90586
mean/mean                             0.07395      0.03971     0.17755      0.01449
mean/std                              0.83716      0.02732     0.89860      0.78862
mean/max                              2.90607      0.17177     3.40595      2.68686
mean/min                              -3.27255     0.14566     -3.01580     -3.65238
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 5, 6, 7, 3, 2, 0, 8, 9, 4]
replay_buffer._size: [13350 13350 13350 13350 13350 13350 13350 13350 13350 13350]
diff1,diff2 7.937929153442383 1.811981201171875e-05
train_time 7.937986135482788
2023-09-06 12:34:11,124 MainThread INFO: EPOCH:87
2023-09-06 12:34:11,124 MainThread INFO: Time Consumed:7.947032690048218s
2023-09-06 12:34:11,125 MainThread INFO: Total Frames:132000s
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:01<14:38,  7.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               855.00546
Train_Epoch_Reward                    5266.21694
Running_Training_Average_Rewards      853.62642
Explore_Time                          0.00494
Train___Time                          7.93799
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.62699
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.70939
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.37437
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -31.26493
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.06693
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.99734
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.66441
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7098.72194
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.23188
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.82971
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.60635      1.49678     11.40022     4.23728
alpha_0                               2.44142      0.01011     2.45823      2.42336
alpha_1                               0.27783      0.00115     0.27978      0.27587
alpha_2                               0.29371      0.00099     0.29534      0.29197
alpha_3                               0.27918      0.00107     0.28100      0.27735
alpha_4                               0.28252      0.00119     0.28456      0.28050
alpha_5                               0.27984      0.00122     0.28192      0.27778
alpha_6                               0.28180      0.00110     0.28368      0.27993
alpha_7                               0.27930      0.00120     0.28134      0.27725
alpha_8                               0.27766      0.00118     0.27967      0.27565
alpha_9                               0.27793      0.00117     0.27992      0.27595
Alpha_loss                            -7.04535     0.11799     -6.85731     -7.34359
Training/policy_loss                  -295.04466   7.22124     -280.27921   -312.90036
Training/qf1_loss                     1998.73092   548.63547   3101.64087   598.29004
Training/qf2_loss                     1226.38405   366.95052   2013.49609   444.03619
Training/pf_norm                      5.58905      2.50514     13.81280     2.28666
Training/qf1_norm                     13452.73052  8511.60012  44050.84766  3084.57690
Training/qf2_norm                     7887.95095   5347.00086  27691.24414  1675.42322
log_std/mean                          -0.22187     0.00469     -0.21326     -0.23141
log_std/std                           0.25876      0.00571     0.27593      0.24892
log_std/max                           0.68778      0.13843     0.88762      0.36106
log_std/min                           -0.95252     0.03823     -0.88562     -1.03099
log_probs/mean                        -0.88285     0.10491     -0.63297     -1.08426
log_probs/std                         3.36369      0.16072     3.68144      3.06122
log_probs/max                         14.32480     0.94139     16.51970     12.10894
log_probs/min                         -6.94294     0.93284     -5.42560     -9.21820
mean/mean                             0.12389      0.02882     0.18186      0.07860
mean/std                              0.82702      0.02184     0.88114      0.77954
mean/max                              2.76107      0.11841     2.98260      2.51336
mean/min                              -3.14371     0.13296     -2.83124     -3.39781
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 4, 9, 1, 5, 0, 6, 7, 2, 8]
replay_buffer._size: [13500 13500 13500 13500 13500 13500 13500 13500 13500 13500]
diff1,diff2 7.618971347808838 5.030632019042969e-05
train_time 7.619100093841553
2023-09-06 12:34:18,951 MainThread INFO: EPOCH:88
2023-09-06 12:34:18,952 MainThread INFO: Time Consumed:7.638748407363892s
2023-09-06 12:34:18,952 MainThread INFO: Total Frames:133500s
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:08<14:29,  7.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               876.21762
Train_Epoch_Reward                    5846.58400
Running_Training_Average_Rewards      849.72971
Explore_Time                          0.01378
Train___Time                          7.61910
Eval____Time                          0.00479
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -57.81711
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.04381
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.95416
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -35.17584
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -45.39803
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.67187
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.45031
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11569.78930
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.46928
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.36085
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.58006      1.61705     12.62701     5.12926
alpha_0                               2.47643      0.01017     2.49327      2.45898
alpha_1                               0.27381      0.00116     0.27579      0.27185
alpha_2                               0.29013      0.00101     0.29189      0.28845
alpha_3                               0.27543      0.00108     0.27728      0.27361
alpha_4                               0.27840      0.00118     0.28041      0.27641
alpha_5                               0.27565      0.00120     0.27770      0.27362
alpha_6                               0.27797      0.00110     0.27985      0.27611
alpha_7                               0.27515      0.00118     0.27717      0.27314
alpha_8                               0.27357      0.00117     0.27557      0.27159
alpha_9                               0.27390      0.00115     0.27587      0.27195
Alpha_loss                            -7.12871     0.10511     -6.89571     -7.32021
Training/policy_loss                  -296.91440   7.72898     -280.61816   -317.02615
Training/qf1_loss                     2009.07421   524.55360   3252.21436   941.46625
Training/qf2_loss                     1193.20584   338.77490   1811.58032   437.35284
Training/pf_norm                      7.36624      3.64972     22.87100     2.39757
Training/qf1_norm                     14663.00748  8762.95279  38094.46094  2965.56616
Training/qf2_norm                     8201.17874   4652.62813  18218.04297  2050.26709
log_std/mean                          -0.20814     0.00760     -0.19447     -0.22442
log_std/std                           0.25608      0.00571     0.26561      0.24279
log_std/max                           0.82155      0.12485     0.99580      0.55204
log_std/min                           -0.90251     0.02273     -0.86112     -0.95357
log_probs/mean                        -0.91535     0.10046     -0.66128     -1.07658
log_probs/std                         3.32114      0.17816     3.65573      2.93077
log_probs/max                         14.35795     1.23281     18.19622     11.86279
log_probs/min                         -6.85842     0.95580     -5.44716     -9.21149
mean/mean                             0.10861      0.03167     0.18009      0.06088
mean/std                              0.82327      0.02056     0.87251      0.79384
mean/max                              2.72463      0.10392     2.95393      2.56164
mean/min                              -3.19585     0.11611     -2.95561     -3.39575
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 7, 6, 4, 2, 0, 1, 5, 8, 9]
replay_buffer._size: [13650 13650 13650 13650 13650 13650 13650 13650 13650 13650]
diff1,diff2 7.644906044006348 2.002716064453125e-05
train_time 7.644992828369141
2023-09-06 12:34:26,803 MainThread INFO: EPOCH:89
2023-09-06 12:34:26,803 MainThread INFO: Time Consumed:7.664248704910278s
2023-09-06 12:34:26,803 MainThread INFO: Total Frames:135000s
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:16<14:22,  7.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               899.47831
Train_Epoch_Reward                    12847.89245
Running_Training_Average_Rewards      798.68978
Explore_Time                          0.01192
Train___Time                          7.64499
Eval____Time                          0.00669
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.79614
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -18.89703
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.68715
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.33571
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -27.85143
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.07885
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.85998
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9331.80524
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -21.55103
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.80274
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.16365      1.30522     11.75081     5.53902
alpha_0                               2.50878      0.00905     2.52511      2.49385
alpha_1                               0.26983      0.00114     0.27177      0.26788
alpha_2                               0.28669      0.00102     0.28839      0.28491
alpha_3                               0.27172      0.00107     0.27353      0.26988
alpha_4                               0.27435      0.00116     0.27633      0.27238
alpha_5                               0.27153      0.00118     0.27354      0.26953
alpha_6                               0.27421      0.00107     0.27603      0.27238
alpha_7                               0.27107      0.00117     0.27306      0.26909
alpha_8                               0.26954      0.00116     0.27151      0.26757
alpha_9                               0.26997      0.00113     0.27188      0.26805
Alpha_loss                            -7.24122     0.17335     -6.86713     -7.57455
Training/policy_loss                  -299.35887   7.42418     -281.43170   -319.26865
Training/qf1_loss                     1891.25745   451.00742   3622.51831   712.87689
Training/qf2_loss                     1089.00119   330.02311   2378.33667   361.54733
Training/pf_norm                      8.56933      5.80522     34.13198     2.13860
Training/qf1_norm                     9840.75304   5464.78735  25340.35547  3005.10693
Training/qf2_norm                     8599.78800   4834.29387  22232.62695  2610.86353
log_std/mean                          -0.22093     0.00448     -0.21360     -0.23023
log_std/std                           0.25045      0.00812     0.27481      0.23638
log_std/max                           0.64568      0.13105     0.86715      0.34330
log_std/min                           -0.92769     0.03456     -0.87628     -1.03397
log_probs/mean                        -0.95480     0.08234     -0.78071     -1.12027
log_probs/std                         3.31930      0.19774     3.73852      2.88342
log_probs/max                         14.65033     0.97544     17.24067     11.89318
log_probs/min                         -6.87894     0.86721     -5.73225     -9.64530
mean/mean                             0.08162      0.02261     0.13276      0.03600
mean/std                              0.82105      0.01856     0.86100      0.78359
mean/max                              2.80671      0.09865     2.98527      2.57964
mean/min                              -3.26612     0.11812     -3.08169     -3.49694
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 8, 0, 4, 3, 1, 6, 5, 9, 2]
replay_buffer._size: [13800 13800 13800 13800 13800 13800 13800 13800 13800 13800]
diff1,diff2 7.761641025543213 2.9087066650390625e-05
train_time 7.761736631393433
2023-09-06 12:34:34,779 MainThread INFO: EPOCH:90
2023-09-06 12:34:34,779 MainThread INFO: Time Consumed:7.779787063598633s
2023-09-06 12:34:34,779 MainThread INFO: Total Frames:136500s
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:24<14:19,  7.89s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               895.11912
Train_Epoch_Reward                    10621.09202
Running_Training_Average_Rewards      977.18562
Explore_Time                          0.01117
Train___Time                          7.76174
Eval____Time                          0.00638
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.80152
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.65347
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.05144
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -35.68436
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.70593
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.32676
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  435.12903
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 6525.95217
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -27.49317
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.18405
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.68558      1.56939     11.93640     5.32352
alpha_0                               2.54629      0.01158     2.56487      2.52593
alpha_1                               0.26590      0.00111     0.26780      0.26402
alpha_2                               0.28318      0.00097     0.28483      0.28151
alpha_3                               0.26809      0.00099     0.26981      0.26640
alpha_4                               0.27034      0.00114     0.27230      0.26841
alpha_5                               0.26748      0.00115     0.26945      0.26554
alpha_6                               0.27060      0.00098     0.27231      0.26895
alpha_7                               0.26707      0.00114     0.26901      0.26514
alpha_8                               0.26557      0.00112     0.26748      0.26365
alpha_9                               0.26614      0.00107     0.26797      0.26432
Alpha_loss                            -7.10883     0.14274     -6.81374     -7.37941
Training/policy_loss                  -303.79017   7.18171     -288.73276   -317.99615
Training/qf1_loss                     2034.09376   636.76122   3761.55713   932.99640
Training/qf2_loss                     1153.84213   388.45816   2241.37964   471.63361
Training/pf_norm                      6.22870      3.68569     19.48974     2.72992
Training/qf1_norm                     15425.91018  8916.76510  35848.30859  2873.89038
Training/qf2_norm                     10077.65182  7101.91340  34492.81641  2168.02075
log_std/mean                          -0.25000     0.01315     -0.21968     -0.27068
log_std/std                           0.26113      0.02684     0.29745      0.22078
log_std/max                           0.59252      0.12128     0.74081      0.30186
log_std/min                           -0.96560     0.10029     -0.83771     -1.13243
log_probs/mean                        -0.71207     0.14654     -0.42920     -0.92305
log_probs/std                         3.42133      0.20520     3.92500      3.07781
log_probs/max                         14.71710     1.52260     18.27821     12.54998
log_probs/min                         -7.16611     1.07729     -5.32816     -10.36486
mean/mean                             0.16634      0.06344     0.27013      0.09547
mean/std                              0.85174      0.01851     0.89736      0.81797
mean/max                              2.87086      0.19694     3.37257      2.62360
mean/min                              -3.21433     0.15249     -2.86020     -3.45686
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 1, 2, 8, 0, 5, 3, 7, 9, 4]
replay_buffer._size: [13950 13950 13950 13950 13954 13957 13951 13950 13950 13950]
diff1,diff2 7.582298040390015 3.0994415283203125e-05
train_time 7.5824079513549805
2023-09-06 12:34:42,579 MainThread INFO: EPOCH:91
2023-09-06 12:34:42,579 MainThread INFO: Time Consumed:7.640262126922607s
2023-09-06 12:34:42,580 MainThread INFO: Total Frames:138000s
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:32<14:09,  7.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               931.31685
Train_Epoch_Reward                    8259.82216
Running_Training_Average_Rewards      1057.62689
Explore_Time                          0.05362
Train___Time                          7.58241
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.63882
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.85137
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -32.31958
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -29.41105
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -32.08324
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.85161
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.69783
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12663.75084
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -22.29598
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.22162
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.45906      1.20211     11.55584     5.77827
alpha_0                               2.58226      0.00994     2.59912      2.56553
alpha_1                               0.26205      0.00111     0.26394      0.26016
alpha_2                               0.27974      0.00099     0.28144      0.27806
alpha_3                               0.26459      0.00101     0.26633      0.26289
alpha_4                               0.26641      0.00113     0.26833      0.26449
alpha_5                               0.26352      0.00114     0.26546      0.26159
alpha_6                               0.26717      0.00100     0.26888      0.26548
alpha_7                               0.26312      0.00114     0.26506      0.26120
alpha_8                               0.26164      0.00114     0.26357      0.25971
alpha_9                               0.26241      0.00108     0.26425      0.26058
Alpha_loss                            -7.27633     0.08882     -7.11168     -7.50454
Training/policy_loss                  -303.70942   8.05144     -285.18747   -322.00949
Training/qf1_loss                     2003.70653   503.98717   3300.68286   832.01202
Training/qf2_loss                     1141.57283   311.21061   2084.93799   400.86996
Training/pf_norm                      9.12964      5.32421     33.46546     3.13082
Training/qf1_norm                     9428.96781   5581.17770  25688.86328  2254.16382
Training/qf2_norm                     7410.14902   4343.92875  23610.34961  2151.88696
log_std/mean                          -0.23835     0.00402     -0.23018     -0.24761
log_std/std                           0.24478      0.01007     0.26235      0.22100
log_std/max                           0.51611      0.13767     0.73479      0.29470
log_std/min                           -0.90855     0.04072     -0.82936     -0.97707
log_probs/mean                        -0.86758     0.08916     -0.66320     -1.02962
log_probs/std                         3.30244      0.13602     3.61935      3.08618
log_probs/max                         14.26281     1.06015     17.19213     12.58227
log_probs/min                         -7.10875     1.10763     -5.51965     -11.17698
mean/mean                             0.13159      0.04529     0.20852      0.06823
mean/std                              0.83177      0.01843     0.86620      0.79951
mean/max                              2.86045      0.15832     3.24234      2.62837
mean/min                              -3.19710     0.15279     -2.83404     -3.52923
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 8, 7, 9, 0, 2, 6, 4, 5, 3]
replay_buffer._size: [14100 14100 14100 14100 14100 14100 14100 14100 14100 14100]
diff1,diff2 7.525793790817261 1.7642974853515625e-05
train_time 7.5258848667144775
2023-09-06 12:34:50,294 MainThread INFO: EPOCH:92
2023-09-06 12:34:50,295 MainThread INFO: Time Consumed:7.5388712882995605s
2023-09-06 12:34:50,295 MainThread INFO: Total Frames:139500s
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:40<13:55,  7.81s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1068.52446
Train_Epoch_Reward                    13134.62747
Running_Training_Average_Rewards      1067.18472
Explore_Time                          0.00631
Train___Time                          7.52588
Eval____Time                          0.00609
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.57229
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -16.52171
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.08676
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.97113
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.52360
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.16700
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.91470
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13431.67058
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -19.14384
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -32.59594
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.41198      1.65897     12.30504     4.77000
alpha_0                               2.61586      0.00954     2.63200      2.59981
alpha_1                               0.25820      0.00111     0.26009      0.25632
alpha_2                               0.27621      0.00104     0.27799      0.27444
alpha_3                               0.26110      0.00101     0.26282      0.25941
alpha_4                               0.26251      0.00112     0.26441      0.26062
alpha_5                               0.25960      0.00113     0.26151      0.25769
alpha_6                               0.26372      0.00100     0.26541      0.26203
alpha_7                               0.25921      0.00112     0.26112      0.25732
alpha_8                               0.25772      0.00112     0.25964      0.25582
alpha_9                               0.25866      0.00109     0.26050      0.25682
Alpha_loss                            -7.38034     0.07661     -7.23595     -7.60302
Training/policy_loss                  -303.99504   8.58322     -289.00919   -328.76239
Training/qf1_loss                     1947.11577   541.49052   3692.95630   992.78937
Training/qf2_loss                     1098.45672   370.45955   2383.45337   463.78394
Training/pf_norm                      10.40070     10.23144    54.56668     2.18385
Training/qf1_norm                     11374.88594  5657.83940  25806.36328  2933.58179
Training/qf2_norm                     10126.98459  6534.22659  25857.05664  1486.68677
log_std/mean                          -0.23209     0.01089     -0.21557     -0.25224
log_std/std                           0.24924      0.00342     0.25672      0.24412
log_std/max                           0.51501      0.14286     0.72586      0.29553
log_std/min                           -0.93769     0.04563     -0.87867     -1.03722
log_probs/mean                        -0.92510     0.06677     -0.75604     -1.06974
log_probs/std                         3.23996      0.13862     3.54367      2.97987
log_probs/max                         14.00507     0.92250     16.71425     12.19728
log_probs/min                         -7.01715     1.03130     -5.32405     -10.08583
mean/mean                             0.11725      0.02532     0.16992      0.06168
mean/std                              0.81743      0.01921     0.85792      0.78631
mean/max                              2.80701      0.12027     3.08504      2.60065
mean/min                              -3.30745     0.18849     -2.88251     -3.67998
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 1, 7, 6, 0, 9, 5, 2, 3, 4]
replay_buffer._size: [14250 14250 14250 14250 14250 14250 14250 14250 14250 14250]
diff1,diff2 6.322554349899292 7.200241088867188e-05
train_time 6.3227174282073975
2023-09-06 12:34:58,249 MainThread INFO: EPOCH:93
2023-09-06 12:34:58,249 MainThread INFO: Time Consumed:6.333519458770752s
2023-09-06 12:34:58,249 MainThread INFO: Total Frames:141000s
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [10:48<13:52,  7.86s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1284.96072
Train_Epoch_Reward                    13830.11611
Running_Training_Average_Rewards      1174.15219
Explore_Time                          0.00621
Train___Time                          6.32272
Eval____Time                          0.00392
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -50.61248
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -13.21782
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -31.31503
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -24.17237
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -36.37532
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.27546
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -12.13161
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13398.59226
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -15.72794
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.49586
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.99373      1.50945     13.21251     5.86559
alpha_0                               2.64879      0.00921     2.66427      2.63268
alpha_1                               0.25441      0.00108     0.25625      0.25260
alpha_2                               0.27262      0.00100     0.27437      0.27104
alpha_3                               0.25764      0.00100     0.25934      0.25597
alpha_4                               0.25870      0.00109     0.26054      0.25685
alpha_5                               0.25574      0.00110     0.25761      0.25388
alpha_6                               0.26031      0.00098     0.26196      0.25865
alpha_7                               0.25538      0.00110     0.25725      0.25353
alpha_8                               0.25386      0.00111     0.25575      0.25199
alpha_9                               0.25491      0.00107     0.25674      0.25311
Alpha_loss                            -7.33336     0.16497     -7.03715     -7.61471
Training/policy_loss                  -307.98165   8.32173     -294.30301   -330.40558
Training/qf1_loss                     2186.83399   521.53574   3743.85938   1002.10382
Training/qf2_loss                     1190.59782   316.05503   2235.67358   493.40167
Training/pf_norm                      11.03811     8.60539     51.00145     3.16760
Training/qf1_norm                     11645.85938  5845.83013  27185.21484  4030.19751
Training/qf2_norm                     9131.38556   5105.29203  22254.87695  2415.44971
log_std/mean                          -0.24851     0.00799     -0.23698     -0.26433
log_std/std                           0.25485      0.01174     0.27756      0.24001
log_std/max                           0.48753      0.12927     0.65214      0.28646
log_std/min                           -1.01293     0.05535     -0.94700     -1.11143
log_probs/mean                        -0.85475     0.12739     -0.56797     -1.06898
log_probs/std                         3.22547      0.11599     3.41286      2.97551
log_probs/max                         14.06450     0.96310     16.73636     12.49255
log_probs/min                         -7.10452     0.98945     -5.39092     -9.91570
mean/mean                             0.10005      0.05491     0.19063      0.02144
mean/std                              0.82782      0.02038     0.86703      0.79103
mean/max                              2.73209      0.05654     2.82513      2.58549
mean/min                              -3.22769     0.14462     -2.81314     -3.45146
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 8, 3, 7, 2, 6, 9, 1, 0, 4]
replay_buffer._size: [14400 14400 14400 14400 14400 14400 14400 14400 14400 14400]
diff1,diff2 7.840264558792114 6.866455078125e-05
train_time 7.840418338775635
2023-09-06 12:35:06,294 MainThread INFO: EPOCH:94
2023-09-06 12:35:06,294 MainThread INFO: Time Consumed:7.849788188934326s
2023-09-06 12:35:06,294 MainThread INFO: Total Frames:142500s
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [10:56<13:51,  7.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1310.61294
Train_Epoch_Reward                    12889.69886
Running_Training_Average_Rewards      1328.48141
Explore_Time                          0.00358
Train___Time                          7.84042
Eval____Time                          0.00510
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.93328
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -23.08661
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.87762
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -30.39934
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.46985
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.84685
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.16274
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13413.36129
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -20.91836
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -42.72035
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.82987      1.40657     11.78150     5.09100
alpha_0                               2.67848      0.00819     2.69299      2.66490
alpha_1                               0.25074      0.00105     0.25253      0.24895
alpha_2                               0.26948      0.00090     0.27099      0.26792
alpha_3                               0.25433      0.00092     0.25591      0.25276
alpha_4                               0.25493      0.00108     0.25677      0.25309
alpha_5                               0.25196      0.00108     0.25380      0.25012
alpha_6                               0.25698      0.00094     0.25858      0.25539
alpha_7                               0.25162      0.00107     0.25345      0.24980
alpha_8                               0.25006      0.00108     0.25191      0.24823
alpha_9                               0.25127      0.00103     0.25303      0.24952
Alpha_loss                            -7.27870     0.12569     -6.99724     -7.53950
Training/policy_loss                  -309.15857   9.18570     -291.53448   -333.08246
Training/qf1_loss                     2171.25000   622.65553   3467.38062   1054.97058
Training/qf2_loss                     1169.72771   370.06915   2064.62500   530.86536
Training/pf_norm                      13.22579     9.64635     52.36680     3.62744
Training/qf1_norm                     14321.56508  7651.09770  33077.70312  4685.65674
Training/qf2_norm                     9471.07563   4764.17736  22746.94727  3202.96143
log_std/mean                          -0.25581     0.00375     -0.24664     -0.26266
log_std/std                           0.26278      0.01028     0.28026      0.24381
log_std/max                           0.58351      0.08361     0.67683      0.33627
log_std/min                           -1.04927     0.03512     -0.98341     -1.10706
log_probs/mean                        -0.82597     0.10880     -0.62379     -1.01013
log_probs/std                         3.12823      0.16845     3.41180      2.74277
log_probs/max                         13.85235     1.12558     17.11176     11.25193
log_probs/min                         -7.16022     0.88477     -5.81494     -9.28585
mean/mean                             0.14060      0.02516     0.18401      0.08953
mean/std                              0.82711      0.02202     0.86971      0.79082
mean/max                              2.72000      0.11773     2.94018      2.56260
mean/min                              -3.26111     0.11385     -2.86438     -3.47371
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 3, 7, 8, 6, 4, 2, 1, 9, 0]
replay_buffer._size: [14550 14550 14550 14550 14550 14550 14550 14550 14550 14550]
diff1,diff2 7.928245782852173 6.771087646484375e-05
train_time 7.928387641906738
2023-09-06 12:35:14,417 MainThread INFO: EPOCH:95
2023-09-06 12:35:14,418 MainThread INFO: Time Consumed:7.937790393829346s
2023-09-06 12:35:14,418 MainThread INFO: Total Frames:144000s
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:04<13:49,  7.98s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1310.68279
Train_Epoch_Reward                    12950.44589
Running_Training_Average_Rewards      1322.34203
Explore_Time                          0.00462
Train___Time                          7.92839
Eval____Time                          0.00410
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.38144
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.53020
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.96012
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -35.73845
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -42.42653
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -65.39953
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.86805
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13484.39756
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -23.24098
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.58329
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.41226      1.27050     11.40426     5.78504
alpha_0                               2.70775      0.00820     2.72208      2.69364
alpha_1                               0.24711      0.00104     0.24888      0.24534
alpha_2                               0.26630      0.00093     0.26786      0.26474
alpha_3                               0.25117      0.00089     0.25269      0.24966
alpha_4                               0.25121      0.00106     0.25301      0.24942
alpha_5                               0.24823      0.00107     0.25005      0.24641
alpha_6                               0.25376      0.00093     0.25533      0.25217
alpha_7                               0.24793      0.00106     0.24973      0.24613
alpha_8                               0.24634      0.00107     0.24815      0.24452
alpha_9                               0.24770      0.00103     0.24945      0.24595
Alpha_loss                            -7.32513     0.09030     -7.17423     -7.48822
Training/policy_loss                  -309.95560   6.95425     -294.23727   -323.18286
Training/qf1_loss                     2150.36557   560.58578   3910.65552   1273.41638
Training/qf2_loss                     1095.72762   349.54799   2106.92261   557.59540
Training/pf_norm                      8.17796      4.46187     23.68611     1.95813
Training/qf1_norm                     11101.53452  6102.95472  27604.86523  2571.91797
Training/qf2_norm                     8991.97890   4513.46754  18032.69922  2282.46777
log_std/mean                          -0.26045     0.00714     -0.25104     -0.27631
log_std/std                           0.26652      0.00718     0.27676      0.25356
log_std/max                           0.66074      0.02870     0.73120      0.59888
log_std/min                           -1.08321     0.05798     -0.99128     -1.20014
log_probs/mean                        -0.81721     0.05269     -0.70582     -0.93225
log_probs/std                         3.11569      0.10084     3.35367      2.87733
log_probs/max                         14.01692     1.39487     18.87280     12.04598
log_probs/min                         -7.31336     1.06373     -5.19366     -10.53976
mean/mean                             0.12079      0.02601     0.16405      0.07877
mean/std                              0.82894      0.01060     0.85261      0.80827
mean/max                              2.72965      0.06225     2.83174      2.57653
mean/min                              -3.29432     0.11031     -3.07819     -3.51849
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 3, 1, 5, 0, 6, 8, 9, 2, 4]
replay_buffer._size: [14700 14700 14700 14700 14700 14700 14700 14700 14700 14700]
diff1,diff2 7.887505769729614 1.8358230590820312e-05
train_time 7.887588977813721
2023-09-06 12:35:22,534 MainThread INFO: EPOCH:96
2023-09-06 12:35:22,534 MainThread INFO: Time Consumed:7.913053750991821s
2023-09-06 12:35:22,534 MainThread INFO: Total Frames:145500s
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:12<13:46,  8.03s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1311.41054
Train_Epoch_Reward                    13029.70200
Running_Training_Average_Rewards      1295.66156
Explore_Time                          0.02125
Train___Time                          7.88759
Eval____Time                          0.00347
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -76.35949
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.45090
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.94138
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -38.23324
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -49.90341
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.58359
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.21936
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13503.42963
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -24.66341
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.97394
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.47140      1.71417     12.30279     4.75217
alpha_0                               2.73611      0.00780     2.74908      2.72268
alpha_1                               0.24359      0.00098     0.24527      0.24192
alpha_2                               0.26323      0.00085     0.26468      0.26176
alpha_3                               0.24814      0.00085     0.24960      0.24669
alpha_4                               0.24756      0.00104     0.24934      0.24580
alpha_5                               0.24455      0.00105     0.24634      0.24277
alpha_6                               0.25051      0.00093     0.25210      0.24893
alpha_7                               0.24429      0.00104     0.24606      0.24253
alpha_8                               0.24267      0.00104     0.24445      0.24092
alpha_9                               0.24418      0.00099     0.24588      0.24250
Alpha_loss                            -7.22439     0.07817     -7.07715     -7.43061
Training/policy_loss                  -310.62840   7.28286     -295.50421   -326.30453
Training/qf1_loss                     2103.86242   578.04057   3542.68726   1047.79187
Training/qf2_loss                     1052.15484   335.64474   2054.47656   511.51514
Training/pf_norm                      11.32893     5.36830     24.68240     2.60111
Training/qf1_norm                     14902.34204  8013.72583  31978.21484  2976.59302
Training/qf2_norm                     9272.50749   5747.66787  25529.75781  2339.44238
log_std/mean                          -0.28331     0.00435     -0.27380     -0.29437
log_std/std                           0.28237      0.00568     0.29628      0.26894
log_std/max                           0.76329      0.07621     0.85940      0.57893
log_std/min                           -1.16808     0.08770     -1.09998     -1.38926
log_probs/mean                        -0.74250     0.08249     -0.55619     -0.88221
log_probs/std                         3.03193      0.13738     3.37599      2.72192
log_probs/max                         13.99946     1.17575     16.76133     11.22342
log_probs/min                         -7.31871     1.04081     -5.71572     -10.75266
mean/mean                             0.11589      0.03217     0.16987      0.05202
mean/std                              0.83542      0.01909     0.87461      0.79804
mean/max                              2.72800      0.13158     3.00242      2.52554
mean/min                              -3.15539     0.15634     -2.84229     -3.36847
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 9, 3, 5, 6, 1, 7, 8, 0, 2]
replay_buffer._size: [14850 14850 14850 14850 14850 14850 14850 14850 14850 14850]
diff1,diff2 7.895066022872925 6.413459777832031e-05
train_time 7.8952085971832275
2023-09-06 12:35:30,614 MainThread INFO: EPOCH:97
2023-09-06 12:35:30,614 MainThread INFO: Time Consumed:7.904529094696045s
2023-09-06 12:35:30,614 MainThread INFO: Total Frames:147000s
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:20<13:39,  8.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1315.53600
Train_Epoch_Reward                    13694.39409
Running_Training_Average_Rewards      1322.48473
Explore_Time                          0.00370
Train___Time                          7.89521
Eval____Time                          0.00438
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.10601
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -34.89454
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.81745
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -36.98850
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.47534
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.65454
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.80391
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13569.63860
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.80846
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.37962
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.56046      1.41182     13.14281     5.21817
alpha_0                               2.76371      0.00851     2.77820      2.74961
alpha_1                               0.24016      0.00100     0.24186      0.23846
alpha_2                               0.26003      0.00099     0.26169      0.25837
alpha_3                               0.24506      0.00093     0.24663      0.24350
alpha_4                               0.24402      0.00102     0.24573      0.24227
alpha_5                               0.24093      0.00104     0.24270      0.23917
alpha_6                               0.24726      0.00096     0.24886      0.24564
alpha_7                               0.24071      0.00103     0.24246      0.23896
alpha_8                               0.23908      0.00104     0.24084      0.23732
alpha_9                               0.24071      0.00101     0.24243      0.23900
Alpha_loss                            -7.57427     0.12292     -7.27160     -7.80824
Training/policy_loss                  -311.46686   9.34883     -289.89352   -342.94772
Training/qf1_loss                     2227.55284   644.45555   4445.96045   1223.89648
Training/qf2_loss                     1046.99609   332.24811   2188.77026   534.24243
Training/pf_norm                      8.92546      4.19710     19.68113     3.47048
Training/qf1_norm                     13988.29440  8651.40022  42621.79297  2724.02271
Training/qf2_norm                     8164.82605   3962.60319  23817.29883  2715.52808
log_std/mean                          -0.27888     0.00819     -0.26457     -0.29647
log_std/std                           0.27436      0.01143     0.29424      0.25646
log_std/max                           0.54555      0.12728     0.69447      0.29750
log_std/min                           -1.22677     0.08425     -1.10426     -1.41016
log_probs/mean                        -0.89920     0.09013     -0.71283     -1.10177
log_probs/std                         3.10210      0.11216     3.35637      2.84890
log_probs/max                         13.96172     0.91660     17.66690     12.19606
log_probs/min                         -7.16562     0.94602     -5.57635     -10.21108
mean/mean                             0.09877      0.07525     0.22523      -0.00560
mean/std                              0.80491      0.01345     0.82794      0.77320
mean/max                              2.71124      0.07106     2.88623      2.58473
mean/min                              -3.04564     0.08061     -2.90966     -3.19241
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 6, 0, 1, 9, 2, 5, 8, 3, 7]
replay_buffer._size: [15000 15000 15000 15000 15000 15000 15000 15000 15000 15000]
diff1,diff2 7.654614686965942 1.7404556274414062e-05
train_time 7.6546714305877686
2023-09-06 12:35:38,446 MainThread INFO: EPOCH:98
2023-09-06 12:35:38,447 MainThread INFO: Time Consumed:7.669398546218872s
2023-09-06 12:35:38,447 MainThread INFO: Total Frames:148500s
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:28<13:25,  7.97s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1297.25243
Train_Epoch_Reward                    13406.71834
Running_Training_Average_Rewards      1337.69381
Explore_Time                          0.00518
Train___Time                          7.65467
Eval____Time                          0.00894
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.51440
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.68695
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.21201
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.23475
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.89386
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.04036
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -21.58735
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13001.79630
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -29.53869
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.32626
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           9.13487      1.33687     12.32625     6.32368
alpha_0                               2.79373      0.00895     2.80867      2.77879
alpha_1                               0.23669      0.00100     0.23839      0.23499
alpha_2                               0.25660      0.00100     0.25830      0.25493
alpha_3                               0.24183      0.00093     0.24344      0.24028
alpha_4                               0.24046      0.00103     0.24220      0.23873
alpha_5                               0.23736      0.00102     0.23910      0.23563
alpha_6                               0.24398      0.00096     0.24558      0.24234
alpha_7                               0.23716      0.00102     0.23889      0.23544
alpha_8                               0.23552      0.00102     0.23725      0.23378
alpha_9                               0.23721      0.00101     0.23893      0.23550
Alpha_loss                            -7.68441     0.11542     -7.50758     -8.03139
Training/policy_loss                  -315.73494   9.03197     -293.87823   -336.30637
Training/qf1_loss                     2327.78118   607.62456   3959.24097   984.33887
Training/qf2_loss                     1118.59708   325.88135   2310.57422   363.97137
Training/pf_norm                      10.63788     5.93820     34.27300     2.36724
Training/qf1_norm                     13273.34690  5908.15688  25214.29492  4228.47998
Training/qf2_norm                     7646.73963   3865.94200  20937.77930  2907.24414
log_std/mean                          -0.26088     0.00672     -0.25031     -0.27325
log_std/std                           0.27090      0.00325     0.27649      0.26438
log_std/max                           0.58320      0.04722     0.65130      0.50506
log_std/min                           -1.13168     0.03220     -1.07211     -1.21726
log_probs/mean                        -0.91600     0.07085     -0.72974     -1.08596
log_probs/std                         3.11377      0.13920     3.45082      2.80479
log_probs/max                         14.13721     0.95495     16.44465     12.17917
log_probs/min                         -7.11157     1.31184     -5.43114     -12.11796
mean/mean                             0.10091      0.04033     0.15766      0.02067
mean/std                              0.80869      0.01856     0.84345      0.76925
mean/max                              2.77798      0.11948     3.03792      2.54677
mean/min                              -3.02101     0.08663     -2.80876     -3.20740
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 0, 6, 7, 4, 9, 2, 8, 1, 5]
replay_buffer._size: [15150 15150 15150 15150 15150 15150 15150 15150 15150 15150]
diff1,diff2 7.734583377838135 4.9114227294921875e-05
train_time 7.734697580337524
2023-09-06 12:35:46,374 MainThread INFO: EPOCH:99
2023-09-06 12:35:46,374 MainThread INFO: Time Consumed:7.754561424255371s
2023-09-06 12:35:46,374 MainThread INFO: Total Frames:150000s
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:36<13:15,  7.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1277.34840
Train_Epoch_Reward                    12667.14763
Running_Training_Average_Rewards      1325.60867
Explore_Time                          0.01430
Train___Time                          7.73470
Eval____Time                          0.00401
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.29850
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -35.06774
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -23.79083
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -32.73750
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -47.17244
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.29892
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -13.86696
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12889.80342
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.61480
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -44.97560
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.63882      1.38591     11.80951     5.98310
alpha_0                               2.82295      0.00794     2.83661      2.80928
alpha_1                               0.23325      0.00098     0.23492      0.23158
alpha_2                               0.25326      0.00095     0.25487      0.25163
alpha_3                               0.23884      0.00080     0.24022      0.23748
alpha_4                               0.23696      0.00100     0.23866      0.23528
alpha_5                               0.23385      0.00100     0.23556      0.23216
alpha_6                               0.24070      0.00092     0.24228      0.23916
alpha_7                               0.23367      0.00100     0.23537      0.23197
alpha_8                               0.23202      0.00100     0.23371      0.23033
alpha_9                               0.23374      0.00099     0.23543      0.23206
Alpha_loss                            -7.56065     0.11158     -7.29309     -7.80961
Training/policy_loss                  -315.76143   8.33173     -298.05664   -330.18286
Training/qf1_loss                     2322.07562   619.15443   3847.31714   1247.03406
Training/qf2_loss                     1091.06062   313.84246   1849.41882   537.54706
Training/pf_norm                      14.16977     9.55679     45.78480     3.32672
Training/qf1_norm                     12999.80887  7548.07820  40118.50781  2386.68066
Training/qf2_norm                     11041.06961  6102.37019  25841.29297  2508.47363
log_std/mean                          -0.27769     0.00562     -0.26730     -0.28833
log_std/std                           0.27625      0.00514     0.28679      0.26945
log_std/max                           0.56168      0.01777     0.59483      0.50746
log_std/min                           -1.16399     0.02311     -1.12050     -1.22051
log_probs/mean                        -0.83596     0.05742     -0.64534     -0.96930
log_probs/std                         3.06070      0.13038     3.38461      2.76937
log_probs/max                         13.71884     0.85415     15.85317     12.24959
log_probs/min                         -7.16473     1.20353     -5.46513     -10.05590
mean/mean                             0.14715      0.04088     0.20810      0.07552
mean/std                              0.81012      0.01838     0.84626      0.76729
mean/max                              2.85862      0.07849     3.01257      2.68317
mean/min                              -2.92006     0.09398     -2.78976     -3.13379
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 8, 1, 5, 0, 4, 3, 9, 2, 6]
replay_buffer._size: [15300 15300 15300 15300 15300 15300 15300 15300 15300 15300]
diff1,diff2 7.7286036014556885 3.600120544433594e-05
train_time 7.728696823120117
2023-09-06 12:35:54,308 MainThread INFO: EPOCH:100
2023-09-06 12:35:54,309 MainThread INFO: Time Consumed:7.739400625228882s
2023-09-06 12:35:54,309 MainThread INFO: Total Frames:151500s
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:46<13:58,  8.47s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1274.21852
Train_Epoch_Reward                    12073.49605
Running_Training_Average_Rewards      1271.57873
Explore_Time                          0.00672
Train___Time                          7.72870
Eval____Time                          0.00329
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.59552
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.20576
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.93203
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -35.23549
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -51.21353
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.89241
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.28409
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13460.19758
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -26.26197
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.76284
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.64589      1.84459     12.71763     5.81164
alpha_0                               2.84756      0.00570     2.85717      2.83714
alpha_1                               0.22987      0.00096     0.23152      0.22824
alpha_2                               0.24996      0.00095     0.25156      0.24833
alpha_3                               0.23612      0.00076     0.23742      0.23481
alpha_4                               0.23353      0.00099     0.23521      0.23186
alpha_5                               0.23041      0.00099     0.23209      0.22874
alpha_6                               0.23757      0.00088     0.23909      0.23609
alpha_7                               0.23022      0.00099     0.23190      0.22855
alpha_8                               0.22858      0.00098     0.23026      0.22691
alpha_9                               0.23034      0.00096     0.23199      0.22871
Alpha_loss                            -7.50449     0.12077     -7.22003     -7.80309
Training/policy_loss                  -318.35879   8.47066     -300.17825   -332.86078
Training/qf1_loss                     2285.29710   668.40980   4301.26514   1071.71460
Training/qf2_loss                     1040.53980   330.63335   2216.55664   524.92023
Training/pf_norm                      10.84473     4.80382     24.39477     3.77222
Training/qf1_norm                     12553.06927  7643.99252  36655.52344  4161.97119
Training/qf2_norm                     9426.65472   5810.04842  26071.71484  2413.20459
log_std/mean                          -0.27414     0.00474     -0.26477     -0.28398
log_std/std                           0.27349      0.00408     0.28144      0.26653
log_std/max                           0.53968      0.04059     0.61524      0.45915
log_std/min                           -1.17642     0.07796     -1.07186     -1.41612
log_probs/mean                        -0.87314     0.06229     -0.75085     -1.01953
log_probs/std                         2.92194      0.12198     3.24892      2.71350
log_probs/max                         14.21082     1.11787     16.47000     11.83285
log_probs/min                         -7.22009     0.79331     -5.58020     -8.98153
mean/mean                             0.12978      0.03804     0.19024      0.04999
mean/std                              0.80227      0.01127     0.82477      0.76938
mean/max                              2.86936      0.09056     3.05749      2.73385
mean/min                              -2.90346     0.07497     -2.72086     -3.06281
------------------------------------  -----------  ----------  -----------  ----------
snapshot at 100
history save at ./log/testing_must_mtsac/mt10/17/model
sample: [3, 8, 4, 6, 7, 5, 2, 9, 0, 1]
replay_buffer._size: [15450 15450 15450 15450 15450 15450 15450 15450 15450 15450]
diff1,diff2 6.265704870223999 1.7642974853515625e-05
train_time 6.265761613845825
2023-09-06 12:36:02,427 MainThread INFO: EPOCH:101
2023-09-06 12:36:02,427 MainThread INFO: Time Consumed:6.274561166763306s
2023-09-06 12:36:02,427 MainThread INFO: Total Frames:153000s
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:52<12:48,  7.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1277.61324
Train_Epoch_Reward                    13445.18573
Running_Training_Average_Rewards      1272.86098
Explore_Time                          0.00416
Train___Time                          6.26576
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.85183
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -22.60124
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -34.95878
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -33.93971
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -37.85084
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.02556
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.63043
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13057.15667
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -25.45995
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.23526
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.79785      1.39145     12.21567     5.51109
alpha_0                               2.86836      0.00660     2.87935      2.85759
alpha_1                               0.22655      0.00095     0.22818      0.22494
alpha_2                               0.24667      0.00092     0.24826      0.24514
alpha_3                               0.23347      0.00077     0.23476      0.23212
alpha_4                               0.23016      0.00095     0.23179      0.22855
alpha_5                               0.22702      0.00097     0.22867      0.22538
alpha_6                               0.23455      0.00086     0.23603      0.23306
alpha_7                               0.22682      0.00097     0.22848      0.22518
alpha_8                               0.22519      0.00097     0.22684      0.22355
alpha_9                               0.22700      0.00096     0.22864      0.22536
Alpha_loss                            -7.56805     0.08512     -7.40220     -7.72854
Training/policy_loss                  -319.85602   8.63404     -305.40439   -340.39029
Training/qf1_loss                     2329.43167   619.87275   4145.97217   1139.62048
Training/qf2_loss                     1012.20073   297.28142   1973.17517   514.08527
Training/pf_norm                      10.08092     5.29540     27.84876     2.23989
Training/qf1_norm                     11960.38659  7298.82897  34188.68750  3708.04736
Training/qf2_norm                     7537.95776   3579.21244  15269.07715  2436.31128
log_std/mean                          -0.28382     0.01420     -0.26242     -0.31380
log_std/std                           0.27695      0.00670     0.28848      0.26471
log_std/max                           0.40792      0.08429     0.56752      0.32704
log_std/min                           -1.18633     0.03038     -1.13585     -1.24909
log_probs/mean                        -0.83262     0.09088     -0.65146     -0.99940
log_probs/std                         2.94694      0.11869     3.16793      2.71158
log_probs/max                         14.04574     0.84883     16.15387     12.15005
log_probs/min                         -7.12305     0.92878     -5.42746     -10.03067
mean/mean                             0.12103      0.05313     0.19474      0.03389
mean/std                              0.80883      0.01758     0.83876      0.77856
mean/max                              2.93279      0.14685     3.19787      2.68418
mean/min                              -2.92825     0.09891     -2.74337     -3.17188
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 3, 4, 5, 2, 6, 1, 9, 7]
replay_buffer._size: [15600 15600 15600 15600 15600 15600 15600 15600 15600 15600]
diff1,diff2 7.966556787490845 1.8358230590820312e-05
train_time 7.966636657714844
2023-09-06 12:36:10,592 MainThread INFO: EPOCH:102
2023-09-06 12:36:10,593 MainThread INFO: Time Consumed:7.975879430770874s
2023-09-06 12:36:10,593 MainThread INFO: Total Frames:154500s
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [12:00<12:50,  7.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1168.43676
Train_Epoch_Reward                    13132.85691
Running_Training_Average_Rewards      1288.38462
Explore_Time                          0.00433
Train___Time                          7.96664
Eval____Time                          0.00429
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.79322
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -14.40671
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -34.79137
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -28.61059
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -40.49994
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.92991
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.12429
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9573.86187
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -19.95553
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.06444
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.27302      1.30650     11.59172     5.83432
alpha_0                               2.89142      0.00690     2.90315      2.87979
alpha_1                               0.22327      0.00094     0.22487      0.22169
alpha_2                               0.24355      0.00091     0.24508      0.24202
alpha_3                               0.23069      0.00081     0.23207      0.22932
alpha_4                               0.22687      0.00094     0.22849      0.22530
alpha_5                               0.22368      0.00096     0.22531      0.22206
alpha_6                               0.23145      0.00091     0.23300      0.22992
alpha_7                               0.22350      0.00095     0.22511      0.22189
alpha_8                               0.22185      0.00096     0.22348      0.22023
alpha_9                               0.22368      0.00095     0.22530      0.22207
Alpha_loss                            -7.68537     0.06944     -7.52681     -7.83093
Training/policy_loss                  -319.12055   8.36433     -301.46924   -336.43735
Training/qf1_loss                     2262.35750   572.75374   3635.91187   1164.21350
Training/qf2_loss                     982.85828    302.26750   1753.32349   443.15576
Training/pf_norm                      13.25731     7.57897     36.49080     4.00560
Training/qf1_norm                     17234.76113  8283.08415  36332.98828  3200.27441
Training/qf2_norm                     9457.48036   5224.94503  25749.42188  2277.24536
log_std/mean                          -0.29592     0.00552     -0.28550     -0.30640
log_std/std                           0.26552      0.00614     0.27970      0.25670
log_std/max                           0.31964      0.02463     0.40770      0.29538
log_std/min                           -1.20247     0.04973     -1.13166     -1.29671
log_probs/mean                        -0.84620     0.06602     -0.67158     -0.98698
log_probs/std                         2.95053      0.09126     3.13130      2.71859
log_probs/max                         13.95377     0.71594     15.51035     12.23325
log_probs/min                         -7.13125     1.09445     -5.54453     -10.75137
mean/mean                             0.13106      0.02691     0.18827      0.09680
mean/std                              0.80774      0.01393     0.83650      0.78376
mean/max                              2.83374      0.06877     2.94574      2.67869
mean/min                              -3.10392     0.09395     -2.92871     -3.24434
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 2, 1, 4, 5, 9, 6, 7, 3, 0]
replay_buffer._size: [15750 15750 15750 15750 15750 15750 15750 15750 15750 15750]
diff1,diff2 8.283113241195679 5.078315734863281e-05
train_time 8.283238887786865
2023-09-06 12:36:19,055 MainThread INFO: EPOCH:103
2023-09-06 12:36:19,055 MainThread INFO: Time Consumed:8.292404413223267s
2023-09-06 12:36:19,055 MainThread INFO: Total Frames:156000s
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:09<12:57,  8.10s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1102.90144
Train_Epoch_Reward                    9763.35872
Running_Training_Average_Rewards      1211.38005
Explore_Time                          0.00436
Train___Time                          8.28324
Eval____Time                          0.00422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.19054
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -25.88354
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.14798
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.83156
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -41.17452
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.25558
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -17.81877
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11530.55669
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.08421
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.41566
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.44240      1.21751     10.50288     4.82414
alpha_0                               2.91513      0.00693     2.92722      2.90360
alpha_1                               0.22006      0.00092     0.22162      0.21851
alpha_2                               0.24044      0.00088     0.24196      0.23895
alpha_3                               0.22794      0.00077     0.22927      0.22666
alpha_4                               0.22364      0.00093     0.22523      0.22207
alpha_5                               0.22039      0.00094     0.22199      0.21880
alpha_6                               0.22837      0.00087     0.22986      0.22690
alpha_7                               0.22024      0.00093     0.22182      0.21867
alpha_8                               0.21857      0.00093     0.22016      0.21699
alpha_9                               0.22042      0.00093     0.22201      0.21886
Alpha_loss                            -7.63530     0.08881     -7.45867     -7.84288
Training/policy_loss                  -323.05492   9.22303     -300.97012   -342.47275
Training/qf1_loss                     2271.14094   550.13120   3797.83081   968.52502
Training/qf2_loss                     926.33203    243.69705   1630.03845   372.02084
Training/pf_norm                      12.93835     7.45814     43.67441     4.39360
Training/qf1_norm                     13033.61686  7670.60810  39943.78125  3925.56079
Training/qf2_norm                     8030.45154   4088.25533  22933.48438  2173.51465
log_std/mean                          -0.31300     0.00750     -0.29653     -0.32596
log_std/std                           0.27691      0.00645     0.28597      0.26052
log_std/max                           0.33015      0.01323     0.35262      0.30145
log_std/min                           -1.26295     0.03113     -1.18877     -1.31638
log_probs/mean                        -0.76152     0.09062     -0.53743     -0.96059
log_probs/std                         2.95050      0.08764     3.20617      2.80326
log_probs/max                         14.02037     0.89043     17.03722     12.42534
log_probs/min                         -7.08045     0.92245     -5.37647     -9.41864
mean/mean                             0.15998      0.02109     0.19942      0.11175
mean/std                              0.81449      0.01790     0.86371      0.78208
mean/max                              2.83260      0.05257     2.92228      2.71875
mean/min                              -3.02232     0.08713     -2.87726     -3.20188
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 6, 9, 0, 3, 1, 2, 5, 4, 8]
replay_buffer._size: [15900 15900 15900 15900 15900 15900 15900 15900 15900 15900]
diff1,diff2 8.064367771148682 4.0531158447265625e-05
train_time 8.064492464065552
2023-09-06 12:36:27,344 MainThread INFO: EPOCH:104
2023-09-06 12:36:27,344 MainThread INFO: Time Consumed:8.076022863388062s
2023-09-06 12:36:27,344 MainThread INFO: Total Frames:157500s
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:17<12:54,  8.15s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1058.15802
Train_Epoch_Reward                    11556.71486
Running_Training_Average_Rewards      1148.43102
Explore_Time                          0.00760
Train___Time                          8.06449
Eval____Time                          0.00330
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.36787
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.89233
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.54844
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.01026
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.31109
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.44080
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -16.66736
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11741.76002
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -28.97780
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.24356
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.76230      1.35828     11.28270     5.96694
alpha_0                               2.94114      0.00813     2.95548      2.92778
alpha_1                               0.21689      0.00092     0.21845      0.21532
alpha_2                               0.23735      0.00092     0.23889      0.23580
alpha_3                               0.22521      0.00084     0.22661      0.22378
alpha_4                               0.22047      0.00091     0.22201      0.21890
alpha_5                               0.21716      0.00093     0.21873      0.21557
alpha_6                               0.22537      0.00089     0.22684      0.22384
alpha_7                               0.21704      0.00092     0.21861      0.21547
alpha_8                               0.21536      0.00092     0.21693      0.21379
alpha_9                               0.21724      0.00092     0.21880      0.21567
Alpha_loss                            -7.95092     0.15184     -7.57061     -8.20053
Training/policy_loss                  -326.36819   8.30356     -308.02914   -346.88474
Training/qf1_loss                     2401.29768   427.47159   3293.00464   1698.51208
Training/qf2_loss                     978.33516    242.18367   1587.81665   528.27655
Training/pf_norm                      10.10256     4.40397     24.43996     4.06282
Training/qf1_norm                     14111.41197  7657.95957  33924.35156  3862.61597
Training/qf2_norm                     9138.97244   3989.47233  21398.82227  2744.77686
log_std/mean                          -0.30266     0.00964     -0.28903     -0.32700
log_std/std                           0.26056      0.01041     0.27707      0.24161
log_std/max                           0.29782      0.00722     0.31135      0.28719
log_std/min                           -1.22430     0.05115     -1.11837     -1.29991
log_probs/mean                        -0.87831     0.08300     -0.64093     -1.06988
log_probs/std                         3.02244      0.14179     3.37190      2.68664
log_probs/max                         14.46530     1.03272     16.97052     12.79959
log_probs/min                         -7.03726     0.93178     -5.52715     -10.23390
mean/mean                             0.12062      0.02588     0.17539      0.07903
mean/std                              0.80572      0.01660     0.85150      0.77307
mean/max                              2.76726      0.11361     2.91201      2.46511
mean/min                              -3.05359     0.10672     -2.85917     -3.25759
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 6, 8, 4, 1, 7, 5, 9, 3]
replay_buffer._size: [16050 16050 16050 16050 16050 16050 16050 16050 16050 16050]
diff1,diff2 8.162461996078491 1.7404556274414062e-05
train_time 8.162522792816162
2023-09-06 12:36:35,747 MainThread INFO: EPOCH:105
2023-09-06 12:36:35,748 MainThread INFO: Time Consumed:8.178747415542603s
2023-09-06 12:36:35,748 MainThread INFO: Total Frames:159000s
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:25<12:54,  8.24s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1114.82509
Train_Epoch_Reward                    11210.44261
Running_Training_Average_Rewards      1084.35054
Explore_Time                          0.01198
Train___Time                          8.16252
Eval____Time                          0.00371
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.25285
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -39.51613
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -26.59101
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.82311
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.23116
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -78.94356
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -18.79677
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11397.98041
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -36.20336
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -59.92475
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.52782      1.23693     11.81591     6.12001
alpha_0                               2.97121      0.00867     2.98586      2.95613
alpha_1                               0.21372      0.00090     0.21526      0.21219
alpha_2                               0.23428      0.00086     0.23574      0.23278
alpha_3                               0.22243      0.00075     0.22372      0.22114
alpha_4                               0.21726      0.00092     0.21884      0.21572
alpha_5                               0.21395      0.00092     0.21551      0.21239
alpha_6                               0.22227      0.00087     0.22377      0.22079
alpha_7                               0.21388      0.00090     0.21541      0.21235
alpha_8                               0.21218      0.00091     0.21373      0.21064
alpha_9                               0.21409      0.00089     0.21561      0.21258
Alpha_loss                            -7.86480     0.14628     -7.63248     -8.21599
Training/policy_loss                  -326.00887   9.32508     -305.48441   -347.00864
Training/qf1_loss                     2362.92933   526.42867   3850.85669   1284.51392
Training/qf2_loss                     927.16624    232.91759   1550.32764   549.39691
Training/pf_norm                      10.38692     5.21951     25.53721     3.56010
Training/qf1_norm                     12484.28258  5661.58538  24252.80859  3840.94043
Training/qf2_norm                     7686.33026   4601.68842  21951.94727  2322.92969
log_std/mean                          -0.31588     0.01066     -0.29645     -0.33344
log_std/std                           0.27364      0.00823     0.28578      0.25955
log_std/max                           0.30237      0.02151     0.33274      0.25742
log_std/min                           -1.29968     0.04953     -1.22630     -1.38331
log_probs/mean                        -0.75728     0.08546     -0.58776     -0.94541
log_probs/std                         3.04559      0.08672     3.26412      2.86711
log_probs/max                         13.89232     0.62532     15.50401     12.58990
log_probs/min                         -6.95019     1.03141     -5.44276     -9.19886
mean/mean                             0.18388      0.04844     0.27722      0.12459
mean/std                              0.81370      0.00836     0.84094      0.80040
mean/max                              2.78449      0.08429     2.90573      2.61323
mean/min                              -2.98385     0.06195     -2.84645     -3.13812
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 5, 4, 2, 3, 1, 6, 8, 7, 9]
replay_buffer._size: [16200 16200 16200 16200 16200 16200 16200 16200 16200 16200]
diff1,diff2 7.837488651275635 1.811981201171875e-05
train_time 7.837563991546631
2023-09-06 12:36:43,766 MainThread INFO: EPOCH:106
2023-09-06 12:36:43,767 MainThread INFO: Time Consumed:7.855781555175781s
2023-09-06 12:36:43,767 MainThread INFO: Total Frames:160500s
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [12:33<12:39,  8.17s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1155.42645
Train_Epoch_Reward                    11329.78826
Running_Training_Average_Rewards      1136.56486
Explore_Time                          0.01356
Train___Time                          7.83756
Eval____Time                          0.00418
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.67962
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.22294
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.97435
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.28264
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -46.24906
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.72480
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -14.65492
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12756.41193
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.23527
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.59297
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.82995      1.51277     12.20389     5.51790
alpha_0                               3.00121      0.00828     3.01504      2.98653
alpha_1                               0.21063      0.00087     0.21213      0.20915
alpha_2                               0.23114      0.00092     0.23272      0.22958
alpha_3                               0.21977      0.00076     0.22108      0.21847
alpha_4                               0.21411      0.00091     0.21566      0.21257
alpha_5                               0.21079      0.00090     0.21233      0.20926
alpha_6                               0.21923      0.00088     0.22073      0.21774
alpha_7                               0.21075      0.00090     0.21229      0.20923
alpha_8                               0.20905      0.00090     0.21058      0.20753
alpha_9                               0.21102      0.00087     0.21252      0.20955
Alpha_loss                            -7.97255     0.08805     -7.81647     -8.24127
Training/policy_loss                  -328.43014   10.84314    -307.44537   -353.20819
Training/qf1_loss                     2661.45737   676.83333   4332.66553   1436.73315
Training/qf2_loss                     1019.71700   329.49064   1852.77429   466.82706
Training/pf_norm                      16.94431     10.45277    55.19240     4.10033
Training/qf1_norm                     16770.20390  7423.88100  35161.57812  3434.15039
Training/qf2_norm                     8932.96938   5031.03632  26065.26172  1967.38086
log_std/mean                          -0.30987     0.00541     -0.29730     -0.32156
log_std/std                           0.26039      0.00451     0.26951      0.25357
log_std/max                           0.26287      0.00678     0.27890      0.24960
log_std/min                           -1.21586     0.01957     -1.17981     -1.26831
log_probs/mean                        -0.82714     0.07049     -0.68414     -1.00625
log_probs/std                         2.96549      0.10519     3.20845      2.69476
log_probs/max                         14.49857     1.13694     17.05039     12.14470
log_probs/min                         -7.15537     1.20843     -5.39992     -11.71224
mean/mean                             0.15180      0.03223     0.20451      0.09073
mean/std                              0.80610      0.01473     0.83205      0.77105
mean/max                              2.83747      0.09387     3.00054      2.63340
mean/min                              -3.10858     0.10377     -2.86318     -3.38272
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 9, 8, 5, 2, 6, 0, 1, 7, 4]
replay_buffer._size: [16350 16350 16350 16350 16350 16350 16350 16350 16350 16350]
diff1,diff2 8.29252314567566 1.8835067749023438e-05
train_time 8.292602777481079
2023-09-06 12:36:52,252 MainThread INFO: EPOCH:107
2023-09-06 12:36:52,253 MainThread INFO: Time Consumed:8.302900791168213s
2023-09-06 12:36:52,253 MainThread INFO: Total Frames:162000s
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [12:42<12:39,  8.26s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1192.39432
Train_Epoch_Reward                    12089.70962
Running_Training_Average_Rewards      1154.33135
Explore_Time                          0.00542
Train___Time                          8.29260
Eval____Time                          0.00404
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.60050
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -23.61314
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -26.15848
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -40.58991
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -43.53679
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.68568
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.80689
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12830.44499
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -32.50299
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.61407
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.70782      1.73277     13.05553     5.47075
alpha_0                               3.02746      0.00721     3.04044      3.01555
alpha_1                               0.20762      0.00086     0.20909      0.20616
alpha_2                               0.22799      0.00091     0.22952      0.22644
alpha_3                               0.21706      0.00081     0.21842      0.21568
alpha_4                               0.21098      0.00089     0.21251      0.20948
alpha_5                               0.20769      0.00089     0.20920      0.20619
alpha_6                               0.21621      0.00087     0.21768      0.21475
alpha_7                               0.20767      0.00087     0.20917      0.20620
alpha_8                               0.20596      0.00088     0.20746      0.20448
alpha_9                               0.20802      0.00086     0.20949      0.20655
Alpha_loss                            -8.01648     0.08124     -7.85878     -8.22049
Training/policy_loss                  -329.67638   10.42373    -311.02145   -354.28351
Training/qf1_loss                     2423.33648   638.90631   3967.27905   1209.08240
Training/qf2_loss                     947.30310    317.60808   1853.54517   425.70401
Training/pf_norm                      14.98388     9.06557     43.24175     3.74279
Training/qf1_norm                     17128.07861  8326.39310  37624.46875  5038.14453
Training/qf2_norm                     9980.11062   5743.43675  27471.56250  2030.37964
log_std/mean                          -0.33516     0.02059     -0.30536     -0.37714
log_std/std                           0.26951      0.00733     0.28571      0.25988
log_std/max                           0.26548      0.02321     0.31120      0.23055
log_std/min                           -1.35106     0.06813     -1.24627     -1.50035
log_probs/mean                        -0.83200     0.09580     -0.58842     -0.98521
log_probs/std                         2.93294      0.18564     3.31337      2.54486
log_probs/max                         14.35202     1.13195     17.42708     11.85787
log_probs/min                         -7.07718     1.00621     -5.24762     -9.98083
mean/mean                             0.13382      0.01838     0.16985      0.09613
mean/std                              0.80227      0.01952     0.84076      0.76609
mean/max                              2.80006      0.08686     2.92885      2.55535
mean/min                              -3.09333     0.11245     -2.90113     -3.40649
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 7, 5, 6, 8, 1, 9, 3, 2]
replay_buffer._size: [16500 16500 16500 16500 16500 16500 16500 16500 16500 16500]
diff1,diff2 8.220006227493286 1.71661376953125e-05
train_time 8.220085620880127
2023-09-06 12:37:00,721 MainThread INFO: EPOCH:108
2023-09-06 12:37:00,722 MainThread INFO: Time Consumed:8.237815141677856s
2023-09-06 12:37:00,722 MainThread INFO: Total Frames:163500s
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [12:50<12:38,  8.33s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1129.76561
Train_Epoch_Reward                    12748.14211
Running_Training_Average_Rewards      1205.58800
Explore_Time                          0.01114
Train___Time                          8.22009
Eval____Time                          0.00606
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -64.31438
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.28046
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.81237
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.86284
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -48.11072
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -77.02795
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.67530
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9458.99147
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -34.67986
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.39132
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.74262      1.56253     12.85219     5.25079
alpha_0                               3.05566      0.00826     3.06967      3.04112
alpha_1                               0.20464      0.00086     0.20610      0.20319
alpha_2                               0.22487      0.00089     0.22638      0.22335
alpha_3                               0.21426      0.00081     0.21562      0.21287
alpha_4                               0.20794      0.00087     0.20942      0.20645
alpha_5                               0.20465      0.00087     0.20613      0.20317
alpha_6                               0.21328      0.00083     0.21470      0.21187
alpha_7                               0.20471      0.00085     0.20614      0.20326
alpha_8                               0.20297      0.00085     0.20442      0.20152
alpha_9                               0.20504      0.00085     0.20649      0.20360
Alpha_loss                            -8.07582     0.11164     -7.84166     -8.30792
Training/policy_loss                  -329.26299   9.70168     -309.27969   -353.47385
Training/qf1_loss                     2571.52297   659.36137   4051.68994   1165.46667
Training/qf2_loss                     955.19216    282.78609   1679.49536   427.92920
Training/pf_norm                      13.62873     6.92150     31.29317     5.22064
Training/qf1_norm                     14666.02890  6828.92619  29975.18164  4215.31543
Training/qf2_norm                     10604.52268  5505.49129  31165.55469  3002.93994
log_std/mean                          -0.34326     0.01981     -0.31111     -0.37614
log_std/std                           0.27019      0.00634     0.28256      0.25933
log_std/max                           0.23877      0.01236     0.28296      0.22281
log_std/min                           -1.36436     0.08094     -1.24517     -1.49205
log_probs/mean                        -0.81411     0.07638     -0.65139     -1.01361
log_probs/std                         2.96353      0.11183     3.19664      2.74742
log_probs/max                         14.28880     0.80708     15.96321     12.49475
log_probs/min                         -7.18653     1.22745     -5.52205     -10.99959
mean/mean                             0.16356      0.03184     0.21698      0.10120
mean/std                              0.79566      0.01479     0.82530      0.76102
mean/max                              2.66939      0.06254     2.81226      2.51817
mean/min                              -3.03931     0.08604     -2.88062     -3.24090
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 6, 3, 5, 2, 1, 0, 8, 4, 7]
replay_buffer._size: [16650 16650 16650 16650 16650 16650 16650 16650 16650 16650]
diff1,diff2 8.152941942214966 4.76837158203125e-05
train_time 8.153072834014893
2023-09-06 12:37:09,096 MainThread INFO: EPOCH:109
2023-09-06 12:37:09,096 MainThread INFO: Time Consumed:8.168518781661987s
2023-09-06 12:37:09,096 MainThread INFO: Total Frames:165000s
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [12:59<12:30,  8.34s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1102.03372
Train_Epoch_Reward                    9665.68921
Running_Training_Average_Rewards      1150.11803
Explore_Time                          0.01128
Train___Time                          8.15307
Eval____Time                          0.00352
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.54828
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.35514
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -43.36902
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.00107
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.88713
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.84888
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -20.52300
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11956.52586
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -39.36220
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -55.79233
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.62744      1.40235      13.24844     5.96472
alpha_0                               3.08431      0.00844      3.09840      3.07020
alpha_1                               0.20167      0.00086      0.20313      0.20021
alpha_2                               0.22181      0.00090      0.22329      0.22029
alpha_3                               0.21139      0.00084      0.21282      0.20996
alpha_4                               0.20492      0.00086      0.20639      0.20346
alpha_5                               0.20163      0.00087      0.20311      0.20016
alpha_6                               0.21036      0.00085      0.21181      0.20892
alpha_7                               0.20175      0.00085      0.20320      0.20031
alpha_8                               0.20000      0.00085      0.20146      0.19856
alpha_9                               0.20212      0.00084      0.20354      0.20070
Alpha_loss                            -8.23332     0.09768      -7.97554     -8.40171
Training/policy_loss                  -329.41559   9.06358      -308.82480   -346.79095
Training/qf1_loss                     2579.45323   631.80555    4556.50879   1284.62073
Training/qf2_loss                     868.86078    290.97929    1793.81433   421.94849
Training/pf_norm                      15.95794     9.86907      44.40422     3.75503
Training/qf1_norm                     17104.21680  10071.04902  48380.81641  3503.06201
Training/qf2_norm                     8562.16093   4340.30349   21586.29688  2318.65625
log_std/mean                          -0.32824     0.00787      -0.31014     -0.34173
log_std/std                           0.27034      0.00375      0.27959      0.26382
log_std/max                           0.31226      0.04037      0.41219      0.26058
log_std/min                           -1.33912     0.04124      -1.26703     -1.42394
log_probs/mean                        -0.86278     0.06118      -0.71352     -0.99947
log_probs/std                         2.99255      0.12131      3.32098      2.73418
log_probs/max                         14.42700     0.81324      16.23879     12.38974
log_probs/min                         -7.06594     0.97389      -5.50334     -9.84454
mean/mean                             0.13115      0.02295      0.16405      0.07939
mean/std                              0.79794      0.01716      0.84678      0.76909
mean/max                              2.66407      0.11636      2.85997      2.45760
mean/min                              -3.14048     0.09880      -2.89791     -3.37847
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 4, 7, 3, 8, 2, 9, 6, 1, 0]
replay_buffer._size: [16800 16800 16800 16800 16800 16800 16800 16800 16800 16800]
diff1,diff2 8.090155839920044 4.410743713378906e-05
train_time 8.090287923812866
2023-09-06 12:37:17,444 MainThread INFO: EPOCH:110
2023-09-06 12:37:17,445 MainThread INFO: Time Consumed:8.11347246170044s
2023-09-06 12:37:17,445 MainThread INFO: Total Frames:166500s
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [13:07<12:22,  8.34s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1021.60356
Train_Epoch_Reward                    11089.56602
Running_Training_Average_Rewards      1116.77991
Explore_Time                          0.01193
Train___Time                          8.09029
Eval____Time                          0.01053
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.45896
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.50583
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -30.86263
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.81883
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.35612
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.99703
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -15.47799
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10465.07124
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -44.04162
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.12054
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.40398      1.48366     11.55655     5.54137
alpha_0                               3.11415      0.00843     3.12811      3.09900
alpha_1                               0.19871      0.00085     0.20015      0.19728
alpha_2                               0.21869      0.00094     0.22023      0.21708
alpha_3                               0.20844      0.00086     0.20990      0.20701
alpha_4                               0.20194      0.00087     0.20340      0.20045
alpha_5                               0.19864      0.00085     0.20010      0.19720
alpha_6                               0.20741      0.00086     0.20886      0.20595
alpha_7                               0.19883      0.00084     0.20025      0.19742
alpha_8                               0.19706      0.00085     0.19850      0.19562
alpha_9                               0.19922      0.00084     0.20064      0.19781
Alpha_loss                            -8.41784     0.10407     -8.10456     -8.65259
Training/policy_loss                  -328.45755   10.28636    -307.41315   -353.63525
Training/qf1_loss                     2542.29924   701.47935   4252.27979   1501.96924
Training/qf2_loss                     908.56860    301.09162   1701.38672   464.83966
Training/pf_norm                      12.09455     7.09389     35.33117     3.21938
Training/qf1_norm                     17725.07432  8643.28286  45525.71094  6101.10107
Training/qf2_norm                     9514.93519   5858.95499  27197.86328  3057.60669
log_std/mean                          -0.31244     0.01720     -0.28121     -0.34192
log_std/std                           0.27218      0.01061     0.28630      0.25469
log_std/max                           0.36890      0.03447     0.45946      0.32391
log_std/min                           -1.40072     0.09623     -1.26068     -1.58058
log_probs/mean                        -0.93874     0.10801     -0.71702     -1.15096
log_probs/std                         2.97994      0.15940     3.31147      2.69130
log_probs/max                         14.48507     1.13495     18.18024     12.45979
log_probs/min                         -7.13976     0.87954     -5.62731     -8.77924
mean/mean                             0.12637      0.05557     0.19883      0.02414
mean/std                              0.78625      0.02256     0.84177      0.75221
mean/max                              2.62851      0.09032     2.82322      2.47850
mean/min                              -3.08693     0.15809     -2.77493     -3.37411
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 2, 9, 3, 0, 5, 1, 4, 6, 8]
replay_buffer._size: [16950 16950 16950 16950 16950 16950 16950 16950 16950 16950]
diff1,diff2 8.159121036529541 2.956390380859375e-05
train_time 8.15921139717102
2023-09-06 12:37:25,792 MainThread INFO: EPOCH:111
2023-09-06 12:37:25,793 MainThread INFO: Time Consumed:8.167577505111694s
2023-09-06 12:37:25,793 MainThread INFO: Total Frames:168000s
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [13:15<12:14,  8.35s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1076.87189
Train_Epoch_Reward                    9602.27196
Running_Training_Average_Rewards      1011.91757
Explore_Time                          0.00417
Train___Time                          8.15921
Eval____Time                          0.00358
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.24625
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -32.21027
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -38.77044
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.19568
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -50.67983
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.97688
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -19.55325
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11153.73616
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -46.20977
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.00766
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.25440      1.33207     11.45654     5.66040
alpha_0                               3.14092      0.00691     3.15187      3.12864
alpha_1                               0.19584      0.00081     0.19722      0.19447
alpha_2                               0.21546      0.00091     0.21701      0.21393
alpha_3                               0.20555      0.00083     0.20696      0.20416
alpha_4                               0.19896      0.00083     0.20038      0.19754
alpha_5                               0.19572      0.00083     0.19714      0.19431
alpha_6                               0.20446      0.00084     0.20589      0.20303
alpha_7                               0.19600      0.00080     0.19737      0.19464
alpha_8                               0.19415      0.00083     0.19557      0.19274
alpha_9                               0.19638      0.00081     0.19776      0.19502
Alpha_loss                            -8.26291     0.09003     -8.04826     -8.40119
Training/policy_loss                  -330.29511   9.16645     -311.18747   -348.30356
Training/qf1_loss                     2559.74081   677.90258   4692.06543   1185.39148
Training/qf2_loss                     821.09303    205.31416   1411.95398   399.21878
Training/pf_norm                      11.08331     7.26954     49.41180     3.70575
Training/qf1_norm                     19485.48397  9964.25922  41299.65234  5224.94141
Training/qf2_norm                     11177.87386  5754.76001  26332.41016  3334.88599
log_std/mean                          -0.32629     0.01277     -0.31163     -0.36023
log_std/std                           0.28398      0.00992     0.30255      0.26766
log_std/max                           0.41956      0.04202     0.49097      0.32900
log_std/min                           -1.52848     0.05341     -1.44379     -1.64787
log_probs/mean                        -0.87629     0.09302     -0.71190     -1.08409
log_probs/std                         2.86852      0.14250     3.16569      2.58556
log_probs/max                         14.52530     1.08397     17.03014     12.50290
log_probs/min                         -7.18906     0.96488     -5.75686     -10.16366
mean/mean                             0.11036      0.05426     0.21294      0.03272
mean/std                              0.79556      0.02236     0.84559      0.75460
mean/max                              2.65448      0.07765     2.82378      2.42096
mean/min                              -3.12353     0.14775     -2.72372     -3.43493
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 5, 6, 4, 1, 7, 3, 9, 8, 2]
replay_buffer._size: [17100 17100 17100 17100 17100 17100 17100 17100 17100 17100]
diff1,diff2 8.23269009590149 1.8835067749023438e-05
train_time 8.23277235031128
2023-09-06 12:37:34,215 MainThread INFO: EPOCH:112
2023-09-06 12:37:34,215 MainThread INFO: Time Consumed:8.250420808792114s
2023-09-06 12:37:34,215 MainThread INFO: Total Frames:169500s
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [13:24<12:07,  8.36s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               994.50472
Train_Epoch_Reward                    11098.89643
Running_Training_Average_Rewards      1059.69115
Explore_Time                          0.01362
Train___Time                          8.23277
Eval____Time                          0.00349
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.58038
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -20.33899
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -37.87550
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.06573
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -54.46370
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.18494
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.09880
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9458.80374
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -42.07844
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.29360
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.54468      1.26884     10.79242     6.11556
alpha_0                               3.16269      0.00651     3.17437      3.15230
alpha_1                               0.19310      0.00077     0.19441      0.19179
alpha_2                               0.21254      0.00078     0.21387      0.21117
alpha_3                               0.20291      0.00071     0.20411      0.20169
alpha_4                               0.19606      0.00082     0.19748      0.19467
alpha_5                               0.19286      0.00082     0.19425      0.19148
alpha_6                               0.20159      0.00081     0.20297      0.20020
alpha_7                               0.19328      0.00077     0.19459      0.19198
alpha_8                               0.19135      0.00079     0.19269      0.19001
alpha_9                               0.19370      0.00074     0.19496      0.19245
Alpha_loss                            -7.95262     0.19477     -7.56224     -8.30317
Training/policy_loss                  -336.91590   10.87422    -315.36783   -357.64145
Training/qf1_loss                     2724.02921   720.99491   4682.26807   1597.39648
Training/qf2_loss                     855.04400    260.61575   1498.98816   398.59915
Training/pf_norm                      13.14089     7.45288     33.01759     4.05391
Training/qf1_norm                     16718.55666  8556.03281  34687.46094  4053.38525
Training/qf2_norm                     8489.74884   4066.73601  20269.47852  2904.52002
log_std/mean                          -0.36956     0.01168     -0.35045     -0.39227
log_std/std                           0.29585      0.01245     0.31439      0.27714
log_std/max                           0.45298      0.03945     0.56058      0.38528
log_std/min                           -1.65384     0.05644     -1.56040     -1.75907
log_probs/mean                        -0.64092     0.11180     -0.39987     -0.85139
log_probs/std                         2.87362      0.12276     3.14313      2.59340
log_probs/max                         14.20382     1.06528     17.17865     11.32603
log_probs/min                         -7.10354     1.28036     -4.95023     -11.82797
mean/mean                             0.20547      0.03118     0.27774      0.15000
mean/std                              0.81257      0.01821     0.84859      0.78041
mean/max                              2.65326      0.06972     2.77851      2.51597
mean/min                              -3.13153     0.11818     -2.91022     -3.37171
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 0, 2, 7, 6, 5, 3, 8, 1, 9]
replay_buffer._size: [17250 17250 17250 17250 17250 17250 17250 17250 17250 17250]
diff1,diff2 8.586176633834839 6.747245788574219e-05
train_time 8.586327075958252
2023-09-06 12:37:42,982 MainThread INFO: EPOCH:113
2023-09-06 12:37:42,982 MainThread INFO: Time Consumed:8.594684600830078s
2023-09-06 12:37:42,982 MainThread INFO: Total Frames:171000s
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [13:32<12:10,  8.49s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               959.39756
Train_Epoch_Reward                    9533.36155
Running_Training_Average_Rewards      1007.81766
Explore_Time                          0.00396
Train___Time                          8.58633
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.91824
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -13.14336
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.54763
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -41.54779
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -55.23992
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -75.06470
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.44902
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9388.86782
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -45.16804
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.57220
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.62250      1.47382     11.76920     5.31251
alpha_0                               3.18563      0.00631     3.19669      3.17485
alpha_1                               0.19043      0.00077     0.19173      0.18913
alpha_2                               0.20966      0.00085     0.21111      0.20825
alpha_3                               0.20036      0.00076     0.20164      0.19907
alpha_4                               0.19324      0.00081     0.19462      0.19186
alpha_5                               0.19006      0.00081     0.19142      0.18869
alpha_6                               0.19876      0.00081     0.20015      0.19738
alpha_7                               0.19062      0.00077     0.19192      0.18932
alpha_8                               0.18861      0.00078     0.18995      0.18729
alpha_9                               0.19118      0.00071     0.19240      0.18999
Alpha_loss                            -8.12134     0.11801     -7.76892     -8.36644
Training/policy_loss                  -334.97957   9.77603     -318.59512   -358.26587
Training/qf1_loss                     2681.18525   619.99867   4881.85498   1790.72327
Training/qf2_loss                     877.70781    247.25194   1609.53967   506.55362
Training/pf_norm                      12.38545     7.10763     39.08334     4.14909
Training/qf1_norm                     15291.59371  6962.70074  32418.02734  4740.44482
Training/qf2_norm                     10049.61258  6425.49492  31950.10742  2577.41602
log_std/mean                          -0.36939     0.01300     -0.34691     -0.39149
log_std/std                           0.28385      0.00699     0.29545      0.26949
log_std/max                           0.46425      0.04302     0.54386      0.32006
log_std/min                           -1.57802     0.04072     -1.46775     -1.65068
log_probs/mean                        -0.71806     0.07606     -0.54473     -0.85586
log_probs/std                         2.84799      0.12219     3.21426      2.56284
log_probs/max                         14.59230     0.97719     16.63801     12.59990
log_probs/min                         -7.23212     0.81949     -5.63689     -9.99962
mean/mean                             0.21510      0.03305     0.27839      0.15675
mean/std                              0.79612      0.01346     0.83940      0.76577
mean/max                              2.74383      0.07246     2.88173      2.60981
mean/min                              -3.07865     0.09066     -2.85105     -3.28183
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 8, 3, 0, 5, 1, 2, 4, 9, 7]
replay_buffer._size: [17400 17400 17400 17400 17400 17400 17400 17400 17400 17400]
diff1,diff2 8.304080963134766 6.4849853515625e-05
train_time 8.304235935211182
2023-09-06 12:37:51,501 MainThread INFO: EPOCH:114
2023-09-06 12:37:51,502 MainThread INFO: Time Consumed:8.315325736999512s
2023-09-06 12:37:51,502 MainThread INFO: Total Frames:172500s
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [13:41<12:02,  8.50s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               907.09120
Train_Epoch_Reward                    9181.23473
Running_Training_Average_Rewards      993.78309
Explore_Time                          0.00566
Train___Time                          8.30424
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.14722
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -15.15051
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -25.13935
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.61204
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -58.08039
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.89695
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.06271
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9569.36662
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -51.79822
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.78393
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.11025      1.45692     11.42526     5.70705
alpha_0                               3.20803      0.00578     3.21710      3.19719
alpha_1                               0.18777      0.00077     0.18908      0.18648
alpha_2                               0.20674      0.00086     0.20820      0.20530
alpha_3                               0.19766      0.00080     0.19902      0.19633
alpha_4                               0.19044      0.00080     0.19180      0.18910
alpha_5                               0.18728      0.00079     0.18863      0.18594
alpha_6                               0.19593      0.00082     0.19732      0.19455
alpha_7                               0.18797      0.00076     0.18927      0.18669
alpha_8                               0.18589      0.00079     0.18723      0.18455
alpha_9                               0.18876      0.00070     0.18994      0.18759
Alpha_loss                            -8.22296     0.14615     -7.85265     -8.49986
Training/policy_loss                  -335.05624   9.36046     -308.49747   -356.23877
Training/qf1_loss                     2552.87753   715.48750   4405.76465   1432.46777
Training/qf2_loss                     802.31292    248.82231   1435.10046   438.26242
Training/pf_norm                      12.26499     6.70536     31.37426     3.91570
Training/qf1_norm                     16699.08306  9365.84570  43083.79297  3314.34521
Training/qf2_norm                     8818.59484   4430.64794  19177.54883  2003.90002
log_std/mean                          -0.35022     0.01275     -0.31624     -0.37005
log_std/std                           0.29252      0.00894     0.30478      0.27269
log_std/max                           0.56821      0.05418     0.68146      0.46125
log_std/min                           -1.59710     0.05785     -1.46990     -1.71778
log_probs/mean                        -0.78604     0.08584     -0.56819     -0.91299
log_probs/std                         2.75755      0.13601     2.99456      2.39018
log_probs/max                         14.09625     1.01487     16.11563     12.31046
log_probs/min                         -7.00569     0.81009     -5.63250     -9.46622
mean/mean                             0.18577      0.01813     0.21859      0.14949
mean/std                              0.78821      0.01531     0.82468      0.75069
mean/max                              2.62036      0.09347     2.82372      2.48201
mean/min                              -3.02440     0.15561     -2.73196     -3.32893
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 4, 8, 5, 2, 0, 9, 7, 1, 3]
replay_buffer._size: [17550 17550 17550 17550 17550 17550 17550 17550 17550 17550]
diff1,diff2 8.090690851211548 6.914138793945312e-05
train_time 8.090860843658447
2023-09-06 12:37:59,794 MainThread INFO: EPOCH:115
2023-09-06 12:37:59,795 MainThread INFO: Time Consumed:8.110337018966675s
2023-09-06 12:37:59,795 MainThread INFO: Total Frames:174000s
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [13:49<11:49,  8.44s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               976.65161
Train_Epoch_Reward                    9896.31681
Running_Training_Average_Rewards      953.69710
Explore_Time                          0.01295
Train___Time                          8.09086
Eval____Time                          0.00508
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -63.75947
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -13.07849
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -39.78842
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -43.23599
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -52.47061
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -55.79592
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.12614
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11532.51813
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.17707
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -36.44996
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.62423      1.27277     11.75986     5.48830
alpha_0                               3.22426      0.00460     3.23332      3.21735
alpha_1                               0.18515      0.00075     0.18643      0.18387
alpha_2                               0.20380      0.00087     0.20524      0.20231
alpha_3                               0.19492      0.00083     0.19628      0.19351
alpha_4                               0.18772      0.00078     0.18904      0.18639
alpha_5                               0.18455      0.00078     0.18588      0.18323
alpha_6                               0.19314      0.00080     0.19450      0.19178
alpha_7                               0.18540      0.00074     0.18664      0.18414
alpha_8                               0.18318      0.00077     0.18449      0.18186
alpha_9                               0.18637      0.00070     0.18754      0.18518
Alpha_loss                            -8.35592     0.21766     -7.92342     -8.68011
Training/policy_loss                  -340.46682   9.99103     -318.52048   -365.49985
Training/qf1_loss                     2735.68147   690.75592   4309.25293   1768.70740
Training/qf2_loss                     846.52088    253.90402   1662.69958   437.53976
Training/pf_norm                      11.13009     5.11598     25.39135     4.44379
Training/qf1_norm                     17059.66069  9200.46455  41231.40625  4594.87256
Training/qf2_norm                     8706.41356   4264.88670  23752.01562  2430.68530
log_std/mean                          -0.34640     0.01402     -0.32162     -0.37152
log_std/std                           0.28946      0.00949     0.30861      0.27652
log_std/max                           0.55763      0.06253     0.66298      0.42209
log_std/min                           -1.56135     0.07514     -1.44683     -1.70859
log_probs/mean                        -0.82824     0.10708     -0.61531     -1.06987
log_probs/std                         2.76200      0.14366     3.09866      2.45259
log_probs/max                         14.40931     1.09855     16.79415     11.09777
log_probs/min                         -7.54968     1.17803     -5.94525     -10.75869
mean/mean                             0.16679      0.03818     0.22749      0.09167
mean/std                              0.78530      0.01983     0.82993      0.75061
mean/max                              2.63243      0.06070     2.74781      2.51756
mean/min                              -3.09322     0.14931     -2.74682     -3.29991
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 5, 7, 1, 9, 6, 2, 8, 4, 3]
replay_buffer._size: [17700 17700 17700 17700 17700 17700 17700 17700 17700 17700]
diff1,diff2 8.436357498168945 6.008148193359375e-05
train_time 8.436497926712036
2023-09-06 12:38:08,455 MainThread INFO: EPOCH:116
2023-09-06 12:38:08,455 MainThread INFO: Time Consumed:8.445624828338623s
2023-09-06 12:38:08,455 MainThread INFO: Total Frames:175500s
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [13:58<11:45,  8.49s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1100.64004
Train_Epoch_Reward                    11484.69991
Running_Training_Average_Rewards      1018.74172
Explore_Time                          0.00446
Train___Time                          8.43650
Eval____Time                          0.00388
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.95010
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -16.27235
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -49.46420
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.86416
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -67.89439
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.74460
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.96497
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13172.79469
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.71768
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.05229
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.37460      1.47781      13.64040     5.24067
alpha_0                               3.24305      0.00535      3.25308      3.23387
alpha_1                               0.18256      0.00073      0.18382      0.18133
alpha_2                               0.20083      0.00082      0.20225      0.19947
alpha_3                               0.19209      0.00078      0.19345      0.19082
alpha_4                               0.18501      0.00078      0.18633      0.18368
alpha_5                               0.18187      0.00077      0.18317      0.18058
alpha_6                               0.19039      0.00079      0.19172      0.18905
alpha_7                               0.18287      0.00071      0.18409      0.18167
alpha_8                               0.18051      0.00076      0.18181      0.17923
alpha_9                               0.18394      0.00068      0.18513      0.18282
Alpha_loss                            -8.20920     0.14868      -7.90524     -8.51384
Training/policy_loss                  -337.83495   8.53556      -322.77646   -357.41162
Training/qf1_loss                     2592.62771   665.93689    4495.15234   1435.03870
Training/qf2_loss                     783.12142    247.27876    1426.00745   344.52863
Training/pf_norm                      11.71612     6.11554      31.21582     4.06479
Training/qf1_norm                     19322.55721  10754.73253  45568.12500  4956.60840
Training/qf2_norm                     8538.36847   5370.10068   23549.64453  2077.85498
log_std/mean                          -0.38065     0.02763      -0.32527     -0.41765
log_std/std                           0.28996      0.00780      0.30186      0.27416
log_std/max                           0.50836      0.05960      0.63101      0.37739
log_std/min                           -1.60051     0.07133      -1.46020     -1.72379
log_probs/mean                        -0.69553     0.13720      -0.44715     -0.97873
log_probs/std                         2.74607      0.13475      2.99533      2.38101
log_probs/max                         13.80996     1.02669      16.92454     11.83228
log_probs/min                         -7.41531     0.94376      -5.27840     -9.43353
mean/mean                             0.21454      0.07572      0.32518      0.09338
mean/std                              0.78934      0.01462      0.82949      0.76275
mean/max                              2.57235      0.08542      2.72102      2.40299
mean/min                              -3.04370     0.11927      -2.84418     -3.33094
------------------------------------  -----------  -----------  -----------  ----------
sample: [6, 9, 8, 0, 3, 4, 7, 1, 5, 2]
replay_buffer._size: [17850 17850 17850 17850 17850 17850 17850 17850 17850 17850]
diff1,diff2 8.142228364944458 2.9325485229492188e-05
train_time 8.142322301864624
2023-09-06 12:38:16,790 MainThread INFO: EPOCH:117
2023-09-06 12:38:16,790 MainThread INFO: Time Consumed:8.154207468032837s
2023-09-06 12:38:16,791 MainThread INFO: Total Frames:177000s
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [14:06<11:32,  8.45s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1156.19915
Train_Epoch_Reward                    12377.01854
Running_Training_Average_Rewards      1125.26784
Explore_Time                          0.00490
Train___Time                          8.14232
Eval____Time                          0.00598
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.57566
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -15.84176
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.66014
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.55816
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.45742
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.09316
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.57940
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11246.48032
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -55.29641
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.94971
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.69835      1.55236      11.61007     5.82196
alpha_0                               3.26300      0.00541      3.27240      3.25357
alpha_1                               0.18005      0.00073      0.18128      0.17882
alpha_2                               0.19803      0.00079      0.19941      0.19673
alpha_3                               0.18945      0.00075      0.19077      0.18825
alpha_4                               0.18234      0.00076      0.18363      0.18105
alpha_5                               0.17923      0.00076      0.18052      0.17796
alpha_6                               0.18768      0.00078      0.18900      0.18636
alpha_7                               0.18038      0.00074      0.18162      0.17913
alpha_8                               0.17791      0.00075      0.17918      0.17663
alpha_9                               0.18163      0.00067      0.18278      0.18052
Alpha_loss                            -8.27527     0.24100      -7.83177     -8.79268
Training/policy_loss                  -340.65493   12.34450     -308.33771   -365.31903
Training/qf1_loss                     2655.09221   836.09630    5422.87158   1314.35486
Training/qf2_loss                     768.19056    222.75376    1369.65125   404.48657
Training/pf_norm                      11.41463     4.87499      24.70396     4.53957
Training/qf1_norm                     19354.14956  10555.40208  44192.86328  3972.48022
Training/qf2_norm                     9564.98776   4932.77709   26672.89258  2308.00439
log_std/mean                          -0.35534     0.02884      -0.31420     -0.40188
log_std/std                           0.27136      0.01034      0.28942      0.25261
log_std/max                           0.42227      0.05794      0.50418      0.29936
log_std/min                           -1.43092     0.08296      -1.28736     -1.59485
log_probs/mean                        -0.70611     0.16152      -0.42694     -0.98770
log_probs/std                         2.73363      0.11299      2.99334      2.52238
log_probs/max                         14.15511     0.83719      15.95874     12.23985
log_probs/min                         -7.17620     0.99750      -5.71524     -11.04875
mean/mean                             0.16738      0.05557      0.27157      0.08078
mean/std                              0.81124      0.01986      0.84976      0.77580
mean/max                              2.63165      0.08145      2.76390      2.39564
mean/min                              -3.12862     0.09137      -2.92731     -3.30655
------------------------------------  -----------  -----------  -----------  ----------
sample: [2, 6, 9, 4, 5, 0, 7, 3, 1, 8]
replay_buffer._size: [18000 18000 18000 18000 18000 18000 18000 18000 18000 18000]
diff1,diff2 8.190158605575562 4.649162292480469e-05
train_time 8.190273761749268
2023-09-06 12:38:25,208 MainThread INFO: EPOCH:118
2023-09-06 12:38:25,209 MainThread INFO: Time Consumed:8.212518692016602s
2023-09-06 12:38:25,209 MainThread INFO: Total Frames:178500s
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [14:15<11:24,  8.45s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1172.00340
Train_Epoch_Reward                    11839.04427
Running_Training_Average_Rewards      1190.02542
Explore_Time                          0.01605
Train___Time                          8.19027
Eval____Time                          0.00553
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.99930
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -14.75038
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.83811
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.73810
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -63.86012
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.99578
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.75116
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12045.12367
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.63916
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.78800
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.31028      1.81168     11.68768     4.84720
alpha_0                               3.27962      0.00406     3.28663      3.27277
alpha_1                               0.17753      0.00072     0.17876      0.17632
alpha_2                               0.19531      0.00080     0.19668      0.19398
alpha_3                               0.18698      0.00072     0.18820      0.18576
alpha_4                               0.17972      0.00075     0.18099      0.17844
alpha_5                               0.17667      0.00073     0.17791      0.17543
alpha_6                               0.18503      0.00076     0.18631      0.18374
alpha_7                               0.17787      0.00071     0.17908      0.17667
alpha_8                               0.17531      0.00074     0.17658      0.17405
alpha_9                               0.17938      0.00064     0.18048      0.17830
Alpha_loss                            -8.26388     0.10793     -8.07060     -8.49083
Training/policy_loss                  -343.04683   11.55773    -322.76535   -368.86179
Training/qf1_loss                     2681.91335   780.32373   4568.89941   1306.55359
Training/qf2_loss                     801.38568    285.34709   1582.65784   356.26010
Training/pf_norm                      10.87779     5.62994     32.45910     3.36282
Training/qf1_norm                     16896.30676  9526.96432  40618.51562  3833.31860
Training/qf2_norm                     12212.97525  5090.59052  21486.29688  3948.49146
log_std/mean                          -0.39555     0.01875     -0.36050     -0.42901
log_std/std                           0.29391      0.01072     0.31320      0.27492
log_std/max                           0.43539      0.05932     0.51292      0.33137
log_std/min                           -1.61159     0.09011     -1.46254     -1.80051
log_probs/mean                        -0.71787     0.10110     -0.48174     -0.91457
log_probs/std                         2.63790      0.12200     2.94682      2.37089
log_probs/max                         14.15173     1.08334     16.52807     12.27052
log_probs/min                         -7.45972     1.14310     -5.92191     -11.90621
mean/mean                             0.19308      0.03522     0.25486      0.13504
mean/std                              0.78524      0.01811     0.82496      0.74651
mean/max                              2.72776      0.11224     2.90198      2.42694
mean/min                              -3.10302     0.13921     -2.81849     -3.42015
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 4, 5, 6, 7, 3, 2, 1, 9, 0]
replay_buffer._size: [18150 18150 18150 18150 18150 18150 18150 18150 18150 18150]
diff1,diff2 8.493348360061646 3.814697265625e-05
train_time 8.493463277816772
2023-09-06 12:38:33,900 MainThread INFO: EPOCH:119
2023-09-06 12:38:33,900 MainThread INFO: Time Consumed:8.503873825073242s
2023-09-06 12:38:33,900 MainThread INFO: Total Frames:180000s
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [14:23<11:21,  8.52s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1120.17458
Train_Epoch_Reward                    10556.11441
Running_Training_Average_Rewards      1159.07257
Explore_Time                          0.00642
Train___Time                          8.49346
Eval____Time                          0.00336
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -59.02458
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -15.46728
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -21.95869
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.87055
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.04401
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.41827
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.45075
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11570.18395
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.82702
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.11734
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.34042      1.25462     12.32464     5.60586
alpha_0                               3.29396      0.00431     3.30176      3.28684
alpha_1                               0.17505      0.00071     0.17627      0.17385
alpha_2                               0.19254      0.00079     0.19392      0.19121
alpha_3                               0.18444      0.00074     0.18570      0.18318
alpha_4                               0.17712      0.00075     0.17839      0.17585
alpha_5                               0.17418      0.00071     0.17538      0.17299
alpha_6                               0.18239      0.00076     0.18368      0.18110
alpha_7                               0.17546      0.00068     0.17662      0.17432
alpha_8                               0.17277      0.00072     0.17400      0.17155
alpha_9                               0.17717      0.00064     0.17826      0.17609
Alpha_loss                            -8.31689     0.15422     -7.89274     -8.68658
Training/policy_loss                  -343.21535   10.47893    -319.14777   -375.78116
Training/qf1_loss                     2453.26868   620.11112   4177.58740   1549.86877
Training/qf2_loss                     755.27713    217.61505   1466.38562   458.22443
Training/pf_norm                      13.12947     7.70474     44.87400     4.57466
Training/qf1_norm                     13512.27556  8644.38412  45130.94922  4133.23633
Training/qf2_norm                     8871.63368   5262.05053  22359.53711  2958.04956
log_std/mean                          -0.40282     0.00889     -0.38012     -0.42211
log_std/std                           0.31553      0.00847     0.32893      0.29631
log_std/max                           0.49374      0.08672     0.67215      0.28017
log_std/min                           -1.74013     0.04817     -1.65200     -1.87437
log_probs/mean                        -0.67848     0.07957     -0.50269     -0.89688
log_probs/std                         2.68256      0.12538     2.94923      2.37461
log_probs/max                         13.94322     0.78144     16.09375     12.48848
log_probs/min                         -7.57238     1.34236     -5.50656     -12.45562
mean/mean                             0.20396      0.02944     0.25993      0.14399
mean/std                              0.78871      0.01832     0.84070      0.74725
mean/max                              2.74215      0.10300     2.91443      2.56509
mean/min                              -3.08005     0.11511     -2.88102     -3.31735
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 6, 0, 9, 7, 2, 8, 1, 4, 5]
replay_buffer._size: [18300 18300 18300 18300 18300 18300 18300 18300 18300 18300]
diff1,diff2 8.429018020629883 1.7881393432617188e-05
train_time 8.429080486297607
2023-09-06 12:38:42,494 MainThread INFO: EPOCH:120
2023-09-06 12:38:42,494 MainThread INFO: Time Consumed:8.43841552734375s
2023-09-06 12:38:42,494 MainThread INFO: Total Frames:181500s
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [14:32<11:15,  8.55s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1161.57235
Train_Epoch_Reward                    10769.16946
Running_Training_Average_Rewards      1105.47760
Explore_Time                          0.00529
Train___Time                          8.42908
Eval____Time                          0.00351
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.70545
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -14.02563
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -23.74421
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -38.23146
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -59.57296
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -71.69830
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.30764
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12454.27953
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -53.39919
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -35.19332
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.53831      1.34150     12.26844     5.49640
alpha_0                               3.31063      0.00476     3.31814      3.30218
alpha_1                               0.17261      0.00070     0.17380      0.17143
alpha_2                               0.18977      0.00081     0.19115      0.18840
alpha_3                               0.18184      0.00076     0.18313      0.18056
alpha_4                               0.17456      0.00073     0.17580      0.17334
alpha_5                               0.17178      0.00069     0.17294      0.17061
alpha_6                               0.17977      0.00075     0.18105      0.17849
alpha_7                               0.17314      0.00067     0.17427      0.17200
alpha_8                               0.17030      0.00070     0.17150      0.16910
alpha_9                               0.17500      0.00061     0.17605      0.17396
Alpha_loss                            -8.34400     0.11283     -8.07635     -8.58389
Training/policy_loss                  -348.05832   11.80724    -325.66623   -376.05014
Training/qf1_loss                     2718.62411   613.08469   4083.81177   1570.29395
Training/qf2_loss                     771.56239    210.72277   1274.61475   353.41223
Training/pf_norm                      14.13877     7.65695     36.76664     4.62573
Training/qf1_norm                     15423.33697  8368.89395  45081.27344  4347.54443
Training/qf2_norm                     10227.52887  5242.27437  21486.64844  2935.69336
log_std/mean                          -0.39700     0.01746     -0.36984     -0.43084
log_std/std                           0.33621      0.00646     0.34937      0.31828
log_std/max                           0.66144      0.08234     0.78205      0.46763
log_std/min                           -1.65837     0.08889     -1.51344     -1.82021
log_probs/mean                        -0.67492     0.07677     -0.47982     -0.84238
log_probs/std                         2.69765      0.10948     2.92445      2.41732
log_probs/max                         13.98730     0.67715     15.79340     11.60579
log_probs/min                         -7.35247     1.18465     -5.57381     -10.63150
mean/mean                             0.22108      0.04452     0.31177      0.14466
mean/std                              0.77881      0.01943     0.81342      0.74223
mean/max                              2.65636      0.05577     2.77092      2.50868
mean/min                              -3.21045     0.15652     -2.94411     -3.69450
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 7, 3, 9, 5, 6, 2, 8, 4, 1]
replay_buffer._size: [18450 18450 18450 18450 18450 18450 18450 18450 18450 18450]
diff1,diff2 8.50398325920105 1.7881393432617188e-05
train_time 8.504071474075317
2023-09-06 12:38:51,191 MainThread INFO: EPOCH:121
2023-09-06 12:38:51,192 MainThread INFO: Time Consumed:8.513392448425293s
2023-09-06 12:38:51,192 MainThread INFO: Total Frames:183000s
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [14:41<11:09,  8.59s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1227.04416
Train_Epoch_Reward                    11608.38979
Running_Training_Average_Rewards      1097.78912
Explore_Time                          0.00439
Train___Time                          8.50407
Eval____Time                          0.00440
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.01103
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -15.10146
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -35.57260
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.37700
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -66.95574
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -72.24928
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.30814
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14004.27775
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.74174
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.04288
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.40066      1.48101     11.85715     5.65563
alpha_0                               3.32478      0.00392     3.33208      3.31843
alpha_1                               0.17023      0.00067     0.17138      0.16908
alpha_2                               0.18715      0.00070     0.18835      0.18592
alpha_3                               0.17941      0.00065     0.18051      0.17826
alpha_4                               0.17206      0.00071     0.17329      0.17085
alpha_5                               0.16939      0.00069     0.17056      0.16822
alpha_6                               0.17718      0.00074     0.17844      0.17593
alpha_7                               0.17081      0.00067     0.17195      0.16968
alpha_8                               0.16787      0.00069     0.16905      0.16669
alpha_9                               0.17295      0.00058     0.17392      0.17192
Alpha_loss                            -8.21796     0.35673     -7.61475     -8.76340
Training/policy_loss                  -348.65783   11.43570    -326.11069   -374.31088
Training/qf1_loss                     2708.67473   786.65280   4989.77441   1257.13074
Training/qf2_loss                     718.13916    242.01744   1663.10938   401.80429
Training/pf_norm                      14.30695     8.52180     41.42280     2.97909
Training/qf1_norm                     15852.04983  9497.26133  39741.94922  6766.73584
Training/qf2_norm                     10137.22748  5529.12580  21848.49414  2285.35205
log_std/mean                          -0.41313     0.04095     -0.34352     -0.46932
log_std/std                           0.32230      0.01492     0.35015      0.29644
log_std/max                           0.67097      0.06273     0.79398      0.55462
log_std/min                           -1.53007     0.09858     -1.34952     -1.68614
log_probs/mean                        -0.56990     0.17269     -0.26447     -0.86874
log_probs/std                         2.69855      0.11449     2.91351      2.40925
log_probs/max                         13.50291     0.73291     14.69806     11.44349
log_probs/min                         -7.63336     1.26576     -5.65723     -11.10359
mean/mean                             0.23409      0.08980     0.34938      0.10268
mean/std                              0.79164      0.01555     0.81988      0.74271
mean/max                              2.63406      0.07384     2.78050      2.48282
mean/min                              -3.25706     0.23477     -2.77401     -3.73339
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 8, 3, 1, 5, 2, 7, 9, 6, 0]
replay_buffer._size: [18600 18600 18600 18600 18600 18600 18600 18600 18600 18600]
diff1,diff2 8.849438667297363 6.604194641113281e-05
train_time 8.84957766532898
2023-09-06 12:39:00,253 MainThread INFO: EPOCH:122
2023-09-06 12:39:00,253 MainThread INFO: Time Consumed:8.859023809432983s
2023-09-06 12:39:00,253 MainThread INFO: Total Frames:184500s
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [14:50<11:11,  8.72s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1411.57721
Train_Epoch_Reward                    14033.81150
Running_Training_Average_Rewards      1213.71236
Explore_Time                          0.00542
Train___Time                          8.84958
Eval____Time                          0.00355
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.04661
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -42.55116
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -62.91499
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -42.58431
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -56.04154
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.10069
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.05260
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17163.42348
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.35493
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.77948
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.34704      1.58996      11.63724     5.00221
alpha_0                               3.33595      0.00182      3.33883      3.33237
alpha_1                               0.16786      0.00068      0.16903      0.16671
alpha_2                               0.18464      0.00071      0.18586      0.18344
alpha_3                               0.17701      0.00069      0.17820      0.17584
alpha_4                               0.16961      0.00070      0.17080      0.16843
alpha_5                               0.16703      0.00067      0.16818      0.16590
alpha_6                               0.17460      0.00075      0.17588      0.17334
alpha_7                               0.16849      0.00067      0.16963      0.16736
alpha_8                               0.16543      0.00071      0.16664      0.16424
alpha_9                               0.17081      0.00061      0.17187      0.16979
Alpha_loss                            -8.24196     0.15690      -7.78887     -8.69763
Training/policy_loss                  -348.42539   12.75277     -321.31363   -369.95993
Training/qf1_loss                     2412.27768   644.97523    4021.13916   1194.28027
Training/qf2_loss                     714.68265    232.70310    1542.12537   362.45795
Training/pf_norm                      14.66606     7.89454      38.71742     4.23135
Training/qf1_norm                     17239.04929  11177.02426  52385.47656  3160.35620
Training/qf2_norm                     12622.64402  7920.37433   32956.21484  2920.89819
log_std/mean                          -0.41011     0.02362      -0.34979     -0.44513
log_std/std                           0.30913      0.00866      0.33144      0.29344
log_std/max                           0.65073      0.05780      0.76805      0.50132
log_std/min                           -1.47089     0.06131      -1.34975     -1.57877
log_probs/mean                        -0.63644     0.08248      -0.52192     -0.85877
log_probs/std                         2.57692      0.11633      2.78134      2.33501
log_probs/max                         13.57577     1.01620      15.42749     11.25236
log_probs/min                         -7.54538     1.33679      -5.85611     -13.65358
mean/mean                             0.17458      0.04241      0.29567      0.11969
mean/std                              0.79797      0.02034      0.83338      0.75787
mean/max                              2.64100      0.07899      2.75902      2.36304
mean/min                              -3.27585     0.22012      -2.89314     -3.82829
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 8, 2, 3, 4, 7, 0, 6, 1, 9]
replay_buffer._size: [18750 18750 18750 18750 18750 18750 18750 18750 18750 18750]
diff1,diff2 8.451534986495972 6.890296936035156e-05
train_time 8.452850103378296
2023-09-06 12:39:08,890 MainThread INFO: EPOCH:123
2023-09-06 12:39:08,891 MainThread INFO: Time Consumed:8.473816633224487s
2023-09-06 12:39:08,891 MainThread INFO: Total Frames:186000s
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [14:58<11:01,  8.70s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1426.80827
Train_Epoch_Reward                    16761.86524
Running_Training_Average_Rewards      1413.46888
Explore_Time                          0.01589
Train___Time                          8.45285
Eval____Time                          0.00399
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -51.69033
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -15.91272
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -20.43282
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.09245
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -61.89156
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -80.62976
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.93470
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12932.54826
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.34516
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.28579
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.23175      1.37282     11.76368     5.18806
alpha_0                               3.33992      0.00122     3.34306      3.33866
alpha_1                               0.16557      0.00065     0.16667      0.16447
alpha_2                               0.18227      0.00066     0.18339      0.18119
alpha_3                               0.17475      0.00061     0.17579      0.17372
alpha_4                               0.16722      0.00068     0.16839      0.16606
alpha_5                               0.16479      0.00062     0.16585      0.16377
alpha_6                               0.17206      0.00072     0.17329      0.17083
alpha_7                               0.16622      0.00064     0.16731      0.16514
alpha_8                               0.16305      0.00067     0.16419      0.16191
alpha_9                               0.16887      0.00050     0.16976      0.16804
Alpha_loss                            -7.80122     0.11067     -7.47822     -8.01681
Training/policy_loss                  -349.04095   10.53056    -326.72745   -370.56317
Training/qf1_loss                     2673.36068   697.32544   4542.62549   1495.68030
Training/qf2_loss                     730.45895    210.75755   1378.66138   378.84763
Training/pf_norm                      14.39782     8.91306     42.91835     3.54304
Training/qf1_norm                     18990.12411  8967.23526  48310.80078  4414.28711
Training/qf2_norm                     11131.54037  5331.12483  27030.03906  3207.30322
log_std/mean                          -0.45643     0.01255     -0.43019     -0.47513
log_std/std                           0.34880      0.00744     0.36253      0.33138
log_std/max                           0.70057      0.05978     0.78904      0.56263
log_std/min                           -1.61924     0.03544     -1.53464     -1.69924
log_probs/mean                        -0.33570     0.10170     -0.09495     -0.52540
log_probs/std                         2.66053      0.11431     2.91152      2.40929
log_probs/max                         13.98461     0.75016     15.91887     12.03738
log_probs/min                         -7.36900     0.91366     -6.07280     -11.79144
mean/mean                             0.30697      0.03085     0.36098      0.25251
mean/std                              0.80432      0.02033     0.85565      0.75825
mean/max                              2.74221      0.10694     3.06599      2.55041
mean/min                              -3.45504     0.33721     -2.92892     -4.05549
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 3, 6, 0, 5, 2, 7, 4, 9, 8]
replay_buffer._size: [18900 18900 18900 18900 18900 18900 18900 18900 18900 18900]
diff1,diff2 8.394002437591553 7.152557373046875e-05
train_time 8.394131660461426
2023-09-06 12:39:17,436 MainThread INFO: EPOCH:124
2023-09-06 12:39:17,436 MainThread INFO: Time Consumed:8.405786991119385s
2023-09-06 12:39:17,437 MainThread INFO: Total Frames:187500s
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [15:07<10:49,  8.66s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1342.78468
Train_Epoch_Reward                    12974.44322
Running_Training_Average_Rewards      1459.00400
Explore_Time                          0.00659
Train___Time                          8.39413
Eval____Time                          0.00432
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.48288
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -11.03214
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -37.57164
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -44.66344
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -64.37446
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.15082
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.37931
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11479.75214
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.03037
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -37.85673
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.47905      1.44514     11.52605     5.21633
alpha_0                               3.35026      0.00431     3.35723      3.34325
alpha_1                               0.16332      0.00066     0.16443      0.16220
alpha_2                               0.17996      0.00071     0.18114      0.17876
alpha_3                               0.17265      0.00061     0.17368      0.17161
alpha_4                               0.16488      0.00067     0.16601      0.16375
alpha_5                               0.16275      0.00058     0.16373      0.16177
alpha_6                               0.16957      0.00072     0.17078      0.16834
alpha_7                               0.16400      0.00065     0.16510      0.16288
alpha_8                               0.16072      0.00067     0.16186      0.15958
alpha_9                               0.16709      0.00056     0.16800      0.16611
Alpha_loss                            -8.17239     0.18397     -7.80416     -8.49893
Training/policy_loss                  -351.06274   11.73921    -329.48282   -371.54901
Training/qf1_loss                     2562.00449   818.84508   5431.88086   1103.23132
Training/qf2_loss                     760.56065    252.00310   1453.75940   222.79832
Training/pf_norm                      17.04576     7.65242     37.81089     4.52458
Training/qf1_norm                     17280.53735  8794.35366  38251.87109  4940.19385
Training/qf2_norm                     11130.16357  5290.54594  24111.08203  2095.34570
log_std/mean                          -0.41743     0.02971     -0.36659     -0.46272
log_std/std                           0.33184      0.01411     0.35715      0.31190
log_std/max                           0.73606      0.06576     0.83366      0.60526
log_std/min                           -1.49870     0.07860     -1.36797     -1.66174
log_probs/mean                        -0.44747     0.10787     -0.26337     -0.65643
log_probs/std                         2.68954      0.11665     2.94371      2.48861
log_probs/max                         14.36039     0.73582     16.33598     12.71278
log_probs/min                         -7.41583     1.32077     -5.30100     -11.15263
mean/mean                             0.24664      0.03732     0.30902      0.16631
mean/std                              0.81683      0.01508     0.85624      0.77715
mean/max                              2.79852      0.12336     3.11926      2.63497
mean/min                              -3.39376     0.32156     -2.95346     -4.04427
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 2, 1, 4, 9, 5, 0, 6, 7]
replay_buffer._size: [19050 19050 19050 19050 19050 19050 19050 19050 19050 19050]
diff1,diff2 7.951974153518677 6.365776062011719e-05
train_time 7.952123641967773
2023-09-06 12:39:25,609 MainThread INFO: EPOCH:125
2023-09-06 12:39:25,610 MainThread INFO: Time Consumed:7.979309558868408s
2023-09-06 12:39:25,610 MainThread INFO: Total Frames:189000s
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [15:15<10:29,  8.51s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1216.67890
Train_Epoch_Reward                    11009.74548
Running_Training_Average_Rewards      1358.20180
Explore_Time                          0.01653
Train___Time                          7.95212
Eval____Time                          0.00999
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.42848
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -50.72316
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.85277
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.10178
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.01209
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.22036
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -49.45468
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 13407.35210
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.60913
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.12610
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.24689      1.54239     11.64415     4.91939
alpha_0                               3.36231      0.00297     3.36754      3.35748
alpha_1                               0.16103      0.00065     0.16215      0.15993
alpha_2                               0.17760      0.00067     0.17871      0.17647
alpha_3                               0.17054      0.00060     0.17156      0.16955
alpha_4                               0.16257      0.00066     0.16370      0.16145
alpha_5                               0.16078      0.00056     0.16173      0.15980
alpha_6                               0.16707      0.00072     0.16829      0.16585
alpha_7                               0.16173      0.00065     0.16284      0.16064
alpha_8                               0.15839      0.00067     0.15953      0.15727
alpha_9                               0.16515      0.00055     0.16607      0.16422
Alpha_loss                            -8.03775     0.21373     -7.60318     -8.47870
Training/policy_loss                  -354.45015   13.58078    -335.88248   -396.01953
Training/qf1_loss                     2500.15916   645.27838   3925.79077   1552.70569
Training/qf2_loss                     728.73767    225.05450   1438.60754   377.48712
Training/pf_norm                      17.78245     8.11236     40.75798     3.68448
Training/qf1_norm                     16964.12240  9294.18945  44932.77344  5554.12158
Training/qf2_norm                     15130.96954  8745.08779  33747.24219  1968.95508
log_std/mean                          -0.42091     0.02189     -0.38992     -0.47573
log_std/std                           0.33040      0.00468     0.33805      0.31925
log_std/max                           0.72128      0.09024     0.86309      0.57277
log_std/min                           -1.51939     0.05682     -1.41531     -1.64941
log_probs/mean                        -0.37411     0.10729     -0.08038     -0.53649
log_probs/std                         2.64556      0.10062     2.92956      2.35138
log_probs/max                         13.87540     0.94717     16.22538     11.86334
log_probs/min                         -7.42216     1.04083     -5.76527     -10.26007
mean/mean                             0.24774      0.05393     0.34160      0.17252
mean/std                              0.83129      0.01568     0.86166      0.79361
mean/max                              2.82050      0.09563     3.08881      2.62680
mean/min                              -3.43247     0.33871     -2.90035     -4.08137
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 4, 9, 2, 7, 3, 5, 0, 6, 8]
replay_buffer._size: [19200 19200 19200 19200 19200 19200 19200 19200 19200 19200]
diff1,diff2 6.744148015975952 1.9550323486328125e-05
train_time 6.744243860244751
2023-09-06 12:39:34,199 MainThread INFO: EPOCH:126
2023-09-06 12:39:34,199 MainThread INFO: Time Consumed:6.761325359344482s
2023-09-06 12:39:34,199 MainThread INFO: Total Frames:190500s
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [15:24<10:22,  8.53s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1199.95664
Train_Epoch_Reward                    11732.74347
Running_Training_Average_Rewards      1190.56441
Explore_Time                          0.01284
Train___Time                          6.74424
Eval____Time                          0.00351
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.40765
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.93072
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -41.64727
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.06403
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.87191
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -74.21944
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.23264
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12510.11386
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.60911
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.46564
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.52440      1.54720      12.23697     5.74258
alpha_0                               3.37286      0.00252      3.37588      3.36779
alpha_1                               0.15882      0.00063      0.15989      0.15775
alpha_2                               0.17536      0.00065      0.17643      0.17425
alpha_3                               0.16866      0.00050      0.16951      0.16782
alpha_4                               0.16028      0.00066      0.16140      0.15916
alpha_5                               0.15878      0.00058      0.15976      0.15780
alpha_6                               0.16459      0.00071      0.16580      0.16340
alpha_7                               0.15950      0.00064      0.16059      0.15841
alpha_8                               0.15615      0.00064      0.15723      0.15506
alpha_9                               0.16330      0.00052      0.16418      0.16241
Alpha_loss                            -7.95251     0.09343      -7.74284     -8.18380
Training/policy_loss                  -355.46093   12.89838     -334.25323   -385.49548
Training/qf1_loss                     2448.85512   690.64198    4502.77295   1319.46387
Training/qf2_loss                     774.74337    225.86730    1228.72803   450.59885
Training/pf_norm                      19.38036     10.28741     45.89896     2.90373
Training/qf1_norm                     19886.27691  11010.64233  43789.03125  5905.23779
Training/qf2_norm                     15460.94769  7293.61592   27552.85156  3899.81934
log_std/mean                          -0.44683     0.01596      -0.41944     -0.47760
log_std/std                           0.33047      0.00416      0.33825      0.32075
log_std/max                           0.68474      0.11827      0.86654      0.43826
log_std/min                           -1.54845     0.06092      -1.46292     -1.73479
log_probs/mean                        -0.31934     0.08513      -0.08687     -0.50383
log_probs/std                         2.65043      0.13173      2.98875      2.37133
log_probs/max                         14.59527     0.90927      16.51837     13.26136
log_probs/min                         -7.55027     1.15811      -5.97327     -11.19122
mean/mean                             0.26712      0.02803      0.31918      0.20265
mean/std                              0.83609      0.01930      0.87754      0.79586
mean/max                              2.83950      0.15686      3.26352      2.58091
mean/min                              -3.68627     0.41096      -2.90362     -4.58002
------------------------------------  -----------  -----------  -----------  ----------
sample: [1, 5, 4, 2, 9, 6, 0, 3, 7, 8]
replay_buffer._size: [19350 19350 19350 19350 19350 19350 19350 19350 19350 19350]
diff1,diff2 8.144577264785767 6.127357482910156e-05
train_time 8.144716739654541
2023-09-06 12:39:42,532 MainThread INFO: EPOCH:127
2023-09-06 12:39:42,532 MainThread INFO: Time Consumed:8.153299331665039s
2023-09-06 12:39:42,533 MainThread INFO: Total Frames:192000s
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [15:32<10:11,  8.49s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1173.90197
Train_Epoch_Reward                    11430.64910
Running_Training_Average_Rewards      1139.10460
Explore_Time                          0.00406
Train___Time                          8.14472
Eval____Time                          0.00367
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.19778
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.28311
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.11883
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.12713
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.16277
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.00703
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.85889
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10713.94089
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.83678
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -43.77844
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.43516      1.57305      11.81483     5.15992
alpha_0                               3.38119      0.00441      3.38890      3.37592
alpha_1                               0.15665      0.00062      0.15771      0.15560
alpha_2                               0.17311      0.00063      0.17420      0.17204
alpha_3                               0.16691      0.00052      0.16779      0.16600
alpha_4                               0.15801      0.00064      0.15912      0.15693
alpha_5                               0.15678      0.00058      0.15776      0.15579
alpha_6                               0.16217      0.00069      0.16335      0.16100
alpha_7                               0.15730      0.00062      0.15837      0.15626
alpha_8                               0.15393      0.00063      0.15502      0.15286
alpha_9                               0.16150      0.00050      0.16237      0.16064
Alpha_loss                            -8.03853     0.13931      -7.83462     -8.46686
Training/policy_loss                  -355.62693   11.67409     -333.02792   -390.41309
Training/qf1_loss                     2401.46907   663.00459    3938.28003   1116.65515
Training/qf2_loss                     763.31407    219.62191    1459.67493   398.96930
Training/pf_norm                      16.71405     7.43048      42.71924     5.01254
Training/qf1_norm                     17100.38438  10816.83178  51632.87109  3104.52417
Training/qf2_norm                     10581.16005  5982.59719   28491.95117  2805.16870
log_std/mean                          -0.44701     0.02287      -0.40820     -0.49231
log_std/std                           0.35232      0.00571      0.36166      0.33920
log_std/max                           0.84128      0.13866      1.10329      0.51642
log_std/min                           -1.57440     0.05228      -1.47702     -1.70049
log_probs/mean                        -0.27710     0.12061      0.00795      -0.56584
log_probs/std                         2.71761      0.13698      2.99185      2.43510
log_probs/max                         14.35525     1.09442      17.33731     12.04581
log_probs/min                         -7.54108     0.90049      -5.63628     -9.52175
mean/mean                             0.29444      0.03946      0.37331      0.23838
mean/std                              0.83033      0.01684      0.86237      0.79846
mean/max                              2.95957      0.20705      3.36295      2.54123
mean/min                              -3.64240     0.45299      -2.93166     -4.41068
------------------------------------  -----------  -----------  -----------  ----------
sample: [1, 4, 9, 5, 3, 8, 7, 6, 2, 0]
replay_buffer._size: [19500 19500 19500 19500 19500 19500 19500 19500 19500 19500]
diff1,diff2 8.138018369674683 2.956390380859375e-05
train_time 8.13812780380249
2023-09-06 12:39:51,072 MainThread INFO: EPOCH:128
2023-09-06 12:39:51,072 MainThread INFO: Time Consumed:8.166387557983398s
2023-09-06 12:39:51,072 MainThread INFO: Total Frames:193500s
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [15:41<10:02,  8.49s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1001.06648
Train_Epoch_Reward                    9206.97230
Running_Training_Average_Rewards      1079.01216
Explore_Time                          0.02394
Train___Time                          8.13813
Eval____Time                          0.00365
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.05465
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -58.14941
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.07841
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.55885
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -69.21483
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -70.19770
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.73901
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8184.49055
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.34106
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.39767
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.20618      1.31880      11.48553     5.67402
alpha_0                               3.39878      0.00596      3.40816      3.38919
alpha_1                               0.15452      0.00060      0.15556      0.15350
alpha_2                               0.17095      0.00060      0.17200      0.16994
alpha_3                               0.16504      0.00052      0.16596      0.16419
alpha_4                               0.15582      0.00062      0.15688      0.15477
alpha_5                               0.15479      0.00055      0.15575      0.15386
alpha_6                               0.15980      0.00067      0.16095      0.15867
alpha_7                               0.15521      0.00059      0.15622      0.15421
alpha_8                               0.15177      0.00062      0.15282      0.15073
alpha_9                               0.15976      0.00048      0.16060      0.15896
Alpha_loss                            -7.81325     0.21420      -7.39534     -8.16462
Training/policy_loss                  -358.66613   10.57700     -334.88687   -377.59933
Training/qf1_loss                     2338.46724   624.33278    3895.99609   1334.01453
Training/qf2_loss                     689.77755    231.56266    1293.40808   280.05133
Training/pf_norm                      17.74537     9.10636      49.50284     5.60692
Training/qf1_norm                     17395.45745  11176.46507  48136.81641  5349.33887
Training/qf2_norm                     11076.50206  5425.91709   23646.57812  2919.17065
log_std/mean                          -0.47476     0.02550      -0.43079     -0.51933
log_std/std                           0.35733      0.00749      0.37099      0.33867
log_std/max                           0.88016      0.13636      1.10397      0.55843
log_std/min                           -1.59947     0.04178      -1.51750     -1.68232
log_probs/mean                        -0.09960     0.13625      0.23434      -0.39516
log_probs/std                         2.75657      0.13231      3.05024      2.55485
log_probs/max                         15.10517     1.38441      17.86411     12.47131
log_probs/min                         -7.42177     0.91095      -5.65267     -10.23953
mean/mean                             0.30377      0.01733      0.33520      0.26159
mean/std                              0.85653      0.01902      0.91424      0.81605
mean/max                              3.11939      0.17889      3.49750      2.75615
mean/min                              -3.90407     0.35475      -2.90227     -4.45368
------------------------------------  -----------  -----------  -----------  ----------
sample: [6, 8, 5, 7, 1, 4, 0, 9, 3, 2]
replay_buffer._size: [19650 19650 19650 19650 19650 19650 19650 19650 19650 19650]
diff1,diff2 8.63550591468811 2.0503997802734375e-05
train_time 8.636183023452759
2023-09-06 12:39:59,894 MainThread INFO: EPOCH:129
2023-09-06 12:39:59,895 MainThread INFO: Time Consumed:8.646595478057861s
2023-09-06 12:39:59,895 MainThread INFO: Total Frames:195000s
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [15:49<10:01,  8.59s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               989.69910
Train_Epoch_Reward                    9334.34758
Running_Training_Average_Rewards      999.06563
Explore_Time                          0.00480
Train___Time                          8.63618
Eval____Time                          0.00464
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.44457
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -54.97412
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -15.76728
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.00371
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -72.66696
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.25893
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.45822
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12154.26072
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.88060
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.16229
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.49062      1.40981      12.08802     4.81678
alpha_0                               3.41310      0.00205      3.41496      3.40842
alpha_1                               0.15243      0.00061      0.15346      0.15143
alpha_2                               0.16886      0.00061      0.16990      0.16786
alpha_3                               0.16321      0.00057      0.16416      0.16228
alpha_4                               0.15370      0.00060      0.15473      0.15268
alpha_5                               0.15289      0.00054      0.15382      0.15197
alpha_6                               0.15750      0.00066      0.15862      0.15638
alpha_7                               0.15315      0.00060      0.15417      0.15213
alpha_8                               0.14963      0.00062      0.15068      0.14858
alpha_9                               0.15810      0.00051      0.15893      0.15721
Alpha_loss                            -7.87888     0.28793      -7.17760     -8.25450
Training/policy_loss                  -361.19645   11.67483     -337.16412   -389.61993
Training/qf1_loss                     2388.34589   606.98300    3896.81323   1532.69922
Training/qf2_loss                     716.60345    247.38956    1581.93518   412.53427
Training/pf_norm                      12.35098     6.73691      38.45870     4.32936
Training/qf1_norm                     21696.06360  12374.67517  52408.64844  5245.24561
Training/qf2_norm                     9163.37050   5036.73381   27849.43359  2521.92236
log_std/mean                          -0.42691     0.03853      -0.37361     -0.51479
log_std/std                           0.35083      0.00538      0.36019      0.33923
log_std/max                           0.94211      0.14750      1.13440      0.59971
log_std/min                           -1.55985     0.08518      -1.41085     -1.69608
log_probs/mean                        -0.22633     0.14487      0.17479      -0.49773
log_probs/std                         2.63264      0.12332      2.97476      2.37122
log_probs/max                         14.94150     1.38193      18.82965     12.54704
log_probs/min                         -7.48336     1.09971      -5.57740     -10.32021
mean/mean                             0.19271      0.08896      0.34003      0.05372
mean/std                              0.86966      0.01389      0.89789      0.84439
mean/max                              2.94953      0.25768      3.39972      2.40263
mean/min                              -3.76385     0.40144      -3.06880     -4.71080
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 4, 1, 2, 7, 9, 6, 3, 8, 0]
replay_buffer._size: [19800 19800 19800 19800 19800 19800 19800 19800 19800 19800]
diff1,diff2 8.479946374893188 4.8160552978515625e-05
train_time 8.48007583618164
2023-09-06 12:40:08,569 MainThread INFO: EPOCH:130
2023-09-06 12:40:08,569 MainThread INFO: Time Consumed:8.491024017333984s
2023-09-06 12:40:08,570 MainThread INFO: Total Frames:196500s
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [15:58<09:53,  8.61s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1027.47132
Train_Epoch_Reward                    12106.78256
Running_Training_Average_Rewards      1021.60341
Explore_Time                          0.00589
Train___Time                          8.48008
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.28657
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -57.07470
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -16.63708
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -47.40677
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.67302
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.59949
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.40931
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11877.11629
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.07197
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.22078
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.33488      1.49767      12.42098     5.74379
alpha_0                               3.41139      0.00130      3.41423      3.40963
alpha_1                               0.15042      0.00058      0.15139      0.14942
alpha_2                               0.16690      0.00057      0.16783      0.16589
alpha_3                               0.16156      0.00044      0.16225      0.16076
alpha_4                               0.15161      0.00061      0.15264      0.15058
alpha_5                               0.15095      0.00058      0.15193      0.14998
alpha_6                               0.15523      0.00065      0.15633      0.15412
alpha_7                               0.15109      0.00058      0.15209      0.15010
alpha_8                               0.14754      0.00059      0.14854      0.14653
alpha_9                               0.15642      0.00043      0.15718      0.15569
Alpha_loss                            -7.75580     0.23801      -7.21397     -8.20848
Training/policy_loss                  -360.67022   13.12980     -334.35873   -400.25287
Training/qf1_loss                     2226.40123   605.53732    3933.92554   979.29388
Training/qf2_loss                     695.93609    206.38335    1209.54297   347.26633
Training/pf_norm                      13.41605     6.94277      38.57170     4.53283
Training/qf1_norm                     19561.57569  12491.00352  60446.71484  4603.94678
Training/qf2_norm                     11620.74577  6604.44097   29122.88281  3294.97900
log_std/mean                          -0.46196     0.01845      -0.44089     -0.51293
log_std/std                           0.35507      0.00467      0.36233      0.34455
log_std/max                           0.86550      0.09994      1.00470      0.63666
log_std/min                           -1.61471     0.06229      -1.52842     -1.81122
log_probs/mean                        -0.10884     0.08289      0.08807      -0.32313
log_probs/std                         2.69501      0.10650      2.96300      2.50092
log_probs/max                         15.71880     1.47118      18.40371     12.41683
log_probs/min                         -7.77403     1.44472      -5.43405     -12.00927
mean/mean                             0.29870      0.02541      0.35533      0.25856
mean/std                              0.85702      0.01567      0.88534      0.82613
mean/max                              3.20065      0.17240      3.53686      2.64457
mean/min                              -3.77826     0.33229      -2.94165     -4.45259
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 9, 6, 1, 7, 4, 8, 3, 2, 0]
replay_buffer._size: [19950 19950 19950 19950 19950 19950 19950 19950 19950 19950]
diff1,diff2 8.523599863052368 4.0531158447265625e-05
train_time 8.523720264434814
2023-09-06 12:40:17,273 MainThread INFO: EPOCH:131
2023-09-06 12:40:17,273 MainThread INFO: Time Consumed:8.5327889919281s
2023-09-06 12:40:17,273 MainThread INFO: Total Frames:198000s
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [16:07<09:47,  8.64s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               939.16984
Train_Epoch_Reward                    12340.05347
Running_Training_Average_Rewards      1126.03945
Explore_Time                          0.00476
Train___Time                          8.52372
Eval____Time                          0.00360
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.62223
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -54.21089
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.99080
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -45.16254
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.84606
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.04716
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.16113
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 5537.64517
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.48296
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.40685
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.36722      1.36820     11.27750     5.01125
alpha_0                               3.42317      0.00496     3.43112      3.41452
alpha_1                               0.14840      0.00058     0.14938      0.14739
alpha_2                               0.16487      0.00057     0.16585      0.16389
alpha_3                               0.15999      0.00044     0.16072      0.15923
alpha_4                               0.14953      0.00059     0.15053      0.14852
alpha_5                               0.14901      0.00056     0.14994      0.14805
alpha_6                               0.15298      0.00064     0.15407      0.15189
alpha_7                               0.14909      0.00057     0.15006      0.14811
alpha_8                               0.14549      0.00059     0.14648      0.14449
alpha_9                               0.15491      0.00046     0.15566      0.15408
Alpha_loss                            -7.85909     0.34928     -7.22355     -8.32850
Training/policy_loss                  -364.65815   11.62709    -344.44247   -390.72629
Training/qf1_loss                     2382.15984   602.22398   3787.28687   1031.22644
Training/qf2_loss                     706.84059    208.91968   1176.50916   275.43903
Training/pf_norm                      13.85775     6.26703     29.94353     3.80343
Training/qf1_norm                     17253.68090  8984.85552  47207.06250  5596.43701
Training/qf2_norm                     10269.36999  4467.38400  22136.42578  3537.48755
log_std/mean                          -0.45469     0.03090     -0.40213     -0.51131
log_std/std                           0.34448      0.01589     0.37221      0.32006
log_std/max                           0.88091      0.08337     0.99377      0.65055
log_std/min                           -1.58737     0.12533     -1.39633     -1.89381
log_probs/mean                        -0.05131     0.21835     0.33780      -0.35638
log_probs/std                         2.79505      0.13220     3.07413      2.47960
log_probs/max                         15.96771     2.16364     21.23493     12.40758
log_probs/min                         -7.70493     1.26444     -5.80754     -10.72680
mean/mean                             0.29352      0.03805     0.37657      0.23936
mean/std                              0.87732      0.02555     0.91831      0.82979
mean/max                              3.25905      0.25700     3.82842      2.79877
mean/min                              -3.84034     0.43597     -2.88237     -4.79747
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 7, 0, 1, 8, 4, 5, 6, 9, 2]
replay_buffer._size: [20100 20100 20100 20100 20100 20100 20100 20100 20100 20100]
diff1,diff2 9.176238298416138 1.8358230590820312e-05
train_time 9.176328420639038
2023-09-06 12:40:26,668 MainThread INFO: EPOCH:132
2023-09-06 12:40:26,668 MainThread INFO: Time Consumed:9.202423810958862s
2023-09-06 12:40:26,668 MainThread INFO: Total Frames:199500s
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [16:16<09:53,  8.86s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               859.63595
Train_Epoch_Reward                    5075.96654
Running_Training_Average_Rewards      984.09342
Explore_Time                          0.02147
Train___Time                          9.17633
Eval____Time                          0.00352
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.10605
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -56.55258
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.35320
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -48.84232
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.25312
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.44109
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -36.68585
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9790.28058
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.60064
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.81853
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.74239      1.53162      11.86925     5.18450
alpha_0                               3.43798      0.00304      3.44331      3.43150
alpha_1                               0.14635      0.00058      0.14735      0.14536
alpha_2                               0.16287      0.00056      0.16384      0.16192
alpha_3                               0.15851      0.00040      0.15920      0.15783
alpha_4                               0.14748      0.00058      0.14848      0.14649
alpha_5                               0.14705      0.00056      0.14801      0.14611
alpha_6                               0.15078      0.00062      0.15185      0.14973
alpha_7                               0.14710      0.00057      0.14807      0.14613
alpha_8                               0.14345      0.00058      0.14444      0.14247
alpha_9                               0.15320      0.00050      0.15404      0.15236
Alpha_loss                            -7.82459     0.14977      -7.52864     -8.14517
Training/policy_loss                  -368.29623   10.72042     -335.70700   -393.06403
Training/qf1_loss                     2283.90019   637.43535    3763.60620   1009.73615
Training/qf2_loss                     734.65680    211.53724    1343.69336   322.22266
Training/pf_norm                      17.18071     9.22182      45.63337     4.64717
Training/qf1_norm                     17864.77836  11747.97048  55918.79297  3237.14160
Training/qf2_norm                     10971.63625  6409.69223   33855.85938  3433.00903
log_std/mean                          -0.45952     0.01083      -0.43874     -0.48108
log_std/std                           0.33323      0.00746      0.34860      0.31870
log_std/max                           0.84501      0.09138      1.04755      0.64716
log_std/min                           -1.59280     0.08868      -1.43709     -1.82243
log_probs/mean                        -0.04652     0.07267      0.07571      -0.20166
log_probs/std                         2.79207      0.10808      2.99173      2.55283
log_probs/max                         16.05842     1.68783      20.17552     13.02041
log_probs/min                         -7.75466     1.25910      -5.81014     -11.01288
mean/mean                             0.26738      0.01258      0.29227      0.23778
mean/std                              0.89127      0.01511      0.91801      0.86346
mean/max                              3.28025      0.25295      3.77410      2.74500
mean/min                              -4.04109     0.42722      -3.01970     -4.77650
------------------------------------  -----------  -----------  -----------  ----------
sample: [4, 0, 1, 5, 9, 3, 6, 7, 8, 2]
replay_buffer._size: [20250 20250 20250 20250 20250 20250 20250 20250 20250 20250]
diff1,diff2 8.830021142959595 7.271766662597656e-05
train_time 8.83018445968628
2023-09-06 12:40:35,714 MainThread INFO: EPOCH:133
2023-09-06 12:40:35,714 MainThread INFO: Time Consumed:8.839378833770752s
2023-09-06 12:40:35,715 MainThread INFO: Total Frames:201000s
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [16:25<09:49,  8.92s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               937.30608
Train_Epoch_Reward                    6425.45563
Running_Training_Average_Rewards      794.71585
Explore_Time                          0.00378
Train___Time                          8.83018
Eval____Time                          0.00482
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.09806
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -53.69268
3                                     1.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -32.73836
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.68023
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.60647
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -69.04340
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.17876
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14234.54718
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.16308
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.50561
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           7.98031      1.51185      12.32325     5.69378
alpha_0                               3.44937      0.00356      3.45407      3.44360
alpha_1                               0.14435      0.00057      0.14532      0.14338
alpha_2                               0.16089      0.00058      0.16188      0.15989
alpha_3                               0.15715      0.00038      0.15780      0.15644
alpha_4                               0.14549      0.00057      0.14645      0.14451
alpha_5                               0.14516      0.00054      0.14607      0.14421
alpha_6                               0.14866      0.00060      0.14969      0.14763
alpha_7                               0.14513      0.00056      0.14609      0.14416
alpha_8                               0.14149      0.00056      0.14243      0.14053
alpha_9                               0.15153      0.00047      0.15233      0.15074
Alpha_loss                            -7.83600     0.31110      -7.21427     -8.34466
Training/policy_loss                  -365.14249   12.79799     -345.50867   -405.01010
Training/qf1_loss                     2111.90335   560.11090    3544.32861   1309.90088
Training/qf2_loss                     695.93933    195.99298    1114.10254   291.63660
Training/pf_norm                      11.70183     6.33767      39.71441     4.44121
Training/qf1_norm                     17625.29381  10232.61460  50011.31250  4826.55371
Training/qf2_norm                     13666.95423  6927.26425   27905.75977  2808.42700
log_std/mean                          -0.45374     0.02593      -0.40754     -0.49465
log_std/std                           0.34349      0.01186      0.36294      0.32333
log_std/max                           0.80934      0.09445      1.02698      0.64916
log_std/min                           -1.60387     0.08750      -1.46606     -1.80595
log_probs/mean                        -0.04895     0.20516      0.35306      -0.42292
log_probs/std                         2.71579      0.16649      3.13089      2.42145
log_probs/max                         15.13679     1.91633      19.37301     11.79945
log_probs/min                         -7.33456     1.07668      -5.72654     -11.55009
mean/mean                             0.28942      0.01752      0.32243      0.24537
mean/std                              0.87800      0.03770      0.96836      0.80985
mean/max                              3.19647      0.25022      3.76355      2.65195
mean/min                              -3.87000     0.39482      -2.91069     -4.70163
------------------------------------  -----------  -----------  -----------  ----------
sample: [8, 2, 4, 6, 1, 3, 9, 7, 5, 0]
replay_buffer._size: [20400 20400 20400 20400 20400 20400 20400 20400 20400 20400]
diff1,diff2 8.603994131088257 6.794929504394531e-05
train_time 8.604990720748901
2023-09-06 12:40:44,492 MainThread INFO: EPOCH:134
2023-09-06 12:40:44,492 MainThread INFO: Time Consumed:8.616487264633179s
2023-09-06 12:40:44,492 MainThread INFO: Total Frames:202500s
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [16:34<09:37,  8.88s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1056.19741
Train_Epoch_Reward                    12639.26523
Running_Training_Average_Rewards      804.68958
Explore_Time                          0.00622
Train___Time                          8.60499
Eval____Time                          0.00451
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.41341
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -50.48634
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.25231
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -49.90360
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.00927
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -73.09040
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.67242
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9124.89798
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.71285
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.90280
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.16019      1.25458      11.31913     5.55975
alpha_0                               3.45674      0.00195      3.46052      3.45374
alpha_1                               0.14238      0.00057      0.14334      0.14143
alpha_2                               0.15882      0.00060      0.15985      0.15783
alpha_3                               0.15564      0.00043      0.15641      0.15493
alpha_4                               0.14351      0.00056      0.14447      0.14256
alpha_5                               0.14323      0.00055      0.14417      0.14229
alpha_6                               0.14653      0.00062      0.14758      0.14547
alpha_7                               0.14314      0.00057      0.14412      0.14218
alpha_8                               0.13954      0.00056      0.14049      0.13860
alpha_9                               0.14991      0.00046      0.15070      0.14914
Alpha_loss                            -7.90800     0.16352      -7.61366     -8.27435
Training/policy_loss                  -367.58786   13.25740     -343.01349   -403.95956
Training/qf1_loss                     2090.27109   669.95543    5019.00879   1076.42810
Training/qf2_loss                     709.25871    204.09107    1507.50842   404.25439
Training/pf_norm                      13.33951     9.24509      58.51146     3.96681
Training/qf1_norm                     19242.59878  10046.14296  49886.32812  7816.13574
Training/qf2_norm                     15171.18771  8732.91063   36399.53516  3557.12451
log_std/mean                          -0.44484     0.01344      -0.42108     -0.47099
log_std/std                           0.35081      0.00781      0.36459      0.33077
log_std/max                           0.82878      0.09216      0.95251      0.61754
log_std/min                           -1.63354     0.08275      -1.49271     -1.88087
log_probs/mean                        -0.05583     0.08927      0.13277      -0.30424
log_probs/std                         2.76252      0.10658      2.99293      2.47585
log_probs/max                         15.01347     1.37903      19.01119     11.53719
log_probs/min                         -7.49392     1.15960      -5.77609     -11.21195
mean/mean                             0.28155      0.03355      0.35193      0.21024
mean/std                              0.88623      0.01736      0.91441      0.83965
mean/max                              3.16596      0.15525      3.51573      2.74093
mean/min                              -3.84510     0.37672      -3.12003     -4.59709
------------------------------------  -----------  -----------  -----------  ----------
sample: [0, 7, 6, 5, 1, 8, 2, 3, 9, 4]
replay_buffer._size: [20550 20550 20550 20550 20550 20550 20550 20550 20550 20550]
diff1,diff2 8.688149452209473 6.532669067382812e-05
train_time 8.688300132751465
2023-09-06 12:40:53,347 MainThread INFO: EPOCH:135
2023-09-06 12:40:53,347 MainThread INFO: Time Consumed:8.701588869094849s
2023-09-06 12:40:53,348 MainThread INFO: Total Frames:204000s
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [16:43<09:27,  8.87s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               971.75638
Train_Epoch_Reward                    8202.93220
Running_Training_Average_Rewards      908.92177
Explore_Time                          0.00586
Train___Time                          8.68830
Eval____Time                          0.00655
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.23799
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -51.64001
3                                     1.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -47.94547
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.57901
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.53057
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -62.91498
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.41338
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 7264.12753
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.14209
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.32764
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.01979      1.03624     10.37146     6.08250
alpha_0                               3.46398      0.00186     3.46733      3.46070
alpha_1                               0.14046      0.00054     0.14139      0.13954
alpha_2                               0.15678      0.00059     0.15779      0.15580
alpha_3                               0.15417      0.00044     0.15490      0.15346
alpha_4                               0.14158      0.00055     0.14253      0.14064
alpha_5                               0.14131      0.00055     0.14226      0.14038
alpha_6                               0.14437      0.00062     0.14543      0.14332
alpha_7                               0.14120      0.00056     0.14214      0.14025
alpha_8                               0.13762      0.00056     0.13857      0.13668
alpha_9                               0.14833      0.00045     0.14911      0.14760
Alpha_loss                            -7.89813     0.15184     -7.57016     -8.21031
Training/policy_loss                  -368.43285   11.92954    -336.57346   -391.90756
Training/qf1_loss                     1896.78861   533.49608   4048.16724   1007.85687
Training/qf2_loss                     694.60948    200.62166   1151.47620   384.70914
Training/pf_norm                      13.41589     7.35798     35.59200     2.76217
Training/qf1_norm                     12075.70678  6554.85480  33192.75391  3480.78906
Training/qf2_norm                     10215.18470  5204.52912  22592.18750  3122.88989
log_std/mean                          -0.44059     0.00918     -0.42153     -0.46176
log_std/std                           0.35305      0.00882     0.36742      0.33679
log_std/max                           0.81235      0.08397     0.95069      0.59999
log_std/min                           -1.62433     0.05195     -1.53714     -1.77143
log_probs/mean                        -0.03599     0.09760     0.14635      -0.25303
log_probs/std                         2.75710      0.13526     3.09543      2.45715
log_probs/max                         14.71639     1.68754     18.23937     11.83764
log_probs/min                         -7.38051     1.06794     -5.87170     -11.15846
mean/mean                             0.29550      0.02262     0.35920      0.25849
mean/std                              0.88585      0.01878     0.93342      0.84018
mean/max                              3.09459      0.19516     3.48296      2.75040
mean/min                              -3.76898     0.40151     -2.93291     -4.44873
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 6, 8, 2, 7, 3, 9, 0, 5, 1]
replay_buffer._size: [20700 20700 20700 20700 20700 20700 20700 20700 20700 20700]
diff1,diff2 8.530656099319458 4.792213439941406e-05
train_time 8.530773401260376
2023-09-06 12:41:02,075 MainThread INFO: EPOCH:136
2023-09-06 12:41:02,075 MainThread INFO: Time Consumed:8.542178869247437s
2023-09-06 12:41:02,075 MainThread INFO: Total Frames:205500s
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [16:52<09:15,  8.82s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               839.06000
Train_Epoch_Reward                    7440.56688
Running_Training_Average_Rewards      942.75881
Explore_Time                          0.00587
Train___Time                          8.53077
Eval____Time                          0.00480
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -58.52900
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -54.65920
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.55454
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.31665
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -75.72064
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -59.46135
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.22766
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 10221.00159
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.02610
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.55731
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.63468      1.60496      13.06512     4.90357
alpha_0                               3.47542      0.00511      3.48257      3.46752
alpha_1                               0.13859      0.00054      0.13951      0.13769
alpha_2                               0.15482      0.00056      0.15576      0.15388
alpha_3                               0.15268      0.00046      0.15343      0.15192
alpha_4                               0.13967      0.00055      0.14061      0.13875
alpha_5                               0.13936      0.00057      0.14034      0.13840
alpha_6                               0.14224      0.00061      0.14328      0.14120
alpha_7                               0.13926      0.00056      0.14022      0.13831
alpha_8                               0.13571      0.00055      0.13665      0.13479
alpha_9                               0.14682      0.00044      0.14757      0.14606
Alpha_loss                            -8.05613     0.19075      -7.67232     -8.43738
Training/policy_loss                  -375.07235   11.58583     -347.85211   -396.74350
Training/qf1_loss                     2008.58836   600.12711    3570.23804   960.48309
Training/qf2_loss                     750.55567    260.29806    1448.46777   317.10629
Training/pf_norm                      14.58196     6.46170      31.84580     4.35770
Training/qf1_norm                     21787.52630  13299.04726  56118.82031  3879.53809
Training/qf2_norm                     15471.01843  10158.77987  51283.73047  3930.71045
log_std/mean                          -0.44105     0.01753      -0.40972     -0.47318
log_std/std                           0.34188      0.00754      0.35760      0.32555
log_std/max                           0.74392      0.12384      0.97251      0.55074
log_std/min                           -1.61035     0.04034      -1.53949     -1.70542
log_probs/mean                        -0.04847     0.10223      0.13298      -0.27119
log_probs/std                         2.75529      0.09593      2.95304      2.52801
log_probs/max                         13.65092     0.89502      16.17472     11.97213
log_probs/min                         -7.44418     1.36639      -5.70261     -13.49328
mean/mean                             0.26922      0.04523      0.34079      0.13367
mean/std                              0.89537      0.02285      0.95123      0.85133
mean/max                              2.92403      0.11501      3.19719      2.70412
mean/min                              -3.66771     0.33448      -2.80923     -4.40538
------------------------------------  -----------  -----------  -----------  ----------
sample: [2, 3, 8, 7, 0, 9, 6, 4, 5, 1]
replay_buffer._size: [20850 20850 20850 20850 20850 20850 20850 20850 20850 20850]
diff1,diff2 7.140077352523804 3.504753112792969e-05
train_time 7.140187740325928
2023-09-06 12:41:10,928 MainThread INFO: EPOCH:137
2023-09-06 12:41:10,929 MainThread INFO: Time Consumed:7.358665227890015s
2023-09-06 12:41:10,929 MainThread INFO: Total Frames:207000s
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [17:00<09:07,  8.84s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               932.42422
Train_Epoch_Reward                    9639.60736
Running_Training_Average_Rewards      842.77021
Explore_Time                          0.21310
Train___Time                          7.14019
Eval____Time                          0.00436
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -62.70636
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -54.72096
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.80650
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -53.37871
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.00579
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.15538
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.75881
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 11913.50257
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.53979
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.04924
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.16645      1.33712     11.10184     4.27754
alpha_0                               3.48463      0.00182     3.48883      3.48262
alpha_1                               0.13677      0.00051     0.13765      0.13591
alpha_2                               0.15291      0.00055     0.15384      0.15199
alpha_3                               0.15117      0.00043     0.15189      0.15044
alpha_4                               0.13780      0.00053     0.13871      0.13691
alpha_5                               0.13745      0.00053     0.13836      0.13655
alpha_6                               0.14012      0.00061     0.14116      0.13908
alpha_7                               0.13735      0.00054     0.13828      0.13645
alpha_8                               0.13382      0.00055     0.13475      0.13289
alpha_9                               0.14524      0.00045     0.14602      0.14449
Alpha_loss                            -7.91547     0.13188     -7.67767     -8.19118
Training/policy_loss                  -373.78697   12.88632    -333.25464   -399.47812
Training/qf1_loss                     1827.91969   463.55055   3344.76562   761.33673
Training/qf2_loss                     662.21907    221.16269   1359.16760   287.49045
Training/pf_norm                      13.01713     6.12206     31.11729     2.59547
Training/qf1_norm                     15743.48372  8405.37420  40231.07812  4560.51807
Training/qf2_norm                     11677.86875  6678.61285  31311.85352  3377.00293
log_std/mean                          -0.45260     0.04128     -0.37656     -0.50409
log_std/std                           0.34131      0.00444     0.35138      0.33179
log_std/max                           0.75365      0.17026     1.05318      0.47910
log_std/min                           -1.62629     0.03892     -1.55300     -1.69357
log_probs/mean                        0.02053      0.11486     0.25682      -0.21887
log_probs/std                         2.76554      0.10916     3.03610      2.58375
log_probs/max                         13.89282     0.96025     16.53800     11.89524
log_probs/min                         -7.35708     1.05728     -5.54145     -10.20074
mean/mean                             0.22075      0.04992     0.28936      0.11331
mean/std                              0.91683      0.01623     0.95153      0.88152
mean/max                              2.93494      0.10926     3.09892      2.47416
mean/min                              -3.83340     0.33540     -2.96697     -4.42309
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 9, 4, 1, 0, 6, 5, 3, 7, 2]
replay_buffer._size: [21000 21000 21000 21000 21000 21000 21000 21000 21000 21000]
diff1,diff2 6.541046380996704 4.839897155761719e-05
train_time 6.5411670207977295
2023-09-06 12:41:19,529 MainThread INFO: EPOCH:138
2023-09-06 12:41:19,529 MainThread INFO: Time Consumed:6.548744201660156s
2023-09-06 12:41:19,529 MainThread INFO: Total Frames:208500s
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [17:09<08:54,  8.77s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1013.67416
Train_Epoch_Reward                    10476.86204
Running_Training_Average_Rewards      918.56788
Explore_Time                          0.00351
Train___Time                          6.54117
Eval____Time                          0.00345
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -66.92547
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -46.01210
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -15.93361
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -52.85546
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.35313
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -68.83136
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -24.55465
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9666.01208
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.83440
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.81735
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.30549      1.30301     11.22887     5.79140
alpha_0                               3.50024      0.00710     3.51088      3.48920
alpha_1                               0.13503      0.00050     0.13588      0.13418
alpha_2                               0.15104      0.00055     0.15196      0.15009
alpha_3                               0.14965      0.00045     0.15041      0.14891
alpha_4                               0.13599      0.00051     0.13687      0.13513
alpha_5                               0.13561      0.00052     0.13651      0.13474
alpha_6                               0.13801      0.00060     0.13904      0.13700
alpha_7                               0.13551      0.00053     0.13641      0.13461
alpha_8                               0.13196      0.00053     0.13286      0.13107
alpha_9                               0.14372      0.00045     0.14446      0.14295
Alpha_loss                            -7.94075     0.14814     -7.50376     -8.22926
Training/policy_loss                  -373.15832   12.06810    -346.97299   -396.29550
Training/qf1_loss                     1768.10958   427.58169   2743.07983   1052.05798
Training/qf2_loss                     704.11599    176.99085   1109.76501   381.89841
Training/pf_norm                      14.61070     10.92896    74.25933     3.60466
Training/qf1_norm                     15061.38221  7061.67445  35647.76953  4718.66602
Training/qf2_norm                     12978.97625  7959.19474  39195.13281  3681.02466
log_std/mean                          -0.48595     0.01507     -0.45662     -0.51837
log_std/std                           0.33991      0.00679     0.35069      0.32336
log_std/max                           0.78973      0.15664     1.00578      0.49851
log_std/min                           -1.67590     0.03301     -1.60843     -1.75039
log_probs/mean                        0.09559      0.08455     0.24157      -0.07619
log_probs/std                         2.75385      0.13788     3.00505      2.49885
log_probs/max                         13.51988     1.08471     15.97704     11.33672
log_probs/min                         -7.73893     1.47158     -5.83380     -12.56780
mean/mean                             0.24042      0.04701     0.33722      0.16746
mean/std                              0.91375      0.02803     0.97062      0.86665
mean/max                              3.03048      0.20942     3.50083      2.65300
mean/min                              -3.71240     0.27281     -3.07525     -4.19897
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 6, 7, 9, 4, 1, 8, 5, 3, 2]
replay_buffer._size: [21150 21150 21150 21150 21150 21150 21150 21150 21150 21150]
diff1,diff2 8.839933633804321 4.839897155761719e-05
train_time 8.840059280395508
2023-09-06 12:41:28,556 MainThread INFO: EPOCH:139
2023-09-06 12:41:28,557 MainThread INFO: Time Consumed:8.850825309753418s
2023-09-06 12:41:28,557 MainThread INFO: Total Frames:210000s
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [17:18<08:50,  8.85s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1150.84840
Train_Epoch_Reward                    7087.85376
Running_Training_Average_Rewards      906.81077
Explore_Time                          0.00502
Train___Time                          8.84006
Eval____Time                          0.00511
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.44535
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -46.13013
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.39195
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.16396
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.29433
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -51.88491
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -25.66372
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14343.07902
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.52740
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.40084
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.42055      1.33029      11.50539     5.35827
alpha_0                               3.52031      0.00540      3.52916      3.51110
alpha_1                               0.13326      0.00053      0.13415      0.13235
alpha_2                               0.14907      0.00059      0.15005      0.14807
alpha_3                               0.14813      0.00046      0.14888      0.14735
alpha_4                               0.13423      0.00051      0.13510      0.13336
alpha_5                               0.13382      0.00052      0.13470      0.13294
alpha_6                               0.13598      0.00059      0.13696      0.13498
alpha_7                               0.13365      0.00055      0.13458      0.13273
alpha_8                               0.13012      0.00054      0.13103      0.12920
alpha_9                               0.14212      0.00046      0.14292      0.14137
Alpha_loss                            -8.23299     0.16439      -7.87724     -8.55501
Training/policy_loss                  -379.25857   13.23605     -353.89224   -411.96832
Training/qf1_loss                     1667.94595   481.17280    3050.16821   670.53412
Training/qf2_loss                     774.37572    213.35745    1652.10181   474.21027
Training/pf_norm                      11.34296     6.57395      34.07386     3.77679
Training/qf1_norm                     16005.44265  7577.89740   38568.31250  6271.29932
Training/qf2_norm                     25346.57676  11588.11066  49759.95703  4348.43555
log_std/mean                          -0.44405     0.01877      -0.40749     -0.47183
log_std/std                           0.32564      0.00579      0.33759      0.31518
log_std/max                           0.78956      0.16030      1.01649      0.53030
log_std/min                           -1.55358     0.03419      -1.48478     -1.61787
log_probs/mean                        -0.03748     0.09896      0.17325      -0.25402
log_probs/std                         2.73339      0.11004      3.02968      2.49378
log_probs/max                         13.51910     1.17899      16.80437     11.22507
log_probs/min                         -7.54587     1.16030      -6.09072     -13.01355
mean/mean                             0.21413      0.03632      0.27079      0.13467
mean/std                              0.90962      0.01941      0.94686      0.86436
mean/max                              2.91084      0.19005      3.44454      2.54205
mean/min                              -3.76209     0.30082      -3.04851     -4.23717
------------------------------------  -----------  -----------  -----------  ----------
sample: [7, 1, 6, 3, 8, 4, 5, 0, 9, 2]
replay_buffer._size: [21300 21300 21300 21300 21300 21300 21300 21300 21300 21300]
diff1,diff2 8.657168626785278 1.811981201171875e-05
train_time 8.657251834869385
2023-09-06 12:41:37,430 MainThread INFO: EPOCH:140
2023-09-06 12:41:37,431 MainThread INFO: Time Consumed:8.673885583877563s
2023-09-06 12:41:37,431 MainThread INFO: Total Frames:211500s
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [17:27<08:42,  8.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1417.77246
Train_Epoch_Reward                    13918.88359
Running_Training_Average_Rewards      1049.45331
Explore_Time                          0.01114
Train___Time                          8.65725
Eval____Time                          0.00494
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -54.71009
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.11490
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.74381
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.94951
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -74.58944
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -76.46932
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.77360
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19908.70252
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -56.74188
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.50705
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.23022      1.22180     10.80324     5.67173
alpha_0                               3.53362      0.00473     3.54494      3.52936
alpha_1                               0.13141      0.00053     0.13231      0.13052
alpha_2                               0.14713      0.00053     0.14803      0.14623
alpha_3                               0.14660      0.00043     0.14732      0.14586
alpha_4                               0.13248      0.00050     0.13333      0.13164
alpha_5                               0.13202      0.00052     0.13290      0.13114
alpha_6                               0.13394      0.00059     0.13494      0.13295
alpha_7                               0.13178      0.00054     0.13269      0.13087
alpha_8                               0.12827      0.00053     0.12917      0.12737
alpha_9                               0.14064      0.00041     0.14134      0.13995
Alpha_loss                            -8.10107     0.18579     -7.68524     -8.56250
Training/policy_loss                  -380.30620   13.60615    -348.63892   -404.25388
Training/qf1_loss                     1497.84945   342.64036   2104.87598   798.94159
Training/qf2_loss                     628.44939    154.28828   1106.48083   363.86221
Training/pf_norm                      16.31981     9.96607     51.35173     4.95053
Training/qf1_norm                     15383.81328  8328.76183  38556.62109  2913.13159
Training/qf2_norm                     10210.44896  5865.36548  33515.36719  3000.27124
log_std/mean                          -0.47756     0.01962     -0.43184     -0.51140
log_std/std                           0.32844      0.00487     0.33817      0.31590
log_std/max                           0.79003      0.14133     1.00493      0.54657
log_std/min                           -1.57044     0.03359     -1.46695     -1.64079
log_probs/mean                        0.06098      0.10770     0.25718      -0.18129
log_probs/std                         2.81198      0.11741     3.08679      2.55438
log_probs/max                         14.22552     0.92585     16.41630     12.39746
log_probs/min                         -7.46018     1.08882     -5.89476     -10.28252
mean/mean                             0.25053      0.03446     0.31262      0.18000
mean/std                              0.91108      0.01323     0.93284      0.87958
mean/max                              2.98078      0.10449     3.17945      2.75611
mean/min                              -3.82718     0.26777     -3.14355     -4.34133
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 7, 3, 4, 8, 5, 2, 9, 6, 0]
replay_buffer._size: [21450 21450 21450 21450 21450 21450 21450 21450 21450 21450]
diff1,diff2 8.512144565582275 1.8358230590820312e-05
train_time 8.51223349571228
2023-09-06 12:41:46,179 MainThread INFO: EPOCH:141
2023-09-06 12:41:46,179 MainThread INFO: Time Consumed:8.543123722076416s
2023-09-06 12:41:46,180 MainThread INFO: Total Frames:213000s
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [17:36<08:31,  8.82s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1397.53700
Train_Epoch_Reward                    12516.95925
Running_Training_Average_Rewards      1117.45655
Explore_Time                          0.02599
Train___Time                          8.51223
Eval____Time                          0.00424
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -55.78475
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -54.92071
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.37835
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.03670
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.65841
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -67.89032
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -28.13296
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 9067.79443
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.35571
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.80594
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.27064      1.58580     11.99066     4.92015
alpha_0                               3.56577      0.01137     3.58403      3.54568
alpha_1                               0.12958      0.00053     0.13048      0.12870
alpha_2                               0.14526      0.00054     0.14619      0.14437
alpha_3                               0.14500      0.00048     0.14583      0.14423
alpha_4                               0.13077      0.00049     0.13161      0.12995
alpha_5                               0.13022      0.00052     0.13111      0.12936
alpha_6                               0.13192      0.00057     0.13291      0.13097
alpha_7                               0.12993      0.00053     0.13083      0.12905
alpha_8                               0.12644      0.00052     0.12733      0.12558
alpha_9                               0.13915      0.00045     0.13992      0.13843
Alpha_loss                            -8.20921     0.43573     -7.53863     -8.86257
Training/policy_loss                  -381.33727   13.99560    -347.03214   -406.58157
Training/qf1_loss                     1612.41935   478.39108   2714.73389   581.36487
Training/qf2_loss                     717.96154    221.66214   1250.36206   308.97461
Training/pf_norm                      18.18914     10.23655    49.03943     5.06542
Training/qf1_norm                     18388.66686  8938.42781  43810.47266  4169.68359
Training/qf2_norm                     15451.22484  8885.57366  35163.32031  2269.42432
log_std/mean                          -0.46971     0.02813     -0.42319     -0.51614
log_std/std                           0.33217      0.00597     0.34487      0.32249
log_std/max                           0.77625      0.13575     0.98873      0.57099
log_std/min                           -1.57260     0.03616     -1.51294     -1.66651
log_probs/mean                        0.12531      0.19960     0.46042      -0.17984
log_probs/std                         2.86609      0.08332     3.08379      2.66656
log_probs/max                         14.17033     1.05600     16.70473     11.86278
log_probs/min                         -7.42649     1.25413     -5.83187     -11.40477
mean/mean                             0.22022      0.03537     0.28498      0.13778
mean/std                              0.93370      0.02861     0.98843      0.88179
mean/max                              2.83565      0.07189     3.08324      2.69871
mean/min                              -3.82678     0.30473     -3.02124     -4.44024
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 2, 0, 9, 8, 5, 7, 1, 4, 3]
replay_buffer._size: [21600 21600 21600 21600 21600 21600 21600 21600 21600 21600]
diff1,diff2 8.558642387390137 6.914138793945312e-05
train_time 8.558817625045776
2023-09-06 12:41:55,084 MainThread INFO: EPOCH:142
2023-09-06 12:41:55,085 MainThread INFO: Time Consumed:8.58578109741211s
2023-09-06 12:41:55,085 MainThread INFO: Total Frames:214500s
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [17:45<08:24,  8.85s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1550.84240
Train_Epoch_Reward                    10541.76656
Running_Training_Average_Rewards      1232.58698
Explore_Time                          0.02227
Train___Time                          8.55882
Eval____Time                          0.00358
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -72.49831
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.71640
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.07709
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.88830
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -73.77099
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.46366
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.14675
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18946.17096
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.88608
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.38486
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           7.90185      1.06819     10.14026     5.23270
alpha_0                               3.59657      0.00573     3.60590      3.58473
alpha_1                               0.12780      0.00051     0.12866      0.12695
alpha_2                               0.14351      0.00049     0.14434      0.14268
alpha_3                               0.14355      0.00038     0.14420      0.14290
alpha_4                               0.12914      0.00046     0.12992      0.12835
alpha_5                               0.12852      0.00049     0.12933      0.12769
alpha_6                               0.13001      0.00054     0.13093      0.12910
alpha_7                               0.12814      0.00052     0.12901      0.12725
alpha_8                               0.12472      0.00048     0.12554      0.12390
alpha_9                               0.13774      0.00040     0.13840      0.13706
Alpha_loss                            -7.79090     0.17952     -7.48926     -8.19075
Training/policy_loss                  -380.35153   9.83827     -359.12695   -402.50632
Training/qf1_loss                     1416.14632   362.00058   2397.40308   875.89856
Training/qf2_loss                     621.61342    167.10576   1153.94763   356.35535
Training/pf_norm                      13.21671     5.39872     26.02773     4.63939
Training/qf1_norm                     10849.89500  4444.60939  24513.06445  5733.46191
Training/qf2_norm                     10858.23222  6300.39967  26901.49219  2896.56445
log_std/mean                          -0.48948     0.01630     -0.46221     -0.52291
log_std/std                           0.32617      0.00676     0.34412      0.31540
log_std/max                           0.71056      0.13103     0.89825      0.48936
log_std/min                           -1.57410     0.03988     -1.47307     -1.65060
log_probs/mean                        0.26649      0.11450     0.48064      0.06988
log_probs/std                         2.79087      0.07568     2.95406      2.64549
log_probs/max                         14.44872     1.24662     18.26756     11.83592
log_probs/min                         -7.28408     0.99313     -5.63763     -10.13981
mean/mean                             0.23166      0.02761     0.31067      0.18290
mean/std                              0.95729      0.01657     0.99337      0.92178
mean/max                              2.88570      0.12144     3.17301      2.60245
mean/min                              -4.06069     0.29563     -3.40701     -4.64462
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 0, 4, 8, 7, 6, 1, 9, 3, 5]
replay_buffer._size: [21750 21750 21750 21750 21750 21750 21750 21750 21750 21750]
diff1,diff2 8.877074956893921 7.271766662597656e-05
train_time 8.87722134590149
2023-09-06 12:42:04,155 MainThread INFO: EPOCH:143
2023-09-06 12:42:04,155 MainThread INFO: Time Consumed:8.88950228691101s
2023-09-06 12:42:04,155 MainThread INFO: Total Frames:216000s
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [17:54<08:18,  8.91s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1403.94458
Train_Epoch_Reward                    18148.39120
Running_Training_Average_Rewards      1373.57057
Explore_Time                          0.00645
Train___Time                          8.87722
Eval____Time                          0.00463
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -61.10702
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -49.17704
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -16.66934
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.19607
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.11817
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -66.32318
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.56271
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15522.01309
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.19818
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.49298
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.11971      1.42150     11.96176     3.85386
alpha_0                               3.61897      0.00787     3.63398      3.60644
alpha_1                               0.12607      0.00051     0.12691      0.12519
alpha_2                               0.14178      0.00053     0.14264      0.14084
alpha_3                               0.14225      0.00038     0.14288      0.14156
alpha_4                               0.12757      0.00045     0.12832      0.12680
alpha_5                               0.12686      0.00047     0.12766      0.12604
alpha_6                               0.12819      0.00052     0.12906      0.12729
alpha_7                               0.12636      0.00050     0.12722      0.12551
alpha_8                               0.12307      0.00047     0.12387      0.12226
alpha_9                               0.13630      0.00045     0.13704      0.13552
Alpha_loss                            -8.02125     0.38047     -7.27758     -8.63082
Training/policy_loss                  -381.81221   15.82153    -329.39084   -420.29865
Training/qf1_loss                     1451.95147   456.80115   3031.85083   732.37921
Training/qf2_loss                     685.44546    266.44711   1701.31531   245.05247
Training/pf_norm                      16.42414     9.07039     52.60571     3.56326
Training/qf1_norm                     18553.87761  9038.73709  40265.37891  4455.34619
Training/qf2_norm                     13004.57154  6586.66100  28237.31641  2968.98071
log_std/mean                          -0.48489     0.03316     -0.42785     -0.53401
log_std/std                           0.32463      0.00691     0.34100      0.30978
log_std/max                           0.71712      0.16009     0.99306      0.43367
log_std/min                           -1.54092     0.09187     -1.41322     -1.68351
log_probs/mean                        0.21837      0.15430     0.53373      -0.06237
log_probs/std                         2.82100      0.14393     3.09970      2.48298
log_probs/max                         14.33219     1.46392     18.89344     11.91710
log_probs/min                         -7.50725     1.13093     -5.16170     -10.74306
mean/mean                             0.23148      0.04721     0.30133      0.14852
mean/std                              0.94579      0.01691     0.98879      0.90692
mean/max                              2.86742      0.11714     3.10659      2.66330
mean/min                              -4.00025     0.34880     -3.16411     -4.69672
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 6, 5, 2, 9, 4, 1, 7, 8, 3]
replay_buffer._size: [21900 21900 21900 21900 21900 21900 21900 21900 21900 21900]
diff1,diff2 8.755467653274536 3.0517578125e-05
train_time 8.755543947219849
2023-09-06 12:42:13,114 MainThread INFO: EPOCH:144
2023-09-06 12:42:13,114 MainThread INFO: Time Consumed:8.767736911773682s
2023-09-06 12:42:13,114 MainThread INFO: Total Frames:217500s
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [18:03<08:10,  8.92s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1612.43810
Train_Epoch_Reward                    11852.40166
Running_Training_Average_Rewards      1351.41865
Explore_Time                          0.00718
Train___Time                          8.75554
Eval____Time                          0.00422
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.16918
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -48.97732
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.48135
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.18225
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.20181
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -56.56969
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.68614
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15325.68816
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.49513
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -51.28930
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.30747      1.18209     11.63787     6.17313
alpha_0                               3.65458      0.01152     3.67465      3.63482
alpha_1                               0.12428      0.00051     0.12516      0.12341
alpha_2                               0.13988      0.00054     0.14080      0.13896
alpha_3                               0.14082      0.00039     0.14153      0.14019
alpha_4                               0.12600      0.00044     0.12677      0.12525
alpha_5                               0.12517      0.00048     0.12600      0.12435
alpha_6                               0.12636      0.00053     0.12726      0.12546
alpha_7                               0.12464      0.00049     0.12547      0.12380
alpha_8                               0.12143      0.00047     0.12223      0.12064
alpha_9                               0.13476      0.00043     0.13549      0.13402
Alpha_loss                            -8.04301     0.13595     -7.71799     -8.34494
Training/policy_loss                  -386.43542   13.73055    -360.46811   -412.88678
Training/qf1_loss                     1412.61755   401.35990   2710.51294   763.46204
Training/qf2_loss                     710.37754    213.72301   1312.81042   360.03113
Training/pf_norm                      17.28884     9.42934     45.54368     4.20901
Training/qf1_norm                     15229.76920  6994.44419  31697.69727  2870.78931
Training/qf2_norm                     14705.98381  6951.78383  31216.30078  3922.17944
log_std/mean                          -0.49025     0.01699     -0.46397     -0.52631
log_std/std                           0.31971      0.00443     0.32616      0.30986
log_std/max                           0.75462      0.16261     0.97615      0.46799
log_std/min                           -1.52260     0.05462     -1.44916     -1.67202
log_probs/mean                        0.27828      0.08206     0.46253      0.11165
log_probs/std                         2.89428      0.10406     3.09747      2.66266
log_probs/max                         14.10397     1.08902     17.47483     11.58466
log_probs/min                         -7.09937     1.13903     -5.32298     -10.09601
mean/mean                             0.27005      0.05326     0.39000      0.17551
mean/std                              0.94571      0.01469     0.96658      0.91215
mean/max                              2.89621      0.12298     3.15087      2.68173
mean/min                              -3.87525     0.29862     -3.01934     -4.37431
------------------------------------  -----------  ----------  -----------  ----------
sample: [0, 8, 7, 6, 2, 1, 3, 9, 4, 5]
replay_buffer._size: [22050 22050 22050 22050 22050 22050 22050 22050 22050 22050]
diff1,diff2 8.547144174575806 6.771087646484375e-05
train_time 8.549338579177856
2023-09-06 12:42:22,018 MainThread INFO: EPOCH:145
2023-09-06 12:42:22,019 MainThread INFO: Time Consumed:8.561148881912231s
2023-09-06 12:42:22,019 MainThread INFO: Total Frames:219000s
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [18:12<08:03,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1698.26220
Train_Epoch_Reward                    16362.62917
Running_Training_Average_Rewards      1545.44740
Explore_Time                          0.00437
Train___Time                          8.54934
Eval____Time                          0.00644
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.70484
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -51.34053
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.88025
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.60551
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.54350
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -52.15790
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.40474
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 21540.17797
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.40668
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.07248
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.29361      1.20979     11.30735     5.77968
alpha_0                               3.69084      0.00761     3.69937      3.67542
alpha_1                               0.12253      0.00049     0.12338      0.12170
alpha_2                               0.13810      0.00048     0.13893      0.13731
alpha_3                               0.13961      0.00032     0.14017      0.13910
alpha_4                               0.12448      0.00044     0.12522      0.12374
alpha_5                               0.12354      0.00046     0.12432      0.12276
alpha_6                               0.12454      0.00051     0.12542      0.12368
alpha_7                               0.12295      0.00048     0.12376      0.12213
alpha_8                               0.11984      0.00045     0.12061      0.11908
alpha_9                               0.13329      0.00041     0.13399      0.13262
Alpha_loss                            -7.59458     0.22026     -7.08846     -8.06300
Training/policy_loss                  -386.50628   12.74277    -360.18051   -416.19391
Training/qf1_loss                     1333.37152   431.79402   2873.05249   773.74347
Training/qf2_loss                     689.57450    211.33989   1340.88220   386.90060
Training/pf_norm                      13.62153     6.74621     35.67793     4.95297
Training/qf1_norm                     13692.87807  8579.27782  46904.23438  3230.26855
Training/qf2_norm                     14204.94106  8880.44973  35796.21484  3689.45532
log_std/mean                          -0.51194     0.01197     -0.48266     -0.53256
log_std/std                           0.31963      0.00582     0.33176      0.30849
log_std/max                           0.63940      0.13190     0.89798      0.45519
log_std/min                           -1.51825     0.04607     -1.43992     -1.69072
log_probs/mean                        0.41184      0.08481     0.56625      0.18752
log_probs/std                         2.80195      0.13110     3.06968      2.58320
log_probs/max                         14.67728     1.66179     18.56442     11.50366
log_probs/min                         -7.22045     0.97705     -5.31714     -9.71073
mean/mean                             0.26747      0.05321     0.37332      0.17432
mean/std                              0.96693      0.02276     1.02669      0.92607
mean/max                              2.91386      0.11483     3.20240      2.67048
mean/min                              -4.03385     0.33514     -3.35063     -4.77306
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 8, 2, 1, 4, 7, 5, 0, 6, 9]
replay_buffer._size: [22200 22200 22200 22200 22200 22200 22200 22200 22200 22200]
diff1,diff2 6.882452726364136 7.104873657226562e-05
train_time 6.882629156112671
2023-09-06 12:42:31,071 MainThread INFO: EPOCH:146
2023-09-06 12:42:31,072 MainThread INFO: Time Consumed:6.895824909210205s
2023-09-06 12:42:31,072 MainThread INFO: Total Frames:220500s
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [18:21<07:54,  8.95s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1851.31321
Train_Epoch_Reward                    22461.57743
Running_Training_Average_Rewards      1689.22028
Explore_Time                          0.00823
Train___Time                          6.88263
Eval____Time                          0.00419
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.59502
6                                     0.00000
door-v1_success_rate                  1.00000
door-v1_eval_rewards                  -52.12157
3                                     1.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.58681
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -64.39823
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.11029
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -49.57380
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -33.67730
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20124.10912
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.75528
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -54.59217
8                                     0.00000
mean_success_rate                     0.20000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.00025      1.14387     11.43514     5.60290
alpha_0                               3.70568      0.00465     3.71242      3.69900
alpha_1                               0.12085      0.00048     0.12166      0.12004
alpha_2                               0.13647      0.00049     0.13727      0.13560
alpha_3                               0.13852      0.00035     0.13908      0.13793
alpha_4                               0.12293      0.00047     0.12371      0.12213
alpha_5                               0.12192      0.00047     0.12272      0.12111
alpha_6                               0.12280      0.00049     0.12364      0.12196
alpha_7                               0.12124      0.00050     0.12210      0.12040
alpha_8                               0.11829      0.00045     0.11905      0.11753
alpha_9                               0.13190      0.00042     0.13259      0.13117
Alpha_loss                            -8.00201     0.20642     -7.49185     -8.46529
Training/policy_loss                  -388.07690   13.33358    -362.85953   -415.90405
Training/qf1_loss                     1159.58148   339.99725   2122.32275   703.19568
Training/qf2_loss                     608.40382    202.03692   1210.54382   299.00269
Training/pf_norm                      11.33153     4.89293     25.55887     3.95955
Training/qf1_norm                     14431.42913  8192.55468  41967.10156  3598.98926
Training/qf2_norm                     10213.71509  5440.42005  26158.18750  3014.51880
log_std/mean                          -0.48802     0.01574     -0.45411     -0.51061
log_std/std                           0.30326      0.00500     0.31444      0.29347
log_std/max                           0.66769      0.18020     1.06519      0.41621
log_std/min                           -1.51440     0.04913     -1.42841     -1.62091
log_probs/mean                        0.22972      0.09667     0.46494      0.00064
log_probs/std                         2.72057      0.05920     2.84993      2.54138
log_probs/max                         13.50650     1.11999     16.43684     10.87550
log_probs/min                         -7.40613     1.12950     -5.58231     -10.57942
mean/mean                             0.23014      0.03675     0.33984      0.17050
mean/std                              0.94981      0.01572     0.99674      0.92424
mean/max                              2.74724      0.12372     3.03474      2.56504
mean/min                              -3.78170     0.23671     -3.10748     -4.24104
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 1, 3, 0, 7, 4, 5, 2, 6, 8]
replay_buffer._size: [22350 22350 22350 22350 22350 22350 22350 22350 22350 22350]
diff1,diff2 8.679886102676392 6.079673767089844e-05
train_time 8.680015802383423
2023-09-06 12:42:39,939 MainThread INFO: EPOCH:147
2023-09-06 12:42:39,939 MainThread INFO: Time Consumed:8.689549922943115s
2023-09-06 12:42:39,939 MainThread INFO: Total Frames:222000s
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [18:29<07:44,  8.94s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2015.05228
Train_Epoch_Reward                    19247.73863
Running_Training_Average_Rewards      1935.73151
Explore_Time                          0.00346
Train___Time                          8.68002
Eval____Time                          0.00486
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.17427
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.77829
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.75658
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.39991
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.97830
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.14702
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.76522
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 20238.10112
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -59.73240
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -48.56081
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.62178      1.26283     11.42829     6.32375
alpha_0                               3.72040      0.00518     3.73029      3.71266
alpha_1                               0.11923      0.00045     0.12001      0.11846
alpha_2                               0.13468      0.00051     0.13557      0.13383
alpha_3                               0.13725      0.00038     0.13790      0.13657
alpha_4                               0.12127      0.00048     0.12209      0.12045
alpha_5                               0.12031      0.00044     0.12108      0.11957
alpha_6                               0.12105      0.00051     0.12192      0.12020
alpha_7                               0.11959      0.00045     0.12036      0.11883
alpha_8                               0.11677      0.00043     0.11750      0.11604
alpha_9                               0.13043      0.00041     0.13114      0.12973
Alpha_loss                            -7.91655     0.38047     -7.21762     -8.49164
Training/policy_loss                  -396.69964   11.99040    -369.43832   -423.24081
Training/qf1_loss                     1228.68827   389.21544   2526.01880   605.09326
Training/qf2_loss                     681.33644    212.06944   1312.98010   365.06094
Training/pf_norm                      14.23914     8.24018     43.47938     4.43258
Training/qf1_norm                     14113.62320  7790.81336  38537.79688  3830.52319
Training/qf2_norm                     12105.40382  5976.50876  29191.48633  3373.57983
log_std/mean                          -0.52148     0.02934     -0.47187     -0.56593
log_std/std                           0.31672      0.00613     0.33276      0.30478
log_std/max                           0.71061      0.18093     1.05399      0.46586
log_std/min                           -1.61285     0.07825     -1.47086     -1.83960
log_probs/mean                        0.31101      0.17908     0.60925      -0.00638
log_probs/std                         2.68475      0.06096     2.84307      2.53404
log_probs/max                         12.79702     1.32641     15.58061     10.50029
log_probs/min                         -7.62053     1.05470     -5.40551     -10.03907
mean/mean                             0.25829      0.06238     0.38239      0.16050
mean/std                              0.93905      0.01147     0.96496      0.91253
mean/max                              2.69835      0.10331     2.92822      2.45737
mean/min                              -3.38345     0.24244     -2.87900     -3.85252
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 1, 9, 7, 4, 8, 6, 2, 0, 5]
replay_buffer._size: [22500 22500 22500 22500 22500 22500 22500 22500 22500 22500]
diff1,diff2 8.456417083740234 4.0531158447265625e-05
train_time 8.456530570983887
2023-09-06 12:42:48,775 MainThread INFO: EPOCH:148
2023-09-06 12:42:48,775 MainThread INFO: Time Consumed:8.48125410079956s
2023-09-06 12:42:48,776 MainThread INFO: Total Frames:223500s
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [18:38<07:33,  8.90s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1585.75688
Train_Epoch_Reward                    15395.14799
Running_Training_Average_Rewards      1903.48214
Explore_Time                          0.01805
Train___Time                          8.45653
Eval____Time                          0.00605
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -77.39220
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -33.06699
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -19.72168
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -62.58210
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.79635
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -45.79981
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -30.31468
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 8630.89756
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.69556
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -53.32873
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.60746      1.69732     13.89970     3.96079
alpha_0                               3.73608      0.00215     3.74088      3.73088
alpha_1                               0.11762      0.00048     0.11842      0.11681
alpha_2                               0.13291      0.00052     0.13379      0.13203
alpha_3                               0.13584      0.00040     0.13654      0.13513
alpha_4                               0.11956      0.00051     0.12042      0.11869
alpha_5                               0.11873      0.00049     0.11954      0.11789
alpha_6                               0.11932      0.00050     0.12016      0.11847
alpha_7                               0.11799      0.00047     0.11879      0.11719
alpha_8                               0.11525      0.00044     0.11601      0.11453
alpha_9                               0.12895      0.00044     0.12970      0.12823
Alpha_loss                            -8.28272     0.18961     -7.94007     -8.68642
Training/policy_loss                  -398.11914   15.74740    -345.29581   -433.34805
Training/qf1_loss                     1259.93510   340.43769   2038.82678   622.84363
Training/qf2_loss                     731.23188    218.84417   1303.38049   359.37915
Training/pf_norm                      10.39931     5.05660     32.14608     3.62598
Training/qf1_norm                     17066.80031  9702.85355  39167.29297  5560.00977
Training/qf2_norm                     15789.75595  8248.75492  38003.12891  3605.23340
log_std/mean                          -0.49917     0.01483     -0.46946     -0.53793
log_std/std                           0.30380      0.01234     0.32998      0.28328
log_std/max                           0.78251      0.16551     1.02421      0.52174
log_std/min                           -1.56431     0.09603     -1.43558     -1.83968
log_probs/mean                        0.11345      0.09116     0.39656      -0.06200
log_probs/std                         2.68794      0.09459     2.90734      2.48814
log_probs/max                         13.05848     1.29651     15.99680     10.66351
log_probs/min                         -7.32772     1.03196     -5.53330     -11.77707
mean/mean                             0.23968      0.05449     0.33325      0.14258
mean/std                              0.91512      0.02296     0.95412      0.86812
mean/max                              2.72734      0.15349     3.07425      2.51750
mean/min                              -3.31068     0.27975     -2.86905     -3.84055
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 1, 3, 8, 4, 0, 2, 6, 5, 9]
replay_buffer._size: [22650 22650 22650 22650 22650 22650 22650 22650 22650 22650]
diff1,diff2 9.071002960205078 6.127357482910156e-05
train_time 9.07113790512085
2023-09-06 12:42:58,044 MainThread INFO: EPOCH:149
2023-09-06 12:42:58,045 MainThread INFO: Time Consumed:9.081435203552246s
2023-09-06 12:42:58,045 MainThread INFO: Total Frames:225000s
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [18:48<07:30,  9.01s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1689.68148
Train_Epoch_Reward                    5990.54783
Running_Training_Average_Rewards      1354.44781
Explore_Time                          0.00626
Train___Time                          9.07114
Eval____Time                          0.00348
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -81.69733
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -45.01252
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.56766
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -58.86687
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.35882
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -60.21958
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -29.27941
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 23232.82753
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -57.79171
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.59703
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.38422      1.63245      11.78336     5.52497
alpha_0                               3.75497      0.00808      3.76885      3.74136
alpha_1                               0.11599      0.00046      0.11678      0.11521
alpha_2                               0.13113      0.00052      0.13199      0.13023
alpha_3                               0.13442      0.00039      0.13509      0.13375
alpha_4                               0.11782      0.00049      0.11865      0.11699
alpha_5                               0.11709      0.00045      0.11786      0.11633
alpha_6                               0.11760      0.00050      0.11844      0.11674
alpha_7                               0.11640      0.00044      0.11716      0.11565
alpha_8                               0.11379      0.00041      0.11450      0.11309
alpha_9                               0.12753      0.00039      0.12820      0.12686
Alpha_loss                            -8.09581     0.25797      -7.59910     -8.69214
Training/policy_loss                  -399.06928   16.25681     -371.82706   -433.75333
Training/qf1_loss                     1260.97052   423.29256    2398.53882   277.78394
Training/qf2_loss                     765.82579    264.04418    1433.07751   243.32420
Training/pf_norm                      10.97255     4.89649      26.02863     4.02069
Training/qf1_norm                     20425.12341  10437.72118  43018.53906  4137.26221
Training/qf2_norm                     20551.89494  10756.56727  45413.71094  3840.64478
log_std/mean                          -0.51346     0.02691      -0.47270     -0.55529
log_std/std                           0.31189      0.00620      0.32408      0.30036
log_std/max                           0.63389      0.11251      0.84369      0.44835
log_std/min                           -1.67247     0.09964      -1.46185     -1.87243
log_probs/mean                        0.30311      0.11770      0.48180      0.02006
log_probs/std                         2.75355      0.06840      2.92283      2.63039
log_probs/max                         13.26379     1.00118      16.18931     11.05906
log_probs/min                         -7.67464     1.36415      -5.73044     -13.08342
mean/mean                             0.22529      0.02128      0.26913      0.18338
mean/std                              0.95358      0.01390      0.98081      0.92783
mean/max                              2.77564      0.09593      2.99461      2.57691
mean/min                              -3.20294     0.15539      -2.88620     -3.51694
------------------------------------  -----------  -----------  -----------  ----------
sample: [1, 2, 5, 9, 7, 4, 8, 6, 0, 3]
replay_buffer._size: [22800 22800 22800 22800 22800 22800 22800 22800 22800 22800]
diff1,diff2 9.068503379821777 2.8371810913085938e-05
train_time 9.068606615066528
2023-09-06 12:43:07,301 MainThread INFO: EPOCH:150
2023-09-06 12:43:07,302 MainThread INFO: Time Consumed:9.083367586135864s
2023-09-06 12:43:07,302 MainThread INFO: Total Frames:226500s
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [18:57<07:24,  9.08s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1601.34041
Train_Epoch_Reward                    16773.11752
Running_Training_Average_Rewards      1271.96044
Explore_Time                          0.00989
Train___Time                          9.06861
Eval____Time                          0.00416
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -78.24164
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -41.36695
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -58.61588
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.78315
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.82664
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -56.58324
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -47.13625
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17647.59039
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.36253
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -56.09772
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.49408      1.19712     11.84892     6.14559
alpha_0                               3.78022      0.00583     3.78930      3.76944
alpha_1                               0.11442      0.00044     0.11518      0.11367
alpha_2                               0.12933      0.00050     0.13019      0.12847
alpha_3                               0.13309      0.00037     0.13372      0.13247
alpha_4                               0.11614      0.00048     0.11696      0.11534
alpha_5                               0.11558      0.00043     0.11630      0.11485
alpha_6                               0.11587      0.00049     0.11671      0.11504
alpha_7                               0.11486      0.00045     0.11562      0.11408
alpha_8                               0.11236      0.00042     0.11306      0.11164
alpha_9                               0.12622      0.00036     0.12683      0.12558
Alpha_loss                            -7.96706     0.34545     -7.21937     -8.50106
Training/policy_loss                  -405.19584   12.98075    -370.90463   -436.89096
Training/qf1_loss                     1187.74088   323.28573   2266.37158   668.35846
Training/qf2_loss                     707.27090    210.78611   1372.27283   283.74240
Training/pf_norm                      14.68709     8.38693     39.07438     3.72643
Training/qf1_norm                     17371.07069  9261.17106  37601.26953  5355.21240
Training/qf2_norm                     14595.08178  9465.03265  42926.25391  2956.64771
log_std/mean                          -0.50928     0.02596     -0.46897     -0.56215
log_std/std                           0.31472      0.00561     0.32561      0.30464
log_std/max                           0.56847      0.06110     0.69633      0.42580
log_std/min                           -1.73190     0.08919     -1.48936     -1.91567
log_probs/mean                        0.34447      0.16844     0.68638      0.05455
log_probs/std                         2.71323      0.08120     2.83813      2.51749
log_probs/max                         12.63542     1.35691     16.28914     9.81847
log_probs/min                         -7.82631     1.29501     -5.92078     -11.16591
mean/mean                             0.24032      0.07297     0.38171      0.13839
mean/std                              0.95663      0.01382     0.98844      0.92891
mean/max                              2.73113      0.16139     3.18816      2.47967
mean/min                              -3.13175     0.22453     -2.68006     -3.68868
------------------------------------  -----------  ----------  -----------  ----------
sample: [9, 2, 5, 4, 7, 3, 0, 1, 6, 8]
replay_buffer._size: [22950 22950 22950 22950 22950 22950 22950 22950 22950 22950]
diff1,diff2 8.782068967819214 1.6450881958007812e-05
train_time 8.782142162322998
2023-09-06 12:43:16,248 MainThread INFO: EPOCH:151
2023-09-06 12:43:16,248 MainThread INFO: Time Consumed:8.7957444190979s
2023-09-06 12:43:16,248 MainThread INFO: Total Frames:228000s
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [19:06<07:13,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1808.38690
Train_Epoch_Reward                    14366.50237
Running_Training_Average_Rewards      1237.67226
Explore_Time                          0.00949
Train___Time                          8.78214
Eval____Time                          0.00342
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -65.57699
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -47.72501
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.36746
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -57.99373
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.21247
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -63.40232
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -46.60990
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14861.17426
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -54.61057
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.08181
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.54785      1.08440     11.60393     6.55933
alpha_0                               3.79807      0.00496     3.80644      3.78964
alpha_1                               0.11291      0.00042     0.11364      0.11222
alpha_2                               0.12757      0.00049     0.12843      0.12675
alpha_3                               0.13191      0.00031     0.13245      0.13141
alpha_4                               0.11451      0.00046     0.11531      0.11376
alpha_5                               0.11406      0.00043     0.11481      0.11335
alpha_6                               0.11419      0.00047     0.11501      0.11340
alpha_7                               0.11325      0.00046     0.11404      0.11248
alpha_8                               0.11092      0.00039     0.11161      0.11028
alpha_9                               0.12486      0.00041     0.12556      0.12416
Alpha_loss                            -7.80481     0.45961     -6.91874     -8.44745
Training/policy_loss                  -404.51643   13.67736    -380.22397   -436.45004
Training/qf1_loss                     1160.66740   342.35486   2538.65015   570.69641
Training/qf2_loss                     699.12091    205.09685   1586.68518   367.97165
Training/pf_norm                      13.28040     7.16977     33.54248     3.16401
Training/qf1_norm                     13324.75323  8209.06298  45401.23438  4638.71191
Training/qf2_norm                     13201.76791  7728.58054  39874.36328  3504.36646
log_std/mean                          -0.53820     0.03853     -0.48327     -0.60878
log_std/std                           0.32061      0.01315     0.34367      0.30152
log_std/max                           0.53666      0.05431     0.64647      0.46291
log_std/min                           -1.86590     0.14917     -1.60123     -2.18292
log_probs/mean                        0.43378      0.22397     0.85617      0.09091
log_probs/std                         2.71481      0.09956     2.95668      2.52137
log_probs/max                         13.69920     1.59869     17.21256     10.71014
log_probs/min                         -7.36353     0.98255     -5.17604     -9.47927
mean/mean                             0.21928      0.03965     0.30630      0.15408
mean/std                              0.96790      0.01993     1.01583      0.93156
mean/max                              2.79514      0.11458     3.11887      2.53558
mean/min                              -3.43103     0.28413     -2.67947     -3.90837
------------------------------------  -----------  ----------  -----------  ----------
sample: [6, 1, 5, 8, 2, 9, 4, 3, 0, 7]
replay_buffer._size: [23100 23100 23100 23100 23100 23100 23100 23100 23100 23100]
diff1,diff2 8.762682437896729 6.556510925292969e-05
train_time 8.806256771087646
2023-09-06 12:43:25,275 MainThread INFO: EPOCH:152
2023-09-06 12:43:25,276 MainThread INFO: Time Consumed:8.81534457206726s
2023-09-06 12:43:25,276 MainThread INFO: Total Frames:229500s
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [19:15<07:04,  9.04s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1553.76723
Train_Epoch_Reward                    16061.11883
Running_Training_Average_Rewards      1573.35796
Explore_Time                          0.00362
Train___Time                          8.80626
Eval____Time                          0.00461
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -60.56086
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.63324
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -47.99794
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.59200
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.38862
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.16336
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.63186
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15588.98399
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -58.57898
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.59062
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.48911      1.49459     12.52096     5.95148
alpha_0                               3.81395      0.00418     3.81913      3.80668
alpha_1                               0.11145      0.00044     0.11219      0.11070
alpha_2                               0.12583      0.00052     0.12671      0.12498
alpha_3                               0.13076      0.00036     0.13139      0.13018
alpha_4                               0.11294      0.00047     0.11373      0.11215
alpha_5                               0.11265      0.00040     0.11333      0.11197
alpha_6                               0.11259      0.00046     0.11337      0.11181
alpha_7                               0.11167      0.00045     0.11245      0.11092
alpha_8                               0.10957      0.00039     0.11025      0.10893
alpha_9                               0.12337      0.00044     0.12413      0.12265
Alpha_loss                            -8.03898     0.37551     -7.41514     -8.70658
Training/policy_loss                  -406.33725   15.62904    -370.95074   -441.08936
Training/qf1_loss                     1018.09481   341.31566   2219.27905   549.15741
Training/qf2_loss                     622.59198    211.26977   1341.12073   329.71899
Training/pf_norm                      12.88823     7.33892     38.68024     3.83151
Training/qf1_norm                     13826.40175  7194.97738  35132.24609  4681.79395
Training/qf2_norm                     11482.96352  5682.25944  31508.10938  4040.70752
log_std/mean                          -0.53303     0.03248     -0.47459     -0.57562
log_std/std                           0.32431      0.00510     0.33636      0.31277
log_std/max                           0.54347      0.05915     0.64568      0.42095
log_std/min                           -2.01191     0.17603     -1.62725     -2.31397
log_probs/mean                        0.31753      0.16769     0.60383      -0.04757
log_probs/std                         2.65858      0.08646     2.84073      2.48648
log_probs/max                         13.11259     1.41537     16.12729     10.69964
log_probs/min                         -7.60423     1.11761     -5.80213     -10.25899
mean/mean                             0.20094      0.05348     0.28455      0.10209
mean/std                              0.94999      0.01527     0.98231      0.91906
mean/max                              2.66701      0.10241     2.81140      2.36982
mean/min                              -3.42466     0.24969     -2.88728     -3.79924
------------------------------------  -----------  ----------  -----------  ----------
sample: [8, 3, 2, 1, 6, 0, 7, 5, 4, 9]
replay_buffer._size: [23250 23250 23250 23250 23250 23250 23250 23250 23250 23250]
diff1,diff2 8.776238918304443 2.86102294921875e-05
train_time 8.77633547782898
2023-09-06 12:43:34,217 MainThread INFO: EPOCH:153
2023-09-06 12:43:34,217 MainThread INFO: Time Consumed:8.787225723266602s
2023-09-06 12:43:34,217 MainThread INFO: Total Frames:231000s
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [19:24<06:54,  9.01s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1751.85116
Train_Epoch_Reward                    13722.86400
Running_Training_Average_Rewards      1471.68284
Explore_Time                          0.00459
Train___Time                          8.77634
Eval____Time                          0.00494
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -67.61598
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.71605
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -16.27263
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -59.50295
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.02489
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -58.85427
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -31.60658
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 23496.83353
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -61.69375
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.45209
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.42416      1.58242      12.42967     5.54917
alpha_0                               3.82702      0.00791      3.83949      3.81864
alpha_1                               0.10998      0.00040      0.11067      0.10931
alpha_2                               0.12420      0.00043      0.12494      0.12346
alpha_3                               0.12957      0.00034      0.13016      0.12903
alpha_4                               0.11140      0.00042      0.11212      0.11068
alpha_5                               0.11131      0.00036      0.11194      0.11070
alpha_6                               0.11102      0.00044      0.11178      0.11029
alpha_7                               0.11018      0.00041      0.11089      0.10951
alpha_8                               0.10831      0.00035      0.10891      0.10773
alpha_9                               0.12192      0.00040      0.12262      0.12128
Alpha_loss                            -7.30261     0.26126      -6.82724     -7.79406
Training/policy_loss                  -408.65319   14.84001     -371.12555   -441.42795
Training/qf1_loss                     1101.79519   338.22867    1980.90662   460.97031
Training/qf2_loss                     755.29522    212.79260    1328.83521   291.40887
Training/pf_norm                      12.78147     5.38754      26.57594     3.95007
Training/qf1_norm                     15156.16723  8683.09688   37675.64844  3297.84521
Training/qf2_norm                     19033.56654  11015.38238  42039.53906  2501.88159
log_std/mean                          -0.59199     0.02756      -0.54512     -0.63584
log_std/std                           0.34327      0.00608      0.35525      0.33052
log_std/max                           0.52553      0.06641      0.69163      0.37665
log_std/min                           -2.29356     0.17897      -1.78756     -2.63119
log_probs/mean                        0.72782      0.16775      1.03909      0.38093
log_probs/std                         2.72216      0.11715      2.97207      2.50098
log_probs/max                         13.44790     1.24000      15.92020     11.26028
log_probs/min                         -7.64398     1.13804      -5.32096     -10.81006
mean/mean                             0.21529      0.04906      0.29760      0.13638
mean/std                              0.99804      0.02059      1.03095      0.94216
mean/max                              2.71450      0.17320      3.05115      2.26124
mean/min                              -3.34673     0.21059      -2.85434     -3.69720
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 8, 9, 7, 1, 4, 3, 0, 2, 6]
replay_buffer._size: [23400 23400 23400 23400 23400 23400 23400 23400 23400 23400]
diff1,diff2 7.275827884674072 1.7881393432617188e-05
train_time 7.275906324386597
2023-09-06 12:43:43,618 MainThread INFO: EPOCH:154
2023-09-06 12:43:43,618 MainThread INFO: Time Consumed:7.283583402633667s
2023-09-06 12:43:43,618 MainThread INFO: Total Frames:232500s
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [19:33<06:50,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1907.61077
Train_Epoch_Reward                    16891.13859
Running_Training_Average_Rewards      1555.83738
Explore_Time                          0.00319
Train___Time                          7.27591
Eval____Time                          0.00390
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -75.87424
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.23107
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -52.95324
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -60.96027
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.18633
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -61.26529
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.88712
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19545.48390
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.04442
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.69954
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.16923      1.41559     13.62986     5.69024
alpha_0                               3.84424      0.00180     3.84589      3.83973
alpha_1                               0.10860      0.00041     0.10929      0.10790
alpha_2                               0.12263      0.00048     0.12343      0.12179
alpha_3                               0.12840      0.00038     0.12901      0.12773
alpha_4                               0.10990      0.00045     0.11065      0.10913
alpha_5                               0.11006      0.00037     0.11067      0.10942
alpha_6                               0.10953      0.00043     0.11026      0.10880
alpha_7                               0.10879      0.00041     0.10948      0.10808
alpha_8                               0.10708      0.00037     0.10770      0.10645
alpha_9                               0.12062      0.00038     0.12126      0.11997
Alpha_loss                            -7.83636     0.37441     -7.29048     -8.59480
Training/policy_loss                  -411.32255   14.20046    -379.58044   -446.28751
Training/qf1_loss                     1051.94907   285.03717   1813.19568   589.21716
Training/qf2_loss                     668.95067    185.63474   1094.03162   377.66348
Training/pf_norm                      14.06797     9.75589     62.58904     4.08402
Training/qf1_norm                     16062.97143  8103.15198  34333.85156  5667.74463
Training/qf2_norm                     12983.70607  5746.60957  31673.97070  3767.24805
log_std/mean                          -0.52431     0.02795     -0.47232     -0.57304
log_std/std                           0.33200      0.01030     0.34776      0.30910
log_std/max                           0.60990      0.06472     0.77148      0.47421
log_std/min                           -2.12879     0.18889     -1.72200     -2.52150
log_probs/mean                        0.42075      0.17908     0.71072      -0.00367
log_probs/std                         2.60611      0.06949     2.76411      2.44304
log_probs/max                         12.29005     1.48676     15.49657     9.85221
log_probs/min                         -7.52964     1.18255     -5.60882     -10.45983
mean/mean                             0.17227      0.03901     0.26272      0.09327
mean/std                              0.97513      0.02626     1.02480      0.91077
mean/max                              2.54807      0.15308     2.96665      2.33587
mean/min                              -3.15760     0.24274     -2.64119     -3.81689
------------------------------------  -----------  ----------  -----------  ----------
sample: [2, 8, 9, 3, 6, 4, 7, 0, 1, 5]
replay_buffer._size: [23550 23550 23550 23550 23550 23550 23550 23550 23550 23550]
diff1,diff2 8.890859603881836 1.8358230590820312e-05
train_time 8.890944004058838
2023-09-06 12:43:52,705 MainThread INFO: EPOCH:155
2023-09-06 12:43:52,705 MainThread INFO: Time Consumed:8.901113986968994s
2023-09-06 12:43:52,705 MainThread INFO: Total Frames:234000s
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [19:42<06:41,  9.13s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2312.79758
Train_Epoch_Reward                    15836.02711
Running_Training_Average_Rewards      1548.33432
Explore_Time                          0.00520
Train___Time                          8.89094
Eval____Time                          0.00445
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -71.41473
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.94562
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -43.19500
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -54.35116
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -77.49925
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.98787
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.86573
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 27766.06104
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.49100
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -47.86012
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.60534      1.32507     11.51866     5.69777
alpha_0                               3.83914      0.00260     3.84498      3.83639
alpha_1                               0.10716      0.00041     0.10787      0.10647
alpha_2                               0.12088      0.00051     0.12175      0.12001
alpha_3                               0.12706      0.00039     0.12770      0.12632
alpha_4                               0.10832      0.00046     0.10910      0.10755
alpha_5                               0.10867      0.00043     0.10939      0.10796
alpha_6                               0.10803      0.00043     0.10877      0.10730
alpha_7                               0.10732      0.00043     0.10805      0.10660
alpha_8                               0.10582      0.00036     0.10642      0.10520
alpha_9                               0.11931      0.00037     0.11995      0.11867
Alpha_loss                            -8.00006     0.34106     -7.34315     -8.61048
Training/policy_loss                  -413.68505   13.15517    -377.76801   -452.09616
Training/qf1_loss                     1106.94468   373.14921   2199.72217   581.99481
Training/qf2_loss                     717.60130    231.48175   1452.64551   365.07339
Training/pf_norm                      10.49074     5.65232     26.82156     3.50956
Training/qf1_norm                     17569.98571  9639.54460  43380.68750  4691.38721
Training/qf2_norm                     11310.76735  6174.75535  28045.69531  3531.24976
log_std/mean                          -0.53303     0.01351     -0.50703     -0.56130
log_std/std                           0.33094      0.00915     0.34562      0.31036
log_std/max                           0.56502      0.07512     0.70290      0.41970
log_std/min                           -2.11017     0.23322     -1.63462     -2.45758
log_probs/mean                        0.35812      0.13964     0.58875      0.07226
log_probs/std                         2.60967      0.06857     2.70917      2.40539
log_probs/max                         11.81843     0.86465     13.60414     10.42661
log_probs/min                         -7.49724     0.98117     -6.07737     -11.07965
mean/mean                             0.25622      0.04345     0.31777      0.17302
mean/std                              0.94190      0.01831     0.97521      0.90217
mean/max                              2.59368      0.15419     3.07930      2.36042
mean/min                              -3.09775     0.16401     -2.77293     -3.62060
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 8, 9, 4, 1, 7, 2, 0, 6, 3]
replay_buffer._size: [23700 23700 23700 23700 23700 23700 23700 23700 23700 23700]
diff1,diff2 9.394793272018433 3.4809112548828125e-05
train_time 9.3948974609375
2023-09-06 12:44:02,265 MainThread INFO: EPOCH:156
2023-09-06 12:44:02,266 MainThread INFO: Time Consumed:9.405166149139404s
2023-09-06 12:44:02,266 MainThread INFO: Total Frames:235500s
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [19:52<06:37,  9.24s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1951.15594
Train_Epoch_Reward                    26230.76252
Running_Training_Average_Rewards      1965.26427
Explore_Time                          0.00523
Train___Time                          9.39490
Eval____Time                          0.00435
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -73.07664
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.02436
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -52.12478
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.77941
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.46818
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.49395
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -37.76917
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 12702.15642
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -62.11243
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.46225
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.20958      1.11491      10.24491     5.12739
alpha_0                               3.84114      0.00191      3.84382      3.83709
alpha_1                               0.10576      0.00040      0.10644      0.10508
alpha_2                               0.11914      0.00049      0.11997      0.11831
alpha_3                               0.12559      0.00039      0.12629      0.12488
alpha_4                               0.10679      0.00042      0.10752      0.10608
alpha_5                               0.10723      0.00042      0.10793      0.10651
alpha_6                               0.10653      0.00043      0.10727      0.10580
alpha_7                               0.10589      0.00040      0.10657      0.10521
alpha_8                               0.10458      0.00034      0.10517      0.10401
alpha_9                               0.11798      0.00038      0.11864      0.11732
Alpha_loss                            -7.86555     0.27388      -7.34394     -8.37751
Training/policy_loss                  -412.46400   15.98476     -372.18771   -443.46921
Training/qf1_loss                     1096.90130   284.66491    1808.65393   566.46332
Training/qf2_loss                     648.54551    186.56176    1057.09412   325.87094
Training/pf_norm                      12.37505     6.58002      36.42114     4.42039
Training/qf1_norm                     24134.84765  12761.09091  58048.96875  6454.69482
Training/qf2_norm                     11334.15852  5480.16118   28492.35547  4176.36133
log_std/mean                          -0.53402     0.02069      -0.49664     -0.56579
log_std/std                           0.32498      0.00815      0.34972      0.31094
log_std/max                           0.63443      0.05429      0.73872      0.43417
log_std/min                           -2.08673     0.24949      -1.62437     -2.48609
log_probs/mean                        0.41772      0.13238      0.74065      0.14192
log_probs/std                         2.56395      0.08001      2.77433      2.38713
log_probs/max                         11.51346     1.31217      15.21926     9.17893
log_probs/min                         -7.45189     1.00067      -5.47353     -9.64185
mean/mean                             0.21255      0.05155      0.31920      0.11875
mean/std                              0.96337      0.01411      1.00493      0.93679
mean/max                              2.55119      0.19469      3.03443      2.23860
mean/min                              -3.05814     0.25084      -2.64476     -3.50964
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 4, 6, 3, 1, 2, 0, 9, 7, 8]
replay_buffer._size: [23850 23850 23850 23850 23850 23850 23850 23850 23850 23850]
diff1,diff2 9.326343536376953 3.075599670410156e-05
train_time 9.326449871063232
2023-09-06 12:44:11,806 MainThread INFO: EPOCH:157
2023-09-06 12:44:11,806 MainThread INFO: Time Consumed:9.350528240203857s
2023-09-06 12:44:11,806 MainThread INFO: Total Frames:237000s
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [20:01<06:32,  9.33s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1932.68536
Train_Epoch_Reward                    12365.35385
Running_Training_Average_Rewards      1814.40478
Explore_Time                          0.01856
Train___Time                          9.32645
Eval____Time                          0.00499
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -74.09601
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.40490
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -54.55136
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -71.49821
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -78.29079
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -43.42650
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -32.53493
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 18998.35385
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.85319
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -52.43303
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.49120      1.32948      10.92655     5.18505
alpha_0                               3.83439      0.00141      3.83687      3.83220
alpha_1                               0.10435      0.00042      0.10505      0.10363
alpha_2                               0.11749      0.00047      0.11828      0.11667
alpha_3                               0.12411      0.00041      0.12485      0.12340
alpha_4                               0.10532      0.00043      0.10605      0.10457
alpha_5                               0.10577      0.00042      0.10648      0.10505
alpha_6                               0.10505      0.00042      0.10577      0.10434
alpha_7                               0.10450      0.00039      0.10518      0.10385
alpha_8                               0.10337      0.00036      0.10398      0.10276
alpha_9                               0.11665      0.00037      0.11730      0.11603
Alpha_loss                            -7.99577     0.32112      -7.42347     -8.59758
Training/policy_loss                  -418.22340   14.08197     -382.02090   -447.89865
Training/qf1_loss                     1214.06379   413.39394    2111.71582   430.69180
Training/qf2_loss                     779.02044    250.80250    1352.41174   274.12103
Training/pf_norm                      10.15853     6.74930      45.50646     2.97275
Training/qf1_norm                     23088.79641  11034.79114  47922.23828  6115.57861
Training/qf2_norm                     20494.67008  10347.83084  44078.14844  5273.97998
log_std/mean                          -0.53086     0.01843      -0.49138     -0.56404
log_std/std                           0.32629      0.00909      0.35194      0.31163
log_std/max                           0.62455      0.08008      0.80397      0.47669
log_std/min                           -2.19964     0.19003      -1.73834     -2.59321
log_probs/mean                        0.41419      0.12641      0.63202      0.11237
log_probs/std                         2.65157      0.08434      2.81823      2.47106
log_probs/max                         11.82418     1.14623      16.07507     9.53496
log_probs/min                         -7.78515     1.37954      -5.73925     -12.40743
mean/mean                             0.23105      0.05480      0.33283      0.12347
mean/std                              0.96159      0.01817      1.00254      0.93196
mean/max                              2.56630      0.10334      2.81446      2.37700
mean/min                              -3.01761     0.23244      -2.54297     -3.69683
------------------------------------  -----------  -----------  -----------  ----------
sample: [3, 6, 9, 5, 4, 8, 2, 1, 0, 7]
replay_buffer._size: [24000 24000 24000 24000 24000 24000 24000 24000 24000 24000]
diff1,diff2 9.3631591796875 1.7404556274414062e-05
train_time 9.363234519958496
2023-09-06 12:44:21,348 MainThread INFO: EPOCH:158
2023-09-06 12:44:21,348 MainThread INFO: Time Consumed:9.372859477996826s
2023-09-06 12:44:21,348 MainThread INFO: Total Frames:238500s
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [20:11<06:25,  9.40s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1524.63558
Train_Epoch_Reward                    18823.26052
Running_Training_Average_Rewards      1913.97923
Explore_Time                          0.00553
Train___Time                          9.36323
Eval____Time                          0.00340
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -70.34413
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -26.30783
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -9.81153
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -69.13838
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -76.89966
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.78985
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.72189
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 15472.28333
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.37391
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -38.93904
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.71430      1.56457      12.94428     6.62587
alpha_0                               3.83376      0.00219      3.83814      3.83065
alpha_1                               0.10291      0.00040      0.10360      0.10223
alpha_2                               0.11586      0.00045      0.11664      0.11510
alpha_3                               0.12268      0.00041      0.12337      0.12198
alpha_4                               0.10380      0.00043      0.10454      0.10307
alpha_5                               0.10434      0.00040      0.10502      0.10365
alpha_6                               0.10361      0.00042      0.10432      0.10290
alpha_7                               0.10318      0.00038      0.10382      0.10254
alpha_8                               0.10215      0.00035      0.10274      0.10156
alpha_9                               0.11544      0.00034      0.11600      0.11486
Alpha_loss                            -7.84038     0.27583      -7.13630     -8.35632
Training/policy_loss                  -428.82879   17.81364     -388.47205   -476.53009
Training/qf1_loss                     1123.80345   374.08113    2132.14355   554.50488
Training/qf2_loss                     753.68804    238.39319    1451.73230   430.67139
Training/pf_norm                      12.28549     6.33140      30.77605     3.87069
Training/qf1_norm                     14960.58973  8478.33322   49837.43359  3622.10376
Training/qf2_norm                     22290.67944  10721.50986  43735.57812  5897.70996
log_std/mean                          -0.54659     0.01474      -0.51438     -0.58372
log_std/std                           0.33426      0.00937      0.35590      0.31553
log_std/max                           0.57703      0.04950      0.69749      0.44100
log_std/min                           -2.25332     0.25815      -1.71330     -2.71467
log_probs/mean                        0.51862      0.11609      0.75849      0.27204
log_probs/std                         2.66169      0.08771      2.82101      2.49572
log_probs/max                         11.69075     1.09902      14.37955     9.16347
log_probs/min                         -7.42458     0.95043      -5.59468     -9.47093
mean/mean                             0.26335      0.03021      0.31106      0.19647
mean/std                              0.96669      0.02209      1.00571      0.92690
mean/max                              2.57170      0.15103      2.93832      2.31456
mean/min                              -2.86309     0.24224      -2.54555     -3.44415
------------------------------------  -----------  -----------  -----------  ----------
sample: [1, 9, 6, 8, 2, 3, 4, 7, 0, 5]
replay_buffer._size: [24150 24150 24150 24150 24150 24150 24150 24150 24150 24150]
diff1,diff2 6.78451132774353 4.9114227294921875e-05
train_time 6.784634828567505
2023-09-06 12:44:30,701 MainThread INFO: EPOCH:159
2023-09-06 12:44:30,701 MainThread INFO: Time Consumed:6.794810056686401s
2023-09-06 12:44:30,701 MainThread INFO: Total Frames:240000s
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [20:20<06:15,  9.40s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1691.15094
Train_Epoch_Reward                    12111.26748
Running_Training_Average_Rewards      1443.32940
Explore_Time                          0.00512
Train___Time                          6.78463
Eval____Time                          0.00452
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -68.86544
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -31.57472
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -42.92107
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -61.37916
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.29342
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -53.64271
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.13656
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17682.07843
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -52.64097
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -45.31820
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.36859      1.10966     10.53586     5.23568
alpha_0                               3.83790      0.00370     3.84378      3.83356
alpha_1                               0.10154      0.00038     0.10220      0.10091
alpha_2                               0.11436      0.00041     0.11507      0.11367
alpha_3                               0.12125      0.00043     0.12196      0.12047
alpha_4                               0.10235      0.00040     0.10304      0.10169
alpha_5                               0.10294      0.00040     0.10362      0.10229
alpha_6                               0.10216      0.00042     0.10287      0.10143
alpha_7                               0.10189      0.00038     0.10251      0.10124
alpha_8                               0.10096      0.00034     0.10153      0.10038
alpha_9                               0.11424      0.00036     0.11483      0.11362
Alpha_loss                            -7.72347     0.22761     -7.21819     -8.07006
Training/policy_loss                  -424.29345   14.21441    -389.78036   -449.72824
Training/qf1_loss                     1062.24589   235.61087   1699.32947   582.32111
Training/qf2_loss                     704.23223    191.23525   1318.87976   353.68588
Training/pf_norm                      12.28295     6.50734     27.65549     3.67762
Training/qf1_norm                     16108.66957  7592.82190  34504.58594  4756.40283
Training/qf2_norm                     14064.96296  7351.44963  37919.85156  5320.32227
log_std/mean                          -0.54607     0.02016     -0.50656     -0.58641
log_std/std                           0.33987      0.00935     0.36606      0.32511
log_std/max                           0.55608      0.05317     0.65321      0.46568
log_std/min                           -2.28596     0.28654     -1.58274     -2.85884
log_probs/mean                        0.55072      0.14570     0.84444      0.26246
log_probs/std                         2.57881      0.11004     2.80474      2.37255
log_probs/max                         11.28995     0.86218     13.38140     8.83751
log_probs/min                         -7.45951     1.11125     -5.76124     -11.59476
mean/mean                             0.19745      0.09486     0.33126      0.04488
mean/std                              0.98263      0.02605     1.02745      0.92478
mean/max                              2.62577      0.15929     3.16204      2.36075
mean/min                              -2.80729     0.23456     -2.35056     -3.21824
------------------------------------  -----------  ----------  -----------  ----------
sample: [4, 2, 5, 8, 6, 3, 0, 7, 1, 9]
replay_buffer._size: [24300 24300 24300 24300 24300 24300 24300 24300 24300 24300]
diff1,diff2 9.287089586257935 4.220008850097656e-05
train_time 9.287209749221802
2023-09-06 12:44:40,221 MainThread INFO: EPOCH:160
2023-09-06 12:44:40,221 MainThread INFO: Time Consumed:9.296605348587036s
2023-09-06 12:44:40,221 MainThread INFO: Total Frames:241500s
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [20:30<06:07,  9.43s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1991.28249
Train_Epoch_Reward                    19031.85786
Running_Training_Average_Rewards      1665.54620
Explore_Time                          0.00410
Train___Time                          9.28721
Eval____Time                          0.00444
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -53.76034
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.37866
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -52.24635
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -62.48639
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.10473
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -61.17053
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -40.52289
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 27985.02814
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.76373
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.38311
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.55283      1.39552     12.12519     6.28572
alpha_0                               3.83806      0.00104     3.84145      3.83616
alpha_1                               0.10030      0.00034     0.10089      0.09971
alpha_2                               0.11298      0.00040     0.11364      0.11229
alpha_3                               0.11977      0.00038     0.12043      0.11910
alpha_4                               0.10101      0.00038     0.10166      0.10037
alpha_5                               0.10156      0.00042     0.10226      0.10085
alpha_6                               0.10071      0.00041     0.10141      0.10001
alpha_7                               0.10058      0.00037     0.10121      0.09995
alpha_8                               0.09983      0.00031     0.10036      0.09929
alpha_9                               0.11298      0.00037     0.11359      0.11234
Alpha_loss                            -7.64639     0.35594     -7.03750     -8.28344
Training/policy_loss                  -428.83257   15.45902    -397.26349   -466.17197
Training/qf1_loss                     1081.66342   289.18884   1784.91199   628.14105
Training/qf2_loss                     692.01149    201.29937   1166.61267   340.86948
Training/pf_norm                      12.59705     8.25431     34.18911     3.40449
Training/qf1_norm                     17900.50622  8130.57511  36839.76953  5593.48096
Training/qf2_norm                     11788.77270  4458.30849  25874.36328  4039.37109
log_std/mean                          -0.56707     0.01618     -0.53197     -0.58566
log_std/std                           0.33660      0.01119     0.36175      0.31243
log_std/max                           0.53013      0.07263     0.68279      0.38571
log_std/min                           -2.40544     0.28737     -1.70542     -2.85023
log_probs/mean                        0.64919      0.15350     0.94246      0.30185
log_probs/std                         2.62386      0.07582     2.84889      2.43471
log_probs/max                         11.59861     0.87920     13.44279     9.61710
log_probs/min                         -7.33802     1.08309     -5.48197     -9.47900
mean/mean                             0.23417      0.03215     0.29197      0.16783
mean/std                              0.98737      0.02082     1.02798      0.94749
mean/max                              2.60572      0.15510     3.18730      2.36791
mean/min                              -2.86545     0.30351     -2.30170     -3.56435
------------------------------------  -----------  ----------  -----------  ----------
sample: [7, 0, 1, 3, 6, 8, 9, 2, 4, 5]
replay_buffer._size: [24450 24450 24450 24450 24450 24450 24450 24450 24450 24450]
diff1,diff2 9.241300582885742 2.1696090698242188e-05
train_time 9.241394996643066
2023-09-06 12:44:49,675 MainThread INFO: EPOCH:161
2023-09-06 12:44:49,676 MainThread INFO: Time Consumed:9.279696464538574s
2023-09-06 12:44:49,676 MainThread INFO: Total Frames:243000s
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [20:39<05:58,  9.44s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1960.33248
Train_Epoch_Reward                    27552.27197
Running_Training_Average_Rewards      1956.51324
Explore_Time                          0.03168
Train___Time                          9.24139
Eval____Time                          0.00574
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -44.72272
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.88237
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -56.31737
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -67.18195
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.16107
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -57.61262
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -39.04779
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14583.65917
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.21971
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.05671
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.40524      1.23814     11.21806     5.73373
alpha_0                               3.84658      0.00150     3.84976      3.84201
alpha_1                               0.09914      0.00031     0.09969      0.09862
alpha_2                               0.11158      0.00040     0.11226      0.11091
alpha_3                               0.11831      0.00045     0.11907      0.11755
alpha_4                               0.09969      0.00038     0.10034      0.09903
alpha_5                               0.10014      0.00039     0.10082      0.09947
alpha_6                               0.09931      0.00039     0.09998      0.09865
alpha_7                               0.09931      0.00037     0.09993      0.09868
alpha_8                               0.09870      0.00034     0.09926      0.09813
alpha_9                               0.11172      0.00034     0.11231      0.11116
Alpha_loss                            -7.53651     0.23284     -6.93315     -7.98973
Training/policy_loss                  -431.30459   13.16731    -407.09589   -467.41592
Training/qf1_loss                     1137.21736   312.16013   1723.60352   584.37872
Training/qf2_loss                     735.77701    214.76596   1148.00281   359.82062
Training/pf_norm                      11.75954     6.67941     32.59910     3.48445
Training/qf1_norm                     19813.37149  9844.68290  42885.53125  6461.41260
Training/qf2_norm                     16959.13983  8251.29797  35806.67188  5591.22656
log_std/mean                          -0.56832     0.01473     -0.53745     -0.60232
log_std/std                           0.35332      0.00724     0.36915      0.34002
log_std/max                           0.56570      0.05852     0.67812      0.42993
log_std/min                           -2.42934     0.23544     -1.84916     -2.92045
log_probs/mean                        0.70678      0.12543     0.95610      0.45817
log_probs/std                         2.62159      0.06407     2.77875      2.48865
log_probs/max                         11.15736     1.13640     14.61931     9.10680
log_probs/min                         -7.36894     1.22693     -5.49590     -10.92900
mean/mean                             0.19621      0.08901     0.33324      0.04939
mean/std                              0.99827      0.01583     1.03790      0.96778
mean/max                              2.53420      0.15159     2.90757      2.26077
mean/min                              -2.81324     0.14285     -2.57603     -3.24578
------------------------------------  -----------  ----------  -----------  ----------
sample: [1, 6, 2, 3, 9, 8, 5, 0, 4, 7]
replay_buffer._size: [24600 24600 24600 24600 24600 24600 24600 24600 24600 24600]
diff1,diff2 8.821466207504272 1.9073486328125e-05
train_time 8.821547031402588
2023-09-06 12:44:58,692 MainThread INFO: EPOCH:162
2023-09-06 12:44:58,693 MainThread INFO: Time Consumed:8.82964563369751s
2023-09-06 12:44:58,693 MainThread INFO: Total Frames:244500s
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [20:48<05:44,  9.31s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2014.87940
Train_Epoch_Reward                    14036.41698
Running_Training_Average_Rewards      2020.68489
Explore_Time                          0.00385
Train___Time                          8.82155
Eval____Time                          0.00361
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.50395
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -30.09316
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -51.72513
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -63.81779
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.63822
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -85.44459
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -44.65200
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 19358.20286
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.24937
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -41.36498
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.17014      1.26458     10.40737     5.76684
alpha_0                               3.84850      0.00165     3.85096      3.84613
alpha_1                               0.09807      0.00032     0.09860      0.09754
alpha_2                               0.11020      0.00042     0.11089      0.10950
alpha_3                               0.11685      0.00042     0.11753      0.11614
alpha_4                               0.09838      0.00036     0.09901      0.09779
alpha_5                               0.09876      0.00040     0.09944      0.09808
alpha_6                               0.09797      0.00039     0.09862      0.09732
alpha_7                               0.09806      0.00036     0.09866      0.09745
alpha_8                               0.09754      0.00034     0.09811      0.09698
alpha_9                               0.11059      0.00032     0.11114      0.11006
Alpha_loss                            -7.42887     0.40114     -6.63544     -8.05760
Training/policy_loss                  -432.09320   13.74357    -398.95868   -461.90509
Training/qf1_loss                     1001.97842   265.34290   1858.30981   550.01068
Training/qf2_loss                     669.48570    183.92452   1224.60510   377.90768
Training/pf_norm                      14.96658     8.64821     39.21556     4.09228
Training/qf1_norm                     16382.44781  7756.07767  40451.44141  7138.10400
Training/qf2_norm                     17529.74165  9860.73583  48745.44922  5038.37646
log_std/mean                          -0.57100     0.02357     -0.53125     -0.61815
log_std/std                           0.34871      0.00917     0.37327      0.33214
log_std/max                           0.64201      0.05530     0.72693      0.49073
log_std/min                           -2.56143     0.25403     -1.87847     -3.03568
log_probs/mean                        0.74028      0.17337     1.06760      0.49996
log_probs/std                         2.62218      0.07506     2.81703      2.46477
log_probs/max                         11.59119     1.08599     14.05414     8.92151
log_probs/min                         -7.45397     1.17748     -5.89186     -11.36451
mean/mean                             0.17769      0.05697     0.33326      0.08827
mean/std                              1.00877      0.02353     1.06369      0.97914
mean/max                              2.53608      0.13446     2.87075      2.34922
mean/min                              -2.86777     0.27321     -2.47774     -3.53177
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 5, 2, 8, 4, 6, 9, 1, 7, 0]
replay_buffer._size: [24750 24750 24750 24750 24750 24750 24750 24750 24750 24750]
diff1,diff2 9.039143562316895 4.792213439941406e-05
train_time 9.039270877838135
2023-09-06 12:45:07,904 MainThread INFO: EPOCH:163
2023-09-06 12:45:07,905 MainThread INFO: Time Consumed:9.051366329193115s
2023-09-06 12:45:07,905 MainThread INFO: Total Frames:246000s
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [20:57<05:33,  9.27s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1894.58938
Train_Epoch_Reward                    18753.65750
Running_Training_Average_Rewards      2011.41155
Explore_Time                          0.00646
Train___Time                          9.03927
Eval____Time                          0.00486
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -69.65452
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.38537
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -60.95768
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.21084
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -83.98148
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -96.65103
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -48.96174
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 24470.09526
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -68.45964
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -46.32205
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.38204      1.36255      11.11763     5.84582
alpha_0                               3.84899      0.00231      3.85207      3.84573
alpha_1                               0.09698      0.00033      0.09752      0.09642
alpha_2                               0.10877      0.00041      0.10947      0.10808
alpha_3                               0.11545      0.00042      0.11612      0.11473
alpha_4                               0.09714      0.00037      0.09776      0.09651
alpha_5                               0.09740      0.00038      0.09805      0.09674
alpha_6                               0.09666      0.00037      0.09729      0.09603
alpha_7                               0.09679      0.00038      0.09743      0.09614
alpha_8                               0.09639      0.00034      0.09696      0.09584
alpha_9                               0.10952      0.00033      0.11005      0.10894
Alpha_loss                            -7.67616     0.33497      -7.06151     -8.28819
Training/policy_loss                  -439.62992   16.37754     -403.59586   -486.50439
Training/qf1_loss                     1049.43544   320.13714    1933.86169   411.16901
Training/qf2_loss                     674.70837    189.89680    1248.32397   277.70889
Training/pf_norm                      16.28584     9.48090      58.82278     3.55688
Training/qf1_norm                     16280.63397  10683.43365  51700.60938  5401.64697
Training/qf2_norm                     14040.57058  8085.74126   41151.33203  4851.69580
log_std/mean                          -0.58099     0.01383      -0.55280     -0.60855
log_std/std                           0.34989      0.00772      0.36990      0.33256
log_std/max                           0.61629      0.04798      0.68344      0.50641
log_std/min                           -2.56883     0.23713      -1.89551     -3.12344
log_probs/mean                        0.66793      0.09756      0.90503      0.47802
log_probs/std                         2.62337      0.06771      2.79464      2.50251
log_probs/max                         11.26812     1.06384      14.34817     9.67497
log_probs/min                         -7.53422     1.25846      -5.66199     -12.70517
mean/mean                             0.19779      0.03330      0.27473      0.13339
mean/std                              0.99534      0.01317      1.01924      0.96263
mean/max                              2.51437      0.07975      2.71396      2.37965
mean/min                              -2.80415     0.22798      -2.40733     -3.32137
------------------------------------  -----------  -----------  -----------  ----------
sample: [0, 4, 5, 7, 9, 3, 6, 8, 1, 2]
replay_buffer._size: [24900 24900 24900 24900 24900 24900 24900 24900 24900 24900]
diff1,diff2 8.93028450012207 3.4332275390625e-05
train_time 8.930394649505615
2023-09-06 12:45:17,041 MainThread INFO: EPOCH:164
2023-09-06 12:45:17,042 MainThread INFO: Time Consumed:8.949045419692993s
2023-09-06 12:45:17,042 MainThread INFO: Total Frames:247500s
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [21:07<05:23,  9.23s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               1906.45259
Train_Epoch_Reward                    31158.55514
Running_Training_Average_Rewards      2131.62099
Explore_Time                          0.01434
Train___Time                          8.93039
Eval____Time                          0.00357
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -45.90166
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -28.62430
3                                     0.00000
drawer-close-v1_success_rate          0.00000
drawer-close-v1_eval_rewards          -10.01836
5                                     0.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -65.30055
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.59616
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -64.98114
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -41.08485
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 14906.55882
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.99176
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -40.70707
8                                     0.00000
mean_success_rate                     0.00000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.61943      1.34600     11.50389     5.70362
alpha_0                               3.85848      0.00688     3.87064      3.85018
alpha_1                               0.09585      0.00032     0.09640      0.09531
alpha_2                               0.10730      0.00043     0.10805      0.10660
alpha_3                               0.11397      0.00042     0.11470      0.11327
alpha_4                               0.09585      0.00038     0.09649      0.09520
alpha_5                               0.09606      0.00038     0.09671      0.09543
alpha_6                               0.09536      0.00037     0.09600      0.09473
alpha_7                               0.09550      0.00036     0.09612      0.09489
alpha_8                               0.09529      0.00031     0.09582      0.09477
alpha_9                               0.10832      0.00036     0.10892      0.10770
Alpha_loss                            -7.76096     0.31631     -7.15247     -8.41103
Training/policy_loss                  -439.67386   15.08291    -400.77545   -471.74326
Training/qf1_loss                     1124.82993   305.35832   1941.13440   566.33728
Training/qf2_loss                     748.68472    208.62830   1337.24268   356.95068
Training/pf_norm                      16.59336     10.38202    52.66150     3.16284
Training/qf1_norm                     16748.04253  9350.26198  50196.91797  5174.17480
Training/qf2_norm                     16499.97225  7186.33914  31988.29883  5455.18994
log_std/mean                          -0.59951     0.02308     -0.54325     -0.63715
log_std/std                           0.35657      0.00491     0.36757      0.34678
log_std/max                           0.59209      0.05220     0.68372      0.46143
log_std/min                           -2.62007     0.26446     -2.02920     -3.09720
log_probs/mean                        0.71724      0.14887     1.00627      0.41677
log_probs/std                         2.66461      0.06342     2.77927      2.50852
log_probs/max                         12.35866     1.32995     17.52813     9.74073
log_probs/min                         -7.81239     1.46881     -5.16334     -14.18590
mean/mean                             0.22864      0.04036     0.30988      0.16429
mean/std                              0.99183      0.02103     1.03902      0.95766
mean/max                              2.62047      0.13366     2.97732      2.36292
mean/min                              -2.98435     0.29943     -2.63875     -3.68870
------------------------------------  -----------  ----------  -----------  ----------
sample: [5, 9, 7, 4, 2, 8, 6, 0, 3, 1]
replay_buffer._size: [25050 25050 25050 25050 25050 25050 25050 25050 25050 25050]
diff1,diff2 9.10839581489563 3.0040740966796875e-05
train_time 9.108502388000488
2023-09-06 12:45:26,328 MainThread INFO: EPOCH:165
2023-09-06 12:45:26,329 MainThread INFO: Time Consumed:9.121331930160522s
2023-09-06 12:45:26,329 MainThread INFO: Total Frames:249000s
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [21:16<05:14,  9.25s/it]------------------------------------  -----------  ----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2167.70467
Train_Epoch_Reward                    11195.79701
Running_Training_Average_Rewards      2036.93366
Explore_Time                          0.00763
Train___Time                          9.10850
Eval____Time                          0.00463
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -38.30274
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -26.65243
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.17061
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -55.21513
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.86593
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.17286
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -38.04676
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 27121.70417
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -67.40731
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.59405
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std         Max          Min
Reward_Mean                           8.53051      1.25378     10.44637     5.49021
alpha_0                               3.87908      0.00424     3.88374      3.87108
alpha_1                               0.09477      0.00030     0.09528      0.09429
alpha_2                               0.10594      0.00035     0.10657      0.10538
alpha_3                               0.11246      0.00046     0.11324      0.11171
alpha_4                               0.09457      0.00035     0.09518      0.09397
alpha_5                               0.09480      0.00036     0.09541      0.09417
alpha_6                               0.09405      0.00039     0.09471      0.09339
alpha_7                               0.09425      0.00037     0.09487      0.09362
alpha_8                               0.09419      0.00032     0.09474      0.09366
alpha_9                               0.10698      0.00041     0.10767      0.10630
Alpha_loss                            -7.66365     0.38598     -6.96949     -8.22269
Training/policy_loss                  -440.01933   18.06599    -405.02719   -490.73495
Training/qf1_loss                     1021.12395   268.72076   1820.79260   526.39838
Training/qf2_loss                     697.58126    180.53874   1273.09692   391.91821
Training/pf_norm                      15.43033     7.87460     35.94837     3.68079
Training/qf1_norm                     15929.70662  8032.42480  39029.81641  4416.52539
Training/qf2_norm                     18073.13218  9657.72098  48314.03516  5775.52686
log_std/mean                          -0.59878     0.01609     -0.57461     -0.63278
log_std/std                           0.36673      0.00669     0.38632      0.35352
log_std/max                           0.69990      0.07413     0.82123      0.50950
log_std/min                           -2.55133     0.28663     -1.90017     -3.08467
log_probs/mean                        0.72310      0.14778     1.01090      0.49740
log_probs/std                         2.60557      0.06048     2.73893      2.45278
log_probs/max                         11.81029     1.70711     17.17383     8.99607
log_probs/min                         -7.72885     1.05466     -5.82832     -11.48075
mean/mean                             0.15391      0.04809     0.23544      0.07225
mean/std                              1.00112      0.02294     1.03744      0.95397
mean/max                              2.51854      0.15409     2.93137      2.31923
mean/min                              -3.03227     0.37847     -2.52796     -3.76936
------------------------------------  -----------  ----------  -----------  ----------
sample: [3, 2, 6, 5, 9, 1, 0, 4, 7, 8]
replay_buffer._size: [25200 25200 25200 25200 25200 25200 25200 25200 25200 25200]
diff1,diff2 8.947937250137329 1.8835067749023438e-05
train_time 8.948020458221436
2023-09-06 12:45:35,572 MainThread INFO: EPOCH:166
2023-09-06 12:45:35,573 MainThread INFO: Time Consumed:8.959543943405151s
2023-09-06 12:45:35,573 MainThread INFO: Total Frames:250500s
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [21:25<05:05,  9.25s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2530.60568
Train_Epoch_Reward                    26514.80914
Running_Training_Average_Rewards      2295.63871
Explore_Time                          0.00714
Train___Time                          8.94802
Eval____Time                          0.00353
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -41.81585
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -36.17296
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.67216
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -46.46854
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.87473
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.74265
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.88412
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 35218.86247
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.21430
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -39.47612
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.69002      1.44824      11.76597     5.45688
alpha_0                               3.88589      0.00149      3.88753      3.88253
alpha_1                               0.09379      0.00028      0.09427      0.09333
alpha_2                               0.10475      0.00036      0.10536      0.10415
alpha_3                               0.11094      0.00045      0.11169      0.11017
alpha_4                               0.09332      0.00037      0.09395      0.09269
alpha_5                               0.09351      0.00037      0.09415      0.09289
alpha_6                               0.09272      0.00038      0.09337      0.09206
alpha_7                               0.09299      0.00036      0.09360      0.09237
alpha_8                               0.09310      0.00033      0.09365      0.09256
alpha_9                               0.10563      0.00039      0.10627      0.10497
Alpha_loss                            -7.81851     0.20365      -7.40227     -8.25107
Training/policy_loss                  -447.67964   17.20064     -413.70303   -480.26682
Training/qf1_loss                     1262.15842   364.45074    2235.94116   522.56757
Training/qf2_loss                     736.62479    218.75206    1394.91150   333.89917
Training/pf_norm                      15.98361     8.04974      42.42732     4.54326
Training/qf1_norm                     37446.53568  19376.02459  77567.06250  5717.24219
Training/qf2_norm                     15319.58974  6840.30021   34910.55078  5640.41602
log_std/mean                          -0.57967     0.01121      -0.55307     -0.60195
log_std/std                           0.37053      0.00859      0.38887      0.35590
log_std/max                           0.66864      0.05002      0.75752      0.55234
log_std/min                           -2.46778     0.28196      -1.91291     -2.98711
log_probs/mean                        0.67555      0.09393      0.86853      0.46415
log_probs/std                         2.60026      0.07798      2.77647      2.38061
log_probs/max                         11.89890     1.31414      14.56271     9.24949
log_probs/min                         -7.73937     1.18486      -5.84207     -10.98068
mean/mean                             0.20882      0.03611      0.26728      0.12856
mean/std                              0.99200      0.01383      1.01851      0.96680
mean/max                              2.71053      0.19749      3.03649      2.35161
mean/min                              -3.15604     0.33643      -2.61929     -3.67337
------------------------------------  -----------  -----------  -----------  ----------
sample: [5, 9, 0, 7, 1, 3, 2, 4, 8, 6]
replay_buffer._size: [25350 25350 25350 25350 25350 25350 25350 25350 25350 25350]
diff1,diff2 8.931534051895142 3.0517578125e-05
train_time 8.931627988815308
2023-09-06 12:45:44,706 MainThread INFO: EPOCH:167
2023-09-06 12:45:44,706 MainThread INFO: Time Consumed:8.944200038909912s
2023-09-06 12:45:44,706 MainThread INFO: Total Frames:252000s
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [21:34<04:54,  9.22s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2619.14198
Train_Epoch_Reward                    33922.25235
Running_Training_Average_Rewards      2387.76195
Explore_Time                          0.00779
Train___Time                          8.93163
Eval____Time                          0.00420
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -52.78188
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -27.14396
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -44.43733
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.72645
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -81.17250
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.43858
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -27.14433
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 17597.47709
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -65.53010
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.65987
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.56330      1.20684      11.45588     6.77818
alpha_0                               3.89446      0.00322      3.90016      3.88736
alpha_1                               0.09282      0.00029      0.09331      0.09234
alpha_2                               0.10345      0.00039      0.10412      0.10279
alpha_3                               0.10935      0.00046      0.11014      0.10858
alpha_4                               0.09202      0.00038      0.09267      0.09136
alpha_5                               0.09228      0.00034      0.09286      0.09171
alpha_6                               0.09139      0.00038      0.09204      0.09075
alpha_7                               0.09174      0.00036      0.09235      0.09113
alpha_8                               0.09197      0.00033      0.09254      0.09140
alpha_9                               0.10425      0.00041      0.10494      0.10354
Alpha_loss                            -8.05035     0.24277      -7.54475     -8.42667
Training/policy_loss                  -447.61304   15.50793     -414.80103   -475.46817
Training/qf1_loss                     1047.52253   282.75525    1684.49377   587.76233
Training/qf2_loss                     708.66783    188.40498    1214.47192   419.63663
Training/pf_norm                      17.06026     10.59898     58.52614     4.50366
Training/qf1_norm                     20384.36351  11568.27185  47670.39844  4938.30371
Training/qf2_norm                     20336.78613  11645.23007  48424.80469  4967.62305
log_std/mean                          -0.59338     0.01637      -0.55574     -0.62148
log_std/std                           0.36430      0.00630      0.38408      0.35381
log_std/max                           0.65477      0.04833      0.71827      0.54110
log_std/min                           -2.41622     0.25937      -1.86150     -2.87936
log_probs/mean                        0.61090      0.08796      0.80537      0.43471
log_probs/std                         2.57195      0.06449      2.74501      2.42040
log_probs/max                         11.72821     1.46823      16.76783     9.47817
log_probs/min                         -7.31193     1.28685      -5.33517     -12.67542
mean/mean                             0.18707      0.03141      0.24532      0.12469
mean/std                              0.97807      0.01042      0.99803      0.95814
mean/max                              2.65827      0.23884      3.21417      2.36122
mean/min                              -3.03629     0.39734      -2.50418     -3.90179
------------------------------------  -----------  -----------  -----------  ----------
sample: [2, 8, 7, 6, 1, 4, 3, 0, 5, 9]
replay_buffer._size: [25500 25500 25500 25500 25500 25500 25500 25500 25500 25500]
diff1,diff2 8.50290560722351 4.744529724121094e-05
train_time 8.50302267074585
2023-09-06 12:45:53,426 MainThread INFO: EPOCH:168
2023-09-06 12:45:53,427 MainThread INFO: Time Consumed:8.514587879180908s
2023-09-06 12:45:53,427 MainThread INFO: Total Frames:253500s
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [21:43<04:41,  9.07s/it]------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2670.33759
Train_Epoch_Reward                    16470.24153
Running_Training_Average_Rewards      2563.57677
Explore_Time                          0.00577
Train___Time                          8.50302
Eval____Time                          0.00521
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -48.46407
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -29.36786
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -18.63586
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.56218
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -80.67952
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -81.67342
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -26.62269
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 28662.37009
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -63.22093
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -49.99896
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           8.68364      1.55472      12.70362     5.80187
alpha_0                               3.91551      0.00933      3.93243      3.90061
alpha_1                               0.09183      0.00029      0.09232      0.09132
alpha_2                               0.10215      0.00037      0.10277      0.10150
alpha_3                               0.10781      0.00041      0.10855      0.10715
alpha_4                               0.09070      0.00037      0.09134      0.09007
alpha_5                               0.09112      0.00033      0.09168      0.09055
alpha_6                               0.09009      0.00037      0.09072      0.08946
alpha_7                               0.09050      0.00035      0.09110      0.08990
alpha_8                               0.09084      0.00032      0.09138      0.09030
alpha_9                               0.10282      0.00039      0.10351      0.10216
Alpha_loss                            -7.89070     0.24557      -7.51418     -8.47292
Training/policy_loss                  -456.21276   13.09822     -435.06534   -486.26740
Training/qf1_loss                     1060.09475   268.50450    1671.97156   542.15002
Training/qf2_loss                     713.95083    177.96714    1185.30029   421.77115
Training/pf_norm                      18.20523     13.22441     54.44913     3.24033
Training/qf1_norm                     18714.31707  10438.48678  48832.44922  4543.81787
Training/qf2_norm                     20362.49648  12185.16836  58357.60938  4624.46680
log_std/mean                          -0.60672     0.01341      -0.57531     -0.63018
log_std/std                           0.36070      0.00955      0.38176      0.34117
log_std/max                           0.62602      0.06216      0.70447      0.45607
log_std/min                           -2.36924     0.28102      -1.85164     -2.82728
log_probs/mean                        0.75158      0.09524      0.93279      0.54421
log_probs/std                         2.64386      0.05635      2.75832      2.44288
log_probs/max                         12.22914     1.13966      16.52639     10.51496
log_probs/min                         -7.46015     1.10702      -5.16566     -9.72396
mean/mean                             0.25569      0.03952      0.32309      0.15190
mean/std                              0.98770      0.01187      1.01063      0.96354
mean/max                              2.88089      0.32936      3.66351      2.48634
mean/min                              -3.16059     0.38934      -2.70525     -3.91681
------------------------------------  -----------  -----------  -----------  ----------
sample: [1, 2, 8, 7, 9, 5, 3, 4, 6, 0]
replay_buffer._size: [25650 25650 25650 25650 25650 25650 25650 25650 25650 25650]
diff1,diff2 9.269889116287231 1.7642974853515625e-05
train_time 9.269969701766968
2023-09-06 12:46:02,875 MainThread INFO: EPOCH:169
2023-09-06 12:46:02,878 MainThread INFO: Time Consumed:9.289262294769287s
2023-09-06 12:46:02,878 MainThread INFO: Total Frames:255000s
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [21:52<04:35,  9.19s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [21:56<03:52,  7.75s/it]
------------------------------------  -----------  -----------  -----------  ----------
Name                                  Value
Running_Average_Rewards               2306.90205
Train_Epoch_Reward                    29503.21951
Running_Training_Average_Rewards      2663.19045
Explore_Time                          0.01497
Train___Time                          9.26997
Eval____Time                          0.00368
button-press-topdown-v1_success_rate  0.00000
button-press-topdown-v1_eval_rewards  -43.92208
6                                     0.00000
door-v1_success_rate                  0.00000
door-v1_eval_rewards                  -26.47402
3                                     0.00000
drawer-close-v1_success_rate          1.00000
drawer-close-v1_eval_rewards          -17.71371
5                                     1.00000
drawer-open-v1_success_rate           0.00000
drawer-open-v1_eval_rewards           -50.96163
4                                     0.00000
ped-insert-side-v1_success_rate       0.00000
ped-insert-side-v1_eval_rewards       -79.69260
7                                     0.00000
pick-place-v1_success_rate            0.00000
pick-place-v1_eval_rewards            -82.02784
2                                     0.00000
push-v1_success_rate                  0.00000
push-v1_eval_rewards                  -35.34904
1                                     0.00000
reach-v1_success_rate                 0.00000
reach-v1_eval_rewards                 24324.62633
0                                     0.00000
window-close-v1_success_rate          0.00000
window-close-v1_eval_rewards          -60.97465
9                                     0.00000
window-open-v1_success_rate           0.00000
window-open-v1_eval_rewards           -50.03602
8                                     0.00000
mean_success_rate                     0.10000

Name                                  Mean         Std          Max          Min
Reward_Mean                           9.09294      1.43699      12.93944     6.68622
alpha_0                               3.92996      0.00322      3.93463      3.92597
alpha_1                               0.09081      0.00028      0.09130      0.09033
alpha_2                               0.10090      0.00034      0.10148      0.10030
alpha_3                               0.10650      0.00037      0.10712      0.10585
alpha_4                               0.08944      0.00034      0.09004      0.08887
alpha_5                               0.08997      0.00033      0.09053      0.08942
alpha_6                               0.08883      0.00036      0.08944      0.08821
alpha_7                               0.08926      0.00036      0.08987      0.08865
alpha_8                               0.08979      0.00029      0.09027      0.08927
alpha_9                               0.10150      0.00036      0.10213      0.10088
Alpha_loss                            -7.55848     0.36188      -6.91774     -8.41442
Training/policy_loss                  -457.06287   15.55536     -422.36008   -496.89865
Training/qf1_loss                     1165.21741   340.86242    2369.71265   697.49066
Training/qf2_loss                     792.77369    229.89401    1554.30798   518.91260
Training/pf_norm                      17.99745     11.88904     58.41308     5.78897
Training/qf1_norm                     24480.91246  13344.17870  59827.62109  7360.51074
Training/qf2_norm                     23877.78176  14053.39560  59655.18359  6134.98584
log_std/mean                          -0.61031     0.01623      -0.57804     -0.63874
log_std/std                           0.36295      0.00724      0.37533      0.34690
log_std/max                           0.67141      0.07334      0.80688      0.47174
log_std/min                           -2.35697     0.32576      -1.80146     -2.99684
log_probs/mean                        0.79311      0.12097      0.98144      0.50439
log_probs/std                         2.52525      0.04952      2.62590      2.44788
log_probs/max                         11.26383     1.48747      16.67389     9.26375
log_probs/min                         -7.46389     1.19436      -5.64393     -11.71597
mean/mean                             0.18529      0.03097      0.25330      0.12060
mean/std                              1.00273      0.01906      1.03199      0.95168
mean/max                              2.68754      0.27136      3.46796      2.39082
mean/min                              -2.96918     0.42523      -2.46469     -3.97036
------------------------------------  -----------  -----------  -----------  ----------
sample: [8, 1, 2, 5, 3, 4, 6, 0, 7, 9]
replay_buffer._size: [25800 25800 25800 25800 25800 25800 25800 25800 25800 25800]
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 149, in _serve
    send(conn, destination_pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 50, in send
    reduction.send_handle(conn, new_fd, pid)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 184, in send_handle
    sendfds(s, [handle])
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 149, in sendfds
    sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)])
BrokenPipeError: [Errno 32] Broken pipe
Process Process-10:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 421, in _recv_bytes
    return self._recv(size)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
first case
[-0.03265199  0.51487863  0.23688568  0.          0.49999998  0.09
  0.          0.7         0.04        0.          0.          0.
  0.          0.          1.          0.          0.          0.
  0.        ]
Process Process-7:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
KeyboardInterrupt
Process Process-15:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-16:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 421, in _recv_bytes
    return self._recv(size)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03264849  0.51488124  0.2368859   0.2         0.79999999  0.15
 -0.2         0.7         0.15        0.          0.          0.
  1.          0.          0.          0.          0.          0.
  0.        ]
Process Process-5:
Process Process-8:
Process Process-12:
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
first case
[-0.03265039  0.51487777  0.2368754   0.          0.6         0.01492813
 -0.1         0.8         0.2         1.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.        ]
Process Process-2:
Process Process-20:
Process Process-4:
Process Process-18:
Process Process-13:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
Process Process-17:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 757, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-3:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "starter/mt_must_sac.py", line 310, in <module>
    experiment(args)
  File "starter/mt_must_sac.py", line 305, in experiment
    agent.train(env.num_tasks,params,group_name)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/rl_algo.py", line 410, in train
    self.update_per_epoch(task_sample_index, task_scheduler, self.mask_buffer, epoch)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 304, in update_per_epoch
    info = self.update(batch, task_sample_index, task_scheduler, mask_buffer)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 123, in update
    q2_device_masks = self.concat_mask_tensors(task_scheduler.task_sample_num,
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/algo/off_policy/must_sac.py", line 47, in concat_mask_tensors
    single_mask = [each.expand(task_batch_size, -1).to(device) for each in specific_mask_buffer[i]]
  File "<string>", line 2, in __getitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 189, in recv_handle
    return recvfds(s, 1)[0]
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 157, in recvfds
    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-19:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Process Process-14:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 318, in _bootstrap
    util._exit_function()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 334, in _exit_function
    _run_finalizers(0)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 887, in _decref
    conn = _Client(token.address, authkey=authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 312, in train_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 322, in train_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 459, in eval_worker_process
    shared_que.put({
  File "<string>", line 2, in put
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 835, in _callmethod
    kind, result = conn.recv()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/scratch/qianxi/t3s/t3s_code/./torchrl/collector/para/async_mt.py", line 456, in eval_worker_process
    state_trajectory[env_info.env_rank] += [episode_state_traj]
  File "<string>", line 2, in __setitem__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/managers.py", line 834, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 405, in _send_bytes
    self._send(buf)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/process.py", line 331, in _bootstrap
    traceback.print_exc()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/scratch/qianxi/t3s/venv/lib/python3.8/site-packages/torch/_fx/graph_module.py", line 27, in patched_getline
    return _orig_getlines(*args, **kwargs)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/tokenize.py", line 392, in open
    buffer = _builtin_open(filename, 'rb')
KeyboardInterrupt
